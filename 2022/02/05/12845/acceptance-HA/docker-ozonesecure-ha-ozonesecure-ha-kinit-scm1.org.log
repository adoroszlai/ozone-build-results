Attaching to ozonesecure-ha_kdc_1, ozonesecure-ha_datanode2_1, ozonesecure-ha_kms_1, ozonesecure-ha_datanode3_1, ozonesecure-ha_om2_1, ozonesecure-ha_datanode1_1, ozonesecure-ha_recon_1, ozonesecure-ha_om3_1, ozonesecure-ha_scm3.org_1, ozonesecure-ha_scm2.org_1, ozonesecure-ha_scm1.org_1, ozonesecure-ha_s3g_1, ozonesecure-ha_om1_1
datanode3_1  | Sleeping for 5 seconds
datanode3_1  | Waiting for the service scm3.org:9894
datanode3_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode3_1  | 2022-02-05 13:08:38,168 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode3_1  | /************************************************************
datanode3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode3_1  | STARTUP_MSG:   host = 1e40b8f48f78/172.25.0.104
datanode3_1  | STARTUP_MSG:   args = []
datanode3_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode3_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/f757d9929c7016e9989d08ab2698179d61ef158b ; compiled by 'runner' on 2022-02-05T12:45Z
datanode3_1  | STARTUP_MSG:   java = 11.0.13
datanode3_1  | ************************************************************/
datanode3_1  | 2022-02-05 13:08:38,260 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode3_1  | 2022-02-05 13:08:40,252 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode3_1  | 2022-02-05 13:08:40,974 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode3_1  | 2022-02-05 13:08:42,053 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode3_1  | 2022-02-05 13:08:42,054 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode3_1  | 2022-02-05 13:08:43,111 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:1e40b8f48f78 ip:172.25.0.104
datanode3_1  | 2022-02-05 13:08:46,476 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode3_1  | 2022-02-05 13:08:47,481 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode3_1  | 2022-02-05 13:08:47,494 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode3_1  | 2022-02-05 13:08:49,636 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode3_1  | 2022-02-05 13:08:49,656 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode3_1  | 2022-02-05 13:08:49,656 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode3_1  | 2022-02-05 13:08:49,659 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode3_1  | 2022-02-05 13:08:58,645 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode3_1  | 2022-02-05 13:08:58,738 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.104,host:1e40b8f48f78
datanode3_1  | 2022-02-05 13:08:58,738 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode3_1  | 2022-02-05 13:08:58,763 [main] ERROR client.DNCertificateClient: Invalid domain 1e40b8f48f78
datanode3_1  | 2022-02-05 13:08:58,772 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@1e40b8f48f78
datanode3_1  | 2022-02-05 13:09:03,901 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode3_1  | 2022-02-05 13:09:03,996 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode3_1  | 2022-02-05 13:09:04,008 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-850810018938.crt.
datanode3_1  | 2022-02-05 13:09:04,020 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/941044329628.crt.
datanode3_1  | 2022-02-05 13:09:04,020 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode3_1  | 2022-02-05 13:09:04,162 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
datanode3_1  | 2022-02-05 13:09:05,049 [main] INFO reflections.Reflections: Reflections took 670 ms to scan 2 urls, producing 85 keys and 173 values 
datanode3_1  | 2022-02-05 13:09:05,413 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode3_1  | 2022-02-05 13:09:07,400 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode3_1  | 2022-02-05 13:09:07,526 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode3_1  | 2022-02-05 13:09:07,630 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode3_1  | 2022-02-05 13:09:07,631 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode3_1  | 2022-02-05 13:09:08,036 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode3_1  | 2022-02-05 13:09:08,268 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2022-02-05 13:09:08,283 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode3_1  | 2022-02-05 13:09:08,295 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode3_1  | 2022-02-05 13:09:08,295 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode3_1  | 2022-02-05 13:09:08,296 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode3_1  | 2022-02-05 13:09:08,457 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode3_1  | 2022-02-05 13:09:08,458 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode3_1  | 2022-02-05 13:09:15,133 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2022-02-05 13:09:15,520 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode3_1  | 2022-02-05 13:09:16,290 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode3_1  | 2022-02-05 13:09:16,302 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode3_1  | 2022-02-05 13:09:16,305 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode3_1  | 2022-02-05 13:09:16,307 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode3_1  | 2022-02-05 13:09:16,312 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-02-05 13:09:16,318 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode3_1  | 2022-02-05 13:09:16,324 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-02-05 13:09:22,727 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode3_1  | 2022-02-05 13:09:22,747 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-02-05 13:09:22,753 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-02-05 13:09:22,871 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-02-05 13:09:23,439 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode3_1  | 2022-02-05 13:09:24,532 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode3_1  | 2022-02-05 13:09:24,532 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode3_1  | 2022-02-05 13:09:24,533 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode3_1  | 2022-02-05 13:09:24,756 [main] INFO util.log: Logging initialized @54685ms to org.eclipse.jetty.util.log.Slf4jLog
datanode3_1  | 2022-02-05 13:09:25,550 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode3_1  | 2022-02-05 13:09:25,571 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode3_1  | 2022-02-05 13:09:25,572 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode3_1  | 2022-02-05 13:09:25,572 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode3_1  | 2022-02-05 13:09:25,572 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode3_1  | 2022-02-05 13:09:25,576 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode3_1  | 2022-02-05 13:09:26,104 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode3_1  | 2022-02-05 13:09:26,147 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-LTS
datanode3_1  | 2022-02-05 13:09:26,568 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode3_1  | 2022-02-05 13:09:26,568 [main] INFO server.session: No SessionScavenger set, using defaults
datanode3_1  | 2022-02-05 13:09:26,618 [main] INFO server.session: node0 Scavenging every 600000ms
datanode3_1  | 2022-02-05 13:09:26,793 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2022-02-05 13:09:26,816 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2c34ce24{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode3_1  | 2022-02-05 13:09:26,817 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6a35cccf{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode3_1  | 2022-02-05 13:09:27,962 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2022-02-05 13:09:28,094 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5c168f98{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-769771279196665951/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode3_1  | 2022-02-05 13:09:28,195 [main] INFO server.AbstractConnector: Started ServerConnector@23b02f37{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode3_1  | 2022-02-05 13:09:28,202 [main] INFO server.Server: Started @58131ms
datanode3_1  | 2022-02-05 13:09:28,218 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode3_1  | 2022-02-05 13:09:28,218 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode3_1  | 2022-02-05 13:09:28,226 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode3_1  | 2022-02-05 13:09:28,248 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode3_1  | 2022-02-05 13:09:28,547 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@21571f90] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode3_1  | 2022-02-05 13:09:28,956 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode3_1  | 2022-02-05 13:09:31,520 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode3_1  | 2022-02-05 13:09:31,535 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode3_1  | 2022-02-05 13:09:32,089 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis a527daad-fcfc-4913-bb86-57ba7fce9b83
datanode3_1  | 2022-02-05 13:09:32,306 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.RaftServer: a527daad-fcfc-4913-bb86-57ba7fce9b83: start RPC server
datanode3_1  | 2022-02-05 13:09:32,314 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: a527daad-fcfc-4913-bb86-57ba7fce9b83: GrpcService started, listening on 9856
datanode3_1  | 2022-02-05 13:09:32,316 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: a527daad-fcfc-4913-bb86-57ba7fce9b83: GrpcService started, listening on 9857
datanode3_1  | 2022-02-05 13:09:32,328 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: a527daad-fcfc-4913-bb86-57ba7fce9b83: GrpcService started, listening on 9858
datanode3_1  | 2022-02-05 13:09:32,360 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis a527daad-fcfc-4913-bb86-57ba7fce9b83 is started using port 9858 for RATIS
datanode3_1  | 2022-02-05 13:09:32,360 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis a527daad-fcfc-4913-bb86-57ba7fce9b83 is started using port 9857 for RATIS_ADMIN
datanode3_1  | 2022-02-05 13:09:32,360 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis a527daad-fcfc-4913-bb86-57ba7fce9b83 is started using port 9856 for RATIS_SERVER
datanode3_1  | 2022-02-05 13:09:32,368 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$347/0x00000008405b6c40@3f0c8db] INFO util.JvmPauseMonitor: JvmPauseMonitor-a527daad-fcfc-4913-bb86-57ba7fce9b83: Started
datanode3_1  | 2022-02-05 13:09:32,402 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2022-02-05 13:09:32,402 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2022-02-05 13:09:35,620 [Command processor thread] INFO server.RaftServer: a527daad-fcfc-4913-bb86-57ba7fce9b83: addNew group-0D06090717C7:[a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] returns group-0D06090717C7:java.util.concurrent.CompletableFuture@18e5a88d[Not completed]
datanode3_1  | 2022-02-05 13:09:35,739 [pool-23-thread-1] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83: new RaftServerImpl for group-0D06090717C7:[a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-02-05 13:09:35,751 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-02-05 13:09:35,758 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-02-05 13:09:35,760 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-02-05 13:09:35,765 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-02-05 13:09:35,765 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-02-05 13:09:35,765 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-02-05 13:09:35,766 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-02-05 13:09:35,798 [pool-23-thread-1] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7: ConfigurationManager, init=-1: [a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-02-05 13:09:35,814 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-02-05 13:09:35,848 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-02-05 13:09:35,867 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-02-05 13:09:35,869 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/194f5d50-3ed1-4cfa-a521-0d06090717c7 does not exist. Creating ...
datanode3_1  | 2022-02-05 13:09:35,889 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/194f5d50-3ed1-4cfa-a521-0d06090717c7/in_use.lock acquired by nodename 9@1e40b8f48f78
datanode3_1  | 2022-02-05 13:09:35,905 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/194f5d50-3ed1-4cfa-a521-0d06090717c7 has been successfully formatted.
datanode3_1  | 2022-02-05 13:09:35,970 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-0D06090717C7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-02-05 13:09:35,987 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-02-05 13:09:36,015 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-02-05 13:09:36,116 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-02-05 13:09:36,120 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-02-05 13:09:36,229 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-02-05 13:09:36,304 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-02-05 13:09:36,305 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-02-05 13:09:36,348 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/194f5d50-3ed1-4cfa-a521-0d06090717c7
datanode3_1  | 2022-02-05 13:09:36,348 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode3_1  | 2022-02-05 13:09:36,360 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-02-05 13:09:36,361 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-02-05 13:09:36,361 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-02-05 13:09:36,361 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-02-05 13:09:36,377 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-02-05 13:09:36,377 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-02-05 13:09:36,377 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-02-05 13:09:36,449 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-02-05 13:09:36,450 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-02-05 13:09:36,493 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-02-05 13:09:36,493 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-02-05 13:09:36,517 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-02-05 13:09:36,532 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-02-05 13:09:36,534 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-02-05 13:09:36,536 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-02-05 13:09:36,546 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-02-05 13:09:36,553 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-02-05 13:09:36,714 [pool-23-thread-1] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7: start as a follower, conf=-1: [a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2022-02-05 13:09:36,728 [pool-23-thread-1] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-02-05 13:09:36,731 [pool-23-thread-1] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: start a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-FollowerState
datanode3_1  | 2022-02-05 13:09:36,764 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0D06090717C7,id=a527daad-fcfc-4913-bb86-57ba7fce9b83
datanode3_1  | 2022-02-05 13:09:36,846 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=194f5d50-3ed1-4cfa-a521-0d06090717c7
datanode3_1  | 2022-02-05 13:09:36,847 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=194f5d50-3ed1-4cfa-a521-0d06090717c7.
datanode3_1  | 2022-02-05 13:09:36,848 [Command processor thread] INFO server.RaftServer: a527daad-fcfc-4913-bb86-57ba7fce9b83: addNew group-139BDF3E2545:[9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0] returns group-139BDF3E2545:java.util.concurrent.CompletableFuture@17af6638[Not completed]
datanode3_1  | 2022-02-05 13:09:36,872 [pool-23-thread-1] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83: new RaftServerImpl for group-139BDF3E2545:[9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-02-05 13:09:36,877 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-02-05 13:09:36,880 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-02-05 13:09:36,880 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-02-05 13:09:36,882 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-02-05 13:09:36,882 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-02-05 13:09:36,882 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-02-05 13:09:36,883 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-02-05 13:09:36,883 [pool-23-thread-1] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545: ConfigurationManager, init=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-02-05 13:09:36,883 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-02-05 13:09:36,886 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-02-05 13:09:36,888 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-02-05 13:09:36,888 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/cd0dbfd1-bf28-4717-93ea-139bdf3e2545 does not exist. Creating ...
datanode3_1  | 2022-02-05 13:09:36,895 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/cd0dbfd1-bf28-4717-93ea-139bdf3e2545/in_use.lock acquired by nodename 9@1e40b8f48f78
datanode3_1  | 2022-02-05 13:09:36,903 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/cd0dbfd1-bf28-4717-93ea-139bdf3e2545 has been successfully formatted.
datanode3_1  | 2022-02-05 13:09:36,904 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-139BDF3E2545: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-02-05 13:09:36,904 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-02-05 13:09:36,904 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-02-05 13:09:36,906 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-02-05 13:09:36,907 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-02-05 13:09:36,907 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-02-05 13:09:36,908 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-02-05 13:09:36,909 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-02-05 13:09:36,910 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/cd0dbfd1-bf28-4717-93ea-139bdf3e2545
datanode3_1  | 2022-02-05 13:09:36,946 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode3_1  | 2022-02-05 13:09:36,946 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-02-05 13:09:36,947 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-02-05 13:09:36,947 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-02-05 13:09:36,948 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-02-05 13:09:36,963 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-02-05 13:09:36,964 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-02-05 13:09:36,966 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-02-05 13:09:36,975 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-02-05 13:09:36,985 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-02-05 13:09:36,994 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-02-05 13:09:36,999 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-02-05 13:09:36,999 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-02-05 13:09:37,001 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-02-05 13:09:37,001 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-02-05 13:09:37,001 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-02-05 13:09:37,002 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-02-05 13:09:37,004 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-02-05 13:09:37,008 [pool-23-thread-1] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545: start as a follower, conf=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode3_1  | 2022-02-05 13:09:37,027 [pool-23-thread-1] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | Sleeping for 5 seconds
datanode2_1  | Waiting for the service scm3.org:9894
datanode2_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode2_1  | 2022-02-05 13:08:39,119 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode2_1  | /************************************************************
datanode2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode2_1  | STARTUP_MSG:   host = e3be6b71356d/172.25.0.103
datanode2_1  | STARTUP_MSG:   args = []
datanode2_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode2_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/f757d9929c7016e9989d08ab2698179d61ef158b ; compiled by 'runner' on 2022-02-05T12:45Z
datanode2_1  | STARTUP_MSG:   java = 11.0.13
datanode2_1  | ************************************************************/
datanode2_1  | 2022-02-05 13:08:39,240 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode2_1  | 2022-02-05 13:08:41,367 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode2_1  | 2022-02-05 13:08:42,052 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode2_1  | 2022-02-05 13:08:43,087 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode2_1  | 2022-02-05 13:08:43,098 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode2_1  | 2022-02-05 13:08:44,173 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:e3be6b71356d ip:172.25.0.103
datanode2_1  | 2022-02-05 13:08:47,566 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode2_1  | 2022-02-05 13:08:48,682 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode2_1  | 2022-02-05 13:08:48,691 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode2_1  | 2022-02-05 13:08:50,630 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode2_1  | 2022-02-05 13:08:50,641 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode2_1  | 2022-02-05 13:08:50,641 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode2_1  | 2022-02-05 13:08:50,659 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode2_1  | 2022-02-05 13:08:56,354 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode2_1  | 2022-02-05 13:08:56,431 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.103,host:e3be6b71356d
datanode2_1  | 2022-02-05 13:08:56,431 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode2_1  | 2022-02-05 13:08:56,467 [main] ERROR client.DNCertificateClient: Invalid domain e3be6b71356d
datanode2_1  | 2022-02-05 13:08:56,473 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@e3be6b71356d
datanode2_1  | 2022-02-05 13:09:01,063 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode2_1  | 2022-02-05 13:09:01,122 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode2_1  | 2022-02-05 13:09:01,128 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-850810018938.crt.
datanode2_1  | 2022-02-05 13:09:01,140 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/938407921790.crt.
datanode2_1  | 2022-02-05 13:09:01,140 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode2_1  | 2022-02-05 13:09:01,229 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
datanode2_1  | 2022-02-05 13:09:02,207 [main] INFO reflections.Reflections: Reflections took 791 ms to scan 2 urls, producing 85 keys and 173 values 
datanode2_1  | 2022-02-05 13:09:02,702 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode2_1  | 2022-02-05 13:09:03,927 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode2_1  | 2022-02-05 13:09:04,024 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode2_1  | 2022-02-05 13:09:04,028 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode2_1  | 2022-02-05 13:09:04,048 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode2_1  | 2022-02-05 13:09:04,295 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode2_1  | 2022-02-05 13:09:04,393 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2022-02-05 13:09:04,399 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode2_1  | 2022-02-05 13:09:04,409 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode2_1  | 2022-02-05 13:09:04,410 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode2_1  | 2022-02-05 13:09:04,410 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode2_1  | 2022-02-05 13:09:04,578 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode2_1  | 2022-02-05 13:09:04,588 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode2_1  | 2022-02-05 13:09:11,844 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2022-02-05 13:09:12,195 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode2_1  | 2022-02-05 13:09:13,169 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode2_1  | 2022-02-05 13:09:13,174 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode2_1  | 2022-02-05 13:09:13,175 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode2_1  | 2022-02-05 13:09:13,178 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode2_1  | 2022-02-05 13:09:13,183 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-02-05 13:09:13,206 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode2_1  | 2022-02-05 13:09:13,208 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-02-05 13:09:19,608 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode2_1  | 2022-02-05 13:09:19,615 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-02-05 13:09:19,621 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-02-05 13:09:19,685 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-02-05 13:09:20,157 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode2_1  | 2022-02-05 13:09:21,075 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode2_1  | 2022-02-05 13:09:21,081 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode2_1  | 2022-02-05 13:09:21,086 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode2_1  | 2022-02-05 13:09:21,394 [main] INFO util.log: Logging initialized @50296ms to org.eclipse.jetty.util.log.Slf4jLog
datanode2_1  | 2022-02-05 13:09:22,371 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode2_1  | 2022-02-05 13:09:22,407 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode2_1  | 2022-02-05 13:09:22,429 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode2_1  | 2022-02-05 13:09:22,430 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode2_1  | 2022-02-05 13:09:22,436 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode2_1  | 2022-02-05 13:09:22,463 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode2_1  | 2022-02-05 13:09:22,875 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode2_1  | 2022-02-05 13:09:22,887 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-LTS
datanode2_1  | 2022-02-05 13:09:23,129 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode2_1  | 2022-02-05 13:09:23,129 [main] INFO server.session: No SessionScavenger set, using defaults
datanode2_1  | 2022-02-05 13:09:23,166 [main] INFO server.session: node0 Scavenging every 600000ms
datanode2_1  | 2022-02-05 13:09:23,311 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2022-02-05 13:09:23,336 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3bb6b9ab{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode2_1  | 2022-02-05 13:09:23,338 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1ef8f7e6{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode2_1  | 2022-02-05 13:09:23,839 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2022-02-05 13:09:23,928 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3582077c{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-14116357680770572454/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode2_1  | 2022-02-05 13:09:23,986 [main] INFO server.AbstractConnector: Started ServerConnector@57f83dc7{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode2_1  | 2022-02-05 13:09:23,990 [main] INFO server.Server: Started @52893ms
datanode2_1  | 2022-02-05 13:09:24,004 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode2_1  | 2022-02-05 13:09:24,004 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode2_1  | 2022-02-05 13:09:24,025 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode2_1  | 2022-02-05 13:09:24,066 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode2_1  | 2022-02-05 13:09:24,463 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@54897357] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode2_1  | 2022-02-05 13:09:24,811 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode2_1  | 2022-02-05 13:09:27,615 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode2_1  | 2022-02-05 13:09:27,662 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode2_1  | 2022-02-05 13:09:28,285 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 3bd141d9-8d6a-4889-940a-437a7867e049
datanode2_1  | 2022-02-05 13:09:28,470 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.RaftServer: 3bd141d9-8d6a-4889-940a-437a7867e049: start RPC server
datanode2_1  | 2022-02-05 13:09:28,487 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 3bd141d9-8d6a-4889-940a-437a7867e049: GrpcService started, listening on 9856
datanode2_1  | 2022-02-05 13:09:28,499 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 3bd141d9-8d6a-4889-940a-437a7867e049: GrpcService started, listening on 9857
datanode2_1  | 2022-02-05 13:09:28,503 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 3bd141d9-8d6a-4889-940a-437a7867e049: GrpcService started, listening on 9858
datanode2_1  | 2022-02-05 13:09:28,581 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 3bd141d9-8d6a-4889-940a-437a7867e049 is started using port 9858 for RATIS
datanode2_1  | 2022-02-05 13:09:28,586 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 3bd141d9-8d6a-4889-940a-437a7867e049 is started using port 9857 for RATIS_ADMIN
datanode2_1  | 2022-02-05 13:09:28,586 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 3bd141d9-8d6a-4889-940a-437a7867e049 is started using port 9856 for RATIS_SERVER
datanode2_1  | 2022-02-05 13:09:28,587 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$346/0x00000008405b6840@f512643] INFO util.JvmPauseMonitor: JvmPauseMonitor-3bd141d9-8d6a-4889-940a-437a7867e049: Started
datanode2_1  | 2022-02-05 13:09:28,618 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2022-02-05 13:09:28,915 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2022-02-05 13:09:41,272 [grpc-default-executor-0] INFO server.RaftServer: 3bd141d9-8d6a-4889-940a-437a7867e049: addNew group-139BDF3E2545:[9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0] returns group-139BDF3E2545:java.util.concurrent.CompletableFuture@445c4da2[Not completed]
datanode2_1  | 2022-02-05 13:09:41,349 [pool-23-thread-1] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049: new RaftServerImpl for group-139BDF3E2545:[9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
datanode1_1  | Sleeping for 5 seconds
datanode1_1  | Waiting for the service scm3.org:9894
datanode1_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode1_1  | 2022-02-05 13:08:38,560 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode1_1  | /************************************************************
datanode1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode1_1  | STARTUP_MSG:   host = f6267b87e946/172.25.0.102
datanode1_1  | STARTUP_MSG:   args = []
datanode1_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode1_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/f757d9929c7016e9989d08ab2698179d61ef158b ; compiled by 'runner' on 2022-02-05T12:45Z
datanode1_1  | STARTUP_MSG:   java = 11.0.13
datanode1_1  | ************************************************************/
datanode1_1  | 2022-02-05 13:08:38,655 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode1_1  | 2022-02-05 13:08:40,567 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode1_1  | 2022-02-05 13:08:41,271 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode1_1  | 2022-02-05 13:08:42,150 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode1_1  | 2022-02-05 13:08:42,174 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode1_1  | 2022-02-05 13:08:43,302 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:f6267b87e946 ip:172.25.0.102
datanode1_1  | 2022-02-05 13:08:46,528 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode1_1  | 2022-02-05 13:08:47,604 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode1_1  | 2022-02-05 13:08:47,604 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode1_1  | 2022-02-05 13:08:50,010 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode1_1  | 2022-02-05 13:08:50,013 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode1_1  | 2022-02-05 13:08:50,014 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode1_1  | 2022-02-05 13:08:50,015 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode1_1  | 2022-02-05 13:08:54,142 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode1_1  | 2022-02-05 13:08:54,207 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.102,host:f6267b87e946
datanode1_1  | 2022-02-05 13:08:54,207 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode1_1  | 2022-02-05 13:08:54,243 [main] ERROR client.DNCertificateClient: Invalid domain f6267b87e946
datanode1_1  | 2022-02-05 13:08:54,246 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@f6267b87e946
datanode1_1  | 2022-02-05 13:08:59,612 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode1_1  | 2022-02-05 13:08:59,683 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/936463488335.crt.
datanode1_1  | 2022-02-05 13:08:59,716 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode1_1  | 2022-02-05 13:08:59,724 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-850810018938.crt.
datanode1_1  | 2022-02-05 13:08:59,724 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode1_1  | 2022-02-05 13:08:59,882 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
datanode1_1  | 2022-02-05 13:09:00,945 [main] INFO reflections.Reflections: Reflections took 777 ms to scan 2 urls, producing 85 keys and 173 values 
datanode1_1  | 2022-02-05 13:09:01,442 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode1_1  | 2022-02-05 13:09:02,825 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode1_1  | 2022-02-05 13:09:02,901 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode1_1  | 2022-02-05 13:09:02,923 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode1_1  | 2022-02-05 13:09:02,939 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode1_1  | 2022-02-05 13:09:03,144 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode1_1  | 2022-02-05 13:09:03,245 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2022-02-05 13:09:03,251 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode1_1  | 2022-02-05 13:09:03,270 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode1_1  | 2022-02-05 13:09:03,274 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode1_1  | 2022-02-05 13:09:03,274 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode1_1  | 2022-02-05 13:09:03,408 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode1_1  | 2022-02-05 13:09:03,452 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode1_1  | 2022-02-05 13:09:11,630 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2022-02-05 13:09:12,132 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode1_1  | 2022-02-05 13:09:13,058 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode1_1  | 2022-02-05 13:09:13,064 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode1_1  | 2022-02-05 13:09:13,066 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode1_1  | 2022-02-05 13:09:13,066 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode1_1  | 2022-02-05 13:09:13,078 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-02-05 13:09:13,079 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode1_1  | 2022-02-05 13:09:13,080 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2022-02-05 13:09:18,385 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode1_1  | 2022-02-05 13:09:18,404 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-02-05 13:09:18,475 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-02-05 13:09:18,837 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-02-05 13:09:19,260 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode1_1  | 2022-02-05 13:09:20,071 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode1_1  | 2022-02-05 13:09:20,074 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
kdc_1        | Feb 05 13:07:05 kdc krb5kdc[6](info): Loaded
kdc_1        | Feb 05 13:07:05 kdc krb5kdc[6](Error): preauth spake failed to initialize: No SPAKE preauth groups configured
kdc_1        | Feb 05 13:07:05 kdc krb5kdc[6](info): setting up network...
kdc_1        | Feb 05 13:07:05 kdc krb5kdc[6](info): setsockopt(8,IPV6_V6ONLY,1) worked
kdc_1        | Feb 05 13:07:05 kdc krb5kdc[6](info): setsockopt(10,IPV6_V6ONLY,1) worked
kdc_1        | Feb 05 13:07:05 kdc krb5kdc[6](info): set up 4 sockets
kdc_1        | Feb 05 13:07:05 kdc krb5kdc[6](info): commencing operation
kdc_1        | krb5kdc: starting...
kdc_1        | Feb 05 13:07:09 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066429, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:07:16 kdc krb5kdc[6](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.114: ISSUE: authtime 1644066436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, s3g/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:07:19 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066439, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:07:21 kdc krb5kdc[6](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.115: ISSUE: authtime 1644066441, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:07:37 kdc krb5kdc[6](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1644066457, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:07:44 kdc krb5kdc[6](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.116: ISSUE: authtime 1644066464, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:07:48 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: ISSUE: authtime 1644066441, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 05 13:07:50 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1644066457, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 05 13:07:52 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066439, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 05 13:07:56 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066476, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:08:03 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066476, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 05 13:08:05 kdc krb5kdc[6](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1644066485, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:08:07 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066487, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:08:11 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1644066485, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 05 13:08:15 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066487, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 05 13:08:15 kdc krb5kdc[6](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1644066495, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:08:16 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1644066495, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
datanode2_1  | 2022-02-05 13:09:41,367 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-02-05 13:09:41,377 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-02-05 13:09:41,379 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-02-05 13:09:41,382 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-02-05 13:09:41,386 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-02-05 13:09:41,386 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-02-05 13:09:41,387 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-02-05 13:09:41,404 [pool-23-thread-1] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-139BDF3E2545: ConfigurationManager, init=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-02-05 13:09:41,413 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-02-05 13:09:41,434 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-02-05 13:09:41,446 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-02-05 13:09:41,449 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/cd0dbfd1-bf28-4717-93ea-139bdf3e2545 does not exist. Creating ...
datanode2_1  | 2022-02-05 13:09:41,473 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/cd0dbfd1-bf28-4717-93ea-139bdf3e2545/in_use.lock acquired by nodename 7@e3be6b71356d
datanode2_1  | 2022-02-05 13:09:41,496 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/cd0dbfd1-bf28-4717-93ea-139bdf3e2545 has been successfully formatted.
datanode2_1  | 2022-02-05 13:09:41,567 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-139BDF3E2545: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-02-05 13:09:41,571 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-02-05 13:09:41,678 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-02-05 13:09:41,785 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-02-05 13:09:41,829 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-02-05 13:09:41,832 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-02-05 13:09:41,901 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-02-05 13:09:41,924 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-02-05 13:09:41,997 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 3bd141d9-8d6a-4889-940a-437a7867e049@group-139BDF3E2545-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/cd0dbfd1-bf28-4717-93ea-139bdf3e2545
datanode2_1  | 2022-02-05 13:09:41,998 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode2_1  | 2022-02-05 13:09:42,000 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-02-05 13:09:42,009 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-02-05 13:09:42,018 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-02-05 13:09:42,024 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-02-05 13:09:42,034 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-02-05 13:09:42,038 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-02-05 13:09:42,038 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-02-05 13:09:42,085 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-02-05 13:09:42,111 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-02-05 13:09:42,178 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 3bd141d9-8d6a-4889-940a-437a7867e049@group-139BDF3E2545-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-02-05 13:09:42,178 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 3bd141d9-8d6a-4889-940a-437a7867e049@group-139BDF3E2545-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-02-05 13:09:42,208 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-02-05 13:09:42,238 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-02-05 13:09:42,238 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-02-05 13:09:42,239 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-02-05 13:09:42,251 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-02-05 13:09:42,258 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-02-05 13:09:42,582 [pool-23-thread-1] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-139BDF3E2545: start as a follower, conf=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-02-05 13:09:42,601 [pool-23-thread-1] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-139BDF3E2545: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-02-05 13:09:42,642 [pool-23-thread-1] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: start 3bd141d9-8d6a-4889-940a-437a7867e049@group-139BDF3E2545-FollowerState
datanode2_1  | 2022-02-05 13:09:42,712 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-139BDF3E2545,id=3bd141d9-8d6a-4889-940a-437a7867e049
datanode3_1  | 2022-02-05 13:09:37,030 [pool-23-thread-1] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: start a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-FollowerState
datanode3_1  | 2022-02-05 13:09:37,050 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-139BDF3E2545,id=a527daad-fcfc-4913-bb86-57ba7fce9b83
datanode3_1  | 2022-02-05 13:09:37,059 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=cd0dbfd1-bf28-4717-93ea-139bdf3e2545
datanode3_1  | 2022-02-05 13:09:41,824 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-FollowerState] INFO impl.FollowerState: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5093619252ns, electionTimeout:5057ms
datanode3_1  | 2022-02-05 13:09:41,825 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-FollowerState] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: shutdown a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-FollowerState
datanode3_1  | 2022-02-05 13:09:41,827 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-FollowerState] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2022-02-05 13:09:41,833 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-02-05 13:09:41,833 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-FollowerState] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: start a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-LeaderElection1
datanode3_1  | 2022-02-05 13:09:41,849 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-LeaderElection1] INFO impl.LeaderElection: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2022-02-05 13:09:41,849 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-LeaderElection1] INFO impl.LeaderElection: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode3_1  | 2022-02-05 13:09:41,850 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-LeaderElection1] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: shutdown a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-LeaderElection1
datanode3_1  | 2022-02-05 13:09:41,850 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-LeaderElection1] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode3_1  | 2022-02-05 13:09:41,850 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-0D06090717C7 with new leaderId: a527daad-fcfc-4913-bb86-57ba7fce9b83
datanode3_1  | 2022-02-05 13:09:41,851 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-LeaderElection1] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7: change Leader from null to a527daad-fcfc-4913-bb86-57ba7fce9b83 at term 1 for becomeLeader, leader elected after 5878ms
datanode3_1  | 2022-02-05 13:09:41,891 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2022-02-05 13:09:41,926 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-02-05 13:09:41,927 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode3_1  | 2022-02-05 13:09:41,963 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2022-02-05 13:09:41,963 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2022-02-05 13:09:41,963 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2022-02-05 13:09:41,992 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-02-05 13:09:42,000 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode3_1  | 2022-02-05 13:09:42,012 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-LeaderElection1] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: start a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-LeaderStateImpl
datanode3_1  | 2022-02-05 13:09:42,221 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-02-05 13:09:42,249 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-FollowerState] INFO impl.FollowerState: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5218859060ns, electionTimeout:5185ms
datanode3_1  | 2022-02-05 13:09:42,251 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-FollowerState] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: shutdown a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-FollowerState
datanode3_1  | 2022-02-05 13:09:42,251 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-FollowerState] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2022-02-05 13:09:42,251 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-02-05 13:09:42,258 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-FollowerState] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: start a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2
datanode3_1  | 2022-02-05 13:09:42,332 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO impl.LeaderElection: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode3_1  | 2022-02-05 13:09:42,552 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-LeaderElection1] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7: set configuration 0: [a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode3_1  | 2022-02-05 13:09:42,887 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-0D06090717C7-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/194f5d50-3ed1-4cfa-a521-0d06090717c7/current/log_inprogress_0
datanode3_1  | 2022-02-05 13:09:43,230 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO impl.LeaderElection: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode3_1  | 2022-02-05 13:09:43,231 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO impl.LeaderElection:   Response 0: a527daad-fcfc-4913-bb86-57ba7fce9b83<-3bd141d9-8d6a-4889-940a-437a7867e049#0:OK-t1
datanode3_1  | 2022-02-05 13:09:43,243 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO impl.LeaderElection: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2 ELECTION round 0: result PASSED
datanode3_1  | 2022-02-05 13:09:43,248 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: shutdown a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2
datanode3_1  | 2022-02-05 13:09:43,250 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode3_1  | 2022-02-05 13:09:43,251 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-139BDF3E2545 with new leaderId: a527daad-fcfc-4913-bb86-57ba7fce9b83
datanode3_1  | 2022-02-05 13:09:43,251 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545: change Leader from null to a527daad-fcfc-4913-bb86-57ba7fce9b83 at term 1 for becomeLeader, leader elected after 6346ms
datanode3_1  | 2022-02-05 13:09:43,257 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2022-02-05 13:09:43,280 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-02-05 13:09:43,290 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode3_1  | 2022-02-05 13:09:43,291 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2022-02-05 13:09:43,291 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2022-02-05 13:09:43,291 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2022-02-05 13:09:43,291 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-02-05 13:09:43,292 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode3_1  | 2022-02-05 13:09:43,374 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2022-02-05 13:09:43,374 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-02-05 13:09:43,375 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2022-02-05 13:09:43,389 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2022-02-05 13:09:43,403 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-02-05 13:09:43,404 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-02-05 13:09:43,454 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2022-02-05 13:09:43,458 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-02-05 13:09:43,478 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2022-02-05 13:09:43,478 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2022-02-05 13:09:43,479 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-02-05 13:09:43,482 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-02-05 13:09:43,493 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: start a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderStateImpl
datanode3_1  | 2022-02-05 13:09:43,494 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-02-05 13:09:43,514 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/cd0dbfd1-bf28-4717-93ea-139bdf3e2545/current/log_inprogress_0
datanode3_1  | 2022-02-05 13:09:43,576 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545-LeaderElection2] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545: set configuration 0: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-02-05 13:09:46,886 [grpc-default-executor-0] INFO leader.FollowerInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee: nextIndex: updateUnconditionally 1 -> 0
datanode3_1  | 2022-02-05 13:09:46,893 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=cd0dbfd1-bf28-4717-93ea-139bdf3e2545.
kdc_1        | Feb 05 13:08:19 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066499, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:08:24 kdc krb5kdc[6](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1644066504, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:08:26 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066499, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 05 13:08:30 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066510, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:08:31 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1644066504, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 05 13:08:47 kdc krb5kdc[6](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.104: ISSUE: authtime 1644066527, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:08:47 kdc krb5kdc[6](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.102: ISSUE: authtime 1644066527, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:08:48 kdc krb5kdc[6](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.103: ISSUE: authtime 1644066528, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:08:50 kdc krb5kdc[6](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1644066530, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:08:50 kdc krb5kdc[6](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1644066530, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:08:50 kdc krb5kdc[6](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1644066530, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:08:54 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1644066530, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 05 13:08:54 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1644066530, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 05 13:08:54 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1644066530, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 05 13:08:57 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1644066527, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 05 13:08:59 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1644066528, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 05 13:09:01 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066510, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 05 13:09:02 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1644066527, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 05 13:09:08 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066548, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:09:25 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1644066527, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
datanode2_1  | 2022-02-05 13:09:43,174 [grpc-default-executor-0] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-139BDF3E2545: receive requestVote(ELECTION, a527daad-fcfc-4913-bb86-57ba7fce9b83, group-139BDF3E2545, 1, (t:0, i:0))
datanode2_1  | 2022-02-05 13:09:43,184 [grpc-default-executor-0] INFO impl.VoteContext: 3bd141d9-8d6a-4889-940a-437a7867e049@group-139BDF3E2545-FOLLOWER: accept ELECTION from a527daad-fcfc-4913-bb86-57ba7fce9b83: our priority 0 <= candidate's priority 1
datanode2_1  | 2022-02-05 13:09:43,189 [grpc-default-executor-0] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-139BDF3E2545: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:a527daad-fcfc-4913-bb86-57ba7fce9b83
datanode2_1  | 2022-02-05 13:09:43,194 [grpc-default-executor-0] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: shutdown 3bd141d9-8d6a-4889-940a-437a7867e049@group-139BDF3E2545-FollowerState
datanode2_1  | 2022-02-05 13:09:43,196 [grpc-default-executor-0] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: start 3bd141d9-8d6a-4889-940a-437a7867e049@group-139BDF3E2545-FollowerState
datanode2_1  | 2022-02-05 13:09:43,196 [3bd141d9-8d6a-4889-940a-437a7867e049@group-139BDF3E2545-FollowerState] INFO impl.FollowerState: 3bd141d9-8d6a-4889-940a-437a7867e049@group-139BDF3E2545-FollowerState was interrupted: {}
datanode2_1  | java.lang.InterruptedException: sleep interrupted
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode2_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode2_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode2_1  | 2022-02-05 13:09:43,204 [grpc-default-executor-0] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-139BDF3E2545 replies to ELECTION vote request: a527daad-fcfc-4913-bb86-57ba7fce9b83<-3bd141d9-8d6a-4889-940a-437a7867e049#0:OK-t1. Peer's state: 3bd141d9-8d6a-4889-940a-437a7867e049@group-139BDF3E2545:t1, leader=null, voted=a527daad-fcfc-4913-bb86-57ba7fce9b83, raftlog=3bd141d9-8d6a-4889-940a-437a7867e049@group-139BDF3E2545-SegmentedRaftLog:OPENED:c-1, conf=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-02-05 13:09:43,807 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-139BDF3E2545 with new leaderId: a527daad-fcfc-4913-bb86-57ba7fce9b83
datanode2_1  | 2022-02-05 13:09:43,811 [grpc-default-executor-0] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-139BDF3E2545: change Leader from null to a527daad-fcfc-4913-bb86-57ba7fce9b83 at term 1 for appendEntries, leader elected after 2236ms
datanode2_1  | 2022-02-05 13:09:43,891 [grpc-default-executor-0] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-139BDF3E2545: set configuration 0: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-02-05 13:09:43,909 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 3bd141d9-8d6a-4889-940a-437a7867e049@group-139BDF3E2545-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-02-05 13:09:44,191 [3bd141d9-8d6a-4889-940a-437a7867e049@group-139BDF3E2545-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3bd141d9-8d6a-4889-940a-437a7867e049@group-139BDF3E2545-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/cd0dbfd1-bf28-4717-93ea-139bdf3e2545/current/log_inprogress_0
datanode2_1  | 2022-02-05 13:09:48,369 [pool-23-thread-1] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049: new RaftServerImpl for group-DD33D84C9D7F:[9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-02-05 13:09:48,370 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-02-05 13:09:48,370 [grpc-default-executor-0] INFO server.RaftServer: 3bd141d9-8d6a-4889-940a-437a7867e049: addNew group-DD33D84C9D7F:[9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1] returns group-DD33D84C9D7F:java.util.concurrent.CompletableFuture@3d50183f[Not completed]
datanode2_1  | 2022-02-05 13:09:48,378 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-02-05 13:09:48,378 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-02-05 13:09:48,379 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-02-05 13:09:48,379 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-02-05 13:09:48,379 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-02-05 13:09:48,379 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-02-05 13:09:48,379 [pool-23-thread-1] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F: ConfigurationManager, init=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-02-05 13:09:48,379 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-02-05 13:09:48,380 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-02-05 13:09:48,380 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-02-05 13:09:48,380 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/f1ca961d-d578-498d-933d-dd33d84c9d7f does not exist. Creating ...
datanode2_1  | 2022-02-05 13:09:48,385 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/f1ca961d-d578-498d-933d-dd33d84c9d7f/in_use.lock acquired by nodename 7@e3be6b71356d
kdc_1        | Feb 05 13:09:27 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1644066528, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Feb 05 13:09:30 kdc krb5kdc[6](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1644066570, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:09:30 kdc krb5kdc[6](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1644066570, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:09:31 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1644066527, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Feb 05 13:09:33 kdc krb5kdc[6](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1644066573, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:09:34 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1644066570, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 05 13:09:34 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1644066570, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 05 13:09:37 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1644066573, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 05 13:09:40 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066548, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 05 13:09:46 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066586, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:09:52 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: ISSUE: authtime 1644066441, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:10:00 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066586, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 05 13:10:01 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066601, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:10:06 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:10:06 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:10:06 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:10:06 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:10:08 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066601, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:10:11 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066611, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode3_1  | 2022-02-05 13:09:46,901 [Command processor thread] INFO server.RaftServer: a527daad-fcfc-4913-bb86-57ba7fce9b83: addNew group-DD33D84C9D7F:[9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] returns group-DD33D84C9D7F:java.util.concurrent.CompletableFuture@604a7ba1[Not completed]
datanode3_1  | 2022-02-05 13:09:46,903 [pool-23-thread-1] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83: new RaftServerImpl for group-DD33D84C9D7F:[9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-02-05 13:09:46,905 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-02-05 13:09:46,905 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-02-05 13:09:46,905 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-02-05 13:09:46,906 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-02-05 13:09:46,910 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-02-05 13:09:46,911 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-02-05 13:09:46,912 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-02-05 13:09:46,912 [pool-23-thread-1] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F: ConfigurationManager, init=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-02-05 13:09:46,912 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-02-05 13:09:46,912 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-02-05 13:09:46,914 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-02-05 13:09:46,914 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/f1ca961d-d578-498d-933d-dd33d84c9d7f does not exist. Creating ...
datanode3_1  | 2022-02-05 13:09:46,934 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/f1ca961d-d578-498d-933d-dd33d84c9d7f/in_use.lock acquired by nodename 9@1e40b8f48f78
datanode3_1  | 2022-02-05 13:09:46,936 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/f1ca961d-d578-498d-933d-dd33d84c9d7f has been successfully formatted.
datanode3_1  | 2022-02-05 13:09:46,966 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-DD33D84C9D7F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-02-05 13:09:46,978 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-02-05 13:09:46,980 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-02-05 13:09:46,980 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-02-05 13:09:46,980 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-02-05 13:09:46,981 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-02-05 13:09:46,981 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-02-05 13:09:46,981 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-02-05 13:09:46,982 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/f1ca961d-d578-498d-933d-dd33d84c9d7f
datanode3_1  | 2022-02-05 13:09:46,982 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode3_1  | 2022-02-05 13:09:46,982 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-02-05 13:09:46,982 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-02-05 13:09:46,982 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-02-05 13:09:46,994 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-02-05 13:09:46,997 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-02-05 13:09:47,000 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-02-05 13:09:47,005 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-02-05 13:09:47,005 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-02-05 13:09:47,010 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-02-05 13:09:47,014 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-02-05 13:09:47,018 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-02-05 13:09:47,019 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-02-05 13:09:47,019 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-02-05 13:09:47,019 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-02-05 13:09:47,019 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-02-05 13:09:47,020 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-02-05 13:09:47,020 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-02-05 13:09:47,021 [pool-23-thread-1] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F: start as a follower, conf=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode1_1  | 2022-02-05 13:09:20,076 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode1_1  | 2022-02-05 13:09:20,249 [main] INFO util.log: Logging initialized @49803ms to org.eclipse.jetty.util.log.Slf4jLog
datanode1_1  | 2022-02-05 13:09:21,073 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode1_1  | 2022-02-05 13:09:21,147 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode1_1  | 2022-02-05 13:09:21,163 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode1_1  | 2022-02-05 13:09:21,163 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode1_1  | 2022-02-05 13:09:21,164 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode1_1  | 2022-02-05 13:09:21,183 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode1_1  | 2022-02-05 13:09:21,576 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode1_1  | 2022-02-05 13:09:21,580 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-LTS
datanode1_1  | 2022-02-05 13:09:21,864 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode1_1  | 2022-02-05 13:09:21,870 [main] INFO server.session: No SessionScavenger set, using defaults
datanode1_1  | 2022-02-05 13:09:21,886 [main] INFO server.session: node0 Scavenging every 600000ms
datanode1_1  | 2022-02-05 13:09:22,048 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2022-02-05 13:09:22,106 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3bb6b9ab{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode1_1  | 2022-02-05 13:09:22,107 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1ef8f7e6{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode1_1  | 2022-02-05 13:09:22,791 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2022-02-05 13:09:22,881 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3582077c{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-3850106144793354758/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode1_1  | 2022-02-05 13:09:22,927 [main] INFO server.AbstractConnector: Started ServerConnector@57f83dc7{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode1_1  | 2022-02-05 13:09:22,942 [main] INFO server.Server: Started @52495ms
datanode1_1  | 2022-02-05 13:09:22,959 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode1_1  | 2022-02-05 13:09:22,959 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode1_1  | 2022-02-05 13:09:22,964 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode1_1  | 2022-02-05 13:09:22,981 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode1_1  | 2022-02-05 13:09:23,147 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@587f3b60] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode1_1  | 2022-02-05 13:09:23,567 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode1_1  | 2022-02-05 13:09:27,390 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode1_1  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:191)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:231)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:633)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:283)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:471)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode1_1  | Caused by: java.util.concurrent.TimeoutException
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:149)
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode1_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode1_1  | 	... 1 more
datanode1_1  | 2022-02-05 13:09:27,585 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode1_1  | 2022-02-05 13:09:27,586 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode1_1  | 2022-02-05 13:09:28,095 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 9905eb49-ac94-40b9-a1a3-f35673531eee
datanode1_1  | 2022-02-05 13:09:28,245 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.RaftServer: 9905eb49-ac94-40b9-a1a3-f35673531eee: start RPC server
datanode1_1  | 2022-02-05 13:09:28,262 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 9905eb49-ac94-40b9-a1a3-f35673531eee: GrpcService started, listening on 9856
datanode1_1  | 2022-02-05 13:09:28,263 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 9905eb49-ac94-40b9-a1a3-f35673531eee: GrpcService started, listening on 9857
datanode1_1  | 2022-02-05 13:09:28,274 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 9905eb49-ac94-40b9-a1a3-f35673531eee: GrpcService started, listening on 9858
datanode1_1  | 2022-02-05 13:09:28,318 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 9905eb49-ac94-40b9-a1a3-f35673531eee is started using port 9858 for RATIS
datanode1_1  | 2022-02-05 13:09:28,318 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 9905eb49-ac94-40b9-a1a3-f35673531eee is started using port 9857 for RATIS_ADMIN
datanode2_1  | 2022-02-05 13:09:48,393 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/f1ca961d-d578-498d-933d-dd33d84c9d7f has been successfully formatted.
datanode2_1  | 2022-02-05 13:09:48,396 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-DD33D84C9D7F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-02-05 13:09:48,396 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-02-05 13:09:48,396 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-02-05 13:09:48,396 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-02-05 13:09:48,397 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-02-05 13:09:48,397 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-02-05 13:09:48,400 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-02-05 13:09:48,400 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-02-05 13:09:48,400 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/f1ca961d-d578-498d-933d-dd33d84c9d7f
datanode2_1  | 2022-02-05 13:09:48,401 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode2_1  | 2022-02-05 13:09:48,401 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-02-05 13:09:48,401 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-02-05 13:09:48,402 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-02-05 13:09:48,410 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-02-05 13:09:48,413 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-02-05 13:09:48,414 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-02-05 13:09:48,414 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-02-05 13:09:48,415 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-02-05 13:09:48,422 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-02-05 13:09:48,447 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-02-05 13:09:48,451 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-02-05 13:09:48,460 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-02-05 13:09:48,492 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-02-05 13:09:48,492 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-02-05 13:09:48,492 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-02-05 13:09:48,492 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-02-05 13:09:48,493 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-02-05 13:09:48,494 [pool-23-thread-1] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F: start as a follower, conf=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-02-05 13:09:48,494 [pool-23-thread-1] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-02-05 13:09:48,494 [pool-23-thread-1] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: start 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState
datanode2_1  | 2022-02-05 13:09:48,502 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DD33D84C9D7F,id=3bd141d9-8d6a-4889-940a-437a7867e049
datanode2_1  | 2022-02-05 13:09:52,163 [grpc-default-executor-0] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F: receive requestVote(ELECTION, a527daad-fcfc-4913-bb86-57ba7fce9b83, group-DD33D84C9D7F, 1, (t:0, i:0))
datanode2_1  | 2022-02-05 13:09:52,164 [grpc-default-executor-0] INFO impl.VoteContext: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FOLLOWER: reject ELECTION from a527daad-fcfc-4913-bb86-57ba7fce9b83: our priority 1 > candidate's priority 0
datanode2_1  | 2022-02-05 13:09:52,164 [grpc-default-executor-0] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:a527daad-fcfc-4913-bb86-57ba7fce9b83
datanode2_1  | 2022-02-05 13:09:52,164 [grpc-default-executor-0] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: shutdown 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState
datanode2_1  | 2022-02-05 13:09:52,164 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState] INFO impl.FollowerState: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState was interrupted: {}
datanode2_1  | java.lang.InterruptedException: sleep interrupted
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode2_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode2_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode2_1  | 2022-02-05 13:09:52,165 [grpc-default-executor-0] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: start 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState
datanode3_1  | 2022-02-05 13:09:47,027 [pool-23-thread-1] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-02-05 13:09:47,040 [pool-23-thread-1] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: start a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState
datanode3_1  | 2022-02-05 13:09:47,060 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DD33D84C9D7F,id=a527daad-fcfc-4913-bb86-57ba7fce9b83
datanode3_1  | 2022-02-05 13:09:47,065 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=f1ca961d-d578-498d-933d-dd33d84c9d7f
datanode3_1  | 2022-02-05 13:09:48,542 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=f1ca961d-d578-498d-933d-dd33d84c9d7f.
datanode3_1  | 2022-02-05 13:09:52,111 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState] INFO impl.FollowerState: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5070291180ns, electionTimeout:5046ms
datanode3_1  | 2022-02-05 13:09:52,111 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: shutdown a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState
datanode3_1  | 2022-02-05 13:09:52,111 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2022-02-05 13:09:52,111 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-02-05 13:09:52,111 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: start a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection3
datanode3_1  | 2022-02-05 13:09:52,140 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection3] INFO impl.LeaderElection: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection3 ELECTION round 0: submit vote requests at term 1 for -1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode3_1  | 2022-02-05 13:09:52,178 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection3] INFO impl.LeaderElection: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection3: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode3_1  | 2022-02-05 13:09:52,178 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection3] INFO impl.LeaderElection:   Response 0: a527daad-fcfc-4913-bb86-57ba7fce9b83<-3bd141d9-8d6a-4889-940a-437a7867e049#0:FAIL-t1
datanode3_1  | 2022-02-05 13:09:52,178 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection3] INFO impl.LeaderElection: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection3 ELECTION round 0: result REJECTED
datanode3_1  | 2022-02-05 13:09:52,179 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection3] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
datanode3_1  | 2022-02-05 13:09:52,179 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection3] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: shutdown a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection3
datanode3_1  | 2022-02-05 13:09:52,179 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection3] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: start a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState
datanode3_1  | 2022-02-05 13:09:57,385 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState] INFO impl.FollowerState: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5205791334ns, electionTimeout:5181ms
datanode3_1  | 2022-02-05 13:09:57,386 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: shutdown a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState
datanode3_1  | 2022-02-05 13:09:57,386 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode3_1  | 2022-02-05 13:09:57,386 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-02-05 13:09:57,387 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: start a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection4
datanode3_1  | 2022-02-05 13:09:57,389 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection4] INFO impl.LeaderElection: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection4 ELECTION round 0: submit vote requests at term 2 for -1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode3_1  | 2022-02-05 13:09:57,418 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection4] INFO impl.LeaderElection: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection4: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode3_1  | 2022-02-05 13:09:57,418 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection4] INFO impl.LeaderElection:   Response 0: a527daad-fcfc-4913-bb86-57ba7fce9b83<-3bd141d9-8d6a-4889-940a-437a7867e049#0:FAIL-t2
datanode3_1  | 2022-02-05 13:09:57,419 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection4] INFO impl.LeaderElection: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection4 ELECTION round 0: result REJECTED
datanode3_1  | 2022-02-05 13:09:57,419 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection4] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
datanode3_1  | 2022-02-05 13:09:57,419 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection4] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: shutdown a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection4
datanode3_1  | 2022-02-05 13:09:57,419 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection4] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: start a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState
datanode3_1  | 2022-02-05 13:09:58,484 [grpc-default-executor-0] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F: receive requestVote(ELECTION, 3bd141d9-8d6a-4889-940a-437a7867e049, group-DD33D84C9D7F, 2, (t:0, i:0))
kdc_1        | Feb 05 13:10:22 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066611, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:10:36 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066611, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:10:41 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066611, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:10:47 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066611, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:10:57 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066611, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:11:03 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066611, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:11:06 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:11:06 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:11:08 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066611, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:11:13 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066611, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:11:27 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066611, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:11:32 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066611, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:11:36 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066611, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:11:40 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066611, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:11:50 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066611, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:11:55 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066611, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:11:59 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066611, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:12:04 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066611, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode2_1  | 2022-02-05 13:09:52,169 [grpc-default-executor-0] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F replies to ELECTION vote request: a527daad-fcfc-4913-bb86-57ba7fce9b83<-3bd141d9-8d6a-4889-940a-437a7867e049#0:FAIL-t1. Peer's state: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F:t1, leader=null, voted=null, raftlog=3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-SegmentedRaftLog:OPENED:c-1, conf=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-02-05 13:09:57,353 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState] INFO impl.FollowerState: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5188137514ns, electionTimeout:5185ms
datanode2_1  | 2022-02-05 13:09:57,354 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: shutdown 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState
datanode2_1  | 2022-02-05 13:09:57,354 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode2_1  | 2022-02-05 13:09:57,357 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-02-05 13:09:57,357 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: start 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection1
datanode2_1  | 2022-02-05 13:09:57,365 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection1] INFO impl.LeaderElection: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for -1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-02-05 13:09:57,398 [grpc-default-executor-0] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F: receive requestVote(ELECTION, a527daad-fcfc-4913-bb86-57ba7fce9b83, group-DD33D84C9D7F, 2, (t:0, i:0))
datanode2_1  | 2022-02-05 13:09:57,399 [grpc-default-executor-0] INFO impl.VoteContext: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-CANDIDATE: reject ELECTION from a527daad-fcfc-4913-bb86-57ba7fce9b83: already has voted for 3bd141d9-8d6a-4889-940a-437a7867e049 at current term 2
datanode2_1  | 2022-02-05 13:09:57,400 [grpc-default-executor-0] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F replies to ELECTION vote request: a527daad-fcfc-4913-bb86-57ba7fce9b83<-3bd141d9-8d6a-4889-940a-437a7867e049#0:FAIL-t2. Peer's state: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F:t2, leader=null, voted=3bd141d9-8d6a-4889-940a-437a7867e049, raftlog=3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-SegmentedRaftLog:OPENED:c-1, conf=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-02-05 13:09:58,534 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection1] INFO impl.LeaderElection: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode2_1  | 2022-02-05 13:09:58,541 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection1] INFO impl.LeaderElection:   Response 0: 3bd141d9-8d6a-4889-940a-437a7867e049<-9905eb49-ac94-40b9-a1a3-f35673531eee#0:FAIL-t2
datanode2_1  | 2022-02-05 13:09:58,543 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection1] INFO impl.LeaderElection:   Response 1: 3bd141d9-8d6a-4889-940a-437a7867e049<-a527daad-fcfc-4913-bb86-57ba7fce9b83#0:FAIL-t2
datanode2_1  | 2022-02-05 13:09:58,544 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection1] INFO impl.LeaderElection: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection1 ELECTION round 0: result REJECTED
datanode2_1  | 2022-02-05 13:09:58,545 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection1] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
datanode2_1  | 2022-02-05 13:09:58,553 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection1] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: shutdown 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection1
datanode2_1  | 2022-02-05 13:09:58,558 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection1] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: start 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState
datanode2_1  | 2022-02-05 13:10:01,695 [Command processor thread] INFO server.RaftServer: 3bd141d9-8d6a-4889-940a-437a7867e049: addNew group-5989287A910B:[3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] returns group-5989287A910B:java.util.concurrent.CompletableFuture@79ac85e4[Not completed]
datanode2_1  | 2022-02-05 13:10:01,697 [pool-23-thread-1] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049: new RaftServerImpl for group-5989287A910B:[3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-02-05 13:10:01,698 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-02-05 13:10:01,698 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-02-05 13:10:01,698 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-02-05 13:10:01,698 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-02-05 13:10:01,698 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-02-05 13:10:01,698 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-02-05 13:10:01,698 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-02-05 13:10:01,698 [pool-23-thread-1] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B: ConfigurationManager, init=-1: [3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-02-05 13:10:01,698 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-02-05 13:10:01,699 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-02-05 13:10:01,699 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-02-05 13:10:01,699 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fc6ad7e7-85fa-4af9-97bb-5989287a910b does not exist. Creating ...
datanode1_1  | 2022-02-05 13:09:28,318 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 9905eb49-ac94-40b9-a1a3-f35673531eee is started using port 9856 for RATIS_SERVER
datanode1_1  | 2022-02-05 13:09:28,320 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$346/0x00000008405b6840@349cd231] INFO util.JvmPauseMonitor: JvmPauseMonitor-9905eb49-ac94-40b9-a1a3-f35673531eee: Started
datanode1_1  | 2022-02-05 13:09:28,414 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2022-02-05 13:09:28,775 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2022-02-05 13:09:44,592 [grpc-default-executor-2] WARN server.GrpcServerProtocolService: 9905eb49-ac94-40b9-a1a3-f35673531eee: Failed requestVote a527daad-fcfc-4913-bb86-57ba7fce9b83->9905eb49-ac94-40b9-a1a3-f35673531eee#0
datanode1_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: 9905eb49-ac94-40b9-a1a3-f35673531eee: group-139BDF3E2545 not found.
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:147)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:339)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:348)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:343)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:548)
datanode1_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:172)
datanode1_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:394)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode1_1  | 2022-02-05 13:09:45,084 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$346/0x00000008405b6840@349cd231] WARN util.JvmPauseMonitor: JvmPauseMonitor-9905eb49-ac94-40b9-a1a3-f35673531eee: Detected pause in JVM or host machine (eg GC): pause of approximately 187851981ns.
datanode1_1  | GC pool 'ParNew' had collection(s): count=1 time=244ms
datanode1_1  | 2022-02-05 13:09:45,166 [grpc-default-executor-1] INFO server.RaftServer: 9905eb49-ac94-40b9-a1a3-f35673531eee: addNew group-139BDF3E2545:[9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0] returns group-139BDF3E2545:java.util.concurrent.CompletableFuture@3fb00e9b[Not completed]
datanode1_1  | 2022-02-05 13:09:45,372 [pool-23-thread-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee: new RaftServerImpl for group-139BDF3E2545:[9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-02-05 13:09:45,394 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-02-05 13:09:45,397 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-02-05 13:09:45,404 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-02-05 13:09:45,404 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-02-05 13:09:45,405 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-02-05 13:09:45,408 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-02-05 13:09:45,414 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-02-05 13:09:45,454 [pool-23-thread-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-139BDF3E2545: ConfigurationManager, init=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-02-05 13:09:45,485 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-02-05 13:09:45,531 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-02-05 13:09:45,534 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-02-05 13:09:45,550 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/cd0dbfd1-bf28-4717-93ea-139bdf3e2545 does not exist. Creating ...
datanode1_1  | 2022-02-05 13:09:45,586 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/cd0dbfd1-bf28-4717-93ea-139bdf3e2545/in_use.lock acquired by nodename 6@f6267b87e946
datanode1_1  | 2022-02-05 13:09:45,636 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/cd0dbfd1-bf28-4717-93ea-139bdf3e2545 has been successfully formatted.
datanode1_1  | 2022-02-05 13:09:45,788 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-139BDF3E2545: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-02-05 13:09:45,882 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-02-05 13:09:45,884 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-02-05 13:09:45,929 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-02-05 13:09:45,929 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-02-05 13:09:45,937 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-02-05 13:09:46,135 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-02-05 13:09:46,137 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-02-05 13:09:46,233 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 9905eb49-ac94-40b9-a1a3-f35673531eee@group-139BDF3E2545-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/cd0dbfd1-bf28-4717-93ea-139bdf3e2545
datanode1_1  | 2022-02-05 13:09:46,234 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode1_1  | 2022-02-05 13:09:46,234 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-02-05 13:09:46,236 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-02-05 13:09:46,237 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-02-05 13:09:46,238 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-02-05 13:09:46,249 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-02-05 13:09:46,252 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-02-05 13:09:46,260 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-02-05 13:09:46,328 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-02-05 13:09:46,331 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-02-05 13:09:46,365 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-139BDF3E2545-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-02-05 13:09:46,372 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-139BDF3E2545-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
kdc_1        | Feb 05 13:12:06 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:12:06 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:12:08 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066611, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:12:13 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066611, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:12:16 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066611, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:12:21 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066611, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:12:25 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066611, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:12:25 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:12:29 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:12:33 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:12:34 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066754, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:12:37 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066754, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:12:42 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066754, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:12:46 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066754, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:12:53 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066754, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:12:56 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066776, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:13:00 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066776, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:13:06 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
datanode2_1  | 2022-02-05 13:10:01,701 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fc6ad7e7-85fa-4af9-97bb-5989287a910b/in_use.lock acquired by nodename 7@e3be6b71356d
datanode2_1  | 2022-02-05 13:10:01,702 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fc6ad7e7-85fa-4af9-97bb-5989287a910b has been successfully formatted.
datanode2_1  | 2022-02-05 13:10:01,704 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-5989287A910B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-02-05 13:10:01,704 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-02-05 13:10:01,705 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-02-05 13:10:01,705 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-02-05 13:10:01,706 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-02-05 13:10:01,707 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-02-05 13:10:01,707 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-02-05 13:10:01,707 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-02-05 13:10:01,707 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fc6ad7e7-85fa-4af9-97bb-5989287a910b
datanode2_1  | 2022-02-05 13:10:01,707 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode2_1  | 2022-02-05 13:10:01,707 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-02-05 13:10:01,707 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-02-05 13:10:01,708 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-02-05 13:10:01,708 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-02-05 13:10:01,708 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-02-05 13:10:01,708 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-02-05 13:10:01,708 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-02-05 13:10:01,709 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-02-05 13:10:01,710 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-02-05 13:10:01,711 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-02-05 13:10:01,711 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-02-05 13:10:01,745 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-02-05 13:10:01,749 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-02-05 13:10:01,749 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-02-05 13:10:01,751 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-02-05 13:10:01,752 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-02-05 13:10:01,753 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-02-05 13:10:01,755 [pool-23-thread-1] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B: start as a follower, conf=-1: [3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2022-02-05 13:10:01,757 [pool-23-thread-1] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-02-05 13:10:01,757 [pool-23-thread-1] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: start 3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-FollowerState
datanode2_1  | 2022-02-05 13:10:01,785 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5989287A910B,id=3bd141d9-8d6a-4889-940a-437a7867e049
datanode2_1  | 2022-02-05 13:10:01,813 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=fc6ad7e7-85fa-4af9-97bb-5989287a910b
datanode2_1  | 2022-02-05 13:10:01,814 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=fc6ad7e7-85fa-4af9-97bb-5989287a910b.
datanode2_1  | 2022-02-05 13:10:02,635 [grpc-default-executor-0] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F: receive requestVote(ELECTION, a527daad-fcfc-4913-bb86-57ba7fce9b83, group-DD33D84C9D7F, 3, (t:0, i:0))
datanode2_1  | 2022-02-05 13:10:02,635 [grpc-default-executor-0] INFO impl.VoteContext: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FOLLOWER: reject ELECTION from a527daad-fcfc-4913-bb86-57ba7fce9b83: our priority 1 > candidate's priority 0
datanode2_1  | 2022-02-05 13:10:02,636 [grpc-default-executor-0] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:a527daad-fcfc-4913-bb86-57ba7fce9b83
datanode2_1  | 2022-02-05 13:10:02,636 [grpc-default-executor-0] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: shutdown 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState
datanode2_1  | 2022-02-05 13:10:02,636 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState] INFO impl.FollowerState: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState was interrupted: {}
datanode2_1  | java.lang.InterruptedException: sleep interrupted
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode2_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode2_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode2_1  | 2022-02-05 13:10:02,637 [grpc-default-executor-0] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: start 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState
datanode3_1  | 2022-02-05 13:09:58,492 [grpc-default-executor-0] INFO impl.VoteContext: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FOLLOWER: reject ELECTION from 3bd141d9-8d6a-4889-940a-437a7867e049: already has voted for a527daad-fcfc-4913-bb86-57ba7fce9b83 at current term 2
datanode3_1  | 2022-02-05 13:09:58,514 [grpc-default-executor-0] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F replies to ELECTION vote request: 3bd141d9-8d6a-4889-940a-437a7867e049<-a527daad-fcfc-4913-bb86-57ba7fce9b83#0:FAIL-t2. Peer's state: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F:t2, leader=null, voted=a527daad-fcfc-4913-bb86-57ba7fce9b83, raftlog=a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-SegmentedRaftLog:OPENED:c-1, conf=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode3_1  | 2022-02-05 13:10:02,597 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState] INFO impl.FollowerState: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5177593287ns, electionTimeout:5176ms
datanode3_1  | 2022-02-05 13:10:02,597 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: shutdown a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState
datanode3_1  | 2022-02-05 13:10:02,597 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
datanode3_1  | 2022-02-05 13:10:02,597 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-02-05 13:10:02,598 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: start a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection5
datanode3_1  | 2022-02-05 13:10:02,611 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection5] INFO impl.LeaderElection: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection5 ELECTION round 0: submit vote requests at term 3 for -1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode3_1  | 2022-02-05 13:10:02,643 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection5] INFO impl.LeaderElection: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection5: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode3_1  | 2022-02-05 13:10:02,643 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection5] INFO impl.LeaderElection:   Response 0: a527daad-fcfc-4913-bb86-57ba7fce9b83<-9905eb49-ac94-40b9-a1a3-f35673531eee#0:FAIL-t3
datanode3_1  | 2022-02-05 13:10:02,644 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection5] INFO impl.LeaderElection:   Response 1: a527daad-fcfc-4913-bb86-57ba7fce9b83<-3bd141d9-8d6a-4889-940a-437a7867e049#0:FAIL-t3
datanode3_1  | 2022-02-05 13:10:02,644 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection5] INFO impl.LeaderElection: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection5 ELECTION round 0: result REJECTED
datanode3_1  | 2022-02-05 13:10:02,644 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection5] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
datanode3_1  | 2022-02-05 13:10:02,644 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection5] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: shutdown a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection5
datanode3_1  | 2022-02-05 13:10:02,644 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection5] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: start a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState
datanode3_1  | 2022-02-05 13:10:03,302 [grpc-default-executor-0] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F: receive requestVote(ELECTION, 9905eb49-ac94-40b9-a1a3-f35673531eee, group-DD33D84C9D7F, 3, (t:0, i:0))
datanode3_1  | 2022-02-05 13:10:03,304 [grpc-default-executor-0] INFO impl.VoteContext: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FOLLOWER: reject ELECTION from 9905eb49-ac94-40b9-a1a3-f35673531eee: already has voted for a527daad-fcfc-4913-bb86-57ba7fce9b83 at current term 3
datanode3_1  | 2022-02-05 13:10:03,304 [grpc-default-executor-0] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F replies to ELECTION vote request: 9905eb49-ac94-40b9-a1a3-f35673531eee<-a527daad-fcfc-4913-bb86-57ba7fce9b83#0:FAIL-t3. Peer's state: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F:t3, leader=null, voted=a527daad-fcfc-4913-bb86-57ba7fce9b83, raftlog=a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-SegmentedRaftLog:OPENED:c-1, conf=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode3_1  | 2022-02-05 13:10:07,735 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState] INFO impl.FollowerState: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5090651490ns, electionTimeout:5085ms
datanode3_1  | 2022-02-05 13:10:07,735 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: shutdown a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState
datanode3_1  | 2022-02-05 13:10:07,738 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
datanode3_1  | 2022-02-05 13:10:07,738 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-02-05 13:10:07,738 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: start a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection6
datanode3_1  | 2022-02-05 13:10:07,743 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection6] INFO impl.LeaderElection: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection6 ELECTION round 0: submit vote requests at term 4 for -1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode3_1  | 2022-02-05 13:10:07,775 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection6] INFO impl.LeaderElection: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection6: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode3_1  | 2022-02-05 13:10:07,775 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection6] INFO impl.LeaderElection:   Response 0: a527daad-fcfc-4913-bb86-57ba7fce9b83<-9905eb49-ac94-40b9-a1a3-f35673531eee#0:OK-t4
datanode3_1  | 2022-02-05 13:10:07,775 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection6] INFO impl.LeaderElection:   Response 1: a527daad-fcfc-4913-bb86-57ba7fce9b83<-3bd141d9-8d6a-4889-940a-437a7867e049#0:FAIL-t4
datanode3_1  | 2022-02-05 13:10:07,775 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection6] INFO impl.LeaderElection: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection6 ELECTION round 0: result REJECTED
datanode3_1  | 2022-02-05 13:10:07,775 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection6] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
datanode3_1  | 2022-02-05 13:10:07,775 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection6] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: shutdown a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection6
datanode3_1  | 2022-02-05 13:10:07,775 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection6] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: start a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState
datanode3_1  | 2022-02-05 13:10:12,812 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState] INFO impl.FollowerState: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5036895695ns, electionTimeout:5021ms
datanode3_1  | 2022-02-05 13:10:12,813 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: shutdown a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState
datanode3_1  | 2022-02-05 13:10:12,813 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
datanode3_1  | 2022-02-05 13:10:12,813 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-02-05 13:10:12,813 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: start a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection7
datanode3_1  | 2022-02-05 13:10:12,817 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection7] INFO impl.LeaderElection: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection7 ELECTION round 0: submit vote requests at term 5 for -1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode3_1  | 2022-02-05 13:10:12,854 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection7] INFO impl.LeaderElection: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection7: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode3_1  | 2022-02-05 13:10:12,855 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection7] INFO impl.LeaderElection:   Response 0: a527daad-fcfc-4913-bb86-57ba7fce9b83<-3bd141d9-8d6a-4889-940a-437a7867e049#0:FAIL-t5
datanode3_1  | 2022-02-05 13:10:12,855 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection7] INFO impl.LeaderElection: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection7 ELECTION round 0: result REJECTED
datanode3_1  | 2022-02-05 13:10:12,855 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection7] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F: changes role from CANDIDATE to FOLLOWER at term 5 for REJECTED
datanode3_1  | 2022-02-05 13:10:12,858 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection7] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: shutdown a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection7
datanode3_1  | 2022-02-05 13:10:12,860 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-LeaderElection7] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: start a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState
datanode3_1  | 2022-02-05 13:10:17,934 [grpc-default-executor-0] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F: receive requestVote(ELECTION, 9905eb49-ac94-40b9-a1a3-f35673531eee, group-DD33D84C9D7F, 6, (t:0, i:0))
datanode3_1  | 2022-02-05 13:10:17,935 [grpc-default-executor-0] INFO impl.VoteContext: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FOLLOWER: accept ELECTION from 9905eb49-ac94-40b9-a1a3-f35673531eee: our priority 0 <= candidate's priority 0
datanode3_1  | 2022-02-05 13:10:17,935 [grpc-default-executor-0] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F: changes role from  FOLLOWER to FOLLOWER at term 6 for candidate:9905eb49-ac94-40b9-a1a3-f35673531eee
datanode3_1  | 2022-02-05 13:10:17,935 [grpc-default-executor-0] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: shutdown a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState
datanode3_1  | 2022-02-05 13:10:17,935 [grpc-default-executor-0] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: start a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState
datanode3_1  | 2022-02-05 13:10:17,936 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState] INFO impl.FollowerState: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState was interrupted: {}
datanode3_1  | java.lang.InterruptedException: sleep interrupted
datanode3_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode3_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode3_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode3_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode3_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode2_1  | 2022-02-05 13:10:02,639 [grpc-default-executor-0] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F replies to ELECTION vote request: a527daad-fcfc-4913-bb86-57ba7fce9b83<-3bd141d9-8d6a-4889-940a-437a7867e049#0:FAIL-t3. Peer's state: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F:t3, leader=null, voted=null, raftlog=3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-SegmentedRaftLog:OPENED:c-1, conf=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-02-05 13:10:03,314 [grpc-default-executor-0] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F: receive requestVote(ELECTION, 9905eb49-ac94-40b9-a1a3-f35673531eee, group-DD33D84C9D7F, 3, (t:0, i:0))
datanode2_1  | 2022-02-05 13:10:03,314 [grpc-default-executor-0] INFO impl.VoteContext: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FOLLOWER: reject ELECTION from 9905eb49-ac94-40b9-a1a3-f35673531eee: our priority 1 > candidate's priority 0
datanode2_1  | 2022-02-05 13:10:03,315 [grpc-default-executor-0] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:9905eb49-ac94-40b9-a1a3-f35673531eee
datanode2_1  | 2022-02-05 13:10:03,315 [grpc-default-executor-0] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: shutdown 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState
datanode2_1  | 2022-02-05 13:10:03,315 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState] INFO impl.FollowerState: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState was interrupted: {}
datanode2_1  | java.lang.InterruptedException: sleep interrupted
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode2_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode2_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode2_1  | 2022-02-05 13:10:03,315 [grpc-default-executor-0] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: start 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState
datanode2_1  | 2022-02-05 13:10:03,317 [grpc-default-executor-0] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F replies to ELECTION vote request: 9905eb49-ac94-40b9-a1a3-f35673531eee<-3bd141d9-8d6a-4889-940a-437a7867e049#0:FAIL-t3. Peer's state: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F:t3, leader=null, voted=null, raftlog=3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-SegmentedRaftLog:OPENED:c-1, conf=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-02-05 13:10:06,956 [3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-FollowerState] INFO impl.FollowerState: 3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5198904671ns, electionTimeout:5134ms
datanode2_1  | 2022-02-05 13:10:06,957 [3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-FollowerState] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: shutdown 3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-FollowerState
datanode2_1  | 2022-02-05 13:10:06,957 [3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-FollowerState] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode2_1  | 2022-02-05 13:10:06,957 [3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-02-05 13:10:06,957 [3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-FollowerState] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: start 3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-LeaderElection2
datanode2_1  | 2022-02-05 13:10:06,960 [3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-LeaderElection2] INFO impl.LeaderElection: 3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2022-02-05 13:10:06,960 [3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-LeaderElection2] INFO impl.LeaderElection: 3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-LeaderElection2 ELECTION round 0: result PASSED (term=1)
datanode2_1  | 2022-02-05 13:10:06,960 [3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-LeaderElection2] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: shutdown 3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-LeaderElection2
datanode2_1  | 2022-02-05 13:10:06,961 [3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-LeaderElection2] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode2_1  | 2022-02-05 13:10:06,961 [3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-5989287A910B with new leaderId: 3bd141d9-8d6a-4889-940a-437a7867e049
datanode2_1  | 2022-02-05 13:10:06,963 [3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-LeaderElection2] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B: change Leader from null to 3bd141d9-8d6a-4889-940a-437a7867e049 at term 1 for becomeLeader, leader elected after 5256ms
datanode2_1  | 2022-02-05 13:10:06,982 [3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode2_1  | 2022-02-05 13:10:07,019 [3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-02-05 13:10:07,019 [3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode2_1  | 2022-02-05 13:10:07,037 [3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode2_1  | 2022-02-05 13:10:07,037 [3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode2_1  | 2022-02-05 13:10:07,042 [3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode2_1  | 2022-02-05 13:10:07,056 [3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-02-05 13:10:07,063 [3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode2_1  | 2022-02-05 13:10:07,068 [3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-LeaderElection2] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: start 3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-LeaderStateImpl
datanode1_1  | 2022-02-05 13:09:46,379 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-02-05 13:09:46,394 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-02-05 13:09:46,395 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-02-05 13:09:46,395 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-02-05 13:09:46,397 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-02-05 13:09:46,402 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-02-05 13:09:46,553 [pool-23-thread-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-139BDF3E2545: start as a follower, conf=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-02-05 13:09:46,563 [pool-23-thread-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-139BDF3E2545: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-02-05 13:09:46,567 [pool-23-thread-1] INFO impl.RoleInfo: 9905eb49-ac94-40b9-a1a3-f35673531eee: start 9905eb49-ac94-40b9-a1a3-f35673531eee@group-139BDF3E2545-FollowerState
datanode1_1  | 2022-02-05 13:09:46,601 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-139BDF3E2545,id=9905eb49-ac94-40b9-a1a3-f35673531eee
datanode1_1  | 2022-02-05 13:09:46,799 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-139BDF3E2545 with new leaderId: a527daad-fcfc-4913-bb86-57ba7fce9b83
datanode1_1  | 2022-02-05 13:09:46,800 [grpc-default-executor-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-139BDF3E2545: change Leader from null to a527daad-fcfc-4913-bb86-57ba7fce9b83 at term 1 for appendEntries, leader elected after 918ms
datanode1_1  | 2022-02-05 13:09:46,818 [grpc-default-executor-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-139BDF3E2545: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
datanode1_1  | 2022-02-05 13:09:46,839 [grpc-default-executor-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-139BDF3E2545: inconsistency entries. Reply:a527daad-fcfc-4913-bb86-57ba7fce9b83<-9905eb49-ac94-40b9-a1a3-f35673531eee#3:FAIL-t0,INCONSISTENCY,nextIndex=0,followerCommit=-1
datanode1_1  | 2022-02-05 13:09:46,937 [grpc-default-executor-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-139BDF3E2545: set configuration 0: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-02-05 13:09:46,961 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-139BDF3E2545-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-02-05 13:09:47,586 [grpc-default-executor-1] INFO server.RaftServer: 9905eb49-ac94-40b9-a1a3-f35673531eee: addNew group-DD33D84C9D7F:[9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1] returns group-DD33D84C9D7F:java.util.concurrent.CompletableFuture@5fe53e5e[Not completed]
datanode1_1  | 2022-02-05 13:09:47,589 [pool-23-thread-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee: new RaftServerImpl for group-DD33D84C9D7F:[9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-02-05 13:09:47,594 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-02-05 13:09:47,598 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-02-05 13:09:47,601 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-02-05 13:09:47,601 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
kdc_1        | Feb 05 13:13:06 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:13:06 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066776, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:13:09 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066789, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:13:13 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066789, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:13:17 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066789, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:13:19 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066799, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:13:22 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066799, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:13:26 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066799, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:13:27 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066807, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:13:31 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066807, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:13:32 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066812, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:13:36 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066812, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:13:37 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066817, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:13:40 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066817, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:13:44 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066817, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:13:49 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066817, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:13:53 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066817, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode3_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode3_1  | 2022-02-05 13:10:17,963 [grpc-default-executor-0] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F replies to ELECTION vote request: 9905eb49-ac94-40b9-a1a3-f35673531eee<-a527daad-fcfc-4913-bb86-57ba7fce9b83#0:OK-t6. Peer's state: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F:t6, leader=null, voted=9905eb49-ac94-40b9-a1a3-f35673531eee, raftlog=a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-SegmentedRaftLog:OPENED:c-1, conf=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode3_1  | 2022-02-05 13:10:22,995 [grpc-default-executor-0] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F: receive requestVote(ELECTION, 3bd141d9-8d6a-4889-940a-437a7867e049, group-DD33D84C9D7F, 7, (t:0, i:0))
datanode3_1  | 2022-02-05 13:10:22,995 [grpc-default-executor-0] INFO impl.VoteContext: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FOLLOWER: accept ELECTION from 3bd141d9-8d6a-4889-940a-437a7867e049: our priority 0 <= candidate's priority 1
datanode3_1  | 2022-02-05 13:10:22,995 [grpc-default-executor-0] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F: changes role from  FOLLOWER to FOLLOWER at term 7 for candidate:3bd141d9-8d6a-4889-940a-437a7867e049
datanode3_1  | 2022-02-05 13:10:22,996 [grpc-default-executor-0] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: shutdown a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState
datanode3_1  | 2022-02-05 13:10:22,996 [grpc-default-executor-0] INFO impl.RoleInfo: a527daad-fcfc-4913-bb86-57ba7fce9b83: start a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState
datanode3_1  | 2022-02-05 13:10:22,996 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState] INFO impl.FollowerState: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-FollowerState was interrupted: {}
datanode3_1  | java.lang.InterruptedException: sleep interrupted
datanode3_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode3_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode3_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode3_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode3_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode3_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode3_1  | 2022-02-05 13:10:22,999 [grpc-default-executor-0] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F replies to ELECTION vote request: 3bd141d9-8d6a-4889-940a-437a7867e049<-a527daad-fcfc-4913-bb86-57ba7fce9b83#0:OK-t7. Peer's state: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F:t7, leader=null, voted=3bd141d9-8d6a-4889-940a-437a7867e049, raftlog=a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-SegmentedRaftLog:OPENED:c-1, conf=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode3_1  | 2022-02-05 13:10:23,472 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-DD33D84C9D7F with new leaderId: 3bd141d9-8d6a-4889-940a-437a7867e049
datanode3_1  | 2022-02-05 13:10:23,479 [grpc-default-executor-0] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F: change Leader from null to 3bd141d9-8d6a-4889-940a-437a7867e049 at term 7 for appendEntries, leader elected after 36494ms
datanode3_1  | 2022-02-05 13:10:23,582 [grpc-default-executor-0] INFO server.RaftServer$Division: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F: set configuration 0: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode3_1  | 2022-02-05 13:10:23,584 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-02-05 13:10:23,589 [a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-DD33D84C9D7F-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/f1ca961d-d578-498d-933d-dd33d84c9d7f/current/log_inprogress_0
datanode3_1  | 2022-02-05 13:10:28,159 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:944034450553.
datanode3_1  | 2022-02-05 13:10:46,887 [java.util.concurrent.ThreadPoolExecutor$Worker@43c7c706[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4,entriesCount=1,lastEntry=(t:1, i:0)
datanode3_1  | 2022-02-05 13:11:28,072 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=230,entriesCount=1,lastEntry=(t:1, i:1)
datanode3_1  | 2022-02-05 13:11:28,145 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=231,entriesCount=1,lastEntry=(t:1, i:2)
datanode3_1  | 2022-02-05 13:11:29,274 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=232,entriesCount=1,lastEntry=(t:1, i:3)
datanode3_1  | 2022-02-05 13:11:29,293 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=233,entriesCount=1,lastEntry=(t:1, i:4)
datanode3_1  | 2022-02-05 13:11:50,037 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=488,entriesCount=1,lastEntry=(t:1, i:5)
datanode3_1  | 2022-02-05 13:11:50,054 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=489,entriesCount=1,lastEntry=(t:1, i:6)
datanode3_1  | 2022-02-05 13:11:50,061 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=490,entriesCount=1,lastEntry=(t:1, i:7)
datanode3_1  | 2022-02-05 13:11:50,086 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=494,entriesCount=1,lastEntry=(t:1, i:8)
datanode3_1  | 2022-02-05 13:12:43,538 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=765,entriesCount=1,lastEntry=(t:1, i:9)
datanode3_1  | 2022-02-05 13:12:43,548 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=766,entriesCount=1,lastEntry=(t:1, i:10)
kdc_1        | Feb 05 13:13:57 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066817, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:14:01 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066817, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:14:02 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066842, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:14:06 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:14:06 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:14:06 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066842, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:14:10 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066842, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:14:15 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066842, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:14:19 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066842, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:14:20 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066860, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:14:20 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066860, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:14:23 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066860, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:14:24 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066864, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:14:24 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066864, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:14:28 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066864, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:14:28 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066868, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:14:28 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066868, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:14:32 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066868, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:14:36 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066868, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:14:37 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066877, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:14:40 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066877, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:14:44 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066877, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:14:49 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066877, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:14:53 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066877, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:14:54 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066894, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:14:57 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066894, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:15:01 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066894, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:15:06 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:15:06 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:15:10 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066894, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:15:13 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066913, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:15:17 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066913, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:15:21 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066913, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:15:25 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066913, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:16:06 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:16:06 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:16:34 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644066994, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:16:37 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644066994, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:16:41 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.114: ISSUE: authtime 1644066436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, s3g/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:16:42 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644067002, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:16:45 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644067002, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:16:55 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644067015, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:16:58 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644067015, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:17:06 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:17:06 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:17:24 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644067044, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:17:27 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644067044, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:17:33 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644067053, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:17:36 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644067053, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:17:40 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644067060, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:17:43 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644067060, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:17:47 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644067067, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:17:50 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644067067, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kms_1        | Sleeping for 5 seconds
kms_1        | WARNING: /opt/hadoop/temp does not exist. Creating.
datanode3_1  | 2022-02-05 13:12:43,561 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=767,entriesCount=1,lastEntry=(t:1, i:11)
datanode3_1  | 2022-02-05 13:12:43,604 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=773,entriesCount=1,lastEntry=(t:1, i:12)
datanode3_1  | 2022-02-05 13:16:04,327 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1101,entriesCount=1,lastEntry=(t:1, i:13)
datanode3_1  | 2022-02-05 13:16:04,335 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1102,entriesCount=1,lastEntry=(t:1, i:14)
datanode3_1  | 2022-02-05 13:16:04,353 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1106,entriesCount=1,lastEntry=(t:1, i:15)
datanode3_1  | 2022-02-05 13:16:04,356 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1108,entriesCount=1,lastEntry=(t:1, i:16)
datanode3_1  | 2022-02-05 13:18:01,455 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1403,entriesCount=1,lastEntry=(t:1, i:17)
datanode3_1  | 2022-02-05 13:18:01,457 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1404,entriesCount=1,lastEntry=(t:1, i:18)
datanode3_1  | 2022-02-05 13:18:01,475 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1405,entriesCount=1,lastEntry=(t:1, i:19)
datanode3_1  | 2022-02-05 13:18:01,485 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1406,entriesCount=1,lastEntry=(t:1, i:20)
datanode3_1  | 2022-02-05 13:18:04,103 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1657,entriesCount=1,lastEntry=(t:1, i:21)
datanode3_1  | 2022-02-05 13:18:04,133 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1658,entriesCount=1,lastEntry=(t:1, i:22)
datanode3_1  | 2022-02-05 13:18:04,134 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1659,entriesCount=1,lastEntry=(t:1, i:23)
datanode3_1  | 2022-02-05 13:18:04,134 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1660,entriesCount=1,lastEntry=(t:1, i:24)
datanode3_1  | 2022-02-05 13:18:06,741 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1909,entriesCount=1,lastEntry=(t:1, i:25)
datanode3_1  | 2022-02-05 13:18:06,748 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1910,entriesCount=1,lastEntry=(t:1, i:26)
datanode3_1  | 2022-02-05 13:18:06,762 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1911,entriesCount=1,lastEntry=(t:1, i:27)
datanode3_1  | 2022-02-05 13:18:06,779 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1913,entriesCount=1,lastEntry=(t:1, i:28)
datanode3_1  | 2022-02-05 13:18:10,038 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2166,entriesCount=1,lastEntry=(t:1, i:29)
datanode3_1  | 2022-02-05 13:18:10,038 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2167,entriesCount=1,lastEntry=(t:1, i:30)
datanode3_1  | 2022-02-05 13:18:10,175 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2168,entriesCount=1,lastEntry=(t:1, i:31)
datanode3_1  | 2022-02-05 13:18:10,183 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2169,entriesCount=1,lastEntry=(t:1, i:32)
datanode3_1  | 2022-02-05 13:18:13,473 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2411,entriesCount=1,lastEntry=(t:1, i:33)
datanode2_1  | 2022-02-05 13:10:07,093 [3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-02-05 13:10:07,095 [3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fc6ad7e7-85fa-4af9-97bb-5989287a910b/current/log_inprogress_0
datanode2_1  | 2022-02-05 13:10:07,100 [3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B-LeaderElection2] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-5989287A910B: set configuration 0: [3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-02-05 13:10:07,755 [grpc-default-executor-0] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F: receive requestVote(ELECTION, a527daad-fcfc-4913-bb86-57ba7fce9b83, group-DD33D84C9D7F, 4, (t:0, i:0))
datanode2_1  | 2022-02-05 13:10:07,755 [grpc-default-executor-0] INFO impl.VoteContext: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FOLLOWER: reject ELECTION from a527daad-fcfc-4913-bb86-57ba7fce9b83: our priority 1 > candidate's priority 0
datanode2_1  | 2022-02-05 13:10:07,755 [grpc-default-executor-0] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:a527daad-fcfc-4913-bb86-57ba7fce9b83
datanode2_1  | 2022-02-05 13:10:07,755 [grpc-default-executor-0] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: shutdown 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState
datanode2_1  | 2022-02-05 13:10:07,756 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState] INFO impl.FollowerState: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState was interrupted: {}
datanode2_1  | java.lang.InterruptedException: sleep interrupted
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode2_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode2_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode2_1  | 2022-02-05 13:10:07,756 [grpc-default-executor-0] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: start 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState
datanode2_1  | 2022-02-05 13:10:07,758 [grpc-default-executor-0] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F replies to ELECTION vote request: a527daad-fcfc-4913-bb86-57ba7fce9b83<-3bd141d9-8d6a-4889-940a-437a7867e049#0:FAIL-t4. Peer's state: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F:t4, leader=null, voted=null, raftlog=3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-SegmentedRaftLog:OPENED:c-1, conf=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-02-05 13:10:12,824 [grpc-default-executor-0] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F: receive requestVote(ELECTION, a527daad-fcfc-4913-bb86-57ba7fce9b83, group-DD33D84C9D7F, 5, (t:0, i:0))
datanode2_1  | 2022-02-05 13:10:12,825 [grpc-default-executor-0] INFO impl.VoteContext: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FOLLOWER: reject ELECTION from a527daad-fcfc-4913-bb86-57ba7fce9b83: our priority 1 > candidate's priority 0
datanode2_1  | 2022-02-05 13:10:12,825 [grpc-default-executor-0] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:a527daad-fcfc-4913-bb86-57ba7fce9b83
datanode2_1  | 2022-02-05 13:10:12,825 [grpc-default-executor-0] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: shutdown 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState
datanode2_1  | 2022-02-05 13:10:12,825 [grpc-default-executor-0] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: start 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState
datanode2_1  | 2022-02-05 13:10:12,825 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState] INFO impl.FollowerState: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState was interrupted: {}
datanode2_1  | java.lang.InterruptedException: sleep interrupted
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode2_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode2_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode2_1  | 2022-02-05 13:10:12,836 [grpc-default-executor-0] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F replies to ELECTION vote request: a527daad-fcfc-4913-bb86-57ba7fce9b83<-3bd141d9-8d6a-4889-940a-437a7867e049#0:FAIL-t5. Peer's state: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F:t5, leader=null, voted=null, raftlog=3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-SegmentedRaftLog:OPENED:c-1, conf=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-02-05 13:10:17,955 [grpc-default-executor-0] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F: receive requestVote(ELECTION, 9905eb49-ac94-40b9-a1a3-f35673531eee, group-DD33D84C9D7F, 6, (t:0, i:0))
datanode2_1  | 2022-02-05 13:10:17,955 [grpc-default-executor-0] INFO impl.VoteContext: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FOLLOWER: reject ELECTION from 9905eb49-ac94-40b9-a1a3-f35673531eee: our priority 1 > candidate's priority 0
datanode2_1  | 2022-02-05 13:10:17,959 [grpc-default-executor-0] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F: changes role from  FOLLOWER to FOLLOWER at term 6 for candidate:9905eb49-ac94-40b9-a1a3-f35673531eee
datanode2_1  | 2022-02-05 13:10:17,959 [grpc-default-executor-0] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: shutdown 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState
datanode2_1  | 2022-02-05 13:10:17,960 [grpc-default-executor-0] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: start 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState
datanode2_1  | 2022-02-05 13:10:17,960 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState] INFO impl.FollowerState: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState was interrupted: {}
datanode2_1  | java.lang.InterruptedException: sleep interrupted
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode2_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode2_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode2_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode2_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode2_1  | 2022-02-05 13:10:17,964 [grpc-default-executor-0] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F replies to ELECTION vote request: 9905eb49-ac94-40b9-a1a3-f35673531eee<-3bd141d9-8d6a-4889-940a-437a7867e049#0:FAIL-t6. Peer's state: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F:t6, leader=null, voted=null, raftlog=3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-SegmentedRaftLog:OPENED:c-1, conf=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-02-05 13:10:22,985 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState] INFO impl.FollowerState: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5025477960ns, electionTimeout:5025ms
datanode2_1  | 2022-02-05 13:10:22,985 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: shutdown 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState
datanode2_1  | 2022-02-05 13:10:22,985 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F: changes role from  FOLLOWER to CANDIDATE at term 6 for changeToCandidate
datanode2_1  | 2022-02-05 13:10:22,986 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-02-05 13:10:22,986 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-FollowerState] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: start 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3
datanode2_1  | 2022-02-05 13:10:22,989 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO impl.LeaderElection: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3 ELECTION round 0: submit vote requests at term 7 for -1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-02-05 13:10:23,042 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO impl.LeaderElection: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode2_1  | 2022-02-05 13:10:23,044 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO impl.LeaderElection:   Response 0: 3bd141d9-8d6a-4889-940a-437a7867e049<-9905eb49-ac94-40b9-a1a3-f35673531eee#0:OK-t7
datanode2_1  | 2022-02-05 13:10:23,044 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO impl.LeaderElection: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3 ELECTION round 0: result PASSED
datanode2_1  | 2022-02-05 13:10:23,045 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: shutdown 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3
datanode2_1  | 2022-02-05 13:10:23,046 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F: changes role from CANDIDATE to LEADER at term 7 for changeToLeader
datanode2_1  | 2022-02-05 13:10:23,046 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-DD33D84C9D7F with new leaderId: 3bd141d9-8d6a-4889-940a-437a7867e049
datanode2_1  | 2022-02-05 13:10:23,046 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F: change Leader from null to 3bd141d9-8d6a-4889-940a-437a7867e049 at term 7 for becomeLeader, leader elected after 34649ms
datanode2_1  | 2022-02-05 13:10:23,046 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode2_1  | 2022-02-05 13:10:23,047 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-02-05 13:10:23,051 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode2_1  | 2022-02-05 13:10:23,052 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode2_1  | 2022-02-05 13:10:23,053 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode2_1  | 2022-02-05 13:10:23,053 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode2_1  | 2022-02-05 13:10:23,053 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-02-05 13:10:23,055 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode2_1  | 2022-02-05 13:10:23,171 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode2_1  | 2022-02-05 13:10:23,180 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-02-05 13:10:23,186 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode2_1  | 2022-02-05 13:10:23,192 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode2_1  | 2022-02-05 13:10:23,225 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-02-05 13:10:23,225 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-02-05 13:10:23,313 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode2_1  | 2022-02-05 13:10:23,320 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-02-05 13:18:13,783 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2412,entriesCount=1,lastEntry=(t:1, i:34)
datanode3_1  | 2022-02-05 13:18:13,815 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2413,entriesCount=1,lastEntry=(t:1, i:35)
datanode3_1  | 2022-02-05 13:18:13,839 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2416,entriesCount=1,lastEntry=(t:1, i:36)
datanode3_1  | 2022-02-05 13:18:14,198 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2449,entriesCount=1,lastEntry=(t:1, i:37)
datanode3_1  | 2022-02-05 13:18:14,219 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2453,entriesCount=1,lastEntry=(t:1, i:38)
datanode3_1  | 2022-02-05 13:18:20,035 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2702,entriesCount=1,lastEntry=(t:1, i:39)
datanode3_1  | 2022-02-05 13:18:20,158 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2703,entriesCount=1,lastEntry=(t:1, i:40)
datanode3_1  | 2022-02-05 13:18:20,433 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2727,entriesCount=1,lastEntry=(t:1, i:41)
datanode3_1  | 2022-02-05 13:18:20,551 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2737,entriesCount=1,lastEntry=(t:1, i:42)
datanode3_1  | 2022-02-05 13:18:20,574 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2739,entriesCount=1,lastEntry=(t:1, i:43)
datanode3_1  | 2022-02-05 13:18:20,603 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2742,entriesCount=1,lastEntry=(t:1, i:44)
datanode3_1  | 2022-02-05 13:18:20,897 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2771,entriesCount=1,lastEntry=(t:1, i:45)
datanode3_1  | 2022-02-05 13:18:20,907 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2772,entriesCount=1,lastEntry=(t:1, i:46)
datanode3_1  | 2022-02-05 13:18:38,613 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$347/0x00000008405b6c40@3f0c8db] WARN util.JvmPauseMonitor: JvmPauseMonitor-a527daad-fcfc-4913-bb86-57ba7fce9b83: Detected pause in JVM or host machine (eg GC): pause of approximately 137997656ns.
datanode3_1  | GC pool 'ParNew' had collection(s): count=2 time=209ms
datanode3_1  | 2022-02-05 13:19:02,038 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3040,entriesCount=1,lastEntry=(t:1, i:47)
datanode3_1  | 2022-02-05 13:19:02,084 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3041,entriesCount=1,lastEntry=(t:1, i:48)
datanode3_1  | 2022-02-05 13:19:02,113 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3042,entriesCount=1,lastEntry=(t:1, i:49)
datanode3_1  | 2022-02-05 13:19:02,177 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3043,entriesCount=1,lastEntry=(t:1, i:50)
datanode3_1  | 2022-02-05 13:19:02,184 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3044,entriesCount=1,lastEntry=(t:1, i:51)
datanode3_1  | 2022-02-05 13:19:02,201 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3046,entriesCount=1,lastEntry=(t:1, i:52)
datanode3_1  | 2022-02-05 13:19:07,199 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3300,entriesCount=1,lastEntry=(t:1, i:53)
datanode3_1  | 2022-02-05 13:19:07,253 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3301,entriesCount=1,lastEntry=(t:1, i:54)
datanode1_1  | 2022-02-05 13:09:47,601 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-02-05 13:09:47,602 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-02-05 13:09:47,602 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-02-05 13:09:47,602 [pool-23-thread-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F: ConfigurationManager, init=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-02-05 13:09:47,602 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-02-05 13:09:47,603 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-02-05 13:09:47,603 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-02-05 13:09:47,603 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/f1ca961d-d578-498d-933d-dd33d84c9d7f does not exist. Creating ...
datanode1_1  | 2022-02-05 13:09:47,604 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/f1ca961d-d578-498d-933d-dd33d84c9d7f/in_use.lock acquired by nodename 6@f6267b87e946
datanode1_1  | 2022-02-05 13:09:47,605 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-139BDF3E2545-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-139BDF3E2545-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/cd0dbfd1-bf28-4717-93ea-139bdf3e2545/current/log_inprogress_0
datanode1_1  | 2022-02-05 13:09:47,607 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/f1ca961d-d578-498d-933d-dd33d84c9d7f has been successfully formatted.
datanode1_1  | 2022-02-05 13:09:47,608 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-DD33D84C9D7F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-02-05 13:09:47,622 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-02-05 13:09:47,628 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-02-05 13:09:47,628 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-02-05 13:09:47,629 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-02-05 13:09:47,629 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-02-05 13:09:47,630 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-02-05 13:09:47,631 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-02-05 13:09:47,631 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/f1ca961d-d578-498d-933d-dd33d84c9d7f
datanode1_1  | 2022-02-05 13:09:47,631 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode1_1  | 2022-02-05 13:09:47,631 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-02-05 13:09:47,631 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-02-05 13:09:47,636 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-02-05 13:09:47,636 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-02-05 13:09:47,637 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-02-05 13:09:47,637 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-02-05 13:09:47,637 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-02-05 13:09:47,638 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-02-05 13:09:47,650 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-02-05 13:09:47,651 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-02-05 13:09:47,657 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-02-05 13:09:47,674 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-02-05 13:09:47,674 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-02-05 13:09:47,675 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-02-05 13:09:47,675 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-02-05 13:09:47,675 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-02-05 13:09:47,675 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-02-05 13:09:47,682 [pool-23-thread-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F: start as a follower, conf=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-02-05 13:09:47,687 [pool-23-thread-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-02-05 13:09:47,687 [pool-23-thread-1] INFO impl.RoleInfo: 9905eb49-ac94-40b9-a1a3-f35673531eee: start 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState
datanode1_1  | 2022-02-05 13:09:47,697 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DD33D84C9D7F,id=9905eb49-ac94-40b9-a1a3-f35673531eee
datanode1_1  | 2022-02-05 13:09:52,179 [grpc-default-executor-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F: receive requestVote(ELECTION, a527daad-fcfc-4913-bb86-57ba7fce9b83, group-DD33D84C9D7F, 1, (t:0, i:0))
datanode1_1  | 2022-02-05 13:09:52,181 [grpc-default-executor-1] INFO impl.VoteContext: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FOLLOWER: accept ELECTION from a527daad-fcfc-4913-bb86-57ba7fce9b83: our priority 0 <= candidate's priority 0
datanode1_1  | 2022-02-05 13:09:52,182 [grpc-default-executor-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:a527daad-fcfc-4913-bb86-57ba7fce9b83
datanode1_1  | 2022-02-05 13:09:52,182 [grpc-default-executor-1] INFO impl.RoleInfo: 9905eb49-ac94-40b9-a1a3-f35673531eee: shutdown 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState
datanode1_1  | 2022-02-05 13:09:52,182 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState] INFO impl.FollowerState: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode1_1  | 2022-02-05 13:09:52,182 [grpc-default-executor-1] INFO impl.RoleInfo: 9905eb49-ac94-40b9-a1a3-f35673531eee: start 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState
datanode1_1  | 2022-02-05 13:09:52,210 [grpc-default-executor-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F replies to ELECTION vote request: a527daad-fcfc-4913-bb86-57ba7fce9b83<-9905eb49-ac94-40b9-a1a3-f35673531eee#0:OK-t1. Peer's state: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F:t1, leader=null, voted=a527daad-fcfc-4913-bb86-57ba7fce9b83, raftlog=9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-SegmentedRaftLog:OPENED:c-1, conf=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-02-05 13:09:57,397 [grpc-default-executor-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F: receive requestVote(ELECTION, a527daad-fcfc-4913-bb86-57ba7fce9b83, group-DD33D84C9D7F, 2, (t:0, i:0))
datanode1_1  | 2022-02-05 13:09:57,398 [grpc-default-executor-1] INFO impl.VoteContext: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FOLLOWER: accept ELECTION from a527daad-fcfc-4913-bb86-57ba7fce9b83: our priority 0 <= candidate's priority 0
datanode1_1  | 2022-02-05 13:09:57,398 [grpc-default-executor-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:a527daad-fcfc-4913-bb86-57ba7fce9b83
datanode1_1  | 2022-02-05 13:09:57,398 [grpc-default-executor-1] INFO impl.RoleInfo: 9905eb49-ac94-40b9-a1a3-f35673531eee: shutdown 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState
datanode1_1  | 2022-02-05 13:09:57,398 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState] INFO impl.FollowerState: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode1_1  | 2022-02-05 13:09:57,399 [grpc-default-executor-1] INFO impl.RoleInfo: 9905eb49-ac94-40b9-a1a3-f35673531eee: start 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState
datanode1_1  | 2022-02-05 13:09:57,410 [grpc-default-executor-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F replies to ELECTION vote request: a527daad-fcfc-4913-bb86-57ba7fce9b83<-9905eb49-ac94-40b9-a1a3-f35673531eee#0:OK-t2. Peer's state: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F:t2, leader=null, voted=a527daad-fcfc-4913-bb86-57ba7fce9b83, raftlog=9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-SegmentedRaftLog:OPENED:c-1, conf=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-02-05 13:09:58,414 [grpc-default-executor-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F: receive requestVote(ELECTION, 3bd141d9-8d6a-4889-940a-437a7867e049, group-DD33D84C9D7F, 2, (t:0, i:0))
datanode1_1  | 2022-02-05 13:09:58,415 [grpc-default-executor-1] INFO impl.VoteContext: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FOLLOWER: reject ELECTION from 3bd141d9-8d6a-4889-940a-437a7867e049: already has voted for a527daad-fcfc-4913-bb86-57ba7fce9b83 at current term 2
datanode1_1  | 2022-02-05 13:09:58,415 [grpc-default-executor-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F replies to ELECTION vote request: 3bd141d9-8d6a-4889-940a-437a7867e049<-9905eb49-ac94-40b9-a1a3-f35673531eee#0:FAIL-t2. Peer's state: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F:t2, leader=null, voted=a527daad-fcfc-4913-bb86-57ba7fce9b83, raftlog=9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-SegmentedRaftLog:OPENED:c-1, conf=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-02-05 13:10:02,398 [Command processor thread] INFO server.RaftServer: 9905eb49-ac94-40b9-a1a3-f35673531eee: addNew group-DF306916AC0E:[9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] returns group-DF306916AC0E:java.util.concurrent.CompletableFuture@6bd82fa9[Not completed]
datanode1_1  | 2022-02-05 13:10:02,401 [pool-23-thread-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee: new RaftServerImpl for group-DF306916AC0E:[9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-02-05 13:10:02,402 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-02-05 13:10:02,402 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-02-05 13:10:02,402 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-02-05 13:10:02,402 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
om2_1        | Sleeping for 5 seconds
om2_1        | Waiting for the service scm3.org:9894
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2022-02-05 13:08:40,087 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = [--init]
om2_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/f757d9929c7016e9989d08ab2698179d61ef158b ; compiled by 'runner' on 2022-02-05T12:45Z
om2_1        | STARTUP_MSG:   java = 11.0.13
om2_1        | ************************************************************/
om2_1        | 2022-02-05 13:08:40,182 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2022-02-05 13:08:49,024 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-02-05 13:08:49,517 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-02-05 13:08:49,517 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-02-05 13:08:49,518 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-02-05 13:08:50,779 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2022-02-05 13:08:50,779 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2022-02-05 13:08:50,952 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-02-05 13:08:55,432 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om2_1        | 2022-02-05 13:08:58,557 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om2_1        | 2022-02-05 13:08:58,571 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om2_1        | 2022-02-05 13:08:58,575 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om2_1        | 2022-02-05 13:09:02,920 [main] INFO om.OzoneManager: Init response: GETCERT
om2_1        | 2022-02-05 13:09:03,283 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.112,host:om2
om2_1        | 2022-02-05 13:09:03,298 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om2_1        | 2022-02-05 13:09:03,322 [main] ERROR client.OMCertificateClient: Invalid domain om2
om2_1        | 2022-02-05 13:09:03,334 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-02-05 13:09:03,337 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-02-05 13:09:03,340 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-02-05 13:09:03,346 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-02-05 13:09:03,353 [main] INFO om.OzoneManager: Creating csr for OM->dns:om2,ip:172.25.0.112,scmId:70490618-601a-4309-ad32-4488318b9859,clusterId:CID-fc180783-fb1e-4dd7-af87-eddf767648b7,subject:om2
om2_1        | 2022-02-05 13:09:04,555 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om2_1        | value: 9862
om2_1        | ]
om2_1        | 2022-02-05 13:09:06,332 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om2_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-fc180783-fb1e-4dd7-af87-eddf767648b7;layoutVersion=0
om2_1        | 2022-02-05 13:09:06,570 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om2_1        | /************************************************************
om2_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om2/172.25.0.112
om2_1        | ************************************************************/
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2022-02-05 13:09:16,889 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
datanode1_1  | 2022-02-05 13:10:02,402 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-02-05 13:10:02,402 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-02-05 13:10:02,403 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-02-05 13:10:02,403 [pool-23-thread-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E: ConfigurationManager, init=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-02-05 13:10:02,403 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-02-05 13:10:02,403 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-02-05 13:10:02,403 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-02-05 13:10:02,404 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/8861f5bd-9ae4-4203-8e86-df306916ac0e does not exist. Creating ...
datanode1_1  | 2022-02-05 13:10:02,407 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/8861f5bd-9ae4-4203-8e86-df306916ac0e/in_use.lock acquired by nodename 6@f6267b87e946
datanode1_1  | 2022-02-05 13:10:02,410 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/8861f5bd-9ae4-4203-8e86-df306916ac0e has been successfully formatted.
datanode1_1  | 2022-02-05 13:10:02,411 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-DF306916AC0E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-02-05 13:10:02,411 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-02-05 13:10:02,411 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-02-05 13:10:02,412 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-02-05 13:10:02,412 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-02-05 13:10:02,412 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-02-05 13:10:02,412 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-02-05 13:10:02,413 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-02-05 13:10:02,413 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/8861f5bd-9ae4-4203-8e86-df306916ac0e
datanode1_1  | 2022-02-05 13:10:02,413 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode1_1  | 2022-02-05 13:10:02,413 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-02-05 13:10:02,413 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-02-05 13:10:02,413 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-02-05 13:10:02,414 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-02-05 13:10:02,414 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-02-05 13:10:02,416 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-02-05 13:10:02,417 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-02-05 13:10:02,519 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState] INFO impl.FollowerState: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5109830996ns, electionTimeout:5055ms
datanode1_1  | 2022-02-05 13:10:02,520 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState] INFO impl.RoleInfo: 9905eb49-ac94-40b9-a1a3-f35673531eee: shutdown 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState
datanode1_1  | 2022-02-05 13:10:02,520 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
datanode1_1  | 2022-02-05 13:10:02,540 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-02-05 13:10:02,566 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-02-05 13:10:02,567 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-02-05 13:10:02,567 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-02-05 13:10:02,569 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-02-05 13:10:02,571 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState] INFO impl.RoleInfo: 9905eb49-ac94-40b9-a1a3-f35673531eee: start 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-LeaderElection1
datanode1_1  | 2022-02-05 13:10:02,582 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-02-05 13:10:02,584 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-02-05 13:10:02,584 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-02-05 13:10:02,584 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-02-05 13:10:02,585 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-02-05 13:10:02,585 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-02-05 13:10:02,586 [pool-23-thread-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E: start as a follower, conf=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2022-02-05 13:10:02,588 [pool-23-thread-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-02-05 13:10:02,588 [pool-23-thread-1] INFO impl.RoleInfo: 9905eb49-ac94-40b9-a1a3-f35673531eee: start 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-FollowerState
datanode3_1  | 2022-02-05 13:19:07,294 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3302,entriesCount=1,lastEntry=(t:1, i:55)
datanode3_1  | 2022-02-05 13:19:07,324 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3303,entriesCount=1,lastEntry=(t:1, i:56)
datanode3_1  | 2022-02-05 13:19:07,334 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3304,entriesCount=1,lastEntry=(t:1, i:57)
datanode3_1  | 2022-02-05 13:19:07,339 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3305,entriesCount=1,lastEntry=(t:1, i:58)
datanode3_1  | 2022-02-05 13:19:10,483 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3556,entriesCount=1,lastEntry=(t:1, i:59)
datanode3_1  | 2022-02-05 13:19:10,494 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3557,entriesCount=1,lastEntry=(t:1, i:60)
datanode3_1  | 2022-02-05 13:19:10,523 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3560,entriesCount=1,lastEntry=(t:1, i:61)
datanode3_1  | 2022-02-05 13:19:10,535 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3562,entriesCount=1,lastEntry=(t:1, i:62)
datanode3_1  | 2022-02-05 13:19:22,060 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3814,entriesCount=1,lastEntry=(t:1, i:63)
datanode3_1  | 2022-02-05 13:19:22,070 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3815,entriesCount=1,lastEntry=(t:1, i:64)
datanode3_1  | 2022-02-05 13:19:22,090 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3819,entriesCount=1,lastEntry=(t:1, i:65)
datanode3_1  | 2022-02-05 13:19:22,100 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3821,entriesCount=1,lastEntry=(t:1, i:66)
datanode3_1  | 2022-02-05 13:19:31,015 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4072,entriesCount=1,lastEntry=(t:1, i:67)
datanode3_1  | 2022-02-05 13:19:31,054 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4073,entriesCount=1,lastEntry=(t:1, i:68)
datanode3_1  | 2022-02-05 13:19:31,059 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4074,entriesCount=1,lastEntry=(t:1, i:69)
datanode3_1  | 2022-02-05 13:19:31,121 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4075,entriesCount=1,lastEntry=(t:1, i:70)
datanode3_1  | 2022-02-05 13:19:31,127 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4076,entriesCount=1,lastEntry=(t:1, i:71)
datanode3_1  | 2022-02-05 13:19:31,138 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4077,entriesCount=1,lastEntry=(t:1, i:72)
datanode3_1  | 2022-02-05 13:19:38,285 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4329,entriesCount=1,lastEntry=(t:1, i:73)
datanode3_1  | 2022-02-05 13:19:38,394 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4330,entriesCount=1,lastEntry=(t:1, i:74)
datanode3_1  | 2022-02-05 13:19:38,620 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4331,entriesCount=1,lastEntry=(t:1, i:75)
datanode3_1  | 2022-02-05 13:19:38,626 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4332,entriesCount=1,lastEntry=(t:1, i:76)
datanode3_1  | 2022-02-05 13:19:38,665 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4333,entriesCount=1,lastEntry=(t:1, i:77)
om1_1        | Sleeping for 5 seconds
om1_1        | Waiting for the service scm3.org:9894
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2022-02-05 13:08:40,284 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = [--init]
om1_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/f757d9929c7016e9989d08ab2698179d61ef158b ; compiled by 'runner' on 2022-02-05T12:45Z
om1_1        | STARTUP_MSG:   java = 11.0.13
om1_1        | ************************************************************/
om1_1        | 2022-02-05 13:08:40,378 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2022-02-05 13:08:49,415 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-02-05 13:08:49,875 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-02-05 13:08:49,875 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-02-05 13:08:49,876 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-02-05 13:08:50,872 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2022-02-05 13:08:50,875 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2022-02-05 13:08:50,911 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-02-05 13:08:55,470 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om1_1        | 2022-02-05 13:08:58,571 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om1_1        | 2022-02-05 13:08:58,571 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om1_1        | 2022-02-05 13:08:58,579 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om1_1        | 2022-02-05 13:09:03,302 [main] INFO om.OzoneManager: Init response: GETCERT
om1_1        | 2022-02-05 13:09:03,645 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.111,host:om1
om1_1        | 2022-02-05 13:09:03,663 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om1_1        | 2022-02-05 13:09:03,685 [main] ERROR client.OMCertificateClient: Invalid domain om1
om1_1        | 2022-02-05 13:09:03,686 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-02-05 13:09:03,690 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-02-05 13:09:03,690 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-02-05 13:09:03,691 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-02-05 13:09:03,692 [main] INFO om.OzoneManager: Creating csr for OM->dns:om1,ip:172.25.0.111,scmId:70490618-601a-4309-ad32-4488318b9859,clusterId:CID-fc180783-fb1e-4dd7-af87-eddf767648b7,subject:om1
om1_1        | 2022-02-05 13:09:04,734 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om1_1        | value: 9862
om1_1        | ]
om1_1        | 2022-02-05 13:09:06,552 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om1_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-fc180783-fb1e-4dd7-af87-eddf767648b7;layoutVersion=0
om1_1        | 2022-02-05 13:09:06,842 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om1_1        | /************************************************************
om1_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om1/172.25.0.111
om1_1        | ************************************************************/
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2022-02-05 13:09:17,070 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = []
om1_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = []
om2_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/f757d9929c7016e9989d08ab2698179d61ef158b ; compiled by 'runner' on 2022-02-05T12:45Z
om2_1        | STARTUP_MSG:   java = 11.0.13
om2_1        | ************************************************************/
om2_1        | 2022-02-05 13:09:16,977 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2022-02-05 13:09:24,878 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-02-05 13:09:25,606 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-02-05 13:09:25,610 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-02-05 13:09:25,618 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-02-05 13:09:25,755 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-02-05 13:09:26,188 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = INITIAL_VERSION (version = 0)
om2_1        | 2022-02-05 13:09:28,828 [main] INFO reflections.Reflections: Reflections took 1922 ms to scan 1 urls, producing 97 keys and 265 values [using 2 cores]
om2_1        | 2022-02-05 13:09:30,732 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2022-02-05 13:09:30,734 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2022-02-05 13:09:30,734 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-02-05 13:09:38,103 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om2_1        | 2022-02-05 13:09:38,865 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om2_1        | 2022-02-05 13:09:38,889 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-850810018938.crt.
om2_1        | 2022-02-05 13:09:38,917 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/943882820224.crt.
om2_1        | 2022-02-05 13:09:39,165 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-02-05 13:09:39,968 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om2_1        | 2022-02-05 13:09:39,984 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om2_1        | 2022-02-05 13:09:41,264 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om2_1        | 2022-02-05 13:09:41,264 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om2_1        | 2022-02-05 13:09:41,971 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
om2_1        | 2022-02-05 13:09:42,486 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2022-02-05 13:09:42,498 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om2_1        | 2022-02-05 13:09:42,600 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
kdc_1        | Feb 05 13:17:54 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644067074, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:17:57 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644067074, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:18:06 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:18:06 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:19:06 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:19:06 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:20:07 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:20:07 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:21:07 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:21:07 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:21:22 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644067282, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:21:28 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644067282, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:22:07 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:22:07 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:23:07 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:23:07 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:24:07 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:24:07 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:25:07 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
datanode1_1  | 2022-02-05 13:10:02,627 [grpc-default-executor-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F: receive requestVote(ELECTION, a527daad-fcfc-4913-bb86-57ba7fce9b83, group-DD33D84C9D7F, 3, (t:0, i:0))
datanode1_1  | 2022-02-05 13:10:02,629 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DF306916AC0E,id=9905eb49-ac94-40b9-a1a3-f35673531eee
datanode1_1  | 2022-02-05 13:10:02,630 [grpc-default-executor-1] INFO impl.VoteContext: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-CANDIDATE: reject ELECTION from a527daad-fcfc-4913-bb86-57ba7fce9b83: already has voted for 9905eb49-ac94-40b9-a1a3-f35673531eee at current term 3
datanode1_1  | 2022-02-05 13:10:02,631 [grpc-default-executor-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F replies to ELECTION vote request: a527daad-fcfc-4913-bb86-57ba7fce9b83<-9905eb49-ac94-40b9-a1a3-f35673531eee#0:FAIL-t3. Peer's state: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F:t3, leader=null, voted=9905eb49-ac94-40b9-a1a3-f35673531eee, raftlog=9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-SegmentedRaftLog:OPENED:c-1, conf=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-02-05 13:10:02,631 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-LeaderElection1] INFO impl.LeaderElection: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-LeaderElection1 ELECTION round 0: submit vote requests at term 3 for -1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-02-05 13:10:02,662 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=8861f5bd-9ae4-4203-8e86-df306916ac0e
datanode1_1  | 2022-02-05 13:10:02,674 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=8861f5bd-9ae4-4203-8e86-df306916ac0e.
datanode1_1  | 2022-02-05 13:10:03,366 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-LeaderElection1] INFO impl.LeaderElection: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode1_1  | 2022-02-05 13:10:03,367 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-LeaderElection1] INFO impl.LeaderElection:   Response 0: 9905eb49-ac94-40b9-a1a3-f35673531eee<-a527daad-fcfc-4913-bb86-57ba7fce9b83#0:FAIL-t3
datanode1_1  | 2022-02-05 13:10:03,367 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-LeaderElection1] INFO impl.LeaderElection:   Response 1: 9905eb49-ac94-40b9-a1a3-f35673531eee<-3bd141d9-8d6a-4889-940a-437a7867e049#0:FAIL-t3
datanode1_1  | 2022-02-05 13:10:03,367 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-LeaderElection1] INFO impl.LeaderElection: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-LeaderElection1 ELECTION round 0: result REJECTED
datanode1_1  | 2022-02-05 13:10:03,369 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-LeaderElection1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
datanode1_1  | 2022-02-05 13:10:03,373 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-LeaderElection1] INFO impl.RoleInfo: 9905eb49-ac94-40b9-a1a3-f35673531eee: shutdown 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-LeaderElection1
datanode1_1  | 2022-02-05 13:10:03,374 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-LeaderElection1] INFO impl.RoleInfo: 9905eb49-ac94-40b9-a1a3-f35673531eee: start 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState
datanode1_1  | 2022-02-05 13:10:07,746 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-FollowerState] INFO impl.FollowerState: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5158091260ns, electionTimeout:5113ms
datanode1_1  | 2022-02-05 13:10:07,748 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-FollowerState] INFO impl.RoleInfo: 9905eb49-ac94-40b9-a1a3-f35673531eee: shutdown 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-FollowerState
datanode1_1  | 2022-02-05 13:10:07,748 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-FollowerState] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode1_1  | 2022-02-05 13:10:07,749 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-02-05 13:10:07,749 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-FollowerState] INFO impl.RoleInfo: 9905eb49-ac94-40b9-a1a3-f35673531eee: start 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-LeaderElection2
datanode1_1  | 2022-02-05 13:10:07,748 [grpc-default-executor-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F: receive requestVote(ELECTION, a527daad-fcfc-4913-bb86-57ba7fce9b83, group-DD33D84C9D7F, 4, (t:0, i:0))
datanode1_1  | 2022-02-05 13:10:07,750 [grpc-default-executor-1] INFO impl.VoteContext: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FOLLOWER: accept ELECTION from a527daad-fcfc-4913-bb86-57ba7fce9b83: our priority 0 <= candidate's priority 0
datanode1_1  | 2022-02-05 13:10:07,750 [grpc-default-executor-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:a527daad-fcfc-4913-bb86-57ba7fce9b83
datanode1_1  | 2022-02-05 13:10:07,751 [grpc-default-executor-1] INFO impl.RoleInfo: 9905eb49-ac94-40b9-a1a3-f35673531eee: shutdown 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState
datanode1_1  | 2022-02-05 13:10:07,751 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState] INFO impl.FollowerState: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode1_1  | 2022-02-05 13:10:07,751 [grpc-default-executor-1] INFO impl.RoleInfo: 9905eb49-ac94-40b9-a1a3-f35673531eee: start 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState
om2_1        | 2022-02-05 13:09:43,431 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om2_1        | 2022-02-05 13:09:43,479 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2022-02-05 13:09:43,646 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om2:9872, om1:9872, om3:9872
om2_1        | 2022-02-05 13:09:43,683 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om2_1        | 2022-02-05 13:09:44,673 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om2_1        | 2022-02-05 13:09:45,292 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om2_1        | 2022-02-05 13:09:45,300 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2022-02-05 13:09:45,306 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om2_1        | 2022-02-05 13:09:45,307 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2022-02-05 13:09:45,319 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2022-02-05 13:09:45,320 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om2_1        | 2022-02-05 13:09:45,328 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-02-05 13:09:45,330 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om2_1        | 2022-02-05 13:09:45,338 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1        | 2022-02-05 13:09:49,022 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om2_1        | 2022-02-05 13:09:49,029 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2022-02-05 13:09:49,031 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2022-02-05 13:09:49,096 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2022-02-05 13:09:49,132 [main] INFO server.RaftServer: om2: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@4ff1b0d[Not completed]
om2_1        | 2022-02-05 13:09:49,132 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om2_1        | 2022-02-05 13:09:49,197 [pool-24-thread-1] INFO server.RaftServer$Division: om2: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om2_1        | 2022-02-05 13:09:49,205 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om2_1        | 2022-02-05 13:09:49,228 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om2_1        | 2022-02-05 13:09:49,230 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om2_1        | 2022-02-05 13:09:49,230 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2022-02-05 13:09:49,231 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2022-02-05 13:09:49,232 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om2_1        | 2022-02-05 13:09:49,234 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1        | 2022-02-05 13:09:49,256 [pool-24-thread-1] INFO server.RaftServer$Division: om2@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om2_1        | 2022-02-05 13:09:49,288 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2022-02-05 13:09:49,347 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om2_1        | 2022-02-05 13:09:49,357 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om2_1        | 2022-02-05 13:09:49,361 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om2_1        | 2022-02-05 13:09:49,370 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om2_1        | 2022-02-05 13:09:49,426 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 9@om2
om2_1        | 2022-02-05 13:09:49,437 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om2_1        | 2022-02-05 13:09:49,541 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om2_1        | 2022-02-05 13:09:49,570 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om2_1        | 2022-02-05 13:09:49,596 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om2_1        | 2022-02-05 13:09:49,789 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om2_1        | 2022-02-05 13:09:49,806 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-02-05 13:09:50,011 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2022-02-05 13:09:50,083 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om2_1        | 2022-02-05 13:09:50,109 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om2_1        | 2022-02-05 13:09:50,173 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new om2@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om2_1        | 2022-02-05 13:09:50,181 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om2_1        | 2022-02-05 13:09:50,181 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om2_1        | 2022-02-05 13:09:50,190 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2022-02-05 13:09:50,197 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om2_1        | 2022-02-05 13:09:50,202 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om2_1        | 2022-02-05 13:09:50,235 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om2_1        | 2022-02-05 13:09:50,236 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om2_1        | 2022-02-05 13:09:50,236 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-02-05 13:19:38,684 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4335,entriesCount=1,lastEntry=(t:1, i:78)
datanode3_1  | 2022-02-05 13:19:38,704 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4339,entriesCount=1,lastEntry=(t:1, i:79)
datanode3_1  | 2022-02-05 13:19:38,785 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4348,entriesCount=1,lastEntry=(t:1, i:80)
datanode3_1  | 2022-02-05 13:19:38,937 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4360,entriesCount=1,lastEntry=(t:1, i:81)
datanode3_1  | 2022-02-05 13:19:38,979 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4364,entriesCount=1,lastEntry=(t:1, i:82)
datanode3_1  | 2022-02-05 13:19:39,042 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4368,entriesCount=1,lastEntry=(t:1, i:83)
datanode3_1  | 2022-02-05 13:19:39,196 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4383,entriesCount=1,lastEntry=(t:1, i:84)
datanode3_1  | 2022-02-05 13:19:44,613 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4632,entriesCount=1,lastEntry=(t:1, i:85)
datanode3_1  | 2022-02-05 13:19:44,681 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4633,entriesCount=1,lastEntry=(t:1, i:86)
datanode3_1  | 2022-02-05 13:19:44,701 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4634,entriesCount=1,lastEntry=(t:1, i:87)
datanode3_1  | 2022-02-05 13:19:44,783 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4635,entriesCount=1,lastEntry=(t:1, i:88)
datanode3_1  | 2022-02-05 13:19:44,803 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4637,entriesCount=1,lastEntry=(t:1, i:89)
datanode3_1  | 2022-02-05 13:19:44,805 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4638,entriesCount=1,lastEntry=(t:1, i:90)
datanode3_1  | 2022-02-05 13:19:51,424 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4892,entriesCount=1,lastEntry=(t:1, i:91)
datanode3_1  | 2022-02-05 13:19:51,505 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4893,entriesCount=1,lastEntry=(t:1, i:92)
datanode3_1  | 2022-02-05 13:19:51,570 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4898,entriesCount=1,lastEntry=(t:1, i:93)
datanode3_1  | 2022-02-05 13:19:51,625 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4903,entriesCount=1,lastEntry=(t:1, i:94)
datanode3_1  | 2022-02-05 13:19:51,684 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4908,entriesCount=1,lastEntry=(t:1, i:95)
datanode3_1  | 2022-02-05 13:19:51,693 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4909,entriesCount=1,lastEntry=(t:1, i:96)
datanode3_1  | 2022-02-05 13:19:51,709 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4911,entriesCount=1,lastEntry=(t:1, i:97)
datanode3_1  | 2022-02-05 13:19:51,745 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4915,entriesCount=1,lastEntry=(t:1, i:98)
datanode3_1  | 2022-02-05 13:19:55,589 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5165,entriesCount=1,lastEntry=(t:1, i:99)
datanode3_1  | 2022-02-05 13:19:55,665 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5166,entriesCount=1,lastEntry=(t:1, i:100)
datanode2_1  | 2022-02-05 13:10:23,320 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode2_1  | 2022-02-05 13:10:23,320 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode2_1  | 2022-02-05 13:10:23,320 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-02-05 13:10:23,322 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-02-05 13:10:23,341 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO impl.RoleInfo: 3bd141d9-8d6a-4889-940a-437a7867e049: start 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderStateImpl
datanode2_1  | 2022-02-05 13:10:23,346 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-02-05 13:10:23,353 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/f1ca961d-d578-498d-933d-dd33d84c9d7f/current/log_inprogress_0
datanode2_1  | 2022-02-05 13:10:23,410 [3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F-LeaderElection3] INFO server.RaftServer$Division: 3bd141d9-8d6a-4889-940a-437a7867e049@group-DD33D84C9D7F: set configuration 0: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-02-05 13:10:28,477 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:944034450553.
datanode2_1  | 2022-02-05 13:17:14,100 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$346/0x00000008405b6840@f512643] WARN util.JvmPauseMonitor: JvmPauseMonitor-3bd141d9-8d6a-4889-940a-437a7867e049: Detected pause in JVM or host machine (eg GC): pause of approximately 153102054ns.
datanode2_1  | GC pool 'ParNew' had collection(s): count=1 time=162ms
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/f757d9929c7016e9989d08ab2698179d61ef158b ; compiled by 'runner' on 2022-02-05T12:45Z
om1_1        | STARTUP_MSG:   java = 11.0.13
om1_1        | ************************************************************/
om1_1        | 2022-02-05 13:09:17,143 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2022-02-05 13:09:24,931 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-02-05 13:09:25,818 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-02-05 13:09:25,822 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-02-05 13:09:25,822 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-02-05 13:09:25,964 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-02-05 13:09:26,457 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = INITIAL_VERSION (version = 0)
om1_1        | 2022-02-05 13:09:28,687 [main] INFO reflections.Reflections: Reflections took 1680 ms to scan 1 urls, producing 97 keys and 265 values [using 2 cores]
om1_1        | 2022-02-05 13:09:30,567 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2022-02-05 13:09:30,572 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2022-02-05 13:09:30,576 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-02-05 13:09:37,195 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om1_1        | 2022-02-05 13:09:37,927 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om1_1        | 2022-02-05 13:09:37,940 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/944034450553.crt.
om1_1        | 2022-02-05 13:09:37,967 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-850810018938.crt.
om1_1        | 2022-02-05 13:09:38,164 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-02-05 13:09:39,096 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om1_1        | 2022-02-05 13:09:39,110 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om1_1        | 2022-02-05 13:09:40,625 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om1_1        | 2022-02-05 13:09:40,625 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om1_1        | 2022-02-05 13:09:41,417 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
om1_1        | 2022-02-05 13:09:41,898 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2022-02-05 13:09:41,902 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om1_1        | 2022-02-05 13:09:41,966 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om1_1        | 2022-02-05 13:09:42,848 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om1_1        | 2022-02-05 13:09:42,894 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2022-02-05 13:09:43,071 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om1:9872, om3:9872, om2:9872
om1_1        | 2022-02-05 13:09:43,119 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om1_1        | 2022-02-05 13:09:44,122 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om1_1        | 2022-02-05 13:09:44,446 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om1_1        | 2022-02-05 13:09:44,454 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2022-02-05 13:09:44,460 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om1_1        | 2022-02-05 13:09:44,461 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2022-02-05 13:09:44,461 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2022-02-05 13:09:44,464 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om1_1        | 2022-02-05 13:09:44,475 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-02-05 13:09:44,481 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om1_1        | 2022-02-05 13:09:44,485 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2022-02-05 13:09:47,845 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om1_1        | 2022-02-05 13:09:47,863 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2022-02-05 13:09:47,863 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2022-02-05 13:09:47,937 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2022-02-05 13:09:47,990 [main] INFO server.RaftServer: om1: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@67e255cf[Not completed]
om1_1        | 2022-02-05 13:09:47,990 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om1_1        | 2022-02-05 13:09:48,109 [pool-24-thread-1] INFO server.RaftServer$Division: om1: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om1_1        | 2022-02-05 13:09:48,167 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om1_1        | 2022-02-05 13:09:48,170 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om1_1        | 2022-02-05 13:09:48,174 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om1_1        | 2022-02-05 13:09:48,174 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2022-02-05 13:09:48,176 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2022-02-05 13:09:48,178 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om1_1        | 2022-02-05 13:09:48,180 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2022-02-05 13:09:48,214 [pool-24-thread-1] INFO server.RaftServer$Division: om1@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om1_1        | 2022-02-05 13:09:48,217 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2022-02-05 13:09:48,261 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om1_1        | 2022-02-05 13:09:48,270 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om1_1        | 2022-02-05 13:09:48,282 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om1_1        | 2022-02-05 13:09:48,426 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1        | 2022-02-05 13:09:48,464 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 7@om1
om1_1        | 2022-02-05 13:09:48,537 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om1_1        | 2022-02-05 13:09:48,602 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om1_1        | 2022-02-05 13:09:48,626 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om1_1        | 2022-02-05 13:09:48,634 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1        | 2022-02-05 13:09:48,655 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om1_1        | 2022-02-05 13:09:48,663 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-02-05 13:09:48,779 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2022-02-05 13:09:48,865 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om1_1        | 2022-02-05 13:09:48,869 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om1_1        | 2022-02-05 13:09:48,914 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new om1@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om1_1        | 2022-02-05 13:09:48,920 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om1_1        | 2022-02-05 13:09:48,922 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om2_1        | 2022-02-05 13:09:50,298 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om2_1        | 2022-02-05 13:09:50,302 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om2_1        | 2022-02-05 13:09:50,361 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om2_1        | 2022-02-05 13:09:50,361 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om2_1        | 2022-02-05 13:09:50,393 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om2_1        | 2022-02-05 13:09:50,445 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om2_1        | 2022-02-05 13:09:50,447 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om2_1        | 2022-02-05 13:09:50,448 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om2_1        | 2022-02-05 13:09:50,456 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om2_1        | 2022-02-05 13:09:50,465 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om2_1        | 2022-02-05 13:09:51,106 [Listener at om2/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om2_1        | 2022-02-05 13:09:51,170 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om2_1        | 2022-02-05 13:09:51,170 [Listener at om2/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om2_1        | 2022-02-05 13:09:51,324 [Listener at om2/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om2/172.25.0.112:9862
om2_1        | 2022-02-05 13:09:51,325 [Listener at om2/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om2 at port 9872
om2_1        | 2022-02-05 13:09:51,348 [Listener at om2/9862] INFO server.RaftServer$Division: om2@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-02-05 13:09:51,351 [Listener at om2/9862] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om2_1        | 2022-02-05 13:09:51,355 [Listener at om2/9862] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2022-02-05 13:09:51,365 [Listener at om2/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om2
om2_1        | 2022-02-05 13:09:51,385 [Listener at om2/9862] INFO server.RaftServer: om2: start RPC server
om2_1        | 2022-02-05 13:09:51,573 [Listener at om2/9862] INFO server.GrpcService: om2: GrpcService started, listening on 9872
om2_1        | 2022-02-05 13:09:51,599 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$407/0x00000008405cfc40@66d0d5ee] INFO util.JvmPauseMonitor: JvmPauseMonitor-om2: Started
om2_1        | 2022-02-05 13:09:51,600 [Listener at om2/9862] INFO om.OzoneManager: Starting OM block token secret manager
om2_1        | 2022-02-05 13:09:51,604 [Listener at om2/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2022-02-05 13:09:51,605 [Listener at om2/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om2_1        | 2022-02-05 13:09:51,614 [Listener at om2/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2022-02-05 13:09:51,633 [Listener at om2/9862] INFO om.OzoneManager: Version File has different layout version (0) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om2_1        | 2022-02-05 13:09:51,638 [Thread[Thread-17,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om2_1        | 2022-02-05 13:09:51,805 [Listener at om2/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om2_1        | 2022-02-05 13:09:51,805 [Listener at om2/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om2_1        | 2022-02-05 13:09:51,805 [Listener at om2/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om2_1        | 2022-02-05 13:09:51,988 [Listener at om2/9862] INFO util.log: Logging initialized @44017ms to org.eclipse.jetty.util.log.Slf4jLog
om2_1        | 2022-02-05 13:09:52,460 [Listener at om2/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om2_1        | 2022-02-05 13:09:52,494 [Listener at om2/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om2_1        | 2022-02-05 13:09:52,502 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om2_1        | 2022-02-05 13:09:52,504 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om2_1        | 2022-02-05 13:09:52,504 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om2_1        | 2022-02-05 13:09:52,520 [Listener at om2/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om2_1        | 2022-02-05 13:09:52,663 [Listener at om2/9862] INFO http.HttpServer2: Jetty bound to port 9874
om2_1        | 2022-02-05 13:09:52,673 [Listener at om2/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-LTS
om2_1        | 2022-02-05 13:09:52,846 [Listener at om2/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om2_1        | 2022-02-05 13:09:52,853 [Listener at om2/9862] INFO server.session: No SessionScavenger set, using defaults
om2_1        | 2022-02-05 13:09:52,855 [Listener at om2/9862] INFO server.session: node0 Scavenging every 660000ms
om2_1        | 2022-02-05 13:09:52,936 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om2_1        | 2022-02-05 13:09:52,951 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1313dea8{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om2_1        | 2022-02-05 13:09:52,956 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@56587330{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om2_1        | 2022-02-05 13:09:53,467 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om2_1        | 2022-02-05 13:09:53,520 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@18f6ccf4{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-10566613994667135634/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om2_1        | 2022-02-05 13:09:53,558 [Listener at om2/9862] INFO server.AbstractConnector: Started ServerConnector@626967a0{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
datanode3_1  | 2022-02-05 13:19:55,964 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5191,entriesCount=1,lastEntry=(t:1, i:101)
datanode3_1  | 2022-02-05 13:19:55,981 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5193,entriesCount=1,lastEntry=(t:1, i:102)
datanode3_1  | 2022-02-05 13:19:55,987 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5194,entriesCount=1,lastEntry=(t:1, i:103)
datanode3_1  | 2022-02-05 13:19:56,064 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5202,entriesCount=1,lastEntry=(t:1, i:104)
datanode3_1  | 2022-02-05 13:19:56,094 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5205,entriesCount=1,lastEntry=(t:1, i:105)
datanode3_1  | 2022-02-05 13:19:56,102 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5206,entriesCount=1,lastEntry=(t:1, i:106)
datanode3_1  | 2022-02-05 13:20:01,709 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5457,entriesCount=1,lastEntry=(t:1, i:107)
datanode3_1  | 2022-02-05 13:20:01,747 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5458,entriesCount=1,lastEntry=(t:1, i:108)
datanode3_1  | 2022-02-05 13:20:01,811 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5464,entriesCount=1,lastEntry=(t:1, i:109)
datanode3_1  | 2022-02-05 13:20:01,877 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5469,entriesCount=1,lastEntry=(t:1, i:110)
datanode3_1  | 2022-02-05 13:20:01,891 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5472,entriesCount=1,lastEntry=(t:1, i:111)
datanode3_1  | 2022-02-05 13:20:01,915 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5475,entriesCount=1,lastEntry=(t:1, i:112)
datanode3_1  | 2022-02-05 13:20:01,948 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5478,entriesCount=1,lastEntry=(t:1, i:113)
datanode3_1  | 2022-02-05 13:20:01,967 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5482,entriesCount=1,lastEntry=(t:1, i:114)
datanode3_1  | 2022-02-05 13:20:08,776 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5731,entriesCount=1,lastEntry=(t:1, i:115)
datanode3_1  | 2022-02-05 13:20:08,854 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5732,entriesCount=1,lastEntry=(t:1, i:116)
datanode3_1  | 2022-02-05 13:20:08,956 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5740,entriesCount=1,lastEntry=(t:1, i:117)
datanode3_1  | 2022-02-05 13:20:08,980 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5743,entriesCount=1,lastEntry=(t:1, i:118)
datanode3_1  | 2022-02-05 13:20:09,007 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5746,entriesCount=1,lastEntry=(t:1, i:119)
datanode3_1  | 2022-02-05 13:20:09,160 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5762,entriesCount=1,lastEntry=(t:1, i:120)
datanode3_1  | 2022-02-05 13:20:09,297 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5776,entriesCount=1,lastEntry=(t:1, i:121)
datanode3_1  | 2022-02-05 13:20:12,487 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6025,entriesCount=1,lastEntry=(t:1, i:122)
om2_1        | 2022-02-05 13:09:53,558 [Listener at om2/9862] INFO server.Server: Started @45598ms
om2_1        | 2022-02-05 13:09:53,560 [Listener at om2/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om2_1        | 2022-02-05 13:09:53,565 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om2_1        | 2022-02-05 13:09:53,570 [Listener at om2/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om2_1        | 2022-02-05 13:09:53,571 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1        | 2022-02-05 13:09:53,573 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om2_1        | 2022-02-05 13:09:53,885 [Listener at om2/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om2_1        | 2022-02-05 13:09:54,064 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@ae20523] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om2_1        | 2022-02-05 13:09:54,696 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:44795
om2_1        | 2022-02-05 13:09:54,717 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-02-05 13:09:56,570 [om2@group-562213E44849-FollowerState] INFO impl.FollowerState: om2@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5218077366ns, electionTimeout:5173ms
om2_1        | 2022-02-05 13:09:56,571 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1        | 2022-02-05 13:09:56,572 [om2@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om2_1        | 2022-02-05 13:09:56,575 [om2@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om2_1        | 2022-02-05 13:09:56,586 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: start om2@group-562213E44849-LeaderElection1
om2_1        | 2022-02-05 13:09:56,594 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-02-05 13:09:57,560 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 1, (t:0, i:~))
om2_1        | 2022-02-05 13:09:57,613 [grpc-default-executor-0] INFO impl.VoteContext: om2@group-562213E44849-CANDIDATE: reject ELECTION from om1: already has voted for om2 at current term 1
om2_1        | 2022-02-05 13:09:57,670 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om1<-om2#0:FAIL-t1. Peer's state: om2@group-562213E44849:t1, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-02-05 13:09:58,527 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om2_1        | 2022-02-05 13:09:58,536 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om2<-om1#0:FAIL-t1
om2_1        | 2022-02-05 13:09:58,536 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om2<-om3#0:FAIL-t1
om2_1        | 2022-02-05 13:09:58,540 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om2_1        | 2022-02-05 13:09:58,541 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om2_1        | 2022-02-05 13:09:58,570 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-LeaderElection1
om2_1        | 2022-02-05 13:09:58,572 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2022-02-05 13:09:59,307 [grpc-default-executor-2] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 1, (t:0, i:~))
om2_1        | 2022-02-05 13:09:59,307 [grpc-default-executor-2] INFO impl.VoteContext: om2@group-562213E44849-FOLLOWER: reject ELECTION from om3: already has voted for om2 at current term 1
om2_1        | 2022-02-05 13:09:59,308 [grpc-default-executor-2] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om3<-om2#0:FAIL-t1. Peer's state: om2@group-562213E44849:t1, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-02-05 13:10:03,238 [grpc-default-executor-2] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 2, (t:0, i:~))
om2_1        | 2022-02-05 13:10:03,240 [grpc-default-executor-2] INFO impl.VoteContext: om2@group-562213E44849-FOLLOWER: accept ELECTION from om1: our priority 0 <= candidate's priority 0
om2_1        | 2022-02-05 13:10:03,240 [grpc-default-executor-2] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:om1
om2_1        | 2022-02-05 13:10:03,240 [grpc-default-executor-2] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1        | 2022-02-05 13:10:03,241 [om2@group-562213E44849-FollowerState] INFO impl.FollowerState: om2@group-562213E44849-FollowerState was interrupted: {}
om2_1        | java.lang.InterruptedException: sleep interrupted
om2_1        | 	at java.base/java.lang.Thread.sleep(Native Method)
om2_1        | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
om2_1        | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
om2_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
om2_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
om2_1        | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
om2_1        | 2022-02-05 13:10:03,246 [grpc-default-executor-2] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2022-02-05 13:10:03,279 [grpc-default-executor-2] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om1<-om2#0:OK-t2. Peer's state: om2@group-562213E44849:t2, leader=null, voted=om1, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-02-05 13:10:03,787 [grpc-default-executor-2] INFO server.RaftServer$Division: om2@group-562213E44849: change Leader from null to om1 at term 2 for appendEntries, leader elected after 14231ms
om2_1        | 2022-02-05 13:10:03,934 [grpc-default-executor-2] INFO server.RaftServer$Division: om2@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1        | 2022-02-05 13:10:03,950 [grpc-default-executor-2] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
kdc_1        | Feb 05 13:25:07 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:26:07 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:26:07 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:26:35 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644067595, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:26:41 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644067595, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:27:07 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:27:07 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:28:07 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:28:07 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:29:07 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:29:07 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:30:07 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:30:07 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:31:01 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644067861, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:31:06 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644067861, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:31:07 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:31:07 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:32:07 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:32:07 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Feb 05 13:32:13 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644067933, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:32:20 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644067933, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:32:37 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644067957, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:32:43 kdc krb5kdc[6](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1644067957, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Feb 05 13:32:46 kdc krb5kdc[6](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644067966, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 05 13:32:46 kdc krb5kdc[6](info): TGS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1644067966, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for HTTP/s3g@EXAMPLE.COM
datanode3_1  | 2022-02-05 13:20:12,502 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6026,entriesCount=1,lastEntry=(t:1, i:123)
datanode3_1  | 2022-02-05 13:20:12,507 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6027,entriesCount=1,lastEntry=(t:1, i:124)
datanode3_1  | 2022-02-05 13:20:12,514 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6028,entriesCount=1,lastEntry=(t:1, i:125)
datanode3_1  | 2022-02-05 13:20:15,780 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6276,entriesCount=1,lastEntry=(t:1, i:126)
datanode3_1  | 2022-02-05 13:20:15,906 [java.util.concurrent.ThreadPoolExecutor$Worker@5fdc68ae[State = -1, empty queue]] WARN server.GrpcLogAppender: a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545->9905eb49-ac94-40b9-a1a3-f35673531eee-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6277,entriesCount=1,lastEntry=(t:1, i:127)
datanode3_1  | 2022-02-05 13:22:16,654 [Thread-653] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-570B04D6CA27->a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545, cid=141, seq=0, Watch-ALL_COMMITTED(131), Message:<EMPTY>, reply=RaftClientReply:client-570B04D6CA27->a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545, cid=141, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 141 and log index 131 is not yet replicated to ALL_COMMITTED, logIndex=131, commits[a527daad-fcfc-4913-bb86-57ba7fce9b83:c145, 9905eb49-ac94-40b9-a1a3-f35673531eee:c127, 3bd141d9-8d6a-4889-940a-437a7867e049:c145]
datanode3_1  | 2022-02-05 13:23:16,652 [Thread-690] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-09FE4ECC4E3A->a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545, cid=147, seq=0, Watch-ALL_COMMITTED(138), Message:<EMPTY>, reply=RaftClientReply:client-09FE4ECC4E3A->a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545, cid=147, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 147 and log index 138 is not yet replicated to ALL_COMMITTED, logIndex=138, commits[a527daad-fcfc-4913-bb86-57ba7fce9b83:c149, 9905eb49-ac94-40b9-a1a3-f35673531eee:c127, 3bd141d9-8d6a-4889-940a-437a7867e049:c149]
datanode3_1  | 2022-02-05 13:24:33,652 [Thread-738] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-9A03C43A6E23->a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545, cid=157, seq=0, Watch-ALL_COMMITTED(143), Message:<EMPTY>, reply=RaftClientReply:client-9A03C43A6E23->a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545, cid=157, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 157 and log index 143 is not yet replicated to ALL_COMMITTED, logIndex=143, commits[a527daad-fcfc-4913-bb86-57ba7fce9b83:c153, 9905eb49-ac94-40b9-a1a3-f35673531eee:c127, 3bd141d9-8d6a-4889-940a-437a7867e049:c153]
datanode3_1  | 2022-02-05 13:25:34,652 [Thread-775] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-7D4833D5CD4D->a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545, cid=162, seq=0, Watch-ALL_COMMITTED(147), Message:<EMPTY>, reply=RaftClientReply:client-7D4833D5CD4D->a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545, cid=162, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 162 and log index 147 is not yet replicated to ALL_COMMITTED, logIndex=147, commits[a527daad-fcfc-4913-bb86-57ba7fce9b83:c157, 9905eb49-ac94-40b9-a1a3-f35673531eee:c127, 3bd141d9-8d6a-4889-940a-437a7867e049:c157]
datanode3_1  | 2022-02-05 13:26:35,652 [Thread-812] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-B6B49F055E82->a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545, cid=167, seq=0, Watch-ALL_COMMITTED(151), Message:<EMPTY>, reply=RaftClientReply:client-B6B49F055E82->a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545, cid=167, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 167 and log index 151 is not yet replicated to ALL_COMMITTED, logIndex=151, commits[a527daad-fcfc-4913-bb86-57ba7fce9b83:c161, 9905eb49-ac94-40b9-a1a3-f35673531eee:c127, 3bd141d9-8d6a-4889-940a-437a7867e049:c161]
datanode3_1  | 2022-02-05 13:27:35,652 [Thread-853] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-6B6C9D214C14->a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545, cid=172, seq=0, Watch-ALL_COMMITTED(155), Message:<EMPTY>, reply=RaftClientReply:client-6B6C9D214C14->a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545, cid=172, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 172 and log index 155 is not yet replicated to ALL_COMMITTED, logIndex=155, commits[a527daad-fcfc-4913-bb86-57ba7fce9b83:c165, 9905eb49-ac94-40b9-a1a3-f35673531eee:c127, 3bd141d9-8d6a-4889-940a-437a7867e049:c165]
datanode3_1  | 2022-02-05 13:28:39,651 [Thread-891] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-C82D1F4775C5->a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545, cid=177, seq=0, Watch-ALL_COMMITTED(160), Message:<EMPTY>, reply=RaftClientReply:client-C82D1F4775C5->a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545, cid=177, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 177 and log index 160 is not yet replicated to ALL_COMMITTED, logIndex=160, commits[a527daad-fcfc-4913-bb86-57ba7fce9b83:c169, 9905eb49-ac94-40b9-a1a3-f35673531eee:c127, 3bd141d9-8d6a-4889-940a-437a7867e049:c169]
datanode3_1  | 2022-02-05 13:29:49,652 [Thread-936] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-3CFDE54989A7->a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545, cid=186, seq=0, Watch-ALL_COMMITTED(164), Message:<EMPTY>, reply=RaftClientReply:client-3CFDE54989A7->a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545, cid=186, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 186 and log index 164 is not yet replicated to ALL_COMMITTED, logIndex=164, commits[a527daad-fcfc-4913-bb86-57ba7fce9b83:c173, 9905eb49-ac94-40b9-a1a3-f35673531eee:c127, 3bd141d9-8d6a-4889-940a-437a7867e049:c173]
datanode3_1  | 2022-02-05 13:30:49,654 [Thread-977] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-C46B8663D0A0->a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545, cid=191, seq=0, Watch-ALL_COMMITTED(167), Message:<EMPTY>, reply=RaftClientReply:client-C46B8663D0A0->a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545, cid=191, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 191 and log index 167 is not yet replicated to ALL_COMMITTED, logIndex=167, commits[a527daad-fcfc-4913-bb86-57ba7fce9b83:c177, 9905eb49-ac94-40b9-a1a3-f35673531eee:c127, 3bd141d9-8d6a-4889-940a-437a7867e049:c177]
datanode3_1  | 2022-02-05 13:31:50,652 [Thread-1018] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-4D017E3D47E5->a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545, cid=196, seq=0, Watch-ALL_COMMITTED(171), Message:<EMPTY>, reply=RaftClientReply:client-4D017E3D47E5->a527daad-fcfc-4913-bb86-57ba7fce9b83@group-139BDF3E2545, cid=196, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 196 and log index 171 is not yet replicated to ALL_COMMITTED, logIndex=171, commits[a527daad-fcfc-4913-bb86-57ba7fce9b83:c181, 9905eb49-ac94-40b9-a1a3-f35673531eee:c127, 3bd141d9-8d6a-4889-940a-437a7867e049:c181]
om1_1        | 2022-02-05 13:09:48,930 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2022-02-05 13:09:48,934 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om1_1        | 2022-02-05 13:09:48,936 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om1_1        | 2022-02-05 13:09:48,937 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om1_1        | 2022-02-05 13:09:48,948 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-02-05 13:10:07,763 [grpc-default-executor-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F replies to ELECTION vote request: a527daad-fcfc-4913-bb86-57ba7fce9b83<-9905eb49-ac94-40b9-a1a3-f35673531eee#0:OK-t4. Peer's state: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F:t4, leader=null, voted=a527daad-fcfc-4913-bb86-57ba7fce9b83, raftlog=9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-SegmentedRaftLog:OPENED:c-1, conf=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-02-05 13:10:07,780 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-LeaderElection2] INFO impl.LeaderElection: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2022-02-05 13:10:07,780 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-LeaderElection2] INFO impl.LeaderElection: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-LeaderElection2 ELECTION round 0: result PASSED (term=1)
datanode1_1  | 2022-02-05 13:10:07,780 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-LeaderElection2] INFO impl.RoleInfo: 9905eb49-ac94-40b9-a1a3-f35673531eee: shutdown 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-LeaderElection2
datanode1_1  | 2022-02-05 13:10:07,780 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-LeaderElection2] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode1_1  | 2022-02-05 13:10:07,780 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-DF306916AC0E with new leaderId: 9905eb49-ac94-40b9-a1a3-f35673531eee
datanode1_1  | 2022-02-05 13:10:07,782 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-LeaderElection2] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E: change Leader from null to 9905eb49-ac94-40b9-a1a3-f35673531eee at term 1 for becomeLeader, leader elected after 5369ms
datanode1_1  | 2022-02-05 13:10:07,786 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode1_1  | 2022-02-05 13:10:07,827 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-02-05 13:10:07,830 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode1_1  | 2022-02-05 13:10:07,843 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode1_1  | 2022-02-05 13:10:07,843 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode1_1  | 2022-02-05 13:10:07,844 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode1_1  | 2022-02-05 13:10:07,849 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-02-05 13:10:07,851 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode1_1  | 2022-02-05 13:10:07,857 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-LeaderElection2] INFO impl.RoleInfo: 9905eb49-ac94-40b9-a1a3-f35673531eee: start 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-LeaderStateImpl
datanode1_1  | 2022-02-05 13:10:07,869 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-02-05 13:10:07,871 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/8861f5bd-9ae4-4203-8e86-df306916ac0e/current/log_inprogress_0
datanode1_1  | 2022-02-05 13:10:07,885 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E-LeaderElection2] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DF306916AC0E: set configuration 0: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-02-05 13:10:12,830 [grpc-default-executor-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F: receive requestVote(ELECTION, a527daad-fcfc-4913-bb86-57ba7fce9b83, group-DD33D84C9D7F, 5, (t:0, i:0))
datanode1_1  | 2022-02-05 13:10:12,831 [grpc-default-executor-1] INFO impl.VoteContext: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FOLLOWER: accept ELECTION from a527daad-fcfc-4913-bb86-57ba7fce9b83: our priority 0 <= candidate's priority 0
datanode1_1  | 2022-02-05 13:10:12,831 [grpc-default-executor-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:a527daad-fcfc-4913-bb86-57ba7fce9b83
datanode1_1  | 2022-02-05 13:10:12,831 [grpc-default-executor-1] INFO impl.RoleInfo: 9905eb49-ac94-40b9-a1a3-f35673531eee: shutdown 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState
datanode1_1  | 2022-02-05 13:10:12,831 [grpc-default-executor-1] INFO impl.RoleInfo: 9905eb49-ac94-40b9-a1a3-f35673531eee: start 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState
datanode1_1  | 2022-02-05 13:10:12,831 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState] INFO impl.FollowerState: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode1_1  | 2022-02-05 13:10:12,856 [grpc-default-executor-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F replies to ELECTION vote request: a527daad-fcfc-4913-bb86-57ba7fce9b83<-9905eb49-ac94-40b9-a1a3-f35673531eee#0:OK-t5. Peer's state: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F:t5, leader=null, voted=a527daad-fcfc-4913-bb86-57ba7fce9b83, raftlog=9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-SegmentedRaftLog:OPENED:c-1, conf=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-02-05 13:10:17,920 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState] INFO impl.FollowerState: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5064099817ns, electionTimeout:5063ms
datanode1_1  | 2022-02-05 13:10:17,920 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState] INFO impl.RoleInfo: 9905eb49-ac94-40b9-a1a3-f35673531eee: shutdown 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState
om3_1        | Sleeping for 5 seconds
om3_1        | Waiting for the service scm3.org:9894
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2022-02-05 13:08:39,431 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = [--init]
om3_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/f757d9929c7016e9989d08ab2698179d61ef158b ; compiled by 'runner' on 2022-02-05T12:45Z
om3_1        | STARTUP_MSG:   java = 11.0.13
om3_1        | ************************************************************/
om3_1        | 2022-02-05 13:08:39,538 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2022-02-05 13:08:49,169 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-02-05 13:08:49,706 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-02-05 13:08:49,706 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-02-05 13:08:49,706 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-02-05 13:08:50,919 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2022-02-05 13:08:50,931 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2022-02-05 13:08:50,944 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-02-05 13:08:55,282 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om3_1        | 2022-02-05 13:08:58,535 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om3_1        | 2022-02-05 13:08:58,535 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om3_1        | 2022-02-05 13:08:58,554 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om3_1        | 2022-02-05 13:09:07,801 [main] INFO om.OzoneManager: Init response: GETCERT
om3_1        | 2022-02-05 13:09:08,202 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.113,host:om3
om3_1        | 2022-02-05 13:09:08,202 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om3_1        | 2022-02-05 13:09:08,217 [main] ERROR client.OMCertificateClient: Invalid domain om3
om3_1        | 2022-02-05 13:09:08,255 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-02-05 13:09:08,259 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-02-05 13:09:08,275 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-02-05 13:09:08,280 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-02-05 13:09:08,281 [main] INFO om.OzoneManager: Creating csr for OM->dns:om3,ip:172.25.0.113,scmId:70490618-601a-4309-ad32-4488318b9859,clusterId:CID-fc180783-fb1e-4dd7-af87-eddf767648b7,subject:om3
om3_1        | 2022-02-05 13:09:09,546 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om3_1        | value: 9862
om3_1        | ]
om3_1        | 2022-02-05 13:09:11,126 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om3_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-fc180783-fb1e-4dd7-af87-eddf767648b7;layoutVersion=0
om3_1        | 2022-02-05 13:09:11,377 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om3_1        | /************************************************************
om3_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om3/172.25.0.113
om3_1        | ************************************************************/
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2022-02-05 13:09:20,712 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = []
om3_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
recon_1      | Sleeping for 5 seconds
recon_1      | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
recon_1      | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1      | 2022-02-05 13:07:14,618 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1      | /************************************************************
recon_1      | STARTUP_MSG: Starting ReconServer
recon_1      | STARTUP_MSG:   host = recon/172.25.0.115
recon_1      | STARTUP_MSG:   args = []
recon_1      | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
recon_1      | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.33.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.18.RELEASE.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-tools-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.18.RELEASE.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.18.RELEASE.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.18.RELEASE.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.33.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.18.RELEASE.jar:/opt/hadoop/share/ozone/lib/ozone-reconcodegen-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar
recon_1      | STARTUP_MSG:   build = https://github.com/apache/ozone/f757d9929c7016e9989d08ab2698179d61ef158b ; compiled by 'runner' on 2022-02-05T12:45Z
recon_1      | STARTUP_MSG:   java = 11.0.13
recon_1      | ************************************************************/
recon_1      | 2022-02-05 13:07:14,685 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1      | 2022-02-05 13:07:18,051 [main] INFO reflections.Reflections: Reflections took 321 ms to scan 1 urls, producing 13 keys and 35 values 
recon_1      | 2022-02-05 13:07:20,683 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1      | 2022-02-05 13:07:20,869 [main] INFO recon.ReconServer: Ozone security is enabled. Attempting login for Recon service. Principal: recon/recon@EXAMPLE.COM, keytab: /etc/security/keytabs/recon.keytab
recon_1      | 2022-02-05 13:07:21,667 [main] INFO security.UserGroupInformation: Login successful for user recon/recon@EXAMPLE.COM using keytab file recon.keytab. Keytab auto renewal enabled : false
recon_1      | 2022-02-05 13:07:21,670 [main] INFO recon.ReconServer: Recon login successful.
recon_1      | 2022-02-05 13:07:22,595 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2022-02-05 13:07:25,708 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | WARNING: An illegal reflective access operation has occurred
recon_1      | WARNING: Illegal reflective access by org.jooq.tools.reflect.Reflect (file:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class)
recon_1      | WARNING: Please consider reporting this to the maintainers of org.jooq.tools.reflect.Reflect
recon_1      | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1      | WARNING: All illegal access operations will be denied in a future release
recon_1      | 2022-02-05 13:07:26,616 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2022-02-05 13:07:26,681 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | 2022-02-05 13:07:26,698 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1      | 2022-02-05 13:07:28,939 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1      | 2022-02-05 13:07:28,939 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
recon_1      | 2022-02-05 13:07:28,940 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.recon.http.auth.type = kerberos
recon_1      | 2022-02-05 13:07:28,970 [main] INFO util.log: Logging initialized @17709ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1      | 2022-02-05 13:07:29,173 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1      | 2022-02-05 13:07:29,190 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1      | 2022-02-05 13:07:29,192 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context recon
recon_1      | 2022-02-05 13:07:29,192 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
recon_1      | 2022-02-05 13:07:29,192 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1      | 2022-02-05 13:07:29,194 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.recon.http.auth.kerberos.principal keytabKey: ozone.recon.http.auth.kerberos.keytab
recon_1      | 2022-02-05 13:07:29,354 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1      | 2022-02-05 13:07:29,906 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1      | 2022-02-05 13:07:29,917 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
recon_1      | 2022-02-05 13:07:29,926 [main] INFO tasks.ReconTaskControllerImpl: Registered task NSSummaryTask with controller.
recon_1      | 2022-02-05 13:07:29,955 [main] INFO ozone.OmUtils: Using OzoneManager ServiceID 'id1'.
recon_1      | 2022-02-05 13:07:31,080 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode1_1  | 2022-02-05 13:10:17,920 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F: changes role from  FOLLOWER to CANDIDATE at term 5 for changeToCandidate
datanode1_1  | 2022-02-05 13:10:17,921 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-02-05 13:10:17,921 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState] INFO impl.RoleInfo: 9905eb49-ac94-40b9-a1a3-f35673531eee: start 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-LeaderElection3
datanode1_1  | 2022-02-05 13:10:17,929 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-LeaderElection3] INFO impl.LeaderElection: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-LeaderElection3 ELECTION round 0: submit vote requests at term 6 for -1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-02-05 13:10:17,967 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-LeaderElection3] INFO impl.LeaderElection: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-LeaderElection3: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode1_1  | 2022-02-05 13:10:17,972 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-LeaderElection3] INFO impl.LeaderElection:   Response 0: 9905eb49-ac94-40b9-a1a3-f35673531eee<-3bd141d9-8d6a-4889-940a-437a7867e049#0:FAIL-t6
datanode1_1  | 2022-02-05 13:10:17,972 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-LeaderElection3] INFO impl.LeaderElection: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-LeaderElection3 ELECTION round 0: result REJECTED
datanode1_1  | 2022-02-05 13:10:17,972 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-LeaderElection3] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F: changes role from CANDIDATE to FOLLOWER at term 6 for REJECTED
datanode1_1  | 2022-02-05 13:10:17,972 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-LeaderElection3] INFO impl.RoleInfo: 9905eb49-ac94-40b9-a1a3-f35673531eee: shutdown 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-LeaderElection3
datanode1_1  | 2022-02-05 13:10:17,973 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-LeaderElection3] INFO impl.RoleInfo: 9905eb49-ac94-40b9-a1a3-f35673531eee: start 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState
datanode1_1  | 2022-02-05 13:10:23,000 [grpc-default-executor-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F: receive requestVote(ELECTION, 3bd141d9-8d6a-4889-940a-437a7867e049, group-DD33D84C9D7F, 7, (t:0, i:0))
datanode1_1  | 2022-02-05 13:10:23,001 [grpc-default-executor-1] INFO impl.VoteContext: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FOLLOWER: accept ELECTION from 3bd141d9-8d6a-4889-940a-437a7867e049: our priority 0 <= candidate's priority 1
datanode1_1  | 2022-02-05 13:10:23,001 [grpc-default-executor-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F: changes role from  FOLLOWER to FOLLOWER at term 7 for candidate:3bd141d9-8d6a-4889-940a-437a7867e049
datanode1_1  | 2022-02-05 13:10:23,001 [grpc-default-executor-1] INFO impl.RoleInfo: 9905eb49-ac94-40b9-a1a3-f35673531eee: shutdown 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState
datanode1_1  | 2022-02-05 13:10:23,002 [grpc-default-executor-1] INFO impl.RoleInfo: 9905eb49-ac94-40b9-a1a3-f35673531eee: start 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState
datanode1_1  | 2022-02-05 13:10:23,002 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState] INFO impl.FollowerState: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-FollowerState was interrupted: {}
datanode1_1  | java.lang.InterruptedException: sleep interrupted
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode1_1  | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
datanode1_1  | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
datanode1_1  | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
datanode1_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
datanode1_1  | 2022-02-05 13:10:23,017 [grpc-default-executor-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F replies to ELECTION vote request: 3bd141d9-8d6a-4889-940a-437a7867e049<-9905eb49-ac94-40b9-a1a3-f35673531eee#0:OK-t7. Peer's state: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F:t7, leader=null, voted=3bd141d9-8d6a-4889-940a-437a7867e049, raftlog=9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-SegmentedRaftLog:OPENED:c-1, conf=-1: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-02-05 13:10:23,459 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-DD33D84C9D7F with new leaderId: 3bd141d9-8d6a-4889-940a-437a7867e049
datanode1_1  | 2022-02-05 13:10:23,459 [grpc-default-executor-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F: change Leader from null to 3bd141d9-8d6a-4889-940a-437a7867e049 at term 7 for appendEntries, leader elected after 35836ms
datanode1_1  | 2022-02-05 13:10:23,582 [grpc-default-executor-1] INFO server.RaftServer$Division: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F: set configuration 0: [9905eb49-ac94-40b9-a1a3-f35673531eee|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, a527daad-fcfc-4913-bb86-57ba7fce9b83|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3bd141d9-8d6a-4889-940a-437a7867e049|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-02-05 13:10:23,583 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-02-05 13:10:23,589 [9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 9905eb49-ac94-40b9-a1a3-f35673531eee@group-DD33D84C9D7F-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/f1ca961d-d578-498d-933d-dd33d84c9d7f/current/log_inprogress_0
datanode1_1  | 2022-02-05 13:10:28,481 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:944034450553.
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/f757d9929c7016e9989d08ab2698179d61ef158b ; compiled by 'runner' on 2022-02-05T12:45Z
om3_1        | STARTUP_MSG:   java = 11.0.13
om3_1        | ************************************************************/
om3_1        | 2022-02-05 13:09:20,822 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2022-02-05 13:09:29,615 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-02-05 13:09:30,356 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-02-05 13:09:30,370 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-02-05 13:09:30,376 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-02-05 13:09:30,459 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-02-05 13:09:30,779 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = INITIAL_VERSION (version = 0)
om3_1        | 2022-02-05 13:09:32,550 [main] INFO reflections.Reflections: Reflections took 1158 ms to scan 1 urls, producing 97 keys and 265 values [using 2 cores]
om3_1        | 2022-02-05 13:09:33,843 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2022-02-05 13:09:33,845 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2022-02-05 13:09:33,846 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-02-05 13:09:40,211 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om3_1        | 2022-02-05 13:09:41,202 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om3_1        | 2022-02-05 13:09:41,271 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/948875716125.crt.
om3_1        | 2022-02-05 13:09:41,285 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-850810018938.crt.
om3_1        | 2022-02-05 13:09:41,507 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-02-05 13:09:42,700 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om3_1        | 2022-02-05 13:09:42,707 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om3_1        | 2022-02-05 13:09:43,877 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om3_1        | 2022-02-05 13:09:43,877 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om3_1        | 2022-02-05 13:09:44,466 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
om3_1        | 2022-02-05 13:09:44,666 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2022-02-05 13:09:48,950 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om1_1        | 2022-02-05 13:09:49,075 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om1_1        | 2022-02-05 13:09:49,077 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om1_1        | 2022-02-05 13:09:49,119 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om1_1        | 2022-02-05 13:09:49,119 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om1_1        | 2022-02-05 13:09:49,125 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om1_1        | 2022-02-05 13:09:49,131 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om1_1        | 2022-02-05 13:09:49,137 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om1_1        | 2022-02-05 13:09:49,137 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om1_1        | 2022-02-05 13:09:49,143 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om1_1        | 2022-02-05 13:09:49,146 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om1_1        | 2022-02-05 13:09:49,611 [Listener at om1/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om1_1        | 2022-02-05 13:09:49,681 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om1_1        | 2022-02-05 13:09:49,682 [Listener at om1/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om1_1        | 2022-02-05 13:09:49,906 [Listener at om1/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om1/172.25.0.111:9862
om1_1        | 2022-02-05 13:09:49,910 [Listener at om1/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
om1_1        | 2022-02-05 13:09:49,914 [Listener at om1/9862] INFO server.RaftServer$Division: om1@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-02-05 13:09:49,917 [Listener at om1/9862] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om1_1        | 2022-02-05 13:09:49,923 [Listener at om1/9862] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2022-02-05 13:09:49,934 [Listener at om1/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om1
om1_1        | 2022-02-05 13:09:49,949 [Listener at om1/9862] INFO server.RaftServer: om1: start RPC server
om1_1        | 2022-02-05 13:09:50,114 [Listener at om1/9862] INFO server.GrpcService: om1: GrpcService started, listening on 9872
om1_1        | 2022-02-05 13:09:50,131 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$407/0x00000008405cfc40@61b3de5b] INFO util.JvmPauseMonitor: JvmPauseMonitor-om1: Started
om1_1        | 2022-02-05 13:09:50,142 [Listener at om1/9862] INFO om.OzoneManager: Starting OM block token secret manager
om1_1        | 2022-02-05 13:09:50,142 [Listener at om1/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2022-02-05 13:09:50,144 [Listener at om1/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om1_1        | 2022-02-05 13:09:50,144 [Listener at om1/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2022-02-05 13:09:50,156 [Listener at om1/9862] INFO om.OzoneManager: Version File has different layout version (0) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om1_1        | 2022-02-05 13:09:50,169 [Thread[Thread-17,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om1_1        | 2022-02-05 13:09:50,321 [Listener at om1/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om1_1        | 2022-02-05 13:09:50,322 [Listener at om1/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om1_1        | 2022-02-05 13:09:50,323 [Listener at om1/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om1_1        | 2022-02-05 13:09:50,442 [Listener at om1/9862] INFO util.log: Logging initialized @41552ms to org.eclipse.jetty.util.log.Slf4jLog
om1_1        | 2022-02-05 13:09:51,092 [Listener at om1/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om1_1        | 2022-02-05 13:09:51,142 [Listener at om1/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om1_1        | 2022-02-05 13:09:51,143 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om1_1        | 2022-02-05 13:09:51,153 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om1_1        | 2022-02-05 13:09:51,153 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om1_1        | 2022-02-05 13:09:51,164 [Listener at om1/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om1_1        | 2022-02-05 13:09:51,341 [Listener at om1/9862] INFO http.HttpServer2: Jetty bound to port 9874
om1_1        | 2022-02-05 13:09:51,348 [Listener at om1/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-LTS
om1_1        | 2022-02-05 13:09:51,462 [Listener at om1/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om1_1        | 2022-02-05 13:09:51,462 [Listener at om1/9862] INFO server.session: No SessionScavenger set, using defaults
om1_1        | 2022-02-05 13:09:51,464 [Listener at om1/9862] INFO server.session: node0 Scavenging every 660000ms
om1_1        | 2022-02-05 13:09:51,535 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2022-02-05 13:09:51,541 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@33dcbdc2{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om1_1        | 2022-02-05 13:09:51,550 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5091456c{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om1_1        | 2022-02-05 13:09:51,931 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2022-02-05 13:09:51,998 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@219c32e3{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-1028637481494077940/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om1_1        | 2022-02-05 13:09:52,041 [Listener at om1/9862] INFO server.AbstractConnector: Started ServerConnector@75fb04ee{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om1_1        | 2022-02-05 13:09:52,045 [Listener at om1/9862] INFO server.Server: Started @43155ms
om1_1        | 2022-02-05 13:09:52,063 [Listener at om1/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om1_1        | 2022-02-05 13:09:52,063 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om1_1        | 2022-02-05 13:09:52,066 [Listener at om1/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om1_1        | 2022-02-05 13:09:52,076 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om1_1        | 2022-02-05 13:09:52,102 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om1_1        | 2022-02-05 13:09:52,403 [Listener at om1/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om1_1        | 2022-02-05 13:09:52,529 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@141cee26] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om1_1        | 2022-02-05 13:09:52,713 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:33779
om1_1        | 2022-02-05 13:09:52,730 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:09:55,014 [om1@group-562213E44849-FollowerState] INFO impl.FollowerState: om1@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5091799187ns, electionTimeout:5081ms
om1_1        | 2022-02-05 13:09:55,018 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
om1_1        | 2022-02-05 13:09:55,021 [om1@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om1_1        | 2022-02-05 13:09:55,024 [om1@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om1_1        | 2022-02-05 13:09:55,028 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderElection1
om1_1        | 2022-02-05 13:09:55,041 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-02-05 13:09:58,190 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om1_1        | 2022-02-05 13:09:58,191 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om1<-om3#0:FAIL-t1
om1_1        | 2022-02-05 13:09:58,191 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om1<-om2#0:FAIL-t1
om1_1        | 2022-02-05 13:09:58,191 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om1_1        | 2022-02-05 13:09:58,193 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om1_1        | 2022-02-05 13:09:58,194 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-LeaderElection1
om1_1        | 2022-02-05 13:09:58,194 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2022-02-05 13:09:58,427 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
om1_1        | 2022-02-05 13:09:58,438 [grpc-default-executor-0] INFO impl.VoteContext: om1@group-562213E44849-FOLLOWER: reject ELECTION from om2: already has voted for om1 at current term 1
om1_1        | 2022-02-05 13:09:58,458 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om2<-om1#0:FAIL-t1. Peer's state: om1@group-562213E44849:t1, leader=null, voted=om1, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-02-05 13:10:04,326 [om2@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om2_1        | 2022-02-05 13:10:07,104 [om2@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om2_1        | [id: "om1"
om2_1        | address: "om1:9872"
om2_1        | , id: "om3"
om2_1        | address: "om3:9872"
om2_1        | , id: "om2"
om2_1        | address: "om2:9872"
om2_1        | ]
om2_1        | 2022-02-05 13:10:24,429 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$407/0x00000008405cfc40@66d0d5ee] WARN util.JvmPauseMonitor: JvmPauseMonitor-om2: Detected pause in JVM or host machine (eg GC): pause of approximately 188791812ns.
om2_1        | GC pool 'ParNew' had collection(s): count=1 time=204ms
om2_1        | 2022-02-05 13:10:24,701 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:root
om2_1        | 2022-02-05 13:11:28,164 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:91536-source for user:root
om2_1        | 2022-02-05 13:11:32,799 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:91536-target for user:root
om2_1        | 2022-02-05 13:14:11,411 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:91536-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:187)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-02-05 13:14:20,077 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:91536-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:187)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-02-05 13:17:31,637 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-8586837866 in volume:s3v
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:187)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-02-05 13:17:40,210 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-1447320186 in volume:s3v
om2_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om2_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2334)
om2_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2304)
om2_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:197)
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:101)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-02-05 13:18:17,154 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-1400913700/ozone-test-1594238177/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om2_1        | 2022-02-05 13:18:17,154 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-1594238177/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-1400913700
om2_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-1400913700 key: ozone-test-1594238177/multipartKey2. Entity too small.
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:473)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 2022-02-05 13:09:59,270 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 1, (t:0, i:~))
om1_1        | 2022-02-05 13:09:59,271 [grpc-default-executor-0] INFO impl.VoteContext: om1@group-562213E44849-FOLLOWER: reject ELECTION from om3: already has voted for om1 at current term 1
om1_1        | 2022-02-05 13:09:59,271 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om3<-om1#0:FAIL-t1. Peer's state: om1@group-562213E44849:t1, leader=null, voted=om1, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-02-05 13:10:03,205 [om1@group-562213E44849-FollowerState] INFO impl.FollowerState: om1@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5010580995ns, electionTimeout:5010ms
om1_1        | 2022-02-05 13:10:03,208 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
om1_1        | 2022-02-05 13:10:03,209 [om1@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
om1_1        | 2022-02-05 13:10:03,209 [om1@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om1_1        | 2022-02-05 13:10:03,209 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderElection2
om1_1        | 2022-02-05 13:10:03,224 [om1@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection2 ELECTION round 0: submit vote requests at term 2 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-02-05 13:10:03,290 [om1@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection2: ELECTION PASSED received 1 response(s) and 0 exception(s):
om1_1        | 2022-02-05 13:10:03,293 [om1@group-562213E44849-LeaderElection2] INFO impl.LeaderElection:   Response 0: om1<-om3#0:OK-t2
om1_1        | 2022-02-05 13:10:03,294 [om1@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection2 ELECTION round 0: result PASSED
om1_1        | 2022-02-05 13:10:03,294 [om1@group-562213E44849-LeaderElection2] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-LeaderElection2
om1_1        | 2022-02-05 13:10:03,294 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
om1_1        | 2022-02-05 13:10:03,296 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om1@group-562213E44849: change Leader from null to om1 at term 2 for becomeLeader, leader elected after 14682ms
om1_1        | 2022-02-05 13:10:03,332 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om1_1        | 2022-02-05 13:10:03,366 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om1_1        | 2022-02-05 13:10:03,368 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
om1_1        | 2022-02-05 13:10:03,397 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om1_1        | 2022-02-05 13:10:03,398 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om1_1        | 2022-02-05 13:10:03,400 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om1_1        | 2022-02-05 13:10:03,418 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om1_1        | 2022-02-05 13:10:03,429 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
om1_1        | 2022-02-05 13:10:03,462 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om1_1        | 2022-02-05 13:10:03,470 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-02-05 13:10:03,471 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om1_1        | 2022-02-05 13:10:03,488 [om1@group-562213E44849-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om1_1        | 2022-02-05 13:10:03,489 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2022-02-05 13:10:03,489 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2022-02-05 13:10:03,509 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om1_1        | 2022-02-05 13:10:03,518 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-02-05 13:10:03,518 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om1_1        | 2022-02-05 13:10:03,519 [om1@group-562213E44849-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om1_1        | 2022-02-05 13:10:03,521 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2022-02-05 13:10:03,521 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2022-02-05 13:10:03,537 [om1@group-562213E44849-LeaderElection2] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderStateImpl
om1_1        | 2022-02-05 13:10:03,582 [om1@group-562213E44849-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om1_1        | 2022-02-05 13:10:03,683 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om1@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1        | 2022-02-05 13:10:04,077 [om1@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om1_1        | 2022-02-05 13:10:04,390 [om1@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om1_1        | [id: "om1"
om1_1        | address: "om1:9872"
om1_1        | , id: "om3"
om1_1        | address: "om3:9872"
om1_1        | , id: "om2"
om1_1        | address: "om2:9872"
om1_1        | ]
om1_1        | 2022-02-05 13:10:08,350 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33526
om1_1        | 2022-02-05 13:10:08,366 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:10:22,289 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33562
om1_1        | 2022-02-05 13:10:22,315 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:10:23,165 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:root
om1_1        | 2022-02-05 13:10:36,390 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33616
om1_1        | 2022-02-05 13:10:36,411 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:10:36,952 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33618
om1_1        | 2022-02-05 13:10:36,956 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:10:42,002 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33642
om1_1        | 2022-02-05 13:10:42,031 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:10:42,563 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33644
om1_1        | 2022-02-05 13:10:42,567 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:10:47,424 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33658
om1_1        | 2022-02-05 13:10:47,444 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:10:57,675 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33682
om1_1        | 2022-02-05 13:10:57,707 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:11:03,227 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33718
om1_1        | 2022-02-05 13:11:03,243 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:11:03,762 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33720
om1_1        | 2022-02-05 13:11:03,774 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:11:06,554 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:34663
om1_1        | 2022-02-05 13:11:06,560 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:11:08,858 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33734
om1_1        | 2022-02-05 13:11:08,882 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:11:13,412 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33738
om1_1        | 2022-02-05 13:11:13,434 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:11:27,563 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33770
om1_1        | 2022-02-05 13:11:27,591 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:11:28,142 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:91536-source for user:root
om1_1        | 2022-02-05 13:11:32,210 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33798
om1_1        | 2022-02-05 13:11:32,251 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1      | 2022-02-05 13:07:31,479 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-02-05 13:07:31,588 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-02-05 13:07:31,637 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
recon_1      | 2022-02-05 13:07:31,647 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1      | 2022-02-05 13:07:31,775 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-02-05 13:07:32,082 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
recon_1      | 2022-02-05 13:07:32,203 [main] INFO reflections.Reflections: Reflections took 108 ms to scan 3 urls, producing 103 keys and 217 values 
recon_1      | 2022-02-05 13:07:32,291 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
recon_1      | 2022-02-05 13:07:32,351 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1      | 2022-02-05 13:07:32,368 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
recon_1      | 2022-02-05 13:07:32,372 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1      | 2022-02-05 13:07:32,437 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1      | 2022-02-05 13:07:32,524 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1      | 2022-02-05 13:07:32,604 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
recon_1      | 2022-02-05 13:07:32,788 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
recon_1      | 2022-02-05 13:07:32,793 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
recon_1      | 2022-02-05 13:07:32,947 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1      | 2022-02-05 13:07:32,974 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1      | 2022-02-05 13:07:32,974 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1      | 2022-02-05 13:07:33,362 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1      | 2022-02-05 13:07:33,363 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-LTS
recon_1      | 2022-02-05 13:07:33,398 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1      | 2022-02-05 13:07:33,402 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1      | 2022-02-05 13:07:33,403 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 660000ms
recon_1      | 2022-02-05 13:07:33,418 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-02-05 13:07:33,432 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7977f046{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1      | 2022-02-05 13:07:33,432 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1859e55c{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1      | 2022-02-05 13:07:34,147 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-02-05 13:07:34,156 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-02-05 13:07:36,086 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@29e10870{recon,/,file:///tmp/jetty-0_0_0_0-9888-ozone-recon-1_3_0-SNAPSHOT_jar-_-any-4350442600404562328/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/recon}
recon_1      | 2022-02-05 13:07:36,110 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@5ea9373e{HTTP/1.1, (http/1.1)}{0.0.0.0:9888}
recon_1      | 2022-02-05 13:07:36,110 [Listener at 0.0.0.0/9891] INFO server.Server: Started @24850ms
recon_1      | 2022-02-05 13:07:36,112 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1      | 2022-02-05 13:07:36,112 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1      | 2022-02-05 13:07:36,115 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1      | 2022-02-05 13:07:36,115 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1      | 2022-02-05 13:07:36,142 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
recon_1      | 2022-02-05 13:07:36,149 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
recon_1      | 2022-02-05 13:07:36,150 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
recon_1      | 2022-02-05 13:07:36,150 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-02-05 13:07:36,150 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1      | 2022-02-05 13:07:36,157 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1      | 2022-02-05 13:07:38,275 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9860 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:07:40,277 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9860 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1        | 2022-02-05 13:11:32,781 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:91536-target for user:root
om1_1        | 2022-02-05 13:11:36,431 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33810
om1_1        | 2022-02-05 13:11:36,451 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:11:40,518 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33832
om1_1        | 2022-02-05 13:11:40,561 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:11:50,180 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33850
om1_1        | 2022-02-05 13:11:50,203 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:11:55,116 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33862
om1_1        | 2022-02-05 13:11:55,151 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:11:57,538 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$407/0x00000008405cfc40@61b3de5b] WARN util.JvmPauseMonitor: JvmPauseMonitor-om1: Detected pause in JVM or host machine (eg GC): pause of approximately 120027690ns. No GCs detected.
om1_1        | 2022-02-05 13:11:59,896 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33898
om1_1        | 2022-02-05 13:11:59,916 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:12:04,292 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33910
om1_1        | 2022-02-05 13:12:04,331 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:12:06,604 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:38763
om1_1        | 2022-02-05 13:12:06,621 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:12:08,840 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33916
om1_1        | 2022-02-05 13:12:08,868 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:12:13,127 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33928
om1_1        | 2022-02-05 13:12:13,165 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:12:16,916 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33940
om1_1        | 2022-02-05 13:12:16,939 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:12:21,141 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33952
s3g_1        | Sleeping for 5 seconds
s3g_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
s3g_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1        | 2022-02-05 13:07:16,720 [main] INFO security.UserGroupInformation: Login successful for user s3g/s3g@EXAMPLE.COM using keytab file s3g.keytab. Keytab auto renewal enabled : false
s3g_1        | 2022-02-05 13:07:16,726 [main] INFO s3.Gateway: S3Gateway login successful.
s3g_1        | 2022-02-05 13:07:17,004 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1        | 2022-02-05 13:07:17,005 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
s3g_1        | 2022-02-05 13:07:17,007 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.s3g.http.auth.type = kerberos
s3g_1        | 2022-02-05 13:07:17,164 [main] INFO util.log: Logging initialized @5650ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1        | 2022-02-05 13:07:17,672 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1        | 2022-02-05 13:07:17,706 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1        | 2022-02-05 13:07:17,715 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context s3gateway
s3g_1        | 2022-02-05 13:07:17,716 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1        | 2022-02-05 13:07:17,718 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
s3g_1        | 2022-02-05 13:07:17,738 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.s3g.http.auth.kerberos.principal keytabKey: ozone.s3g.http.auth.kerberos.keytab
s3g_1        | 2022-02-05 13:07:18,338 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1        | /************************************************************
s3g_1        | STARTUP_MSG: Starting Gateway
s3g_1        | STARTUP_MSG:   host = s3g/172.25.0.114
s3g_1        | STARTUP_MSG:   args = []
s3g_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-02-05 13:18:18,282 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-1400913700/ozone-test-9831389542/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om2_1        | partName: "etag1"
om2_1        | , partNumber: 2
om2_1        | partName: "etag2"
om2_1        | ]
om2_1        | 2022-02-05 13:18:18,286 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-9831389542/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-1400913700
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-1400913700 key: ozone-test-9831389542/multipartKey3
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:176)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-02-05 13:18:18,809 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-1400913700/ozone-test-9831389542/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om2_1        | partName: "etag1"
om2_1        | , partNumber: 1
om2_1        | partName: "etag2"
om2_1        | ]
om2_1        | 2022-02-05 13:18:18,822 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-9831389542/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-1400913700
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-1400913700 key: ozone-test-9831389542/multipartKey3
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:176)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-02-05 13:18:25,212 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-9831389542/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-1400913700
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-1400913700 key: ozone-test-9831389542/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-1400913700/ozone-test-9831389542/multipartKey3-4aa6b580-8307-4ca0-89fa-b8b99779129d-107745581312966689-1
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:455)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-02-05 13:18:25,727 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-9831389542/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-1400913700
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-1400913700 key: ozone-test-9831389542/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-1400913700/ozone-test-9831389542/multipartKey3-4aa6b580-8307-4ca0-89fa-b8b99779129d-107745581312966689-2
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:455)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | 2022-02-05 13:07:42,279 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm1.org:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9860 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:07:44,281 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9860 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:07:46,283 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9860 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:07:48,996 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:70490618-601a-4309-ad32-4488318b9859 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
recon_1      | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:245)
recon_1      | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:169)
recon_1      | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:60718)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9860 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:07:50,998 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9860 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:07:53,000 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9860 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:07:55,193 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 0 pipelines from SCM.
recon_1      | 2022-02-05 13:07:55,194 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1      | 2022-02-05 13:07:55,194 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1      | 2022-02-05 13:07:55,196 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1      | 2022-02-05 13:07:55,199 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1      | 2022-02-05 13:07:55,286 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered ContainerHealthTask task 
recon_1      | 2022-02-05 13:07:55,286 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting ContainerHealthTask Thread.
recon_1      | 2022-02-05 13:07:55,290 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
recon_1      | 2022-02-05 13:07:55,290 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1      | 2022-02-05 13:07:55,320 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1      | 2022-02-05 13:07:55,324 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 23 milliseconds.
recon_1      | 2022-02-05 13:07:56,157 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-02-05 13:07:56,158 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-02-05 13:07:56,224 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:07:56,225 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:07:58,227 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 3 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:07:58,228 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 4 failover attempts. Trying to failover immediately.
om2_1        | 2022-02-05 13:18:26,242 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-1400913700/ozone-test-9831389542/multipartKey3
om2_1        | 2022-02-05 13:18:26,252 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-9831389542/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-1400913700
om2_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-1400913700 key: ozone-test-9831389542/multipartKey3 because parts are in Invalid order.
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:421)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:183)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-02-05 13:18:29,183 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-5306351759/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-1400913700
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-1400913700key: ozone-test-5306351759/multipartKey5
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:156)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-02-05 13:18:29,731 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-1400913700, Key:ozone-test-4933169466/multipartKey. 
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:743)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:632)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:609)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:273)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-02-05 13:22:16,705 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCommitPartRequest: MultipartUpload Commit is failed for Key:ozone-test-5048365730/copyrange/destination in Volume/Bucket s3v/bucket-ozone-test-1400913700
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId 8d8cef6b-bfdd-433d-9bd6-48f754cd8048-107745584413147190
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCommitPartRequest.validateAndUpdateCache(S3MultipartUploadCommitPartRequest.java:185)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-02-05 13:23:16,702 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCommitPartRequest: MultipartUpload Commit is failed for Key:ozone-test-5048365730/copyrange/destination in Volume/Bucket s3v/bucket-ozone-test-1400913700
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId 8d8cef6b-bfdd-433d-9bd6-48f754cd8048-107745584413147190
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCommitPartRequest.validateAndUpdateCache(S3MultipartUploadCommitPartRequest.java:185)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-02-05 13:32:12,697 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-6636892664, Key:ozone-test-9758447856/multidelete/key=value/f4.
om2_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:148)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:94)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-02-05 13:09:44,671 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om3_1        | 2022-02-05 13:09:44,731 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om3_1        | 2022-02-05 13:09:45,809 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om3_1        | 2022-02-05 13:09:45,927 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2022-02-05 13:09:46,140 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om3:9872, om1:9872, om2:9872
om3_1        | 2022-02-05 13:09:46,205 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om3_1        | 2022-02-05 13:09:47,530 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om3_1        | 2022-02-05 13:09:48,023 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om3_1        | 2022-02-05 13:09:48,027 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-02-05 13:09:48,028 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om3_1        | 2022-02-05 13:09:48,028 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-02-05 13:09:48,030 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-02-05 13:09:48,032 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om3_1        | 2022-02-05 13:09:48,033 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2022-02-05 13:09:48,036 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om3_1        | 2022-02-05 13:09:48,041 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1        | 2022-02-05 13:09:50,065 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om3_1        | 2022-02-05 13:09:50,075 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2022-02-05 13:09:50,077 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2022-02-05 13:09:50,125 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2022-02-05 13:09:50,173 [main] INFO server.RaftServer: om3: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@1bb90d4d[Not completed]
om3_1        | 2022-02-05 13:09:50,174 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om3_1        | 2022-02-05 13:09:50,303 [pool-24-thread-1] INFO server.RaftServer$Division: om3: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om3_1        | 2022-02-05 13:09:50,330 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om3_1        | 2022-02-05 13:09:50,335 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om3_1        | 2022-02-05 13:09:50,335 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om3_1        | 2022-02-05 13:09:50,336 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2022-02-05 13:09:50,338 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2022-02-05 13:09:50,338 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om3_1        | 2022-02-05 13:09:50,342 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1        | 2022-02-05 13:09:50,389 [pool-24-thread-1] INFO server.RaftServer$Division: om3@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om3_1        | 2022-02-05 13:09:50,401 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2022-02-05 13:09:50,409 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om3_1        | 2022-02-05 13:09:50,426 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om3_1        | 2022-02-05 13:09:50,438 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om3_1        | 2022-02-05 13:09:50,428 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1        | 2022-02-05 13:09:50,494 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om3_1        | 2022-02-05 13:09:50,508 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 6@om3
om3_1        | 2022-02-05 13:09:50,631 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om3_1        | 2022-02-05 13:09:50,653 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om3_1        | 2022-02-05 13:09:50,702 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om3_1        | 2022-02-05 13:09:50,733 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om3_1        | 2022-02-05 13:09:50,735 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2022-02-05 13:09:51,125 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2022-02-05 13:09:51,212 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om3_1        | 2022-02-05 13:09:51,216 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om3_1        | 2022-02-05 13:09:51,278 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new om3@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om3_1        | 2022-02-05 13:09:51,282 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om3_1        | 2022-02-05 13:09:51,283 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om3_1        | 2022-02-05 13:09:51,285 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2022-02-05 13:09:51,290 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om3_1        | 2022-02-05 13:09:51,290 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om3_1        | 2022-02-05 13:09:51,313 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om3_1        | 2022-02-05 13:09:51,314 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om1_1        | 2022-02-05 13:12:21,159 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:12:25,124 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33956
om1_1        | 2022-02-05 13:12:25,149 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:12:29,429 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33984
om1_1        | 2022-02-05 13:12:29,470 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:12:33,680 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34004
om1_1        | 2022-02-05 13:12:33,704 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:12:37,865 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34020
om1_1        | 2022-02-05 13:12:37,890 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:12:42,170 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34032
om1_1        | 2022-02-05 13:12:42,213 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:12:46,230 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34046
om1_1        | 2022-02-05 13:12:46,250 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:12:53,406 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34086
om1_1        | 2022-02-05 13:12:53,425 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:13:00,098 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34102
om1_1        | 2022-02-05 13:13:00,128 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:13:06,667 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:40557
om1_1        | 2022-02-05 13:13:06,674 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:13:06,927 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34120
om1_1        | 2022-02-05 13:13:06,958 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:13:13,310 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34136
om1_1        | 2022-02-05 13:13:13,338 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:13:17,842 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34148
om1_1        | 2022-02-05 13:13:17,878 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:13:22,889 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34184
om1_1        | 2022-02-05 13:13:22,910 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:13:26,813 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34188
om1_1        | 2022-02-05 13:13:26,839 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:13:31,452 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34200
s3g_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.12.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.33.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar
s3g_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/f757d9929c7016e9989d08ab2698179d61ef158b ; compiled by 'runner' on 2022-02-05T12:45Z
s3g_1        | STARTUP_MSG:   java = 11.0.13
s3g_1        | ************************************************************/
s3g_1        | 2022-02-05 13:07:18,433 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1        | 2022-02-05 13:07:18,713 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1        | 2022-02-05 13:07:18,799 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1        | 2022-02-05 13:07:18,842 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-LTS
s3g_1        | 2022-02-05 13:07:19,084 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1        | 2022-02-05 13:07:19,084 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1        | 2022-02-05 13:07:19,099 [main] INFO server.session: node0 Scavenging every 660000ms
s3g_1        | 2022-02-05 13:07:19,237 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | 2022-02-05 13:07:19,280 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@267f474e{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1        | 2022-02-05 13:07:19,291 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@68d6972f{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1        | WARNING: An illegal reflective access operation has occurred
s3g_1        | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1        | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1        | WARNING: All illegal access operations will be denied in a future release
s3g_1        | 2022-02-05 13:07:25,615 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | Feb 05, 2022 1:07:28 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1        | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1        | 
s3g_1        | 2022-02-05 13:07:28,455 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4597e6e3{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-ozone-s3gateway-1_3_0-SNAPSHOT_jar-_-any-18122276189075676115/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1        | 2022-02-05 13:07:28,500 [main] INFO server.AbstractConnector: Started ServerConnector@27a5328c{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1        | 2022-02-05 13:07:28,500 [main] INFO server.Server: Started @16987ms
s3g_1        | 2022-02-05 13:07:28,510 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
s3g_1        | 2022-02-05 13:16:41,068 [qtp1431556341-21] INFO ozone.OmUtils: Using OzoneManager ServiceID 'id1'.
s3g_1        | 2022-02-05 13:16:42,226 [qtp1431556341-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-7140543203, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-02-05 13:16:42,255 [qtp1431556341-21] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-7140543203
s3g_1        | 2022-02-05 13:16:48,183 [qtp1431556341-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-9912553244, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-02-05 13:16:48,202 [qtp1431556341-17] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-9912553244
s3g_1        | 2022-02-05 13:16:49,656 [qtp1431556341-20] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1      | 2022-02-05 13:07:58,229 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:08:00,231 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 6 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:00,233 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 7 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:00,236 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:08:02,239 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 9 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:02,241 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 10 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:02,242 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:08:04,243 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 12 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:04,244 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 13 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:04,245 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 14 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:08:06,247 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 15 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:06,248 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 16 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:06,249 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 17 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:08:08,250 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 18 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:08,251 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 19 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:08,252 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 20 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:08:10,254 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 21 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:10,259 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 22 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:10,259 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 23 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:08:12,261 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 24 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:12,262 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 25 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:12,263 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 26 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:08:14,264 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 27 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:14,267 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 28 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:14,269 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 29 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:08:16,271 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 30 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:16,273 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 31 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:16,276 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 32 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:08:18,280 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 33 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:18,281 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 34 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:18,282 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 35 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:08:20,285 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 36 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:20,286 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 37 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:20,294 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 38 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:08:22,296 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 39 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:22,297 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 40 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:22,297 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 41 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:08:24,299 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 42 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:24,301 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 43 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:24,301 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 44 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:08:26,303 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 45 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:26,304 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 46 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:26,305 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 47 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:08:28,306 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 48 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:28,307 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 49 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:28,308 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 50 failover attempts. Trying to failover after sleeping for 2000ms.
scm1.org_1   | Sleeping for 5 seconds
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2022-02-05 13:07:20,649 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = [--init]
scm1.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
recon_1      | 2022-02-05 13:08:30,310 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 51 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:30,311 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 52 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:30,315 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 53 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:08:32,317 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 54 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:32,318 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 55 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:32,319 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 56 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:08:34,321 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 57 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:34,321 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 58 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:34,323 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 59 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:08:36,325 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 60 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:36,326 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 61 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:36,327 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 62 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:08:38,328 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 63 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:38,329 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 64 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:38,330 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 65 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:08:40,332 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 66 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:40,333 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 67 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:40,334 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 68 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:08:42,335 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 69 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:42,336 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 70 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:42,338 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 71 failover attempts. Trying to failover after sleeping for 2000ms.
s3g_1        | 2022-02-05 13:16:49,672 [qtp1431556341-20] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1        | 2022-02-05 13:16:49,672 [qtp1431556341-20] INFO impl.MetricsSystemImpl: XceiverClientMetrics metrics system started
s3g_1        | 2022-02-05 13:16:49,678 [qtp1431556341-20] INFO impl.MetricsSinkAdapter: Sink prometheus started
s3g_1        | 2022-02-05 13:16:49,678 [qtp1431556341-20] INFO impl.MetricsSystemImpl: Registered sink prometheus
s3g_1        | 2022-02-05 13:16:50,031 [qtp1431556341-20] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
s3g_1        | 2022-02-05 13:17:00,670 [qtp1431556341-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-9697366694, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-02-05 13:17:00,703 [qtp1431556341-20] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-9697366694
s3g_1        | 2022-02-05 13:17:01,316 [qtp1431556341-24] INFO rpc.RpcClient: Creating Bucket: s3v/ozone-test-xjbfafhbre, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-02-05 13:17:01,336 [qtp1431556341-24] INFO endpoint.BucketEndpoint: Location is /ozone-test-xjbfafhbre
s3g_1        | 2022-02-05 13:17:16,822 [qtp1431556341-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-lonjmimkhy, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-02-05 13:17:16,840 [qtp1431556341-21] INFO endpoint.BucketEndpoint: Location is /bucket-lonjmimkhy
s3g_1        | 2022-02-05 13:17:30,040 [qtp1431556341-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-9122060856, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-02-05 13:17:30,053 [qtp1431556341-17] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-9122060856
s3g_1        | 2022-02-05 13:17:30,549 [qtp1431556341-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-1762219765, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-02-05 13:17:30,565 [qtp1431556341-21] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-1762219765
s3g_1        | 2022-02-05 13:17:31,079 [qtp1431556341-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-8586837866, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-02-05 13:17:31,102 [qtp1431556341-17] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-8586837866
s3g_1        | 2022-02-05 13:17:31,594 [qtp1431556341-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-8586837866, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-02-05 13:17:31,610 [qtp1431556341-21] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-8586837866
s3g_1        | 2022-02-05 13:17:32,148 [qtp1431556341-17] ERROR endpoint.BucketEndpoint: Error in Create Bucket Request for bucket: invalid_bucket_ozone-test-5231176958
s3g_1        | INVALID_BUCKET_NAME org.apache.hadoop.ozone.om.exceptions.OMException: Bucket or Volume name has an unsupported character : _
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.verifyBucketName(RpcClient.java:582)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.createBucket(RpcClient.java:521)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.createBucket(RpcClient.java:512)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneVolume.createBucket(OzoneVolume.java:385)
s3g_1        | 	at org.apache.hadoop.ozone.client.ObjectStore.createS3Bucket(ObjectStore.java:118)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.createS3Bucket(EndpointBase.java:117)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:239)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
om1_1        | 2022-02-05 13:13:31,467 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:13:36,382 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34212
om1_1        | 2022-02-05 13:13:36,395 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:13:40,680 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34234
om1_1        | 2022-02-05 13:13:40,696 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:13:44,851 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34240
om1_1        | 2022-02-05 13:13:44,876 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
om3_1        | 2022-02-05 13:09:51,314 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om3_1        | 2022-02-05 13:09:51,424 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om3_1        | 2022-02-05 13:09:51,435 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om3_1        | 2022-02-05 13:09:51,509 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om3_1        | 2022-02-05 13:09:51,524 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om3_1        | 2022-02-05 13:09:51,573 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om3_1        | 2022-02-05 13:09:51,574 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om3_1        | 2022-02-05 13:09:51,588 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om3_1        | 2022-02-05 13:09:51,596 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om3_1        | 2022-02-05 13:09:51,615 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om3_1        | 2022-02-05 13:09:51,616 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om3_1        | 2022-02-05 13:09:51,846 [Listener at om3/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om3_1        | 2022-02-05 13:09:51,986 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om3_1        | 2022-02-05 13:09:51,990 [Listener at om3/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om3_1        | 2022-02-05 13:09:52,315 [Listener at om3/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om3/172.25.0.113:9862
om3_1        | 2022-02-05 13:09:52,317 [Listener at om3/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om3 at port 9872
om3_1        | 2022-02-05 13:09:52,326 [Listener at om3/9862] INFO server.RaftServer$Division: om3@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-02-05 13:09:52,339 [Listener at om3/9862] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om3_1        | 2022-02-05 13:09:52,340 [Listener at om3/9862] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2022-02-05 13:09:52,349 [Listener at om3/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om3
om3_1        | 2022-02-05 13:09:52,373 [Listener at om3/9862] INFO server.RaftServer: om3: start RPC server
om3_1        | 2022-02-05 13:09:52,608 [Listener at om3/9862] INFO server.GrpcService: om3: GrpcService started, listening on 9872
om3_1        | 2022-02-05 13:09:52,613 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$407/0x00000008405cfc40@12c1826] INFO util.JvmPauseMonitor: JvmPauseMonitor-om3: Started
om3_1        | 2022-02-05 13:09:52,617 [Listener at om3/9862] INFO om.OzoneManager: Starting OM block token secret manager
om3_1        | 2022-02-05 13:09:52,618 [Listener at om3/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2022-02-05 13:09:52,637 [Listener at om3/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om3_1        | 2022-02-05 13:09:52,647 [Listener at om3/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2022-02-05 13:09:52,664 [Listener at om3/9862] INFO om.OzoneManager: Version File has different layout version (0) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om3_1        | 2022-02-05 13:09:52,665 [Thread[Thread-17,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om3_1        | 2022-02-05 13:09:52,811 [Listener at om3/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om3_1        | 2022-02-05 13:09:52,812 [Listener at om3/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om3_1        | 2022-02-05 13:09:52,812 [Listener at om3/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om3_1        | 2022-02-05 13:09:53,066 [Listener at om3/9862] INFO util.log: Logging initialized @40503ms to org.eclipse.jetty.util.log.Slf4jLog
om3_1        | 2022-02-05 13:09:53,721 [Listener at om3/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om3_1        | 2022-02-05 13:09:53,748 [Listener at om3/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om3_1        | 2022-02-05 13:09:53,760 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om3_1        | 2022-02-05 13:09:53,765 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om3_1        | 2022-02-05 13:09:53,765 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om3_1        | 2022-02-05 13:09:53,778 [Listener at om3/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om3_1        | 2022-02-05 13:09:54,011 [Listener at om3/9862] INFO http.HttpServer2: Jetty bound to port 9874
om3_1        | 2022-02-05 13:09:54,027 [Listener at om3/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-LTS
om3_1        | 2022-02-05 13:09:54,169 [Listener at om3/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om3_1        | 2022-02-05 13:09:54,170 [Listener at om3/9862] INFO server.session: No SessionScavenger set, using defaults
om3_1        | 2022-02-05 13:09:54,172 [Listener at om3/9862] INFO server.session: node0 Scavenging every 600000ms
om3_1        | 2022-02-05 13:09:54,401 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2022-02-05 13:09:54,434 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3e37c38f{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om3_1        | 2022-02-05 13:09:54,438 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@45c57dbd{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om3_1        | 2022-02-05 13:09:54,893 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2022-02-05 13:09:54,922 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@fa3db48{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-11311899455426479320/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/f757d9929c7016e9989d08ab2698179d61ef158b ; compiled by 'runner' on 2022-02-05T12:45Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.13
scm1.org_1   | ************************************************************/
scm1.org_1   | 2022-02-05 13:07:20,754 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2022-02-05 13:07:21,286 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-02-05 13:07:21,546 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2022-02-05 13:07:21,546 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2022-02-05 13:07:22,079 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm1.org_1   | 2022-02-05 13:07:22,091 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2022-02-05 13:07:22,161 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm1.org_1   | 2022-02-05 13:07:25,316 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm1.org_1   | 2022-02-05 13:07:25,319 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm1.org_1   | 2022-02-05 13:07:25,338 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm1.org_1   | 2022-02-05 13:07:29,860 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm1.org_1   | 2022-02-05 13:07:31,877 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2022-02-05 13:07:31,878 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2022-02-05 13:07:32,288 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2022-02-05 13:07:32,288 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2022-02-05 13:07:32,289 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm1.org,scmId:70490618-601a-4309-ad32-4488318b9859,clusterId:CID-fc180783-fb1e-4dd7-af87-eddf767648b7,subject:scm-sub@scm1.org
scm1.org_1   | 2022-02-05 13:07:32,542 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm1.org_1   | 2022-02-05 13:07:33,015 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2022-02-05 13:07:33,312 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2022-02-05 13:07:33,313 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-02-05 13:07:33,313 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm1.org_1   | 2022-02-05 13:07:33,314 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-02-05 13:07:33,314 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-02-05 13:07:33,322 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2022-02-05 13:07:33,324 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-02-05 13:07:33,324 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2022-02-05 13:07:33,325 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-02-05 13:07:34,016 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2022-02-05 13:07:34,032 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-02-05 13:07:34,032 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-02-05 13:07:34,094 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-02-05 13:07:34,146 [main] INFO server.RaftServer: 70490618-601a-4309-ad32-4488318b9859: addNew group-EDDF767648B7:[70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|priority:0] returns group-EDDF767648B7:java.util.concurrent.CompletableFuture@3ad85136[Not completed]
scm1.org_1   | 2022-02-05 13:07:34,242 [pool-2-thread-1] INFO server.RaftServer$Division: 70490618-601a-4309-ad32-4488318b9859: new RaftServerImpl for group-EDDF767648B7:[70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|priority:0] with SCMStateMachine:uninitialized
scm1.org_1   | 2022-02-05 13:07:34,244 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2022-02-05 13:07:34,254 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2022-02-05 13:07:34,254 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2022-02-05 13:07:34,254 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-02-05 13:07:34,255 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-02-05 13:07:34,256 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2022-02-05 13:07:34,256 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-02-05 13:07:34,286 [pool-2-thread-1] INFO server.RaftServer$Division: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7: ConfigurationManager, init=-1: [70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|priority:0], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2022-02-05 13:07:34,290 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-02-05 13:07:34,302 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2022-02-05 13:07:34,322 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm1.org_1   | 2022-02-05 13:07:34,324 [pool-2-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/fc180783-fb1e-4dd7-af87-eddf767648b7 does not exist. Creating ...
scm1.org_1   | 2022-02-05 13:07:34,381 [pool-2-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/fc180783-fb1e-4dd7-af87-eddf767648b7/in_use.lock acquired by nodename 89@scm1.org
scm1.org_1   | 2022-02-05 13:07:34,406 [pool-2-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/fc180783-fb1e-4dd7-af87-eddf767648b7 has been successfully formatted.
scm1.org_1   | 2022-02-05 13:07:34,417 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2022-02-05 13:07:34,419 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2022-02-05 13:07:34,439 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2022-02-05 13:07:34,440 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-02-05 13:07:34,480 [pool-2-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2022-02-05 13:07:34,785 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-02-05 13:07:34,825 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2022-02-05 13:07:34,834 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2022-02-05 13:07:34,848 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: new 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/fc180783-fb1e-4dd7-af87-eddf767648b7
scm1.org_1   | 2022-02-05 13:07:34,849 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-02-05 13:07:34,849 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2022-02-05 13:07:34,850 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-02-05 13:07:34,852 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm1.org_1   | 2022-02-05 13:07:34,862 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2022-02-05 13:07:34,873 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2022-02-05 13:07:34,873 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2022-02-05 13:07:34,875 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2022-02-05 13:07:34,895 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2022-02-05 13:07:34,896 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2022-02-05 13:07:34,911 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-02-05 13:07:34,911 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-02-05 13:07:34,937 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2022-02-05 13:07:34,939 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2022-02-05 13:07:34,940 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2022-02-05 13:07:34,940 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2022-02-05 13:07:34,941 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2022-02-05 13:07:34,950 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2022-02-05 13:07:35,073 [main] INFO server.RaftServer$Division: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7: start as a follower, conf=-1: [70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|priority:0], old=null
scm1.org_1   | 2022-02-05 13:07:35,080 [main] INFO server.RaftServer$Division: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm1.org_1   | 2022-02-05 13:07:35,082 [main] INFO impl.RoleInfo: 70490618-601a-4309-ad32-4488318b9859: start 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-FollowerState
scm1.org_1   | 2022-02-05 13:07:35,086 [main] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-EDDF767648B7,id=70490618-601a-4309-ad32-4488318b9859
scm1.org_1   | 2022-02-05 13:07:35,098 [main] INFO server.RaftServer: 70490618-601a-4309-ad32-4488318b9859: start RPC server
scm1.org_1   | 2022-02-05 13:07:35,200 [main] INFO server.GrpcService: 70490618-601a-4309-ad32-4488318b9859: GrpcService started, listening on 9894
scm1.org_1   | 2022-02-05 13:07:35,214 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$338/0x000000084031f040@642413d4] INFO util.JvmPauseMonitor: JvmPauseMonitor-70490618-601a-4309-ad32-4488318b9859: Started
scm1.org_1   | 2022-02-05 13:07:40,240 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-FollowerState] INFO impl.FollowerState: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5158751097ns, electionTimeout:5156ms
scm1.org_1   | 2022-02-05 13:07:40,241 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-FollowerState] INFO impl.RoleInfo: 70490618-601a-4309-ad32-4488318b9859: shutdown 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-FollowerState
scm1.org_1   | 2022-02-05 13:07:40,241 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-FollowerState] INFO server.RaftServer$Division: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
scm1.org_1   | 2022-02-05 13:07:40,244 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm1.org_1   | 2022-02-05 13:07:40,244 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-FollowerState] INFO impl.RoleInfo: 70490618-601a-4309-ad32-4488318b9859: start 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1
scm1.org_1   | 2022-02-05 13:07:40,254 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO impl.LeaderElection: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|priority:0], old=null
scm1.org_1   | 2022-02-05 13:07:40,254 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO impl.LeaderElection: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1 ELECTION round 0: result PASSED (term=1)
scm1.org_1   | 2022-02-05 13:07:40,255 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO impl.RoleInfo: 70490618-601a-4309-ad32-4488318b9859: shutdown 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1
scm1.org_1   | 2022-02-05 13:07:40,255 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO server.RaftServer$Division: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
scm1.org_1   | 2022-02-05 13:07:40,255 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO server.RaftServer$Division: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7: change Leader from null to 70490618-601a-4309-ad32-4488318b9859 at term 1 for becomeLeader, leader elected after 5839ms
om1_1        | 2022-02-05 13:13:49,287 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34254
om1_1        | 2022-02-05 13:13:49,337 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:13:53,560 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34292
om1_1        | 2022-02-05 13:13:53,582 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:13:57,704 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34304
om1_1        | 2022-02-05 13:13:57,736 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:14:02,009 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34308
om1_1        | 2022-02-05 13:14:02,028 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:14:06,723 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35445
om1_1        | 2022-02-05 13:14:06,738 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:14:06,809 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34320
om1_1        | 2022-02-05 13:14:06,832 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:14:10,929 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34334
om1_1        | 2022-02-05 13:14:10,966 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:14:11,401 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:91536-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:187)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-02-05 13:14:15,042 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34338
om1_1        | 2022-02-05 13:14:15,057 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:14:19,503 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34374
om1_1        | 2022-02-05 13:14:19,531 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:14:20,070 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:91536-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:187)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-02-05 13:14:23,781 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34386
om1_1        | 2022-02-05 13:14:23,798 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:14:28,202 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34398
om1_1        | 2022-02-05 13:14:28,229 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:14:28,664 [IPC Server handler 8 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access bucket Volume:91536-target Bucket:unreadable-link 
om1_1        | 2022-02-05 13:14:32,487 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34402
om1_1        | 2022-02-05 13:14:32,502 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:14:36,660 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34414
om1_1        | 2022-02-05 13:14:36,678 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:14:37,206 [IPC Server handler 16 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have LIST permission to access bucket Volume:91536-source Bucket:unreadable-bucket Key:
om1_1        | 2022-02-05 13:14:40,759 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34436
om1_1        | 2022-02-05 13:14:40,779 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:14:44,878 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34440
om1_1        | 2022-02-05 13:14:44,907 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:14:49,365 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34454
om1_1        | 2022-02-05 13:14:49,391 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:14:53,470 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34490
om1_1        | 2022-02-05 13:14:53,507 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:14:57,544 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34494
om1_1        | 2022-02-05 13:14:57,579 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:15:01,714 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34506
om1_1        | 2022-02-05 13:15:01,743 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:15:06,763 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:41705
om1_1        | 2022-02-05 13:15:06,774 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:15:10,862 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34532
om1_1        | 2022-02-05 13:15:10,882 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:15:17,355 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34548
om1_1        | 2022-02-05 13:15:17,384 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:15:21,617 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34576
om1_1        | 2022-02-05 13:15:21,648 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:15:25,925 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34588
om1_1        | 2022-02-05 13:15:25,950 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:16:06,813 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:40811
om1_1        | 2022-02-05 13:16:06,825 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:16:37,737 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34892
om1_1        | 2022-02-05 13:16:37,771 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:16:41,697 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:40753
om1_1        | 2022-02-05 13:16:41,714 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:16:42,171 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:42,241 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:45,584 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34912
om1_1        | 2022-02-05 13:16:45,603 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:16:48,173 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:48,186 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:48,731 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:48,737 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:48,761 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:51,164 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:51,743 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:51,747 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:51,753 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:51,915 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:52,447 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:52,456 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:52,466 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:52,472 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:52,980 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:52,984 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:52,987 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:52,991 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:53,479 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:53,482 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:53,486 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:53,489 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:53,982 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:53,986 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:53,993 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:54,109 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:54,673 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:54,676 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:54,678 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:54,683 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:16:58,139 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34978
om1_1        | 2022-02-05 13:16:58,169 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:17:00,668 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:00,673 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
recon_1      | 2022-02-05 13:08:44,340 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 72 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:44,341 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 73 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:44,342 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 74 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:08:46,343 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 75 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:46,346 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 76 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:46,348 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 77 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:08:48,363 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 78 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:48,365 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 79 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:48,379 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 80 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:08:50,384 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 81 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:50,385 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 82 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:50,386 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 83 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:08:52,387 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 84 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:52,388 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 85 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:52,389 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 86 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:08:54,390 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 87 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:54,391 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 88 failover attempts. Trying to failover immediately.
om3_1        | 2022-02-05 13:09:54,947 [Listener at om3/9862] INFO server.AbstractConnector: Started ServerConnector@5c863996{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om3_1        | 2022-02-05 13:09:54,950 [Listener at om3/9862] INFO server.Server: Started @42387ms
om3_1        | 2022-02-05 13:09:54,958 [Listener at om3/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om3_1        | 2022-02-05 13:09:54,958 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om3_1        | 2022-02-05 13:09:54,962 [Listener at om3/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om3_1        | 2022-02-05 13:09:54,962 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om3_1        | 2022-02-05 13:09:54,982 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om3_1        | 2022-02-05 13:09:55,065 [Listener at om3/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om3_1        | 2022-02-05 13:09:55,142 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@ecd3a9b] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om3_1        | 2022-02-05 13:09:56,466 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:44285
om3_1        | 2022-02-05 13:09:56,471 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-02-05 13:09:57,482 [om3@group-562213E44849-FollowerState] INFO impl.FollowerState: om3@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5141781087ns, electionTimeout:5109ms
om3_1        | 2022-02-05 13:09:57,488 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1        | 2022-02-05 13:09:57,496 [om3@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om3_1        | 2022-02-05 13:09:57,511 [om3@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om3_1        | 2022-02-05 13:09:57,514 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: start om3@group-562213E44849-LeaderElection1
om3_1        | 2022-02-05 13:09:57,598 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-02-05 13:09:57,824 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 1, (t:0, i:~))
om3_1        | 2022-02-05 13:09:57,831 [grpc-default-executor-0] INFO impl.VoteContext: om3@group-562213E44849-CANDIDATE: reject ELECTION from om1: already has voted for om3 at current term 1
om3_1        | 2022-02-05 13:09:57,953 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om1<-om3#0:FAIL-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om3, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-02-05 13:09:58,454 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
om3_1        | 2022-02-05 13:09:58,454 [grpc-default-executor-0] INFO impl.VoteContext: om3@group-562213E44849-CANDIDATE: reject ELECTION from om2: already has voted for om3 at current term 1
om3_1        | 2022-02-05 13:09:58,454 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om2<-om3#0:FAIL-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om3, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-02-05 13:09:59,329 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om3_1        | 2022-02-05 13:09:59,334 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om3<-om1#0:FAIL-t1
om3_1        | 2022-02-05 13:09:59,334 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om3<-om2#0:FAIL-t1
om3_1        | 2022-02-05 13:09:59,335 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om3_1        | 2022-02-05 13:09:59,339 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om3_1        | 2022-02-05 13:09:59,340 [om3@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-LeaderElection1
om3_1        | 2022-02-05 13:09:59,343 [om3@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2022-02-05 13:10:03,249 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 2, (t:0, i:~))
om3_1        | 2022-02-05 13:10:03,250 [grpc-default-executor-1] INFO impl.VoteContext: om3@group-562213E44849-FOLLOWER: accept ELECTION from om1: our priority 0 <= candidate's priority 0
om3_1        | 2022-02-05 13:10:03,251 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:om1
om3_1        | 2022-02-05 13:10:03,251 [grpc-default-executor-1] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1        | 2022-02-05 13:10:03,252 [om3@group-562213E44849-FollowerState] INFO impl.FollowerState: om3@group-562213E44849-FollowerState was interrupted: {}
om3_1        | java.lang.InterruptedException: sleep interrupted
om3_1        | 	at java.base/java.lang.Thread.sleep(Native Method)
om3_1        | 	at java.base/java.lang.Thread.sleep(Thread.java:334)
om3_1        | 	at java.base/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
om3_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
om3_1        | 	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
om3_1        | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
om3_1        | 2022-02-05 13:10:03,259 [grpc-default-executor-1] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2022-02-05 13:10:03,285 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om1<-om3#0:OK-t2. Peer's state: om3@group-562213E44849:t2, leader=null, voted=om1, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-02-05 13:10:03,740 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: change Leader from null to om1 at term 2 for appendEntries, leader elected after 13105ms
om3_1        | 2022-02-05 13:10:03,882 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1        | 2022-02-05 13:10:03,911 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om3_1        | 2022-02-05 13:10:04,299 [om3@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om3_1        | 2022-02-05 13:10:07,036 [om3@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om3_1        | [id: "om1"
om3_1        | address: "om1:9872"
om3_1        | , id: "om3"
om3_1        | address: "om3:9872"
om3_1        | , id: "om2"
om3_1        | address: "om2:9872"
om3_1        | ]
om3_1        | 2022-02-05 13:10:24,353 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:root
om3_1        | 2022-02-05 13:11:28,151 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:91536-source for user:root
recon_1      | 2022-02-05 13:08:54,393 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 89 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:08:56,395 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 90 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:56,396 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 91 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:56,397 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 92 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:08:58,399 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 93 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:58,400 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 94 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:08:58,400 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 95 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:09:00,402 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 96 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:00,403 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 97 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:00,404 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 98 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:09:02,407 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 99 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:02,408 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 100 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:02,409 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 101 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:09:04,411 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 102 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:04,412 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 103 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:04,414 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 104 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1        | 2022-02-05 13:17:01,313 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:01,318 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:01,354 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:01,358 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:01,363 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:04,002 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:04,056 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:04,058 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:04,061 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:06,644 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:06,688 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:06,691 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:06,694 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:06,888 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:39897
om1_1        | 2022-02-05 13:17:06,891 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:17:09,294 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:09,337 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:09,341 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:09,348 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:09,524 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:09,527 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:09,550 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:09,599 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:09,712 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:09,722 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:09,730 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:09,778 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:10,975 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:12,696 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:12,772 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:12,776 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:12,791 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:12,864 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:12,870 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:12,874 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:12,969 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:12,983 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:12,991 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:13,011 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:13,107 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:13,116 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:13,127 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:13,170 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:13,561 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:16,731 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:16,765 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:16,785 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:16,788 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:16,821 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:16,824 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:16,852 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:16,857 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:16,862 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:16,882 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:16,890 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:16,912 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:16,916 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:16,958 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:16,961 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:16,965 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,097 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | 2022-02-05 13:17:38,608 [qtp1431556341-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-4308704714, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-02-05 13:17:38,622 [qtp1431556341-21] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-4308704714
s3g_1        | 2022-02-05 13:17:39,181 [qtp1431556341-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-6225558855, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-02-05 13:17:39,194 [qtp1431556341-17] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-6225558855
s3g_1        | 2022-02-05 13:17:46,266 [qtp1431556341-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-8907484251, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-02-05 13:17:46,280 [qtp1431556341-21] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-8907484251
s3g_1        | 2022-02-05 13:17:47,296 [qtp1431556341-17] ERROR endpoint.BucketEndpoint: Exception occurred in headBucket
s3g_1        | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:131)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getBucket(EndpointBase.java:91)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.head(BucketEndpoint.java:295)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm1.org_1   | 2022-02-05 13:07:40,270 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2022-02-05 13:07:40,277 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-02-05 13:07:40,278 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-02-05 13:07:40,285 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm1.org_1   | 2022-02-05 13:07:40,285 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm1.org_1   | 2022-02-05 13:07:40,286 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm1.org_1   | 2022-02-05 13:07:40,290 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-02-05 13:07:40,292 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm1.org_1   | 2022-02-05 13:07:40,302 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO impl.RoleInfo: 70490618-601a-4309-ad32-4488318b9859: start 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderStateImpl
scm1.org_1   | 2022-02-05 13:07:40,334 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-SegmentedRaftLogWorker: Starting segment from index:0
scm1.org_1   | 2022-02-05 13:07:40,392 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO server.RaftServer$Division: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7: set configuration 0: [70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-02-05 13:07:40,445 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/fc180783-fb1e-4dd7-af87-eddf767648b7/current/log_inprogress_0
scm1.org_1   | 2022-02-05 13:07:41,213 [main] INFO server.RaftServer: 70490618-601a-4309-ad32-4488318b9859: close
scm1.org_1   | 2022-02-05 13:07:41,214 [main] INFO server.RaftServer$Division: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7: shutdown
scm1.org_1   | 2022-02-05 13:07:41,215 [main] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-EDDF767648B7,id=70490618-601a-4309-ad32-4488318b9859
scm1.org_1   | 2022-02-05 13:07:41,215 [main] INFO impl.RoleInfo: 70490618-601a-4309-ad32-4488318b9859: shutdown 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderStateImpl
scm1.org_1   | 2022-02-05 13:07:41,227 [main] INFO impl.PendingRequests: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-PendingRequests: sendNotLeaderResponses
scm1.org_1   | 2022-02-05 13:07:41,230 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO impl.StateMachineUpdater: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater: Took a snapshot at index 0
scm1.org_1   | 2022-02-05 13:07:41,230 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO impl.StateMachineUpdater: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
scm1.org_1   | 2022-02-05 13:07:41,231 [main] INFO impl.StateMachineUpdater: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater: set stopIndex = 0
scm1.org_1   | 2022-02-05 13:07:41,235 [main] INFO server.RaftServer$Division: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7: closes. applyIndex: 0
scm1.org_1   | 2022-02-05 13:07:41,238 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
scm1.org_1   | 2022-02-05 13:07:41,239 [main] INFO segmented.SegmentedRaftLogWorker: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-SegmentedRaftLogWorker close()
scm1.org_1   | 2022-02-05 13:07:41,241 [main] INFO server.GrpcService: 70490618-601a-4309-ad32-4488318b9859: shutdown server with port 9894 now
scm1.org_1   | 2022-02-05 13:07:41,245 [main] INFO server.GrpcService: 70490618-601a-4309-ad32-4488318b9859: shutdown server with port 9894 successfully
scm1.org_1   | 2022-02-05 13:07:41,246 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$338/0x000000084031f040@642413d4] INFO util.JvmPauseMonitor: JvmPauseMonitor-70490618-601a-4309-ad32-4488318b9859: Stopped
scm1.org_1   | 2022-02-05 13:07:41,246 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-02-05 13:07:41,248 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-fc180783-fb1e-4dd7-af87-eddf767648b7; layoutVersion=2; scmId=70490618-601a-4309-ad32-4488318b9859
scm1.org_1   | 2022-02-05 13:07:41,250 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm1.org/172.25.0.116
scm1.org_1   | ************************************************************/
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2022-02-05 13:07:42,822 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = []
scm1.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm2.org_1   | Sleeping for 5 seconds
scm2.org_1   | Waiting for the service scm1.org:9894
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 2022-02-05 13:07:37,385 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm2.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm2.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/f757d9929c7016e9989d08ab2698179d61ef158b ; compiled by 'runner' on 2022-02-05T12:45Z
scm2.org_1   | STARTUP_MSG:   java = 11.0.13
scm2.org_1   | ************************************************************/
scm2.org_1   | 2022-02-05 13:07:37,393 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2022-02-05 13:07:37,467 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2022-02-05 13:07:37,467 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2022-02-05 13:07:37,507 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2022-02-05 13:07:37,507 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm2.org_1   | 2022-02-05 13:07:37,513 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-02-05 13:07:37,749 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm2.org_1   | 2022-02-05 13:07:37,749 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2022-02-05 13:07:40,031 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm2.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-02-05 13:07:42,033 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-02-05 13:07:44,035 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-02-05 13:07:46,037 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm2.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-02-05 13:07:48,046 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-02-05 13:07:50,234 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:70490618-601a-4309-ad32-4488318b9859 is not the leader. Could not determine the leader node.
scm2.org_1   | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:245)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:108)
scm2.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13937)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm2.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm2.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm2.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm2.org_1   | , while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-02-05 13:07:52,236 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm2.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-02-05 13:07:54,238 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-02-05 13:07:56,600 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
recon_1      | 2022-02-05 13:09:06,423 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 105 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:06,423 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 106 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:06,424 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 107 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:09:08,428 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 108 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:08,451 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 109 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:08,492 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 110 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:09:10,493 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 111 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:10,494 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 112 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:10,496 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 113 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:09:12,499 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 114 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:12,501 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 115 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:12,502 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 116 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:09:14,504 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 117 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:14,505 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 118 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:14,506 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 119 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:09:16,507 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 120 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:16,508 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 121 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:16,509 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 122 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:09:18,510 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 123 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:18,511 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 124 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:18,512 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 125 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:09:20,513 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 126 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:20,514 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 127 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:20,515 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 128 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:09:22,516 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 129 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:22,517 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 130 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:22,518 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 131 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:09:24,520 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 132 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:24,521 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 133 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:24,522 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 134 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:09:25,512 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59280
recon_1      | 2022-02-05 13:09:25,542 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:09:26,531 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 135 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:26,538 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 136 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:26,554 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 137 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:09:27,223 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46906
om3_1        | 2022-02-05 13:11:32,785 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:91536-target for user:root
om3_1        | 2022-02-05 13:14:11,411 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:91536-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:187)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-02-05 13:14:20,078 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:91536-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:187)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-02-05 13:17:31,622 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-8586837866 in volume:s3v
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:187)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-02-05 13:17:40,207 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-1447320186 in volume:s3v
om3_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om3_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2334)
om3_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2304)
om3_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:197)
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:101)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-02-05 13:18:17,154 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-1400913700/ozone-test-1594238177/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om3_1        | 2022-02-05 13:18:17,164 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-1594238177/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-1400913700
om3_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-1400913700 key: ozone-test-1594238177/multipartKey2. Entity too small.
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:473)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | 2022-02-05 13:09:27,251 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:09:28,565 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 138 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:28,568 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 139 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:28,568 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 140 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:09:29,269 [IPC Server handler 12 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/3bd141d9-8d6a-4889-940a-437a7867e049
recon_1      | 2022-02-05 13:09:29,302 [IPC Server handler 12 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 938407921790, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-02-05 13:09:29,487 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 3bd141d9-8d6a-4889-940a-437a7867e049 to Node DB.
recon_1      | 2022-02-05 13:09:29,719 [IPC Server handler 2 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/9905eb49-ac94-40b9-a1a3-f35673531eee
recon_1      | 2022-02-05 13:09:29,722 [IPC Server handler 2 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 936463488335, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-02-05 13:09:29,725 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 9905eb49-ac94-40b9-a1a3-f35673531eee to Node DB.
recon_1      | 2022-02-05 13:09:30,575 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 141 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:30,587 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 142 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:30,595 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 143 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:09:30,835 [IPC Server handler 1 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net
recon_1      | 2022-02-05 13:09:31,312 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59672
recon_1      | 2022-02-05 13:09:31,498 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:09:31,603 [IPC Server handler 7 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net
recon_1      | 2022-02-05 13:09:32,597 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 144 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:32,598 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 145 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:32,599 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 146 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:09:32,749 [IPC Server handler 13 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/a527daad-fcfc-4913-bb86-57ba7fce9b83
recon_1      | 2022-02-05 13:09:32,749 [IPC Server handler 13 on default port 9891] INFO node.SCMNodeManager: Registered Data node : a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 941044329628, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-02-05 13:09:32,750 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node a527daad-fcfc-4913-bb86-57ba7fce9b83 to Node DB.
recon_1      | 2022-02-05 13:09:34,539 [IPC Server handler 2 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net
scm2.org_1   | 2022-02-05 13:07:57,458 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm2.org_1   | 2022-02-05 13:07:57,458 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm2.org_1   | 2022-02-05 13:07:57,459 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm2.org_1   | 2022-02-05 13:07:59,017 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm2.org_1   | 2022-02-05 13:07:59,117 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.117,host:scm2.org
scm2.org_1   | 2022-02-05 13:07:59,122 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm2.org_1   | 2022-02-05 13:07:59,125 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm2.org,scmId:ed216bc4-3c18-4c9d-881d-c81a0a0e45d8,clusterId:CID-fc180783-fb1e-4dd7-af87-eddf767648b7,subject:scm-sub@scm2.org
scm2.org_1   | 2022-02-05 13:08:01,513 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm2.org_1   | 2022-02-05 13:08:01,561 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-fc180783-fb1e-4dd7-af87-eddf767648b7, SCMID ed216bc4-3c18-4c9d-881d-c81a0a0e45d8
scm2.org_1   | 2022-02-05 13:08:01,561 [main] INFO server.StorageContainerManager: Primary SCM Node ID 70490618-601a-4309-ad32-4488318b9859
scm2.org_1   | 2022-02-05 13:08:01,658 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm2.org/172.25.0.117
scm2.org_1   | ************************************************************/
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 2022-02-05 13:08:04,355 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm2.org_1   | STARTUP_MSG:   args = []
scm2.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om1_1        | 2022-02-05 13:17:17,139 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,141 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,157 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,173 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,175 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,177 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,201 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,209 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,213 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,276 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,553 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,556 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,567 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,585 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,633 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,635 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,637 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,674 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,676 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,679 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,741 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,744 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,754 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,802 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,806 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,811 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,831 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,838 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,841 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:17,962 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:19,189 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:19,290 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:19,295 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:19,298 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:19,351 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:19,358 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:19,367 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:19,387 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:19,398 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:19,402 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:19,582 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:23,429 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:23,497 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:23,504 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:23,512 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/f757d9929c7016e9989d08ab2698179d61ef158b ; compiled by 'runner' on 2022-02-05T12:45Z
scm2.org_1   | STARTUP_MSG:   java = 11.0.13
scm2.org_1   | ************************************************************/
scm2.org_1   | 2022-02-05 13:08:04,369 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2022-02-05 13:08:04,441 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2022-02-05 13:08:04,441 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2022-02-05 13:08:04,500 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2022-02-05 13:08:04,500 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm2.org_1   | 2022-02-05 13:08:04,528 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-02-05 13:08:04,557 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
scm2.org_1   | 2022-02-05 13:08:04,786 [main] INFO reflections.Reflections: Reflections took 92 ms to scan 3 urls, producing 103 keys and 217 values 
scm2.org_1   | 2022-02-05 13:08:05,302 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm2.org_1   | 2022-02-05 13:08:05,446 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm2.org_1   | 2022-02-05 13:08:05,452 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm2.org_1   | 2022-02-05 13:08:05,455 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/878412281398.crt.
scm2.org_1   | 2022-02-05 13:08:05,633 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm2.org_1   | 2022-02-05 13:08:05,633 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2022-02-05 13:08:05,687 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-02-05 13:08:05,843 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-02-05 13:08:06,064 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm2.org_1   | 2022-02-05 13:08:06,064 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm2.org_1   | 2022-02-05 13:08:06,195 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm2.org_1   | 2022-02-05 13:08:06,260 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:ed216bc4-3c18-4c9d-881d-c81a0a0e45d8
scm2.org_1   | 2022-02-05 13:08:06,411 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm2.org_1   | 2022-02-05 13:08:06,572 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm2.org_1   | 2022-02-05 13:08:06,576 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-02-05 13:08:06,577 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm2.org_1   | 2022-02-05 13:08:06,578 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-02-05 13:08:06,578 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-02-05 13:08:06,583 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm2.org_1   | 2022-02-05 13:08:06,585 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2022-02-05 13:08:06,585 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm2.org_1   | 2022-02-05 13:08:06,587 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm2.org_1   | 2022-02-05 13:08:07,438 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm2.org_1   | 2022-02-05 13:08:07,441 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm2.org_1   | 2022-02-05 13:08:07,441 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2022-02-05 13:08:07,461 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   | 2022-02-05 13:08:07,483 [main] INFO server.RaftServer: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8: addNew group-EDDF767648B7:[] returns group-EDDF767648B7:java.util.concurrent.CompletableFuture@1b31af02[Not completed]
scm2.org_1   | 2022-02-05 13:08:07,563 [pool-14-thread-1] INFO server.RaftServer$Division: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8: new RaftServerImpl for group-EDDF767648B7:[] with SCMStateMachine:uninitialized
scm2.org_1   | 2022-02-05 13:08:07,567 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm3.org_1   | Sleeping for 5 seconds
scm3.org_1   | Waiting for the service scm2.org:9894
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2022-02-05 13:08:14,843 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm3.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/f757d9929c7016e9989d08ab2698179d61ef158b ; compiled by 'runner' on 2022-02-05T12:45Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.13
scm3.org_1   | ************************************************************/
scm3.org_1   | 2022-02-05 13:08:14,863 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2022-02-05 13:08:15,017 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2022-02-05 13:08:15,017 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2022-02-05 13:08:15,112 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm3.org_1   | 2022-02-05 13:08:15,117 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm3.org_1   | 2022-02-05 13:08:15,138 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-02-05 13:08:15,559 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2022-02-05 13:08:15,559 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2022-02-05 13:08:16,108 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm3.org_1   | 2022-02-05 13:08:16,616 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm3.org_1   | 2022-02-05 13:08:16,617 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm3.org_1   | 2022-02-05 13:08:16,618 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm3.org_1   | 2022-02-05 13:08:17,408 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm3.org_1   | 2022-02-05 13:08:17,500 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.118,host:scm3.org
scm3.org_1   | 2022-02-05 13:08:17,500 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm3.org_1   | 2022-02-05 13:08:17,503 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm3.org,scmId:9c3b6d1e-fc28-4275-b423-e30487699bae,clusterId:CID-fc180783-fb1e-4dd7-af87-eddf767648b7,subject:scm-sub@scm3.org
scm3.org_1   | 2022-02-05 13:08:18,693 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm3.org_1   | 2022-02-05 13:08:18,763 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-fc180783-fb1e-4dd7-af87-eddf767648b7, SCMID 9c3b6d1e-fc28-4275-b423-e30487699bae
scm3.org_1   | 2022-02-05 13:08:18,764 [main] INFO server.StorageContainerManager: Primary SCM Node ID 70490618-601a-4309-ad32-4488318b9859
scm3.org_1   | 2022-02-05 13:08:18,825 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm3.org/172.25.0.118
om3_1        | 2022-02-05 13:18:18,280 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-1400913700/ozone-test-9831389542/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om3_1        | partName: "etag1"
om3_1        | , partNumber: 2
om3_1        | partName: "etag2"
om3_1        | ]
om3_1        | 2022-02-05 13:18:18,281 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-9831389542/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-1400913700
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-1400913700 key: ozone-test-9831389542/multipartKey3
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:176)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-02-05 13:18:18,806 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-1400913700/ozone-test-9831389542/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om3_1        | partName: "etag1"
om3_1        | , partNumber: 1
om3_1        | partName: "etag2"
om3_1        | ]
om3_1        | 2022-02-05 13:18:18,807 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-9831389542/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-1400913700
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-1400913700 key: ozone-test-9831389542/multipartKey3
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:176)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-02-05 13:18:25,213 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-9831389542/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-1400913700
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-1400913700 key: ozone-test-9831389542/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-1400913700/ozone-test-9831389542/multipartKey3-4aa6b580-8307-4ca0-89fa-b8b99779129d-107745581312966689-1
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:455)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-02-05 13:18:25,716 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-9831389542/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-1400913700
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-1400913700 key: ozone-test-9831389542/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-1400913700/ozone-test-9831389542/multipartKey3-4aa6b580-8307-4ca0-89fa-b8b99779129d-107745581312966689-2
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:455)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-02-05 13:18:26,238 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-1400913700/ozone-test-9831389542/multipartKey3
om3_1        | 2022-02-05 13:18:26,248 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-9831389542/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-1400913700
om3_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-1400913700 key: ozone-test-9831389542/multipartKey3 because parts are in Invalid order.
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:421)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:183)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-02-05 13:18:29,190 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-5306351759/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-1400913700
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-1400913700key: ozone-test-5306351759/multipartKey5
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:156)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-02-05 13:18:29,729 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-1400913700, Key:ozone-test-4933169466/multipartKey. 
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:743)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:632)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:609)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:273)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-02-05 13:22:16,707 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCommitPartRequest: MultipartUpload Commit is failed for Key:ozone-test-5048365730/copyrange/destination in Volume/Bucket s3v/bucket-ozone-test-1400913700
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId 8d8cef6b-bfdd-433d-9bd6-48f754cd8048-107745584413147190
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCommitPartRequest.validateAndUpdateCache(S3MultipartUploadCommitPartRequest.java:185)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 2022-02-05 13:17:27,423 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35066
om1_1        | 2022-02-05 13:17:27,440 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:17:30,038 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:30,041 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:30,546 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:30,550 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:31,076 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:31,082 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:31,592 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:31,595 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:31,605 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-8586837866 in volume:s3v
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:187)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-02-05 13:17:32,143 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:36,050 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35096
om1_1        | 2022-02-05 13:17:36,080 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:17:38,604 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:38,610 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:39,179 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:39,182 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:39,682 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:39,693 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:40,193 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:40,196 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:40,202 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-1447320186 in volume:s3v
om1_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om1_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2334)
om1_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2304)
om1_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:197)
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:101)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-02-05 13:17:43,661 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35126
om1_1        | 2022-02-05 13:17:43,677 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:17:46,262 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:46,269 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:46,804 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:46,807 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:47,292 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:47,295 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:51,007 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35172
om1_1        | 2022-02-05 13:17:51,023 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:17:53,546 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:53,550 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:54,065 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:54,068 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:54,072 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:17:57,482 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35188
om1_1        | 2022-02-05 13:17:57,507 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:18:00,088 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:00,091 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:00,589 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:00,592 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:00,595 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:01,162 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:01,165 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:01,168 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:01,822 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:01,825 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:01,827 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:01,847 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:04,717 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:05,313 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:05,316 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:05,318 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:05,346 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:05,813 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:06,392 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:06,394 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:06,398 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:06,911 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:41133
om1_1        | 2022-02-05 13:18:06,917 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:18:07,047 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:07,050 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:07,052 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:07,071 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:09,852 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:10,413 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:10,416 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:10,419 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:10,439 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:13,047 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:13,649 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:13,652 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:13,655 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:14,210 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:14,214 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:14,216 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:14,268 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:15,141 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:15,143 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:15,147 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:15,719 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:15,723 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:15,725 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:15,747 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:15,906 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:16,476 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:16,478 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:16,480 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:16,500 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:16,593 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:17,136 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:17,139 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:17,141 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:17,161 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-1400913700/ozone-test-1594238177/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om1_1        | 2022-02-05 13:18:17,164 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-1594238177/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-1400913700
om1_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-1400913700 key: ozone-test-1594238177/multipartKey2. Entity too small.
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:473)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-02-05 13:18:17,662 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:17,667 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:17,671 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:18,258 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:18,263 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:18,265 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:18,276 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-1400913700/ozone-test-9831389542/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om1_1        | partName: "etag1"
om1_1        | , partNumber: 2
scm3.org_1   | ************************************************************/
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2022-02-05 13:08:22,210 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = []
scm3.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
recon_1      | 2022-02-05 13:09:34,601 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 147 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:34,602 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 148 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:34,603 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 149 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:09:35,972 [IPC Server handler 8 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net
recon_1      | 2022-02-05 13:09:35,975 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=194f5d50-3ed1-4cfa-a521-0d06090717c7. Trying to get from SCM.
recon_1      | 2022-02-05 13:09:36,461 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 194f5d50-3ed1-4cfa-a521-0d06090717c7, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.794Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-02-05 13:09:36,604 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 150 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:36,605 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 151 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:36,615 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 152 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:09:36,625 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 194f5d50-3ed1-4cfa-a521-0d06090717c7, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.794Z[UTC]].
recon_1      | 2022-02-05 13:09:36,658 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=194f5d50-3ed1-4cfa-a521-0d06090717c7 reported by a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 941044329628, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-02-05 13:09:36,661 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 194f5d50-3ed1-4cfa-a521-0d06090717c7, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.794Z[UTC]] moved to OPEN state
recon_1      | 2022-02-05 13:09:36,955 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=cd0dbfd1-bf28-4717-93ea-139bdf3e2545. Trying to get from SCM.
recon_1      | 2022-02-05 13:09:36,969 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]] to Recon pipeline metadata.
scm2.org_1   | 2022-02-05 13:08:07,569 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm2.org_1   | 2022-02-05 13:08:07,570 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm2.org_1   | 2022-02-05 13:08:07,570 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm2.org_1   | 2022-02-05 13:08:07,571 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2022-02-05 13:08:07,571 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm2.org_1   | 2022-02-05 13:08:07,574 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm2.org_1   | 2022-02-05 13:08:07,578 [pool-14-thread-1] INFO server.RaftServer$Division: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm2.org_1   | 2022-02-05 13:08:07,584 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   | 2022-02-05 13:08:07,596 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm2.org_1   | 2022-02-05 13:08:07,597 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm2.org_1   | 2022-02-05 13:08:07,599 [pool-14-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/fc180783-fb1e-4dd7-af87-eddf767648b7 does not exist. Creating ...
scm2.org_1   | 2022-02-05 13:08:07,630 [pool-14-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/fc180783-fb1e-4dd7-af87-eddf767648b7/in_use.lock acquired by nodename 7@scm2.org
scm2.org_1   | 2022-02-05 13:08:07,663 [pool-14-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/fc180783-fb1e-4dd7-af87-eddf767648b7 has been successfully formatted.
scm2.org_1   | 2022-02-05 13:08:07,685 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm2.org_1   | 2022-02-05 13:08:07,692 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm2.org_1   | 2022-02-05 13:08:07,709 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm2.org_1   | 2022-02-05 13:08:07,709 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2022-02-05 13:08:07,729 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm2.org_1   | 2022-02-05 13:08:07,751 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm2.org_1   | 2022-02-05 13:08:07,752 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm2.org_1   | 2022-02-05 13:08:07,772 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: new ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/fc180783-fb1e-4dd7-af87-eddf767648b7
scm2.org_1   | 2022-02-05 13:08:07,773 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm2.org_1   | 2022-02-05 13:08:07,773 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm2.org_1   | 2022-02-05 13:08:07,774 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm2.org_1   | 2022-02-05 13:08:07,775 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm2.org_1   | 2022-02-05 13:08:07,775 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm2.org_1   | 2022-02-05 13:08:07,777 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm2.org_1   | 2022-02-05 13:08:07,777 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm2.org_1   | 2022-02-05 13:08:07,777 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm2.org_1   | 2022-02-05 13:08:07,798 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm2.org_1   | 2022-02-05 13:08:07,798 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm2.org_1   | 2022-02-05 13:08:07,814 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2022-02-05 13:08:07,814 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2022-02-05 13:08:07,820 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm2.org_1   | 2022-02-05 13:08:07,820 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm2.org_1   | 2022-02-05 13:08:07,822 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm2.org_1   | 2022-02-05 13:08:07,826 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm2.org_1   | 2022-02-05 13:08:07,827 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm2.org_1   | 2022-02-05 13:08:07,828 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm2.org_1   | 2022-02-05 13:08:07,889 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm2.org_1   | 2022-02-05 13:08:07,889 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm2.org_1   | 2022-02-05 13:08:07,890 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm2.org_1   | 2022-02-05 13:08:08,119 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm2.org_1   | 2022-02-05 13:08:08,119 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm2.org_1   | 2022-02-05 13:08:08,122 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm2.org_1   | 2022-02-05 13:08:08,125 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm2.org_1   | 2022-02-05 13:08:08,276 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm2.org_1   | 2022-02-05 13:08:08,299 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm2.org_1   | 2022-02-05 13:08:08,315 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm2.org_1   | 2022-02-05 13:08:08,383 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm2.org_1   | 2022-02-05 13:08:08,395 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm2.org_1   | 2022-02-05 13:08:08,396 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm2.org_1   | 2022-02-05 13:08:08,461 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm2.org_1   | 2022-02-05 13:08:08,516 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm2.org_1   | 2022-02-05 13:08:08,582 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm2.org_1   | 2022-02-05 13:08:08,609 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm2.org_1   | 2022-02-05 13:08:08,630 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm2.org_1   | 2022-02-05 13:08:08,625 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-02-05 13:08:08,641 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-02-05 13:08:08,647 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2022-02-05 13:08:08,732 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm2.org_1   | 2022-02-05 13:08:08,771 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-02-05 13:08:08,854 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm2.org_1   | 2022-02-05 13:08:10,246 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-02-05 13:08:10,248 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm2.org_1   | 2022-02-05 13:08:10,323 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-02-05 13:08:10,325 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm2.org_1   | 2022-02-05 13:08:10,404 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-02-05 13:08:10,405 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm2.org_1   | 2022-02-05 13:08:10,662 [Listener at 0.0.0.0/9860] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm2.org_1   | 2022-02-05 13:08:10,696 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm2.org_1   | Container Balancer status:
scm2.org_1   | Key                            Value
scm2.org_1   | Running                        false
scm2.org_1   | Container Balancer Configuration values:
scm2.org_1   | Key                                                Value
scm2.org_1   | Threshold                                          10
scm2.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm2.org_1   | Max Size to Move per Iteration                     500GB
scm2.org_1   | Max Size Entering Target per Iteration             26GB
scm2.org_1   | Max Size Leaving Source per Iteration              26GB
scm2.org_1   | 
scm2.org_1   | 2022-02-05 13:08:10,697 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-02-05 13:08:10,697 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm2.org_1   | 2022-02-05 13:08:10,720 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm2.org_1   | 2022-02-05 13:08:10,723 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm2.org_1   | 2022-02-05 13:08:10,723 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7: start with initializing state, conf=-1: [], old=null
scm2.org_1   | 2022-02-05 13:08:10,731 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7: changes role from      null to FOLLOWER at term 0 for startInitializing
scm2.org_1   | 2022-02-05 13:08:10,732 [Listener at 0.0.0.0/9860] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-EDDF767648B7,id=ed216bc4-3c18-4c9d-881d-c81a0a0e45d8
scm2.org_1   | 2022-02-05 13:08:10,753 [Listener at 0.0.0.0/9860] INFO server.RaftServer: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8: start RPC server
scm2.org_1   | 2022-02-05 13:08:10,893 [Listener at 0.0.0.0/9860] INFO server.GrpcService: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8: GrpcService started, listening on 9894
scm2.org_1   | 2022-02-05 13:08:10,907 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$420/0x000000084052f040@4f239a76] INFO util.JvmPauseMonitor: JvmPauseMonitor-ed216bc4-3c18-4c9d-881d-c81a0a0e45d8: Started
scm2.org_1   | 2022-02-05 13:08:10,923 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-02-05 13:08:10,924 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-02-05 13:08:10,924 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm2.org_1   | 2022-02-05 13:08:12,363 [grpc-default-executor-0] INFO server.RaftServer$Division: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7: receive installSnapshot: 70490618-601a-4309-ad32-4488318b9859->ed216bc4-3c18-4c9d-881d-c81a0a0e45d8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2022-02-05 13:08:12,384 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm2.org_1   | 2022-02-05 13:08:12,384 [grpc-default-executor-0] INFO server.RaftServer$Division: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7: change Leader from null to 70490618-601a-4309-ad32-4488318b9859 at term 2 for installSnapshot, leader elected after 4698ms
scm2.org_1   | 2022-02-05 13:08:12,394 [grpc-default-executor-0] INFO server.RaftServer$Division: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7: Received notification to install snapshot at index 4
scm2.org_1   | 2022-02-05 13:08:12,463 [grpc-default-executor-0] INFO server.RaftServer$Division: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7: notifyInstallSnapshot: nextIndex is 0 but the leader's first available index is 4.
scm2.org_1   | 2022-02-05 13:08:12,466 [grpc-default-executor-0] INFO ha.SCMStateMachine: Received install snapshot notification from SCM leader: scm1.org:9894 with term index: (t:2, i:4)
scm2.org_1   | 2022-02-05 13:08:12,469 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Downloading checkpoint from leader SCM scm1 and reloading state from the checkpoint.
scm2.org_1   | 2022-02-05 13:08:13,281 [grpc-default-executor-2] INFO ha.InterSCMGrpcClient: Checkpoint is downloaded to /data/metadata/snapshot/scm.db-scm1-1644066492478.tar.gz
scm2.org_1   | 2022-02-05 13:08:13,303 [pool-16-thread-1] INFO ha.SCMSnapshotProvider: Successfully downloaded latest checkpoint from leader SCM: scm1 path /data/metadata/snapshot/scm.db-scm1-1644066492478
recon_1      | 2022-02-05 13:09:36,971 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]].
recon_1      | 2022-02-05 13:09:36,971 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=cd0dbfd1-bf28-4717-93ea-139bdf3e2545 reported by a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 941044329628, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-02-05 13:09:38,623 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 153 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:38,625 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 154 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:38,627 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 155 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:09:40,628 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 156 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:40,629 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 157 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:40,630 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 158 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:09:41,667 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46954
recon_1      | 2022-02-05 13:09:41,835 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:09:41,836 [IPC Server handler 8 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net
recon_1      | 2022-02-05 13:09:41,837 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=cd0dbfd1-bf28-4717-93ea-139bdf3e2545 reported by 3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 938407921790, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-02-05 13:09:41,908 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=cd0dbfd1-bf28-4717-93ea-139bdf3e2545 reported by a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 941044329628, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-02-05 13:09:42,632 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 159 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:42,633 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 160 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:42,634 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 161 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:09:43,262 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=cd0dbfd1-bf28-4717-93ea-139bdf3e2545 reported by a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 941044329628, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-02-05 13:09:44,638 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 162 failover attempts. Trying to failover immediately.
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/f757d9929c7016e9989d08ab2698179d61ef158b ; compiled by 'runner' on 2022-02-05T12:45Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.13
scm1.org_1   | ************************************************************/
scm1.org_1   | 2022-02-05 13:07:42,832 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2022-02-05 13:07:42,924 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2022-02-05 13:07:42,926 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2022-02-05 13:07:43,050 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm1.org_1   | 2022-02-05 13:07:43,050 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2022-02-05 13:07:43,096 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-02-05 13:07:43,132 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
scm1.org_1   | 2022-02-05 13:07:43,391 [main] INFO reflections.Reflections: Reflections took 143 ms to scan 3 urls, producing 103 keys and 217 values 
scm1.org_1   | 2022-02-05 13:07:43,926 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm1.org_1   | 2022-02-05 13:07:44,073 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm1.org_1   | 2022-02-05 13:07:44,077 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/850810018938.crt.
scm1.org_1   | 2022-02-05 13:07:44,080 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm1.org_1   | 2022-02-05 13:07:44,244 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm1.org_1   | 2022-02-05 13:07:44,244 [main] INFO server.StorageContainerManager: SCM login successful.
scm1.org_1   | 2022-02-05 13:07:44,282 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-02-05 13:07:44,451 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-02-05 13:07:44,662 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm1.org_1   | 2022-02-05 13:07:44,662 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm1.org_1   | 2022-02-05 13:07:44,749 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2022-02-05 13:07:44,793 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:70490618-601a-4309-ad32-4488318b9859
scm1.org_1   | 2022-02-05 13:07:44,887 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2022-02-05 13:07:44,981 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2022-02-05 13:07:44,982 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-02-05 13:07:44,983 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm1.org_1   | 2022-02-05 13:07:44,984 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-02-05 13:07:44,984 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-02-05 13:07:44,985 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2022-02-05 13:07:44,988 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-02-05 13:07:44,989 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2022-02-05 13:07:44,990 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-02-05 13:07:45,581 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2022-02-05 13:07:45,583 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-02-05 13:07:45,583 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-02-05 13:07:45,594 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-02-05 13:07:45,596 [main] INFO server.RaftServer: 70490618-601a-4309-ad32-4488318b9859: found a subdirectory /data/metadata/scm-ha/fc180783-fb1e-4dd7-af87-eddf767648b7
scm1.org_1   | 2022-02-05 13:07:45,608 [main] INFO server.RaftServer: 70490618-601a-4309-ad32-4488318b9859: addNew group-EDDF767648B7:[] returns group-EDDF767648B7:java.util.concurrent.CompletableFuture@3c16528d[Not completed]
scm1.org_1   | 2022-02-05 13:07:45,630 [pool-14-thread-1] INFO server.RaftServer$Division: 70490618-601a-4309-ad32-4488318b9859: new RaftServerImpl for group-EDDF767648B7:[] with SCMStateMachine:uninitialized
scm1.org_1   | 2022-02-05 13:07:45,633 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2022-02-05 13:07:45,634 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2022-02-05 13:07:45,634 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2022-02-05 13:07:45,634 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-02-05 13:07:45,635 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-02-05 13:07:45,635 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2022-02-05 13:07:45,635 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-02-05 13:07:45,653 [pool-14-thread-1] INFO server.RaftServer$Division: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2022-02-05 13:07:45,654 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-02-05 13:07:45,657 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2022-02-05 13:07:45,657 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm1.org_1   | 2022-02-05 13:07:45,666 [pool-14-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/fc180783-fb1e-4dd7-af87-eddf767648b7/in_use.lock acquired by nodename 9@scm1.org
scm1.org_1   | 2022-02-05 13:07:45,671 [pool-14-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=70490618-601a-4309-ad32-4488318b9859} from /data/metadata/scm-ha/fc180783-fb1e-4dd7-af87-eddf767648b7/current/raft-meta
scm1.org_1   | 2022-02-05 13:07:45,700 [pool-14-thread-1] INFO server.RaftServer$Division: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7: set configuration 0: [70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-02-05 13:07:45,700 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2022-02-05 13:07:45,702 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2022-02-05 13:07:45,709 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2022-02-05 13:07:45,709 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-02-05 13:07:45,721 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-02-05 13:07:45,729 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2022-02-05 13:07:45,729 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2022-02-05 13:07:45,734 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: new 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/fc180783-fb1e-4dd7-af87-eddf767648b7
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | 2022-02-05 13:17:53,548 [qtp1431556341-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-0774637061, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-02-05 13:17:53,561 [qtp1431556341-21] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-0774637061
s3g_1        | 2022-02-05 13:18:00,090 [qtp1431556341-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-1400913700, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-02-05 13:18:00,106 [qtp1431556341-21] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-1400913700
s3g_1        | 2022-02-05 13:18:17,165 [qtp1431556341-17] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-ozone-test-1400913700, , key: ozone-test-1594238177/multipartKey2
s3g_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-1400913700 key: ozone-test-1594238177/multipartKey2. Entity too small.
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:654)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:1027)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1231)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:762)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:534)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.25.3.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/f757d9929c7016e9989d08ab2698179d61ef158b ; compiled by 'runner' on 2022-02-05T12:45Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.13
scm3.org_1   | ************************************************************/
scm3.org_1   | 2022-02-05 13:08:22,242 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2022-02-05 13:08:22,367 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2022-02-05 13:08:22,367 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2022-02-05 13:08:22,475 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm3.org_1   | 2022-02-05 13:08:22,476 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm3.org_1   | 2022-02-05 13:08:22,563 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-02-05 13:08:22,625 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
scm3.org_1   | 2022-02-05 13:08:23,169 [main] INFO reflections.Reflections: Reflections took 255 ms to scan 3 urls, producing 103 keys and 217 values 
scm3.org_1   | 2022-02-05 13:08:24,191 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm3.org_1   | 2022-02-05 13:08:24,415 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm3.org_1   | 2022-02-05 13:08:24,425 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/896186891008.crt.
scm3.org_1   | 2022-02-05 13:08:24,427 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm3.org_1   | 2022-02-05 13:08:24,683 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2022-02-05 13:08:24,683 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2022-02-05 13:08:24,734 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-02-05 13:08:25,112 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-02-05 13:08:25,501 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-02-05 13:23:16,693 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCommitPartRequest: MultipartUpload Commit is failed for Key:ozone-test-5048365730/copyrange/destination in Volume/Bucket s3v/bucket-ozone-test-1400913700
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId 8d8cef6b-bfdd-433d-9bd6-48f754cd8048-107745584413147190
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCommitPartRequest.validateAndUpdateCache(S3MultipartUploadCommitPartRequest.java:185)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-02-05 13:32:12,713 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-6636892664, Key:ozone-test-9758447856/multidelete/key=value/f4.
om3_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:148)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:94)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm3.org_1   | 2022-02-05 13:08:25,502 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm3.org_1   | 2022-02-05 13:08:25,654 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm3.org_1   | 2022-02-05 13:08:25,846 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:9c3b6d1e-fc28-4275-b423-e30487699bae
scm3.org_1   | 2022-02-05 13:08:26,052 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm3.org_1   | 2022-02-05 13:08:26,176 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm3.org_1   | 2022-02-05 13:08:26,177 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2022-02-05 13:08:26,177 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm3.org_1   | 2022-02-05 13:08:26,178 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2022-02-05 13:08:26,178 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2022-02-05 13:08:26,179 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm3.org_1   | 2022-02-05 13:08:26,186 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2022-02-05 13:08:26,186 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm3.org_1   | 2022-02-05 13:08:26,187 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm3.org_1   | 2022-02-05 13:08:27,056 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm3.org_1   | 2022-02-05 13:08:27,057 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2022-02-05 13:08:27,057 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm3.org_1   | 2022-02-05 13:08:27,071 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2022-02-05 13:08:27,082 [main] INFO server.RaftServer: 9c3b6d1e-fc28-4275-b423-e30487699bae: addNew group-EDDF767648B7:[] returns group-EDDF767648B7:java.util.concurrent.CompletableFuture@1b31af02[Not completed]
scm3.org_1   | 2022-02-05 13:08:27,102 [pool-14-thread-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae: new RaftServerImpl for group-EDDF767648B7:[] with SCMStateMachine:uninitialized
scm3.org_1   | 2022-02-05 13:08:27,111 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm3.org_1   | 2022-02-05 13:08:27,112 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm3.org_1   | 2022-02-05 13:08:27,112 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm3.org_1   | 2022-02-05 13:08:27,112 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2022-02-05 13:08:27,113 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm3.org_1   | 2022-02-05 13:08:27,113 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm3.org_1   | 2022-02-05 13:08:27,113 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm3.org_1   | 2022-02-05 13:08:27,118 [pool-14-thread-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm3.org_1   | 2022-02-05 13:08:27,118 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2022-02-05 13:08:27,123 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm3.org_1   | 2022-02-05 13:08:27,124 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm3.org_1   | 2022-02-05 13:08:27,126 [pool-14-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/fc180783-fb1e-4dd7-af87-eddf767648b7 does not exist. Creating ...
scm3.org_1   | 2022-02-05 13:08:27,137 [pool-14-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/fc180783-fb1e-4dd7-af87-eddf767648b7/in_use.lock acquired by nodename 7@scm3.org
scm3.org_1   | 2022-02-05 13:08:27,153 [pool-14-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/fc180783-fb1e-4dd7-af87-eddf767648b7 has been successfully formatted.
scm3.org_1   | 2022-02-05 13:08:27,166 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm3.org_1   | 2022-02-05 13:08:27,167 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm3.org_1   | 2022-02-05 13:08:27,178 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm3.org_1   | 2022-02-05 13:08:27,179 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2022-02-05 13:08:27,201 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm3.org_1   | 2022-02-05 13:08:27,210 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm3.org_1   | 2022-02-05 13:08:27,210 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm3.org_1   | 2022-02-05 13:08:27,216 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: new 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/fc180783-fb1e-4dd7-af87-eddf767648b7
scm3.org_1   | 2022-02-05 13:08:27,217 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm3.org_1   | 2022-02-05 13:08:27,218 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm3.org_1   | 2022-02-05 13:08:27,219 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm3.org_1   | 2022-02-05 13:08:27,219 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm3.org_1   | 2022-02-05 13:08:27,220 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm3.org_1   | 2022-02-05 13:08:27,221 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm3.org_1   | 2022-02-05 13:08:27,221 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm3.org_1   | 2022-02-05 13:08:27,222 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm3.org_1   | 2022-02-05 13:08:27,229 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm3.org_1   | 2022-02-05 13:08:27,229 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm3.org_1   | 2022-02-05 13:08:27,234 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm3.org_1   | 2022-02-05 13:08:27,235 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm3.org_1   | 2022-02-05 13:08:27,239 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm3.org_1   | 2022-02-05 13:08:27,239 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm3.org_1   | 2022-02-05 13:08:27,240 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm3.org_1   | 2022-02-05 13:08:27,241 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm3.org_1   | 2022-02-05 13:08:27,242 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm3.org_1   | 2022-02-05 13:08:27,244 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm3.org_1   | 2022-02-05 13:08:27,275 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm3.org_1   | 2022-02-05 13:08:27,276 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm3.org_1   | 2022-02-05 13:08:27,277 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm3.org_1   | 2022-02-05 13:08:27,455 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm3.org_1   | 2022-02-05 13:08:27,455 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm3.org_1   | 2022-02-05 13:08:27,459 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm3.org_1   | 2022-02-05 13:08:27,462 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm3.org_1   | 2022-02-05 13:08:27,513 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm3.org_1   | 2022-02-05 13:08:27,533 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm3.org_1   | 2022-02-05 13:08:27,577 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm3.org_1   | 2022-02-05 13:08:27,631 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm3.org_1   | 2022-02-05 13:08:27,641 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm3.org_1   | 2022-02-05 13:08:27,641 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm3.org_1   | 2022-02-05 13:08:27,688 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm3.org_1   | 2022-02-05 13:08:27,708 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm2.org_1   | 2022-02-05 13:08:13,305 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Downloaded checkpoint from Leader scm1 to the location /data/metadata/snapshot/scm.db-scm1-1644066492478
scm2.org_1   | 2022-02-05 13:08:13,379 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Installing checkpoint with SCMTransactionInfo 2#4
scm2.org_1   | 2022-02-05 13:08:13,380 [pool-16-thread-1] INFO server.RaftServer$Division: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7: StateMachine successfully installed snapshot index 4. Reloading the StateMachine.
scm2.org_1   | 2022-02-05 13:08:13,380 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-SegmentedRaftLogWorker: flushIndex: setUnconditionally -1 -> 4
scm2.org_1   | 2022-02-05 13:08:13,381 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally -1 -> 4
scm2.org_1   | 2022-02-05 13:08:13,387 [pool-16-thread-1] INFO raftlog.RaftLog: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-SegmentedRaftLog: snapshotIndex: updateIncreasingly -1 -> 4
scm2.org_1   | 2022-02-05 13:08:13,388 [grpc-default-executor-0] INFO server.RaftServer$Division: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7: InstallSnapshot notification result: SNAPSHOT_INSTALLED, at index: 4
scm2.org_1   | 2022-02-05 13:08:13,574 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Installing checkpoint with SCMTransactionInfo 2#4
scm2.org_1   | 2022-02-05 13:08:13,616 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Replaced DB with checkpoint, term: 2, index: 4
scm2.org_1   | 2022-02-05 13:08:13,622 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-02-05 13:08:13,642 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-02-05 13:08:13,813 [grpc-default-executor-0] INFO server.RaftServer$Division: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "70490618-601a-4309-ad32-4488318b9859"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm2.org_1   | 2022-02-05 13:08:13,836 [grpc-default-executor-0] INFO server.RaftServer$Division: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7: set configuration 1: [70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-02-05 13:08:13,848 [grpc-default-executor-0] INFO server.RaftServer$Division: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7: reply installSnapshot: 70490618-601a-4309-ad32-4488318b9859<-ed216bc4-3c18-4c9d-881d-c81a0a0e45d8#0:FAIL-t0,SNAPSHOT_INSTALLED,snapshotIndex=4
scm2.org_1   | 2022-02-05 13:08:13,860 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8: Completed INSTALL_SNAPSHOT, lastRequest: 70490618-601a-4309-ad32-4488318b9859->ed216bc4-3c18-4c9d-881d-c81a0a0e45d8#0-t2,notify:(t:2, i:4)
scm2.org_1   | 2022-02-05 13:08:13,928 [grpc-default-executor-0] INFO impl.RoleInfo: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8: start ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-FollowerState
scm2.org_1   | 2022-02-05 13:08:13,939 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO ha.SequenceIdGenerator: reinitialize SequenceIdGenerator.
scm2.org_1   | 2022-02-05 13:08:13,963 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm2.org_1   | 2022-02-05 13:08:13,980 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Reloaded SCM state with Term: 2 and Index: 4
scm2.org_1   | 2022-02-05 13:08:13,981 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO impl.StateMachineUpdater: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater: snapshotIndex: setUnconditionally -1 -> 4
scm2.org_1   | 2022-02-05 13:08:13,981 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO impl.StateMachineUpdater: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater: appliedIndex: setUnconditionally -1 -> 4
scm2.org_1   | 2022-02-05 13:08:17,015 [grpc-default-executor-0] INFO server.RaftServer$Division: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7: set configuration 5: [70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-02-05 13:08:17,020 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-SegmentedRaftLogWorker: Starting segment from index:5
scm2.org_1   | 2022-02-05 13:08:17,267 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/fc180783-fb1e-4dd7-af87-eddf767648b7/current/log_inprogress_5
scm2.org_1   | 2022-02-05 13:08:17,300 [grpc-default-executor-0] INFO server.RaftServer$Division: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7: set configuration 7: [70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-02-05 13:08:17,321 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-02-05 13:08:17,323 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm2.org_1   | 2022-02-05 13:08:17,323 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2022-02-05 13:08:17,324 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm2.org_1   | 2022-02-05 13:08:17,344 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-02-05 13:08:17,378 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm2.org_1   | 2022-02-05 13:08:17,447 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm2 to group group-EDDF767648B7:[70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-02-05 13:08:17,447 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm2.org_1   | 2022-02-05 13:08:17,480 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm2.org_1   | 2022-02-05 13:08:17,480 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
recon_1      | 2022-02-05 13:09:44,639 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 163 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:44,640 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 164 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:09:45,786 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59372
recon_1      | 2022-02-05 13:09:45,838 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:09:45,839 [IPC Server handler 8 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net
recon_1      | 2022-02-05 13:09:45,846 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=cd0dbfd1-bf28-4717-93ea-139bdf3e2545 reported by 9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 936463488335, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-02-05 13:09:45,846 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]] moved to OPEN state
recon_1      | 2022-02-05 13:09:46,641 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 165 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:46,642 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 166 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:46,643 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 167 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:09:46,957 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=f1ca961d-d578-498d-933d-dd33d84c9d7f. Trying to get from SCM.
recon_1      | 2022-02-05 13:09:47,104 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: f1ca961d-d578-498d-933d-dd33d84c9d7f, Nodes: 9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-02-05T13:09:33.048Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-02-05 13:09:47,106 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: f1ca961d-d578-498d-933d-dd33d84c9d7f, Nodes: 9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-02-05T13:09:33.048Z[UTC]].
recon_1      | 2022-02-05 13:09:47,106 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=f1ca961d-d578-498d-933d-dd33d84c9d7f reported by a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 941044329628, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-02-05 13:09:47,620 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=f1ca961d-d578-498d-933d-dd33d84c9d7f reported by 9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 936463488335, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-02-05 13:09:48,438 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=f1ca961d-d578-498d-933d-dd33d84c9d7f reported by 3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 938407921790, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-02-05 13:09:54,518 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:198)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:191)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:150)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 168 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:56,242 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:198)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:191)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:150)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 169 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:09:59,234 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:198)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:191)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:150)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 170 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:10:01,239 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:198)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:191)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:150)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 171 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:10:01,251 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:198)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:191)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:150)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm3.org_1   | 2022-02-05 13:08:27,759 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm3.org_1   | 2022-02-05 13:08:27,785 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm3.org_1   | 2022-02-05 13:08:27,798 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-02-05 13:08:27,807 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm3.org_1   | 2022-02-05 13:08:27,811 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-02-05 13:08:27,816 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm3.org_1   | 2022-02-05 13:08:27,921 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm3.org_1   | 2022-02-05 13:08:27,967 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-02-05 13:08:28,008 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm3.org_1   | 2022-02-05 13:08:28,853 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-02-05 13:08:28,856 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm3.org_1   | 2022-02-05 13:08:28,875 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-02-05 13:08:28,878 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm3.org_1   | 2022-02-05 13:08:28,902 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-02-05 13:08:28,903 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm3.org_1   | 2022-02-05 13:08:28,977 [Listener at 0.0.0.0/9860] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm3.org_1   | 2022-02-05 13:08:28,991 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm3.org_1   | Container Balancer status:
scm3.org_1   | Key                            Value
scm3.org_1   | Running                        false
scm3.org_1   | Container Balancer Configuration values:
scm3.org_1   | Key                                                Value
scm3.org_1   | Threshold                                          10
scm3.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm3.org_1   | Max Size to Move per Iteration                     500GB
scm3.org_1   | Max Size Entering Target per Iteration             26GB
scm3.org_1   | Max Size Leaving Source per Iteration              26GB
scm3.org_1   | 
scm3.org_1   | 2022-02-05 13:08:28,991 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-02-05 13:08:28,991 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm3.org_1   | 2022-02-05 13:08:28,995 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm3.org_1   | 2022-02-05 13:08:28,998 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm3.org_1   | 2022-02-05 13:08:28,998 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: start with initializing state, conf=-1: [], old=null
scm3.org_1   | 2022-02-05 13:08:29,000 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: changes role from      null to FOLLOWER at term 0 for startInitializing
scm3.org_1   | 2022-02-05 13:08:29,001 [Listener at 0.0.0.0/9860] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-EDDF767648B7,id=9c3b6d1e-fc28-4275-b423-e30487699bae
scm3.org_1   | 2022-02-05 13:08:29,008 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 9c3b6d1e-fc28-4275-b423-e30487699bae: start RPC server
scm3.org_1   | 2022-02-05 13:08:29,209 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 9c3b6d1e-fc28-4275-b423-e30487699bae: GrpcService started, listening on 9894
scm3.org_1   | 2022-02-05 13:08:29,225 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$420/0x000000084052f040@4f239a76] INFO util.JvmPauseMonitor: JvmPauseMonitor-9c3b6d1e-fc28-4275-b423-e30487699bae: Started
scm3.org_1   | 2022-02-05 13:08:29,227 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm3.org_1   | 2022-02-05 13:08:29,228 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm3.org_1   | 2022-02-05 13:08:29,229 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm3.org_1   | 2022-02-05 13:08:33,002 [grpc-default-executor-0] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: receive installSnapshot: 70490618-601a-4309-ad32-4488318b9859->9c3b6d1e-fc28-4275-b423-e30487699bae#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-02-05 13:08:33,295 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm3.org_1   | 2022-02-05 13:08:33,297 [grpc-default-executor-0] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: change Leader from null to 70490618-601a-4309-ad32-4488318b9859 at term 2 for installSnapshot, leader elected after 6129ms
scm3.org_1   | 2022-02-05 13:08:33,301 [grpc-default-executor-0] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: Received notification to install snapshot at index 10
scm3.org_1   | 2022-02-05 13:08:33,538 [grpc-default-executor-0] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: notifyInstallSnapshot: nextIndex is 0 but the leader's first available index is 10.
scm3.org_1   | 2022-02-05 13:08:33,543 [grpc-default-executor-0] INFO ha.SCMStateMachine: Received install snapshot notification from SCM leader: scm1.org:9894 with term index: (t:2, i:10)
scm3.org_1   | 2022-02-05 13:08:33,567 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Downloading checkpoint from leader SCM scm1 and reloading state from the checkpoint.
scm3.org_1   | 2022-02-05 13:08:35,769 [grpc-default-executor-0] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "70490618-601a-4309-ad32-4488318b9859"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "ed216bc4-3c18-4c9d-881d-c81a0a0e45d8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-02-05 13:08:35,777 [grpc-default-executor-0] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: set configuration 7: [70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-02-05 13:08:35,777 [grpc-default-executor-0] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: reply installSnapshot: 70490618-601a-4309-ad32-4488318b9859<-9c3b6d1e-fc28-4275-b423-e30487699bae#0:FAIL-t0,IN_PROGRESS
scm3.org_1   | 2022-02-05 13:08:35,918 [grpc-default-executor-1] INFO ha.InterSCMGrpcClient: Checkpoint is downloaded to /data/metadata/snapshot/scm.db-scm1-1644066513590.tar.gz
scm3.org_1   | 2022-02-05 13:08:35,938 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 9c3b6d1e-fc28-4275-b423-e30487699bae: Completed INSTALL_SNAPSHOT, lastRequest: 70490618-601a-4309-ad32-4488318b9859->9c3b6d1e-fc28-4275-b423-e30487699bae#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-02-05 13:08:36,091 [pool-16-thread-1] INFO ha.SCMSnapshotProvider: Successfully downloaded latest checkpoint from leader SCM: scm1 path /data/metadata/snapshot/scm.db-scm1-1644066513590
scm3.org_1   | 2022-02-05 13:08:36,092 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Downloaded checkpoint from Leader scm1 to the location /data/metadata/snapshot/scm.db-scm1-1644066513590
scm3.org_1   | 2022-02-05 13:08:36,151 [grpc-default-executor-0] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: receive installSnapshot: 70490618-601a-4309-ad32-4488318b9859->9c3b6d1e-fc28-4275-b423-e30487699bae#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-02-05 13:08:36,151 [grpc-default-executor-0] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "70490618-601a-4309-ad32-4488318b9859"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm1.org_1   | 2022-02-05 13:07:45,735 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-02-05 13:07:45,735 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2022-02-05 13:07:45,736 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-02-05 13:07:45,737 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm1.org_1   | 2022-02-05 13:07:45,737 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2022-02-05 13:07:45,738 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2022-02-05 13:07:45,739 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2022-02-05 13:07:45,739 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2022-02-05 13:07:45,747 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2022-02-05 13:07:45,748 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2022-02-05 13:07:45,771 [pool-14-thread-1] INFO server.RaftServer$Division: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7: set configuration 0: [70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-02-05 13:07:45,772 [pool-14-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/fc180783-fb1e-4dd7-af87-eddf767648b7/current/log_inprogress_0
scm1.org_1   | 2022-02-05 13:07:45,775 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-02-05 13:07:45,775 [pool-14-thread-1] INFO segmented.SegmentedRaftLogWorker: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-02-05 13:07:45,860 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2022-02-05 13:07:45,861 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2022-02-05 13:07:45,862 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2022-02-05 13:07:45,862 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2022-02-05 13:07:45,864 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2022-02-05 13:07:45,864 [pool-14-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2022-02-05 13:07:45,895 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm1.org_1   | 2022-02-05 13:07:45,895 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm1.org_1   | 2022-02-05 13:07:45,896 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm1.org_1   | 2022-02-05 13:07:46,047 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm1.org_1   | 2022-02-05 13:07:46,048 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm1.org_1   | 2022-02-05 13:07:46,058 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm1.org_1   | 2022-02-05 13:07:46,061 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm1.org_1   | 2022-02-05 13:07:46,159 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm1.org_1   | 2022-02-05 13:07:46,170 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm1.org_1   | 2022-02-05 13:07:46,179 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm1.org_1   | 2022-02-05 13:07:46,211 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm1.org_1   | 2022-02-05 13:07:46,217 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm1.org_1   | 2022-02-05 13:07:46,217 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm1.org_1   | 2022-02-05 13:07:46,247 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm1.org_1   | 2022-02-05 13:07:46,263 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm1.org_1   | 2022-02-05 13:07:46,305 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm1.org_1   | 2022-02-05 13:07:46,354 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm1.org_1   | 2022-02-05 13:07:46,365 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm1.org_1   | 2022-02-05 13:07:46,366 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm1.org_1   | 2022-02-05 13:07:46,369 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-02-05 13:07:46,372 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm1.org_1   | 2022-02-05 13:07:46,399 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2022-02-05 13:07:46,404 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2022-02-05 13:07:46,405 [main] INFO server.StorageContainerManager: Storing sub-ca certificate serialId 850810018938 on primary SCM
scm1.org_1   | 2022-02-05 13:07:46,409 [main] INFO server.StorageContainerManager: Storing root certificate serialId 1
scm1.org_1   | 2022-02-05 13:07:46,438 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-02-05 13:07:46,474 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm1.org_1   | 2022-02-05 13:07:47,231 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-02-05 13:07:47,245 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm1.org_1   | 2022-02-05 13:07:47,271 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-02-05 13:07:47,272 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
om1_1        | partName: "etag2"
om1_1        | ]
om1_1        | 2022-02-05 13:18:18,277 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-9831389542/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-1400913700
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-1400913700 key: ozone-test-9831389542/multipartKey3
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:176)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-02-05 13:18:18,790 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:18,792 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:18,794 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:18,804 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-1400913700/ozone-test-9831389542/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om1_1        | partName: "etag1"
om1_1        | , partNumber: 1
om1_1        | partName: "etag2"
om1_1        | ]
om1_1        | 2022-02-05 13:18:18,810 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-9831389542/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-1400913700
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-1400913700 key: ozone-test-9831389542/multipartKey3
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:176)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-02-05 13:18:19,591 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:19,594 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:19,601 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:19,624 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:20,041 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:20,758 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:20,761 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:20,763 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:20,784 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:21,377 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:21,942 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:21,944 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:21,947 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:21,969 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:24,619 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:25,190 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:25,193 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:25,196 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:25,203 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-9831389542/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-1400913700
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-1400913700 key: ozone-test-9831389542/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-1400913700/ozone-test-9831389542/multipartKey3-4aa6b580-8307-4ca0-89fa-b8b99779129d-107745581312966689-1
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:455)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-02-05 13:18:25,697 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:25,700 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:25,704 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:25,714 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-9831389542/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-1400913700
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-1400913700 key: ozone-test-9831389542/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-1400913700/ozone-test-9831389542/multipartKey3-4aa6b580-8307-4ca0-89fa-b8b99779129d-107745581312966689-2
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:455)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-02-05 13:18:26,220 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:26,222 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:26,224 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:26,233 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-1400913700/ozone-test-9831389542/multipartKey3
om1_1        | 2022-02-05 13:18:26,236 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-9831389542/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-1400913700
om1_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-1400913700 key: ozone-test-9831389542/multipartKey3 because parts are in Invalid order.
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:421)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:183)
scm1.org_1   | 2022-02-05 13:07:47,384 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-02-05 13:07:47,385 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm1.org_1   | 2022-02-05 13:07:47,472 [Listener at 0.0.0.0/9860] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm1.org_1   | 2022-02-05 13:07:47,488 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm1.org_1   | Container Balancer status:
scm1.org_1   | Key                            Value
scm1.org_1   | Running                        false
scm1.org_1   | Container Balancer Configuration values:
scm1.org_1   | Key                                                Value
scm1.org_1   | Threshold                                          10
scm1.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm1.org_1   | Max Size to Move per Iteration                     500GB
scm1.org_1   | Max Size Entering Target per Iteration             26GB
scm1.org_1   | Max Size Leaving Source per Iteration              26GB
scm1.org_1   | 
scm1.org_1   | 2022-02-05 13:07:47,488 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-02-05 13:07:47,489 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm1.org_1   | 2022-02-05 13:07:47,495 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm1.org_1   | 2022-02-05 13:07:47,496 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm1.org_1   | 2022-02-05 13:07:47,496 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7: start as a follower, conf=0: [70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-02-05 13:07:47,506 [Listener at 0.0.0.0/9860] INFO server.RaftServer$Division: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7: changes role from      null to FOLLOWER at term 1 for startAsFollower
scm1.org_1   | 2022-02-05 13:07:47,508 [Listener at 0.0.0.0/9860] INFO impl.RoleInfo: 70490618-601a-4309-ad32-4488318b9859: start 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-FollowerState
scm1.org_1   | 2022-02-05 13:07:47,523 [Listener at 0.0.0.0/9860] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-EDDF767648B7,id=70490618-601a-4309-ad32-4488318b9859
scm1.org_1   | 2022-02-05 13:07:47,533 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 70490618-601a-4309-ad32-4488318b9859: start RPC server
scm1.org_1   | 2022-02-05 13:07:47,601 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 70490618-601a-4309-ad32-4488318b9859: GrpcService started, listening on 9894
scm1.org_1   | 2022-02-05 13:07:47,604 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2022-02-05 13:07:47,624 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm1.org_1   | 2022-02-05 13:07:47,625 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$439/0x000000084053f040@6ddc9001] INFO util.JvmPauseMonitor: JvmPauseMonitor-70490618-601a-4309-ad32-4488318b9859: Started
scm1.org_1   | 2022-02-05 13:07:47,634 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm1.org_1   | 2022-02-05 13:07:47,634 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm1.org_1   | 2022-02-05 13:07:47,727 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm1.org_1   | 2022-02-05 13:07:47,740 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm1.org_1   | 2022-02-05 13:07:47,740 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm1.org_1   | 2022-02-05 13:07:48,069 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm1.org_1   | 2022-02-05 13:07:48,070 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-02-05 13:07:48,071 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm3.org_1   |     id: "ed216bc4-3c18-4c9d-881d-c81a0a0e45d8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-02-05 13:08:36,152 [grpc-default-executor-0] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: set configuration 7: [70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-02-05 13:08:36,167 [grpc-default-executor-0] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: reply installSnapshot: 70490618-601a-4309-ad32-4488318b9859<-9c3b6d1e-fc28-4275-b423-e30487699bae#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2022-02-05 13:08:36,192 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 9c3b6d1e-fc28-4275-b423-e30487699bae: Completed INSTALL_SNAPSHOT, lastRequest: 70490618-601a-4309-ad32-4488318b9859->9c3b6d1e-fc28-4275-b423-e30487699bae#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-02-05 13:08:36,195 [grpc-default-executor-1] INFO impl.RoleInfo: 9c3b6d1e-fc28-4275-b423-e30487699bae: start 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-FollowerState
scm3.org_1   | 2022-02-05 13:08:36,202 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2022-02-05 13:08:36,206 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: inconsistency entries. Reply:70490618-601a-4309-ad32-4488318b9859<-9c3b6d1e-fc28-4275-b423-e30487699bae#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-02-05 13:08:36,310 [grpc-default-executor-0] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2022-02-05 13:08:36,310 [grpc-default-executor-0] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: inconsistency entries. Reply:70490618-601a-4309-ad32-4488318b9859<-9c3b6d1e-fc28-4275-b423-e30487699bae#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-02-05 13:08:36,317 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: receive installSnapshot: 70490618-601a-4309-ad32-4488318b9859->9c3b6d1e-fc28-4275-b423-e30487699bae#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-02-05 13:08:36,343 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "70490618-601a-4309-ad32-4488318b9859"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "ed216bc4-3c18-4c9d-881d-c81a0a0e45d8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-02-05 13:08:36,344 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: set configuration 7: [70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-02-05 13:08:36,345 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: reply installSnapshot: 70490618-601a-4309-ad32-4488318b9859<-9c3b6d1e-fc28-4275-b423-e30487699bae#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2022-02-05 13:08:36,354 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: 9c3b6d1e-fc28-4275-b423-e30487699bae: Completed INSTALL_SNAPSHOT, lastRequest: 70490618-601a-4309-ad32-4488318b9859->9c3b6d1e-fc28-4275-b423-e30487699bae#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-02-05 13:08:36,376 [grpc-default-executor-0] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2022-02-05 13:08:36,378 [grpc-default-executor-0] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: inconsistency entries. Reply:70490618-601a-4309-ad32-4488318b9859<-9c3b6d1e-fc28-4275-b423-e30487699bae#2:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-02-05 13:08:36,390 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: receive installSnapshot: 70490618-601a-4309-ad32-4488318b9859->9c3b6d1e-fc28-4275-b423-e30487699bae#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-02-05 13:08:36,416 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "70490618-601a-4309-ad32-4488318b9859"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "ed216bc4-3c18-4c9d-881d-c81a0a0e45d8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-02-05 13:08:36,419 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: set configuration 7: [70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-02-05 13:08:36,430 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: reply installSnapshot: 70490618-601a-4309-ad32-4488318b9859<-9c3b6d1e-fc28-4275-b423-e30487699bae#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2022-02-05 13:08:36,431 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: 9c3b6d1e-fc28-4275-b423-e30487699bae: Completed INSTALL_SNAPSHOT, lastRequest: 70490618-601a-4309-ad32-4488318b9859->9c3b6d1e-fc28-4275-b423-e30487699bae#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-02-05 13:08:36,494 [grpc-default-executor-0] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2022-02-05 13:08:36,498 [grpc-default-executor-0] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: inconsistency entries. Reply:70490618-601a-4309-ad32-4488318b9859<-9c3b6d1e-fc28-4275-b423-e30487699bae#3:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-02-05 13:08:36,519 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: receive installSnapshot: 70490618-601a-4309-ad32-4488318b9859->9c3b6d1e-fc28-4275-b423-e30487699bae#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-02-05 13:08:36,521 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "70490618-601a-4309-ad32-4488318b9859"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "ed216bc4-3c18-4c9d-881d-c81a0a0e45d8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-02-05 13:08:36,523 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: set configuration 7: [70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-02-05 13:08:36,525 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: reply installSnapshot: 70490618-601a-4309-ad32-4488318b9859<-9c3b6d1e-fc28-4275-b423-e30487699bae#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2022-02-05 13:08:36,538 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: 9c3b6d1e-fc28-4275-b423-e30487699bae: Completed INSTALL_SNAPSHOT, lastRequest: 70490618-601a-4309-ad32-4488318b9859->9c3b6d1e-fc28-4275-b423-e30487699bae#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-02-05 13:08:36,576 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2022-02-05 13:08:36,598 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: inconsistency entries. Reply:70490618-601a-4309-ad32-4488318b9859<-9c3b6d1e-fc28-4275-b423-e30487699bae#4:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-02-05 13:08:36,611 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: receive installSnapshot: 70490618-601a-4309-ad32-4488318b9859->9c3b6d1e-fc28-4275-b423-e30487699bae#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-02-05 13:08:36,616 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "70490618-601a-4309-ad32-4488318b9859"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "ed216bc4-3c18-4c9d-881d-c81a0a0e45d8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-02-05 13:08:36,630 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: set configuration 7: [70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-02-05 13:08:17,659 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm2.org_1   | 2022-02-05 13:08:17,718 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm2.org_1   | 2022-02-05 13:08:17,718 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm2.org_1   | 2022-02-05 13:08:18,503 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-02-05 13:08:18,503 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm2.org_1   | 2022-02-05 13:08:18,503 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm2.org_1   | 2022-02-05 13:08:18,747 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm2.org_1   | 2022-02-05 13:08:18,758 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-02-05 13:08:18,922 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm2.org_1   | 2022-02-05 13:08:18,965 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm2.org_1   | 2022-02-05 13:08:18,970 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm2.org_1   | 2022-02-05 13:08:18,971 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-02-05 13:08:18,971 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm2.org_1   | 2022-02-05 13:08:19,013 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm2.org_1   | 2022-02-05 13:08:19,015 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-02-05 13:08:19,016 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm2.org_1   | 2022-02-05 13:08:19,016 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm2.org_1   | 2022-02-05 13:08:19,176 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-02-05 13:08:19,177 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-02-05 13:08:19,178 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm2.org_1   | 2022-02-05 13:08:19,613 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6e057374] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm2.org_1   | 2022-02-05 13:08:19,624 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm2.org_1   | 2022-02-05 13:08:19,624 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm2.org_1   | 2022-02-05 13:08:19,634 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm2.org_1   | 2022-02-05 13:08:19,677 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @17565ms to org.eclipse.jetty.util.log.Slf4jLog
scm2.org_1   | 2022-02-05 13:08:19,927 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm2.org_1   | 2022-02-05 13:08:19,939 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm2.org_1   | 2022-02-05 13:08:19,947 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm2.org_1   | 2022-02-05 13:08:19,947 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm2.org_1   | 2022-02-05 13:08:19,947 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm2.org_1   | 2022-02-05 13:08:20,014 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm2.org_1   | 2022-02-05 13:08:20,100 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm2.org_1   | 2022-02-05 13:08:20,111 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-LTS
scm2.org_1   | 2022-02-05 13:08:20,239 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm2.org_1   | 2022-02-05 13:08:20,242 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm2.org_1   | 2022-02-05 13:08:20,267 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm2.org_1   | 2022-02-05 13:08:20,297 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm2.org_1   | 2022-02-05 13:08:20,304 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@22109f72{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm2.org_1   | 2022-02-05 13:08:20,304 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@71dbfe64{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm2.org_1   | 2022-02-05 13:08:20,577 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm2.org_1   | 2022-02-05 13:08:20,597 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1d07fb2{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-9575110525146357040/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm2.org_1   | 2022-02-05 13:08:20,627 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@26169be3{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm2.org_1   | 2022-02-05 13:08:20,627 [Listener at 0.0.0.0/9860] INFO server.Server: Started @18515ms
scm2.org_1   | 2022-02-05 13:08:20,629 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm2.org_1   | 2022-02-05 13:08:20,632 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm2.org_1   | 2022-02-05 13:08:20,634 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 172 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:10:01,256 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:198)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:191)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:150)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 173 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:10:01,739 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47038
recon_1      | 2022-02-05 13:10:01,766 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:10:01,767 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=fc6ad7e7-85fa-4af9-97bb-5989287a910b. Trying to get from SCM.
recon_1      | 2022-02-05 13:10:01,816 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: fc6ad7e7-85fa-4af9-97bb-5989287a910b, Nodes: 3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-02-05T13:09:31.352Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-02-05 13:10:01,817 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: fc6ad7e7-85fa-4af9-97bb-5989287a910b, Nodes: 3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-02-05T13:09:31.352Z[UTC]].
recon_1      | 2022-02-05 13:10:01,817 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=fc6ad7e7-85fa-4af9-97bb-5989287a910b reported by 3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 938407921790, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-02-05 13:10:01,818 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: fc6ad7e7-85fa-4af9-97bb-5989287a910b, Nodes: 3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:3bd141d9-8d6a-4889-940a-437a7867e049, CreationTimestamp2022-02-05T13:09:31.352Z[UTC]] moved to OPEN state
recon_1      | 2022-02-05 13:10:01,818 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=f1ca961d-d578-498d-933d-dd33d84c9d7f reported by 3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 938407921790, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-02-05 13:10:02,584 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59432
recon_1      | 2022-02-05 13:10:02,728 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:10:02,730 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=8861f5bd-9ae4-4203-8e86-df306916ac0e. Trying to get from SCM.
recon_1      | 2022-02-05 13:10:02,755 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 8861f5bd-9ae4-4203-8e86-df306916ac0e, Nodes: 9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:9905eb49-ac94-40b9-a1a3-f35673531eee, CreationTimestamp2022-02-05T13:09:30.372Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-02-05 13:10:02,757 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 8861f5bd-9ae4-4203-8e86-df306916ac0e, Nodes: 9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:9905eb49-ac94-40b9-a1a3-f35673531eee, CreationTimestamp2022-02-05T13:09:30.372Z[UTC]].
recon_1      | 2022-02-05 13:10:02,757 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=8861f5bd-9ae4-4203-8e86-df306916ac0e reported by 9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 936463488335, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-02-05 13:10:02,757 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 8861f5bd-9ae4-4203-8e86-df306916ac0e, Nodes: 9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:9905eb49-ac94-40b9-a1a3-f35673531eee, CreationTimestamp2022-02-05T13:09:30.372Z[UTC]] moved to OPEN state
recon_1      | 2022-02-05 13:10:02,758 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=f1ca961d-d578-498d-933d-dd33d84c9d7f reported by 9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 936463488335, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-02-05 13:10:03,262 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:198)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:191)
scm2.org_1   | 2022-02-05 13:08:39,186 [grpc-default-executor-0] INFO server.RaftServer$Division: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7: set configuration 11: [9c3b6d1e-fc28-4275-b423-e30487699bae|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-02-05 13:08:39,225 [grpc-default-executor-0] INFO server.RaftServer$Division: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7: set configuration 13: [9c3b6d1e-fc28-4275-b423-e30487699bae|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-02-05 13:08:58,797 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-02-05 13:09:00,416 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-02-05 13:09:02,913 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-02-05 13:09:05,648 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-02-05 13:09:05,901 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-02-05 13:09:10,690 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-02-05 13:09:25,586 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40986
scm2.org_1   | 2022-02-05 13:09:25,632 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:09:26,982 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51342
scm2.org_1   | 2022-02-05 13:09:27,131 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:09:29,467 [IPC Server handler 6 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/3bd141d9-8d6a-4889-940a-437a7867e049
scm2.org_1   | 2022-02-05 13:09:29,564 [IPC Server handler 6 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 938407921790, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-02-05 13:09:29,667 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm2.org_1   | 2022-02-05 13:09:29,757 [IPC Server handler 0 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/9905eb49-ac94-40b9-a1a3-f35673531eee
scm2.org_1   | 2022-02-05 13:09:29,694 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-02-05 13:09:29,863 [IPC Server handler 0 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 936463488335, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-02-05 13:09:29,863 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-02-05 13:09:29,886 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm2.org_1   | 2022-02-05 13:09:31,158 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38564
scm2.org_1   | 2022-02-05 13:09:31,246 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:09:31,461 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 8861f5bd-9ae4-4203-8e86-df306916ac0e, Nodes: 9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-02-05T13:09:30.372Z[UTC]].
scm2.org_1   | 2022-02-05 13:09:31,461 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-02-05 13:09:31,647 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: fc6ad7e7-85fa-4af9-97bb-5989287a910b, Nodes: 3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-02-05T13:09:31.352Z[UTC]].
scm2.org_1   | 2022-02-05 13:09:31,647 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-02-05 13:09:32,738 [IPC Server handler 6 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/a527daad-fcfc-4913-bb86-57ba7fce9b83
scm2.org_1   | 2022-02-05 13:09:32,742 [IPC Server handler 6 on default port 9861] INFO node.SCMNodeManager: Registered Data node : a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 941044329628, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-02-05 13:09:32,743 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-02-05 13:09:32,745 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm1.org_1   | 2022-02-05 13:07:48,106 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm1.org_1   | 2022-02-05 13:07:48,108 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm1.org_1   | 2022-02-05 13:07:48,109 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-02-05 13:07:48,109 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm1.org_1   | 2022-02-05 13:07:48,154 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm1.org_1   | 2022-02-05 13:07:48,155 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm1.org_1   | 2022-02-05 13:07:48,180 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm1.org_1   | 2022-02-05 13:07:48,180 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-02-05 13:07:48,241 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@72cf159f] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm1.org_1   | 2022-02-05 13:07:48,252 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm1.org_1   | 2022-02-05 13:07:48,252 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm1.org_1   | 2022-02-05 13:07:48,253 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm1.org_1   | 2022-02-05 13:07:48,276 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @6522ms to org.eclipse.jetty.util.log.Slf4jLog
scm1.org_1   | 2022-02-05 13:07:48,520 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm1.org_1   | 2022-02-05 13:07:48,526 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm1.org_1   | 2022-02-05 13:07:48,527 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm1.org_1   | 2022-02-05 13:07:48,527 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm1.org_1   | 2022-02-05 13:07:48,527 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm1.org_1   | 2022-02-05 13:07:48,529 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm1.org_1   | 2022-02-05 13:07:48,555 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:38015
scm1.org_1   | 2022-02-05 13:07:48,579 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-02-05 13:07:48,622 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm1.org_1   | 2022-02-05 13:07:48,623 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-LTS
scm1.org_1   | 2022-02-05 13:07:48,718 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm1.org_1   | 2022-02-05 13:07:48,718 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm1.org_1   | 2022-02-05 13:07:48,727 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm1.org_1   | 2022-02-05 13:07:48,763 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm1.org_1   | 2022-02-05 13:07:48,771 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5dfaa2f0{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm1.org_1   | 2022-02-05 13:07:48,771 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@f1e5f85{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm1.org_1   | 2022-02-05 13:07:48,962 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm1.org_1   | 2022-02-05 13:07:48,983 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1227ea21{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-9445065505229076315/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm1.org_1   | 2022-02-05 13:07:49,003 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@21d30ba5{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm1.org_1   | 2022-02-05 13:07:49,006 [Listener at 0.0.0.0/9860] INFO server.Server: Started @7252ms
scm1.org_1   | 2022-02-05 13:07:49,008 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm1.org_1   | 2022-02-05 13:07:49,009 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm1.org_1   | 2022-02-05 13:07:49,010 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm1.org_1   | 2022-02-05 13:07:50,150 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:50594
scm1.org_1   | 2022-02-05 13:07:50,177 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:07:52,642 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-FollowerState] INFO impl.FollowerState: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5134260366ns, electionTimeout:5118ms
scm1.org_1   | 2022-02-05 13:07:52,643 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-FollowerState] INFO impl.RoleInfo: 70490618-601a-4309-ad32-4488318b9859: shutdown 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-FollowerState
scm1.org_1   | 2022-02-05 13:07:52,644 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-FollowerState] INFO server.RaftServer$Division: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
scm1.org_1   | 2022-02-05 13:07:52,647 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm1.org_1   | 2022-02-05 13:07:52,647 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-FollowerState] INFO impl.RoleInfo: 70490618-601a-4309-ad32-4488318b9859: start 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1
scm1.org_1   | 2022-02-05 13:07:52,662 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO impl.LeaderElection: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: [70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-02-05 13:07:52,663 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO impl.LeaderElection: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1 ELECTION round 0: result PASSED (term=2)
scm1.org_1   | 2022-02-05 13:07:52,664 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO impl.RoleInfo: 70490618-601a-4309-ad32-4488318b9859: shutdown 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1
scm1.org_1   | 2022-02-05 13:07:52,664 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO server.RaftServer$Division: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
scm1.org_1   | 2022-02-05 13:07:52,664 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
scm1.org_1   | 2022-02-05 13:07:52,664 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
scm1.org_1   | 2022-02-05 13:07:52,666 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO server.RaftServer$Division: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7: change Leader from null to 70490618-601a-4309-ad32-4488318b9859 at term 2 for becomeLeader, leader elected after 6964ms
scm1.org_1   | 2022-02-05 13:07:52,672 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2022-02-05 13:07:52,676 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-02-05 13:07:52,677 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-02-05 13:07:52,682 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm1.org_1   | 2022-02-05 13:07:52,682 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm2.org_1   | 2022-02-05 13:09:32,745 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm2.org_1   | 2022-02-05 13:09:32,746 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm2.org_1   | 2022-02-05 13:09:32,746 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-02-05 13:09:32,756 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm2.org_1   | 2022-02-05 13:09:32,756 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-02-05 13:09:32,886 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 194f5d50-3ed1-4cfa-a521-0d06090717c7, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-02-05T13:09:32.794Z[UTC]].
scm2.org_1   | 2022-02-05 13:09:32,890 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-02-05 13:09:33,014 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]].
scm2.org_1   | 2022-02-05 13:09:33,015 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-02-05 13:09:33,104 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: f1ca961d-d578-498d-933d-dd33d84c9d7f, Nodes: 9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-02-05T13:09:33.048Z[UTC]].
scm2.org_1   | 2022-02-05 13:09:33,106 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-02-05 13:09:36,074 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 194f5d50-3ed1-4cfa-a521-0d06090717c7, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.794Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-02-05 13:09:36,478 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-02-05 13:09:36,975 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-02-05 13:09:41,877 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51396
scm2.org_1   | 2022-02-05 13:09:41,884 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-02-05 13:09:42,001 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:09:43,267 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-02-05 13:09:46,017 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41082
scm2.org_1   | 2022-02-05 13:09:46,078 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:150)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy43.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 174 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:10:03,266 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:198)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:191)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:150)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy43.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 175 failover attempts. Trying to failover immediately.
recon_1      | 2022-02-05 13:10:03,270 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:211)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:198)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:191)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:150)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:124)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | 2022-02-05 13:18:18,279 [qtp1431556341-21] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-ozone-test-1400913700, , key: ozone-test-9831389542/multipartKey3
s3g_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-1400913700 key: ozone-test-9831389542/multipartKey3
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:654)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:1027)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1231)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:762)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:534)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-02-05 13:18:26,726 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:26,729 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:26,731 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:27,259 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:27,261 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:27,265 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:27,315 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:28,087 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:28,089 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:28,092 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:28,636 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:28,638 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:28,642 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:29,167 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:29,169 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:29,170 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:29,181 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-5306351759/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-1400913700
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-1400913700key: ozone-test-5306351759/multipartKey5
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:156)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-02-05 13:18:29,699 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:29,701 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:29,703 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:29,714 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-1400913700, Key:ozone-test-4933169466/multipartKey. 
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:743)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:632)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:609)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:273)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-02-05 13:18:30,228 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:30,230 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:30,233 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:30,876 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:30,878 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:30,880 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:30,892 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:33,649 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:34,229 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:34,231 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:34,233 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:34,245 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:34,388 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:34,972 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:34,975 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:34,979 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:35,683 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:35,685 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:35,687 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:36,315 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:36,317 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:36,320 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:36,865 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:36,868 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:36,875 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:37,578 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:37,580 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:37,583 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:37,692 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:37,695 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:37,697 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:37,715 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:37,718 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:37,721 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:37,724 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:37,726 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:37,733 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:37,759 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:37,816 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:37,827 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:39,032 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:41,708 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:41,737 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:41,781 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:41,786 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:41,791 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:42,352 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:42,354 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:42,356 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:42,374 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:42,381 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:42,385 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:42,386 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:42,395 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:42,401 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:42,444 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:42,448 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:42,460 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:42,486 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:42,490 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:42,491 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:43,670 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:43,672 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:43,674 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:43,686 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:44,454 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:44,457 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:44,459 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:47,311 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:47,819 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:47,821 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:47,824 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
scm2.org_1   | 2022-02-05 13:09:46,084 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-02-05 13:09:46,306 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm2.org_1   | 2022-02-05 13:09:46,957 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-02-05 13:09:46,958 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm2.org_1   | 2022-02-05 13:09:46,958 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm2.org_1   | 2022-02-05 13:09:46,959 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm2.org_1   | 2022-02-05 13:09:46,959 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm2.org_1   | 2022-02-05 13:09:46,959 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-02-05 13:09:46,960 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm2.org_1   | 2022-02-05 13:10:01,811 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51476
scm2.org_1   | 2022-02-05 13:10:01,833 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:10:01,835 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: fc6ad7e7-85fa-4af9-97bb-5989287a910b, Nodes: 3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:3bd141d9-8d6a-4889-940a-437a7867e049, CreationTimestamp2022-02-05T13:09:31.352Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-02-05 13:10:02,580 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41138
scm2.org_1   | 2022-02-05 13:10:02,695 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:10:02,697 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 8861f5bd-9ae4-4203-8e86-df306916ac0e, Nodes: 9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:9905eb49-ac94-40b9-a1a3-f35673531eee, CreationTimestamp2022-02-05T13:09:30.372Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-02-05 13:10:17,068 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38734
scm2.org_1   | 2022-02-05 13:10:17,086 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:10:23,217 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51546
scm2.org_1   | 2022-02-05 13:10:23,275 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:10:23,278 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: f1ca961d-d578-498d-933d-dd33d84c9d7f, Nodes: 9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:3bd141d9-8d6a-4889-940a-437a7867e049, CreationTimestamp2022-02-05T13:09:33.048Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-02-05 13:10:24,743 [ed216bc4-3c18-4c9d-881d-c81a0a0e45d8@group-EDDF767648B7-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm2.org_1   | 2022-02-05 13:10:28,721 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38780
scm2.org_1   | 2022-02-05 13:10:28,799 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:10:29,249 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41230
scm2.org_1   | 2022-02-05 13:10:29,302 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:10:58,723 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38872
scm3.org_1   | 2022-02-05 13:08:36,631 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: reply installSnapshot: 70490618-601a-4309-ad32-4488318b9859<-9c3b6d1e-fc28-4275-b423-e30487699bae#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2022-02-05 13:08:36,636 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: 9c3b6d1e-fc28-4275-b423-e30487699bae: Completed INSTALL_SNAPSHOT, lastRequest: 70490618-601a-4309-ad32-4488318b9859->9c3b6d1e-fc28-4275-b423-e30487699bae#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-02-05 13:08:36,664 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: Failed appendEntries as snapshot (10) installation is in progress
scm1.org_1   | 2022-02-05 13:07:52,682 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm1.org_1   | 2022-02-05 13:07:52,686 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-02-05 13:07:52,688 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm1.org_1   | 2022-02-05 13:07:52,690 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO impl.RoleInfo: 70490618-601a-4309-ad32-4488318b9859: start 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderStateImpl
scm1.org_1   | 2022-02-05 13:07:52,696 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm1.org_1   | 2022-02-05 13:07:52,705 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/fc180783-fb1e-4dd7-af87-eddf767648b7/current/log_inprogress_0 to /data/metadata/scm-ha/fc180783-fb1e-4dd7-af87-eddf767648b7/current/log_0-0
scm1.org_1   | 2022-02-05 13:07:52,716 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderElection1] INFO server.RaftServer$Division: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7: set configuration 1: [70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-02-05 13:07:52,726 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/fc180783-fb1e-4dd7-af87-eddf767648b7/current/log_inprogress_1
scm1.org_1   | 2022-02-05 13:07:52,733 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
scm1.org_1   | 2022-02-05 13:07:52,733 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
scm1.org_1   | 2022-02-05 13:07:52,734 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-02-05 13:07:52,735 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm1.org_1   | 2022-02-05 13:07:52,735 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm1.org_1   | 2022-02-05 13:07:52,736 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm1.org_1   | 2022-02-05 13:07:52,756 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-02-05 13:07:52,756 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm1.org_1   | 2022-02-05 13:07:52,866 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48166
scm1.org_1   | 2022-02-05 13:07:52,887 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-02-05 13:07:59,626 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:46166
scm1.org_1   | 2022-02-05 13:07:59,647 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-02-05 13:07:59,814 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm2.org, nodeId: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8
scm1.org_1   | 2022-02-05 13:08:01,395 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-02-05 13:08:01,399 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm1.org_1   | 2022-02-05 13:08:01,400 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm1.org_1   | 2022-02-05 13:08:03,397 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48338
scm1.org_1   | 2022-02-05 13:08:03,462 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-02-05 13:08:11,378 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:50930
scm1.org_1   | 2022-02-05 13:08:11,422 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:08:11,425 [IPC Server handler 3 on default port 9863] INFO ha.SCMRatisServerImpl: 70490618-601a-4309-ad32-4488318b9859: Submitting SetConfiguration request to Ratis server with new SCM peers list: [70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-02-05 13:08:11,431 [IPC Server handler 3 on default port 9863] INFO server.RaftServer$Division: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7: receive setConfiguration SetConfigurationRequest:client-D875AB9100C3->70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7, cid=0, seq=0, RW, null, peers:[70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-02-05 13:08:11,431 [IPC Server handler 3 on default port 9863] INFO server.RaftServer$Division: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-D875AB9100C3->70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7, cid=0, seq=0, RW, null, peers:[70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-02-05 13:08:11,445 [IPC Server handler 3 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm1.org_1   | 2022-02-05 13:08:11,449 [IPC Server handler 3 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-02-05 13:08:11,450 [IPC Server handler 3 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
scm1.org_1   | 2022-02-05 13:08:11,458 [IPC Server handler 3 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm1.org_1   | 2022-02-05 13:08:11,465 [IPC Server handler 3 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-02-05 13:08:11,465 [IPC Server handler 3 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-02-05 13:08:11,508 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->ed216bc4-3c18-4c9d-881d-c81a0a0e45d8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->ed216bc4-3c18-4c9d-881d-c81a0a0e45d8-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:4)
scm3.org_1   | 2022-02-05 13:08:36,677 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: inconsistency entries. Reply:70490618-601a-4309-ad32-4488318b9859<-9c3b6d1e-fc28-4275-b423-e30487699bae#5:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-02-05 13:08:36,702 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: receive installSnapshot: 70490618-601a-4309-ad32-4488318b9859->9c3b6d1e-fc28-4275-b423-e30487699bae#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-02-05 13:08:36,704 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "70490618-601a-4309-ad32-4488318b9859"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "ed216bc4-3c18-4c9d-881d-c81a0a0e45d8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-02-05 13:08:36,706 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: set configuration 7: [70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-02-05 13:08:36,706 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: reply installSnapshot: 70490618-601a-4309-ad32-4488318b9859<-9c3b6d1e-fc28-4275-b423-e30487699bae#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2022-02-05 13:08:36,709 [pool-16-thread-1] INFO ha.SCMHAManagerImpl: Installing checkpoint with SCMTransactionInfo 2#10
scm3.org_1   | 2022-02-05 13:08:36,719 [pool-16-thread-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: StateMachine successfully installed snapshot index 10. Reloading the StateMachine.
scm3.org_1   | 2022-02-05 13:08:36,719 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: 9c3b6d1e-fc28-4275-b423-e30487699bae: Completed INSTALL_SNAPSHOT, lastRequest: 70490618-601a-4309-ad32-4488318b9859->9c3b6d1e-fc28-4275-b423-e30487699bae#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-02-05 13:08:36,724 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-SegmentedRaftLogWorker: flushIndex: setUnconditionally -1 -> 10
scm3.org_1   | 2022-02-05 13:08:36,729 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally -1 -> 10
scm3.org_1   | 2022-02-05 13:08:36,734 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2022-02-05 13:08:36,765 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: inconsistency entries. Reply:70490618-601a-4309-ad32-4488318b9859<-9c3b6d1e-fc28-4275-b423-e30487699bae#6:FAIL-t2,INCONSISTENCY,nextIndex=11,followerCommit=-1
scm3.org_1   | 2022-02-05 13:08:36,767 [pool-16-thread-1] INFO raftlog.RaftLog: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-SegmentedRaftLog: snapshotIndex: updateIncreasingly -1 -> 10
scm3.org_1   | 2022-02-05 13:08:36,794 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: receive installSnapshot: 70490618-601a-4309-ad32-4488318b9859->9c3b6d1e-fc28-4275-b423-e30487699bae#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-02-05 13:08:36,843 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "70490618-601a-4309-ad32-4488318b9859"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "ed216bc4-3c18-4c9d-881d-c81a0a0e45d8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-02-05 13:08:36,851 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: set configuration 7: [70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-02-05 13:08:36,859 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: reply installSnapshot: 70490618-601a-4309-ad32-4488318b9859<-9c3b6d1e-fc28-4275-b423-e30487699bae#0:FAIL-t2,IN_PROGRESS
scm3.org_1   | 2022-02-05 13:08:36,916 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: 9c3b6d1e-fc28-4275-b423-e30487699bae: Completed INSTALL_SNAPSHOT, lastRequest: 70490618-601a-4309-ad32-4488318b9859->9c3b6d1e-fc28-4275-b423-e30487699bae#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-02-05 13:08:36,952 [grpc-default-executor-0] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: Failed appendEntries as snapshot (10) installation is in progress
scm3.org_1   | 2022-02-05 13:08:36,957 [grpc-default-executor-0] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: inconsistency entries. Reply:70490618-601a-4309-ad32-4488318b9859<-9c3b6d1e-fc28-4275-b423-e30487699bae#7:FAIL-t2,INCONSISTENCY,nextIndex=11,followerCommit=10
scm3.org_1   | 2022-02-05 13:08:37,002 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: receive installSnapshot: 70490618-601a-4309-ad32-4488318b9859->9c3b6d1e-fc28-4275-b423-e30487699bae#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-02-05 13:08:37,010 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: InstallSnapshot notification result: SNAPSHOT_INSTALLED, at index: 10
scm3.org_1   | 2022-02-05 13:08:37,014 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: set new configuration index: 7
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "70490618-601a-4309-ad32-4488318b9859"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "ed216bc4-3c18-4c9d-881d-c81a0a0e45d8"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-02-05 13:08:37,014 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: set configuration 7: [70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-02-05 13:08:37,015 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: reply installSnapshot: 70490618-601a-4309-ad32-4488318b9859<-9c3b6d1e-fc28-4275-b423-e30487699bae#0:FAIL-t2,SNAPSHOT_INSTALLED,snapshotIndex=10
scm3.org_1   | 2022-02-05 13:08:37,022 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: 9c3b6d1e-fc28-4275-b423-e30487699bae: Completed INSTALL_SNAPSHOT, lastRequest: 70490618-601a-4309-ad32-4488318b9859->9c3b6d1e-fc28-4275-b423-e30487699bae#0-t2,notify:(t:2, i:10)
scm3.org_1   | 2022-02-05 13:08:37,163 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Installing checkpoint with SCMTransactionInfo 2#10
scm3.org_1   | 2022-02-05 13:08:37,273 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Replaced DB with checkpoint, term: 2, index: 10
scm3.org_1   | 2022-02-05 13:08:37,279 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-02-05 13:08:37,281 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-02-05 13:08:37,486 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO ha.SequenceIdGenerator: reinitialize SequenceIdGenerator.
scm3.org_1   | 2022-02-05 13:08:37,499 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm3.org_1   | 2022-02-05 13:08:37,514 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO ha.SCMHAManagerImpl: Reloaded SCM state with Term: 2 and Index: 10
scm3.org_1   | 2022-02-05 13:08:37,515 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO impl.StateMachineUpdater: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater: snapshotIndex: setUnconditionally -1 -> 10
scm3.org_1   | 2022-02-05 13:08:37,516 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO impl.StateMachineUpdater: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater: appliedIndex: setUnconditionally -1 -> 10
scm3.org_1   | 2022-02-05 13:08:39,175 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: set configuration 11: [9c3b6d1e-fc28-4275-b423-e30487699bae|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-02-05 13:08:39,195 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-SegmentedRaftLogWorker: Starting segment from index:11
scm3.org_1   | 2022-02-05 13:08:39,406 [grpc-default-executor-1] INFO server.RaftServer$Division: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7: set configuration 13: [9c3b6d1e-fc28-4275-b423-e30487699bae|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-02-05 13:08:39,700 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm3 to group group-EDDF767648B7:[9c3b6d1e-fc28-4275-b423-e30487699bae|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-02-05 13:08:39,740 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm3.org_1   | 2022-02-05 13:08:39,804 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm3.org_1   | 2022-02-05 13:08:39,812 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm3.org_1   | 2022-02-05 13:08:40,279 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/fc180783-fb1e-4dd7-af87-eddf767648b7/current/log_inprogress_11
scm3.org_1   | 2022-02-05 13:08:40,430 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-02-05 13:08:40,454 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm3.org_1   | 2022-02-05 13:08:40,561 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm3.org_1   | 2022-02-05 13:08:40,581 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm3.org_1   | 2022-02-05 13:08:40,873 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm3.org_1   | 2022-02-05 13:08:40,928 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm3.org_1   | 2022-02-05 13:08:40,928 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm3.org_1   | 2022-02-05 13:08:42,267 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm3.org_1   | 2022-02-05 13:08:42,315 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-02-05 13:08:42,640 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm3.org_1   | 2022-02-05 13:08:42,723 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-02-05 13:08:42,725 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm3.org_1   | 2022-02-05 13:08:43,067 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm3.org_1   | 2022-02-05 13:08:43,091 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm3.org_1   | 2022-02-05 13:08:43,108 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-02-05 13:08:43,112 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm3.org_1   | 2022-02-05 13:08:43,289 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm3.org_1   | 2022-02-05 13:08:43,312 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-02-05 13:08:43,312 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm3.org_1   | 2022-02-05 13:08:43,312 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm3.org_1   | 2022-02-05 13:08:43,727 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm3.org_1   | 2022-02-05 13:08:43,727 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm3.org_1   | 2022-02-05 13:08:43,727 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm3.org_1   | 2022-02-05 13:08:45,067 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@113b39e9] INFO util.JvmPauseMonitor: Starting JVM pause monitor
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy43.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 176 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-02-05 13:10:06,522 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | 2022-02-05 13:18:18,813 [qtp1431556341-17] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-ozone-test-1400913700, , key: ozone-test-9831389542/multipartKey3
s3g_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-1400913700 key: ozone-test-9831389542/multipartKey3
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:654)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:1027)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1231)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:762)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:534)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
scm1.org_1   | 2022-02-05 13:08:11,533 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->ed216bc4-3c18-4c9d-881d-c81a0a0e45d8-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->ed216bc4-3c18-4c9d-881d-c81a0a0e45d8-GrpcLogAppender: send 70490618-601a-4309-ad32-4488318b9859->ed216bc4-3c18-4c9d-881d-c81a0a0e45d8#0-t2,notify:(t:2, i:4)
scm1.org_1   | 2022-02-05 13:08:12,990 [grpc-default-executor-1] INFO ha.SCMDBCheckpointProvider: Received request to obtain SCM DB checkpoint snapshot
scm1.org_1   | 2022-02-05 13:08:13,050 [grpc-default-executor-1] INFO db.RDBCheckpointManager: Created checkpoint at /data/metadata/db.checkpoints/scm.db_checkpoint_1644066492991 in 58 milliseconds
scm1.org_1   | 2022-02-05 13:08:13,262 [grpc-default-executor-1] INFO ha.SCMGrpcOutputStream: Sent 7554 bytes for cluster CID-fc180783-fb1e-4dd7-af87-eddf767648b7
scm1.org_1   | 2022-02-05 13:08:13,275 [grpc-default-executor-1] INFO ha.SCMDBCheckpointProvider: Time taken to write the checkpoint to response output stream: 224 milliseconds
scm1.org_1   | 2022-02-05 13:08:13,276 [grpc-default-executor-1] INFO db.RocksDBCheckpoint: Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/scm.db_checkpoint_1644066492991
scm1.org_1   | 2022-02-05 13:08:13,872 [grpc-default-executor-1] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->ed216bc4-3c18-4c9d-881d-c81a0a0e45d8-InstallSnapshotResponseHandler: received the first reply 70490618-601a-4309-ad32-4488318b9859<-ed216bc4-3c18-4c9d-881d-c81a0a0e45d8#0:FAIL-t0,SNAPSHOT_INSTALLED,snapshotIndex=4
scm1.org_1   | 2022-02-05 13:08:13,880 [grpc-default-executor-1] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->ed216bc4-3c18-4c9d-881d-c81a0a0e45d8-InstallSnapshotResponseHandler: Follower installed snapshot at index 4
scm1.org_1   | 2022-02-05 13:08:13,899 [grpc-default-executor-1] INFO leader.FollowerInfo: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->ed216bc4-3c18-4c9d-881d-c81a0a0e45d8: snapshotIndex: setUnconditionally 0 -> 4
scm1.org_1   | 2022-02-05 13:08:13,899 [grpc-default-executor-1] INFO leader.FollowerInfo: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->ed216bc4-3c18-4c9d-881d-c81a0a0e45d8: matchIndex: setUnconditionally 0 -> 4
scm1.org_1   | 2022-02-05 13:08:13,899 [grpc-default-executor-1] INFO leader.FollowerInfo: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->ed216bc4-3c18-4c9d-881d-c81a0a0e45d8: nextIndex: setUnconditionally 0 -> 5
scm1.org_1   | 2022-02-05 13:08:13,899 [grpc-default-executor-1] INFO leader.FollowerInfo: Follower 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->ed216bc4-3c18-4c9d-881d-c81a0a0e45d8 acknowledged installing snapshot
scm1.org_1   | 2022-02-05 13:08:13,900 [grpc-default-executor-1] INFO leader.FollowerInfo: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->ed216bc4-3c18-4c9d-881d-c81a0a0e45d8: nextIndex: updateToMax old=5, new=5, updated? false
scm1.org_1   | 2022-02-05 13:08:15,152 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48522
scm1.org_1   | 2022-02-05 13:08:15,191 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-02-05 13:08:16,057 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:42446
scm1.org_1   | 2022-02-05 13:08:16,069 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:08:17,007 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderStateImpl] INFO server.RaftServer$Division: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7: set configuration 5: [70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|priority:0], old=[70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2022-02-05 13:08:17,292 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderStateImpl] INFO server.RaftServer$Division: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7: set configuration 7: [70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|priority:0], old=null
scm1.org_1   | 2022-02-05 13:08:17,307 [IPC Server handler 3 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: ed216bc4-3c18-4c9d-881d-c81a0a0e45d8.
scm1.org_1   | 2022-02-05 13:08:17,798 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:50190
scm1.org_1   | 2022-02-05 13:08:17,817 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-02-05 13:08:17,818 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm3.org, nodeId: 9c3b6d1e-fc28-4275-b423-e30487699bae
scm1.org_1   | 2022-02-05 13:08:18,292 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-02-05 13:08:19,422 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:46470
scm1.org_1   | 2022-02-05 13:08:19,438 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-02-05 13:08:26,178 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48674
scm1.org_1   | 2022-02-05 13:08:26,226 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-02-05 13:08:31,246 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:42638
scm1.org_1   | 2022-02-05 13:08:31,402 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:08:31,409 [IPC Server handler 0 on default port 9863] INFO ha.SCMRatisServerImpl: 70490618-601a-4309-ad32-4488318b9859: Submitting SetConfiguration request to Ratis server with new SCM peers list: [70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|priority:0, 9c3b6d1e-fc28-4275-b423-e30487699bae|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-02-05 13:08:31,410 [IPC Server handler 0 on default port 9863] INFO server.RaftServer$Division: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7: receive setConfiguration SetConfigurationRequest:client-D875AB9100C3->70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7, cid=1, seq=0, RW, null, peers:[70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|priority:0, 9c3b6d1e-fc28-4275-b423-e30487699bae|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-02-05 13:08:31,412 [IPC Server handler 0 on default port 9863] INFO server.RaftServer$Division: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-D875AB9100C3->70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7, cid=1, seq=0, RW, null, peers:[70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|priority:0, 9c3b6d1e-fc28-4275-b423-e30487699bae|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-02-05 13:08:31,413 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm1.org_1   | 2022-02-05 13:08:31,418 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-02-05 13:08:31,420 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
scm1.org_1   | 2022-02-05 13:08:31,421 [IPC Server handler 0 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm1.org_1   | 2022-02-05 13:08:31,426 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-02-05 13:08:31,426 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-02-05 13:08:31,444 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2022-02-05 13:08:31,446 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender: send 70490618-601a-4309-ad32-4488318b9859->9c3b6d1e-fc28-4275-b423-e30487699bae#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2022-02-05 13:08:35,538 [grpc-default-executor-1] INFO ha.SCMDBCheckpointProvider: Received request to obtain SCM DB checkpoint snapshot
scm1.org_1   | 2022-02-05 13:08:35,651 [grpc-default-executor-1] INFO db.RDBCheckpointManager: Created checkpoint at /data/metadata/db.checkpoints/scm.db_checkpoint_1644066515538 in 112 milliseconds
scm1.org_1   | 2022-02-05 13:08:35,843 [grpc-default-executor-1] INFO ha.SCMGrpcOutputStream: Sent 8691 bytes for cluster CID-fc180783-fb1e-4dd7-af87-eddf767648b7
scm1.org_1   | 2022-02-05 13:08:35,846 [grpc-default-executor-1] INFO ha.SCMDBCheckpointProvider: Time taken to write the checkpoint to response output stream: 191 milliseconds
scm1.org_1   | 2022-02-05 13:08:35,848 [grpc-default-executor-1] INFO db.RocksDBCheckpoint: Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/scm.db_checkpoint_1644066515538
scm1.org_1   | 2022-02-05 13:08:36,046 [grpc-default-executor-1] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-InstallSnapshotResponseHandler: received the first reply 70490618-601a-4309-ad32-4488318b9859<-9c3b6d1e-fc28-4275-b423-e30487699bae#0:FAIL-t0,IN_PROGRESS
scm1.org_1   | 2022-02-05 13:08:36,054 [grpc-default-executor-1] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-02-05 13:08:36,058 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2022-02-05 13:08:36,062 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender: send 70490618-601a-4309-ad32-4488318b9859->9c3b6d1e-fc28-4275-b423-e30487699bae#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2022-02-05 13:08:36,244 [grpc-default-executor-1] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-InstallSnapshotResponseHandler: received a reply 70490618-601a-4309-ad32-4488318b9859<-9c3b6d1e-fc28-4275-b423-e30487699bae#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-02-05 13:08:36,266 [grpc-default-executor-1] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-02-05 13:08:36,291 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2022-02-05 13:08:36,294 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender: send 70490618-601a-4309-ad32-4488318b9859->9c3b6d1e-fc28-4275-b423-e30487699bae#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2022-02-05 13:08:36,322 [grpc-default-executor-1] INFO leader.FollowerInfo: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-02-05 13:08:36,326 [grpc-default-executor-1] INFO leader.FollowerInfo: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-02-05 13:08:36,365 [grpc-default-executor-1] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-InstallSnapshotResponseHandler: received a reply 70490618-601a-4309-ad32-4488318b9859<-9c3b6d1e-fc28-4275-b423-e30487699bae#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-02-05 13:08:36,370 [grpc-default-executor-1] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-02-05 13:08:36,371 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2022-02-05 13:08:36,372 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender: send 70490618-601a-4309-ad32-4488318b9859->9c3b6d1e-fc28-4275-b423-e30487699bae#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2022-02-05 13:08:36,387 [grpc-default-executor-1] INFO leader.FollowerInfo: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-02-05 13:08:36,437 [grpc-default-executor-1] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-InstallSnapshotResponseHandler: received a reply 70490618-601a-4309-ad32-4488318b9859<-9c3b6d1e-fc28-4275-b423-e30487699bae#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-02-05 13:08:36,449 [grpc-default-executor-1] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-02-05 13:08:36,450 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2022-02-05 13:08:36,454 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender: send 70490618-601a-4309-ad32-4488318b9859->9c3b6d1e-fc28-4275-b423-e30487699bae#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2022-02-05 13:08:36,508 [grpc-default-executor-1] INFO leader.FollowerInfo: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-02-05 13:08:36,555 [grpc-default-executor-1] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-InstallSnapshotResponseHandler: received a reply 70490618-601a-4309-ad32-4488318b9859<-9c3b6d1e-fc28-4275-b423-e30487699bae#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-02-05 13:08:36,555 [grpc-default-executor-1] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-02-05 13:08:36,558 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2022-02-05 13:08:36,562 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender: send 70490618-601a-4309-ad32-4488318b9859->9c3b6d1e-fc28-4275-b423-e30487699bae#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2022-02-05 13:08:36,627 [grpc-default-executor-1] INFO leader.FollowerInfo: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-02-05 13:08:36,658 [grpc-default-executor-1] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-InstallSnapshotResponseHandler: received a reply 70490618-601a-4309-ad32-4488318b9859<-9c3b6d1e-fc28-4275-b423-e30487699bae#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-02-05 13:08:36,658 [grpc-default-executor-1] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-02-05 13:08:36,661 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-02-05 13:10:06,979 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=f1ca961d-d578-498d-933d-dd33d84c9d7f reported by 3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 938407921790, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-02-05 13:10:07,807 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=f1ca961d-d578-498d-933d-dd33d84c9d7f reported by 9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 936463488335, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-02-05 13:10:17,006 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59844
recon_1      | 2022-02-05 13:10:17,012 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:10:23,223 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47108
recon_1      | 2022-02-05 13:10:23,270 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:10:23,271 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=f1ca961d-d578-498d-933d-dd33d84c9d7f reported by 3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 938407921790, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-02-05 13:10:58,744 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:10:58,938 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51676
scm2.org_1   | 2022-02-05 13:10:58,952 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:10:59,271 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41338
scm2.org_1   | 2022-02-05 13:10:59,290 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:11:28,697 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38960
scm2.org_1   | 2022-02-05 13:11:28,761 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:11:28,946 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51760
scm2.org_1   | 2022-02-05 13:11:28,974 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:11:29,239 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41422
scm2.org_1   | 2022-02-05 13:11:29,290 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:11:58,746 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39064
scm2.org_1   | 2022-02-05 13:11:58,766 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:11:58,936 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51864
scm2.org_1   | 2022-02-05 13:11:58,959 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:11:59,227 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41528
scm2.org_1   | 2022-02-05 13:11:59,275 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:12:28,723 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39156
scm2.org_1   | 2022-02-05 13:12:28,787 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:12:28,956 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51960
scm2.org_1   | 2022-02-05 13:12:28,972 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:12:29,222 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41622
scm2.org_1   | 2022-02-05 13:12:29,260 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:12:49,045 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41688
scm2.org_1   | 2022-02-05 13:12:49,110 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52038
scm2.org_1   | 2022-02-05 13:12:49,160 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39252
scm2.org_1   | 2022-02-05 13:12:49,175 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:12:49,201 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:12:49,274 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:13:08,638 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-02-05 13:13:19,135 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41784
scm2.org_1   | 2022-02-05 13:13:19,184 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:13:19,198 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39356
scm2.org_1   | 2022-02-05 13:13:19,214 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:13:19,216 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52140
scm2.org_1   | 2022-02-05 13:13:19,250 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:13:49,092 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39458
scm2.org_1   | 2022-02-05 13:13:49,093 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52254
scm2.org_1   | 2022-02-05 13:13:49,131 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41890
scm2.org_1   | 2022-02-05 13:13:49,155 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:13:49,189 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:13:49,194 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:14:19,078 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41986
scm2.org_1   | 2022-02-05 13:14:19,126 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52348
scm2.org_1   | 2022-02-05 13:14:19,141 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:14:19,146 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39550
scm2.org_1   | 2022-02-05 13:14:19,156 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:14:19,164 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:14:49,088 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42094
scm2.org_1   | 2022-02-05 13:14:49,100 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52446
scm2.org_1   | 2022-02-05 13:14:49,110 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39664
scm2.org_1   | 2022-02-05 13:14:49,152 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:14:49,153 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:14:49,196 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:15:19,083 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52544
scm2.org_1   | 2022-02-05 13:15:19,174 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39758
scm2.org_1   | 2022-02-05 13:15:19,177 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42186
scm2.org_1   | 2022-02-05 13:15:19,184 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:15:19,185 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:15:19,203 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:15:49,106 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42398
scm2.org_1   | 2022-02-05 13:15:49,112 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39956
scm2.org_1   | 2022-02-05 13:15:49,127 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52742
scm2.org_1   | 2022-02-05 13:15:49,145 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:15:49,162 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:15:49,190 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:16:19,077 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42462
scm2.org_1   | 2022-02-05 13:16:19,108 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:16:19,133 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40034
scm2.org_1   | 2022-02-05 13:16:19,159 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52818
scm2.org_1   | 2022-02-05 13:16:19,167 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:16:19,201 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:16:49,081 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52922
scm2.org_1   | 2022-02-05 13:16:49,082 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42568
scm2.org_1   | 2022-02-05 13:16:49,102 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:16:49,123 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40136
scm3.org_1   | 2022-02-05 13:08:45,202 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm3.org_1   | 2022-02-05 13:08:45,209 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm3.org_1   | 2022-02-05 13:08:45,214 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm3.org_1   | 2022-02-05 13:08:45,455 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @26091ms to org.eclipse.jetty.util.log.Slf4jLog
scm3.org_1   | 2022-02-05 13:08:46,321 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm3.org_1   | 2022-02-05 13:08:46,371 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm3.org_1   | 2022-02-05 13:08:46,386 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm3.org_1   | 2022-02-05 13:08:46,409 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm3.org_1   | 2022-02-05 13:08:46,414 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm3.org_1   | 2022-02-05 13:08:46,449 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm3.org_1   | 2022-02-05 13:08:46,751 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm3.org_1   | 2022-02-05 13:08:46,761 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-LTS
scm3.org_1   | 2022-02-05 13:08:47,073 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm3.org_1   | 2022-02-05 13:08:47,075 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm3.org_1   | 2022-02-05 13:08:47,102 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
scm3.org_1   | 2022-02-05 13:08:47,283 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2022-02-05 13:08:47,328 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@510cefb6{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm3.org_1   | 2022-02-05 13:08:47,347 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2139aa1f{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm3.org_1   | 2022-02-05 13:08:48,009 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2022-02-05 13:08:48,138 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@46f5030f{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-16513358305102530932/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm3.org_1   | 2022-02-05 13:08:48,226 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@f573dcb{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm3.org_1   | 2022-02-05 13:08:48,226 [Listener at 0.0.0.0/9860] INFO server.Server: Started @28862ms
scm3.org_1   | 2022-02-05 13:08:48,250 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm3.org_1   | 2022-02-05 13:08:48,250 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm3.org_1   | 2022-02-05 13:08:48,257 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm3.org_1   | 2022-02-05 13:08:48,686 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$420/0x000000084052f040@4f239a76] WARN util.JvmPauseMonitor: JvmPauseMonitor-9c3b6d1e-fc28-4275-b423-e30487699bae: Detected pause in JVM or host machine (eg GC): pause of approximately 137646303ns.
scm3.org_1   | GC pool 'ParNew' had collection(s): count=1 time=123ms
scm3.org_1   | 2022-02-05 13:08:59,061 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-02-05 13:08:59,078 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm3.org_1   | 2022-02-05 13:08:59,078 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm3.org_1   | 2022-02-05 13:09:00,412 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-02-05 13:09:02,917 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-02-05 13:09:05,641 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-02-05 13:09:05,910 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-02-05 13:09:10,706 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-02-05 13:09:25,680 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34956
scm2.org_1   | 2022-02-05 13:16:49,136 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:16:49,161 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:17:19,120 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42672
scm2.org_1   | 2022-02-05 13:17:19,124 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53032
scm2.org_1   | 2022-02-05 13:17:19,163 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40234
scm2.org_1   | 2022-02-05 13:17:19,243 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:17:19,248 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:17:19,258 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:17:49,105 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40344
scm2.org_1   | 2022-02-05 13:17:49,116 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53130
scm2.org_1   | 2022-02-05 13:17:49,134 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42798
scm2.org_1   | 2022-02-05 13:17:49,179 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:17:49,182 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:17:49,221 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:18:08,638 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-02-05 13:18:19,095 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42908
scm2.org_1   | 2022-02-05 13:18:19,106 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53258
scm2.org_1   | 2022-02-05 13:18:19,124 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:18:19,153 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40478
scm2.org_1   | 2022-02-05 13:18:19,170 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:18:19,197 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:18:49,073 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40634
scm2.org_1   | 2022-02-05 13:18:49,147 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53418
scm2.org_1   | 2022-02-05 13:18:49,156 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43064
scm2.org_1   | 2022-02-05 13:18:49,172 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:18:49,232 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:18:49,235 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:19:19,110 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40734
scm2.org_1   | 2022-02-05 13:19:19,120 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53532
scm2.org_1   | 2022-02-05 13:19:19,151 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43170
scm2.org_1   | 2022-02-05 13:19:19,160 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:19:19,170 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-02-05 13:10:23,272 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: f1ca961d-d578-498d-933d-dd33d84c9d7f, Nodes: 9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:3bd141d9-8d6a-4889-940a-437a7867e049, CreationTimestamp2022-02-05T13:09:33.048Z[UTC]] moved to OPEN state
recon_1      | 2022-02-05 13:10:28,689 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59890
recon_1      | 2022-02-05 13:10:28,810 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:10:28,828 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #1 got from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-02-05 13:10:28,984 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
recon_1      | 2022-02-05 13:10:29,289 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59528
recon_1      | 2022-02-05 13:10:29,319 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:10:58,695 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59982
recon_1      | 2022-02-05 13:10:58,744 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:10:58,951 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47230
recon_1      | 2022-02-05 13:10:58,962 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:10:59,253 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59632
recon_1      | 2022-02-05 13:10:59,265 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:11:06,528 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-02-05 13:11:06,528 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-02-05 13:11:06,576 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
om1_1        | 2022-02-05 13:18:48,384 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:48,386 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:48,391 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:48,412 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:48,422 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:48,427 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:48,438 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:48,443 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:48,453 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:48,487 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:48,964 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:49,902 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:49,904 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:49,906 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:50,422 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:50,425 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:50,427 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:50,436 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:51,248 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:51,250 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:51,252 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:54,252 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:54,780 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:54,782 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:54,784 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:55,341 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:55,342 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:55,345 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:55,366 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:55,369 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:55,376 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:55,385 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:55,388 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:55,389 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:55,423 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:58,622 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:59,190 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:59,191 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:59,194 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:59,206 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:59,210 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:59,213 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:59,233 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:59,237 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:59,238 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:59,267 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:59,388 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
scm1.org_1   | 2022-02-05 13:08:36,661 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender: send 70490618-601a-4309-ad32-4488318b9859->9c3b6d1e-fc28-4275-b423-e30487699bae#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2022-02-05 13:08:36,686 [grpc-default-executor-1] INFO leader.FollowerInfo: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-02-05 13:08:36,728 [grpc-default-executor-1] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-InstallSnapshotResponseHandler: received a reply 70490618-601a-4309-ad32-4488318b9859<-9c3b6d1e-fc28-4275-b423-e30487699bae#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-02-05 13:08:36,728 [grpc-default-executor-1] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-02-05 13:08:36,729 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2022-02-05 13:08:36,731 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender: send 70490618-601a-4309-ad32-4488318b9859->9c3b6d1e-fc28-4275-b423-e30487699bae#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2022-02-05 13:08:36,846 [grpc-default-executor-1] INFO leader.FollowerInfo: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae: nextIndex: updateUnconditionally 0 -> 11
scm1.org_1   | 2022-02-05 13:08:36,875 [grpc-default-executor-1] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-InstallSnapshotResponseHandler: received a reply 70490618-601a-4309-ad32-4488318b9859<-9c3b6d1e-fc28-4275-b423-e30487699bae#0:FAIL-t2,IN_PROGRESS
scm1.org_1   | 2022-02-05 13:08:36,878 [grpc-default-executor-1] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-InstallSnapshotResponseHandler: InstallSnapshot in progress.
scm1.org_1   | 2022-02-05 13:08:36,978 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender: followerNextIndex = 11 but logStartIndex = 0, notify follower to install snapshot-(t:2, i:10)
scm1.org_1   | 2022-02-05 13:08:36,979 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-GrpcLogAppender: send 70490618-601a-4309-ad32-4488318b9859->9c3b6d1e-fc28-4275-b423-e30487699bae#0-t2,notify:(t:2, i:10)
scm1.org_1   | 2022-02-05 13:08:36,982 [grpc-default-executor-1] INFO leader.FollowerInfo: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae: nextIndex: updateUnconditionally 11 -> 11
scm1.org_1   | 2022-02-05 13:08:37,045 [grpc-default-executor-1] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-InstallSnapshotResponseHandler: received a reply 70490618-601a-4309-ad32-4488318b9859<-9c3b6d1e-fc28-4275-b423-e30487699bae#0:FAIL-t2,SNAPSHOT_INSTALLED,snapshotIndex=10
scm1.org_1   | 2022-02-05 13:08:37,045 [grpc-default-executor-1] INFO server.GrpcLogAppender: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae-InstallSnapshotResponseHandler: Follower installed snapshot at index 10
scm1.org_1   | 2022-02-05 13:08:37,045 [grpc-default-executor-1] INFO leader.FollowerInfo: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae: snapshotIndex: setUnconditionally 0 -> 10
scm1.org_1   | 2022-02-05 13:08:37,045 [grpc-default-executor-1] INFO leader.FollowerInfo: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae: matchIndex: setUnconditionally 0 -> 10
scm1.org_1   | 2022-02-05 13:08:37,045 [grpc-default-executor-1] INFO leader.FollowerInfo: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae: nextIndex: setUnconditionally 11 -> 11
scm1.org_1   | 2022-02-05 13:08:37,045 [grpc-default-executor-1] INFO leader.FollowerInfo: Follower 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae acknowledged installing snapshot
scm1.org_1   | 2022-02-05 13:08:37,065 [grpc-default-executor-1] INFO leader.FollowerInfo: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7->9c3b6d1e-fc28-4275-b423-e30487699bae: nextIndex: updateToMax old=11, new=11, updated? false
scm1.org_1   | 2022-02-05 13:08:39,166 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderStateImpl] INFO server.RaftServer$Division: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7: set configuration 11: [9c3b6d1e-fc28-4275-b423-e30487699bae|rpc:scm3.org:9894|priority:0, 70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|priority:0], old=[70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-02-05 13:08:39,205 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-LeaderStateImpl] INFO server.RaftServer$Division: 70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7: set configuration 13: [9c3b6d1e-fc28-4275-b423-e30487699bae|rpc:scm3.org:9894|priority:0, 70490618-601a-4309-ad32-4488318b9859|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, ed216bc4-3c18-4c9d-881d-c81a0a0e45d8|rpc:scm2.org:9894|priority:0], old=null
scm1.org_1   | 2022-02-05 13:08:39,251 [IPC Server handler 0 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: 9c3b6d1e-fc28-4275-b423-e30487699bae.
scm1.org_1   | 2022-02-05 13:08:44,403 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:50422
scm1.org_1   | 2022-02-05 13:08:44,434 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-02-05 13:08:54,737 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:52184
scm1.org_1   | 2022-02-05 13:08:54,902 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:55262
scm1.org_1   | 2022-02-05 13:08:54,977 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:08:55,063 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:42320
scm1.org_1   | 2022-02-05 13:08:55,076 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:08:55,222 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:08:57,947 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54312
scm1.org_1   | 2022-02-05 13:08:58,038 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-02-05 13:08:58,042 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn f6267b87e946, UUID: 9905eb49-ac94-40b9-a1a3-f35673531eee
scm1.org_1   | 2022-02-05 13:08:58,794 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-02-05 13:08:59,894 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53430
scm1.org_1   | 2022-02-05 13:09:00,030 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-02-05 13:09:00,030 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn e3be6b71356d, UUID: 3bd141d9-8d6a-4889-940a-437a7867e049
scm1.org_1   | 2022-02-05 13:09:00,369 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-02-05 13:09:01,452 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48820
scm1.org_1   | 2022-02-05 13:09:01,705 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-02-05 13:09:02,550 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39050
scm1.org_1   | 2022-02-05 13:09:02,682 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-02-05 13:09:02,682 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 1e40b8f48f78, UUID: a527daad-fcfc-4913-bb86-57ba7fce9b83
scm1.org_1   | 2022-02-05 13:09:02,895 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-02-05 13:09:05,363 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:58456
scm1.org_1   | 2022-02-05 13:09:05,396 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-02-05 13:09:05,406 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om2, UUID: 174dac4c-8d44-4d64-8b5a-9042894ad2be
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | 2022-02-05 13:18:25,205 [qtp1431556341-21] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-ozone-test-1400913700, , key: ozone-test-9831389542/multipartKey3
s3g_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-1400913700 key: ozone-test-9831389542/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-1400913700/ozone-test-9831389542/multipartKey3-4aa6b580-8307-4ca0-89fa-b8b99779129d-107745581312966689-1
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:654)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:1027)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1231)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:762)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:534)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
scm3.org_1   | 2022-02-05 13:09:25,709 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:09:27,039 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44060
scm3.org_1   | 2022-02-05 13:09:27,178 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:09:29,278 [IPC Server handler 5 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/3bd141d9-8d6a-4889-940a-437a7867e049
scm3.org_1   | 2022-02-05 13:09:29,311 [IPC Server handler 5 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 938407921790, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2022-02-05 13:09:29,421 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-02-05 13:09:29,540 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm3.org_1   | 2022-02-05 13:09:29,699 [IPC Server handler 57 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/9905eb49-ac94-40b9-a1a3-f35673531eee
scm3.org_1   | 2022-02-05 13:09:29,730 [IPC Server handler 57 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 936463488335, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2022-02-05 13:09:29,741 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm3.org_1   | 2022-02-05 13:09:29,741 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-02-05 13:09:30,819 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46362
scm3.org_1   | 2022-02-05 13:09:30,926 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:09:31,468 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$420/0x000000084052f040@4f239a76] WARN util.JvmPauseMonitor: JvmPauseMonitor-9c3b6d1e-fc28-4275-b423-e30487699bae: Detected pause in JVM or host machine (eg GC): pause of approximately 101787665ns.
scm3.org_1   | GC pool 'ParNew' had collection(s): count=1 time=182ms
scm3.org_1   | 2022-02-05 13:09:31,703 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 8861f5bd-9ae4-4203-8e86-df306916ac0e, Nodes: 9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-02-05T13:09:30.372Z[UTC]].
scm3.org_1   | 2022-02-05 13:09:31,734 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-02-05 13:09:31,744 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: fc6ad7e7-85fa-4af9-97bb-5989287a910b, Nodes: 3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-02-05T13:09:31.352Z[UTC]].
scm3.org_1   | 2022-02-05 13:09:31,748 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-02-05 13:09:32,740 [IPC Server handler 57 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/a527daad-fcfc-4913-bb86-57ba7fce9b83
scm3.org_1   | 2022-02-05 13:09:32,741 [IPC Server handler 57 on default port 9861] INFO node.SCMNodeManager: Registered Data node : a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 941044329628, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2022-02-05 13:09:32,742 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-02-05 13:09:32,747 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm3.org_1   | 2022-02-05 13:09:32,747 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm3.org_1   | 2022-02-05 13:09:32,747 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm3.org_1   | 2022-02-05 13:09:32,747 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-02-05 13:09:32,747 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm3.org_1   | 2022-02-05 13:09:32,747 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-02-05 13:09:32,869 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 194f5d50-3ed1-4cfa-a521-0d06090717c7, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-02-05T13:09:32.794Z[UTC]].
scm3.org_1   | 2022-02-05 13:09:32,872 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-02-05 13:09:33,026 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]].
scm3.org_1   | 2022-02-05 13:09:33,026 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-02-05 13:09:33,083 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: f1ca961d-d578-498d-933d-dd33d84c9d7f, Nodes: 9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-02-05T13:09:33.048Z[UTC]].
scm3.org_1   | 2022-02-05 13:09:33,084 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-02-05 13:09:36,078 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 194f5d50-3ed1-4cfa-a521-0d06090717c7, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.794Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-02-05 13:09:36,538 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-02-05 13:09:36,952 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-02-05 13:09:41,725 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44110
scm3.org_1   | 2022-02-05 13:09:41,847 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:09:41,874 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-02-05 13:09:43,282 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-02-05 13:09:46,080 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35056
scm3.org_1   | 2022-02-05 13:09:46,208 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:09:46,210 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-02-05 13:09:46,300 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm3.org_1   | 2022-02-05 13:09:46,946 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-02-05 13:09:46,948 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm3.org_1   | 2022-02-05 13:09:46,948 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm3.org_1   | 2022-02-05 13:09:46,948 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm3.org_1   | 2022-02-05 13:09:46,948 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm3.org_1   | 2022-02-05 13:09:46,948 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-02-05 13:09:46,949 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm3.org_1   | 2022-02-05 13:10:01,737 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44186
scm3.org_1   | 2022-02-05 13:10:01,791 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:10:01,793 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: fc6ad7e7-85fa-4af9-97bb-5989287a910b, Nodes: 3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:3bd141d9-8d6a-4889-940a-437a7867e049, CreationTimestamp2022-02-05T13:09:31.352Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-02-05 13:10:02,580 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35126
om1_1        | 2022-02-05 13:18:59,956 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:59,958 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:18:59,960 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:00,490 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:00,492 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:00,495 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:00,509 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:01,572 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:01,573 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:01,576 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:04,473 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:04,972 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:04,973 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:04,975 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:05,523 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:05,525 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:05,526 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:06,954 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:37875
om1_1        | 2022-02-05 13:19:06,963 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:19:07,454 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:07,458 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:07,460 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:07,476 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:07,478 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:07,480 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:07,495 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:08,029 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:08,033 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:08,035 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:08,053 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:08,055 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:08,058 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:08,069 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:08,569 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:08,572 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:08,574 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:08,593 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:08,595 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:08,596 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:08,603 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:08,605 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:08,612 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:08,639 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:11,806 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:12,377 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | 2022-02-05 13:18:25,728 [qtp1431556341-17] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-ozone-test-1400913700, , key: ozone-test-9831389542/multipartKey3
s3g_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-1400913700 key: ozone-test-9831389542/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-1400913700/ozone-test-9831389542/multipartKey3-4aa6b580-8307-4ca0-89fa-b8b99779129d-107745581312966689-2
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:654)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:1027)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1231)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:762)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:534)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-02-05 13:11:28,704 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60070
recon_1      | 2022-02-05 13:11:28,762 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:11:28,972 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47322
recon_1      | 2022-02-05 13:11:28,995 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:11:29,235 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59724
recon_1      | 2022-02-05 13:11:29,289 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:11:58,748 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60174
recon_1      | 2022-02-05 13:11:58,766 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:11:58,962 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47426
recon_1      | 2022-02-05 13:11:58,995 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:11:59,272 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59822
recon_1      | 2022-02-05 13:11:59,282 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:12:06,576 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-02-05 13:12:06,577 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-02-05 13:12:06,638 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
scm1.org_1   | 2022-02-05 13:09:05,483 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:41350
scm1.org_1   | 2022-02-05 13:09:05,511 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-02-05 13:09:05,513 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om1, UUID: f176db6c-ce74-4d04-8f63-6dd09f018ade
scm1.org_1   | 2022-02-05 13:09:05,645 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-02-05 13:09:05,876 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-02-05 13:09:10,455 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:56700
scm1.org_1   | 2022-02-05 13:09:10,459 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-02-05 13:09:10,502 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om3, UUID: 2971c4fc-3575-48dc-a77a-04da41328be5
scm1.org_1   | 2022-02-05 13:09:10,672 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-02-05 13:09:10,811 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54344
scm1.org_1   | 2022-02-05 13:09:10,865 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-02-05 13:09:11,282 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53464
scm1.org_1   | 2022-02-05 13:09:11,312 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-02-05 13:09:14,470 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39094
scm1.org_1   | 2022-02-05 13:09:14,578 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-02-05 13:09:25,790 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57520
scm1.org_1   | 2022-02-05 13:09:25,894 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:09:27,158 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52346
scm1.org_1   | 2022-02-05 13:09:27,206 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:09:30,182 [IPC Server handler 4 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/9905eb49-ac94-40b9-a1a3-f35673531eee
scm1.org_1   | 2022-02-05 13:09:30,230 [IPC Server handler 4 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 936463488335, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-02-05 13:09:30,346 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-02-05 13:09:30,484 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=8861f5bd-9ae4-4203-8e86-df306916ac0e to datanode:9905eb49-ac94-40b9-a1a3-f35673531eee
scm1.org_1   | 2022-02-05 13:09:30,390 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm1.org_1   | 2022-02-05 13:09:30,628 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$439/0x000000084053f040@6ddc9001] WARN util.JvmPauseMonitor: JvmPauseMonitor-70490618-601a-4309-ad32-4488318b9859: Detected pause in JVM or host machine (eg GC): pause of approximately 208365742ns. No GCs detected.
scm1.org_1   | 2022-02-05 13:09:30,878 [IPC Server handler 1 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/3bd141d9-8d6a-4889-940a-437a7867e049
scm1.org_1   | 2022-02-05 13:09:30,882 [IPC Server handler 1 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 938407921790, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-02-05 13:09:30,891 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-02-05 13:09:30,955 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm1.org_1   | 2022-02-05 13:09:31,137 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46800
scm1.org_1   | 2022-02-05 13:09:31,210 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:09:31,228 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 8861f5bd-9ae4-4203-8e86-df306916ac0e, Nodes: 9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-02-05T13:09:30.372Z[UTC]].
scm1.org_1   | 2022-02-05 13:09:31,228 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-02-05 13:09:31,352 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=fc6ad7e7-85fa-4af9-97bb-5989287a910b to datanode:3bd141d9-8d6a-4889-940a-437a7867e049
scm1.org_1   | 2022-02-05 13:09:31,616 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: fc6ad7e7-85fa-4af9-97bb-5989287a910b, Nodes: 3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-02-05T13:09:31.352Z[UTC]].
scm1.org_1   | 2022-02-05 13:09:31,619 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-02-05 13:09:32,755 [IPC Server handler 26 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/a527daad-fcfc-4913-bb86-57ba7fce9b83
scm1.org_1   | 2022-02-05 13:09:32,780 [IPC Server handler 26 on default port 9861] INFO node.SCMNodeManager: Registered Data node : a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 941044329628, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-02-05 13:09:32,788 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-02-05 13:09:32,790 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm1.org_1   | 2022-02-05 13:09:32,790 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm1.org_1   | 2022-02-05 13:09:32,800 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm1.org_1   | 2022-02-05 13:09:32,801 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-02-05 13:09:32,801 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm1.org_1   | 2022-02-05 13:09:32,801 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-02-05 13:09:32,794 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=194f5d50-3ed1-4cfa-a521-0d06090717c7 to datanode:a527daad-fcfc-4913-bb86-57ba7fce9b83
scm1.org_1   | 2022-02-05 13:09:32,844 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 194f5d50-3ed1-4cfa-a521-0d06090717c7, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-02-05T13:09:32.794Z[UTC]].
scm1.org_1   | 2022-02-05 13:09:32,862 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-02-05 13:09:32,907 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=cd0dbfd1-bf28-4717-93ea-139bdf3e2545 to datanode:a527daad-fcfc-4913-bb86-57ba7fce9b83
scm1.org_1   | 2022-02-05 13:09:32,962 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=cd0dbfd1-bf28-4717-93ea-139bdf3e2545 to datanode:3bd141d9-8d6a-4889-940a-437a7867e049
scm1.org_1   | 2022-02-05 13:09:32,962 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=cd0dbfd1-bf28-4717-93ea-139bdf3e2545 to datanode:9905eb49-ac94-40b9-a1a3-f35673531eee
scm1.org_1   | 2022-02-05 13:09:33,005 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]].
scm1.org_1   | 2022-02-05 13:09:33,030 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-02-05 13:09:33,048 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=f1ca961d-d578-498d-933d-dd33d84c9d7f to datanode:9905eb49-ac94-40b9-a1a3-f35673531eee
scm1.org_1   | 2022-02-05 13:09:33,060 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=f1ca961d-d578-498d-933d-dd33d84c9d7f to datanode:3bd141d9-8d6a-4889-940a-437a7867e049
scm1.org_1   | 2022-02-05 13:09:33,060 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=f1ca961d-d578-498d-933d-dd33d84c9d7f to datanode:a527daad-fcfc-4913-bb86-57ba7fce9b83
scm1.org_1   | 2022-02-05 13:09:33,083 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: f1ca961d-d578-498d-933d-dd33d84c9d7f, Nodes: 9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-02-05T13:09:33.048Z[UTC]].
scm1.org_1   | 2022-02-05 13:09:33,120 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-02-05 13:09:33,146 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineManagerImpl: Pipeline: PipelineID=f1ca961d-d578-498d-933d-dd33d84c9d7f contains same datanodes as previous pipelines: PipelineID=cd0dbfd1-bf28-4717-93ea-139bdf3e2545 nodeIds: 9905eb49-ac94-40b9-a1a3-f35673531eee, 3bd141d9-8d6a-4889-940a-437a7867e049, a527daad-fcfc-4913-bb86-57ba7fce9b83
scm1.org_1   | 2022-02-05 13:09:34,303 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:55374
scm1.org_1   | 2022-02-05 13:09:34,383 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:09:34,830 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:42432
scm1.org_1   | 2022-02-05 13:09:34,977 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:09:36,274 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:45409
scm1.org_1   | 2022-02-05 13:09:36,288 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 194f5d50-3ed1-4cfa-a521-0d06090717c7, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.794Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-02-05 13:09:36,378 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-02-05 13:09:36,448 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-02-05 13:09:36,560 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-02-05 13:09:36,973 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-02-05 13:09:37,202 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:52302
scm1.org_1   | 2022-02-05 13:09:37,255 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:09:40,693 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48942
scm1.org_1   | 2022-02-05 13:09:40,866 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-02-05 13:09:41,894 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-02-05 13:09:42,010 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52402
scm1.org_1   | 2022-02-05 13:09:42,064 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:09:43,259 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-02-05 13:09:43,760 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:41472
scm1.org_1   | 2022-02-05 13:09:43,774 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-02-05 13:09:44,371 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:58584
scm1.org_1   | 2022-02-05 13:09:44,397 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-02-05 13:09:46,141 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57616
scm1.org_1   | 2022-02-05 13:09:46,242 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:09:46,254 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-02-05 13:09:46,287 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm2.org_1   | 2022-02-05 13:19:19,189 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:19:49,063 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53596
scm2.org_1   | 2022-02-05 13:19:49,107 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40816
scm2.org_1   | 2022-02-05 13:19:49,141 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43248
scm2.org_1   | 2022-02-05 13:19:49,145 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:19:49,157 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:19:49,164 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:20:19,058 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43326
scm2.org_1   | 2022-02-05 13:20:19,090 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53680
scm2.org_1   | 2022-02-05 13:20:19,100 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40892
scm2.org_1   | 2022-02-05 13:20:19,131 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:20:19,138 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:20:19,162 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:20:49,047 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53750
scm2.org_1   | 2022-02-05 13:20:49,073 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43398
scm2.org_1   | 2022-02-05 13:20:49,086 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40968
scm2.org_1   | 2022-02-05 13:20:49,126 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:20:49,133 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:20:49,165 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:21:19,110 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41040
scm2.org_1   | 2022-02-05 13:21:19,133 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:21:19,134 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43492
scm2.org_1   | 2022-02-05 13:21:19,150 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53822
scm2.org_1   | 2022-02-05 13:21:19,193 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:21:19,205 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:21:49,096 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43582
scm2.org_1   | 2022-02-05 13:21:49,126 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:21:49,135 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53938
scm2.org_1   | 2022-02-05 13:21:49,140 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41152
scm2.org_1   | 2022-02-05 13:21:49,150 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:21:49,156 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:22:19,095 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54006
scm2.org_1   | 2022-02-05 13:22:19,097 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41222
scm2.org_1   | 2022-02-05 13:22:19,119 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43646
scm2.org_1   | 2022-02-05 13:22:19,133 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:22:19,144 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:22:19,168 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:22:49,072 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54084
scm2.org_1   | 2022-02-05 13:22:49,126 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43728
scm2.org_1   | 2022-02-05 13:22:49,146 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:22:49,153 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41304
scm2.org_1   | 2022-02-05 13:22:49,167 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:22:49,173 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:23:08,639 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om1_1        | 2022-02-05 13:19:12,378 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:12,380 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:12,393 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:12,397 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:12,399 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:12,409 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:12,410 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:12,411 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:12,433 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:15,025 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:15,589 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:15,591 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:15,593 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:15,612 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:15,614 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:15,615 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:15,628 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:15,630 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:15,631 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:19:15,660 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:20:06,992 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:37355
om1_1        | 2022-02-05 13:20:07,001 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:20:15,823 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:37045
om1_1        | 2022-02-05 13:20:15,835 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:20:15,836 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:20:15,839 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:20:15,841 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:20:15,852 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:20:15,860 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:20:15,865 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:20:15,902 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:20:15,904 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:20:15,906 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:20:15,976 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:07,033 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:40331
om1_1        | 2022-02-05 13:21:07,052 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:21:16,901 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:37733
om1_1        | 2022-02-05 13:21:16,910 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:21:16,911 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:16,914 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:16,917 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:16,937 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:16,941 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:16,946 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
scm3.org_1   | 2022-02-05 13:10:02,668 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:10:02,670 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 8861f5bd-9ae4-4203-8e86-df306916ac0e, Nodes: 9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:9905eb49-ac94-40b9-a1a3-f35673531eee, CreationTimestamp2022-02-05T13:09:30.372Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-02-05 13:10:17,073 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46530
scm3.org_1   | 2022-02-05 13:10:17,088 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:10:23,172 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44256
scm3.org_1   | 2022-02-05 13:10:23,265 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:10:23,266 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: f1ca961d-d578-498d-933d-dd33d84c9d7f, Nodes: 9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:3bd141d9-8d6a-4889-940a-437a7867e049, CreationTimestamp2022-02-05T13:09:33.048Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-02-05 13:10:24,713 [9c3b6d1e-fc28-4275-b423-e30487699bae@group-EDDF767648B7-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm3.org_1   | 2022-02-05 13:10:28,684 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46582
scm3.org_1   | 2022-02-05 13:10:28,712 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:10:29,295 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35210
scm3.org_1   | 2022-02-05 13:10:29,346 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:10:58,707 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46674
scm3.org_1   | 2022-02-05 13:10:58,749 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:10:58,937 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44386
scm3.org_1   | 2022-02-05 13:10:58,955 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:10:59,237 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35310
scm3.org_1   | 2022-02-05 13:10:59,294 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:11:28,696 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46764
scm3.org_1   | 2022-02-05 13:11:28,763 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:11:28,943 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44470
scm3.org_1   | 2022-02-05 13:11:28,967 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:11:29,219 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35402
scm3.org_1   | 2022-02-05 13:11:29,235 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:11:58,678 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46866
scm3.org_1   | 2022-02-05 13:11:58,690 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:11:58,938 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44574
scm3.org_1   | 2022-02-05 13:11:58,994 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:11:59,223 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35500
scm3.org_1   | 2022-02-05 13:11:59,247 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:23:19,070 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54150
scm2.org_1   | 2022-02-05 13:23:19,115 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43800
scm2.org_1   | 2022-02-05 13:23:19,122 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:23:19,159 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41372
scm2.org_1   | 2022-02-05 13:23:19,162 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:23:19,183 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:23:49,055 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41454
scm2.org_1   | 2022-02-05 13:23:49,074 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54236
scm2.org_1   | 2022-02-05 13:23:49,111 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:23:49,119 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43886
scm2.org_1   | 2022-02-05 13:23:49,157 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:23:49,187 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:24:19,080 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54302
scm2.org_1   | 2022-02-05 13:24:19,093 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:24:19,102 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41522
scm2.org_1   | 2022-02-05 13:24:19,140 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43950
scm2.org_1   | 2022-02-05 13:24:19,144 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:24:19,175 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:24:49,072 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54390
scm2.org_1   | 2022-02-05 13:24:49,094 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41602
scm2.org_1   | 2022-02-05 13:24:49,099 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44036
scm2.org_1   | 2022-02-05 13:24:49,112 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:24:49,124 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:24:49,145 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:25:19,052 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54458
scm2.org_1   | 2022-02-05 13:25:19,073 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41672
scm2.org_1   | 2022-02-05 13:25:19,099 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44104
scm2.org_1   | 2022-02-05 13:25:19,103 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:25:19,134 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:25:19,137 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:25:49,098 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41750
scm2.org_1   | 2022-02-05 13:25:49,106 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54536
scm2.org_1   | 2022-02-05 13:25:49,107 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44202
scm2.org_1   | 2022-02-05 13:25:49,152 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:25:49,164 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:25:49,191 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:26:19,053 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54608
scm2.org_1   | 2022-02-05 13:26:19,093 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44250
scm2.org_1   | 2022-02-05 13:26:19,115 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41824
scm3.org_1   | 2022-02-05 13:12:28,727 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46960
scm3.org_1   | 2022-02-05 13:12:28,778 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:12:28,950 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44670
scm3.org_1   | 2022-02-05 13:12:28,971 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:12:29,219 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35596
scm3.org_1   | 2022-02-05 13:12:29,265 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:12:49,075 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35666
scm3.org_1   | 2022-02-05 13:12:49,111 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44752
scm3.org_1   | 2022-02-05 13:12:49,159 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47054
scm3.org_1   | 2022-02-05 13:12:49,185 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:12:49,206 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:12:49,292 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:13:19,164 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47154
scm3.org_1   | 2022-02-05 13:13:19,166 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44848
scm3.org_1   | 2022-02-05 13:13:19,170 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35764
scm3.org_1   | 2022-02-05 13:13:19,194 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:13:19,205 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:13:19,225 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:13:27,798 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-02-05 13:13:49,070 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35868
scm3.org_1   | 2022-02-05 13:13:49,080 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44956
scm3.org_1   | 2022-02-05 13:13:49,108 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:13:49,134 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47254
scm3.org_1   | 2022-02-05 13:13:49,174 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:13:49,237 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:14:19,152 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35958
scm3.org_1   | 2022-02-05 13:14:19,159 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47346
scm3.org_1   | 2022-02-05 13:14:19,169 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45056
scm3.org_1   | 2022-02-05 13:14:19,175 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:14:19,180 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:14:19,186 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:14:49,106 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36066
scm3.org_1   | 2022-02-05 13:14:49,116 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47462
scm3.org_1   | 2022-02-05 13:14:49,128 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:14:49,162 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45156
scm3.org_1   | 2022-02-05 13:14:49,201 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:14:49,216 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:15:19,117 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47560
scm3.org_1   | 2022-02-05 13:15:19,128 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36166
scm3.org_1   | 2022-02-05 13:15:19,142 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:15:19,170 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45250
scm3.org_1   | 2022-02-05 13:15:19,182 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:15:19,211 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:15:49,110 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47762
scm3.org_1   | 2022-02-05 13:15:49,114 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45452
scm3.org_1   | 2022-02-05 13:15:49,135 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36376
scm3.org_1   | 2022-02-05 13:15:49,154 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:15:49,179 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:15:49,191 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:16:19,053 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36440
scm3.org_1   | 2022-02-05 13:16:19,106 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:16:19,113 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47832
scm3.org_1   | 2022-02-05 13:16:19,164 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45528
scm3.org_1   | 2022-02-05 13:16:19,167 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:16:19,204 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:16:49,076 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45628
scm3.org_1   | 2022-02-05 13:16:49,094 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47938
scm3.org_1   | 2022-02-05 13:16:49,102 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36540
scm3.org_1   | 2022-02-05 13:16:49,130 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:16:49,136 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:16:49,156 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:17:19,106 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36640
scm3.org_1   | 2022-02-05 13:17:19,193 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45740
scm3.org_1   | 2022-02-05 13:17:19,199 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48032
scm3.org_1   | 2022-02-05 13:17:19,225 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:17:19,256 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:17:19,267 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:17:49,143 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48140
scm3.org_1   | 2022-02-05 13:17:49,152 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45840
scm3.org_1   | 2022-02-05 13:17:49,188 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:17:49,193 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36772
scm3.org_1   | 2022-02-05 13:17:49,200 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:17:49,213 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:18:19,064 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48274
scm3.org_1   | 2022-02-05 13:18:19,135 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:18:19,151 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45976
om1_1        | 2022-02-05 13:21:16,986 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:16,988 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:16,992 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:17,060 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:17,920 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:18,560 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:18,563 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:18,565 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:19,347 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:19,349 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:19,352 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:19,364 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:20,644 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:20,646 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:20,649 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:21,295 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:21,297 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:21,299 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:22,016 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:22,018 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:22,023 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:28,884 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35890
om1_1        | 2022-02-05 13:21:28,906 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:21:32,204 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:40689
om1_1        | 2022-02-05 13:21:32,209 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:21:32,209 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:32,215 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:32,717 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:32,720 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:33,238 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:33,240 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:21:33,242 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:22:07,083 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:36711
om1_1        | 2022-02-05 13:22:07,098 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:22:16,683 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:37761
om1_1        | 2022-02-05 13:22:16,688 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:22:16,689 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:22:16,710 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCommitPartRequest: MultipartUpload Commit is failed for Key:ozone-test-5048365730/copyrange/destination in Volume/Bucket s3v/bucket-ozone-test-1400913700
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId 8d8cef6b-bfdd-433d-9bd6-48f754cd8048-107745584413147190
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCommitPartRequest.validateAndUpdateCache(S3MultipartUploadCommitPartRequest.java:185)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-02-05 13:22:33,702 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:42139
om1_1        | 2022-02-05 13:22:33,708 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:22:33,709 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:22:33,712 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:22:33,742 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:23:07,147 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:44001
om1_1        | 2022-02-05 13:23:07,151 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:23:16,669 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:46143
om1_1        | 2022-02-05 13:23:16,671 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:23:16,671 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:23:16,683 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCommitPartRequest: MultipartUpload Commit is failed for Key:ozone-test-5048365730/copyrange/destination in Volume/Bucket s3v/bucket-ozone-test-1400913700
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId 8d8cef6b-bfdd-433d-9bd6-48f754cd8048-107745584413147190
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCommitPartRequest.validateAndUpdateCache(S3MultipartUploadCommitPartRequest.java:185)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-02-05 13:12:28,721 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60270
recon_1      | 2022-02-05 13:12:28,777 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:12:28,919 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47516
recon_1      | 2022-02-05 13:12:28,942 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:12:29,242 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59920
recon_1      | 2022-02-05 13:12:29,274 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:12:49,120 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60368
recon_1      | 2022-02-05 13:12:49,146 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59982
recon_1      | 2022-02-05 13:12:49,150 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47612
recon_1      | 2022-02-05 13:12:49,189 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:12:49,190 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #2 got from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-02-05 13:12:49,201 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:12:49,267 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #2 to Recon.
recon_1      | 2022-02-05 13:12:49,298 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm2.org_1   | 2022-02-05 13:26:19,115 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:26:19,137 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:26:19,151 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:26:49,063 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54720
scm2.org_1   | 2022-02-05 13:26:49,082 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44366
scm2.org_1   | 2022-02-05 13:26:49,116 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41934
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
recon_1      | 2022-02-05 13:12:55,336 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 47 milliseconds to process 0 existing database records.
recon_1      | 2022-02-05 13:12:55,356 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 20 milliseconds for processing 2 containers.
recon_1      | 2022-02-05 13:12:55,367 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-02-05 13:12:55,370 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 11 milliseconds.
recon_1      | 2022-02-05 13:13:06,644 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-02-05 13:13:06,644 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
scm2.org_1   | 2022-02-05 13:26:49,132 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:26:49,170 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:26:49,188 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:27:19,062 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54786
scm2.org_1   | 2022-02-05 13:27:19,071 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44432
scm2.org_1   | 2022-02-05 13:27:19,087 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42004
scm2.org_1   | 2022-02-05 13:27:19,106 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-02-05 13:13:06,702 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
scm2.org_1   | 2022-02-05 13:27:19,124 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:27:19,132 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:27:49,085 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42078
scm2.org_1   | 2022-02-05 13:27:49,111 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54866
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
scm1.org_1   | 2022-02-05 13:09:46,295 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm1.org_1   | 2022-02-05 13:09:46,297 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm1.org_1   | 2022-02-05 13:09:46,297 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm1.org_1   | 2022-02-05 13:09:46,297 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm1.org_1   | 2022-02-05 13:09:46,297 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-02-05 13:09:46,301 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm1.org_1   | 2022-02-05 13:09:46,306 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO container.ReplicationManager: Service ReplicationManager transitions to RUNNING.
scm1.org_1   | 2022-02-05 13:09:47,005 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:37131
scm1.org_1   | 2022-02-05 13:09:47,034 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:56834
scm1.org_1   | 2022-02-05 13:09:47,056 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-02-05 13:09:47,059 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-02-05 13:10:00,092 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49020
scm1.org_1   | 2022-02-05 13:10:00,133 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm2.org_1   | 2022-02-05 13:27:49,123 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44508
scm2.org_1   | 2022-02-05 13:27:49,138 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:27:49,143 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:27:49,179 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:28:08,639 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-02-05 13:28:19,070 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54934
scm2.org_1   | 2022-02-05 13:28:19,087 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44582
scm2.org_1   | 2022-02-05 13:28:19,101 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42154
scm2.org_1   | 2022-02-05 13:28:19,131 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:28:19,140 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:28:19,156 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:28:49,073 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55012
scm2.org_1   | 2022-02-05 13:28:49,131 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42230
scm2.org_1   | 2022-02-05 13:28:49,132 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:28:49,172 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44658
scm2.org_1   | 2022-02-05 13:28:49,184 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:28:49,203 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:29:19,058 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55086
scm2.org_1   | 2022-02-05 13:29:19,099 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44730
scm2.org_1   | 2022-02-05 13:29:19,124 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
scm3.org_1   | 2022-02-05 13:18:19,162 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:18:19,181 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36886
scm3.org_1   | 2022-02-05 13:18:19,204 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:18:27,798 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-02-05 13:18:49,080 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48436
scm3.org_1   | 2022-02-05 13:18:49,118 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37044
scm3.org_1   | 2022-02-05 13:18:49,141 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46128
scm3.org_1   | 2022-02-05 13:18:49,163 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:18:49,170 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:18:49,237 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:19:19,154 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48542
scm3.org_1   | 2022-02-05 13:19:19,159 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37144
scm3.org_1   | 2022-02-05 13:19:19,191 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:19:19,197 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
scm1.org_1   | 2022-02-05 13:10:01,783 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:37911
scm1.org_1   | 2022-02-05 13:10:01,787 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52474
scm1.org_1   | 2022-02-05 13:10:01,810 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-02-05 13:10:01,837 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:10:01,842 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: fc6ad7e7-85fa-4af9-97bb-5989287a910b, Nodes: 3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:3bd141d9-8d6a-4889-940a-437a7867e049, CreationTimestamp2022-02-05T13:09:31.352Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-02-05 13:10:02,590 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57678
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm3.org_1   | 2022-02-05 13:19:19,200 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46232
scm3.org_1   | 2022-02-05 13:19:19,212 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:19:49,095 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48618
scm3.org_1   | 2022-02-05 13:19:49,102 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46312
scm3.org_1   | 2022-02-05 13:19:49,111 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37218
scm3.org_1   | 2022-02-05 13:19:49,126 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:19:49,137 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:19:49,169 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:20:19,059 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37300
scm3.org_1   | 2022-02-05 13:20:19,097 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:20:19,109 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46390
scm3.org_1   | 2022-02-05 13:20:19,114 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48694
scm3.org_1   | 2022-02-05 13:20:19,140 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:20:19,161 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:20:49,064 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46464
scm3.org_1   | 2022-02-05 13:20:49,093 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48770
scm3.org_1   | 2022-02-05 13:20:49,101 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37378
scm3.org_1   | 2022-02-05 13:20:49,134 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:20:49,153 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:20:49,169 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:21:19,096 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48838
scm3.org_1   | 2022-02-05 13:21:19,124 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46536
scm3.org_1   | 2022-02-05 13:21:19,133 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:21:19,170 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37450
scm1.org_1   | 2022-02-05 13:10:02,728 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:10:02,733 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 8861f5bd-9ae4-4203-8e86-df306916ac0e, Nodes: 9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:9905eb49-ac94-40b9-a1a3-f35673531eee, CreationTimestamp2022-02-05T13:09:30.372Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-02-05 13:10:17,077 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46978
scm1.org_1   | 2022-02-05 13:10:17,087 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:10:23,206 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52544
scm1.org_1   | 2022-02-05 13:10:23,271 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:10:23,295 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: f1ca961d-d578-498d-933d-dd33d84c9d7f, Nodes: 9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:3bd141d9-8d6a-4889-940a-437a7867e049, CreationTimestamp2022-02-05T13:09:33.048Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-02-05 13:10:24,389 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:55558
scm1.org_1   | 2022-02-05 13:10:24,398 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:10:24,503 [IPC Server handler 24 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
scm1.org_1   | 2022-02-05 13:10:24,696 [70490618-601a-4309-ad32-4488318b9859@group-EDDF767648B7-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm1.org_1   | 2022-02-05 13:10:24,735 [IPC Server handler 24 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 109611004723200000 to 109611004723201000.
scm1.org_1   | 2022-02-05 13:10:28,210 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39340
scm1.org_1   | 2022-02-05 13:10:28,223 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-02-05 13:10:28,519 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53726
scm1.org_1   | 2022-02-05 13:10:28,533 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-02-05 13:10:28,546 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54612
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
scm2.org_1   | 2022-02-05 13:29:19,131 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-02-05 13:23:34,658 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:33031
om1_1        | 2022-02-05 13:23:34,663 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:23:34,664 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:23:34,668 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:23:34,670 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
scm2.org_1   | 2022-02-05 13:29:19,157 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42300
scm2.org_1   | 2022-02-05 13:29:19,168 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:29:49,067 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44810
scm2.org_1   | 2022-02-05 13:29:49,117 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:29:49,124 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42376
scm2.org_1   | 2022-02-05 13:29:49,141 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55160
scm2.org_1   | 2022-02-05 13:29:49,168 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:29:49,189 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:30:19,062 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44904
scm2.org_1   | 2022-02-05 13:30:19,073 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55242
scm2.org_1   | 2022-02-05 13:30:19,090 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42466
scm2.org_1   | 2022-02-05 13:30:19,099 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:30:19,134 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:30:19,157 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:30:49,073 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44958
scm2.org_1   | 2022-02-05 13:30:49,099 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55312
scm2.org_1   | 2022-02-05 13:30:49,113 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42532
scm2.org_1   | 2022-02-05 13:30:49,123 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:30:49,139 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:30:49,149 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:31:19,092 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42632
scm2.org_1   | 2022-02-05 13:31:19,121 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55412
scm2.org_1   | 2022-02-05 13:31:19,127 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45062
scm2.org_1   | 2022-02-05 13:31:19,130 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:31:19,143 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:31:19,152 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:31:49,046 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55486
scm2.org_1   | 2022-02-05 13:31:49,073 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:31:49,087 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45136
om1_1        | 2022-02-05 13:24:07,186 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:44573
om1_1        | 2022-02-05 13:24:07,194 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:24:33,682 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:43393
om1_1        | 2022-02-05 13:24:33,695 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:24:33,696 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:24:35,306 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:24:35,309 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:24:35,312 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:25:07,229 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:43223
om1_1        | 2022-02-05 13:25:07,239 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:25:34,677 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:41807
om1_1        | 2022-02-05 13:25:34,681 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:25:34,682 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:25:38,706 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:25:38,715 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:25:38,717 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:07,277 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:37735
om1_1        | 2022-02-05 13:26:07,281 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:26:32,813 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:44501
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
scm1.org_1   | 2022-02-05 13:10:28,558 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-02-05 13:10:28,691 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47018
scm1.org_1   | 2022-02-05 13:10:28,798 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:10:28,863 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:40943
scm1.org_1   | 2022-02-05 13:10:28,922 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-02-05 13:10:29,217 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57774
scm1.org_1   | 2022-02-05 13:10:29,276 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:10:36,970 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:55606
scm1.org_1   | 2022-02-05 13:10:36,987 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | 2022-02-05 13:18:26,238 [qtp1431556341-21] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-ozone-test-1400913700, , key: ozone-test-9831389542/multipartKey3
s3g_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-1400913700 key: ozone-test-9831389542/multipartKey3 because parts are in Invalid order.
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:654)
s3g_1        | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:1027)
s3g_1        | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:1231)
s3g_1        | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:762)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:534)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1        | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-02-05 13:13:19,123 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60082
recon_1      | 2022-02-05 13:13:19,129 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60470
recon_1      | 2022-02-05 13:13:19,131 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47698
recon_1      | 2022-02-05 13:13:19,135 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:13:19,146 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:13:19,169 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:13:49,073 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60190
recon_1      | 2022-02-05 13:13:49,098 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47812
recon_1      | 2022-02-05 13:13:49,124 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:13:49,179 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:13:49,182 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60576
recon_1      | 2022-02-05 13:13:49,249 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:14:06,705 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-02-05 13:14:06,705 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-02-05 13:14:06,750 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om1_1        | 2022-02-05 13:26:32,817 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:26:32,818 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:32,821 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:32,822 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:32,824 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:33,427 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:33,429 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:34,451 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:34,457 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
scm2.org_1   | 2022-02-05 13:31:49,092 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42704
scm3.org_1   | 2022-02-05 13:21:19,199 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:21:19,219 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:21:49,057 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46644
scm3.org_1   | 2022-02-05 13:21:49,115 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37554
scm3.org_1   | 2022-02-05 13:21:49,115 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:31:49,119 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:31:49,152 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:32:19,089 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55576
scm2.org_1   | 2022-02-05 13:32:19,104 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42792
scm2.org_1   | 2022-02-05 13:32:19,117 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:32:19,147 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:32:19,158 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45222
scm2.org_1   | 2022-02-05 13:32:19,195 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:32:49,072 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45356
scm2.org_1   | 2022-02-05 13:32:49,124 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42930
scm1.org_1   | 2022-02-05 13:10:48,145 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:55646
scm1.org_1   | 2022-02-05 13:10:48,152 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:10:58,705 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47118
scm1.org_1   | 2022-02-05 13:10:58,753 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:10:58,940 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52674
scm1.org_1   | 2022-02-05 13:10:58,954 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:10:59,237 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57870
scm1.org_1   | 2022-02-05 13:10:59,253 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:11:14,076 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:57250
scm1.org_1   | 2022-02-05 13:11:14,084 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-02-05 13:11:28,714 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47204
scm1.org_1   | 2022-02-05 13:11:28,769 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:11:28,953 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52766
scm1.org_1   | 2022-02-05 13:11:28,970 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:11:29,246 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57962
scm1.org_1   | 2022-02-05 13:11:29,296 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:11:41,240 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:55820
scm3.org_1   | 2022-02-05 13:21:49,131 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48948
scm3.org_1   | 2022-02-05 13:21:49,142 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:21:49,153 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:22:19,074 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37628
scm3.org_1   | 2022-02-05 13:22:19,077 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49018
scm3.org_1   | 2022-02-05 13:22:19,091 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46714
scm3.org_1   | 2022-02-05 13:22:19,129 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:22:19,140 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:22:19,156 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:22:49,085 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37710
scm3.org_1   | 2022-02-05 13:22:49,087 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46800
om1_1        | 2022-02-05 13:26:34,460 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
scm2.org_1   | 2022-02-05 13:32:49,154 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55712
scm2.org_1   | 2022-02-05 13:32:49,180 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:32:49,208 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-02-05 13:32:49,230 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:22:49,108 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49098
scm3.org_1   | 2022-02-05 13:22:49,119 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:22:49,139 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:22:49,149 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:23:19,071 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46864
scm1.org_1   | 2022-02-05 13:11:41,250 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:11:50,345 [IPC Server handler 73 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for delTxnId, change lastId from 0 to 1000.
scm1.org_1   | 2022-02-05 13:11:58,788 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47302
scm1.org_1   | 2022-02-05 13:11:58,802 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:11:58,950 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52862
scm3.org_1   | 2022-02-05 13:23:19,088 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37772
scm3.org_1   | 2022-02-05 13:23:19,092 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49168
scm1.org_1   | 2022-02-05 13:11:58,999 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm1.org_1   | 2022-02-05 13:11:59,260 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58060
scm1.org_1   | 2022-02-05 13:11:59,267 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:12:28,753 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47396
scm1.org_1   | 2022-02-05 13:12:28,790 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:23:19,145 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:23:19,150 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:23:19,162 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:23:27,799 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-02-05 13:23:49,107 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46946
scm3.org_1   | 2022-02-05 13:23:49,134 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37860
om1_1        | 2022-02-05 13:26:34,461 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:34,463 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:35,657 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:41,134 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36686
om1_1        | 2022-02-05 13:26:41,166 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:26:44,262 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:44,267 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:44,773 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
scm1.org_1   | 2022-02-05 13:12:28,963 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52956
scm1.org_1   | 2022-02-05 13:12:28,977 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:12:29,273 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58156
scm1.org_1   | 2022-02-05 13:12:29,285 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:12:46,366 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm1.org_1   | 2022-02-05 13:12:46,830 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:56034
scm1.org_1   | 2022-02-05 13:12:46,833 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:12:49,099 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58222
scm1.org_1   | 2022-02-05 13:12:49,164 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53052
scm1.org_1   | 2022-02-05 13:12:49,183 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47492
scm1.org_1   | 2022-02-05 13:12:49,184 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:12:49,231 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:42943
scm1.org_1   | 2022-02-05 13:12:49,238 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:12:49,254 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-02-05 13:12:49,286 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:12:53,885 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:57598
scm1.org_1   | 2022-02-05 13:12:53,895 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-02-05 13:13:00,668 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:56090
scm3.org_1   | 2022-02-05 13:23:49,145 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49256
scm3.org_1   | 2022-02-05 13:23:49,150 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-02-05 13:26:44,774 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:44,777 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:44,943 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:45,576 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:45,579 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:45,581 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:45,583 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:46,101 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:46,104 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:46,106 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:46,137 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:46,841 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:46,845 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:46,849 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:47,438 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:47,442 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:47,444 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:48,013 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:48,016 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:48,017 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:48,529 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:48,534 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:48,535 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:49,292 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
scm3.org_1   | 2022-02-05 13:23:49,180 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:23:49,187 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
scm3.org_1   | 2022-02-05 13:24:19,083 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37928
scm3.org_1   | 2022-02-05 13:24:19,094 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47016
scm3.org_1   | 2022-02-05 13:24:19,098 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:24:19,108 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49324
scm3.org_1   | 2022-02-05 13:24:19,137 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-02-05 13:14:19,054 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60280
recon_1      | 2022-02-05 13:14:19,097 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60660
recon_1      | 2022-02-05 13:14:19,117 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:14:19,124 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47906
recon_1      | 2022-02-05 13:14:19,136 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:14:19,155 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:14:49,115 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60772
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
scm3.org_1   | 2022-02-05 13:24:19,149 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:24:49,061 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47104
scm3.org_1   | 2022-02-05 13:24:49,095 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38014
scm3.org_1   | 2022-02-05 13:24:49,101 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49406
scm3.org_1   | 2022-02-05 13:24:49,106 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:24:49,134 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:24:49,145 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:13:00,674 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:13:07,488 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:57632
scm1.org_1   | 2022-02-05 13:13:07,490 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-02-05 13:13:19,165 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53144
scm1.org_1   | 2022-02-05 13:13:19,171 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47594
scm1.org_1   | 2022-02-05 13:13:19,171 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58320
scm1.org_1   | 2022-02-05 13:13:19,198 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:13:19,205 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:13:19,243 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:13:49,183 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58426
scm1.org_1   | 2022-02-05 13:13:49,205 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:13:49,216 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53244
scm1.org_1   | 2022-02-05 13:13:49,225 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47698
scm1.org_1   | 2022-02-05 13:13:49,227 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:13:49,262 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:13:50,258 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:56266
scm1.org_1   | 2022-02-05 13:13:50,264 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:14:19,224 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53352
scm1.org_1   | 2022-02-05 13:14:19,231 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:14:19,231 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58526
scm1.org_1   | 2022-02-05 13:14:19,232 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47786
scm1.org_1   | 2022-02-05 13:14:19,240 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:14:19,258 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:14:49,195 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58626
scm1.org_1   | 2022-02-05 13:14:49,204 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:14:49,223 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47900
scm1.org_1   | 2022-02-05 13:14:49,243 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53444
scm1.org_1   | 2022-02-05 13:14:49,246 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:14:49,250 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:15:02,309 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:56494
scm1.org_1   | 2022-02-05 13:15:02,318 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:15:11,473 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:58044
scm3.org_1   | 2022-02-05 13:25:19,070 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49474
scm3.org_1   | 2022-02-05 13:25:19,075 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47164
scm3.org_1   | 2022-02-05 13:25:19,101 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38074
scm3.org_1   | 2022-02-05 13:25:19,102 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:25:19,137 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:25:19,141 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:25:49,084 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49552
scm3.org_1   | 2022-02-05 13:25:49,114 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47246
scm3.org_1   | 2022-02-05 13:25:49,123 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38176
scm3.org_1   | 2022-02-05 13:25:49,159 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:25:49,164 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:25:49,189 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:26:19,090 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38228
scm3.org_1   | 2022-02-05 13:26:19,124 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47318
scm3.org_1   | 2022-02-05 13:26:19,130 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49620
scm3.org_1   | 2022-02-05 13:26:19,137 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:26:19,146 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:26:19,168 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:26:49,080 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38340
scm3.org_1   | 2022-02-05 13:26:49,097 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47426
scm3.org_1   | 2022-02-05 13:26:49,151 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49732
scm3.org_1   | 2022-02-05 13:26:49,156 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:26:49,176 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:26:49,199 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:27:19,079 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47500
scm3.org_1   | 2022-02-05 13:27:19,088 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49802
scm3.org_1   | 2022-02-05 13:27:19,093 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38412
scm3.org_1   | 2022-02-05 13:27:19,110 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:27:19,123 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:27:19,130 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:27:49,088 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38488
scm3.org_1   | 2022-02-05 13:27:49,090 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47572
scm3.org_1   | 2022-02-05 13:27:49,093 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49882
scm3.org_1   | 2022-02-05 13:27:49,108 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:27:49,125 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:27:49,148 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:28:19,071 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47650
scm3.org_1   | 2022-02-05 13:28:19,105 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49950
scm3.org_1   | 2022-02-05 13:28:19,110 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38556
scm3.org_1   | 2022-02-05 13:28:19,127 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:28:19,146 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:28:19,159 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:28:27,799 [ReplicationMonitor] INFO container.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-02-05 13:28:49,044 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50026
scm3.org_1   | 2022-02-05 13:28:49,103 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:28:49,123 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47722
scm3.org_1   | 2022-02-05 13:28:49,133 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:28:49,148 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38638
scm3.org_1   | 2022-02-05 13:28:49,191 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:29:19,071 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47796
scm3.org_1   | 2022-02-05 13:29:19,076 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38708
scm3.org_1   | 2022-02-05 13:29:19,106 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50104
om1_1        | 2022-02-05 13:26:49,294 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:26:49,297 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:27:07,317 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35263
om1_1        | 2022-02-05 13:27:07,324 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:27:35,679 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:34377
om1_1        | 2022-02-05 13:27:35,686 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:27:35,686 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:27:49,445 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:34375
om1_1        | 2022-02-05 13:27:49,453 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:27:49,454 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:27:49,456 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:27:49,469 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:28:07,354 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:45883
om1_1        | 2022-02-05 13:28:07,356 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:28:39,691 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:42009
om1_1        | 2022-02-05 13:28:39,695 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:28:39,696 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:28:49,686 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:28:49,688 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:28:49,690 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:29:07,386 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:38537
om1_1        | 2022-02-05 13:29:07,392 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:29:49,680 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:39805
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | 2022-02-05 13:21:32,213 [qtp1431556341-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-1307050678, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-02-05 13:21:32,227 [qtp1431556341-17] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-1307050678
s3g_1        | 2022-02-05 13:21:32,718 [qtp1431556341-17] INFO rpc.RpcClient: Creating Bucket: s3v/destbucket-90233, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
recon_1      | 2022-02-05 13:14:49,144 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60388
recon_1      | 2022-02-05 13:14:49,169 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48008
recon_1      | 2022-02-05 13:14:49,188 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm1.org_1   | 2022-02-05 13:15:11,477 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-02-05 13:15:19,208 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47996
scm1.org_1   | 2022-02-05 13:15:19,214 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58722
scm1.org_1   | 2022-02-05 13:15:19,219 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:15:19,224 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53542
scm1.org_1   | 2022-02-05 13:15:19,247 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:15:19,252 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:15:49,109 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48202
scm1.org_1   | 2022-02-05 13:15:49,131 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53740
scm1.org_1   | 2022-02-05 13:15:49,136 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58926
scm1.org_1   | 2022-02-05 13:15:49,166 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:15:49,176 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:15:49,195 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:16:19,051 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58998
scm1.org_1   | 2022-02-05 13:16:19,107 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:16:19,140 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48272
scm1.org_1   | 2022-02-05 13:16:19,148 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53822
scm1.org_1   | 2022-02-05 13:16:19,167 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:16:19,199 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:16:48,853 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:56914
scm1.org_1   | 2022-02-05 13:16:48,857 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:16:49,108 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59100
scm1.org_1   | 2022-02-05 13:16:49,113 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53922
scm1.org_1   | 2022-02-05 13:16:49,126 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48374
scm1.org_1   | 2022-02-05 13:16:49,133 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:16:49,161 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:16:49,168 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:17:17,244 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:58536
scm1.org_1   | 2022-02-05 13:17:17,255 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-02-05 13:17:19,042 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59206
s3g_1        | 2022-02-05 13:21:32,728 [qtp1431556341-17] INFO endpoint.BucketEndpoint: Location is /destbucket-90233
s3g_1        | 2022-02-05 13:22:16,241 [qtp1431556341-22] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]]
recon_1      | 2022-02-05 13:14:49,199 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:14:49,207 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:15:06,753 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-02-05 13:15:06,754 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-02-05 13:15:06,787 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
om1_1        | 2022-02-05 13:29:49,697 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:29:49,697 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:29:53,561 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:29:53,567 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:29:53,569 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:29:53,758 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:29:54,425 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:29:54,426 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:29:54,428 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:29:54,431 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:29:55,060 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:29:55,063 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:29:55,065 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:29:55,599 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:29:55,601 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:29:55,606 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:29:55,608 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:29:56,141 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:29:56,143 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:29:56,151 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #141 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:373)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:533)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:547)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:495)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:469)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:522)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:639)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:167)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
om1_1        | 2022-02-05 13:29:56,181 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:29:56,870 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:29:56,873 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:29:56,876 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:30:07,443 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:41509
om1_1        | 2022-02-05 13:30:07,456 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:30:49,682 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:37761
om1_1        | 2022-02-05 13:30:49,688 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:30:49,688 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:30:57,597 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:30:57,599 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:30:57,603 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:30:57,732 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:30:58,366 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
scm3.org_1   | 2022-02-05 13:29:19,124 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:29:19,132 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:29:19,166 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
scm1.org_1   | 2022-02-05 13:17:19,123 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54014
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
scm3.org_1   | 2022-02-05 13:29:49,080 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38784
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
scm3.org_1   | 2022-02-05 13:29:49,093 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47870
scm1.org_1   | 2022-02-05 13:17:19,144 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48470
scm1.org_1   | 2022-02-05 13:17:19,170 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:17:19,182 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:17:19,234 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:17:46,369 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 3 milliseconds for processing 2 containers.
scm1.org_1   | 2022-02-05 13:17:49,176 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54126
scm1.org_1   | 2022-02-05 13:17:49,194 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59332
om1_1        | 2022-02-05 13:30:58,368 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm3.org_1   | 2022-02-05 13:29:49,119 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:29:49,123 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50178
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
om1_1        | 2022-02-05 13:30:58,369 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
scm1.org_1   | 2022-02-05 13:17:49,215 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48588
scm1.org_1   | 2022-02-05 13:17:49,226 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:29:49,129 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
om1_1        | 2022-02-05 13:30:58,372 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:30:58,933 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
om1_1        | 2022-02-05 13:30:58,935 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:30:58,937 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:30:59,520 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:30:59,522 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
scm3.org_1   | 2022-02-05 13:29:49,164 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:30:19,091 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50262
scm1.org_1   | 2022-02-05 13:17:49,234 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:17:49,244 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
scm1.org_1   | 2022-02-05 13:17:50,257 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:57156
om1_1        | 2022-02-05 13:30:59,524 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:30:59,526 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
scm3.org_1   | 2022-02-05 13:30:19,092 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38878
scm3.org_1   | 2022-02-05 13:30:19,106 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47952
scm3.org_1   | 2022-02-05 13:30:19,130 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:30:19,133 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:17:50,264 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:17:55,407 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:34101
scm1.org_1   | 2022-02-05 13:17:55,423 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om1_1        | 2022-02-05 13:31:00,012 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:31:00,014 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:31:00,015 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:31:00,049 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:31:00,556 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
scm3.org_1   | 2022-02-05 13:30:19,150 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:30:49,048 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48022
scm3.org_1   | 2022-02-05 13:30:49,081 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50330
scm1.org_1   | 2022-02-05 13:18:01,862 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:57192
scm1.org_1   | 2022-02-05 13:18:01,874 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:18:14,254 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:58752
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
om1_1        | 2022-02-05 13:31:00,557 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:31:06,073 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37396
scm1.org_1   | 2022-02-05 13:18:14,262 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-02-05 13:18:19,084 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54264
scm1.org_1   | 2022-02-05 13:18:19,107 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59442
scm3.org_1   | 2022-02-05 13:30:49,087 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38948
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
scm3.org_1   | 2022-02-05 13:30:49,091 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:30:49,142 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-02-05 13:31:06,101 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:31:07,526 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:44819
om1_1        | 2022-02-05 13:31:07,538 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm1.org_1   | 2022-02-05 13:18:19,118 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48722
scm1.org_1   | 2022-02-05 13:18:19,121 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:30:49,150 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:31:19,058 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50428
scm3.org_1   | 2022-02-05 13:31:19,075 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48128
scm3.org_1   | 2022-02-05 13:31:19,081 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:18:19,139 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-02-05 13:15:19,039 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60484
om1_1        | 2022-02-05 13:31:09,284 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:31:09,291 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:31:09,805 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
scm1.org_1   | 2022-02-05 13:18:19,200 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
recon_1      | 2022-02-05 13:15:19,093 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48102
recon_1      | 2022-02-05 13:15:19,125 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60868
recon_1      | 2022-02-05 13:15:19,144 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:15:19,175 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm1.org_1   | 2022-02-05 13:18:27,296 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:58832
scm1.org_1   | 2022-02-05 13:18:27,303 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-02-05 13:18:42,446 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:58912
scm3.org_1   | 2022-02-05 13:31:19,089 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39036
scm3.org_1   | 2022-02-05 13:31:19,117 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:31:19,144 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
om1_1        | 2022-02-05 13:31:09,808 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:31:09,811 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:31:50,673 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:37755
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
recon_1      | 2022-02-05 13:15:19,189 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:15:49,107 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:32838
scm3.org_1   | 2022-02-05 13:31:49,081 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48202
scm3.org_1   | 2022-02-05 13:31:49,086 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39108
scm3.org_1   | 2022-02-05 13:31:49,098 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:18:42,465 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-02-05 13:18:49,193 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48874
scm1.org_1   | 2022-02-05 13:18:49,194 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59600
om1_1        | 2022-02-05 13:31:50,675 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:31:50,676 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:07,593 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35831
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
recon_1      | 2022-02-05 13:15:49,120 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60686
scm1.org_1   | 2022-02-05 13:18:49,215 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54422
scm3.org_1   | 2022-02-05 13:31:49,120 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50502
scm3.org_1   | 2022-02-05 13:31:49,129 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
scm1.org_1   | 2022-02-05 13:18:49,221 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:18:49,247 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:18:49,249 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:19:19,101 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48974
recon_1      | 2022-02-05 13:15:49,122 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48316
om1_1        | 2022-02-05 13:32:07,596 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1      | 2022-02-05 13:15:49,154 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm3.org_1   | 2022-02-05 13:31:49,143 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:32:19,073 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48290
scm3.org_1   | 2022-02-05 13:32:19,102 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39196
om1_1        | 2022-02-05 13:32:10,119 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:40675
om1_1        | 2022-02-05 13:32:10,121 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:32:10,121 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
recon_1      | 2022-02-05 13:15:49,162 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm1.org_1   | 2022-02-05 13:19:19,111 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59704
scm1.org_1   | 2022-02-05 13:19:19,145 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:19:19,169 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54532
scm3.org_1   | 2022-02-05 13:32:19,114 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-02-05 13:15:49,197 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
om1_1        | 2022-02-05 13:32:10,124 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:10,127 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
scm3.org_1   | 2022-02-05 13:32:19,123 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50596
scm3.org_1   | 2022-02-05 13:32:19,145 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:32:19,163 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-02-05 13:16:06,788 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-02-05 13:16:06,788 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
om1_1        | 2022-02-05 13:32:10,279 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:10,917 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:10,921 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
scm1.org_1   | 2022-02-05 13:19:19,181 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:19:19,198 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:19:49,084 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59782
scm1.org_1   | 2022-02-05 13:19:49,091 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49054
recon_1      | 2022-02-05 13:16:06,840 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
scm3.org_1   | 2022-02-05 13:32:49,074 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39336
scm3.org_1   | 2022-02-05 13:32:49,084 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48428
scm3.org_1   | 2022-02-05 13:32:49,160 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50728
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
om1_1        | 2022-02-05 13:32:10,923 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:11,025 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:11,605 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
scm1.org_1   | 2022-02-05 13:19:49,118 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:19:49,142 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54604
scm1.org_1   | 2022-02-05 13:19:49,145 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:19:49,174 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:32:49,188 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-02-05 13:32:49,209 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
om1_1        | 2022-02-05 13:32:11,607 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:11,609 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:11,667 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:12,157 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
scm3.org_1   | 2022-02-05 13:32:49,232 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
scm1.org_1   | 2022-02-05 13:19:50,266 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:57620
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
om1_1        | 2022-02-05 13:32:12,159 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:12,161 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:12,163 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:12,649 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:12,651 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:12,652 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:12,669 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:12,676 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:12,695 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-6636892664, Key:ozone-test-9758447856/multidelete/key=value/f4.
om1_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
scm1.org_1   | 2022-02-05 13:19:50,269 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:20:15,893 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59182
scm1.org_1   | 2022-02-05 13:20:15,896 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-02-05 13:20:15,983 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:57662
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #141 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:368)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:368)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:357)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-02-05 13:22:16,249 [qtp1431556341-22] INFO scm.XceiverClientRatis: Could not commit index 131 on pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]] to all the nodes. Server 9905eb49-ac94-40b9-a1a3-f35673531eee has failed. Committed by majority.
s3g_1        | 2022-02-05 13:22:16,249 [qtp1431556341-22] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 109611004723200043 bcsId: 131 on Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]]. Failed nodes: [9905eb49-ac94-40b9-a1a3-f35673531eee{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-02-05 13:23:16,598 [qtp1431556341-24] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #147 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
scm1.org_1   | 2022-02-05 13:20:15,990 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:20:19,067 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59860
scm1.org_1   | 2022-02-05 13:20:19,096 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54676
scm1.org_1   | 2022-02-05 13:20:19,119 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49132
scm1.org_1   | 2022-02-05 13:20:19,125 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:20:19,133 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:20:19,164 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:20:49,067 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54758
scm1.org_1   | 2022-02-05 13:20:49,070 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59934
scm1.org_1   | 2022-02-05 13:20:49,096 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49208
scm1.org_1   | 2022-02-05 13:20:49,133 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:20:49,152 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:20:49,169 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:21:16,974 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59340
scm1.org_1   | 2022-02-05 13:21:16,977 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-02-05 13:21:17,074 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:57822
scm1.org_1   | 2022-02-05 13:21:17,078 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:21:19,121 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60034
scm1.org_1   | 2022-02-05 13:21:19,121 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54830
scm1.org_1   | 2022-02-05 13:21:19,128 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49286
scm1.org_1   | 2022-02-05 13:21:19,183 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:21:19,198 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:21:19,206 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:21:33,255 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:57892
scm1.org_1   | 2022-02-05 13:21:33,257 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:21:49,060 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54936
scm1.org_1   | 2022-02-05 13:21:49,065 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60122
scm1.org_1   | 2022-02-05 13:21:49,079 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:21:49,086 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:21:49,110 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49392
scm1.org_1   | 2022-02-05 13:21:49,115 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:21:50,264 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:57956
scm1.org_1   | 2022-02-05 13:21:50,270 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:22:19,045 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60186
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:148)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:94)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:244)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:502)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$2(OzoneManagerStateMachine.java:312)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-02-05 13:32:13,209 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:13,211 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:13,212 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:13,217 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:20,743 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37620
om1_1        | 2022-02-05 13:32:20,786 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:32:24,337 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:41345
om1_1        | 2022-02-05 13:32:24,342 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-02-05 13:32:24,343 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:24,348 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:25,006 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:25,008 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:25,009 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:25,199 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:25,850 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:25,852 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:25,857 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:25,859 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:26,397 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:26,403 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:26,406 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:26,430 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:27,078 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:27,082 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:27,083 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:27,086 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:27,659 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:27,661 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:27,662 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:27,681 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:28,322 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:28,324 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:28,330 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:28,341 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:28,962 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:28,965 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:28,971 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:28,977 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:29,555 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:29,556 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:29,561 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:29,568 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:373)
scm1.org_1   | 2022-02-05 13:22:19,064 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49458
scm1.org_1   | 2022-02-05 13:22:19,092 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55002
scm1.org_1   | 2022-02-05 13:22:19,139 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:22:19,147 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:22:19,151 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:22:33,763 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:58042
scm1.org_1   | 2022-02-05 13:22:33,769 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:22:46,370 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm1.org_1   | 2022-02-05 13:22:49,082 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55084
scm1.org_1   | 2022-02-05 13:22:49,130 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60268
scm1.org_1   | 2022-02-05 13:22:49,142 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49544
scm1.org_1   | 2022-02-05 13:22:49,143 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:22:49,159 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:22:49,170 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:22:50,267 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:58106
scm1.org_1   | 2022-02-05 13:22:50,269 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:22:55,449 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:39215
scm1.org_1   | 2022-02-05 13:22:55,456 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:533)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:547)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:495)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:469)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:522)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:639)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:167)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
scm1.org_1   | 2022-02-05 13:23:19,079 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55158
scm1.org_1   | 2022-02-05 13:23:19,115 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60340
scm1.org_1   | 2022-02-05 13:23:19,124 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-02-05 13:32:30,157 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
scm1.org_1   | 2022-02-05 13:23:19,141 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49608
scm1.org_1   | 2022-02-05 13:23:19,169 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	... 35 more
recon_1      | 2022-02-05 13:16:19,080 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60762
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
recon_1      | 2022-02-05 13:16:19,123 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:16:19,160 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:32916
scm1.org_1   | 2022-02-05 13:23:19,177 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:23:34,685 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:58192
recon_1      | 2022-02-05 13:16:19,179 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:16:19,195 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48374
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
recon_1      | 2022-02-05 13:16:19,208 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:16:49,086 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48478
recon_1      | 2022-02-05 13:16:49,094 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33014
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
recon_1      | 2022-02-05 13:16:49,105 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60862
recon_1      | 2022-02-05 13:16:49,110 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:16:49,135 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
scm1.org_1   | 2022-02-05 13:23:34,691 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:23:49,057 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55240
om1_1        | 2022-02-05 13:32:30,158 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:30,160 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:30,722 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:30,723 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:30,725 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
scm1.org_1   | 2022-02-05 13:23:49,152 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60418
scm1.org_1   | 2022-02-05 13:23:49,153 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-02-05 13:32:30,736 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:31,447 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:31,449 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:31,451 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:31,462 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
scm1.org_1   | 2022-02-05 13:23:49,162 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49692
recon_1      | 2022-02-05 13:16:49,156 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:17:06,845 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
recon_1      | 2022-02-05 13:17:06,845 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-02-05 13:17:06,900 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
om1_1        | 2022-02-05 13:32:32,101 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
scm1.org_1   | 2022-02-05 13:23:49,180 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:23:49,191 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:23:50,263 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:58258
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
scm1.org_1   | 2022-02-05 13:23:50,265 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om1_1        | 2022-02-05 13:32:32,103 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
om1_1        | 2022-02-05 13:32:32,104 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:32,112 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
scm1.org_1   | 2022-02-05 13:24:19,100 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49760
scm1.org_1   | 2022-02-05 13:24:19,125 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55302
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
scm1.org_1   | 2022-02-05 13:24:19,150 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:24:19,161 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
om1_1        | 2022-02-05 13:32:32,752 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:32,755 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
om1_1        | 2022-02-05 13:32:32,758 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:32,765 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
om1_1        | 2022-02-05 13:32:33,432 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:33,434 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
scm1.org_1   | 2022-02-05 13:24:19,173 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60486
scm1.org_1   | 2022-02-05 13:24:19,182 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
om1_1        | 2022-02-05 13:32:33,436 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:33,445 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:34,103 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:34,104 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:34,106 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:34,112 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:34,807 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
scm1.org_1   | 2022-02-05 13:24:35,333 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:58344
scm1.org_1   | 2022-02-05 13:24:35,343 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om1_1        | 2022-02-05 13:32:34,809 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:34,811 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:34,818 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:35,476 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:35,480 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:35,482 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:35,491 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
scm1.org_1   | 2022-02-05 13:24:49,083 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55388
scm1.org_1   | 2022-02-05 13:24:49,088 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60570
om1_1        | 2022-02-05 13:32:36,078 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:36,081 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:36,082 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:36,642 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:36,645 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:36,647 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:37,176 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om1_1        | 2022-02-05 13:32:37,179 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
scm1.org_1   | 2022-02-05 13:24:49,098 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49850
scm1.org_1   | 2022-02-05 13:24:49,105 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:24:49,131 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
scm1.org_1   | 2022-02-05 13:24:49,151 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:25:19,051 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55458
scm1.org_1   | 2022-02-05 13:25:19,072 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49910
scm1.org_1   | 2022-02-05 13:25:19,092 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60638
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
om1_1        | 2022-02-05 13:32:37,181 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
om1_1        | 2022-02-05 13:32:43,372 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37708
scm1.org_1   | 2022-02-05 13:25:19,106 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm1.org_1   | 2022-02-05 13:25:19,115 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:25:19,130 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:25:38,734 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:58512
scm1.org_1   | 2022-02-05 13:25:38,737 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
om1_1        | 2022-02-05 13:32:43,395 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
om1_1        | 2022-02-05 13:32:46,608 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
scm1.org_1   | 2022-02-05 13:25:49,057 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49988
scm1.org_1   | 2022-02-05 13:25:49,079 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:25:49,125 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55530
recon_1      | 	... 19 more
om1_1        | 2022-02-05 13:32:46,611 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 8c6d556d9c84fc3e88db084d2a9e8208af3ccbf164fca5f7e31b13ba782f99f3
scm1.org_1   | 2022-02-05 13:25:49,146 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60718
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #147 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:368)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:368)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:357)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
scm1.org_1   | 2022-02-05 13:25:49,172 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
scm1.org_1   | 2022-02-05 13:25:49,199 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:25:50,269 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:58558
scm1.org_1   | 2022-02-05 13:25:50,280 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:26:19,055 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55604
scm1.org_1   | 2022-02-05 13:26:19,075 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60786
scm1.org_1   | 2022-02-05 13:26:19,117 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:26:19,123 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50064
scm1.org_1   | 2022-02-05 13:26:19,132 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:26:19,167 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:26:44,794 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:58686
scm1.org_1   | 2022-02-05 13:26:44,798 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
scm1.org_1   | 2022-02-05 13:26:46,116 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:60218
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
scm1.org_1   | 2022-02-05 13:26:46,126 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-02-05 13:26:49,115 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60900
scm1.org_1   | 2022-02-05 13:26:49,143 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55718
scm1.org_1   | 2022-02-05 13:26:49,148 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50172
scm1.org_1   | 2022-02-05 13:26:49,165 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
s3g_1        | 	... 1 more
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
scm1.org_1   | 2022-02-05 13:26:49,182 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 2022-02-05 13:23:16,608 [qtp1431556341-24] INFO scm.XceiverClientRatis: Could not commit index 138 on pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]] to all the nodes. Server 9905eb49-ac94-40b9-a1a3-f35673531eee has failed. Committed by majority.
s3g_1        | 2022-02-05 13:23:16,609 [qtp1431556341-24] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 109611004723200044 bcsId: 138 on Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]]. Failed nodes: [9905eb49-ac94-40b9-a1a3-f35673531eee{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-02-05 13:24:33,361 [qtp1431556341-17] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #157 timeout 180s
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
scm1.org_1   | 2022-02-05 13:26:49,202 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:27:19,067 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55786
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
scm1.org_1   | 2022-02-05 13:27:19,070 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60968
scm1.org_1   | 2022-02-05 13:27:19,107 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:27:19,116 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50242
scm1.org_1   | 2022-02-05 13:27:19,123 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:27:19,141 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:27:46,370 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm1.org_1   | 2022-02-05 13:27:49,096 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50318
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:373)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:533)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:547)
recon_1      | 	... 35 more
recon_1      | 2022-02-05 13:17:19,061 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33110
recon_1      | 2022-02-05 13:17:19,099 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48590
recon_1      | 2022-02-05 13:17:19,161 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:17:19,174 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:17:19,274 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60966
recon_1      | 2022-02-05 13:17:19,286 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:17:49,080 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48686
scm1.org_1   | 2022-02-05 13:27:49,112 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55866
scm1.org_1   | 2022-02-05 13:27:49,123 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:32812
scm1.org_1   | 2022-02-05 13:27:49,141 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:27:49,148 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:27:49,172 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:27:49,483 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:58886
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:495)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:469)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:522)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:231)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
recon_1      | 2022-02-05 13:17:49,129 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:32864
recon_1      | 2022-02-05 13:17:49,165 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33222
recon_1      | 2022-02-05 13:17:49,167 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:17:49,175 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:17:49,199 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:17:55,358 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 2 milliseconds to process 0 existing database records.
recon_1      | 2022-02-05 13:17:55,364 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 6 milliseconds for processing 2 containers.
recon_1      | 2022-02-05 13:17:55,431 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-02-05 13:17:55,434 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 57 milliseconds.
recon_1      | 2022-02-05 13:18:06,901 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-02-05 13:18:06,901 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-02-05 13:18:06,935 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
scm1.org_1   | 2022-02-05 13:27:49,495 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
scm1.org_1   | 2022-02-05 13:27:55,487 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:37983
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
scm1.org_1   | 2022-02-05 13:27:55,495 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-02-05 13:28:19,082 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:32884
scm1.org_1   | 2022-02-05 13:28:19,082 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55934
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
scm1.org_1   | 2022-02-05 13:28:19,130 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50390
scm1.org_1   | 2022-02-05 13:28:19,140 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:28:19,145 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:28:19,157 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:28:49,069 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56016
scm1.org_1   | 2022-02-05 13:28:49,101 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50474
scm1.org_1   | 2022-02-05 13:28:49,113 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:28:49,141 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:32962
scm1.org_1   | 2022-02-05 13:28:49,149 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:28:49,156 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:28:49,708 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59036
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
scm1.org_1   | 2022-02-05 13:28:49,735 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:29:19,067 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56084
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm1.org_1   | 2022-02-05 13:29:19,101 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50540
scm1.org_1   | 2022-02-05 13:29:19,108 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33034
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm1.org_1   | 2022-02-05 13:29:19,125 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:29:19,136 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:29:19,165 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
scm1.org_1   | 2022-02-05 13:29:49,061 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33110
scm1.org_1   | 2022-02-05 13:29:49,089 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50614
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
scm1.org_1   | 2022-02-05 13:29:49,095 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56174
scm1.org_1   | 2022-02-05 13:29:49,109 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
scm1.org_1   | 2022-02-05 13:29:49,161 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:29:49,189 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
scm1.org_1   | 2022-02-05 13:29:53,580 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59184
scm1.org_1   | 2022-02-05 13:29:53,587 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
scm1.org_1   | 2022-02-05 13:29:56,167 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:60728
scm1.org_1   | 2022-02-05 13:29:56,174 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
scm1.org_1   | 2022-02-05 13:30:19,133 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56240
scm1.org_1   | 2022-02-05 13:30:19,135 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50710
scm1.org_1   | 2022-02-05 13:30:19,148 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
scm1.org_1   | 2022-02-05 13:30:19,160 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
scm1.org_1   | 2022-02-05 13:30:19,164 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33206
scm1.org_1   | 2022-02-05 13:30:19,170 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:30:49,054 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56318
scm1.org_1   | 2022-02-05 13:30:49,082 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50770
scm1.org_1   | 2022-02-05 13:30:49,089 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:30:49,128 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:30:49,163 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33268
scm1.org_1   | 2022-02-05 13:30:49,168 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:30:50,261 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59346
scm1.org_1   | 2022-02-05 13:30:50,263 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:31:00,043 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:60892
scm1.org_1   | 2022-02-05 13:31:00,044 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-02-05 13:31:09,819 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59398
scm1.org_1   | 2022-02-05 13:31:09,823 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:31:19,087 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50868
scm1.org_1   | 2022-02-05 13:31:19,092 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33362
scm1.org_1   | 2022-02-05 13:31:19,120 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:31:19,124 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56412
scm1.org_1   | 2022-02-05 13:31:19,129 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:31:19,153 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:31:49,062 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33436
scm1.org_1   | 2022-02-05 13:31:49,063 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50948
scm1.org_1   | 2022-02-05 13:31:49,078 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:31:49,087 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56486
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
scm1.org_1   | 2022-02-05 13:31:49,102 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:31:49,130 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:31:50,263 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59518
scm1.org_1   | 2022-02-05 13:31:50,266 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
scm1.org_1   | 2022-02-05 13:32:10,143 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59548
scm1.org_1   | 2022-02-05 13:32:10,147 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:32:19,059 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33532
scm1.org_1   | 2022-02-05 13:32:19,089 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56576
scm1.org_1   | 2022-02-05 13:32:19,128 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51032
scm1.org_1   | 2022-02-05 13:32:19,130 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:32:19,139 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:32:19,165 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:32:25,023 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59612
scm1.org_1   | 2022-02-05 13:32:25,034 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-02-05 13:32:27,672 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:32924
scm1.org_1   | 2022-02-05 13:32:27,675 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-02-05 13:32:46,371 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 2 containers.
scm1.org_1   | 2022-02-05 13:32:49,128 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33664
scm1.org_1   | 2022-02-05 13:32:49,157 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51168
scm1.org_1   | 2022-02-05 13:32:49,158 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56712
scm1.org_1   | 2022-02-05 13:32:49,185 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:32:49,201 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:32:49,222 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-02-05 13:32:50,258 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59744
scm1.org_1   | 2022-02-05 13:32:50,264 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #157 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:368)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
recon_1      | 	... 35 more
recon_1      | 2022-02-05 13:18:19,076 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48820
recon_1      | 2022-02-05 13:18:19,102 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:32970
recon_1      | 2022-02-05 13:18:19,118 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33356
recon_1      | 2022-02-05 13:18:19,121 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:18:19,162 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:18:19,193 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:18:49,078 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33518
recon_1      | 2022-02-05 13:18:49,124 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33130
recon_1      | 2022-02-05 13:18:49,163 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48982
recon_1      | 2022-02-05 13:18:49,177 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:18:49,222 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:18:49,232 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:19:06,936 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-02-05 13:19:06,937 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-02-05 13:19:06,974 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:368)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:357)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-02-05 13:24:33,369 [qtp1431556341-17] INFO scm.XceiverClientRatis: Could not commit index 143 on pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]] to all the nodes. Server 9905eb49-ac94-40b9-a1a3-f35673531eee has failed. Committed by majority.
s3g_1        | 2022-02-05 13:24:33,369 [qtp1431556341-17] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 109611004723200046 bcsId: 143 on Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]]. Failed nodes: [9905eb49-ac94-40b9-a1a3-f35673531eee{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-02-05 13:25:33,886 [qtp1431556341-20] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #162 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:373)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:533)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:547)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:495)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:469)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:522)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:231)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-02-05 13:19:19,066 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33236
recon_1      | 2022-02-05 13:19:19,107 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33616
recon_1      | 2022-02-05 13:19:19,124 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:19:19,124 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49082
recon_1      | 2022-02-05 13:19:19,168 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:19:19,181 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:19:49,077 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33694
recon_1      | 2022-02-05 13:19:49,093 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33310
recon_1      | 2022-02-05 13:19:49,098 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49158
recon_1      | 2022-02-05 13:19:49,120 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:19:49,144 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:19:49,168 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:20:06,976 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-02-05 13:20:06,977 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-02-05 13:20:07,014 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #162 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:368)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:368)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:357)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-02-05 13:25:33,902 [qtp1431556341-20] INFO scm.XceiverClientRatis: Could not commit index 147 on pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]] to all the nodes. Server 9905eb49-ac94-40b9-a1a3-f35673531eee has failed. Committed by majority.
s3g_1        | 2022-02-05 13:25:33,903 [qtp1431556341-20] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 109611004723200047 bcsId: 147 on Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]]. Failed nodes: [9905eb49-ac94-40b9-a1a3-f35673531eee{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-02-05 13:26:34,863 [qtp1431556341-23] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #167 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:373)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:533)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:547)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:495)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:469)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:522)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:231)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-02-05 13:20:19,038 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49236
recon_1      | 2022-02-05 13:20:19,078 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33384
recon_1      | 2022-02-05 13:20:19,094 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33776
recon_1      | 2022-02-05 13:20:19,124 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:20:19,139 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:20:19,147 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:20:49,083 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33464
recon_1      | 2022-02-05 13:20:49,092 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33852
recon_1      | 2022-02-05 13:20:49,128 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49314
recon_1      | 2022-02-05 13:20:49,130 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:20:49,159 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:20:49,172 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:21:07,015 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-02-05 13:21:07,016 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-02-05 13:21:07,063 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #167 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:368)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:368)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:357)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-02-05 13:21:19,056 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33922
recon_1      | 2022-02-05 13:21:19,075 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49386
recon_1      | 2022-02-05 13:21:19,098 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33558
recon_1      | 2022-02-05 13:21:19,114 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:21:19,180 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:21:19,190 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:21:49,060 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49496
recon_1      | 2022-02-05 13:21:49,064 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33644
recon_1      | 2022-02-05 13:21:49,079 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:21:49,087 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:21:49,111 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34034
recon_1      | 2022-02-05 13:21:49,116 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:22:07,064 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-02-05 13:22:07,064 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-02-05 13:22:07,123 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-02-05 13:26:34,868 [qtp1431556341-23] INFO scm.XceiverClientRatis: Could not commit index 151 on pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]] to all the nodes. Server 9905eb49-ac94-40b9-a1a3-f35673531eee has failed. Committed by majority.
s3g_1        | 2022-02-05 13:26:34,869 [qtp1431556341-23] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 109611004723200048 bcsId: 151 on Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]]. Failed nodes: [9905eb49-ac94-40b9-a1a3-f35673531eee{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-02-05 13:26:44,265 [qtp1431556341-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-6915578855, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-02-05 13:26:44,276 [qtp1431556341-20] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-6915578855
s3g_1        | 2022-02-05 13:27:35,448 [qtp1431556341-22] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #172 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:373)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:533)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:547)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:495)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:469)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:522)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:231)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-02-05 13:22:19,057 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34100
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
recon_1      | 2022-02-05 13:22:19,075 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33714
recon_1      | 2022-02-05 13:22:19,096 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49564
recon_1      | 2022-02-05 13:22:19,132 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:22:19,137 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:22:19,154 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:22:49,055 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49646
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
recon_1      | 2022-02-05 13:22:49,107 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34180
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
recon_1      | 2022-02-05 13:22:49,118 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33796
recon_1      | 2022-02-05 13:22:49,127 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
recon_1      | 2022-02-05 13:22:49,136 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:22:49,168 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:22:55,365 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
recon_1      | 2022-02-05 13:22:55,371 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 4 milliseconds for processing 2 containers.
recon_1      | 2022-02-05 13:22:55,459 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-02-05 13:22:55,463 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 23 milliseconds.
recon_1      | 2022-02-05 13:23:07,125 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-02-05 13:23:07,125 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
recon_1      | 2022-02-05 13:23:07,168 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #172 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:368)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:368)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:357)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 2022-02-05 13:27:35,458 [qtp1431556341-22] INFO scm.XceiverClientRatis: Could not commit index 155 on pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]] to all the nodes. Server 9905eb49-ac94-40b9-a1a3-f35673531eee has failed. Committed by majority.
s3g_1        | 2022-02-05 13:27:35,459 [qtp1431556341-22] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 109611004723200049 bcsId: 155 on Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]]. Failed nodes: [9905eb49-ac94-40b9-a1a3-f35673531eee{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-02-05 13:28:38,857 [qtp1431556341-17] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #177 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:373)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:533)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:547)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:495)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:469)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:522)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:231)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-02-05 13:23:19,057 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33862
recon_1      | 2022-02-05 13:23:19,074 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49714
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
recon_1      | 2022-02-05 13:23:19,100 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34250
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
recon_1      | 2022-02-05 13:23:19,124 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
recon_1      | 2022-02-05 13:23:19,160 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
recon_1      | 2022-02-05 13:23:19,177 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
recon_1      | 2022-02-05 13:23:49,079 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34332
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
recon_1      | 2022-02-05 13:23:49,080 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49800
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
recon_1      | 2022-02-05 13:23:49,132 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33946
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
recon_1      | 2022-02-05 13:23:49,148 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
recon_1      | 2022-02-05 13:23:49,149 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
recon_1      | 2022-02-05 13:23:49,195 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
recon_1      | 2022-02-05 13:24:07,169 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
recon_1      | 2022-02-05 13:24:07,169 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
recon_1      | 2022-02-05 13:24:07,205 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
recon_1      | java.lang.reflect.UndeclaredThrowableException
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #177 timeout 180s
recon_1      | 	... 12 more
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:368)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:368)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:357)
recon_1      | 	... 19 more
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	... 20 more
s3g_1        | 	... 1 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
s3g_1        | 2022-02-05 13:28:38,862 [qtp1431556341-17] INFO scm.XceiverClientRatis: Could not commit index 160 on pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]] to all the nodes. Server 9905eb49-ac94-40b9-a1a3-f35673531eee has failed. Committed by majority.
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
s3g_1        | 2022-02-05 13:28:38,863 [qtp1431556341-17] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 109611004723200050 bcsId: 160 on Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]]. Failed nodes: [9905eb49-ac94-40b9-a1a3-f35673531eee{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
s3g_1        | 2022-02-05 13:29:49,381 [qtp1431556341-19] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]]
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #186 timeout 180s
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:373)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:533)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:547)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:495)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:469)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:522)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:231)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
recon_1      | 	... 27 more
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #186 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:368)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:373)
recon_1      | 	... 35 more
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:368)
recon_1      | 2022-02-05 13:24:19,040 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34026
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:357)
recon_1      | 2022-02-05 13:24:19,097 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34400
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
recon_1      | 2022-02-05 13:24:19,105 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49866
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
recon_1      | 2022-02-05 13:24:19,137 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
recon_1      | 2022-02-05 13:24:19,152 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:24:19,161 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
recon_1      | 2022-02-05 13:24:49,068 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49948
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 2022-02-05 13:24:49,087 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34098
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
recon_1      | 2022-02-05 13:24:49,100 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34484
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
recon_1      | 2022-02-05 13:24:49,106 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 2022-02-05 13:24:49,125 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 2022-02-05 13:24:49,143 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 	... 1 more
recon_1      | 2022-02-05 13:25:07,206 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1        | 2022-02-05 13:29:49,408 [qtp1431556341-19] INFO scm.XceiverClientRatis: Could not commit index 164 on pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]] to all the nodes. Server 9905eb49-ac94-40b9-a1a3-f35673531eee has failed. Committed by majority.
recon_1      | 2022-02-05 13:25:07,206 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
s3g_1        | 2022-02-05 13:29:49,408 [qtp1431556341-19] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 109611004723200052 bcsId: 164 on Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]]. Failed nodes: [9905eb49-ac94-40b9-a1a3-f35673531eee{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
recon_1      | 2022-02-05 13:25:07,259 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
s3g_1        | 2022-02-05 13:30:49,592 [qtp1431556341-20] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]]
recon_1      | java.lang.reflect.UndeclaredThrowableException
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #191 timeout 180s
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:373)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:533)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:547)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:495)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:469)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:522)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:231)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #191 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:368)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:368)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:357)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-02-05 13:25:19,066 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50014
recon_1      | 2022-02-05 13:25:19,071 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34166
recon_1      | 2022-02-05 13:25:19,074 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34550
recon_1      | 2022-02-05 13:25:19,112 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:25:19,125 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:25:19,147 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:25:49,097 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34628
recon_1      | 2022-02-05 13:25:49,116 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50090
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
recon_1      | 2022-02-05 13:25:49,119 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34250
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
recon_1      | 2022-02-05 13:25:49,152 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:25:49,164 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:25:49,183 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
recon_1      | 2022-02-05 13:26:07,259 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 2022-02-05 13:26:07,259 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
recon_1      | 2022-02-05 13:26:07,300 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
recon_1      | java.lang.reflect.UndeclaredThrowableException
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
s3g_1        | 2022-02-05 13:30:49,597 [qtp1431556341-20] INFO scm.XceiverClientRatis: Could not commit index 167 on pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]] to all the nodes. Server 9905eb49-ac94-40b9-a1a3-f35673531eee has failed. Committed by majority.
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
s3g_1        | 2022-02-05 13:30:49,598 [qtp1431556341-20] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 109611004723200053 bcsId: 167 on Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]]. Failed nodes: [9905eb49-ac94-40b9-a1a3-f35673531eee{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
s3g_1        | 2022-02-05 13:31:09,287 [qtp1431556341-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-6636892664, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 2022-02-05 13:31:09,303 [qtp1431556341-17] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-6636892664
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
s3g_1        | 2022-02-05 13:31:49,831 [qtp1431556341-22] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]]
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #196 timeout 180s
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
recon_1      | 	at jdk.internal.reflect.GeneratedConstructorAccessor49.newInstance(Unknown Source)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:373)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:533)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:547)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:495)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:469)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:522)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:231)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
recon_1      | 	... 12 more
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
recon_1      | 	... 20 more
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
recon_1      | 	... 35 more
recon_1      | 2022-02-05 13:26:19,054 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50164
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
recon_1      | 2022-02-05 13:26:19,086 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34318
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
recon_1      | 2022-02-05 13:26:19,115 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
recon_1      | 2022-02-05 13:26:19,122 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34698
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
recon_1      | 2022-02-05 13:26:19,135 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:26:19,159 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
recon_1      | 2022-02-05 13:26:49,073 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50278
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
recon_1      | 2022-02-05 13:26:49,113 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34424
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
recon_1      | 2022-02-05 13:26:49,122 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34816
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
recon_1      | 2022-02-05 13:26:49,143 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
recon_1      | 2022-02-05 13:26:49,161 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
recon_1      | 2022-02-05 13:26:49,199 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
recon_1      | 2022-02-05 13:27:07,301 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
recon_1      | 2022-02-05 13:27:07,301 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
recon_1      | 2022-02-05 13:27:07,336 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
recon_1      | 	at jdk.internal.reflect.GeneratedConstructorAccessor49.newInstance(Unknown Source)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
recon_1      | 	... 12 more
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #196 timeout 180s
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:368)
recon_1      | 	... 19 more
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:373)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:368)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:357)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
s3g_1        | 	... 1 more
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
s3g_1        | 2022-02-05 13:31:49,837 [qtp1431556341-22] INFO scm.XceiverClientRatis: Could not commit index 171 on pipeline Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]] to all the nodes. Server 9905eb49-ac94-40b9-a1a3-f35673531eee has failed. Committed by majority.
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
s3g_1        | 2022-02-05 13:31:49,837 [qtp1431556341-22] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 109611004723200054 bcsId: 171 on Pipeline[ Id: cd0dbfd1-bf28-4717-93ea-139bdf3e2545, Nodes: a527daad-fcfc-4913-bb86-57ba7fce9b83{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3bd141d9-8d6a-4889-940a-437a7867e049{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9905eb49-ac94-40b9-a1a3-f35673531eee{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:a527daad-fcfc-4913-bb86-57ba7fce9b83, CreationTimestamp2022-02-05T13:09:32.907Z[UTC]]. Failed nodes: [9905eb49-ac94-40b9-a1a3-f35673531eee{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
s3g_1        | 2022-02-05 13:32:24,346 [qtp1431556341-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-6395062438, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
recon_1      | 	... 27 more
s3g_1        | 2022-02-05 13:32:24,363 [qtp1431556341-22] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-6395062438
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
s3g_1        | 2022-02-05 13:32:46,609 [qtp1431556341-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-3770273318, with root as owner and Versioning false and Storage Type set to DISK and Encryption set to false 
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
s3g_1        | 2022-02-05 13:32:46,618 [qtp1431556341-22] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-3770273318
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-02-05 13:27:19,036 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34498
recon_1      | 2022-02-05 13:27:19,061 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50350
recon_1      | 2022-02-05 13:27:19,087 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34886
recon_1      | 2022-02-05 13:27:19,094 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:27:19,104 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:27:19,129 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:27:49,024 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34574
recon_1      | 2022-02-05 13:27:49,099 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34960
recon_1      | 2022-02-05 13:27:49,110 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:27:49,114 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50422
recon_1      | 2022-02-05 13:27:49,146 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:27:49,152 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:27:55,372 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 2 milliseconds to process 0 existing database records.
recon_1      | 2022-02-05 13:27:55,379 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 6 milliseconds for processing 2 containers.
recon_1      | 2022-02-05 13:27:55,500 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-02-05 13:27:55,508 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 32 milliseconds.
recon_1      | 2022-02-05 13:28:07,337 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-02-05 13:28:07,337 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-02-05 13:28:07,368 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at jdk.internal.reflect.GeneratedConstructorAccessor49.newInstance(Unknown Source)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-02-05 13:28:19,041 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35032
recon_1      | 2022-02-05 13:28:19,044 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50496
recon_1      | 2022-02-05 13:28:19,113 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:28:19,118 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34648
recon_1      | 2022-02-05 13:28:19,127 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:28:19,156 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:28:49,035 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50576
recon_1      | 2022-02-05 13:28:49,053 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:28:49,081 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34724
recon_1      | 2022-02-05 13:28:49,121 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35108
recon_1      | 2022-02-05 13:28:49,143 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:28:49,173 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:29:07,369 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-02-05 13:29:07,369 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-02-05 13:29:07,410 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at jdk.internal.reflect.GeneratedConstructorAccessor49.newInstance(Unknown Source)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-02-05 13:29:19,058 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34798
recon_1      | 2022-02-05 13:29:19,106 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35182
recon_1      | 2022-02-05 13:29:19,123 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:29:19,127 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50648
recon_1      | 2022-02-05 13:29:19,158 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:29:19,158 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:29:49,059 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34870
recon_1      | 2022-02-05 13:29:49,136 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:29:49,143 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35254
recon_1      | 2022-02-05 13:29:49,154 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50722
recon_1      | 2022-02-05 13:29:49,175 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:29:49,194 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:30:07,420 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-02-05 13:30:07,420 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-02-05 13:30:07,471 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at jdk.internal.reflect.GeneratedConstructorAccessor49.newInstance(Unknown Source)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-02-05 13:30:19,053 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35344
recon_1      | 2022-02-05 13:30:19,063 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34970
recon_1      | 2022-02-05 13:30:19,104 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50804
recon_1      | 2022-02-05 13:30:19,110 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:30:19,116 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:30:19,147 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:30:49,046 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50874
recon_1      | 2022-02-05 13:30:49,071 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35024
recon_1      | 2022-02-05 13:30:49,083 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35414
recon_1      | 2022-02-05 13:30:49,089 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:30:49,143 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:30:49,155 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:31:07,513 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-02-05 13:31:07,513 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-02-05 13:31:07,560 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at jdk.internal.reflect.GeneratedConstructorAccessor49.newInstance(Unknown Source)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-02-05 13:31:19,057 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35510
recon_1      | 2022-02-05 13:31:19,063 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35122
recon_1      | 2022-02-05 13:31:19,080 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:31:19,103 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50974
recon_1      | 2022-02-05 13:31:19,117 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:31:19,149 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:31:49,082 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51048
recon_1      | 2022-02-05 13:31:49,103 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:31:49,109 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35580
recon_1      | 2022-02-05 13:31:49,121 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:31:49,138 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35198
recon_1      | 2022-02-05 13:31:49,155 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:32:07,563 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-02-05 13:32:07,563 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-02-05 13:32:07,607 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:297)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:329)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:427)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:233)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at jdk.internal.reflect.GeneratedConstructorAccessor49.newInstance(Unknown Source)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:237)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:298)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-02-05 13:32:19,048 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35288
recon_1      | 2022-02-05 13:32:19,090 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51140
recon_1      | 2022-02-05 13:32:19,116 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35674
recon_1      | 2022-02-05 13:32:19,118 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:32:19,138 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:32:19,153 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:32:49,073 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35426
recon_1      | 2022-02-05 13:32:49,110 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51274
recon_1      | 2022-02-05 13:32:49,118 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35812
recon_1      | 2022-02-05 13:32:49,180 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:32:49,204 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-02-05 13:32:49,206 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
