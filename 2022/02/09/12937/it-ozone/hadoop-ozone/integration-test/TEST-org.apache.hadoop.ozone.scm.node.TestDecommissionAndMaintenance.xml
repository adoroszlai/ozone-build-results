<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report.xsd" name="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="673.628" tests="8" errors="6" skipped="0" failures="0">
  <properties>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/classes:/home/runner/.m2/repository/org/apache/ozone/ozone-common/1.3.0-SNAPSHOT/ozone-common-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.3.0-SNAPSHOT/hdds-common-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-client/1.3.0-SNAPSHOT/hdds-client-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-client/1.3.0-SNAPSHOT/ozone-interface-client-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-test-utils/1.3.0-SNAPSHOT/hdds-test-utils-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/guava/guava/30.1.1-jre/guava-30.1.1-jre.jar:/home/runner/.m2/repository/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar:/home/runner/.m2/repository/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/runner/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/runner/.m2/repository/org/checkerframework/checker-qual/3.8.0/checker-qual-3.8.0.jar:/home/runner/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/runner/.m2/repository/com/google/j2objc/j2objc-annotations/1.3/j2objc-annotations-1.3.jar:/home/runner/.m2/repository/commons-io/commons-io/2.11.0/commons-io-2.11.0.jar:/home/runner/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/runner/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/runner/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.3.0-SNAPSHOT/hdds-server-scm-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-server/1.3.0-SNAPSHOT/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.1/hadoop-hdfs-3.3.1.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-framework/1.3.0-SNAPSHOT/hdds-server-framework-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-server/1.3.0-SNAPSHOT/hdds-interface-server-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-servlet/9.4.43.v20210629/jetty-servlet-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-security/9.4.43.v20210629/jetty-security-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/rocksdb/rocksdbjni/6.25.3/rocksdbjni-6.25.3.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_dropwizard/0.7.0/simpleclient_dropwizard-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient/0.7.0/simpleclient-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_common/0.7.0/simpleclient_common-0.7.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.12.1/jackson-datatype-jsr310-2.12.1.jar:/home/runner/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.3.1/hadoop-hdfs-client-3.3.1.jar:/home/runner/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.67/bcprov-jdk15on-1.67.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.3.0-SNAPSHOT/ozone-manager-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/aspectj/aspectjrt/1.9.7/aspectjrt-1.9.7.jar:/home/runner/.m2/repository/org/aspectj/aspectjweaver/1.9.7/aspectjweaver-1.9.7.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-client/1.3.0-SNAPSHOT/hdds-interface-client-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-protobuf_3_7/1.1.1/hadoop-shaded-protobuf_3_7-1.1.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-storage/1.3.0-SNAPSHOT/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.3.1/hadoop-minikdc-3.3.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/runner/.m2/repository/org/slf4j/slf4j-log4j12/1.7.30/slf4j-log4j12-1.7.30.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-s3gateway/1.3.0-SNAPSHOT/ozone-s3gateway-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/home/runner/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.33/jersey-container-servlet-core-2.33.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-common/2.33/jersey-common-2.33.jar:/home/runner/.m2/repository/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.33/jersey-cdi1x-2.33.jar:/home/runner/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.33/jersey-hk2-2.33.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.33/jersey-media-jaxb-2.33.jar:/home/runner/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.12.1/jackson-dataformat-xml-2.12.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.1/jackson-core-2.12.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.1/jackson-module-jaxb-annotations-2.12.1.jar:/home/runner/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/runner/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/runner/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/runner/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/runner/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/runner/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/runner/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/runner/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-runtime/2.3.0.1/jaxb-runtime-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/txw2/2.3.0.1/txw2-2.3.0.1.jar:/home/runner/.m2/repository/com/sun/istack/istack-commons-runtime/3.0.5/istack-commons-runtime-3.0.5.jar:/home/runner/.m2/repository/org/jvnet/staxex/stax-ex/1.7.8/stax-ex-1.7.8.jar:/home/runner/.m2/repository/com/sun/xml/fastinfoset/FastInfoset/1.2.13/FastInfoset-1.2.13.jar:/home/runner/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-csi/1.3.0-SNAPSHOT/ozone-csi-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java-util/3.12.0/protobuf-java-util-3.12.0.jar:/home/runner/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-config/1.3.0-SNAPSHOT/hdds-config-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/grpc/grpc-netty/1.33.0/grpc-netty-1.33.0.jar:/home/runner/.m2/repository/io/grpc/grpc-core/1.33.0/grpc-core-1.33.0.jar:/home/runner/.m2/repository/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar:/home/runner/.m2/repository/io/netty/netty-codec-http2/4.1.63.Final/netty-codec-http2-4.1.63.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.63.Final/netty-codec-http-4.1.63.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler-proxy/4.1.63.Final/netty-handler-proxy-4.1.63.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-socks/4.1.63.Final/netty-codec-socks-4.1.63.Final.jar:/home/runner/.m2/repository/io/perfmark/perfmark-api/0.19.0/perfmark-api-0.19.0.jar:/home/runner/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.18/animal-sniffer-annotations-1.18.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.63.Final/netty-transport-native-epoll-4.1.63.Final.jar:/home/runner/.m2/repository/io/netty/netty-common/4.1.63.Final/netty-common-4.1.63.Final.jar:/home/runner/.m2/repository/io/netty/netty-buffer/4.1.63.Final/netty-buffer-4.1.63.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.63.Final/netty-transport-native-unix-common-4.1.63.Final.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf/1.33.0/grpc-protobuf-1.33.0.jar:/home/runner/.m2/repository/io/grpc/grpc-api/1.33.0/grpc-api-1.33.0.jar:/home/runner/.m2/repository/io/grpc/grpc-context/1.33.0/grpc-context-1.33.0.jar:/home/runner/.m2/repository/com/google/api/grpc/proto-google-common-protos/1.17.0/proto-google-common-protos-1.17.0.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf-lite/1.33.0/grpc-protobuf-lite-1.33.0.jar:/home/runner/.m2/repository/io/grpc/grpc-stub/1.33.0/grpc-stub-1.33.0.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-recon/1.3.0-SNAPSHOT/ozone-recon-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-reconcodegen/1.3.0-SNAPSHOT/ozone-reconcodegen-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/runner/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/runner/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.33/jersey-container-servlet-2.33.jar:/home/runner/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-server/2.33/jersey-server-2.33.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-client/2.33/jersey-client-2.33.jar:/home/runner/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.5/jakarta.annotation-api-1.3.5.jar:/home/runner/.m2/repository/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.33/jersey-media-json-jackson-2.33.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.33/jersey-entity-filtering-2.33.jar:/home/runner/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/runner/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/runner/.m2/repository/org/apache/derby/derby/10.14.2.0/derby-10.14.2.0.jar:/home/runner/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/runner/.m2/repository/org/springframework/spring-jdbc/5.2.18.RELEASE/spring-jdbc-5.2.18.RELEASE.jar:/home/runner/.m2/repository/org/springframework/spring-beans/5.2.18.RELEASE/spring-beans-5.2.18.RELEASE.jar:/home/runner/.m2/repository/org/springframework/spring-core/5.2.18.RELEASE/spring-core-5.2.18.RELEASE.jar:/home/runner/.m2/repository/org/springframework/spring-jcl/5.2.18.RELEASE/spring-jcl-5.2.18.RELEASE.jar:/home/runner/.m2/repository/org/springframework/spring-tx/5.2.18.RELEASE/spring-tx-5.2.18.RELEASE.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-client/1.3.0-SNAPSHOT/ozone-client-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem/1.3.0-SNAPSHOT/ozone-filesystem-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem-common/1.3.0-SNAPSHOT/ozone-filesystem-common-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-tools/1.3.0-SNAPSHOT/ozone-tools-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-tools/2.2.0/ratis-tools-2.2.0.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-core/1.12.124/aws-java-sdk-core-1.12.124.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/runner/.m2/repository/software/amazon/ion/ion-java/1.0.2/ion-java-1.0.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.12.1/jackson-dataformat-cbor-2.12.1.jar:/home/runner/.m2/repository/joda-time/joda-time/2.8.1/joda-time-2.8.1.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-s3/1.12.124/aws-java-sdk-s3-1.12.124.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-kms/1.12.124/aws-java-sdk-kms-1.12.124.jar:/home/runner/.m2/repository/com/amazonaws/jmespath-java/1.12.124/jmespath-java-1.12.124.jar:/home/runner/.m2/repository/org/kohsuke/metainf-services/metainf-services/1.8/metainf-services-1.8.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-tools/1.3.0-SNAPSHOT/hdds-tools-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/runner/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.3.0-SNAPSHOT/ozone-manager-1.3.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.3.0-SNAPSHOT/hdds-common-1.3.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-client/1.3.0-SNAPSHOT/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/info/picocli/picocli/4.6.1/picocli-4.6.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.1/jackson-annotations-2.12.1.jar:/home/runner/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server/2.2.0/ratis-server-2.2.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-client/2.2.0/ratis-client-2.2.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server-api/2.2.0/ratis-server-api-2.2.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics/2.2.0/ratis-metrics-2.2.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-netty/2.2.0/ratis-netty-2.2.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-grpc/2.2.0/ratis-grpc-2.2.0.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-api/2.17.1/log4j-api-2.17.1.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-core/2.17.1/log4j-core-2.17.1.jar:/home/runner/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/runner/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/runner/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.67/bcpkix-jdk15on-1.67.jar:/home/runner/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/runner/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/runner/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/runner/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-client/1.6.0/jaeger-client-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-thrift/1.6.0/jaeger-thrift-1.6.0.jar:/home/runner/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/runner/.m2/repository/com/squareup/okhttp3/okhttp/4.9.0/okhttp-4.9.0.jar:/home/runner/.m2/repository/com/squareup/okio/okio/2.8.0/okio-2.8.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-core/1.6.0/jaeger-core-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-tracerresolver/1.6.0/jaeger-tracerresolver-1.6.0.jar:/home/runner/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.8/opentracing-tracerresolver-0.1.8.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib/1.4.31/kotlin-stdlib-1.4.31.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-common/1.4.31/kotlin-stdlib-common-1.4.31.jar:/home/runner/.m2/repository/org/jetbrains/annotations/13.0/annotations-13.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-util/0.33.0/opentracing-util-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-api/0.33.0/opentracing-api-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-noop/0.33.0/opentracing-noop-0.33.0.jar:/home/runner/.m2/repository/org/yaml/snakeyaml/1.26/snakeyaml-1.26.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-admin/1.3.0-SNAPSHOT/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/junit/junit/4.13.1/junit-4.13.1.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.7.0/junit-jupiter-api-5.7.0.jar:/home/runner/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/runner/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-commons/1.7.0/junit-platform-commons-1.7.0.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.7.0/junit-jupiter-engine-5.7.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-engine/1.7.0/junit-platform-engine-1.7.0.jar:/home/runner/.m2/repository/org/junit/vintage/junit-vintage-engine/5.7.0/junit-vintage-engine-5.7.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-launcher/1.7.0/junit-platform-launcher-1.7.0.jar:/home/runner/.m2/repository/org/mockito/mockito-core/2.28.2/mockito-core-2.28.2.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy/1.9.10/byte-buddy-1.9.10.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy-agent/1.9.10/byte-buddy-agent-1.9.10.jar:/home/runner/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.1/hadoop-kms-3.3.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-auth/3.3.1/hadoop-auth-3.3.1.jar:/home/runner/.m2/repository/com/nimbusds/nimbus-jose-jwt/7.9/nimbus-jose-jwt-7.9.jar:/home/runner/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/runner/.m2/repository/net/minidev/json-smart/2.3.1/json-smart-2.3.1.jar:/home/runner/.m2/repository/net/minidev/accessors-smart/2.3.1/accessors-smart-2.3.1.jar:/home/runner/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper/3.5.6/zookeeper-3.5.6.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.6/zookeeper-jute-3.5.6.jar:/home/runner/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-guava/1.1.1/hadoop-shaded-guava-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/runner/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/runner/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-server/9.4.43.v20210629/jetty-server-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-http/9.4.43.v20210629/jetty-http-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-io/9.4.43.v20210629/jetty-io-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-webapp/9.4.43.v20210629/jetty-webapp-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-xml/9.4.43.v20210629/jetty-xml-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.1/hadoop-common-3.3.1.jar:/home/runner/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/runner/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/runner/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/runner/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/runner/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/runner/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/runner/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/runner/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/runner/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/runner/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/runner/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/runner/.m2/repository/org/xerial/snappy/snappy-java/1.1.8.2/snappy-java-1.1.8.2.jar:/home/runner/.m2/repository/org/slf4j/jul-to-slf4j/1.7.30/jul-to-slf4j-1.7.30.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util/9.4.43.v20210629/jetty-util-9.4.43.v20210629.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.1/jackson-databind-2.12.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.1/hadoop-kms-3.3.1-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.3.0-SNAPSHOT/hdds-server-scm-1.3.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/home/runner/.m2/repository/io/netty/netty-transport/4.1.63.Final/netty-transport-4.1.63.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver/4.1.63.Final/netty-resolver-4.1.63.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec/4.1.63.Final/netty-codec-4.1.63.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler/4.1.63.Final/netty-handler-4.1.63.Final.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-test/1.3.0-SNAPSHOT/hdds-hadoop-dependency-test-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.1/hadoop-common-3.3.1-tests.jar:/home/runner/.m2/repository/org/assertj/assertj-core/3.12.2/assertj-core-3.12.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.1/hadoop-hdfs-3.3.1-tests.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.4.43.v20210629/jetty-util-ajax-9.4.43.v20210629.jar:/home/runner/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/runner/.m2/repository/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/home/runner/.m2/repository/io/netty/netty-all/4.1.63.Final/netty-all-4.1.63.Final.jar:/home/runner/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/runner/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.1/hadoop-distcp-3.3.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.3.1/hadoop-mapreduce-client-jobclient-3.3.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.3.1/hadoop-mapreduce-client-common-3.3.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.3.1/hadoop-yarn-common-3.3.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.3.1/hadoop-yarn-api-3.3.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/runner/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.1/jackson-jaxrs-json-provider-2.12.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.1/jackson-jaxrs-base-2.12.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.3.1/hadoop-yarn-client-3.3.1.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.4.40.v20210413/websocket-client-9.4.40.v20210413.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-client/9.4.40.v20210413/jetty-client-9.4.40.v20210413.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.4.40.v20210413/websocket-common-9.4.40.v20210413.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.4.40.v20210413/websocket-api-9.4.40.v20210413.jar:/home/runner/.m2/repository/org/jline/jline/3.9.0/jline-3.9.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.3.1/hadoop-mapreduce-client-core-3.3.1.jar:/home/runner/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/runner/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-annotations/3.3.1/hadoop-annotations-3.3.1.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/../lib/tools.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.1/hadoop-distcp-3.3.1-tests.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-common/2.2.0/ratis-common-2.2.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/0.7.0/ratis-thirdparty-misc-0.7.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-proto/2.2.0/ratis-proto-2.2.0.jar:"/>
    <property name="java.vm.vendor" value="Temurin"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="test.build.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir"/>
    <property name="test.cache.data" value=""/>
    <property name="java.vendor.url" value="https://adoptium.net/"/>
    <property name="user.timezone" value=""/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="os.name" value="Linux"/>
    <property name="test.build.data" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/surefire/surefirebooter1792386987714083452.jar /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/surefire 2022-02-09T07-00-14_152-jvmRun1 surefire6093234441806265458tmp surefire_59701148842778130175tmp"/>
    <property name="surefire.test.class.path" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/classes:/home/runner/.m2/repository/org/apache/ozone/ozone-common/1.3.0-SNAPSHOT/ozone-common-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.3.0-SNAPSHOT/hdds-common-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-client/1.3.0-SNAPSHOT/hdds-client-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-client/1.3.0-SNAPSHOT/ozone-interface-client-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-test-utils/1.3.0-SNAPSHOT/hdds-test-utils-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/guava/guava/30.1.1-jre/guava-30.1.1-jre.jar:/home/runner/.m2/repository/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar:/home/runner/.m2/repository/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/runner/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/runner/.m2/repository/org/checkerframework/checker-qual/3.8.0/checker-qual-3.8.0.jar:/home/runner/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/runner/.m2/repository/com/google/j2objc/j2objc-annotations/1.3/j2objc-annotations-1.3.jar:/home/runner/.m2/repository/commons-io/commons-io/2.11.0/commons-io-2.11.0.jar:/home/runner/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/runner/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/runner/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.3.0-SNAPSHOT/hdds-server-scm-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-server/1.3.0-SNAPSHOT/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.1/hadoop-hdfs-3.3.1.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-framework/1.3.0-SNAPSHOT/hdds-server-framework-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-server/1.3.0-SNAPSHOT/hdds-interface-server-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-servlet/9.4.43.v20210629/jetty-servlet-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-security/9.4.43.v20210629/jetty-security-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/rocksdb/rocksdbjni/6.25.3/rocksdbjni-6.25.3.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_dropwizard/0.7.0/simpleclient_dropwizard-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient/0.7.0/simpleclient-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_common/0.7.0/simpleclient_common-0.7.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.12.1/jackson-datatype-jsr310-2.12.1.jar:/home/runner/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.3.1/hadoop-hdfs-client-3.3.1.jar:/home/runner/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.67/bcprov-jdk15on-1.67.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.3.0-SNAPSHOT/ozone-manager-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/aspectj/aspectjrt/1.9.7/aspectjrt-1.9.7.jar:/home/runner/.m2/repository/org/aspectj/aspectjweaver/1.9.7/aspectjweaver-1.9.7.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-client/1.3.0-SNAPSHOT/hdds-interface-client-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-protobuf_3_7/1.1.1/hadoop-shaded-protobuf_3_7-1.1.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-storage/1.3.0-SNAPSHOT/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.3.1/hadoop-minikdc-3.3.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/runner/.m2/repository/org/slf4j/slf4j-log4j12/1.7.30/slf4j-log4j12-1.7.30.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-s3gateway/1.3.0-SNAPSHOT/ozone-s3gateway-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/home/runner/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.33/jersey-container-servlet-core-2.33.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-common/2.33/jersey-common-2.33.jar:/home/runner/.m2/repository/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.33/jersey-cdi1x-2.33.jar:/home/runner/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.33/jersey-hk2-2.33.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.33/jersey-media-jaxb-2.33.jar:/home/runner/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.12.1/jackson-dataformat-xml-2.12.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.1/jackson-core-2.12.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.12.1/jackson-module-jaxb-annotations-2.12.1.jar:/home/runner/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/runner/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/runner/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/runner/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/runner/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/runner/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/runner/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/runner/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-runtime/2.3.0.1/jaxb-runtime-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/txw2/2.3.0.1/txw2-2.3.0.1.jar:/home/runner/.m2/repository/com/sun/istack/istack-commons-runtime/3.0.5/istack-commons-runtime-3.0.5.jar:/home/runner/.m2/repository/org/jvnet/staxex/stax-ex/1.7.8/stax-ex-1.7.8.jar:/home/runner/.m2/repository/com/sun/xml/fastinfoset/FastInfoset/1.2.13/FastInfoset-1.2.13.jar:/home/runner/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-csi/1.3.0-SNAPSHOT/ozone-csi-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java-util/3.12.0/protobuf-java-util-3.12.0.jar:/home/runner/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-config/1.3.0-SNAPSHOT/hdds-config-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/grpc/grpc-netty/1.33.0/grpc-netty-1.33.0.jar:/home/runner/.m2/repository/io/grpc/grpc-core/1.33.0/grpc-core-1.33.0.jar:/home/runner/.m2/repository/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar:/home/runner/.m2/repository/io/netty/netty-codec-http2/4.1.63.Final/netty-codec-http2-4.1.63.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.63.Final/netty-codec-http-4.1.63.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler-proxy/4.1.63.Final/netty-handler-proxy-4.1.63.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-socks/4.1.63.Final/netty-codec-socks-4.1.63.Final.jar:/home/runner/.m2/repository/io/perfmark/perfmark-api/0.19.0/perfmark-api-0.19.0.jar:/home/runner/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.18/animal-sniffer-annotations-1.18.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.63.Final/netty-transport-native-epoll-4.1.63.Final.jar:/home/runner/.m2/repository/io/netty/netty-common/4.1.63.Final/netty-common-4.1.63.Final.jar:/home/runner/.m2/repository/io/netty/netty-buffer/4.1.63.Final/netty-buffer-4.1.63.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.63.Final/netty-transport-native-unix-common-4.1.63.Final.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf/1.33.0/grpc-protobuf-1.33.0.jar:/home/runner/.m2/repository/io/grpc/grpc-api/1.33.0/grpc-api-1.33.0.jar:/home/runner/.m2/repository/io/grpc/grpc-context/1.33.0/grpc-context-1.33.0.jar:/home/runner/.m2/repository/com/google/api/grpc/proto-google-common-protos/1.17.0/proto-google-common-protos-1.17.0.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf-lite/1.33.0/grpc-protobuf-lite-1.33.0.jar:/home/runner/.m2/repository/io/grpc/grpc-stub/1.33.0/grpc-stub-1.33.0.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-recon/1.3.0-SNAPSHOT/ozone-recon-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-reconcodegen/1.3.0-SNAPSHOT/ozone-reconcodegen-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/runner/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/runner/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.33/jersey-container-servlet-2.33.jar:/home/runner/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-server/2.33/jersey-server-2.33.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-client/2.33/jersey-client-2.33.jar:/home/runner/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.5/jakarta.annotation-api-1.3.5.jar:/home/runner/.m2/repository/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.33/jersey-media-json-jackson-2.33.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.33/jersey-entity-filtering-2.33.jar:/home/runner/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/runner/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/runner/.m2/repository/org/apache/derby/derby/10.14.2.0/derby-10.14.2.0.jar:/home/runner/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/runner/.m2/repository/org/springframework/spring-jdbc/5.2.18.RELEASE/spring-jdbc-5.2.18.RELEASE.jar:/home/runner/.m2/repository/org/springframework/spring-beans/5.2.18.RELEASE/spring-beans-5.2.18.RELEASE.jar:/home/runner/.m2/repository/org/springframework/spring-core/5.2.18.RELEASE/spring-core-5.2.18.RELEASE.jar:/home/runner/.m2/repository/org/springframework/spring-jcl/5.2.18.RELEASE/spring-jcl-5.2.18.RELEASE.jar:/home/runner/.m2/repository/org/springframework/spring-tx/5.2.18.RELEASE/spring-tx-5.2.18.RELEASE.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-client/1.3.0-SNAPSHOT/ozone-client-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem/1.3.0-SNAPSHOT/ozone-filesystem-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem-common/1.3.0-SNAPSHOT/ozone-filesystem-common-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-tools/1.3.0-SNAPSHOT/ozone-tools-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-tools/2.2.0/ratis-tools-2.2.0.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-core/1.12.124/aws-java-sdk-core-1.12.124.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/runner/.m2/repository/software/amazon/ion/ion-java/1.0.2/ion-java-1.0.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.12.1/jackson-dataformat-cbor-2.12.1.jar:/home/runner/.m2/repository/joda-time/joda-time/2.8.1/joda-time-2.8.1.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-s3/1.12.124/aws-java-sdk-s3-1.12.124.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-kms/1.12.124/aws-java-sdk-kms-1.12.124.jar:/home/runner/.m2/repository/com/amazonaws/jmespath-java/1.12.124/jmespath-java-1.12.124.jar:/home/runner/.m2/repository/org/kohsuke/metainf-services/metainf-services/1.8/metainf-services-1.8.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-tools/1.3.0-SNAPSHOT/hdds-tools-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/runner/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.3.0-SNAPSHOT/ozone-manager-1.3.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.3.0-SNAPSHOT/hdds-common-1.3.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-client/1.3.0-SNAPSHOT/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/info/picocli/picocli/4.6.1/picocli-4.6.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.12.1/jackson-annotations-2.12.1.jar:/home/runner/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server/2.2.0/ratis-server-2.2.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-client/2.2.0/ratis-client-2.2.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server-api/2.2.0/ratis-server-api-2.2.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics/2.2.0/ratis-metrics-2.2.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-netty/2.2.0/ratis-netty-2.2.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-grpc/2.2.0/ratis-grpc-2.2.0.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-api/2.17.1/log4j-api-2.17.1.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-core/2.17.1/log4j-core-2.17.1.jar:/home/runner/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/runner/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/runner/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.67/bcpkix-jdk15on-1.67.jar:/home/runner/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/runner/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/runner/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/runner/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-client/1.6.0/jaeger-client-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-thrift/1.6.0/jaeger-thrift-1.6.0.jar:/home/runner/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/runner/.m2/repository/com/squareup/okhttp3/okhttp/4.9.0/okhttp-4.9.0.jar:/home/runner/.m2/repository/com/squareup/okio/okio/2.8.0/okio-2.8.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-core/1.6.0/jaeger-core-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-tracerresolver/1.6.0/jaeger-tracerresolver-1.6.0.jar:/home/runner/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.8/opentracing-tracerresolver-0.1.8.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib/1.4.31/kotlin-stdlib-1.4.31.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-common/1.4.31/kotlin-stdlib-common-1.4.31.jar:/home/runner/.m2/repository/org/jetbrains/annotations/13.0/annotations-13.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-util/0.33.0/opentracing-util-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-api/0.33.0/opentracing-api-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-noop/0.33.0/opentracing-noop-0.33.0.jar:/home/runner/.m2/repository/org/yaml/snakeyaml/1.26/snakeyaml-1.26.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-admin/1.3.0-SNAPSHOT/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/junit/junit/4.13.1/junit-4.13.1.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.7.0/junit-jupiter-api-5.7.0.jar:/home/runner/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/runner/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-commons/1.7.0/junit-platform-commons-1.7.0.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.7.0/junit-jupiter-engine-5.7.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-engine/1.7.0/junit-platform-engine-1.7.0.jar:/home/runner/.m2/repository/org/junit/vintage/junit-vintage-engine/5.7.0/junit-vintage-engine-5.7.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-launcher/1.7.0/junit-platform-launcher-1.7.0.jar:/home/runner/.m2/repository/org/mockito/mockito-core/2.28.2/mockito-core-2.28.2.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy/1.9.10/byte-buddy-1.9.10.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy-agent/1.9.10/byte-buddy-agent-1.9.10.jar:/home/runner/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.1/hadoop-kms-3.3.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-auth/3.3.1/hadoop-auth-3.3.1.jar:/home/runner/.m2/repository/com/nimbusds/nimbus-jose-jwt/7.9/nimbus-jose-jwt-7.9.jar:/home/runner/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/runner/.m2/repository/net/minidev/json-smart/2.3.1/json-smart-2.3.1.jar:/home/runner/.m2/repository/net/minidev/accessors-smart/2.3.1/accessors-smart-2.3.1.jar:/home/runner/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper/3.5.6/zookeeper-3.5.6.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.6/zookeeper-jute-3.5.6.jar:/home/runner/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-guava/1.1.1/hadoop-shaded-guava-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/runner/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/runner/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-server/9.4.43.v20210629/jetty-server-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-http/9.4.43.v20210629/jetty-http-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-io/9.4.43.v20210629/jetty-io-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-webapp/9.4.43.v20210629/jetty-webapp-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-xml/9.4.43.v20210629/jetty-xml-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.1/hadoop-common-3.3.1.jar:/home/runner/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/runner/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/runner/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/runner/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/runner/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/runner/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/runner/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/runner/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/runner/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/runner/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/runner/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/runner/.m2/repository/org/xerial/snappy/snappy-java/1.1.8.2/snappy-java-1.1.8.2.jar:/home/runner/.m2/repository/org/slf4j/jul-to-slf4j/1.7.30/jul-to-slf4j-1.7.30.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util/9.4.43.v20210629/jetty-util-9.4.43.v20210629.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.1/jackson-databind-2.12.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.1/hadoop-kms-3.3.1-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.3.0-SNAPSHOT/hdds-server-scm-1.3.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/home/runner/.m2/repository/io/netty/netty-transport/4.1.63.Final/netty-transport-4.1.63.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver/4.1.63.Final/netty-resolver-4.1.63.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec/4.1.63.Final/netty-codec-4.1.63.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler/4.1.63.Final/netty-handler-4.1.63.Final.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-test/1.3.0-SNAPSHOT/hdds-hadoop-dependency-test-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.1/hadoop-common-3.3.1-tests.jar:/home/runner/.m2/repository/org/assertj/assertj-core/3.12.2/assertj-core-3.12.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.1/hadoop-hdfs-3.3.1-tests.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.4.43.v20210629/jetty-util-ajax-9.4.43.v20210629.jar:/home/runner/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/runner/.m2/repository/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/home/runner/.m2/repository/io/netty/netty-all/4.1.63.Final/netty-all-4.1.63.Final.jar:/home/runner/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/runner/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.1/hadoop-distcp-3.3.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.3.1/hadoop-mapreduce-client-jobclient-3.3.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.3.1/hadoop-mapreduce-client-common-3.3.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.3.1/hadoop-yarn-common-3.3.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.3.1/hadoop-yarn-api-3.3.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/runner/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.12.1/jackson-jaxrs-json-provider-2.12.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.12.1/jackson-jaxrs-base-2.12.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.3.1/hadoop-yarn-client-3.3.1.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.4.40.v20210413/websocket-client-9.4.40.v20210413.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-client/9.4.40.v20210413/jetty-client-9.4.40.v20210413.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.4.40.v20210413/websocket-common-9.4.40.v20210413.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.4.40.v20210413/websocket-api-9.4.40.v20210413.jar:/home/runner/.m2/repository/org/jline/jline/3.9.0/jline-3.9.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.3.1/hadoop-mapreduce-client-core-3.3.1.jar:/home/runner/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/runner/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-annotations/3.3.1/hadoop-annotations-3.3.1.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/../lib/tools.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.1/hadoop-distcp-3.3.1-tests.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-common/2.2.0/ratis-common-2.2.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/0.7.0/ratis-thirdparty-misc-0.7.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-proto/2.2.0/ratis-proto-2.2.0.jar:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/runner"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre"/>
    <property name="java.security.krb5.conf" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/krb5.conf"/>
    <property name="basedir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test"/>
    <property name="file.separator" value="/"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="skip.installnpx" value="true"/>
    <property name="surefire.real.class.path" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/surefire/surefirebooter1792386987714083452.jar:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.5/org.jacoco.agent-0.8.5-runtime.jar"/>
    <property name="hadoop.log.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/classes"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="skip.npx" value="true"/>
    <property name="java.runtime.version" value="1.8.0_312-b07"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="user.name" value="runner"/>
    <property name="path.separator" value=":"/>
    <property name="java.security.egd" value="file:///dev/urandom"/>
    <property name="os.version" value="5.4.0-1068-azure"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="test.build.webapps" value=""/>
    <property name="localRepository" value="/home/runner/.m2/repository"/>
    <property name="java.vendor.url.bug" value="https://github.com/adoptium/adoptium-support/issues"/>
    <property name="java.io.tmpdir" value="/tmp"/>
    <property name="require.test.libhadoop" value=""/>
    <property name="java.version" value="1.8.0_312"/>
    <property name="user.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test"/>
    <property name="os.arch" value="amd64"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="test.build.classes" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="hadoop.tmp.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/tmp"/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vendor" value="Temurin"/>
    <property name="java.vm.version" value="25.312-b07"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.class.version" value="52.0"/>
  </properties>
  <testcase name="testNodeWithOpenPipelineCanBeDecommissionedAndRecommissioned" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="51.026"/>
  <testcase name="testContainerIsReplicatedWhenAllNodesGotoMaintenance" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="22.09"/>
  <testcase name="testMaintenanceEndsAutomaticallyAtTimeout" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="100.015">
    <error message="Failed to obtain available cluster in time" type="java.io.IOException">java.io.IOException: Failed to obtain available cluster in time
	at org.apache.hadoop.ozone.MiniOzoneClusterProvider.provide(MiniOzoneClusterProvider.java:162)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.setUp(TestDecommissionAndMaintenance.java:142)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:108)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:96)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:75)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:142)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:113)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
</error>
    <system-out><![CDATA[2022-02-09 08:19:22,462 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(134)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5127006478ns, electionTimeout:5126ms
2022-02-09 08:19:22,462 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(108)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d: shutdown d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-FollowerState
2022-02-09 08:19:22,462 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(290)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-02-09 08:19:22,462 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.leaderelection.pre-vote = false (custom)
2022-02-09 08:19:22,462 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(130)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d: start d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29
2022-02-09 08:19:22,482 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(306)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29 ELECTION round 0: submit vote requests at term 1 for -1: [d446f06f-c919-4727-b846-3f8c8c5e1658|rpc:10.1.0.47:35969|priority:0, 4b3568ef-ad3d-4964-ac82-76a8654b6a6f|rpc:10.1.0.47:43347|priority:0, d6ad39fc-5f17-463f-9d0b-f520f0947e2d|rpc:10.1.0.47:41167|priority:1], old=null
2022-02-09 08:19:22,504 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1046)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6: receive requestVote(ELECTION, d6ad39fc-5f17-463f-9d0b-f520f0947e2d, group-A0306DFE1CC6, 1, (t:0, i:0))
2022-02-09 08:19:22,505 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(48)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6-FOLLOWER: accept ELECTION from d6ad39fc-5f17-463f-9d0b-f520f0947e2d: our priority 0 <= candidate's priority 1
2022-02-09 08:19:22,505 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(290)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:d6ad39fc-5f17-463f-9d0b-f520f0947e2d
2022-02-09 08:19:22,505 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(108)) - d446f06f-c919-4727-b846-3f8c8c5e1658: shutdown d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6-FollowerState
2022-02-09 08:19:22,505 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(130)) - d446f06f-c919-4727-b846-3f8c8c5e1658: start d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6-FollowerState
2022-02-09 08:19:22,505 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6-FollowerState was interrupted: {}
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at java.lang.Thread.sleep(Thread.java:340)
	at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
2022-02-09 08:19:22,508 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1078)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6 replies to ELECTION vote request: d6ad39fc-5f17-463f-9d0b-f520f0947e2d<-d446f06f-c919-4727-b846-3f8c8c5e1658#0:OK-t1. Peer's state: d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6:t1, leader=null, voted=d6ad39fc-5f17-463f-9d0b-f520f0947e2d, raftlog=d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6-SegmentedRaftLog:OPENED:c-1, conf=-1: [d446f06f-c919-4727-b846-3f8c8c5e1658|rpc:10.1.0.47:35969|dataStream:|priority:0, 4b3568ef-ad3d-4964-ac82-76a8654b6a6f|rpc:10.1.0.47:43347|dataStream:|priority:0, d6ad39fc-5f17-463f-9d0b-f520f0947e2d|rpc:10.1.0.47:41167|dataStream:|priority:1], old=null
2022-02-09 08:19:22,514 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29: ELECTION PASSED received 1 response(s) and 0 exception(s):
2022-02-09 08:19:22,514 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: d6ad39fc-5f17-463f-9d0b-f520f0947e2d<-d446f06f-c919-4727-b846-3f8c8c5e1658#0:OK-t1
2022-02-09 08:19:22,515 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(308)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29 ELECTION round 0: result PASSED
2022-02-09 08:19:22,515 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(121)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d: shutdown d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29
2022-02-09 08:19:22,515 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(290)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-02-09 08:19:22,515 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(866)) - Leader change notification received for group: group-A0306DFE1CC6 with new leaderId: d6ad39fc-5f17-463f-9d0b-f520f0947e2d
2022-02-09 08:19:22,515 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  server.RaftServer$Division (ServerState.java:setLeader(285)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6: change Leader from null to d6ad39fc-5f17-463f-9d0b-f520f0947e2d at term 1 for becomeLeader, leader elected after 5194ms
2022-02-09 08:19:22,515 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2022-02-09 08:19:22,515 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2022-02-09 08:19:22,515 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-02-09 08:19:22,516 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 180s (custom)
2022-02-09 08:19:22,516 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2022-02-09 08:19:22,516 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2022-02-09 08:19:22,516 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2022-02-09 08:19:22,516 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-02-09 08:19:22,516 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2022-02-09 08:19:22,516 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-02-09 08:19:22,516 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2022-02-09 08:19:22,516 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2022-02-09 08:19:22,516 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2022-02-09 08:19:22,520 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1046)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6: receive requestVote(ELECTION, d6ad39fc-5f17-463f-9d0b-f520f0947e2d, group-A0306DFE1CC6, 1, (t:0, i:0))
2022-02-09 08:19:22,518 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(291)) - Pipeline Pipeline[ Id: a3411903-4a88-4c3e-b106-a0306dfe1cc6, Nodes: d446f06f-c919-4727-b846-3f8c8c5e1658{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=43319, RATIS=35969, RATIS_ADMIN=35969, RATIS_SERVER=35969, STANDALONE=37823], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}d6ad39fc-5f17-463f-9d0b-f520f0947e2d{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=34325, RATIS=41167, RATIS_ADMIN=41167, RATIS_SERVER=41167, STANDALONE=32839], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}4b3568ef-ad3d-4964-ac82-76a8654b6a6f{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=38721, RATIS=43347, RATIS_ADMIN=43347, RATIS_SERVER=43347, STANDALONE=44323], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:d6ad39fc-5f17-463f-9d0b-f520f0947e2d, CreationTimestamp2022-02-09T08:19:15.795Z[Etc/UTC]] moved to OPEN state
2022-02-09 08:19:22,523 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(48)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6-FOLLOWER: accept ELECTION from d6ad39fc-5f17-463f-9d0b-f520f0947e2d: our priority 0 <= candidate's priority 1
2022-02-09 08:19:22,524 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(290)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:d6ad39fc-5f17-463f-9d0b-f520f0947e2d
2022-02-09 08:19:22,524 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(108)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f: shutdown 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6-FollowerState
2022-02-09 08:19:22,524 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(130)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f: start 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6-FollowerState
2022-02-09 08:19:22,524 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6-FollowerState was interrupted: {}
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at java.lang.Thread.sleep(Thread.java:340)
	at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
2022-02-09 08:19:22,524 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-02-09 08:19:22,529 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2022-02-09 08:19:22,552 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-02-09 08:19:22,552 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2022-02-09 08:19:22,553 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2022-02-09 08:19:22,553 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2022-02-09 08:19:22,553 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-02-09 08:19:22,554 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(130)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d: start d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderStateImpl
2022-02-09 08:19:22,554 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(394)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-SegmentedRaftLogWorker: Starting segment from index:0
2022-02-09 08:19:22,548 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1078)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6 replies to ELECTION vote request: d6ad39fc-5f17-463f-9d0b-f520f0947e2d<-4b3568ef-ad3d-4964-ac82-76a8654b6a6f#0:OK-t1. Peer's state: 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6:t1, leader=null, voted=d6ad39fc-5f17-463f-9d0b-f520f0947e2d, raftlog=4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6-SegmentedRaftLog:OPENED:c-1, conf=-1: [d446f06f-c919-4727-b846-3f8c8c5e1658|rpc:10.1.0.47:35969|dataStream:|priority:0, 4b3568ef-ad3d-4964-ac82-76a8654b6a6f|rpc:10.1.0.47:43347|dataStream:|priority:0, d6ad39fc-5f17-463f-9d0b-f520f0947e2d|rpc:10.1.0.47:41167|dataStream:|priority:1], old=null
2022-02-09 08:19:22,557 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(601)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-1/data/ratis/a3411903-4a88-4c3e-b106-a0306dfe1cc6/current/log_inprogress_0
2022-02-09 08:19:22,599 [grpc-default-executor-4] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(866)) - Leader change notification received for group: group-A0306DFE1CC6 with new leaderId: d6ad39fc-5f17-463f-9d0b-f520f0947e2d
2022-02-09 08:19:22,600 [grpc-default-executor-4] INFO  server.RaftServer$Division (ServerState.java:setLeader(285)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6: change Leader from null to d6ad39fc-5f17-463f-9d0b-f520f0947e2d at term 1 for appendEntries, leader elected after 5102ms
2022-02-09 08:19:22,600 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderElection29] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(387)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6: set configuration 0: [d446f06f-c919-4727-b846-3f8c8c5e1658|rpc:10.1.0.47:35969|dataStream:|priority:0, 4b3568ef-ad3d-4964-ac82-76a8654b6a6f|rpc:10.1.0.47:43347|dataStream:|priority:0, d6ad39fc-5f17-463f-9d0b-f520f0947e2d|rpc:10.1.0.47:41167|dataStream:|priority:1], old=null
2022-02-09 08:19:22,610 [grpc-default-executor-1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(866)) - Leader change notification received for group: group-A0306DFE1CC6 with new leaderId: d6ad39fc-5f17-463f-9d0b-f520f0947e2d
2022-02-09 08:19:22,610 [grpc-default-executor-1] INFO  server.RaftServer$Division (ServerState.java:setLeader(285)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6: change Leader from null to d6ad39fc-5f17-463f-9d0b-f520f0947e2d at term 1 for appendEntries, leader elected after 5223ms
2022-02-09 08:19:22,610 [grpc-default-executor-4] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(387)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6: set configuration 0: [d446f06f-c919-4727-b846-3f8c8c5e1658|rpc:10.1.0.47:35969|dataStream:|priority:0, 4b3568ef-ad3d-4964-ac82-76a8654b6a6f|rpc:10.1.0.47:43347|dataStream:|priority:0, d6ad39fc-5f17-463f-9d0b-f520f0947e2d|rpc:10.1.0.47:41167|dataStream:|priority:1], old=null
2022-02-09 08:19:22,611 [grpc-default-executor-4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(394)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6-SegmentedRaftLogWorker: Starting segment from index:0
2022-02-09 08:19:22,613 [grpc-default-executor-1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(387)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6: set configuration 0: [d446f06f-c919-4727-b846-3f8c8c5e1658|rpc:10.1.0.47:35969|dataStream:|priority:0, 4b3568ef-ad3d-4964-ac82-76a8654b6a6f|rpc:10.1.0.47:43347|dataStream:|priority:0, d6ad39fc-5f17-463f-9d0b-f520f0947e2d|rpc:10.1.0.47:41167|dataStream:|priority:1], old=null
2022-02-09 08:19:22,613 [grpc-default-executor-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(394)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6-SegmentedRaftLogWorker: Starting segment from index:0
2022-02-09 08:19:22,617 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(601)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-0/data/ratis/a3411903-4a88-4c3e-b106-a0306dfe1cc6/current/log_inprogress_0
2022-02-09 08:19:22,646 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(601)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-2/data/ratis/a3411903-4a88-4c3e-b106-a0306dfe1cc6/current/log_inprogress_0
2022-02-09 08:19:22,680 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(134)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5124080457ns, electionTimeout:5123ms
2022-02-09 08:19:22,681 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(108)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d: shutdown d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-FollowerState
2022-02-09 08:19:22,681 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(290)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-02-09 08:19:22,688 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.leaderelection.pre-vote = false (custom)
2022-02-09 08:19:22,688 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(130)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d: start d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-LeaderElection30
2022-02-09 08:19:22,718 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-LeaderElection30] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(306)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-LeaderElection30 ELECTION round 0: submit vote requests at term 1 for -1: [d6ad39fc-5f17-463f-9d0b-f520f0947e2d|rpc:10.1.0.47:41167|priority:1], old=null
2022-02-09 08:19:22,718 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-LeaderElection30] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(308)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-LeaderElection30 ELECTION round 0: result PASSED (term=1)
2022-02-09 08:19:22,718 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-LeaderElection30] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(121)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d: shutdown d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-LeaderElection30
2022-02-09 08:19:22,718 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-LeaderElection30] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(290)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-02-09 08:19:22,718 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-LeaderElection30] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(866)) - Leader change notification received for group: group-1FA18B14ADE5 with new leaderId: d6ad39fc-5f17-463f-9d0b-f520f0947e2d
2022-02-09 08:19:22,718 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-LeaderElection30] INFO  server.RaftServer$Division (ServerState.java:setLeader(285)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5: change Leader from null to d6ad39fc-5f17-463f-9d0b-f520f0947e2d at term 1 for becomeLeader, leader elected after 5169ms
2022-02-09 08:19:22,718 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2022-02-09 08:19:22,719 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2022-02-09 08:19:22,719 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-02-09 08:19:22,719 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 180s (custom)
2022-02-09 08:19:22,719 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2022-02-09 08:19:22,719 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2022-02-09 08:19:22,719 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2022-02-09 08:19:22,719 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-LeaderElection30] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-02-09 08:19:22,719 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-LeaderElection30] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(130)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d: start d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-LeaderStateImpl
2022-02-09 08:19:22,720 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-LeaderElection30] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(394)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-SegmentedRaftLogWorker: Starting segment from index:0
2022-02-09 08:19:22,722 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(601)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-1/data/ratis/f82cb8ae-e6c3-4fcc-b554-1fa18b14ade5/current/log_inprogress_0
2022-02-09 08:19:22,738 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-LeaderElection30] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(387)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5: set configuration 0: [d6ad39fc-5f17-463f-9d0b-f520f0947e2d|rpc:10.1.0.47:41167|dataStream:|priority:1], old=null
2022-02-09 08:19:23,060 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-02-09 08:19:23,408 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(134)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5068210883ns, electionTimeout:5058ms
2022-02-09 08:19:23,409 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(108)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f: shutdown 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-FollowerState
2022-02-09 08:19:23,409 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(290)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-02-09 08:19:23,409 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.leaderelection.pre-vote = false (custom)
2022-02-09 08:19:23,409 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(130)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f: start 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-LeaderElection31
2022-02-09 08:19:23,421 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(149)) - Not enough healthy nodes to allocate container. 2  datanodes required. Found 1
2022-02-09 08:19:23,421 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Not enough healthy nodes to allocate container. 2  datanodes required. Found 1
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:150)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:23,421 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(149)) - Not enough healthy nodes to allocate container. 2  datanodes required. Found 1
2022-02-09 08:19:23,421 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Not enough healthy nodes to allocate container. 2  datanodes required. Found 1
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:150)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:23,421 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(149)) - Not enough healthy nodes to allocate container. 2  datanodes required. Found 1
2022-02-09 08:19:23,422 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Not enough healthy nodes to allocate container. 2  datanodes required. Found 1
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:150)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:23,422 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-02-09 08:19:23,436 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-LeaderElection31] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(306)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-LeaderElection31 ELECTION round 0: submit vote requests at term 1 for -1: [4b3568ef-ad3d-4964-ac82-76a8654b6a6f|rpc:10.1.0.47:43347|priority:1], old=null
2022-02-09 08:19:23,437 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-LeaderElection31] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(308)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-LeaderElection31 ELECTION round 0: result PASSED (term=1)
2022-02-09 08:19:23,437 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-LeaderElection31] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(121)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f: shutdown 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-LeaderElection31
2022-02-09 08:19:23,437 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-LeaderElection31] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(290)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-02-09 08:19:23,437 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-LeaderElection31] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(866)) - Leader change notification received for group: group-D94A0698663A with new leaderId: 4b3568ef-ad3d-4964-ac82-76a8654b6a6f
2022-02-09 08:19:23,438 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-LeaderElection31] INFO  server.RaftServer$Division (ServerState.java:setLeader(285)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A: change Leader from null to 4b3568ef-ad3d-4964-ac82-76a8654b6a6f at term 1 for becomeLeader, leader elected after 5122ms
2022-02-09 08:19:23,438 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-LeaderElection31] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2022-02-09 08:19:23,438 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-LeaderElection31] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2022-02-09 08:19:23,439 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-LeaderElection31] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-02-09 08:19:23,439 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-LeaderElection31] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 180s (custom)
2022-02-09 08:19:23,439 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-LeaderElection31] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2022-02-09 08:19:23,439 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-LeaderElection31] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2022-02-09 08:19:23,439 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-LeaderElection31] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2022-02-09 08:19:23,440 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-LeaderElection31] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-02-09 08:19:23,440 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-LeaderElection31] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(130)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f: start 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-LeaderStateImpl
2022-02-09 08:19:23,440 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-LeaderElection31] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(394)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-SegmentedRaftLogWorker: Starting segment from index:0
2022-02-09 08:19:23,445 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(601)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-2/data/ratis/f2fc3af5-81c0-4f09-8979-d94a0698663a/current/log_inprogress_0
2022-02-09 08:19:23,466 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-LeaderElection31] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(387)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A: set configuration 0: [4b3568ef-ad3d-4964-ac82-76a8654b6a6f|rpc:10.1.0.47:43347|dataStream:|priority:1], old=null
2022-02-09 08:19:23,471 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(134)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5123259646ns, electionTimeout:5122ms
2022-02-09 08:19:23,472 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(108)) - d446f06f-c919-4727-b846-3f8c8c5e1658: shutdown d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-FollowerState
2022-02-09 08:19:23,472 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(290)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-02-09 08:19:23,472 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.leaderelection.pre-vote = false (custom)
2022-02-09 08:19:23,472 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(130)) - d446f06f-c919-4727-b846-3f8c8c5e1658: start d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-LeaderElection32
2022-02-09 08:19:23,496 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-LeaderElection32] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(306)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-LeaderElection32 ELECTION round 0: submit vote requests at term 1 for -1: [d446f06f-c919-4727-b846-3f8c8c5e1658|rpc:10.1.0.47:35969|priority:1], old=null
2022-02-09 08:19:23,501 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-LeaderElection32] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(308)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-LeaderElection32 ELECTION round 0: result PASSED (term=1)
2022-02-09 08:19:23,502 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-LeaderElection32] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(121)) - d446f06f-c919-4727-b846-3f8c8c5e1658: shutdown d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-LeaderElection32
2022-02-09 08:19:23,502 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-LeaderElection32] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(290)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-02-09 08:19:23,502 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-LeaderElection32] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(866)) - Leader change notification received for group: group-E7473FFE323D with new leaderId: d446f06f-c919-4727-b846-3f8c8c5e1658
2022-02-09 08:19:23,502 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-LeaderElection32] INFO  server.RaftServer$Division (ServerState.java:setLeader(285)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D: change Leader from null to d446f06f-c919-4727-b846-3f8c8c5e1658 at term 1 for becomeLeader, leader elected after 5189ms
2022-02-09 08:19:23,503 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-LeaderElection32] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2022-02-09 08:19:23,503 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-LeaderElection32] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2022-02-09 08:19:23,503 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-LeaderElection32] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-02-09 08:19:23,504 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-LeaderElection32] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 180s (custom)
2022-02-09 08:19:23,504 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-LeaderElection32] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2022-02-09 08:19:23,504 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-LeaderElection32] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2022-02-09 08:19:23,505 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-LeaderElection32] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2022-02-09 08:19:23,505 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-LeaderElection32] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-02-09 08:19:23,505 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-LeaderElection32] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(130)) - d446f06f-c919-4727-b846-3f8c8c5e1658: start d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-LeaderStateImpl
2022-02-09 08:19:23,518 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-LeaderElection32] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(394)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-SegmentedRaftLogWorker: Starting segment from index:0
2022-02-09 08:19:23,519 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(601)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-0/data/ratis/531ec647-fe59-4e6d-b079-e7473ffe323d/current/log_inprogress_0
2022-02-09 08:19:23,538 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-LeaderElection32] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(387)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D: set configuration 0: [d446f06f-c919-4727-b846-3f8c8c5e1658|rpc:10.1.0.47:35969|dataStream:|priority:1], old=null
2022-02-09 08:19:23,679 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode aa0b8223-7685-4e0e-8077-085ec758d7c1{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=43267, RATIS=45565, RATIS_ADMIN=45565, RATIS_SERVER=45565, STANDALONE=38609], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=6341b3b3-a77c-4ffa-a1ba-62f1bd7e3486]
2022-02-09 08:19:23,679 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(365)) - Pipeline Pipeline[ Id: 6341b3b3-a77c-4ffa-a1ba-62f1bd7e3486, Nodes: aa0b8223-7685-4e0e-8077-085ec758d7c1{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=43267, RATIS=45565, RATIS_ADMIN=45565, RATIS_SERVER=45565, STANDALONE=38609], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONED, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:aa0b8223-7685-4e0e-8077-085ec758d7c1, CreationTimestamp2022-02-09T08:18:57.237Z[Etc/UTC]] moved to CLOSED state
2022-02-09 08:19:23,679 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode 4b172544-f8d9-4b39-b7cd-191c86dc5ee2{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=39269, RATIS=36505, RATIS_ADMIN=36505, RATIS_SERVER=36505, STANDALONE=45371], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=5d086ff7-1821-4951-a480-ac05006fa5c0]
2022-02-09 08:19:23,680 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(365)) - Pipeline Pipeline[ Id: 5d086ff7-1821-4951-a480-ac05006fa5c0, Nodes: 4b172544-f8d9-4b39-b7cd-191c86dc5ee2{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=39269, RATIS=36505, RATIS_ADMIN=36505, RATIS_SERVER=36505, STANDALONE=45371], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:4b172544-f8d9-4b39-b7cd-191c86dc5ee2, CreationTimestamp2022-02-09T08:18:21.162Z[Etc/UTC]] moved to CLOSED state
2022-02-09 08:19:24,061 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-02-09 08:19:24,422 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #1, no healthy replica found.
2022-02-09 08:19:24,422 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #2, no healthy replica found.
2022-02-09 08:19:24,422 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #3, no healthy replica found.
2022-02-09 08:19:24,422 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-02-09 08:19:25,062 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-02-09 08:19:25,423 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #1, no healthy replica found.
2022-02-09 08:19:25,423 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #2, no healthy replica found.
2022-02-09 08:19:25,423 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #3, no healthy replica found.
2022-02-09 08:19:25,423 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-02-09 08:19:25,640 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(336)) - Attempting to stop container services.
2022-02-09 08:19:25,642 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(391)) - 4b172544-f8d9-4b39-b7cd-191c86dc5ee2: close
2022-02-09 08:19:25,642 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(412)) - 4b172544-f8d9-4b39-b7cd-191c86dc5ee2@group-AC05006FA5C0: shutdown
2022-02-09 08:19:25,642 [Mini-Cluster-Provider-Reap] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-AC05006FA5C0,id=4b172544-f8d9-4b39-b7cd-191c86dc5ee2
2022-02-09 08:19:25,642 [Mini-Cluster-Provider-Reap] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(91)) - 4b172544-f8d9-4b39-b7cd-191c86dc5ee2: shutdown 4b172544-f8d9-4b39-b7cd-191c86dc5ee2@group-AC05006FA5C0-LeaderStateImpl
2022-02-09 08:19:25,642 [Mini-Cluster-Provider-Reap] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 4b172544-f8d9-4b39-b7cd-191c86dc5ee2@group-AC05006FA5C0-PendingRequests: sendNotLeaderResponses
2022-02-09 08:19:25,643 [4b172544-f8d9-4b39-b7cd-191c86dc5ee2@group-AC05006FA5C0-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(299)) - group-AC05006FA5C0: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d801a796-82ec-4b39-b9e8-93acad14199c/datanode-4/data/ratis/5d086ff7-1821-4951-a480-ac05006fa5c0/sm/snapshot.1_0
2022-02-09 08:19:25,644 [Mini-Cluster-Provider-Reap] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(149)) - 4b172544-f8d9-4b39-b7cd-191c86dc5ee2@group-AC05006FA5C0-StateMachineUpdater: set stopIndex = 0
2022-02-09 08:19:25,645 [4b172544-f8d9-4b39-b7cd-191c86dc5ee2@group-AC05006FA5C0-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(310)) - group-AC05006FA5C0: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d801a796-82ec-4b39-b9e8-93acad14199c/datanode-4/data/ratis/5d086ff7-1821-4951-a480-ac05006fa5c0/sm/snapshot.1_0 took: 2 ms
2022-02-09 08:19:25,645 [4b172544-f8d9-4b39-b7cd-191c86dc5ee2@group-AC05006FA5C0-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(281)) - 4b172544-f8d9-4b39-b7cd-191c86dc5ee2@group-AC05006FA5C0-StateMachineUpdater: Took a snapshot at index 0
2022-02-09 08:19:25,645 [4b172544-f8d9-4b39-b7cd-191c86dc5ee2@group-AC05006FA5C0-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(89)) - 4b172544-f8d9-4b39-b7cd-191c86dc5ee2@group-AC05006FA5C0-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-02-09 08:19:25,647 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (ServerState.java:close(419)) - 4b172544-f8d9-4b39-b7cd-191c86dc5ee2@group-AC05006FA5C0: closes. applyIndex: 0
2022-02-09 08:19:25,647 [4b172544-f8d9-4b39-b7cd-191c86dc5ee2@group-AC05006FA5C0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(327)) - 4b172544-f8d9-4b39-b7cd-191c86dc5ee2@group-AC05006FA5C0-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-02-09 08:19:25,647 [Mini-Cluster-Provider-Reap] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(237)) - 4b172544-f8d9-4b39-b7cd-191c86dc5ee2@group-AC05006FA5C0-SegmentedRaftLogWorker close()
2022-02-09 08:19:25,648 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(262)) - 4b172544-f8d9-4b39-b7cd-191c86dc5ee2: shutdown server with port 36505 now
2022-02-09 08:19:25,664 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 4b172544-f8d9-4b39-b7cd-191c86dc5ee2: shutdown server with port 36505 successfully
2022-02-09 08:19:25,665 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$541/997754283@23ca8c6b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-4b172544-f8d9-4b39-b7cd-191c86dc5ee2: Stopped
2022-02-09 08:19:25,681 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(336)) - Attempting to stop container services.
2022-02-09 08:19:25,682 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(391)) - aa0b8223-7685-4e0e-8077-085ec758d7c1: close
2022-02-09 08:19:25,682 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(412)) - aa0b8223-7685-4e0e-8077-085ec758d7c1@group-62F1BD7E3486: shutdown
2022-02-09 08:19:25,682 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-62F1BD7E3486,id=aa0b8223-7685-4e0e-8077-085ec758d7c1
2022-02-09 08:19:25,682 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(91)) - aa0b8223-7685-4e0e-8077-085ec758d7c1: shutdown aa0b8223-7685-4e0e-8077-085ec758d7c1@group-62F1BD7E3486-LeaderStateImpl
2022-02-09 08:19:25,682 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - aa0b8223-7685-4e0e-8077-085ec758d7c1@group-62F1BD7E3486-PendingRequests: sendNotLeaderResponses
2022-02-09 08:19:25,683 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(149)) - aa0b8223-7685-4e0e-8077-085ec758d7c1@group-62F1BD7E3486-StateMachineUpdater: set stopIndex = 0
2022-02-09 08:19:25,683 [aa0b8223-7685-4e0e-8077-085ec758d7c1@group-62F1BD7E3486-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(299)) - group-62F1BD7E3486: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d801a796-82ec-4b39-b9e8-93acad14199c/datanode-0/data/ratis/6341b3b3-a77c-4ffa-a1ba-62f1bd7e3486/sm/snapshot.1_0
2022-02-09 08:19:25,685 [aa0b8223-7685-4e0e-8077-085ec758d7c1@group-62F1BD7E3486-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(310)) - group-62F1BD7E3486: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-d801a796-82ec-4b39-b9e8-93acad14199c/datanode-0/data/ratis/6341b3b3-a77c-4ffa-a1ba-62f1bd7e3486/sm/snapshot.1_0 took: 2 ms
2022-02-09 08:19:25,685 [aa0b8223-7685-4e0e-8077-085ec758d7c1@group-62F1BD7E3486-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(281)) - aa0b8223-7685-4e0e-8077-085ec758d7c1@group-62F1BD7E3486-StateMachineUpdater: Took a snapshot at index 0
2022-02-09 08:19:25,685 [aa0b8223-7685-4e0e-8077-085ec758d7c1@group-62F1BD7E3486-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(89)) - aa0b8223-7685-4e0e-8077-085ec758d7c1@group-62F1BD7E3486-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-02-09 08:19:25,685 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer$Division (ServerState.java:close(419)) - aa0b8223-7685-4e0e-8077-085ec758d7c1@group-62F1BD7E3486: closes. applyIndex: 0
2022-02-09 08:19:25,688 [aa0b8223-7685-4e0e-8077-085ec758d7c1@group-62F1BD7E3486-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(327)) - aa0b8223-7685-4e0e-8077-085ec758d7c1@group-62F1BD7E3486-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-02-09 08:19:25,688 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(237)) - aa0b8223-7685-4e0e-8077-085ec758d7c1@group-62F1BD7E3486-SegmentedRaftLogWorker close()
2022-02-09 08:19:25,688 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(262)) - aa0b8223-7685-4e0e-8077-085ec758d7c1: shutdown server with port 45565 now
2022-02-09 08:19:25,701 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - aa0b8223-7685-4e0e-8077-085ec758d7c1: shutdown server with port 45565 successfully
2022-02-09 08:19:25,701 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$541/997754283@48e3a7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-aa0b8223-7685-4e0e-8077-085ec758d7c1: Stopped
2022-02-09 08:19:26,065 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-02-09 08:19:26,423 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #1, no healthy replica found.
2022-02-09 08:19:26,424 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #2, no healthy replica found.
2022-02-09 08:19:26,424 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #3, no healthy replica found.
2022-02-09 08:19:26,424 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-02-09 08:19:26,683 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. aa0b8223-7685-4e0e-8077-085ec758d7c1{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=43267, RATIS=45565, RATIS_ADMIN=45565, RATIS_SERVER=45565, STANDALONE=38609], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-02-09 08:19:26,683 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(222)) - Send pipeline:PipelineID=6341b3b3-a77c-4ffa-a1ba-62f1bd7e3486 close command to datanode aa0b8223-7685-4e0e-8077-085ec758d7c1
2022-02-09 08:19:26,684 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(223)) - Pipeline Pipeline[ Id: 6341b3b3-a77c-4ffa-a1ba-62f1bd7e3486, Nodes: aa0b8223-7685-4e0e-8077-085ec758d7c1{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=43267, RATIS=45565, RATIS_ADMIN=45565, RATIS_SERVER=45565, STANDALONE=38609], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONED, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:aa0b8223-7685-4e0e-8077-085ec758d7c1, CreationTimestamp2022-02-09T08:18:57.237Z[Etc/UTC]] removed.
2022-02-09 08:19:26,684 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(137)) - Removed a node: /default-rack/aa0b8223-7685-4e0e-8077-085ec758d7c1
2022-02-09 08:19:26,684 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. 4b172544-f8d9-4b39-b7cd-191c86dc5ee2{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=39269, RATIS=36505, RATIS_ADMIN=36505, RATIS_SERVER=36505, STANDALONE=45371], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-02-09 08:19:26,685 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(222)) - Send pipeline:PipelineID=5d086ff7-1821-4951-a480-ac05006fa5c0 close command to datanode 4b172544-f8d9-4b39-b7cd-191c86dc5ee2
2022-02-09 08:19:26,685 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(223)) - Pipeline Pipeline[ Id: 5d086ff7-1821-4951-a480-ac05006fa5c0, Nodes: 4b172544-f8d9-4b39-b7cd-191c86dc5ee2{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=39269, RATIS=36505, RATIS_ADMIN=36505, RATIS_SERVER=36505, STANDALONE=45371], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:4b172544-f8d9-4b39-b7cd-191c86dc5ee2, CreationTimestamp2022-02-09T08:18:21.162Z[Etc/UTC]] removed.
2022-02-09 08:19:26,685 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(137)) - Removed a node: /default-rack/4b172544-f8d9-4b39-b7cd-191c86dc5ee2
2022-02-09 08:19:27,067 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 2 milliseconds for processing 6 containers.
2022-02-09 08:19:27,424 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #1, no healthy replica found.
2022-02-09 08:19:27,424 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #2, no healthy replica found.
2022-02-09 08:19:27,424 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #3, no healthy replica found.
2022-02-09 08:19:27,424 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-02-09 08:19:27,687 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-02-09 08:19:27,735 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-02-09 08:19:28,069 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-02-09 08:19:28,425 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #1, no healthy replica found.
2022-02-09 08:19:28,425 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #2, no healthy replica found.
2022-02-09 08:19:28,425 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #3, no healthy replica found.
2022-02-09 08:19:28,425 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-02-09 08:19:29,079 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-02-09 08:19:29,426 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #1, no healthy replica found.
2022-02-09 08:19:29,426 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #2, no healthy replica found.
2022-02-09 08:19:29,426 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #3, no healthy replica found.
2022-02-09 08:19:29,426 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-02-09 08:19:30,079 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-02-09 08:19:30,426 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #1, no healthy replica found.
2022-02-09 08:19:30,426 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #2, no healthy replica found.
2022-02-09 08:19:30,426 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #3, no healthy replica found.
2022-02-09 08:19:30,426 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-02-09 08:19:30,705 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(529)) - Ozone container server stopped.
2022-02-09 08:19:30,709 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@57d22e1d{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-02-09 08:19:30,710 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@6ca09e95{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-02-09 08:19:30,710 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-02-09 08:19:30,710 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@63384e67{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-02-09 08:19:30,710 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@3c53b440{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-02-09 08:19:30,741 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(529)) - Ozone container server stopped.
2022-02-09 08:19:30,746 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@21eedcde{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-02-09 08:19:30,746 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@3428420d{HTTP/1.1, (http/1.1)}{0.0.0.0:39967}
2022-02-09 08:19:30,746 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-02-09 08:19:30,747 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@7c88d04f{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-02-09 08:19:30,747 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@2e62e227{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-02-09 08:19:30,755 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(526)) - Stopping the StorageContainerManager
2022-02-09 08:19:30,755 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1390)) - Stopping Container Balancer service.
2022-02-09 08:19:30,755 [Mini-Cluster-Provider-Reap] INFO  balancer.ContainerBalancer (ContainerBalancer.java:stop(751)) - Container Balancer is not running.
2022-02-09 08:19:30,755 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1397)) - Stopping Replication Manager Service.
2022-02-09 08:19:30,755 [Mini-Cluster-Provider-Reap] INFO  container.ReplicationManager (ReplicationManager.java:stop(357)) - Stopping Replication Monitor Thread.
2022-02-09 08:19:30,755 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1404)) - Stopping the Datanode Admin Monitor.
2022-02-09 08:19:30,756 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1411)) - Stopping Lease Manager of the command watchers
2022-02-09 08:19:30,756 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1418)) - Stopping datanode service RPC server
2022-02-09 08:19:30,756 [Mini-Cluster-Provider-Reap] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(390)) - Stopping the RPC server for DataNodes
2022-02-09 08:19:30,756 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3414)) - Stopping server on 44943
2022-02-09 08:19:30,762 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - Stopping IPC Server Responder
2022-02-09 08:19:30,762 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1376)) - Stopping IPC Server listener on 0
2022-02-09 08:19:30,798 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(799)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2022-02-09 08:19:30,799 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1426)) - Stopping block service RPC server
2022-02-09 08:19:30,799 [Mini-Cluster-Provider-Reap] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(160)) - Stopping the RPC server for Block Protocol
2022-02-09 08:19:30,799 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3414)) - Stopping server on 44945
2022-02-09 08:19:30,802 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1376)) - Stopping IPC Server listener on 0
2022-02-09 08:19:30,802 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1433)) - Stopping the StorageContainerLocationProtocol RPC server
2022-02-09 08:19:30,802 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - Stopping IPC Server Responder
2022-02-09 08:19:30,802 [Mini-Cluster-Provider-Reap] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(174)) - Stopping the RPC server for Client Protocol
2022-02-09 08:19:30,802 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3414)) - Stopping server on 36859
2022-02-09 08:19:30,806 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1376)) - Stopping IPC Server listener on 0
2022-02-09 08:19:30,806 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1440)) - Stopping Storage Container Manager HTTP server.
2022-02-09 08:19:30,806 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - Stopping IPC Server Responder
2022-02-09 08:19:30,809 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@2654cf3{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2022-02-09 08:19:30,809 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@62485521{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-02-09 08:19:30,809 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-02-09 08:19:30,810 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@400461a9{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2022-02-09 08:19:30,810 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@5ded8a9a{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-02-09 08:19:30,813 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1451)) - Stopping Block Manager Service.
2022-02-09 08:19:30,813 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service SCMBlockDeletingService
2022-02-09 08:19:30,813 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service SCMBlockDeletingService
2022-02-09 08:19:30,813 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1478)) - Stopping SCM Event Queue.
2022-02-09 08:19:30,829 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1489)) - Stopping SCM HA services.
2022-02-09 08:19:30,829 [Mini-Cluster-Provider-Reap] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(158)) - Stopping RatisPipelineUtilsThread.
2022-02-09 08:19:30,829 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1499)) - Stopping SCM MetadataStore.
2022-02-09 08:19:30,830 [Mini-Cluster-Provider-Reap] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(205)) - HddsDatanode metrics system stopped (again)
2022-02-09 08:19:31,014 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(437)) - Shutting down the Mini Ozone Cluster
2022-02-09 08:19:31,015 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(452)) - Stopping the Mini Ozone Cluster
2022-02-09 08:19:31,015 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(534)) - Stopping the OzoneManager
2022-02-09 08:19:31,015 [Mini-Cluster-Provider-Reap] INFO  om.OzoneManager (OzoneManager.java:stop(1893)) - om1[localhost:0]: Stopping Ozone Manager
2022-02-09 08:19:31,034 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3414)) - Stopping server on 43955
2022-02-09 08:19:31,034 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1376)) - Stopping IPC Server listener on 0
2022-02-09 08:19:31,041 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - Stopping IPC Server Responder
2022-02-09 08:19:31,041 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(391)) - om1: close
2022-02-09 08:19:31,047 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(412)) - om1@group-C5BA1605619E: shutdown
2022-02-09 08:19:31,047 [Mini-Cluster-Provider-Reap] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id="om1"
2022-02-09 08:19:31,047 [Mini-Cluster-Provider-Reap] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(91)) - om1: shutdown om1@group-C5BA1605619E-LeaderStateImpl
2022-02-09 08:19:31,047 [Mini-Cluster-Provider-Reap] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - om1@group-C5BA1605619E-PendingRequests: sendNotLeaderResponses
2022-02-09 08:19:31,058 [Mini-Cluster-Provider-Reap] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(149)) - om1@group-C5BA1605619E-StateMachineUpdater: set stopIndex = 84
2022-02-09 08:19:31,058 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(417)) - Current Snapshot Index (t:1, i:84)
2022-02-09 08:19:31,058 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(281)) - om1@group-C5BA1605619E-StateMachineUpdater: Took a snapshot at index 84
2022-02-09 08:19:31,058 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(89)) - om1@group-C5BA1605619E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 84
2022-02-09 08:19:31,058 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(471)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2022-02-09 08:19:31,059 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (ServerState.java:close(419)) - om1@group-C5BA1605619E: closes. applyIndex: 84
2022-02-09 08:19:31,060 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(327)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-02-09 08:19:31,061 [Mini-Cluster-Provider-Reap] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(237)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker close()
2022-02-09 08:19:31,061 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(262)) - om1: shutdown server with port 36819 now
2022-02-09 08:19:31,062 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - om1: shutdown server with port 36819 successfully
2022-02-09 08:19:31,062 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$541/997754283@78284ea1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-om1: Stopped
2022-02-09 08:19:31,062 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(437)) - Stopping OMDoubleBuffer flush thread
2022-02-09 08:19:31,078 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(356)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2022-02-09 08:19:31,079 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service KeyDeletingService
2022-02-09 08:19:31,080 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-02-09 08:19:31,082 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service DirectoryDeletingService
2022-02-09 08:19:31,092 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@53f5f879{ozoneManager,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2022-02-09 08:19:31,094 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@42d1ffeb{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-02-09 08:19:31,094 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-02-09 08:19:31,095 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@4d696933{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2022-02-09 08:19:31,095 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@6cd682e5{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-02-09 08:19:31,112 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(511)) - Stopping the HddsDatanodes
2022-02-09 08:19:31,643 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(336)) - Attempting to stop container services.
2022-02-09 08:19:31,644 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(391)) - a6c92f00-aadd-4833-aecb-8acb899822d4: close
2022-02-09 08:19:31,644 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(412)) - a6c92f00-aadd-4833-aecb-8acb899822d4@group-EC2B3945FFA8: shutdown
2022-02-09 08:19:31,645 [Mini-Cluster-Provider-Reap] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-EC2B3945FFA8,id=a6c92f00-aadd-4833-aecb-8acb899822d4
2022-02-09 08:19:31,645 [Mini-Cluster-Provider-Reap] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(91)) - a6c92f00-aadd-4833-aecb-8acb899822d4: shutdown a6c92f00-aadd-4833-aecb-8acb899822d4@group-EC2B3945FFA8-LeaderStateImpl
2022-02-09 08:19:31,645 [Mini-Cluster-Provider-Reap] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - a6c92f00-aadd-4833-aecb-8acb899822d4@group-EC2B3945FFA8-PendingRequests: sendNotLeaderResponses
2022-02-09 08:19:31,646 [Mini-Cluster-Provider-Reap] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(149)) - a6c92f00-aadd-4833-aecb-8acb899822d4@group-EC2B3945FFA8-StateMachineUpdater: set stopIndex = 0
2022-02-09 08:19:31,647 [a6c92f00-aadd-4833-aecb-8acb899822d4@group-EC2B3945FFA8-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(299)) - group-EC2B3945FFA8: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-3/data/ratis/7aa38f27-c5b1-4668-bc1a-ec2b3945ffa8/sm/snapshot.1_0
2022-02-09 08:19:31,655 [a6c92f00-aadd-4833-aecb-8acb899822d4@group-EC2B3945FFA8-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(310)) - group-EC2B3945FFA8: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-3/data/ratis/7aa38f27-c5b1-4668-bc1a-ec2b3945ffa8/sm/snapshot.1_0 took: 8 ms
2022-02-09 08:19:31,655 [a6c92f00-aadd-4833-aecb-8acb899822d4@group-EC2B3945FFA8-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(281)) - a6c92f00-aadd-4833-aecb-8acb899822d4@group-EC2B3945FFA8-StateMachineUpdater: Took a snapshot at index 0
2022-02-09 08:19:31,655 [a6c92f00-aadd-4833-aecb-8acb899822d4@group-EC2B3945FFA8-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(89)) - a6c92f00-aadd-4833-aecb-8acb899822d4@group-EC2B3945FFA8-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-02-09 08:19:31,660 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (ServerState.java:close(419)) - a6c92f00-aadd-4833-aecb-8acb899822d4@group-EC2B3945FFA8: closes. applyIndex: 0
2022-02-09 08:19:31,660 [a6c92f00-aadd-4833-aecb-8acb899822d4@group-EC2B3945FFA8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(327)) - a6c92f00-aadd-4833-aecb-8acb899822d4@group-EC2B3945FFA8-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-02-09 08:19:31,661 [Mini-Cluster-Provider-Reap] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(237)) - a6c92f00-aadd-4833-aecb-8acb899822d4@group-EC2B3945FFA8-SegmentedRaftLogWorker close()
2022-02-09 08:19:31,661 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(412)) - a6c92f00-aadd-4833-aecb-8acb899822d4@group-914DF9B16788: shutdown
2022-02-09 08:19:31,662 [Mini-Cluster-Provider-Reap] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-914DF9B16788,id=a6c92f00-aadd-4833-aecb-8acb899822d4
2022-02-09 08:19:31,662 [Mini-Cluster-Provider-Reap] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(108)) - a6c92f00-aadd-4833-aecb-8acb899822d4: shutdown a6c92f00-aadd-4833-aecb-8acb899822d4@group-914DF9B16788-FollowerState
2022-02-09 08:19:31,664 [Mini-Cluster-Provider-Reap] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(149)) - a6c92f00-aadd-4833-aecb-8acb899822d4@group-914DF9B16788-StateMachineUpdater: set stopIndex = 23
2022-02-09 08:19:31,664 [a6c92f00-aadd-4833-aecb-8acb899822d4@group-914DF9B16788-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(299)) - group-914DF9B16788: Taking a snapshot at:(t:3, i:23) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-3/data/ratis/40f9fd32-189e-4aa5-9225-914df9b16788/sm/snapshot.3_23
2022-02-09 08:19:31,664 [a6c92f00-aadd-4833-aecb-8acb899822d4@group-914DF9B16788-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - a6c92f00-aadd-4833-aecb-8acb899822d4@group-914DF9B16788-FollowerState was interrupted: {}
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at java.lang.Thread.sleep(Thread.java:340)
	at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
2022-02-09 08:19:31,667 [a6c92f00-aadd-4833-aecb-8acb899822d4@group-914DF9B16788-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(310)) - group-914DF9B16788: Finished taking a snapshot at:(t:3, i:23) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-3/data/ratis/40f9fd32-189e-4aa5-9225-914df9b16788/sm/snapshot.3_23 took: 3 ms
2022-02-09 08:19:31,667 [a6c92f00-aadd-4833-aecb-8acb899822d4@group-914DF9B16788-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(281)) - a6c92f00-aadd-4833-aecb-8acb899822d4@group-914DF9B16788-StateMachineUpdater: Took a snapshot at index 23
2022-02-09 08:19:31,667 [a6c92f00-aadd-4833-aecb-8acb899822d4@group-914DF9B16788-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(89)) - a6c92f00-aadd-4833-aecb-8acb899822d4@group-914DF9B16788-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 23
2022-02-09 08:19:31,667 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (ServerState.java:close(419)) - a6c92f00-aadd-4833-aecb-8acb899822d4@group-914DF9B16788: closes. applyIndex: 23
2022-02-09 08:19:31,668 [a6c92f00-aadd-4833-aecb-8acb899822d4@group-914DF9B16788-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(327)) - a6c92f00-aadd-4833-aecb-8acb899822d4@group-914DF9B16788-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-02-09 08:19:31,668 [Mini-Cluster-Provider-Reap] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(237)) - a6c92f00-aadd-4833-aecb-8acb899822d4@group-914DF9B16788-SegmentedRaftLogWorker close()
2022-02-09 08:19:31,669 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(262)) - a6c92f00-aadd-4833-aecb-8acb899822d4: shutdown server with port 37711 now
2022-02-09 08:19:31,671 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: HTTP/2 error code: CANCEL
Received Rst Stream
2022-02-09 08:19:31,671 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(47)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4: nextIndex: updateUnconditionally 24 -> 23
2022-02-09 08:19:31,681 [grpc-default-executor-3] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - a6c92f00-aadd-4833-aecb-8acb899822d4: installSnapshot onError, lastRequest: 00879972-6a44-40a3-8061-2c26daaa092c->a6c92f00-aadd-4833-aecb-8acb899822d4#199-t3,previous=(t:3, i:22),leaderCommit=21,initializing? true,entries: size=1, first=(t:3, i:23), METADATAENTRY(c:21): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2022-02-09 08:19:31,681 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-02-09 08:19:31,682 [grpc-default-executor-2] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(47)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4: nextIndex: updateUnconditionally 24 -> 23
2022-02-09 08:19:31,732 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - a6c92f00-aadd-4833-aecb-8acb899822d4: shutdown server with port 37711 successfully
2022-02-09 08:19:31,732 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$541/997754283@7bfb7187] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-a6c92f00-aadd-4833-aecb-8acb899822d4: Stopped
2022-02-09 08:19:32,080 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-02-09 08:19:33,081 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-02-09 08:19:33,206 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode a6c92f00-aadd-4833-aecb-8acb899822d4{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42497, RATIS=37711, RATIS_ADMIN=37711, RATIS_SERVER=37711, STANDALONE=44989], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=7aa38f27-c5b1-4668-bc1a-ec2b3945ffa8, PipelineID=40f9fd32-189e-4aa5-9225-914df9b16788]
2022-02-09 08:19:33,207 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(365)) - Pipeline Pipeline[ Id: 7aa38f27-c5b1-4668-bc1a-ec2b3945ffa8, Nodes: a6c92f00-aadd-4833-aecb-8acb899822d4{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42497, RATIS=37711, RATIS_ADMIN=37711, RATIS_SERVER=37711, STANDALONE=44989], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:a6c92f00-aadd-4833-aecb-8acb899822d4, CreationTimestamp2022-02-09T08:18:35.449Z[Etc/UTC]] moved to CLOSED state
2022-02-09 08:19:33,208 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(344)) - Container #4 closed for pipeline=PipelineID=40f9fd32-189e-4aa5-9225-914df9b16788
2022-02-09 08:19:33,208 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(69)) - Close container Event triggered for container : #4
2022-02-09 08:19:33,208 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(344)) - Container #5 closed for pipeline=PipelineID=40f9fd32-189e-4aa5-9225-914df9b16788
2022-02-09 08:19:33,208 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(69)) - Close container Event triggered for container : #5
2022-02-09 08:19:33,208 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(344)) - Container #6 closed for pipeline=PipelineID=40f9fd32-189e-4aa5-9225-914df9b16788
2022-02-09 08:19:33,209 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(365)) - Pipeline Pipeline[ Id: 40f9fd32-189e-4aa5-9225-914df9b16788, Nodes: b1c11bf6-0210-4fae-ad64-f50b3eead4b6{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42459, RATIS=42099, RATIS_ADMIN=42099, RATIS_SERVER=42099, STANDALONE=41503], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}00879972-6a44-40a3-8061-2c26daaa092c{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=36567, RATIS=46343, RATIS_ADMIN=46343, RATIS_SERVER=46343, STANDALONE=42547], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a6c92f00-aadd-4833-aecb-8acb899822d4{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42497, RATIS=37711, RATIS_ADMIN=37711, RATIS_SERVER=37711, STANDALONE=44989], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:00879972-6a44-40a3-8061-2c26daaa092c, CreationTimestamp2022-02-09T08:18:36.586Z[Etc/UTC]] moved to CLOSED state
2022-02-09 08:19:33,209 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(69)) - Close container Event triggered for container : #6
2022-02-09 08:19:33,764 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-02-09 08:19:33,807 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode d6ad39fc-5f17-463f-9d0b-f520f0947e2d{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=34325, RATIS=41167, RATIS_ADMIN=41167, RATIS_SERVER=41167, STANDALONE=32839], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=f82cb8ae-e6c3-4fcc-b554-1fa18b14ade5, PipelineID=a3411903-4a88-4c3e-b106-a0306dfe1cc6]
2022-02-09 08:19:33,807 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(365)) - Pipeline Pipeline[ Id: f82cb8ae-e6c3-4fcc-b554-1fa18b14ade5, Nodes: d6ad39fc-5f17-463f-9d0b-f520f0947e2d{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=34325, RATIS=41167, RATIS_ADMIN=41167, RATIS_SERVER=41167, STANDALONE=32839], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:d6ad39fc-5f17-463f-9d0b-f520f0947e2d, CreationTimestamp2022-02-09T08:19:15.798Z[Etc/UTC]] moved to CLOSED state
2022-02-09 08:19:33,808 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(365)) - Pipeline Pipeline[ Id: a3411903-4a88-4c3e-b106-a0306dfe1cc6, Nodes: d446f06f-c919-4727-b846-3f8c8c5e1658{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=43319, RATIS=35969, RATIS_ADMIN=35969, RATIS_SERVER=35969, STANDALONE=37823], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}d6ad39fc-5f17-463f-9d0b-f520f0947e2d{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=34325, RATIS=41167, RATIS_ADMIN=41167, RATIS_SERVER=41167, STANDALONE=32839], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}4b3568ef-ad3d-4964-ac82-76a8654b6a6f{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=38721, RATIS=43347, RATIS_ADMIN=43347, RATIS_SERVER=43347, STANDALONE=44323], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:d6ad39fc-5f17-463f-9d0b-f520f0947e2d, CreationTimestamp2022-02-09T08:19:15.795Z[Etc/UTC]] moved to CLOSED state
2022-02-09 08:19:34,081 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:sendCloseCommand(1540)) - Sending close container command for container #4 to datanode a6c92f00-aadd-4833-aecb-8acb899822d4{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42497, RATIS=37711, RATIS_ADMIN=37711, RATIS_SERVER=37711, STANDALONE=44989], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-02-09 08:19:34,082 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:sendCloseCommand(1540)) - Sending close container command for container #4 to datanode b1c11bf6-0210-4fae-ad64-f50b3eead4b6{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42459, RATIS=42099, RATIS_ADMIN=42099, RATIS_SERVER=42099, STANDALONE=41503], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-02-09 08:19:34,082 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:sendCloseCommand(1540)) - Sending close container command for container #4 to datanode 00879972-6a44-40a3-8061-2c26daaa092c{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=36567, RATIS=46343, RATIS_ADMIN=46343, RATIS_SERVER=46343, STANDALONE=42547], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-02-09 08:19:34,082 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:sendCloseCommand(1540)) - Sending close container command for container #5 to datanode a6c92f00-aadd-4833-aecb-8acb899822d4{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42497, RATIS=37711, RATIS_ADMIN=37711, RATIS_SERVER=37711, STANDALONE=44989], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-02-09 08:19:34,082 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:sendCloseCommand(1540)) - Sending close container command for container #5 to datanode b1c11bf6-0210-4fae-ad64-f50b3eead4b6{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42459, RATIS=42099, RATIS_ADMIN=42099, RATIS_SERVER=42099, STANDALONE=41503], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-02-09 08:19:34,082 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:sendCloseCommand(1540)) - Sending close container command for container #5 to datanode 00879972-6a44-40a3-8061-2c26daaa092c{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=36567, RATIS=46343, RATIS_ADMIN=46343, RATIS_SERVER=46343, STANDALONE=42547], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-02-09 08:19:34,082 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:sendCloseCommand(1540)) - Sending close container command for container #6 to datanode a6c92f00-aadd-4833-aecb-8acb899822d4{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42497, RATIS=37711, RATIS_ADMIN=37711, RATIS_SERVER=37711, STANDALONE=44989], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-02-09 08:19:34,082 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:sendCloseCommand(1540)) - Sending close container command for container #6 to datanode b1c11bf6-0210-4fae-ad64-f50b3eead4b6{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42459, RATIS=42099, RATIS_ADMIN=42099, RATIS_SERVER=42099, STANDALONE=41503], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-02-09 08:19:34,082 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:sendCloseCommand(1540)) - Sending close container command for container #6 to datanode 00879972-6a44-40a3-8061-2c26daaa092c{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=36567, RATIS=46343, RATIS_ADMIN=46343, RATIS_SERVER=46343, STANDALONE=42547], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-02-09 08:19:34,082 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-02-09 08:19:34,179 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-02-09 08:19:34,179 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(47)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4: nextIndex: updateUnconditionally 24 -> 23
2022-02-09 08:19:34,396 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-02-09 08:19:34,397 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(47)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4: nextIndex: updateUnconditionally 24 -> 23
2022-02-09 08:19:34,413 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-02-09 08:19:34,414 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(47)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4: nextIndex: updateUnconditionally 24 -> 23
2022-02-09 08:19:34,443 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-02-09 08:19:34,477 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(47)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4: nextIndex: updateUnconditionally 24 -> 23
2022-02-09 08:19:34,491 [pool-423-thread-3] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(401)) - Container 4 is synced with bcsId 13.
2022-02-09 08:19:34,495 [pool-423-thread-3] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(401)) - Container 4 is synced with bcsId 13.
2022-02-09 08:19:34,510 [pool-423-thread-3] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(338)) - Container 4 is closed with bcsId 13.
2022-02-09 08:19:34,513 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(223)) - Moving container #4 to CLOSED state, datanode 00879972-6a44-40a3-8061-2c26daaa092c{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=36567, RATIS=46343, RATIS_ADMIN=46343, RATIS_SERVER=46343, STANDALONE=42547], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
2022-02-09 08:19:34,515 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-02-09 08:19:34,516 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(47)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4: nextIndex: updateUnconditionally 24 -> 23
2022-02-09 08:19:34,525 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-02-09 08:19:34,525 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(47)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4: nextIndex: updateUnconditionally 24 -> 23
2022-02-09 08:19:34,530 [pool-422-thread-3] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(401)) - Container 4 is synced with bcsId 13.
2022-02-09 08:19:34,530 [pool-422-thread-3] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(401)) - Container 4 is synced with bcsId 13.
2022-02-09 08:19:34,539 [pool-422-thread-3] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(338)) - Container 4 is closed with bcsId 13.
2022-02-09 08:19:34,553 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-02-09 08:19:34,554 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(47)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4: nextIndex: updateUnconditionally 24 -> 23
2022-02-09 08:19:34,556 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-02-09 08:19:34,557 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(47)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4: nextIndex: updateUnconditionally 24 -> 23
2022-02-09 08:19:34,600 [pool-422-thread-4] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(401)) - Container 5 is synced with bcsId 17.
2022-02-09 08:19:34,600 [pool-422-thread-4] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(401)) - Container 5 is synced with bcsId 17.
2022-02-09 08:19:34,604 [pool-422-thread-4] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(338)) - Container 5 is closed with bcsId 17.
2022-02-09 08:19:34,608 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(223)) - Moving container #5 to CLOSED state, datanode b1c11bf6-0210-4fae-ad64-f50b3eead4b6{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42459, RATIS=42099, RATIS_ADMIN=42099, RATIS_SERVER=42099, STANDALONE=41503], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
2022-02-09 08:19:34,619 [pool-423-thread-4] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(401)) - Container 5 is synced with bcsId 17.
2022-02-09 08:19:34,620 [pool-423-thread-4] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(401)) - Container 5 is synced with bcsId 17.
2022-02-09 08:19:34,622 [pool-423-thread-4] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(338)) - Container 5 is closed with bcsId 17.
2022-02-09 08:19:34,625 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-02-09 08:19:34,626 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(47)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4: nextIndex: updateUnconditionally 24 -> 23
2022-02-09 08:19:34,663 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-02-09 08:19:34,664 [grpc-default-executor-2] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(47)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4: nextIndex: updateUnconditionally 24 -> 23
2022-02-09 08:19:34,666 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-02-09 08:19:34,666 [grpc-default-executor-2] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(47)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4: nextIndex: updateUnconditionally 24 -> 23
2022-02-09 08:19:34,700 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-02-09 08:19:34,700 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(47)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4: nextIndex: updateUnconditionally 24 -> 23
2022-02-09 08:19:34,731 [pool-422-thread-5] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(401)) - Container 6 is synced with bcsId 21.
2022-02-09 08:19:34,731 [pool-422-thread-5] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(401)) - Container 6 is synced with bcsId 21.
2022-02-09 08:19:34,739 [pool-422-thread-5] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(338)) - Container 6 is closed with bcsId 21.
2022-02-09 08:19:34,751 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(223)) - Moving container #6 to CLOSED state, datanode b1c11bf6-0210-4fae-ad64-f50b3eead4b6{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42459, RATIS=42099, RATIS_ADMIN=42099, RATIS_SERVER=42099, STANDALONE=41503], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
2022-02-09 08:19:34,777 [pool-423-thread-5] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(401)) - Container 6 is synced with bcsId 21.
2022-02-09 08:19:34,777 [pool-423-thread-5] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(401)) - Container 6 is synced with bcsId 21.
2022-02-09 08:19:34,780 [pool-423-thread-5] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(338)) - Container 6 is closed with bcsId 21.
2022-02-09 08:19:35,083 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:sendCloseCommand(1540)) - Sending close container command for container #4 to datanode a6c92f00-aadd-4833-aecb-8acb899822d4{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42497, RATIS=37711, RATIS_ADMIN=37711, RATIS_SERVER=37711, STANDALONE=44989], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-02-09 08:19:35,083 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:sendCloseCommand(1540)) - Sending close container command for container #5 to datanode a6c92f00-aadd-4833-aecb-8acb899822d4{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42497, RATIS=37711, RATIS_ADMIN=37711, RATIS_SERVER=37711, STANDALONE=44989], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-02-09 08:19:35,083 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:sendCloseCommand(1540)) - Sending close container command for container #6 to datanode a6c92f00-aadd-4833-aecb-8acb899822d4{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42497, RATIS=37711, RATIS_ADMIN=37711, RATIS_SERVER=37711, STANDALONE=44989], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-02-09 08:19:35,083 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-02-09 08:19:36,084 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:sendCloseCommand(1540)) - Sending close container command for container #4 to datanode a6c92f00-aadd-4833-aecb-8acb899822d4{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42497, RATIS=37711, RATIS_ADMIN=37711, RATIS_SERVER=37711, STANDALONE=44989], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-02-09 08:19:36,084 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:sendCloseCommand(1540)) - Sending close container command for container #5 to datanode a6c92f00-aadd-4833-aecb-8acb899822d4{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42497, RATIS=37711, RATIS_ADMIN=37711, RATIS_SERVER=37711, STANDALONE=44989], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-02-09 08:19:36,084 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:sendCloseCommand(1540)) - Sending close container command for container #6 to datanode a6c92f00-aadd-4833-aecb-8acb899822d4{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42497, RATIS=37711, RATIS_ADMIN=37711, RATIS_SERVER=37711, STANDALONE=44989], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-02-09 08:19:36,085 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 2 milliseconds for processing 6 containers.
2022-02-09 08:19:36,113 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(336)) - Attempting to stop container services.
2022-02-09 08:19:36,114 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(391)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d: close
2022-02-09 08:19:36,114 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(412)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5: shutdown
2022-02-09 08:19:36,114 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-1FA18B14ADE5,id=d6ad39fc-5f17-463f-9d0b-f520f0947e2d
2022-02-09 08:19:36,114 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(91)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d: shutdown d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-LeaderStateImpl
2022-02-09 08:19:36,114 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-PendingRequests: sendNotLeaderResponses
2022-02-09 08:19:36,115 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(149)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-StateMachineUpdater: set stopIndex = 0
2022-02-09 08:19:36,116 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(299)) - group-1FA18B14ADE5: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-1/data/ratis/f82cb8ae-e6c3-4fcc-b554-1fa18b14ade5/sm/snapshot.1_0
2022-02-09 08:19:36,117 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(310)) - group-1FA18B14ADE5: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-1/data/ratis/f82cb8ae-e6c3-4fcc-b554-1fa18b14ade5/sm/snapshot.1_0 took: 1 ms
2022-02-09 08:19:36,118 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(281)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-StateMachineUpdater: Took a snapshot at index 0
2022-02-09 08:19:36,118 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(89)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-02-09 08:19:36,118 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer$Division (ServerState.java:close(419)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5: closes. applyIndex: 0
2022-02-09 08:19:36,118 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(327)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-02-09 08:19:36,118 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(237)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-1FA18B14ADE5-SegmentedRaftLogWorker close()
2022-02-09 08:19:36,128 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(412)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6: shutdown
2022-02-09 08:19:36,129 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A0306DFE1CC6,id=d6ad39fc-5f17-463f-9d0b-f520f0947e2d
2022-02-09 08:19:36,129 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(91)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d: shutdown d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-LeaderStateImpl
2022-02-09 08:19:36,129 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6->d446f06f-c919-4727-b846-3f8c8c5e1658-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(177)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6->d446f06f-c919-4727-b846-3f8c8c5e1658-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2022-02-09 08:19:36,129 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6->4b3568ef-ad3d-4964-ac82-76a8654b6a6f-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(177)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6->4b3568ef-ad3d-4964-ac82-76a8654b6a6f-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2022-02-09 08:19:36,129 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-PendingRequests: sendNotLeaderResponses
2022-02-09 08:19:36,130 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(149)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-StateMachineUpdater: set stopIndex = 0
2022-02-09 08:19:36,133 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(140)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f: Completed APPEND_ENTRIES, lastRequest: d6ad39fc-5f17-463f-9d0b-f520f0947e2d->4b3568ef-ad3d-4964-ac82-76a8654b6a6f#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? true,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY
2022-02-09 08:19:36,133 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(299)) - group-A0306DFE1CC6: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-1/data/ratis/a3411903-4a88-4c3e-b106-a0306dfe1cc6/sm/snapshot.1_0
2022-02-09 08:19:36,132 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(140)) - d446f06f-c919-4727-b846-3f8c8c5e1658: Completed APPEND_ENTRIES, lastRequest: d6ad39fc-5f17-463f-9d0b-f520f0947e2d->d446f06f-c919-4727-b846-3f8c8c5e1658#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? true,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY
2022-02-09 08:19:36,134 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(346)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6->d446f06f-c919-4727-b846-3f8c8c5e1658-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2022-02-09 08:19:36,153 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(47)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6->d446f06f-c919-4727-b846-3f8c8c5e1658: nextIndex: updateUnconditionally 1 -> 0
2022-02-09 08:19:36,152 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(310)) - group-A0306DFE1CC6: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-1/data/ratis/a3411903-4a88-4c3e-b106-a0306dfe1cc6/sm/snapshot.1_0 took: 19 ms
2022-02-09 08:19:36,153 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(281)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-StateMachineUpdater: Took a snapshot at index 0
2022-02-09 08:19:36,153 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(89)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-02-09 08:19:36,153 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer$Division (ServerState.java:close(419)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6: closes. applyIndex: 0
2022-02-09 08:19:36,154 [d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(327)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-02-09 08:19:36,154 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(237)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6-SegmentedRaftLogWorker close()
2022-02-09 08:19:36,155 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(346)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6->4b3568ef-ad3d-4964-ac82-76a8654b6a6f-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2022-02-09 08:19:36,155 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(47)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d@group-A0306DFE1CC6->4b3568ef-ad3d-4964-ac82-76a8654b6a6f: nextIndex: updateUnconditionally 1 -> 0
2022-02-09 08:19:36,156 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(262)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d: shutdown server with port 41167 now
2022-02-09 08:19:36,172 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - d6ad39fc-5f17-463f-9d0b-f520f0947e2d: shutdown server with port 41167 successfully
2022-02-09 08:19:36,173 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$541/997754283@70b40bd8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-d6ad39fc-5f17-463f-9d0b-f520f0947e2d: Stopped
2022-02-09 08:19:36,173 [grpc-default-executor-2] WARN  client.GrpcClientProtocolService (LogUtils.java:warn(122)) - 1-UnorderedRequestStreamObserver1: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2022-02-09 08:19:36,215 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. a6c92f00-aadd-4833-aecb-8acb899822d4{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42497, RATIS=37711, RATIS_ADMIN=37711, RATIS_SERVER=37711, STANDALONE=44989], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-02-09 08:19:36,216 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(222)) - Send pipeline:PipelineID=7aa38f27-c5b1-4668-bc1a-ec2b3945ffa8 close command to datanode a6c92f00-aadd-4833-aecb-8acb899822d4
2022-02-09 08:19:36,218 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(223)) - Pipeline Pipeline[ Id: 7aa38f27-c5b1-4668-bc1a-ec2b3945ffa8, Nodes: a6c92f00-aadd-4833-aecb-8acb899822d4{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42497, RATIS=37711, RATIS_ADMIN=37711, RATIS_SERVER=37711, STANDALONE=44989], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:a6c92f00-aadd-4833-aecb-8acb899822d4, CreationTimestamp2022-02-09T08:18:35.449Z[Etc/UTC]] removed.
2022-02-09 08:19:36,220 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(222)) - Send pipeline:PipelineID=40f9fd32-189e-4aa5-9225-914df9b16788 close command to datanode b1c11bf6-0210-4fae-ad64-f50b3eead4b6
2022-02-09 08:19:36,221 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(222)) - Send pipeline:PipelineID=40f9fd32-189e-4aa5-9225-914df9b16788 close command to datanode 00879972-6a44-40a3-8061-2c26daaa092c
2022-02-09 08:19:36,221 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(222)) - Send pipeline:PipelineID=40f9fd32-189e-4aa5-9225-914df9b16788 close command to datanode a6c92f00-aadd-4833-aecb-8acb899822d4
2022-02-09 08:19:36,221 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(223)) - Pipeline Pipeline[ Id: 40f9fd32-189e-4aa5-9225-914df9b16788, Nodes: b1c11bf6-0210-4fae-ad64-f50b3eead4b6{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42459, RATIS=42099, RATIS_ADMIN=42099, RATIS_SERVER=42099, STANDALONE=41503], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}00879972-6a44-40a3-8061-2c26daaa092c{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=36567, RATIS=46343, RATIS_ADMIN=46343, RATIS_SERVER=46343, STANDALONE=42547], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a6c92f00-aadd-4833-aecb-8acb899822d4{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42497, RATIS=37711, RATIS_ADMIN=37711, RATIS_SERVER=37711, STANDALONE=44989], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:00879972-6a44-40a3-8061-2c26daaa092c, CreationTimestamp2022-02-09T08:18:36.586Z[Etc/UTC]] removed.
2022-02-09 08:19:36,222 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(137)) - Removed a node: /default-rack/a6c92f00-aadd-4833-aecb-8acb899822d4
2022-02-09 08:19:36,783 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=40f9fd32-189e-4aa5-9225-914df9b16788 is not found
2022-02-09 08:19:36,787 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(529)) - Ozone container server stopped.
2022-02-09 08:19:36,790 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@36cf93b9{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-02-09 08:19:36,790 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@7f6dc22f{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-02-09 08:19:36,790 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-02-09 08:19:36,790 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@62562ea6{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-02-09 08:19:36,791 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@13896fee{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-02-09 08:19:36,815 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. d6ad39fc-5f17-463f-9d0b-f520f0947e2d{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=34325, RATIS=41167, RATIS_ADMIN=41167, RATIS_SERVER=41167, STANDALONE=32839], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-02-09 08:19:36,816 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(222)) - Send pipeline:PipelineID=f82cb8ae-e6c3-4fcc-b554-1fa18b14ade5 close command to datanode d6ad39fc-5f17-463f-9d0b-f520f0947e2d
2022-02-09 08:19:36,816 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(223)) - Pipeline Pipeline[ Id: f82cb8ae-e6c3-4fcc-b554-1fa18b14ade5, Nodes: d6ad39fc-5f17-463f-9d0b-f520f0947e2d{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=34325, RATIS=41167, RATIS_ADMIN=41167, RATIS_SERVER=41167, STANDALONE=32839], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:d6ad39fc-5f17-463f-9d0b-f520f0947e2d, CreationTimestamp2022-02-09T08:19:15.798Z[Etc/UTC]] removed.
2022-02-09 08:19:36,816 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(222)) - Send pipeline:PipelineID=a3411903-4a88-4c3e-b106-a0306dfe1cc6 close command to datanode d446f06f-c919-4727-b846-3f8c8c5e1658
2022-02-09 08:19:36,816 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(222)) - Send pipeline:PipelineID=a3411903-4a88-4c3e-b106-a0306dfe1cc6 close command to datanode d6ad39fc-5f17-463f-9d0b-f520f0947e2d
2022-02-09 08:19:36,816 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(222)) - Send pipeline:PipelineID=a3411903-4a88-4c3e-b106-a0306dfe1cc6 close command to datanode 4b3568ef-ad3d-4964-ac82-76a8654b6a6f
2022-02-09 08:19:36,816 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(223)) - Pipeline Pipeline[ Id: a3411903-4a88-4c3e-b106-a0306dfe1cc6, Nodes: d446f06f-c919-4727-b846-3f8c8c5e1658{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=43319, RATIS=35969, RATIS_ADMIN=35969, RATIS_SERVER=35969, STANDALONE=37823], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}d6ad39fc-5f17-463f-9d0b-f520f0947e2d{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=34325, RATIS=41167, RATIS_ADMIN=41167, RATIS_SERVER=41167, STANDALONE=32839], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}4b3568ef-ad3d-4964-ac82-76a8654b6a6f{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=38721, RATIS=43347, RATIS_ADMIN=43347, RATIS_SERVER=43347, STANDALONE=44323], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:d6ad39fc-5f17-463f-9d0b-f520f0947e2d, CreationTimestamp2022-02-09T08:19:15.795Z[Etc/UTC]] removed.
2022-02-09 08:19:36,816 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(137)) - Removed a node: /default-rack/d6ad39fc-5f17-463f-9d0b-f520f0947e2d
2022-02-09 08:19:37,085 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1224)) - Container #2 is under replicated. Expected replica count is 3, but found 2.
2022-02-09 08:19:37,086 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:sendReplicateCommand(1578)) - Sending replicate container command for container #2 to datanode b1c11bf6-0210-4fae-ad64-f50b3eead4b6{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42459, RATIS=42099, RATIS_ADMIN=42099, RATIS_SERVER=42099, STANDALONE=41503], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [00879972-6a44-40a3-8061-2c26daaa092c{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=36567, RATIS=46343, RATIS_ADMIN=46343, RATIS_SERVER=46343, STANDALONE=42547], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 4b3568ef-ad3d-4964-ac82-76a8654b6a6f{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=38721, RATIS=43347, RATIS_ADMIN=43347, RATIS_SERVER=43347, STANDALONE=44323], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-02-09 08:19:37,086 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1224)) - Container #4 is under replicated. Expected replica count is 3, but found 2.
2022-02-09 08:19:37,086 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:sendReplicateCommand(1578)) - Sending replicate container command for container #4 to datanode d446f06f-c919-4727-b846-3f8c8c5e1658{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=43319, RATIS=35969, RATIS_ADMIN=35969, RATIS_SERVER=35969, STANDALONE=37823], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [b1c11bf6-0210-4fae-ad64-f50b3eead4b6{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42459, RATIS=42099, RATIS_ADMIN=42099, RATIS_SERVER=42099, STANDALONE=41503], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 00879972-6a44-40a3-8061-2c26daaa092c{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=36567, RATIS=46343, RATIS_ADMIN=46343, RATIS_SERVER=46343, STANDALONE=42547], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-02-09 08:19:37,086 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1224)) - Container #5 is under replicated. Expected replica count is 3, but found 2.
2022-02-09 08:19:37,086 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:sendReplicateCommand(1578)) - Sending replicate container command for container #5 to datanode d446f06f-c919-4727-b846-3f8c8c5e1658{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=43319, RATIS=35969, RATIS_ADMIN=35969, RATIS_SERVER=35969, STANDALONE=37823], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [b1c11bf6-0210-4fae-ad64-f50b3eead4b6{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42459, RATIS=42099, RATIS_ADMIN=42099, RATIS_SERVER=42099, STANDALONE=41503], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 00879972-6a44-40a3-8061-2c26daaa092c{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=36567, RATIS=46343, RATIS_ADMIN=46343, RATIS_SERVER=46343, STANDALONE=42547], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-02-09 08:19:37,086 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1224)) - Container #6 is under replicated. Expected replica count is 3, but found 2.
2022-02-09 08:19:37,086 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:sendReplicateCommand(1578)) - Sending replicate container command for container #6 to datanode d446f06f-c919-4727-b846-3f8c8c5e1658{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=43319, RATIS=35969, RATIS_ADMIN=35969, RATIS_SERVER=35969, STANDALONE=37823], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [b1c11bf6-0210-4fae-ad64-f50b3eead4b6{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42459, RATIS=42099, RATIS_ADMIN=42099, RATIS_SERVER=42099, STANDALONE=41503], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 00879972-6a44-40a3-8061-2c26daaa092c{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=36567, RATIS=46343, RATIS_ADMIN=46343, RATIS_SERVER=46343, STANDALONE=42547], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-02-09 08:19:37,087 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 2 milliseconds for processing 6 containers.
2022-02-09 08:19:37,200 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-02-09 08:19:37,201 [grpc-default-executor-2] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(47)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4: nextIndex: updateUnconditionally 24 -> 23
2022-02-09 08:19:37,203 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-02-09 08:19:37,204 [grpc-default-executor-3] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(47)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4: nextIndex: updateUnconditionally 24 -> 23
2022-02-09 08:19:37,447 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=a3411903-4a88-4c3e-b106-a0306dfe1cc6 is not found
2022-02-09 08:19:37,516 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=a3411903-4a88-4c3e-b106-a0306dfe1cc6 is not found
2022-02-09 08:19:38,087 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-02-09 08:19:38,212 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-02-09 08:19:38,782 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(106)) - 00879972-6a44-40a3-8061-2c26daaa092c: remove    LEADER 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788:t3, leader=00879972-6a44-40a3-8061-2c26daaa092c, voted=00879972-6a44-40a3-8061-2c26daaa092c, raftlog=00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788-SegmentedRaftLog:OPENED:c29, conf=0: [b1c11bf6-0210-4fae-ad64-f50b3eead4b6|rpc:10.1.0.47:42099|dataStream:|priority:0, 00879972-6a44-40a3-8061-2c26daaa092c|rpc:10.1.0.47:46343|dataStream:|priority:1, a6c92f00-aadd-4833-aecb-8acb899822d4|rpc:10.1.0.47:37711|dataStream:|priority:0], old=null RUNNING
2022-02-09 08:19:38,782 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(412)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788: shutdown
2022-02-09 08:19:38,782 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-914DF9B16788,id=00879972-6a44-40a3-8061-2c26daaa092c
2022-02-09 08:19:38,782 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(91)) - 00879972-6a44-40a3-8061-2c26daaa092c: shutdown 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788-LeaderStateImpl
2022-02-09 08:19:38,782 [Command processor thread] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788-PendingRequests: sendNotLeaderResponses
2022-02-09 08:19:38,784 [00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(177)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->a6c92f00-aadd-4833-aecb-8acb899822d4-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2022-02-09 08:19:38,788 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(149)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788-StateMachineUpdater: set stopIndex = 29
2022-02-09 08:19:38,796 [00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->b1c11bf6-0210-4fae-ad64-f50b3eead4b6-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(177)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->b1c11bf6-0210-4fae-ad64-f50b3eead4b6-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2022-02-09 08:19:38,797 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=40f9fd32-189e-4aa5-9225-914df9b16788 is not found
2022-02-09 08:19:38,798 [00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(299)) - group-914DF9B16788: Taking a snapshot at:(t:3, i:29) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-4/data/ratis/40f9fd32-189e-4aa5-9225-914df9b16788/sm/snapshot.3_29
2022-02-09 08:19:38,800 [00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(310)) - group-914DF9B16788: Finished taking a snapshot at:(t:3, i:29) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-4/data/ratis/40f9fd32-189e-4aa5-9225-914df9b16788/sm/snapshot.3_29 took: 1 ms
2022-02-09 08:19:38,800 [00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(281)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788-StateMachineUpdater: Took a snapshot at index 29
2022-02-09 08:19:38,800 [00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(89)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 29
2022-02-09 08:19:38,801 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(140)) - b1c11bf6-0210-4fae-ad64-f50b3eead4b6: Completed APPEND_ENTRIES, lastRequest: 00879972-6a44-40a3-8061-2c26daaa092c->b1c11bf6-0210-4fae-ad64-f50b3eead4b6#486-t3,previous=(t:3, i:28),leaderCommit=28,initializing? true,entries: size=1, first=(t:3, i:29), METADATAENTRY(c:28)
2022-02-09 08:19:38,801 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(419)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788: closes. applyIndex: 29
2022-02-09 08:19:38,801 [00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(327)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-02-09 08:19:38,802 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(346)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->b1c11bf6-0210-4fae-ad64-f50b3eead4b6-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2022-02-09 08:19:38,802 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(47)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788->b1c11bf6-0210-4fae-ad64-f50b3eead4b6: nextIndex: updateUnconditionally 30 -> 29
2022-02-09 08:19:38,802 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(237)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788-SegmentedRaftLogWorker close()
2022-02-09 08:19:38,804 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(382)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-914DF9B16788: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-4/data/ratis/40f9fd32-189e-4aa5-9225-914df9b16788
2022-02-09 08:19:38,804 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=40f9fd32-189e-4aa5-9225-914df9b16788 command on datanode 00879972-6a44-40a3-8061-2c26daaa092c.
2022-02-09 08:19:39,088 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-02-09 08:19:39,444 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(106)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f: remove  FOLLOWER 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6:t1, leader=d6ad39fc-5f17-463f-9d0b-f520f0947e2d, voted=d6ad39fc-5f17-463f-9d0b-f520f0947e2d, raftlog=4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6-SegmentedRaftLog:OPENED:c0, conf=0: [d446f06f-c919-4727-b846-3f8c8c5e1658|rpc:10.1.0.47:35969|dataStream:|priority:0, 4b3568ef-ad3d-4964-ac82-76a8654b6a6f|rpc:10.1.0.47:43347|dataStream:|priority:0, d6ad39fc-5f17-463f-9d0b-f520f0947e2d|rpc:10.1.0.47:41167|dataStream:|priority:1], old=null RUNNING
2022-02-09 08:19:39,444 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(412)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6: shutdown
2022-02-09 08:19:39,444 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A0306DFE1CC6,id=4b3568ef-ad3d-4964-ac82-76a8654b6a6f
2022-02-09 08:19:39,444 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(108)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f: shutdown 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6-FollowerState
2022-02-09 08:19:39,444 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(149)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6-StateMachineUpdater: set stopIndex = 0
2022-02-09 08:19:39,445 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6-FollowerState was interrupted: {}
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at java.lang.Thread.sleep(Thread.java:340)
	at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
2022-02-09 08:19:39,445 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(299)) - group-A0306DFE1CC6: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-2/data/ratis/a3411903-4a88-4c3e-b106-a0306dfe1cc6/sm/snapshot.1_0
2022-02-09 08:19:39,453 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=a3411903-4a88-4c3e-b106-a0306dfe1cc6 is not found
2022-02-09 08:19:39,453 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(310)) - group-A0306DFE1CC6: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-2/data/ratis/a3411903-4a88-4c3e-b106-a0306dfe1cc6/sm/snapshot.1_0 took: 8 ms
2022-02-09 08:19:39,454 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(281)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6-StateMachineUpdater: Took a snapshot at index 0
2022-02-09 08:19:39,454 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(89)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-02-09 08:19:39,454 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(419)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6: closes. applyIndex: 0
2022-02-09 08:19:39,454 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(327)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-02-09 08:19:39,456 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(237)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6-SegmentedRaftLogWorker close()
2022-02-09 08:19:39,458 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(382)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-A0306DFE1CC6: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-2/data/ratis/a3411903-4a88-4c3e-b106-a0306dfe1cc6
2022-02-09 08:19:39,458 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=a3411903-4a88-4c3e-b106-a0306dfe1cc6 command on datanode 4b3568ef-ad3d-4964-ac82-76a8654b6a6f.
2022-02-09 08:19:39,515 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(106)) - d446f06f-c919-4727-b846-3f8c8c5e1658: remove  FOLLOWER d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6:t1, leader=d6ad39fc-5f17-463f-9d0b-f520f0947e2d, voted=d6ad39fc-5f17-463f-9d0b-f520f0947e2d, raftlog=d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6-SegmentedRaftLog:OPENED:c0, conf=0: [d446f06f-c919-4727-b846-3f8c8c5e1658|rpc:10.1.0.47:35969|dataStream:|priority:0, 4b3568ef-ad3d-4964-ac82-76a8654b6a6f|rpc:10.1.0.47:43347|dataStream:|priority:0, d6ad39fc-5f17-463f-9d0b-f520f0947e2d|rpc:10.1.0.47:41167|dataStream:|priority:1], old=null RUNNING
2022-02-09 08:19:39,515 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(412)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6: shutdown
2022-02-09 08:19:39,515 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A0306DFE1CC6,id=d446f06f-c919-4727-b846-3f8c8c5e1658
2022-02-09 08:19:39,515 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(108)) - d446f06f-c919-4727-b846-3f8c8c5e1658: shutdown d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6-FollowerState
2022-02-09 08:19:39,515 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(149)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6-StateMachineUpdater: set stopIndex = 0
2022-02-09 08:19:39,517 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6-FollowerState was interrupted: {}
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at java.lang.Thread.sleep(Thread.java:340)
	at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
2022-02-09 08:19:39,521 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(299)) - group-A0306DFE1CC6: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-0/data/ratis/a3411903-4a88-4c3e-b106-a0306dfe1cc6/sm/snapshot.1_0
2022-02-09 08:19:39,522 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(310)) - group-A0306DFE1CC6: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-0/data/ratis/a3411903-4a88-4c3e-b106-a0306dfe1cc6/sm/snapshot.1_0 took: 1 ms
2022-02-09 08:19:39,523 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(281)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6-StateMachineUpdater: Took a snapshot at index 0
2022-02-09 08:19:39,523 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(89)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-02-09 08:19:39,523 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(419)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6: closes. applyIndex: 0
2022-02-09 08:19:39,523 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(327)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-02-09 08:19:39,524 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(237)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6-SegmentedRaftLogWorker close()
2022-02-09 08:19:39,525 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(382)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-A0306DFE1CC6: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-0/data/ratis/a3411903-4a88-4c3e-b106-a0306dfe1cc6
2022-02-09 08:19:39,525 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=a3411903-4a88-4c3e-b106-a0306dfe1cc6 command on datanode d446f06f-c919-4727-b846-3f8c8c5e1658.
2022-02-09 08:19:39,529 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 4 from [b1c11bf6-0210-4fae-ad64-f50b3eead4b6{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42459, RATIS=42099, RATIS_ADMIN=42099, RATIS_SERVER=42099, STANDALONE=41503], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 00879972-6a44-40a3-8061-2c26daaa092c{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=36567, RATIS=46343, RATIS_ADMIN=46343, RATIS_SERVER=46343, STANDALONE=42547], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-02-09 08:19:39,532 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 5 from [b1c11bf6-0210-4fae-ad64-f50b3eead4b6{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42459, RATIS=42099, RATIS_ADMIN=42099, RATIS_SERVER=42099, STANDALONE=41503], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 00879972-6a44-40a3-8061-2c26daaa092c{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=36567, RATIS=46343, RATIS_ADMIN=46343, RATIS_SERVER=46343, STANDALONE=42547], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-02-09 08:19:39,534 [grpc-default-executor-2] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(52)) - Streaming container data (4) to other datanode
2022-02-09 08:19:39,543 [grpc-default-executor-2] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 18358 bytes for container 4
2022-02-09 08:19:39,558 [grpc-default-executor-3] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(197)) - Container 4 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-0/data/replication/work/container-4.tar.gz
2022-02-09 08:19:39,572 [grpc-default-executor-1] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(52)) - Streaming container data (5) to other datanode
2022-02-09 08:19:39,576 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 4 is downloaded with size 18358, starting to import.
2022-02-09 08:19:39,582 [ContainerReplicationThread-2] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 6 from [b1c11bf6-0210-4fae-ad64-f50b3eead4b6{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42459, RATIS=42099, RATIS_ADMIN=42099, RATIS_SERVER=42099, STANDALONE=41503], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 00879972-6a44-40a3-8061-2c26daaa092c{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=36567, RATIS=46343, RATIS_ADMIN=46343, RATIS_SERVER=46343, STANDALONE=42547], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-02-09 08:19:39,587 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=a3411903-4a88-4c3e-b106-a0306dfe1cc6 is not found
2022-02-09 08:19:39,589 [grpc-default-executor-2] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(52)) - Streaming container data (6) to other datanode
2022-02-09 08:19:39,632 [grpc-default-executor-1] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 18307 bytes for container 5
2022-02-09 08:19:39,635 [grpc-default-executor-1] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(197)) - Container 5 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-0/data/replication/work/container-5.tar.gz
2022-02-09 08:19:39,637 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 5 is downloaded with size 18307, starting to import.
2022-02-09 08:19:39,639 [grpc-default-executor-2] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 17986 bytes for container 6
2022-02-09 08:19:39,667 [grpc-default-executor-2] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(197)) - Container 6 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-0/data/replication/work/container-6.tar.gz
2022-02-09 08:19:39,677 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 4 is replicated successfully
2022-02-09 08:19:39,677 [ContainerReplicationThread-0] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(176)) - Container 4 is replicated.
2022-02-09 08:19:39,681 [ContainerReplicationThread-2] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 6 is downloaded with size 17986, starting to import.
2022-02-09 08:19:39,734 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 5 is replicated successfully
2022-02-09 08:19:39,734 [ContainerReplicationThread-1] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(176)) - Container 5 is replicated.
2022-02-09 08:19:39,773 [ContainerReplicationThread-2] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 6 is replicated successfully
2022-02-09 08:19:39,773 [ContainerReplicationThread-2] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(176)) - Container 6 is replicated.
2022-02-09 08:19:39,837 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode b1c11bf6-0210-4fae-ad64-f50b3eead4b6{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42459, RATIS=42099, RATIS_ADMIN=42099, RATIS_SERVER=42099, STANDALONE=41503], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=1420cafe-bde3-4bc0-bae8-1f41b68cdb6d]
2022-02-09 08:19:39,838 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(365)) - Pipeline Pipeline[ Id: 1420cafe-bde3-4bc0-bae8-1f41b68cdb6d, Nodes: b1c11bf6-0210-4fae-ad64-f50b3eead4b6{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42459, RATIS=42099, RATIS_ADMIN=42099, RATIS_SERVER=42099, STANDALONE=41503], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:b1c11bf6-0210-4fae-ad64-f50b3eead4b6, CreationTimestamp2022-02-09T08:18:36.585Z[Etc/UTC]] moved to CLOSED state
2022-02-09 08:19:40,089 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1224)) - Container #2 is under replicated. Expected replica count is 3, but found 2.
2022-02-09 08:19:40,089 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:sendReplicateCommand(1578)) - Sending replicate container command for container #2 to datanode d446f06f-c919-4727-b846-3f8c8c5e1658{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=43319, RATIS=35969, RATIS_ADMIN=35969, RATIS_SERVER=35969, STANDALONE=37823], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [00879972-6a44-40a3-8061-2c26daaa092c{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=36567, RATIS=46343, RATIS_ADMIN=46343, RATIS_SERVER=46343, STANDALONE=42547], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 4b3568ef-ad3d-4964-ac82-76a8654b6a6f{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=38721, RATIS=43347, RATIS_ADMIN=43347, RATIS_SERVER=43347, STANDALONE=44323], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-02-09 08:19:40,089 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-02-09 08:19:41,090 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-02-09 08:19:41,220 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(529)) - Ozone container server stopped.
2022-02-09 08:19:41,235 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@6d34d1e5{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-02-09 08:19:41,242 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@4deb4d3a{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-02-09 08:19:41,242 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-02-09 08:19:41,242 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@57b32307{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-02-09 08:19:41,242 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@744ae538{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-02-09 08:19:41,521 [ContainerReplicationThread-3] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 2 from [00879972-6a44-40a3-8061-2c26daaa092c{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=36567, RATIS=46343, RATIS_ADMIN=46343, RATIS_SERVER=46343, STANDALONE=42547], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 4b3568ef-ad3d-4964-ac82-76a8654b6a6f{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=38721, RATIS=43347, RATIS_ADMIN=43347, RATIS_SERVER=43347, STANDALONE=44323], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-02-09 08:19:41,527 [grpc-default-executor-2] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(52)) - Streaming container data (2) to other datanode
2022-02-09 08:19:41,595 [grpc-default-executor-2] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 18494 bytes for container 2
2022-02-09 08:19:41,596 [grpc-default-executor-3] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(197)) - Container 2 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-0/data/replication/work/container-2.tar.gz
2022-02-09 08:19:41,601 [ContainerReplicationThread-3] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 2 is downloaded with size 18494, starting to import.
2022-02-09 08:19:41,694 [ContainerReplicationThread-3] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 2 is replicated successfully
2022-02-09 08:19:41,694 [ContainerReplicationThread-3] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(176)) - Container 2 is replicated.
2022-02-09 08:19:41,794 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(336)) - Attempting to stop container services.
2022-02-09 08:19:41,794 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(391)) - b1c11bf6-0210-4fae-ad64-f50b3eead4b6: close
2022-02-09 08:19:41,795 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(412)) - b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-914DF9B16788: shutdown
2022-02-09 08:19:41,795 [Mini-Cluster-Provider-Reap] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-914DF9B16788,id=b1c11bf6-0210-4fae-ad64-f50b3eead4b6
2022-02-09 08:19:41,795 [Mini-Cluster-Provider-Reap] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(108)) - b1c11bf6-0210-4fae-ad64-f50b3eead4b6: shutdown b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-914DF9B16788-FollowerState
2022-02-09 08:19:41,795 [Mini-Cluster-Provider-Reap] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(149)) - b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-914DF9B16788-StateMachineUpdater: set stopIndex = 29
2022-02-09 08:19:41,795 [b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-914DF9B16788-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-914DF9B16788-FollowerState was interrupted: {}
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at java.lang.Thread.sleep(Thread.java:340)
	at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:324)
	at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:309)
	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:118)
2022-02-09 08:19:41,797 [b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-914DF9B16788-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(299)) - group-914DF9B16788: Taking a snapshot at:(t:3, i:29) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-5/data/ratis/40f9fd32-189e-4aa5-9225-914df9b16788/sm/snapshot.3_29
2022-02-09 08:19:41,798 [b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-914DF9B16788-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(310)) - group-914DF9B16788: Finished taking a snapshot at:(t:3, i:29) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-5/data/ratis/40f9fd32-189e-4aa5-9225-914df9b16788/sm/snapshot.3_29 took: 1 ms
2022-02-09 08:19:41,799 [b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-914DF9B16788-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(281)) - b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-914DF9B16788-StateMachineUpdater: Took a snapshot at index 29
2022-02-09 08:19:41,799 [b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-914DF9B16788-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(89)) - b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-914DF9B16788-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 29
2022-02-09 08:19:41,800 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (ServerState.java:close(419)) - b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-914DF9B16788: closes. applyIndex: 29
2022-02-09 08:19:41,800 [b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-914DF9B16788-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(327)) - b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-914DF9B16788-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-02-09 08:19:41,800 [Mini-Cluster-Provider-Reap] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(237)) - b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-914DF9B16788-SegmentedRaftLogWorker close()
2022-02-09 08:19:41,801 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(412)) - b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-1F41B68CDB6D: shutdown
2022-02-09 08:19:41,801 [Mini-Cluster-Provider-Reap] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-1F41B68CDB6D,id=b1c11bf6-0210-4fae-ad64-f50b3eead4b6
2022-02-09 08:19:41,801 [Mini-Cluster-Provider-Reap] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(91)) - b1c11bf6-0210-4fae-ad64-f50b3eead4b6: shutdown b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-1F41B68CDB6D-LeaderStateImpl
2022-02-09 08:19:41,801 [Mini-Cluster-Provider-Reap] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-1F41B68CDB6D-PendingRequests: sendNotLeaderResponses
2022-02-09 08:19:41,802 [Mini-Cluster-Provider-Reap] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(149)) - b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-1F41B68CDB6D-StateMachineUpdater: set stopIndex = 0
2022-02-09 08:19:41,802 [b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-1F41B68CDB6D-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(299)) - group-1F41B68CDB6D: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-5/data/ratis/1420cafe-bde3-4bc0-bae8-1f41b68cdb6d/sm/snapshot.1_0
2022-02-09 08:19:41,803 [b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-1F41B68CDB6D-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(310)) - group-1F41B68CDB6D: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-5/data/ratis/1420cafe-bde3-4bc0-bae8-1f41b68cdb6d/sm/snapshot.1_0 took: 1 ms
2022-02-09 08:19:41,804 [b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-1F41B68CDB6D-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(281)) - b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-1F41B68CDB6D-StateMachineUpdater: Took a snapshot at index 0
2022-02-09 08:19:41,804 [b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-1F41B68CDB6D-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(89)) - b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-1F41B68CDB6D-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-02-09 08:19:41,808 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (ServerState.java:close(419)) - b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-1F41B68CDB6D: closes. applyIndex: 0
2022-02-09 08:19:41,809 [b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-1F41B68CDB6D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(327)) - b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-1F41B68CDB6D-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-02-09 08:19:41,809 [Mini-Cluster-Provider-Reap] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(237)) - b1c11bf6-0210-4fae-ad64-f50b3eead4b6@group-1F41B68CDB6D-SegmentedRaftLogWorker close()
2022-02-09 08:19:41,809 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(262)) - b1c11bf6-0210-4fae-ad64-f50b3eead4b6: shutdown server with port 42099 now
2022-02-09 08:19:41,833 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - b1c11bf6-0210-4fae-ad64-f50b3eead4b6: shutdown server with port 42099 successfully
2022-02-09 08:19:41,834 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$541/997754283@14f780eb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-b1c11bf6-0210-4fae-ad64-f50b3eead4b6: Stopped
2022-02-09 08:19:42,091 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-02-09 08:19:42,752 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. b1c11bf6-0210-4fae-ad64-f50b3eead4b6{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42459, RATIS=42099, RATIS_ADMIN=42099, RATIS_SERVER=42099, STANDALONE=41503], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-02-09 08:19:42,753 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(222)) - Send pipeline:PipelineID=1420cafe-bde3-4bc0-bae8-1f41b68cdb6d close command to datanode b1c11bf6-0210-4fae-ad64-f50b3eead4b6
2022-02-09 08:19:42,753 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(223)) - Pipeline Pipeline[ Id: 1420cafe-bde3-4bc0-bae8-1f41b68cdb6d, Nodes: b1c11bf6-0210-4fae-ad64-f50b3eead4b6{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=42459, RATIS=42099, RATIS_ADMIN=42099, RATIS_SERVER=42099, STANDALONE=41503], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:b1c11bf6-0210-4fae-ad64-f50b3eead4b6, CreationTimestamp2022-02-09T08:18:36.585Z[Etc/UTC]] removed.
2022-02-09 08:19:42,753 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(137)) - Removed a node: /default-rack/b1c11bf6-0210-4fae-ad64-f50b3eead4b6
2022-02-09 08:19:43,092 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1224)) - Container #4 is under replicated. Expected replica count is 3, but found 2.
2022-02-09 08:19:43,092 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:sendReplicateCommand(1578)) - Sending replicate container command for container #4 to datanode 4b3568ef-ad3d-4964-ac82-76a8654b6a6f{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=38721, RATIS=43347, RATIS_ADMIN=43347, RATIS_SERVER=43347, STANDALONE=44323], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [d446f06f-c919-4727-b846-3f8c8c5e1658{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=43319, RATIS=35969, RATIS_ADMIN=35969, RATIS_SERVER=35969, STANDALONE=37823], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 00879972-6a44-40a3-8061-2c26daaa092c{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=36567, RATIS=46343, RATIS_ADMIN=46343, RATIS_SERVER=46343, STANDALONE=42547], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-02-09 08:19:43,093 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1224)) - Container #5 is under replicated. Expected replica count is 3, but found 2.
2022-02-09 08:19:43,093 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:sendReplicateCommand(1578)) - Sending replicate container command for container #5 to datanode 4b3568ef-ad3d-4964-ac82-76a8654b6a6f{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=38721, RATIS=43347, RATIS_ADMIN=43347, RATIS_SERVER=43347, STANDALONE=44323], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [d446f06f-c919-4727-b846-3f8c8c5e1658{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=43319, RATIS=35969, RATIS_ADMIN=35969, RATIS_SERVER=35969, STANDALONE=37823], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 00879972-6a44-40a3-8061-2c26daaa092c{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=36567, RATIS=46343, RATIS_ADMIN=46343, RATIS_SERVER=46343, STANDALONE=42547], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-02-09 08:19:43,093 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1224)) - Container #6 is under replicated. Expected replica count is 3, but found 2.
2022-02-09 08:19:43,093 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:sendReplicateCommand(1578)) - Sending replicate container command for container #6 to datanode 4b3568ef-ad3d-4964-ac82-76a8654b6a6f{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=38721, RATIS=43347, RATIS_ADMIN=43347, RATIS_SERVER=43347, STANDALONE=44323], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [d446f06f-c919-4727-b846-3f8c8c5e1658{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=43319, RATIS=35969, RATIS_ADMIN=35969, RATIS_SERVER=35969, STANDALONE=37823], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 00879972-6a44-40a3-8061-2c26daaa092c{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=36567, RATIS=46343, RATIS_ADMIN=46343, RATIS_SERVER=46343, STANDALONE=42547], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-02-09 08:19:43,093 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 2 milliseconds for processing 6 containers.
2022-02-09 08:19:43,454 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode 4b3568ef-ad3d-4964-ac82-76a8654b6a6f{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=38721, RATIS=43347, RATIS_ADMIN=43347, RATIS_SERVER=43347, STANDALONE=44323], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=f2fc3af5-81c0-4f09-8979-d94a0698663a]
2022-02-09 08:19:43,455 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(365)) - Pipeline Pipeline[ Id: f2fc3af5-81c0-4f09-8979-d94a0698663a, Nodes: 4b3568ef-ad3d-4964-ac82-76a8654b6a6f{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=38721, RATIS=43347, RATIS_ADMIN=43347, RATIS_SERVER=43347, STANDALONE=44323], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:4b3568ef-ad3d-4964-ac82-76a8654b6a6f, CreationTimestamp2022-02-09T08:19:15.804Z[Etc/UTC]] moved to CLOSED state
2022-02-09 08:19:43,862 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-02-09 08:19:44,094 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:44,094 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 4.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:44,094 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:44,095 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 5.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:44,095 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:44,095 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 6.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:44,095 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 2 milliseconds for processing 6 containers.
2022-02-09 08:19:45,095 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:45,095 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 4.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:45,096 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:45,096 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 5.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:45,096 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:45,096 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 6.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:45,096 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-02-09 08:19:46,097 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:46,097 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 4.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:46,097 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:46,097 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 5.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:46,098 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:46,098 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 6.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:46,098 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 2 milliseconds for processing 6 containers.
2022-02-09 08:19:46,246 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(336)) - Attempting to stop container services.
2022-02-09 08:19:46,247 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(391)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f: close
2022-02-09 08:19:46,247 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(412)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A: shutdown
2022-02-09 08:19:46,247 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D94A0698663A,id=4b3568ef-ad3d-4964-ac82-76a8654b6a6f
2022-02-09 08:19:46,247 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(91)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f: shutdown 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-LeaderStateImpl
2022-02-09 08:19:46,247 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-PendingRequests: sendNotLeaderResponses
2022-02-09 08:19:46,248 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(149)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-StateMachineUpdater: set stopIndex = 0
2022-02-09 08:19:46,248 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(299)) - group-D94A0698663A: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-2/data/ratis/f2fc3af5-81c0-4f09-8979-d94a0698663a/sm/snapshot.1_0
2022-02-09 08:19:46,250 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(310)) - group-D94A0698663A: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-2/data/ratis/f2fc3af5-81c0-4f09-8979-d94a0698663a/sm/snapshot.1_0 took: 2 ms
2022-02-09 08:19:46,250 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(281)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-StateMachineUpdater: Took a snapshot at index 0
2022-02-09 08:19:46,250 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(89)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-02-09 08:19:46,250 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer$Division (ServerState.java:close(419)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A: closes. applyIndex: 0
2022-02-09 08:19:46,250 [4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(327)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-02-09 08:19:46,251 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(237)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f@group-D94A0698663A-SegmentedRaftLogWorker close()
2022-02-09 08:19:46,262 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(262)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f: shutdown server with port 43347 now
2022-02-09 08:19:46,264 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 4b3568ef-ad3d-4964-ac82-76a8654b6a6f: shutdown server with port 43347 successfully
2022-02-09 08:19:46,264 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$541/997754283@17d03eb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-4b3568ef-ad3d-4964-ac82-76a8654b6a6f: Stopped
2022-02-09 08:19:46,463 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. 4b3568ef-ad3d-4964-ac82-76a8654b6a6f{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=38721, RATIS=43347, RATIS_ADMIN=43347, RATIS_SERVER=43347, STANDALONE=44323], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-02-09 08:19:46,464 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(222)) - Send pipeline:PipelineID=f2fc3af5-81c0-4f09-8979-d94a0698663a close command to datanode 4b3568ef-ad3d-4964-ac82-76a8654b6a6f
2022-02-09 08:19:46,464 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(223)) - Pipeline Pipeline[ Id: f2fc3af5-81c0-4f09-8979-d94a0698663a, Nodes: 4b3568ef-ad3d-4964-ac82-76a8654b6a6f{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=38721, RATIS=43347, RATIS_ADMIN=43347, RATIS_SERVER=43347, STANDALONE=44323], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:4b3568ef-ad3d-4964-ac82-76a8654b6a6f, CreationTimestamp2022-02-09T08:19:15.804Z[Etc/UTC]] removed.
2022-02-09 08:19:46,464 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(137)) - Removed a node: /default-rack/4b3568ef-ad3d-4964-ac82-76a8654b6a6f
2022-02-09 08:19:46,879 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(529)) - Ozone container server stopped.
2022-02-09 08:19:46,882 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@1ef4ff14{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-02-09 08:19:46,887 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@3c1cf2a{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-02-09 08:19:46,887 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-02-09 08:19:46,887 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@1357d0c3{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-02-09 08:19:46,887 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@5795b367{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-02-09 08:19:47,098 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:47,098 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:47,099 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:47,099 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:47,099 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:47,099 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:47,099 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:47,099 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 4.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:47,100 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:47,100 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 5.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:47,100 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:47,100 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 6.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:47,100 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 2 milliseconds for processing 6 containers.
2022-02-09 08:19:48,101 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:48,101 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:48,101 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:48,101 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:48,101 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:48,101 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:48,102 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:48,102 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 4.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:48,102 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:48,102 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 5.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:48,102 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:48,102 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 6.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:48,102 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 2 milliseconds for processing 6 containers.
2022-02-09 08:19:48,293 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-02-09 08:19:49,103 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:49,103 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:49,103 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:49,103 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:49,103 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:49,103 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:49,104 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:49,104 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 4.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:49,104 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:49,104 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 5.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:49,104 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:49,104 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 6.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:49,104 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 2 milliseconds for processing 6 containers.
2022-02-09 08:19:49,873 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode 00879972-6a44-40a3-8061-2c26daaa092c{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=36567, RATIS=46343, RATIS_ADMIN=46343, RATIS_SERVER=46343, STANDALONE=42547], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=6c769f3f-08d1-4725-84d7-c0609b63db32]
2022-02-09 08:19:49,873 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(365)) - Pipeline Pipeline[ Id: 6c769f3f-08d1-4725-84d7-c0609b63db32, Nodes: 00879972-6a44-40a3-8061-2c26daaa092c{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=36567, RATIS=46343, RATIS_ADMIN=46343, RATIS_SERVER=46343, STANDALONE=42547], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:00879972-6a44-40a3-8061-2c26daaa092c, CreationTimestamp2022-02-09T08:18:35.915Z[Etc/UTC]] moved to CLOSED state
2022-02-09 08:19:50,105 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:50,105 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:50,105 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:50,105 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:50,106 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:50,106 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:50,106 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:50,106 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 4.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:50,106 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:50,106 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 5.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:50,106 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:50,106 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 6.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:50,106 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 2 milliseconds for processing 6 containers.
2022-02-09 08:19:51,108 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:51,108 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:51,108 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:51,108 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:51,111 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:51,111 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:51,111 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:51,111 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 4.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:51,111 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:51,111 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 5.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:51,111 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:51,112 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 6.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:51,128 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 21 milliseconds for processing 6 containers.
2022-02-09 08:19:51,302 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(529)) - Ozone container server stopped.
2022-02-09 08:19:51,305 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@5c15465f{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-02-09 08:19:51,313 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@7a2d2bde{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-02-09 08:19:51,313 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-02-09 08:19:51,313 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@45d24647{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-02-09 08:19:51,313 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@67ba5d32{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-02-09 08:19:51,899 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(336)) - Attempting to stop container services.
2022-02-09 08:19:51,920 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(391)) - 00879972-6a44-40a3-8061-2c26daaa092c: close
2022-02-09 08:19:51,920 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(412)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-C0609B63DB32: shutdown
2022-02-09 08:19:51,921 [Mini-Cluster-Provider-Reap] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C0609B63DB32,id=00879972-6a44-40a3-8061-2c26daaa092c
2022-02-09 08:19:51,921 [Mini-Cluster-Provider-Reap] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(91)) - 00879972-6a44-40a3-8061-2c26daaa092c: shutdown 00879972-6a44-40a3-8061-2c26daaa092c@group-C0609B63DB32-LeaderStateImpl
2022-02-09 08:19:51,921 [Mini-Cluster-Provider-Reap] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-C0609B63DB32-PendingRequests: sendNotLeaderResponses
2022-02-09 08:19:51,922 [Mini-Cluster-Provider-Reap] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(149)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-C0609B63DB32-StateMachineUpdater: set stopIndex = 0
2022-02-09 08:19:51,922 [00879972-6a44-40a3-8061-2c26daaa092c@group-C0609B63DB32-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(299)) - group-C0609B63DB32: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-4/data/ratis/6c769f3f-08d1-4725-84d7-c0609b63db32/sm/snapshot.1_0
2022-02-09 08:19:51,924 [00879972-6a44-40a3-8061-2c26daaa092c@group-C0609B63DB32-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(310)) - group-C0609B63DB32: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-4/data/ratis/6c769f3f-08d1-4725-84d7-c0609b63db32/sm/snapshot.1_0 took: 2 ms
2022-02-09 08:19:51,925 [00879972-6a44-40a3-8061-2c26daaa092c@group-C0609B63DB32-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(281)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-C0609B63DB32-StateMachineUpdater: Took a snapshot at index 0
2022-02-09 08:19:51,925 [00879972-6a44-40a3-8061-2c26daaa092c@group-C0609B63DB32-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(89)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-C0609B63DB32-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-02-09 08:19:51,925 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (ServerState.java:close(419)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-C0609B63DB32: closes. applyIndex: 0
2022-02-09 08:19:51,925 [00879972-6a44-40a3-8061-2c26daaa092c@group-C0609B63DB32-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(327)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-C0609B63DB32-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-02-09 08:19:51,925 [Mini-Cluster-Provider-Reap] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(237)) - 00879972-6a44-40a3-8061-2c26daaa092c@group-C0609B63DB32-SegmentedRaftLogWorker close()
2022-02-09 08:19:51,926 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(262)) - 00879972-6a44-40a3-8061-2c26daaa092c: shutdown server with port 46343 now
2022-02-09 08:19:51,928 [grpc-default-executor-2] WARN  client.GrpcClientProtocolService (LogUtils.java:warn(122)) - 1-UnorderedRequestStreamObserver1: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2022-02-09 08:19:51,950 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 00879972-6a44-40a3-8061-2c26daaa092c: shutdown server with port 46343 successfully
2022-02-09 08:19:51,950 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$541/997754283@147664d5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-00879972-6a44-40a3-8061-2c26daaa092c: Stopped
2022-02-09 08:19:52,129 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:52,129 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:52,129 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:52,129 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:52,130 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:52,130 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:52,130 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:52,130 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 4.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:52,130 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:52,130 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 5.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:52,131 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:52,131 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 6.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:52,131 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 3 milliseconds for processing 6 containers.
2022-02-09 08:19:52,885 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. 00879972-6a44-40a3-8061-2c26daaa092c{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=36567, RATIS=46343, RATIS_ADMIN=46343, RATIS_SERVER=46343, STANDALONE=42547], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-02-09 08:19:52,885 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(222)) - Send pipeline:PipelineID=6c769f3f-08d1-4725-84d7-c0609b63db32 close command to datanode 00879972-6a44-40a3-8061-2c26daaa092c
2022-02-09 08:19:52,885 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(223)) - Pipeline Pipeline[ Id: 6c769f3f-08d1-4725-84d7-c0609b63db32, Nodes: 00879972-6a44-40a3-8061-2c26daaa092c{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=36567, RATIS=46343, RATIS_ADMIN=46343, RATIS_SERVER=46343, STANDALONE=42547], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:00879972-6a44-40a3-8061-2c26daaa092c, CreationTimestamp2022-02-09T08:18:35.915Z[Etc/UTC]] removed.
2022-02-09 08:19:52,886 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(137)) - Removed a node: /default-rack/00879972-6a44-40a3-8061-2c26daaa092c
2022-02-09 08:19:53,131 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:53,131 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:53,132 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:53,132 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:53,132 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:53,132 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:53,132 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:53,132 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 4.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:53,132 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:53,133 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 5.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:53,133 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(140)) - No healthy node found to allocate container.
2022-02-09 08:19:53,133 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1257)) - Exception while replicating container 6.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:141)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.handleUnderReplicatedContainer(ReplicationManager.java:1221)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processContainer(ReplicationManager.java:559)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.processAll(ReplicationManager.java:383)
	at org.apache.hadoop.hdds.scm.container.ReplicationManager.run(ReplicationManager.java:403)
	at java.lang.Thread.run(Thread.java:748)
2022-02-09 08:19:53,133 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 2 milliseconds for processing 6 containers.
2022-02-09 08:19:53,788 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode d446f06f-c919-4727-b846-3f8c8c5e1658{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=43319, RATIS=35969, RATIS_ADMIN=35969, RATIS_SERVER=35969, STANDALONE=37823], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=531ec647-fe59-4e6d-b079-e7473ffe323d]
2022-02-09 08:19:53,789 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(365)) - Pipeline Pipeline[ Id: 531ec647-fe59-4e6d-b079-e7473ffe323d, Nodes: d446f06f-c919-4727-b846-3f8c8c5e1658{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=43319, RATIS=35969, RATIS_ADMIN=35969, RATIS_SERVER=35969, STANDALONE=37823], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:d446f06f-c919-4727-b846-3f8c8c5e1658, CreationTimestamp2022-02-09T08:19:15.793Z[Etc/UTC]] moved to CLOSED state
2022-02-09 08:19:53,980 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-02-09 08:19:54,136 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #1, no healthy replica found.
2022-02-09 08:19:54,136 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #2, no healthy replica found.
2022-02-09 08:19:54,136 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #3, no healthy replica found.
2022-02-09 08:19:54,136 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #4, no healthy replica found.
2022-02-09 08:19:54,136 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #5, no healthy replica found.
2022-02-09 08:19:54,136 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #6, no healthy replica found.
2022-02-09 08:19:54,136 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-02-09 08:19:55,138 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #1, no healthy replica found.
2022-02-09 08:19:55,138 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #2, no healthy replica found.
2022-02-09 08:19:55,138 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #3, no healthy replica found.
2022-02-09 08:19:55,138 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #4, no healthy replica found.
2022-02-09 08:19:55,138 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #5, no healthy replica found.
2022-02-09 08:19:55,138 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #6, no healthy replica found.
2022-02-09 08:19:55,138 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-02-09 08:19:56,139 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #1, no healthy replica found.
2022-02-09 08:19:56,139 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #2, no healthy replica found.
2022-02-09 08:19:56,139 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #3, no healthy replica found.
2022-02-09 08:19:56,139 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #4, no healthy replica found.
2022-02-09 08:19:56,139 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #5, no healthy replica found.
2022-02-09 08:19:56,139 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #6, no healthy replica found.
2022-02-09 08:19:56,140 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-02-09 08:19:56,318 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(336)) - Attempting to stop container services.
2022-02-09 08:19:56,323 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(391)) - d446f06f-c919-4727-b846-3f8c8c5e1658: close
2022-02-09 08:19:56,323 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(412)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D: shutdown
2022-02-09 08:19:56,323 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-E7473FFE323D,id=d446f06f-c919-4727-b846-3f8c8c5e1658
2022-02-09 08:19:56,323 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(91)) - d446f06f-c919-4727-b846-3f8c8c5e1658: shutdown d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-LeaderStateImpl
2022-02-09 08:19:56,323 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-PendingRequests: sendNotLeaderResponses
2022-02-09 08:19:56,324 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(149)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-StateMachineUpdater: set stopIndex = 0
2022-02-09 08:19:56,324 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(299)) - group-E7473FFE323D: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-0/data/ratis/531ec647-fe59-4e6d-b079-e7473ffe323d/sm/snapshot.1_0
2022-02-09 08:19:56,330 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(310)) - group-E7473FFE323D: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a1043cae-421d-42a3-a303-ace104c64326/datanode-0/data/ratis/531ec647-fe59-4e6d-b079-e7473ffe323d/sm/snapshot.1_0 took: 6 ms
2022-02-09 08:19:56,330 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(281)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-StateMachineUpdater: Took a snapshot at index 0
2022-02-09 08:19:56,330 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(89)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-02-09 08:19:56,330 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer$Division (ServerState.java:close(419)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D: closes. applyIndex: 0
2022-02-09 08:19:56,331 [d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(327)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-02-09 08:19:56,332 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(237)) - d446f06f-c919-4727-b846-3f8c8c5e1658@group-E7473FFE323D-SegmentedRaftLogWorker close()
2022-02-09 08:19:56,341 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(262)) - d446f06f-c919-4727-b846-3f8c8c5e1658: shutdown server with port 35969 now
2022-02-09 08:19:56,353 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - d446f06f-c919-4727-b846-3f8c8c5e1658: shutdown server with port 35969 successfully
2022-02-09 08:19:56,353 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$541/997754283@2b2c40c9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-d446f06f-c919-4727-b846-3f8c8c5e1658: Stopped
2022-02-09 08:19:56,799 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. d446f06f-c919-4727-b846-3f8c8c5e1658{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=43319, RATIS=35969, RATIS_ADMIN=35969, RATIS_SERVER=35969, STANDALONE=37823], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-02-09 08:19:56,799 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(222)) - Send pipeline:PipelineID=531ec647-fe59-4e6d-b079-e7473ffe323d close command to datanode d446f06f-c919-4727-b846-3f8c8c5e1658
2022-02-09 08:19:56,799 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(223)) - Pipeline Pipeline[ Id: 531ec647-fe59-4e6d-b079-e7473ffe323d, Nodes: d446f06f-c919-4727-b846-3f8c8c5e1658{ip: 10.1.0.47, host: fv-az270-916.tacnzluakwdehk1hpragurqkma.bx.internal.cloudapp.net, ports: [REPLICATION=43319, RATIS=35969, RATIS_ADMIN=35969, RATIS_SERVER=35969, STANDALONE=37823], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:d446f06f-c919-4727-b846-3f8c8c5e1658, CreationTimestamp2022-02-09T08:19:15.793Z[Etc/UTC]] removed.
2022-02-09 08:19:56,800 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(137)) - Removed a node: /default-rack/d446f06f-c919-4727-b846-3f8c8c5e1658
2022-02-09 08:19:57,006 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(529)) - Ozone container server stopped.
2022-02-09 08:19:57,009 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@1f7b2139{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-02-09 08:19:57,009 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@3b1dc9d2{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-02-09 08:19:57,009 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-02-09 08:19:57,009 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@d8be824{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-02-09 08:19:57,010 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@6ab3b5ae{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-02-09 08:19:57,140 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #1, no healthy replica found.
2022-02-09 08:19:57,140 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #2, no healthy replica found.
2022-02-09 08:19:57,140 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #3, no healthy replica found.
2022-02-09 08:19:57,140 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #4, no healthy replica found.
2022-02-09 08:19:57,140 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #5, no healthy replica found.
2022-02-09 08:19:57,140 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #6, no healthy replica found.
2022-02-09 08:19:57,140 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-02-09 08:19:58,141 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #1, no healthy replica found.
2022-02-09 08:19:58,141 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #2, no healthy replica found.
2022-02-09 08:19:58,141 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #3, no healthy replica found.
2022-02-09 08:19:58,141 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #4, no healthy replica found.
2022-02-09 08:19:58,141 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #5, no healthy replica found.
2022-02-09 08:19:58,141 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #6, no healthy replica found.
2022-02-09 08:19:58,141 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-02-09 08:19:58,373 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-02-09 08:19:59,142 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #1, no healthy replica found.
2022-02-09 08:19:59,142 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #2, no healthy replica found.
2022-02-09 08:19:59,143 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #3, no healthy replica found.
2022-02-09 08:19:59,143 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #4, no healthy replica found.
2022-02-09 08:19:59,143 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #5, no healthy replica found.
2022-02-09 08:19:59,143 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #6, no healthy replica found.
2022-02-09 08:19:59,143 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-02-09 08:20:00,145 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #1, no healthy replica found.
2022-02-09 08:20:00,145 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #2, no healthy replica found.
2022-02-09 08:20:00,145 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #3, no healthy replica found.
2022-02-09 08:20:00,145 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #4, no healthy replica found.
2022-02-09 08:20:00,145 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #5, no healthy replica found.
2022-02-09 08:20:00,145 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #6, no healthy replica found.
2022-02-09 08:20:00,145 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-02-09 08:20:01,145 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #1, no healthy replica found.
2022-02-09 08:20:01,146 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #2, no healthy replica found.
2022-02-09 08:20:01,146 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #3, no healthy replica found.
2022-02-09 08:20:01,146 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #4, no healthy replica found.
2022-02-09 08:20:01,146 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #5, no healthy replica found.
2022-02-09 08:20:01,146 [ReplicationMonitor] WARN  container.ReplicationManager (ReplicationManager.java:handleUnderReplicatedContainer(1253)) - Cannot replicate container #6, no healthy replica found.
2022-02-09 08:20:01,146 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:processAll(387)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-02-09 08:20:01,395 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(529)) - Ozone container server stopped.
2022-02-09 08:20:01,409 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@1ad53a51{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-02-09 08:20:01,418 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@1e3939ef{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-02-09 08:20:01,418 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-02-09 08:20:01,418 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@75d465f3{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-02-09 08:20:01,418 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@3c4a37ea{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-02-09 08:20:01,420 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(526)) - Stopping the StorageContainerManager
2022-02-09 08:20:01,420 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1390)) - Stopping Container Balancer service.
2022-02-09 08:20:01,420 [Mini-Cluster-Provider-Reap] INFO  balancer.ContainerBalancer (ContainerBalancer.java:stop(751)) - Container Balancer is not running.
2022-02-09 08:20:01,420 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1397)) - Stopping Replication Manager Service.
2022-02-09 08:20:01,420 [Mini-Cluster-Provider-Reap] INFO  container.ReplicationManager (ReplicationManager.java:stop(357)) - Stopping Replication Monitor Thread.
2022-02-09 08:20:01,420 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1404)) - Stopping the Datanode Admin Monitor.
2022-02-09 08:20:01,420 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1411)) - Stopping Lease Manager of the command watchers
2022-02-09 08:20:01,420 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1418)) - Stopping datanode service RPC server
2022-02-09 08:20:01,420 [Mini-Cluster-Provider-Reap] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(390)) - Stopping the RPC server for DataNodes
2022-02-09 08:20:01,425 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3414)) - Stopping server on 41269
2022-02-09 08:20:01,428 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - Stopping IPC Server Responder
2022-02-09 08:20:01,428 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1376)) - Stopping IPC Server listener on 0
2022-02-09 08:20:01,455 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(799)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2022-02-09 08:20:01,455 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1426)) - Stopping block service RPC server
2022-02-09 08:20:01,456 [Mini-Cluster-Provider-Reap] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(160)) - Stopping the RPC server for Block Protocol
2022-02-09 08:20:01,456 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3414)) - Stopping server on 42729
2022-02-09 08:20:01,494 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1433)) - Stopping the StorageContainerLocationProtocol RPC server
2022-02-09 08:20:01,495 [Mini-Cluster-Provider-Reap] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(174)) - Stopping the RPC server for Client Protocol
2022-02-09 08:20:01,495 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1376)) - Stopping IPC Server listener on 0
2022-02-09 08:20:01,495 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - Stopping IPC Server Responder
2022-02-09 08:20:01,495 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3414)) - Stopping server on 35765
2022-02-09 08:20:01,499 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1440)) - Stopping Storage Container Manager HTTP server.
2022-02-09 08:20:01,499 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - Stopping IPC Server Responder
2022-02-09 08:20:01,511 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@79a6d1d3{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2022-02-09 08:20:01,522 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@6c3223e4{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-02-09 08:20:01,523 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-02-09 08:20:01,523 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@6df53d3a{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2022-02-09 08:20:01,523 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@7575b8b4{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-02-09 08:20:01,527 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1451)) - Stopping Block Manager Service.
2022-02-09 08:20:01,527 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service SCMBlockDeletingService
2022-02-09 08:20:01,528 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service SCMBlockDeletingService
2022-02-09 08:20:01,528 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1478)) - Stopping SCM Event Queue.
2022-02-09 08:20:01,533 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1376)) - Stopping IPC Server listener on 0
2022-02-09 08:20:01,548 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1489)) - Stopping SCM HA services.
2022-02-09 08:20:01,548 [Mini-Cluster-Provider-Reap] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(158)) - Stopping RatisPipelineUtilsThread.
2022-02-09 08:20:01,548 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1499)) - Stopping SCM MetadataStore.
2022-02-09 08:20:01,549 [Mini-Cluster-Provider-Reap] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(205)) - HddsDatanode metrics system stopped (again)
]]></system-out>
  </testcase>
  <testcase name="testSingleNodeWithOpenPipelineCanGotoMaintenance" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="100.002">
    <error message="Failed to obtain available cluster in time" type="java.io.IOException">java.io.IOException: Failed to obtain available cluster in time
	at org.apache.hadoop.ozone.MiniOzoneClusterProvider.provide(MiniOzoneClusterProvider.java:162)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.setUp(TestDecommissionAndMaintenance.java:142)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:108)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:96)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:75)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:142)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:113)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
</error>
  </testcase>
  <testcase name="testSCMHandlesRestartForMaintenanceNode" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="100.004">
    <error message="Failed to obtain available cluster in time" type="java.io.IOException">java.io.IOException: Failed to obtain available cluster in time
	at org.apache.hadoop.ozone.MiniOzoneClusterProvider.provide(MiniOzoneClusterProvider.java:162)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.setUp(TestDecommissionAndMaintenance.java:142)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:108)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:96)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:75)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:142)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:113)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
</error>
  </testcase>
  <testcase name="testStoppedDecommissionedNodeTakesSCMStateOnRestart" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="99.999">
    <error message="Failed to obtain available cluster in time" type="java.io.IOException">java.io.IOException: Failed to obtain available cluster in time
	at org.apache.hadoop.ozone.MiniOzoneClusterProvider.provide(MiniOzoneClusterProvider.java:162)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.setUp(TestDecommissionAndMaintenance.java:142)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:108)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:96)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:75)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:142)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:113)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
</error>
  </testcase>
  <testcase name="testEnteringMaintenanceNodeCompletesAfterSCMRestart" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="100.006">
    <error message="Failed to obtain available cluster in time" type="java.io.IOException">java.io.IOException: Failed to obtain available cluster in time
	at org.apache.hadoop.ozone.MiniOzoneClusterProvider.provide(MiniOzoneClusterProvider.java:162)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.setUp(TestDecommissionAndMaintenance.java:142)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:108)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:96)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:75)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:142)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:113)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
</error>
  </testcase>
  <testcase name="testDecommissioningNodesCompleteDecommissionOnSCMRestart" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="99.996">
    <error message="Failed to obtain available cluster in time" type="java.io.IOException">java.io.IOException: Failed to obtain available cluster in time
	at org.apache.hadoop.ozone.MiniOzoneClusterProvider.provide(MiniOzoneClusterProvider.java:162)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.setUp(TestDecommissionAndMaintenance.java:142)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:108)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:96)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:75)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:142)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:113)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
</error>
  </testcase>
</testsuite>