Attaching to ha_s3g_1, ha_dn1_1, ha_dn2_1, ha_dn3_1, ha_dn5_1, ha_dn4_1, ha_om3_1, ha_om1_1, ha_om2_1, ha_recon_1, ha_scm_1
dn1_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
dn1_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
dn1_1    | 2022-06-16 01:13:42,763 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
dn1_1    | /************************************************************
dn1_1    | STARTUP_MSG: Starting HddsDatanodeService
dn1_1    | STARTUP_MSG:   host = 9b513447a933/10.9.0.15
dn1_1    | STARTUP_MSG:   args = []
dn1_1    | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
dn1_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/gson-2.8.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
dn1_1    | STARTUP_MSG:   build = https://github.com/apache/ozone/17d3301a908af2df7683a0c61b8ee3ae8dd41d6a ; compiled by 'runner' on 2022-06-16T00:51Z
dn1_1    | STARTUP_MSG:   java = 11.0.14.1
dn1_1    | ************************************************************/
dn1_1    | 2022-06-16 01:13:42,804 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
dn1_1    | 2022-06-16 01:13:43,344 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
dn1_1    | 2022-06-16 01:13:44,082 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
dn1_1    | 2022-06-16 01:13:45,442 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
dn1_1    | 2022-06-16 01:13:45,442 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
dn1_1    | 2022-06-16 01:13:47,259 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:9b513447a933 ip:10.9.0.15
dn1_1    | 2022-06-16 01:13:49,161 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = DATANODE_SCHEMA_V3 (version = 4)
dn1_1    | 2022-06-16 01:13:50,839 [main] INFO reflections.Reflections: Reflections took 1405 ms to scan 2 urls, producing 89 keys and 191 values 
dn1_1    | 2022-06-16 01:13:51,300 [main] INFO upgrade.HDDSLayoutVersionManager: Registering Upgrade Action : DatanodeSchemaV3FinalizeAction
dn1_1    | 2022-06-16 01:13:51,526 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
dn1_1    | 2022-06-16 01:13:52,887 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/hdds/scmUsed: 4096 at 2022-06-16T01:13:17.110Z
dn1_1    | 2022-06-16 01:13:53,022 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
dn1_1    | 2022-06-16 01:13:53,029 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
dn1_1    | 2022-06-16 01:13:53,034 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
dn1_1    | 2022-06-16 01:13:53,255 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
dn1_1    | 2022-06-16 01:13:53,494 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn1_1    | 2022-06-16 01:13:53,532 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/metadata/ratis/scmUsed: 4096 at 2022-06-16T01:13:17.107Z
dn1_1    | 2022-06-16 01:13:53,551 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
dn1_1    | 2022-06-16 01:13:53,566 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
dn1_1    | 2022-06-16 01:13:53,597 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
dn1_1    | 2022-06-16 01:13:53,723 [Thread-3] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
dn1_1    | 2022-06-16 01:13:55,625 [Thread-3] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
dn1_1    | 2022-06-16 01:13:55,637 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 1s
dn1_1    | 2022-06-16 01:14:06,185 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
dn1_1    | 2022-06-16 01:14:06,630 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn1_1    | 2022-06-16 01:14:07,083 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
dn1_1    | 2022-06-16 01:14:08,076 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
dn1_1    | 2022-06-16 01:14:08,088 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
dn1_1    | 2022-06-16 01:14:08,088 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
dn1_1    | 2022-06-16 01:14:08,099 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
dn1_1    | 2022-06-16 01:14:08,100 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2022-06-16 01:14:08,101 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
dn1_1    | 2022-06-16 01:14:08,105 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn1_1    | 2022-06-16 01:14:08,249 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
dn1_1    | 2022-06-16 01:14:08,254 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
dn1_1    | 2022-06-16 01:14:10,939 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
dn1_1    | 2022-06-16 01:14:10,964 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
dn1_1    | 2022-06-16 01:14:10,964 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
dn1_1    | 2022-06-16 01:14:10,965 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn1_1    | 2022-06-16 01:14:10,965 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn1_1    | 2022-06-16 01:14:11,040 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn1_1    | 2022-06-16 01:14:11,075 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6-impl-thread1] INFO server.RaftServer: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: found a subdirectory /data/metadata/ratis/ae07a9fd-bfc0-4f3c-b02e-a4b953253c7c
dn1_1    | 2022-06-16 01:14:11,167 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6-impl-thread1] INFO server.RaftServer: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: addNew group-A4B953253C7C:[] returns group-A4B953253C7C:java.util.concurrent.CompletableFuture@5122a779[Not completed]
dn1_1    | 2022-06-16 01:14:11,170 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6-impl-thread1] INFO server.RaftServer: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: found a subdirectory /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de
dn1_1    | 2022-06-16 01:14:11,188 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6-impl-thread1] INFO server.RaftServer: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: addNew group-5FC878C6C2DE:[] returns group-5FC878C6C2DE:java.util.concurrent.CompletableFuture@4d115a39[Not completed]
dn1_1    | 2022-06-16 01:14:11,205 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6-impl-thread1] INFO server.RaftServer: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: found a subdirectory /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399
dn1_1    | 2022-06-16 01:14:11,205 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6-impl-thread1] INFO server.RaftServer: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: addNew group-8C8526B83399:[] returns group-8C8526B83399:java.util.concurrent.CompletableFuture@1e4be848[Not completed]
dn1_1    | 2022-06-16 01:14:11,379 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
dn1_1    | 2022-06-16 01:14:11,515 [pool-46-thread-1] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: new RaftServerImpl for group-A4B953253C7C:[] with ContainerStateMachine:uninitialized
dn1_1    | 2022-06-16 01:14:11,572 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn1_1    | 2022-06-16 01:14:11,600 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn1_1    | 2022-06-16 01:14:11,600 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn1_1    | 2022-06-16 01:14:11,600 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn1_1    | 2022-06-16 01:14:11,600 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn1_1    | 2022-06-16 01:14:11,600 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn1_1    | 2022-06-16 01:14:11,755 [pool-46-thread-1] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn1_1    | 2022-06-16 01:14:11,758 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn1_1    | 2022-06-16 01:14:11,760 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn1_1    | 2022-06-16 01:14:11,816 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn1_1    | 2022-06-16 01:14:12,027 [pool-46-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/ae07a9fd-bfc0-4f3c-b02e-a4b953253c7c/in_use.lock acquired by nodename 7@9b513447a933
dn1_1    | 2022-06-16 01:14:12,091 [pool-46-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=3, votedFor=8b366c76-456d-4ec7-ac8e-95910f7eaaa6} from /data/metadata/ratis/ae07a9fd-bfc0-4f3c-b02e-a4b953253c7c/current/raft-meta
dn1_1    | 2022-06-16 01:14:12,489 [pool-46-thread-1] INFO ratis.ContainerStateMachine: group-A4B953253C7C: Setting the last applied index to (t:3, i:4)
dn1_1    | 2022-06-16 01:14:12,573 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
dn1_1    | 2022-06-16 01:14:12,852 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
dn1_1    | 2022-06-16 01:14:13,139 [main] INFO util.log: Logging initialized @41893ms to org.eclipse.jetty.util.log.Slf4jLog
dn1_1    | 2022-06-16 01:14:14,167 [pool-46-thread-1] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C: set configuration 3: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:14:14,206 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn1_1    | 2022-06-16 01:14:14,211 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn1_1    | 2022-06-16 01:14:14,308 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn1_1    | 2022-06-16 01:14:14,308 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2022-06-16 01:14:14,309 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn1_1    | 2022-06-16 01:14:14,524 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2022-06-16 01:14:14,596 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
dn1_1    | 2022-06-16 01:14:14,653 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn1_1    | 2022-06-16 01:14:14,653 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn1_1    | 2022-06-16 01:14:14,665 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
dn1_1    | 2022-06-16 01:14:14,743 [pool-46-thread-1] INFO segmented.SegmentedRaftLogWorker: new 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/ae07a9fd-bfc0-4f3c-b02e-a4b953253c7c
dn1_1    | 2022-06-16 01:14:14,748 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn1_1    | 2022-06-16 01:14:14,767 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn1_1    | 2022-06-16 01:14:14,771 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2022-06-16 01:14:14,754 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
dn1_1    | 2022-06-16 01:14:14,788 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn1_1    | 2022-06-16 01:14:14,791 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn1_1    | 2022-06-16 01:14:14,795 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
dn1_1    | 2022-06-16 01:14:14,813 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
dn1_1    | 2022-06-16 01:14:14,813 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
dn1_1    | 2022-06-16 01:14:14,838 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn1_1    | 2022-06-16 01:14:14,843 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn1_1    | 2022-06-16 01:14:14,851 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn1_1    | 2022-06-16 01:14:15,063 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn1_1    | 2022-06-16 01:14:15,074 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn1_1    | 2022-06-16 01:14:15,095 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn1_1    | 2022-06-16 01:14:15,299 [main] INFO http.HttpServer2: Jetty bound to port 9882
dn1_1    | 2022-06-16 01:14:15,301 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
dn1_1    | 2022-06-16 01:14:15,545 [pool-46-thread-1] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C: set configuration 0: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:14:15,551 [pool-46-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/ae07a9fd-bfc0-4f3c-b02e-a4b953253c7c/current/log_0-0
dn1_1    | 2022-06-16 01:14:15,626 [pool-46-thread-1] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C: set configuration 1: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:14:15,633 [pool-46-thread-1] INFO segmented.LogSegment: Successfully read 2 entries from segment file /data/metadata/ratis/ae07a9fd-bfc0-4f3c-b02e-a4b953253c7c/current/log_1-2
dn1_1    | 2022-06-16 01:14:15,756 [pool-46-thread-1] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C: set configuration 3: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:14:15,760 [pool-46-thread-1] INFO segmented.LogSegment: Successfully read 2 entries from segment file /data/metadata/ratis/ae07a9fd-bfc0-4f3c-b02e-a4b953253c7c/current/log_inprogress_3
dn1_1    | 2022-06-16 01:14:15,800 [pool-46-thread-1] INFO segmented.SegmentedRaftLogWorker: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 4
dn1_1    | 2022-06-16 01:14:15,817 [pool-46-thread-1] INFO segmented.SegmentedRaftLogWorker: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 2
dn1_1    | 2022-06-16 01:14:15,970 [main] INFO server.session: DefaultSessionIdManager workerName=node0
dn1_1    | 2022-06-16 01:14:15,970 [main] INFO server.session: No SessionScavenger set, using defaults
dn1_1    | 2022-06-16 01:14:16,016 [main] INFO server.session: node0 Scavenging every 660000ms
dn1_1    | 2022-06-16 01:14:16,155 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7197b07f{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
dn1_1    | 2022-06-16 01:14:16,193 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@33a8c9c9{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
dn1_1    | 2022-06-16 01:14:16,676 [pool-46-thread-1] INFO raftlog.RaftLog: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-SegmentedRaftLog: commitIndex: updateToMax old=4, new=3, updated? false
dn1_1    | 2022-06-16 01:14:16,720 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn1_1    | 2022-06-16 01:14:16,734 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn1_1    | 2022-06-16 01:14:16,735 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn1_1    | 2022-06-16 01:14:16,736 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn1_1    | 2022-06-16 01:14:16,784 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn1_1    | 2022-06-16 01:14:16,784 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn1_1    | 2022-06-16 01:14:17,107 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7a65c995{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-11812661442803453522/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
dn1_1    | 2022-06-16 01:14:17,155 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn1_1    | 2022-06-16 01:14:17,162 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn1_1    | 2022-06-16 01:14:17,179 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn1_1    | 2022-06-16 01:14:17,195 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn1_1    | 2022-06-16 01:14:17,198 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn1_1    | 2022-06-16 01:14:17,204 [pool-46-thread-1] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: new RaftServerImpl for group-5FC878C6C2DE:[] with ContainerStateMachine:uninitialized
dn1_1    | 2022-06-16 01:14:17,202 [main] INFO server.AbstractConnector: Started ServerConnector@d653e41{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
dn1_1    | 2022-06-16 01:14:17,206 [main] INFO server.Server: Started @45960ms
dn1_1    | 2022-06-16 01:14:17,220 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn1_1    | 2022-06-16 01:14:17,222 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn1_1    | 2022-06-16 01:14:17,222 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn1_1    | 2022-06-16 01:14:17,222 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn1_1    | 2022-06-16 01:14:17,223 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn1_1    | 2022-06-16 01:14:17,225 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn1_1    | 2022-06-16 01:14:17,226 [pool-46-thread-1] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn1_1    | 2022-06-16 01:14:17,230 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn1_1    | 2022-06-16 01:14:17,231 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn1_1    | 2022-06-16 01:14:17,231 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn1_1    | 2022-06-16 01:14:17,223 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
dn1_1    | 2022-06-16 01:14:17,235 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
dn1_1    | 2022-06-16 01:14:17,238 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
dn1_1    | 2022-06-16 01:14:17,248 [pool-46-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de/in_use.lock acquired by nodename 7@9b513447a933
dn1_1    | 2022-06-16 01:14:17,249 [pool-46-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=13, votedFor=c7eeb289-59cc-4c90-a00f-b0c50499b5ba} from /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de/current/raft-meta
dn1_1    | 2022-06-16 01:14:17,250 [pool-46-thread-1] INFO ratis.ContainerStateMachine: group-5FC878C6C2DE: Setting the last applied index to (t:13, i:38)
dn1_1    | 2022-06-16 01:14:17,252 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
dn1_1    | 2022-06-16 01:14:17,259 [Datanode State Machine Daemon Thread] INFO upgrade.UpgradeFinalizer: Running pre-finalized state validations for unfinalized layout features.
dn1_1    | 2022-06-16 01:14:17,349 [Datanode State Machine Daemon Thread] INFO upgrade.UpgradeFinalizer: Running first upgrade commands for unfinalized layout features.
dn1_1    | 2022-06-16 01:14:17,351 [pool-46-thread-1] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE: set configuration 22: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-06-16 01:14:17,360 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn2_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
dn2_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
dn2_1    | 2022-06-16 01:13:41,964 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
dn2_1    | /************************************************************
dn2_1    | STARTUP_MSG: Starting HddsDatanodeService
dn2_1    | STARTUP_MSG:   host = 233dd8228c59/10.9.0.16
dn2_1    | STARTUP_MSG:   args = []
dn2_1    | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
dn1_1    | 2022-06-16 01:14:17,361 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn1_1    | 2022-06-16 01:14:17,361 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn1_1    | 2022-06-16 01:14:17,358 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@b9105d3] INFO util.JvmPauseMonitor: Starting JVM pause monitor
dn1_1    | 2022-06-16 01:14:17,362 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2022-06-16 01:14:17,389 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn1_1    | 2022-06-16 01:14:17,390 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2022-06-16 01:14:17,390 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn1_1    | 2022-06-16 01:14:17,390 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn1_1    | 2022-06-16 01:14:17,390 [pool-46-thread-1] INFO segmented.SegmentedRaftLogWorker: new 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de
dn1_1    | 2022-06-16 01:14:17,391 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn1_1    | 2022-06-16 01:14:17,391 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn1_1    | 2022-06-16 01:14:17,391 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2022-06-16 01:14:17,391 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn1_1    | 2022-06-16 01:14:17,391 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn1_1    | 2022-06-16 01:14:17,391 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn1_1    | 2022-06-16 01:14:17,391 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn1_1    | 2022-06-16 01:14:17,391 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn1_1    | 2022-06-16 01:14:17,392 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn1_1    | 2022-06-16 01:14:17,415 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn1_1    | 2022-06-16 01:14:17,417 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn1_1    | 2022-06-16 01:14:17,426 [pool-46-thread-1] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE: set configuration 0: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-06-16 01:14:17,429 [pool-46-thread-1] INFO segmented.LogSegment: Successfully read 4 entries from segment file /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de/current/log_0-3
dn1_1    | 2022-06-16 01:14:17,445 [pool-46-thread-1] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE: set configuration 4: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-06-16 01:14:17,447 [pool-46-thread-1] INFO segmented.LogSegment: Successfully read 18 entries from segment file /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de/current/log_4-21
dn1_1    | 2022-06-16 01:14:17,472 [pool-46-thread-1] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE: set configuration 22: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-06-16 01:14:17,477 [pool-46-thread-1] INFO segmented.LogSegment: Successfully read 17 entries from segment file /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de/current/log_inprogress_22
dn1_1    | 2022-06-16 01:14:17,485 [pool-46-thread-1] INFO segmented.SegmentedRaftLogWorker: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 38
dn1_1    | 2022-06-16 01:14:17,485 [pool-46-thread-1] INFO segmented.SegmentedRaftLogWorker: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 21
dn1_1    | 2022-06-16 01:14:17,495 [pool-46-thread-1] INFO raftlog.RaftLog: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-SegmentedRaftLog: commitIndex: updateToMax old=38, new=36, updated? false
dn1_1    | 2022-06-16 01:14:17,495 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn1_1    | 2022-06-16 01:14:17,496 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn1_1    | 2022-06-16 01:14:17,496 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn1_1    | 2022-06-16 01:14:17,499 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn1_1    | 2022-06-16 01:14:17,502 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn1_1    | 2022-06-16 01:14:17,502 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn1_1    | 2022-06-16 01:14:17,514 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn1_1    | 2022-06-16 01:14:17,514 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn1_1    | 2022-06-16 01:14:17,515 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn1_1    | 2022-06-16 01:14:17,515 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn1_1    | 2022-06-16 01:14:17,515 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn1_1    | 2022-06-16 01:14:17,517 [pool-46-thread-1] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: new RaftServerImpl for group-8C8526B83399:[] with ContainerStateMachine:uninitialized
dn1_1    | 2022-06-16 01:14:17,523 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn1_1    | 2022-06-16 01:14:17,523 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn1_1    | 2022-06-16 01:14:17,523 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn1_1    | 2022-06-16 01:14:17,523 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn1_1    | 2022-06-16 01:14:17,524 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn1_1    | 2022-06-16 01:14:17,524 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn1_1    | 2022-06-16 01:14:17,524 [pool-46-thread-1] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn1_1    | 2022-06-16 01:14:17,524 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn1_1    | 2022-06-16 01:14:17,525 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn1_1    | 2022-06-16 01:14:17,526 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn1_1    | 2022-06-16 01:14:17,528 [pool-46-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399/in_use.lock acquired by nodename 7@9b513447a933
dn1_1    | 2022-06-16 01:14:17,529 [pool-46-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=8, votedFor=c3461ed7-1554-428d-9478-8d95583cf36e} from /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399/current/raft-meta
dn1_1    | 2022-06-16 01:14:17,530 [pool-46-thread-1] INFO ratis.ContainerStateMachine: group-8C8526B83399: Setting the last applied index to (t:8, i:28)
dn1_1    | 2022-06-16 01:14:17,530 [pool-46-thread-1] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: set configuration 19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:14:17,539 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn1_1    | 2022-06-16 01:14:17,540 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn1_1    | 2022-06-16 01:14:17,540 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn1_1    | 2022-06-16 01:14:17,542 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2022-06-16 01:14:17,542 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn1_1    | 2022-06-16 01:14:17,543 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2022-06-16 01:14:17,543 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn1_1    | 2022-06-16 01:14:17,544 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn1_1    | 2022-06-16 01:14:17,544 [pool-46-thread-1] INFO segmented.SegmentedRaftLogWorker: new 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399
dn1_1    | 2022-06-16 01:14:17,545 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn1_1    | 2022-06-16 01:14:17,545 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn1_1    | 2022-06-16 01:14:17,545 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2022-06-16 01:14:17,545 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn1_1    | 2022-06-16 01:14:17,545 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn1_1    | 2022-06-16 01:14:17,545 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn1_1    | 2022-06-16 01:14:17,549 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn1_1    | 2022-06-16 01:14:17,552 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn1_1    | 2022-06-16 01:14:17,553 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn1_1    | 2022-06-16 01:14:17,556 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn1_1    | 2022-06-16 01:14:17,557 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn1_1    | 2022-06-16 01:14:17,558 [pool-46-thread-1] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: set configuration 0: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:14:17,563 [pool-46-thread-1] INFO segmented.LogSegment: Successfully read 9 entries from segment file /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399/current/log_0-8
dn1_1    | 2022-06-16 01:14:17,567 [pool-46-thread-1] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: set configuration 9: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:14:17,569 [pool-46-thread-1] INFO segmented.LogSegment: Successfully read 10 entries from segment file /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399/current/log_9-18
dn1_1    | 2022-06-16 01:14:17,576 [pool-46-thread-1] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: set configuration 19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:14:17,581 [pool-46-thread-1] INFO segmented.LogSegment: Successfully read 10 entries from segment file /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399/current/log_inprogress_19
dn1_1    | 2022-06-16 01:14:17,582 [pool-46-thread-1] INFO segmented.SegmentedRaftLogWorker: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 28
dn1_1    | 2022-06-16 01:14:17,586 [pool-46-thread-1] INFO segmented.SegmentedRaftLogWorker: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 18
dn1_1    | 2022-06-16 01:14:17,594 [pool-46-thread-1] INFO raftlog.RaftLog: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-SegmentedRaftLog: commitIndex: updateToMax old=28, new=27, updated? false
dn1_1    | 2022-06-16 01:14:17,594 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn1_1    | 2022-06-16 01:14:17,595 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn1_1    | 2022-06-16 01:14:17,595 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn1_1    | 2022-06-16 01:14:17,597 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn1_1    | 2022-06-16 01:14:17,598 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn1_1    | 2022-06-16 01:14:17,599 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn1_1    | 2022-06-16 01:14:17,608 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn1_1    | 2022-06-16 01:14:17,609 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn1_1    | 2022-06-16 01:14:17,609 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn1_1    | 2022-06-16 01:14:17,610 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn1_1    | 2022-06-16 01:14:17,612 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn1_1    | 2022-06-16 01:14:17,661 [Datanode State Machine Task Thread - 1] WARN statemachine.SCMConnectionManager: Trying to add an existing SCM Machine to Machines group. Ignoring the request.
dn1_1    | 2022-06-16 01:14:20,906 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
dn1_1    | 2022-06-16 01:14:20,917 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
dn1_1    | 2022-06-16 01:14:21,135 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 8b366c76-456d-4ec7-ac8e-95910f7eaaa6
dn1_1    | 2022-06-16 01:14:21,170 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6-impl-thread1] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE: start as a follower, conf=22: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-06-16 01:14:21,178 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6-impl-thread1] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE: changes role from      null to FOLLOWER at term 13 for startAsFollower
dn1_1    | 2022-06-16 01:14:21,180 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6-impl-thread1] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-FollowerState
dn1_1    | 2022-06-16 01:14:21,173 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6-impl-thread2] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C: start as a follower, conf=3: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:14:21,290 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6-impl-thread2] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C: changes role from      null to FOLLOWER at term 3 for startAsFollower
dn1_1    | 2022-06-16 01:14:21,267 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6-impl-thread3] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: start as a follower, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:14:21,293 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6-impl-thread3] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: changes role from      null to FOLLOWER at term 8 for startAsFollower
dn1_1    | 2022-06-16 01:14:21,294 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6-impl-thread3] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState
dn1_1    | 2022-06-16 01:14:21,290 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5FC878C6C2DE,id=8b366c76-456d-4ec7-ac8e-95910f7eaaa6
dn1_1    | 2022-06-16 01:14:21,302 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6-impl-thread3] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8C8526B83399,id=8b366c76-456d-4ec7-ac8e-95910f7eaaa6
dn1_1    | 2022-06-16 01:14:21,291 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6-impl-thread2] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-FollowerState
dn1_1    | 2022-06-16 01:14:21,344 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6-impl-thread2] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A4B953253C7C,id=8b366c76-456d-4ec7-ac8e-95910f7eaaa6
dn1_1    | 2022-06-16 01:14:21,400 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.RaftServer: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start RPC server
dn1_1    | 2022-06-16 01:14:21,435 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: GrpcService started, listening on 9856
dn1_1    | 2022-06-16 01:14:21,437 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: GrpcService started, listening on 9857
dn1_1    | 2022-06-16 01:14:21,446 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: GrpcService started, listening on 9858
dn1_1    | 2022-06-16 01:14:21,479 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 8b366c76-456d-4ec7-ac8e-95910f7eaaa6 is started using port 9858 for RATIS
dn1_1    | 2022-06-16 01:14:21,483 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 8b366c76-456d-4ec7-ac8e-95910f7eaaa6 is started using port 9857 for RATIS_ADMIN
dn1_1    | 2022-06-16 01:14:21,483 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 8b366c76-456d-4ec7-ac8e-95910f7eaaa6 is started using port 9856 for RATIS_SERVER
dn1_1    | 2022-06-16 01:14:21,494 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$484/0x0000000840568c40@a240181] INFO util.JvmPauseMonitor: JvmPauseMonitor-8b366c76-456d-4ec7-ac8e-95910f7eaaa6: Started
dn1_1    | 2022-06-16 01:14:26,288 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-FollowerState] INFO impl.FollowerState: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5108838150ns, electionTimeout:5016ms
dn1_1    | 2022-06-16 01:14:26,290 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-FollowerState] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: shutdown 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-FollowerState
dn1_1    | 2022-06-16 01:14:26,290 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-FollowerState] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE: changes role from  FOLLOWER to CANDIDATE at term 13 for changeToCandidate
dn1_1    | 2022-06-16 01:14:26,292 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn1_1    | 2022-06-16 01:14:26,293 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-FollowerState] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-LeaderElection1
dn1_1    | 2022-06-16 01:14:26,386 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-FollowerState] INFO impl.FollowerState: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5095025754ns, electionTimeout:5018ms
dn1_1    | 2022-06-16 01:14:26,413 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-FollowerState] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: shutdown 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-FollowerState
dn1_1    | 2022-06-16 01:14:26,413 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-FollowerState] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
dn1_1    | 2022-06-16 01:14:26,413 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn1_1    | 2022-06-16 01:14:26,413 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-FollowerState] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-LeaderElection2
dn1_1    | 2022-06-16 01:14:26,439 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-LeaderElection1] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-LeaderElection1 ELECTION round 0: submit vote requests at term 14 for 22: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-06-16 01:14:26,442 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-LeaderElection2] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-LeaderElection2 ELECTION round 0: submit vote requests at term 4 for 3: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:14:26,452 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-LeaderElection2] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-LeaderElection2 ELECTION round 0: result PASSED (term=4)
dn1_1    | 2022-06-16 01:14:26,457 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-LeaderElection2] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: shutdown 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-LeaderElection2
dn1_1    | 2022-06-16 01:14:26,478 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.FollowerState: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5183387693ns, electionTimeout:5130ms
dn1_1    | 2022-06-16 01:14:26,484 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: shutdown 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState
dn1_1    | 2022-06-16 01:14:26,484 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: changes role from  FOLLOWER to CANDIDATE at term 8 for changeToCandidate
dn1_1    | 2022-06-16 01:14:26,486 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn1_1    | 2022-06-16 01:14:26,486 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection3
dn1_1    | 2022-06-16 01:14:26,499 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-LeaderElection2] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C: changes role from CANDIDATE to LEADER at term 4 for changeToLeader
dn1_1    | 2022-06-16 01:14:26,499 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A4B953253C7C with new leaderId: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6
dn1_1    | 2022-06-16 01:14:26,526 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-LeaderElection2] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C: change Leader from null to 8b366c76-456d-4ec7-ac8e-95910f7eaaa6 at term 4 for becomeLeader, leader elected after 12298ms
dn1_1    | 2022-06-16 01:14:26,983 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection3] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection3 ELECTION round 0: submit vote requests at term 9 for 19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:14:27,035 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn1_1    | 2022-06-16 01:14:27,089 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn1_1    | 2022-06-16 01:14:27,143 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn1_1    | 2022-06-16 01:14:27,212 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn1_1    | 2022-06-16 01:14:27,279 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn1_1    | 2022-06-16 01:14:27,327 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn1_1    | 2022-06-16 01:14:27,373 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn1_1    | 2022-06-16 01:14:27,437 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn1_1    | 2022-06-16 01:14:27,479 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-LeaderElection2] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-LeaderStateImpl
dn1_1    | 2022-06-16 01:14:27,630 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-SegmentedRaftLogWorker: Rolling segment log-3_4 to index:4
dn1_1    | 2022-06-16 01:14:27,651 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/ae07a9fd-bfc0-4f3c-b02e-a4b953253c7c/current/log_inprogress_3 to /data/metadata/ratis/ae07a9fd-bfc0-4f3c-b02e-a4b953253c7c/current/log_3-4
dn1_1    | 2022-06-16 01:14:27,751 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-LeaderElection2] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C: set configuration 5: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:14:27,838 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-A4B953253C7C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/ae07a9fd-bfc0-4f3c-b02e-a4b953253c7c/current/log_inprogress_5
dn1_1    | 2022-06-16 01:14:29,896 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: receive requestVote(ELECTION, c3461ed7-1554-428d-9478-8d95583cf36e, group-8C8526B83399, 9, (t:8, i:28))
dn1_1    | 2022-06-16 01:14:29,900 [grpc-default-executor-0] INFO impl.VoteContext: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-CANDIDATE: reject ELECTION from c3461ed7-1554-428d-9478-8d95583cf36e: already has voted for 8b366c76-456d-4ec7-ac8e-95910f7eaaa6 at current term 9
dn1_1    | 2022-06-16 01:14:29,912 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399 replies to ELECTION vote request: c3461ed7-1554-428d-9478-8d95583cf36e<-8b366c76-456d-4ec7-ac8e-95910f7eaaa6#0:FAIL-t9. Peer's state: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399:t9, leader=null, voted=8b366c76-456d-4ec7-ac8e-95910f7eaaa6, raftlog=8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:14:29,928 [grpc-default-executor-1] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE: receive requestVote(ELECTION, c3461ed7-1554-428d-9478-8d95583cf36e, group-5FC878C6C2DE, 14, (t:13, i:38))
dn1_1    | 2022-06-16 01:14:29,928 [grpc-default-executor-1] INFO impl.VoteContext: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-CANDIDATE: reject ELECTION from c3461ed7-1554-428d-9478-8d95583cf36e: already has voted for 8b366c76-456d-4ec7-ac8e-95910f7eaaa6 at current term 14
dn1_1    | 2022-06-16 01:14:29,929 [grpc-default-executor-1] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE replies to ELECTION vote request: c3461ed7-1554-428d-9478-8d95583cf36e<-8b366c76-456d-4ec7-ac8e-95910f7eaaa6#0:FAIL-t14. Peer's state: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE:t14, leader=null, voted=8b366c76-456d-4ec7-ac8e-95910f7eaaa6, raftlog=8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-SegmentedRaftLog:OPENED:c38, conf=22: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-06-16 01:14:30,025 [grpc-default-executor-1] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE: receive requestVote(ELECTION, c7eeb289-59cc-4c90-a00f-b0c50499b5ba, group-5FC878C6C2DE, 14, (t:13, i:38))
dn1_1    | 2022-06-16 01:14:30,026 [grpc-default-executor-1] INFO impl.VoteContext: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-CANDIDATE: reject ELECTION from c7eeb289-59cc-4c90-a00f-b0c50499b5ba: already has voted for 8b366c76-456d-4ec7-ac8e-95910f7eaaa6 at current term 14
dn1_1    | 2022-06-16 01:14:30,026 [grpc-default-executor-1] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE replies to ELECTION vote request: c7eeb289-59cc-4c90-a00f-b0c50499b5ba<-8b366c76-456d-4ec7-ac8e-95910f7eaaa6#0:FAIL-t14. Peer's state: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE:t14, leader=null, voted=8b366c76-456d-4ec7-ac8e-95910f7eaaa6, raftlog=8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-SegmentedRaftLog:OPENED:c38, conf=22: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-06-16 01:14:30,047 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: receive requestVote(ELECTION, c7eeb289-59cc-4c90-a00f-b0c50499b5ba, group-8C8526B83399, 9, (t:8, i:28))
dn1_1    | 2022-06-16 01:14:30,047 [grpc-default-executor-0] INFO impl.VoteContext: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-CANDIDATE: reject ELECTION from c7eeb289-59cc-4c90-a00f-b0c50499b5ba: already has voted for 8b366c76-456d-4ec7-ac8e-95910f7eaaa6 at current term 9
dn1_1    | 2022-06-16 01:14:30,048 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399 replies to ELECTION vote request: c7eeb289-59cc-4c90-a00f-b0c50499b5ba<-8b366c76-456d-4ec7-ac8e-95910f7eaaa6#0:FAIL-t9. Peer's state: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399:t9, leader=null, voted=8b366c76-456d-4ec7-ac8e-95910f7eaaa6, raftlog=8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:14:30,172 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection3] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection3: ELECTION REJECTED received 1 response(s) and 0 exception(s):
dn1_1    | 2022-06-16 01:14:30,172 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection3] INFO impl.LeaderElection:   Response 0: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t9
dn1_1    | 2022-06-16 01:14:30,172 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection3] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection3 ELECTION round 0: result REJECTED
dn2_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/gson-2.8.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
dn2_1    | STARTUP_MSG:   build = https://github.com/apache/ozone/17d3301a908af2df7683a0c61b8ee3ae8dd41d6a ; compiled by 'runner' on 2022-06-16T00:51Z
dn2_1    | STARTUP_MSG:   java = 11.0.14.1
dn2_1    | ************************************************************/
dn2_1    | 2022-06-16 01:13:42,015 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
dn2_1    | 2022-06-16 01:13:42,512 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
dn2_1    | 2022-06-16 01:13:43,402 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
dn2_1    | 2022-06-16 01:13:44,736 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
dn2_1    | 2022-06-16 01:13:44,755 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
dn2_1    | 2022-06-16 01:13:46,416 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:233dd8228c59 ip:10.9.0.16
dn2_1    | 2022-06-16 01:13:48,321 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = DATANODE_SCHEMA_V3 (version = 4)
dn2_1    | 2022-06-16 01:13:49,454 [main] INFO reflections.Reflections: Reflections took 839 ms to scan 2 urls, producing 89 keys and 191 values 
dn2_1    | 2022-06-16 01:13:50,116 [main] INFO upgrade.HDDSLayoutVersionManager: Registering Upgrade Action : DatanodeSchemaV3FinalizeAction
dn2_1    | 2022-06-16 01:13:50,352 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
dn2_1    | 2022-06-16 01:13:51,456 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/hdds/scmUsed: 8192 at 2022-06-16T01:13:16.910Z
dn2_1    | 2022-06-16 01:13:51,567 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
dn2_1    | 2022-06-16 01:13:51,583 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
dn2_1    | 2022-06-16 01:13:51,594 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
dn2_1    | 2022-06-16 01:13:51,818 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
dn2_1    | 2022-06-16 01:13:51,949 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn2_1    | 2022-06-16 01:13:52,022 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/metadata/ratis/scmUsed: 4096 at 2022-06-16T01:13:16.913Z
dn2_1    | 2022-06-16 01:13:52,050 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
dn2_1    | 2022-06-16 01:13:52,054 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
dn2_1    | 2022-06-16 01:13:52,054 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
dn2_1    | 2022-06-16 01:13:52,253 [Thread-3] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
dn2_1    | 2022-06-16 01:13:53,953 [Thread-3] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
dn2_1    | 2022-06-16 01:13:53,954 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 1s
dn2_1    | 2022-06-16 01:14:05,199 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
dn2_1    | 2022-06-16 01:14:05,837 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn2_1    | 2022-06-16 01:14:06,305 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
dn2_1    | 2022-06-16 01:14:07,363 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
dn2_1    | 2022-06-16 01:14:07,383 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
dn2_1    | 2022-06-16 01:14:07,389 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
dn2_1    | 2022-06-16 01:14:07,390 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
dn2_1    | 2022-06-16 01:14:07,391 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2022-06-16 01:14:07,394 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
dn2_1    | 2022-06-16 01:14:07,396 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn2_1    | 2022-06-16 01:14:07,561 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
dn2_1    | 2022-06-16 01:14:07,562 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
dn2_1    | 2022-06-16 01:14:10,178 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
dn2_1    | 2022-06-16 01:14:10,206 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
dn2_1    | 2022-06-16 01:14:10,211 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
dn2_1    | 2022-06-16 01:14:10,215 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn2_1    | 2022-06-16 01:14:10,228 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn2_1    | 2022-06-16 01:14:10,349 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn2_1    | 2022-06-16 01:14:10,386 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba-impl-thread1] INFO server.RaftServer: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: found a subdirectory /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de
dn2_1    | 2022-06-16 01:14:10,482 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba-impl-thread1] INFO server.RaftServer: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: addNew group-5FC878C6C2DE:[] returns group-5FC878C6C2DE:java.util.concurrent.CompletableFuture@58dbb1bd[Not completed]
dn2_1    | 2022-06-16 01:14:10,490 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba-impl-thread1] INFO server.RaftServer: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: found a subdirectory /data/metadata/ratis/0934911a-aba3-405f-94e4-cbcf5e919788
dn2_1    | 2022-06-16 01:14:10,490 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba-impl-thread1] INFO server.RaftServer: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: addNew group-CBCF5E919788:[] returns group-CBCF5E919788:java.util.concurrent.CompletableFuture@3c5ea5f[Not completed]
dn2_1    | 2022-06-16 01:14:10,490 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba-impl-thread1] INFO server.RaftServer: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: found a subdirectory /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399
dn2_1    | 2022-06-16 01:14:10,490 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba-impl-thread1] INFO server.RaftServer: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: addNew group-8C8526B83399:[] returns group-8C8526B83399:java.util.concurrent.CompletableFuture@5407f7c3[Not completed]
dn2_1    | 2022-06-16 01:14:10,667 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
dn2_1    | 2022-06-16 01:14:10,839 [pool-46-thread-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: new RaftServerImpl for group-5FC878C6C2DE:[] with ContainerStateMachine:uninitialized
dn2_1    | 2022-06-16 01:14:10,919 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn2_1    | 2022-06-16 01:14:10,934 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn2_1    | 2022-06-16 01:14:10,954 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn2_1    | 2022-06-16 01:14:10,954 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn2_1    | 2022-06-16 01:14:10,954 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn2_1    | 2022-06-16 01:14:10,954 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn2_1    | 2022-06-16 01:14:11,065 [pool-46-thread-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn2_1    | 2022-06-16 01:14:11,086 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn2_1    | 2022-06-16 01:14:11,136 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn2_1    | 2022-06-16 01:14:11,138 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn2_1    | 2022-06-16 01:14:11,321 [pool-46-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de/in_use.lock acquired by nodename 8@233dd8228c59
dn2_1    | 2022-06-16 01:14:11,372 [pool-46-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=13, votedFor=c7eeb289-59cc-4c90-a00f-b0c50499b5ba} from /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de/current/raft-meta
dn2_1    | 2022-06-16 01:14:11,701 [pool-46-thread-1] INFO ratis.ContainerStateMachine: group-5FC878C6C2DE: Setting the last applied index to (t:13, i:38)
dn2_1    | 2022-06-16 01:14:11,705 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
dn2_1    | 2022-06-16 01:14:11,910 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
dn2_1    | 2022-06-16 01:14:12,216 [main] INFO util.log: Logging initialized @41663ms to org.eclipse.jetty.util.log.Slf4jLog
dn2_1    | 2022-06-16 01:14:13,416 [pool-46-thread-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE: set configuration 22: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-06-16 01:14:13,425 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn2_1    | 2022-06-16 01:14:13,430 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn2_1    | 2022-06-16 01:14:13,507 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn2_1    | 2022-06-16 01:14:13,544 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2022-06-16 01:14:13,550 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn2_1    | 2022-06-16 01:14:13,641 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2022-06-16 01:14:13,796 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
dn2_1    | 2022-06-16 01:14:13,813 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn2_1    | 2022-06-16 01:14:13,819 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn2_1    | 2022-06-16 01:14:13,869 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
dn2_1    | 2022-06-16 01:14:13,881 [pool-46-thread-1] INFO segmented.SegmentedRaftLogWorker: new c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de
dn2_1    | 2022-06-16 01:14:13,900 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn2_1    | 2022-06-16 01:14:13,905 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn2_1    | 2022-06-16 01:14:13,906 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2022-06-16 01:14:13,920 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn2_1    | 2022-06-16 01:14:13,922 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn2_1    | 2022-06-16 01:14:13,943 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn2_1    | 2022-06-16 01:14:13,945 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn2_1    | 2022-06-16 01:14:13,952 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn2_1    | 2022-06-16 01:14:13,945 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
dn2_1    | 2022-06-16 01:14:13,969 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
dn2_1    | 2022-06-16 01:14:13,980 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
dn2_1    | 2022-06-16 01:14:13,998 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
dn2_1    | 2022-06-16 01:14:14,062 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn2_1    | 2022-06-16 01:14:14,064 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn2_1    | 2022-06-16 01:14:14,080 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn2_1    | 2022-06-16 01:14:14,504 [main] INFO http.HttpServer2: Jetty bound to port 9882
dn3_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
dn3_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
dn3_1    | 2022-06-16 01:13:40,691 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
dn3_1    | /************************************************************
dn3_1    | STARTUP_MSG: Starting HddsDatanodeService
dn3_1    | STARTUP_MSG:   host = 072040935ca7/10.9.0.17
dn3_1    | STARTUP_MSG:   args = []
dn3_1    | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
dn1_1    | 2022-06-16 01:14:30,174 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection3] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: changes role from CANDIDATE to FOLLOWER at term 9 for REJECTED
dn1_1    | 2022-06-16 01:14:30,174 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection3] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: shutdown 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection3
dn1_1    | 2022-06-16 01:14:30,174 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection3] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState
dn1_1    | 2022-06-16 01:14:30,259 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-LeaderElection1] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
dn1_1    | 2022-06-16 01:14:30,259 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-LeaderElection1] INFO impl.LeaderElection:   Response 0: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c7eeb289-59cc-4c90-a00f-b0c50499b5ba#0:FAIL-t14
dn1_1    | 2022-06-16 01:14:30,259 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-LeaderElection1] INFO impl.LeaderElection:   Response 1: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t14
dn1_1    | 2022-06-16 01:14:30,259 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-LeaderElection1] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-LeaderElection1 ELECTION round 0: result REJECTED
dn1_1    | 2022-06-16 01:14:30,260 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-LeaderElection1] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE: changes role from CANDIDATE to FOLLOWER at term 14 for REJECTED
dn1_1    | 2022-06-16 01:14:30,260 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-LeaderElection1] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: shutdown 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-LeaderElection1
dn1_1    | 2022-06-16 01:14:30,260 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-LeaderElection1] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-FollowerState
dn1_1    | 2022-06-16 01:14:35,268 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-FollowerState] INFO impl.FollowerState: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5008109385ns, electionTimeout:5007ms
dn1_1    | 2022-06-16 01:14:35,268 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-FollowerState] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: shutdown 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-FollowerState
dn1_1    | 2022-06-16 01:14:35,269 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-FollowerState] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE: changes role from  FOLLOWER to CANDIDATE at term 14 for changeToCandidate
dn1_1    | 2022-06-16 01:14:35,269 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn1_1    | 2022-06-16 01:14:35,269 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-FollowerState] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-LeaderElection4
dn1_1    | 2022-06-16 01:14:35,272 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-LeaderElection4] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-LeaderElection4 ELECTION round 0: submit vote requests at term 15 for 22: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-06-16 01:14:35,321 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.FollowerState: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5147532158ns, electionTimeout:5141ms
dn1_1    | 2022-06-16 01:14:35,321 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: shutdown 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState
dn1_1    | 2022-06-16 01:14:35,322 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: changes role from  FOLLOWER to CANDIDATE at term 9 for changeToCandidate
dn1_1    | 2022-06-16 01:14:35,322 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn1_1    | 2022-06-16 01:14:35,322 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection5
dn1_1    | 2022-06-16 01:14:35,329 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection5] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection5 ELECTION round 0: submit vote requests at term 10 for 19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:14:35,349 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: receive requestVote(ELECTION, c7eeb289-59cc-4c90-a00f-b0c50499b5ba, group-8C8526B83399, 10, (t:8, i:28))
dn1_1    | 2022-06-16 01:14:35,350 [grpc-default-executor-0] INFO impl.VoteContext: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-CANDIDATE: reject ELECTION from c7eeb289-59cc-4c90-a00f-b0c50499b5ba: already has voted for 8b366c76-456d-4ec7-ac8e-95910f7eaaa6 at current term 10
dn1_1    | 2022-06-16 01:14:35,350 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399 replies to ELECTION vote request: c7eeb289-59cc-4c90-a00f-b0c50499b5ba<-8b366c76-456d-4ec7-ac8e-95910f7eaaa6#0:FAIL-t10. Peer's state: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399:t10, leader=null, voted=8b366c76-456d-4ec7-ac8e-95910f7eaaa6, raftlog=8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:14:35,377 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection5] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection5: ELECTION REJECTED received 1 response(s) and 0 exception(s):
dn1_1    | 2022-06-16 01:14:35,379 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection5] INFO impl.LeaderElection:   Response 0: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t10
dn2_1    | 2022-06-16 01:14:14,505 [pool-46-thread-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE: set configuration 0: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-06-16 01:14:14,505 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
dn2_1    | 2022-06-16 01:14:14,566 [pool-46-thread-1] INFO segmented.LogSegment: Successfully read 4 entries from segment file /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de/current/log_0-3
dn2_1    | 2022-06-16 01:14:14,593 [pool-46-thread-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE: set configuration 4: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-06-16 01:14:14,606 [pool-46-thread-1] INFO segmented.LogSegment: Successfully read 18 entries from segment file /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de/current/log_4-21
dn2_1    | 2022-06-16 01:14:14,607 [pool-46-thread-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE: set configuration 22: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-06-16 01:14:14,640 [pool-46-thread-1] INFO segmented.LogSegment: Successfully read 17 entries from segment file /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de/current/log_inprogress_22
dn2_1    | 2022-06-16 01:14:14,647 [pool-46-thread-1] INFO segmented.SegmentedRaftLogWorker: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 38
dn2_1    | 2022-06-16 01:14:14,664 [pool-46-thread-1] INFO segmented.SegmentedRaftLogWorker: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 21
dn2_1    | 2022-06-16 01:14:14,813 [main] INFO server.session: DefaultSessionIdManager workerName=node0
dn2_1    | 2022-06-16 01:14:14,835 [main] INFO server.session: No SessionScavenger set, using defaults
dn2_1    | 2022-06-16 01:14:14,836 [main] INFO server.session: node0 Scavenging every 600000ms
dn2_1    | 2022-06-16 01:14:14,934 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7197b07f{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
dn2_1    | 2022-06-16 01:14:14,935 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@33a8c9c9{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
dn2_1    | 2022-06-16 01:14:15,628 [pool-46-thread-1] INFO raftlog.RaftLog: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-SegmentedRaftLog: commitIndex: updateToMax old=38, new=36, updated? false
dn2_1    | 2022-06-16 01:14:15,659 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn2_1    | 2022-06-16 01:14:15,699 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn2_1    | 2022-06-16 01:14:15,701 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn2_1    | 2022-06-16 01:14:15,717 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn2_1    | 2022-06-16 01:14:15,722 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn2_1    | 2022-06-16 01:14:15,722 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn2_1    | 2022-06-16 01:14:15,981 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7a65c995{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-16989769672820363376/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
dn2_1    | 2022-06-16 01:14:16,107 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn2_1    | 2022-06-16 01:14:16,135 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn2_1    | 2022-06-16 01:14:16,136 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn2_1    | 2022-06-16 01:14:16,137 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn2_1    | 2022-06-16 01:14:16,142 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn2_1    | 2022-06-16 01:14:16,140 [main] INFO server.AbstractConnector: Started ServerConnector@d653e41{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
dn2_1    | 2022-06-16 01:14:16,150 [main] INFO server.Server: Started @45597ms
dn2_1    | 2022-06-16 01:14:16,182 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
dn2_1    | 2022-06-16 01:14:16,188 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
dn2_1    | 2022-06-16 01:14:16,202 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
dn2_1    | 2022-06-16 01:14:16,243 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
dn2_1    | 2022-06-16 01:14:16,406 [pool-46-thread-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: new RaftServerImpl for group-CBCF5E919788:[] with ContainerStateMachine:uninitialized
dn2_1    | 2022-06-16 01:14:16,417 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn2_1    | 2022-06-16 01:14:16,429 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn2_1    | 2022-06-16 01:14:16,441 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn2_1    | 2022-06-16 01:14:16,443 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn2_1    | 2022-06-16 01:14:16,444 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn2_1    | 2022-06-16 01:14:16,451 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn2_1    | 2022-06-16 01:14:16,457 [pool-46-thread-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn2_1    | 2022-06-16 01:14:16,457 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn2_1    | 2022-06-16 01:14:16,461 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn2_1    | 2022-06-16 01:14:16,467 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn2_1    | 2022-06-16 01:14:16,481 [Datanode State Machine Daemon Thread] INFO upgrade.UpgradeFinalizer: Running pre-finalized state validations for unfinalized layout features.
dn2_1    | 2022-06-16 01:14:16,521 [Datanode State Machine Daemon Thread] INFO upgrade.UpgradeFinalizer: Running first upgrade commands for unfinalized layout features.
dn3_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/gson-2.8.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
dn3_1    | STARTUP_MSG:   build = https://github.com/apache/ozone/17d3301a908af2df7683a0c61b8ee3ae8dd41d6a ; compiled by 'runner' on 2022-06-16T00:51Z
dn3_1    | STARTUP_MSG:   java = 11.0.14.1
dn3_1    | ************************************************************/
dn3_1    | 2022-06-16 01:13:40,750 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
dn3_1    | 2022-06-16 01:13:41,207 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
dn3_1    | 2022-06-16 01:13:42,044 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
dn3_1    | 2022-06-16 01:13:43,370 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
dn3_1    | 2022-06-16 01:13:43,373 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
dn3_1    | 2022-06-16 01:13:45,199 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:072040935ca7 ip:10.9.0.17
dn3_1    | 2022-06-16 01:13:47,068 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = DATANODE_SCHEMA_V3 (version = 4)
dn3_1    | 2022-06-16 01:13:48,123 [main] INFO reflections.Reflections: Reflections took 762 ms to scan 2 urls, producing 89 keys and 191 values 
dn3_1    | 2022-06-16 01:13:48,543 [main] INFO upgrade.HDDSLayoutVersionManager: Registering Upgrade Action : DatanodeSchemaV3FinalizeAction
dn3_1    | 2022-06-16 01:13:48,768 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
dn3_1    | 2022-06-16 01:13:49,980 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/hdds/scmUsed: 4096 at 2022-06-16T01:13:17.034Z
dn3_1    | 2022-06-16 01:13:50,055 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
dn3_1    | 2022-06-16 01:13:50,087 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
dn3_1    | 2022-06-16 01:13:50,088 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
dn3_1    | 2022-06-16 01:13:50,261 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
dn3_1    | 2022-06-16 01:13:50,394 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn3_1    | 2022-06-16 01:13:50,427 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/metadata/ratis/scmUsed: 4096 at 2022-06-16T01:13:17.069Z
dn3_1    | 2022-06-16 01:13:50,494 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
dn3_1    | 2022-06-16 01:13:50,495 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
dn3_1    | 2022-06-16 01:13:50,498 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
dn3_1    | 2022-06-16 01:13:50,651 [Thread-3] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
dn3_1    | 2022-06-16 01:13:50,667 [Thread-3] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
dn3_1    | 2022-06-16 01:13:50,667 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
dn3_1    | 2022-06-16 01:14:02,180 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
dn3_1    | 2022-06-16 01:14:02,741 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn3_1    | 2022-06-16 01:14:03,549 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
dn3_1    | 2022-06-16 01:14:04,934 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
dn3_1    | 2022-06-16 01:14:04,939 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
dn3_1    | 2022-06-16 01:14:04,952 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
dn3_1    | 2022-06-16 01:14:04,966 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
dn3_1    | 2022-06-16 01:14:04,967 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2022-06-16 01:14:04,973 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
dn3_1    | 2022-06-16 01:14:04,978 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn3_1    | 2022-06-16 01:14:05,090 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
dn3_1    | 2022-06-16 01:14:05,098 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
dn3_1    | 2022-06-16 01:14:08,047 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
dn3_1    | 2022-06-16 01:14:08,060 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
dn3_1    | 2022-06-16 01:14:08,060 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
dn3_1    | 2022-06-16 01:14:08,066 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn3_1    | 2022-06-16 01:14:08,066 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn3_1    | 2022-06-16 01:14:08,184 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn3_1    | 2022-06-16 01:14:08,206 [32c66434-cc2b-41ce-bc06-c42e833faba3-impl-thread1] INFO server.RaftServer: 32c66434-cc2b-41ce-bc06-c42e833faba3: found a subdirectory /data/metadata/ratis/2577d48d-2a86-4064-a889-f9ecb8551840
dn3_1    | 2022-06-16 01:14:08,291 [32c66434-cc2b-41ce-bc06-c42e833faba3-impl-thread1] INFO server.RaftServer: 32c66434-cc2b-41ce-bc06-c42e833faba3: addNew group-F9ECB8551840:[] returns group-F9ECB8551840:java.util.concurrent.CompletableFuture@3bd8f816[Not completed]
dn3_1    | 2022-06-16 01:14:08,535 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
dn3_1    | 2022-06-16 01:14:08,702 [pool-22-thread-1] INFO server.RaftServer$Division: 32c66434-cc2b-41ce-bc06-c42e833faba3: new RaftServerImpl for group-F9ECB8551840:[] with ContainerStateMachine:uninitialized
dn3_1    | 2022-06-16 01:14:08,761 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn3_1    | 2022-06-16 01:14:08,781 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn3_1    | 2022-06-16 01:14:08,781 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn3_1    | 2022-06-16 01:14:08,782 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn3_1    | 2022-06-16 01:14:08,786 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn3_1    | 2022-06-16 01:14:08,787 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn3_1    | 2022-06-16 01:14:08,934 [pool-22-thread-1] INFO server.RaftServer$Division: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn3_1    | 2022-06-16 01:14:08,945 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn3_1    | 2022-06-16 01:14:08,976 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn3_1    | 2022-06-16 01:14:09,029 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn3_1    | 2022-06-16 01:14:09,171 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/2577d48d-2a86-4064-a889-f9ecb8551840/in_use.lock acquired by nodename 6@072040935ca7
dn3_1    | 2022-06-16 01:14:09,239 [pool-22-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=3, votedFor=32c66434-cc2b-41ce-bc06-c42e833faba3} from /data/metadata/ratis/2577d48d-2a86-4064-a889-f9ecb8551840/current/raft-meta
dn3_1    | 2022-06-16 01:14:09,603 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-F9ECB8551840: Setting the last applied index to (t:3, i:4)
dn3_1    | 2022-06-16 01:14:09,764 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
dn3_1    | 2022-06-16 01:14:10,061 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
dn3_1    | 2022-06-16 01:14:10,503 [main] INFO util.log: Logging initialized @41847ms to org.eclipse.jetty.util.log.Slf4jLog
dn3_1    | 2022-06-16 01:14:11,308 [pool-22-thread-1] INFO server.RaftServer$Division: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840: set configuration 3: [32c66434-cc2b-41ce-bc06-c42e833faba3|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-06-16 01:14:11,321 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn3_1    | 2022-06-16 01:14:11,342 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn3_1    | 2022-06-16 01:14:11,424 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn3_1    | 2022-06-16 01:14:11,450 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2022-06-16 01:14:11,452 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn3_1    | 2022-06-16 01:14:11,617 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2022-06-16 01:14:11,734 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn3_1    | 2022-06-16 01:14:11,734 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn3_1    | 2022-06-16 01:14:11,765 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
dn3_1    | 2022-06-16 01:14:11,811 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/2577d48d-2a86-4064-a889-f9ecb8551840
dn3_1    | 2022-06-16 01:14:11,811 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn3_1    | 2022-06-16 01:14:11,843 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
dn3_1    | 2022-06-16 01:14:11,851 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn3_1    | 2022-06-16 01:14:11,852 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2022-06-16 01:14:11,853 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn3_1    | 2022-06-16 01:14:11,869 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn3_1    | 2022-06-16 01:14:11,874 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn3_1    | 2022-06-16 01:14:11,874 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn3_1    | 2022-06-16 01:14:11,874 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn3_1    | 2022-06-16 01:14:11,941 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
dn3_1    | 2022-06-16 01:14:11,986 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
dn3_1    | 2022-06-16 01:14:11,986 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
dn3_1    | 2022-06-16 01:14:11,986 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
dn3_1    | 2022-06-16 01:14:12,023 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn3_1    | 2022-06-16 01:14:12,034 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn3_1    | 2022-06-16 01:14:12,038 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn3_1    | 2022-06-16 01:14:12,515 [pool-22-thread-1] INFO server.RaftServer$Division: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840: set configuration 0: [32c66434-cc2b-41ce-bc06-c42e833faba3|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-06-16 01:14:12,516 [pool-22-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/2577d48d-2a86-4064-a889-f9ecb8551840/current/log_0-0
dn3_1    | 2022-06-16 01:14:12,616 [pool-22-thread-1] INFO server.RaftServer$Division: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840: set configuration 1: [32c66434-cc2b-41ce-bc06-c42e833faba3|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-06-16 01:14:12,617 [pool-22-thread-1] INFO segmented.LogSegment: Successfully read 2 entries from segment file /data/metadata/ratis/2577d48d-2a86-4064-a889-f9ecb8551840/current/log_1-2
dn3_1    | 2022-06-16 01:14:12,648 [pool-22-thread-1] INFO server.RaftServer$Division: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840: set configuration 3: [32c66434-cc2b-41ce-bc06-c42e833faba3|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-06-16 01:14:12,657 [pool-22-thread-1] INFO segmented.LogSegment: Successfully read 2 entries from segment file /data/metadata/ratis/2577d48d-2a86-4064-a889-f9ecb8551840/current/log_inprogress_3
dn3_1    | 2022-06-16 01:14:12,663 [main] INFO http.HttpServer2: Jetty bound to port 9882
dn3_1    | 2022-06-16 01:14:12,679 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 4
dn1_1    | 2022-06-16 01:14:35,380 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection5] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection5 ELECTION round 0: result REJECTED
dn1_1    | 2022-06-16 01:14:35,380 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection5] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: changes role from CANDIDATE to FOLLOWER at term 10 for REJECTED
dn1_1    | 2022-06-16 01:14:35,381 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection5] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: shutdown 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection5
dn1_1    | 2022-06-16 01:14:35,382 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection5] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState
dn1_1    | 2022-06-16 01:14:35,396 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-LeaderElection4] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-LeaderElection4: ELECTION REJECTED received 2 response(s) and 0 exception(s):
dn1_1    | 2022-06-16 01:14:35,402 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-LeaderElection4] INFO impl.LeaderElection:   Response 0: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c7eeb289-59cc-4c90-a00f-b0c50499b5ba#0:FAIL-t15
dn1_1    | 2022-06-16 01:14:35,405 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-LeaderElection4] INFO impl.LeaderElection:   Response 1: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c3461ed7-1554-428d-9478-8d95583cf36e#0:OK-t15
dn1_1    | 2022-06-16 01:14:35,405 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-LeaderElection4] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-LeaderElection4 ELECTION round 0: result REJECTED
dn1_1    | 2022-06-16 01:14:35,406 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-LeaderElection4] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE: changes role from CANDIDATE to FOLLOWER at term 15 for REJECTED
dn1_1    | 2022-06-16 01:14:35,406 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-LeaderElection4] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: shutdown 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-LeaderElection4
dn1_1    | 2022-06-16 01:14:35,406 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-LeaderElection4] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-FollowerState
dn1_1    | 2022-06-16 01:14:40,428 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.FollowerState: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5045957742ns, electionTimeout:5026ms
dn1_1    | 2022-06-16 01:14:40,429 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: shutdown 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState
dn1_1    | 2022-06-16 01:14:40,429 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: changes role from  FOLLOWER to CANDIDATE at term 10 for changeToCandidate
dn1_1    | 2022-06-16 01:14:40,429 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn1_1    | 2022-06-16 01:14:40,429 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection6
dn1_1    | 2022-06-16 01:14:40,435 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection6] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection6 ELECTION round 0: submit vote requests at term 11 for 19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:14:40,466 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection6] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection6: ELECTION REJECTED received 1 response(s) and 0 exception(s):
dn1_1    | 2022-06-16 01:14:40,466 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection6] INFO impl.LeaderElection:   Response 0: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t11
dn1_1    | 2022-06-16 01:14:40,466 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection6] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection6 ELECTION round 0: result REJECTED
dn1_1    | 2022-06-16 01:14:40,466 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection6] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: changes role from CANDIDATE to FOLLOWER at term 11 for REJECTED
dn1_1    | 2022-06-16 01:14:40,466 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection6] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: shutdown 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection6
dn1_1    | 2022-06-16 01:14:40,467 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection6] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState
dn1_1    | 2022-06-16 01:14:40,492 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE: receive requestVote(ELECTION, c7eeb289-59cc-4c90-a00f-b0c50499b5ba, group-5FC878C6C2DE, 16, (t:13, i:38))
dn1_1    | 2022-06-16 01:14:40,495 [grpc-default-executor-0] INFO impl.VoteContext: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-FOLLOWER: accept ELECTION from c7eeb289-59cc-4c90-a00f-b0c50499b5ba: our priority 0 <= candidate's priority 1
dn1_1    | 2022-06-16 01:14:40,495 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE: changes role from  FOLLOWER to FOLLOWER at term 16 for candidate:c7eeb289-59cc-4c90-a00f-b0c50499b5ba
dn1_1    | 2022-06-16 01:14:40,495 [grpc-default-executor-0] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: shutdown 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-FollowerState
dn1_1    | 2022-06-16 01:14:40,497 [grpc-default-executor-0] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-FollowerState
dn1_1    | 2022-06-16 01:14:40,497 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-FollowerState] INFO impl.FollowerState: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-FollowerState was interrupted
dn1_1    | 2022-06-16 01:14:40,519 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE replies to ELECTION vote request: c7eeb289-59cc-4c90-a00f-b0c50499b5ba<-8b366c76-456d-4ec7-ac8e-95910f7eaaa6#0:OK-t16. Peer's state: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE:t16, leader=null, voted=c7eeb289-59cc-4c90-a00f-b0c50499b5ba, raftlog=8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-SegmentedRaftLog:OPENED:c38, conf=22: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-06-16 01:14:40,821 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-5FC878C6C2DE with new leaderId: c7eeb289-59cc-4c90-a00f-b0c50499b5ba
dn1_1    | 2022-06-16 01:14:40,825 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6-server-thread1] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE: change Leader from null to c7eeb289-59cc-4c90-a00f-b0c50499b5ba at term 16 for appendEntries, leader elected after 23460ms
dn1_1    | 2022-06-16 01:14:40,912 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6-server-thread2] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE: set configuration 39: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-06-16 01:14:40,915 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6-server-thread2] INFO segmented.SegmentedRaftLogWorker: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-SegmentedRaftLogWorker: Rolling segment log-22_38 to index:38
dn1_1    | 2022-06-16 01:14:40,918 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de/current/log_inprogress_22 to /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de/current/log_22-38
dn1_1    | 2022-06-16 01:14:40,931 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-5FC878C6C2DE-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de/current/log_inprogress_39
dn1_1    | 2022-06-16 01:14:45,529 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.FollowerState: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5062020632ns, electionTimeout:5055ms
dn1_1    | 2022-06-16 01:14:45,529 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: shutdown 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState
dn1_1    | 2022-06-16 01:14:45,529 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: changes role from  FOLLOWER to CANDIDATE at term 11 for changeToCandidate
dn1_1    | 2022-06-16 01:14:45,529 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn1_1    | 2022-06-16 01:14:45,529 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection7
dn1_1    | 2022-06-16 01:14:45,533 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection7] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection7 ELECTION round 0: submit vote requests at term 12 for 19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:14:45,549 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection7] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection7: ELECTION REJECTED received 1 response(s) and 0 exception(s):
dn1_1    | 2022-06-16 01:14:45,549 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection7] INFO impl.LeaderElection:   Response 0: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t12
dn1_1    | 2022-06-16 01:14:45,549 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection7] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection7 ELECTION round 0: result REJECTED
dn1_1    | 2022-06-16 01:14:45,549 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection7] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: changes role from CANDIDATE to FOLLOWER at term 12 for REJECTED
dn1_1    | 2022-06-16 01:14:45,549 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection7] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: shutdown 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection7
dn1_1    | 2022-06-16 01:14:45,549 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection7] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState
dn1_1    | 2022-06-16 01:14:50,553 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.FollowerState: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5003225117ns, electionTimeout:5002ms
dn1_1    | 2022-06-16 01:14:50,553 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: shutdown 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState
dn1_1    | 2022-06-16 01:14:50,554 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: changes role from  FOLLOWER to CANDIDATE at term 12 for changeToCandidate
dn1_1    | 2022-06-16 01:14:50,554 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn1_1    | 2022-06-16 01:14:50,554 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection8
dn1_1    | 2022-06-16 01:14:50,561 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection8] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection8 ELECTION round 0: submit vote requests at term 13 for 19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:14:50,580 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection8] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection8: ELECTION REJECTED received 1 response(s) and 0 exception(s):
dn1_1    | 2022-06-16 01:14:50,580 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection8] INFO impl.LeaderElection:   Response 0: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t13
dn2_1    | 2022-06-16 01:14:16,482 [pool-46-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/0934911a-aba3-405f-94e4-cbcf5e919788/in_use.lock acquired by nodename 8@233dd8228c59
dn2_1    | 2022-06-16 01:14:16,534 [pool-46-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=3, votedFor=c7eeb289-59cc-4c90-a00f-b0c50499b5ba} from /data/metadata/ratis/0934911a-aba3-405f-94e4-cbcf5e919788/current/raft-meta
dn2_1    | 2022-06-16 01:14:16,535 [pool-46-thread-1] INFO ratis.ContainerStateMachine: group-CBCF5E919788: Setting the last applied index to (t:3, i:4)
dn2_1    | 2022-06-16 01:14:16,538 [pool-46-thread-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788: set configuration 3: [c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-06-16 01:14:16,538 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn2_1    | 2022-06-16 01:14:16,539 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn2_1    | 2022-06-16 01:14:16,540 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn2_1    | 2022-06-16 01:14:16,540 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2022-06-16 01:14:16,540 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn2_1    | 2022-06-16 01:14:16,540 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2022-06-16 01:14:16,542 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn2_1    | 2022-06-16 01:14:16,545 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn2_1    | 2022-06-16 01:14:16,545 [pool-46-thread-1] INFO segmented.SegmentedRaftLogWorker: new c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/0934911a-aba3-405f-94e4-cbcf5e919788
dn2_1    | 2022-06-16 01:14:16,545 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn2_1    | 2022-06-16 01:14:16,545 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn2_1    | 2022-06-16 01:14:16,546 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2022-06-16 01:14:16,550 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn2_1    | 2022-06-16 01:14:16,552 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn2_1    | 2022-06-16 01:14:16,552 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn2_1    | 2022-06-16 01:14:16,552 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn2_1    | 2022-06-16 01:14:16,553 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn2_1    | 2022-06-16 01:14:16,554 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn2_1    | 2022-06-16 01:14:16,558 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn2_1    | 2022-06-16 01:14:16,566 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn2_1    | 2022-06-16 01:14:16,571 [pool-46-thread-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788: set configuration 0: [c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-06-16 01:14:16,613 [pool-46-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/0934911a-aba3-405f-94e4-cbcf5e919788/current/log_0-0
dn2_1    | 2022-06-16 01:14:16,594 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5e60147a] INFO util.JvmPauseMonitor: Starting JVM pause monitor
dn2_1    | 2022-06-16 01:14:16,616 [pool-46-thread-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788: set configuration 1: [c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-06-16 01:14:16,622 [pool-46-thread-1] INFO segmented.LogSegment: Successfully read 2 entries from segment file /data/metadata/ratis/0934911a-aba3-405f-94e4-cbcf5e919788/current/log_1-2
dn2_1    | 2022-06-16 01:14:16,626 [pool-46-thread-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788: set configuration 3: [c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-06-16 01:14:16,627 [pool-46-thread-1] INFO segmented.LogSegment: Successfully read 2 entries from segment file /data/metadata/ratis/0934911a-aba3-405f-94e4-cbcf5e919788/current/log_inprogress_3
dn2_1    | 2022-06-16 01:14:16,627 [pool-46-thread-1] INFO segmented.SegmentedRaftLogWorker: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 4
dn2_1    | 2022-06-16 01:14:16,640 [pool-46-thread-1] INFO segmented.SegmentedRaftLogWorker: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 2
dn2_1    | 2022-06-16 01:14:16,694 [pool-46-thread-1] INFO raftlog.RaftLog: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-SegmentedRaftLog: commitIndex: updateToMax old=4, new=3, updated? false
dn2_1    | 2022-06-16 01:14:16,696 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn2_1    | 2022-06-16 01:14:16,700 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn2_1    | 2022-06-16 01:14:16,701 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn2_1    | 2022-06-16 01:14:16,701 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn2_1    | 2022-06-16 01:14:16,703 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn2_1    | 2022-06-16 01:14:16,710 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn2_1    | 2022-06-16 01:14:16,711 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn2_1    | 2022-06-16 01:14:16,718 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn2_1    | 2022-06-16 01:14:16,718 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn2_1    | 2022-06-16 01:14:16,718 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn2_1    | 2022-06-16 01:14:16,719 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn2_1    | 2022-06-16 01:14:16,731 [pool-46-thread-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: new RaftServerImpl for group-8C8526B83399:[] with ContainerStateMachine:uninitialized
dn2_1    | 2022-06-16 01:14:16,737 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn2_1    | 2022-06-16 01:14:16,742 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn2_1    | 2022-06-16 01:14:16,742 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn2_1    | 2022-06-16 01:14:16,744 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn2_1    | 2022-06-16 01:14:16,744 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn2_1    | 2022-06-16 01:14:16,751 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn2_1    | 2022-06-16 01:14:16,751 [pool-46-thread-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn2_1    | 2022-06-16 01:14:16,751 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn2_1    | 2022-06-16 01:14:16,752 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn2_1    | 2022-06-16 01:14:16,752 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn2_1    | 2022-06-16 01:14:16,757 [pool-46-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399/in_use.lock acquired by nodename 8@233dd8228c59
dn2_1    | 2022-06-16 01:14:16,757 [pool-46-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=8, votedFor=c3461ed7-1554-428d-9478-8d95583cf36e} from /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399/current/raft-meta
dn2_1    | 2022-06-16 01:14:16,779 [pool-46-thread-1] INFO ratis.ContainerStateMachine: group-8C8526B83399: Setting the last applied index to (t:8, i:28)
dn2_1    | 2022-06-16 01:14:16,779 [pool-46-thread-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: set configuration 19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-06-16 01:14:16,789 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn2_1    | 2022-06-16 01:14:16,789 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn2_1    | 2022-06-16 01:14:16,795 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn2_1    | 2022-06-16 01:14:16,796 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2022-06-16 01:14:16,796 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn2_1    | 2022-06-16 01:14:16,802 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2022-06-16 01:14:16,808 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn2_1    | 2022-06-16 01:14:16,814 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn2_1    | 2022-06-16 01:14:16,814 [pool-46-thread-1] INFO segmented.SegmentedRaftLogWorker: new c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399
dn2_1    | 2022-06-16 01:14:16,814 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn2_1    | 2022-06-16 01:14:16,814 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn2_1    | 2022-06-16 01:14:16,814 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2022-06-16 01:14:16,817 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn2_1    | 2022-06-16 01:14:16,817 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn2_1    | 2022-06-16 01:14:16,817 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn2_1    | 2022-06-16 01:14:16,817 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn2_1    | 2022-06-16 01:14:16,817 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn2_1    | 2022-06-16 01:14:16,835 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn2_1    | 2022-06-16 01:14:16,839 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn2_1    | 2022-06-16 01:14:16,842 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn2_1    | 2022-06-16 01:14:16,843 [pool-46-thread-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: set configuration 0: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-06-16 01:14:16,846 [pool-46-thread-1] INFO segmented.LogSegment: Successfully read 9 entries from segment file /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399/current/log_0-8
dn2_1    | 2022-06-16 01:14:16,870 [pool-46-thread-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: set configuration 9: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-06-16 01:14:12,679 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 2
dn3_1    | 2022-06-16 01:14:12,710 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
dn3_1    | 2022-06-16 01:14:13,058 [main] INFO server.session: DefaultSessionIdManager workerName=node0
dn3_1    | 2022-06-16 01:14:13,074 [main] INFO server.session: No SessionScavenger set, using defaults
dn3_1    | 2022-06-16 01:14:13,111 [main] INFO server.session: node0 Scavenging every 660000ms
dn3_1    | 2022-06-16 01:14:13,252 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@9df564f{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
dn3_1    | 2022-06-16 01:14:13,273 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4b765e92{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
dn3_1    | 2022-06-16 01:14:13,671 [pool-22-thread-1] INFO raftlog.RaftLog: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-SegmentedRaftLog: commitIndex: updateToMax old=4, new=3, updated? false
dn3_1    | 2022-06-16 01:14:13,687 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn3_1    | 2022-06-16 01:14:13,694 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn3_1    | 2022-06-16 01:14:13,694 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn3_1    | 2022-06-16 01:14:13,699 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn3_1    | 2022-06-16 01:14:13,703 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn3_1    | 2022-06-16 01:14:13,704 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn3_1    | 2022-06-16 01:14:14,194 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn3_1    | 2022-06-16 01:14:14,201 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn3_1    | 2022-06-16 01:14:14,207 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn3_1    | 2022-06-16 01:14:14,217 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn3_1    | 2022-06-16 01:14:14,217 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn3_1    | 2022-06-16 01:14:14,467 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@666618d6{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-9607221119181842703/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
dn3_1    | 2022-06-16 01:14:14,547 [main] INFO server.AbstractConnector: Started ServerConnector@457a5b2d{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
dn3_1    | 2022-06-16 01:14:14,547 [main] INFO server.Server: Started @45892ms
dn3_1    | 2022-06-16 01:14:14,555 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
dn3_1    | 2022-06-16 01:14:14,555 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
dn3_1    | 2022-06-16 01:14:14,561 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
dn3_1    | 2022-06-16 01:14:14,586 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
dn3_1    | 2022-06-16 01:14:14,681 [Datanode State Machine Daemon Thread] INFO upgrade.UpgradeFinalizer: Running pre-finalized state validations for unfinalized layout features.
dn3_1    | 2022-06-16 01:14:14,682 [Datanode State Machine Daemon Thread] INFO upgrade.UpgradeFinalizer: Running first upgrade commands for unfinalized layout features.
dn3_1    | 2022-06-16 01:14:14,798 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6cc7c30f] INFO util.JvmPauseMonitor: Starting JVM pause monitor
dn3_1    | 2022-06-16 01:14:18,148 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn3_1    | 2022-06-16 01:14:19,149 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn3_1    | 2022-06-16 01:14:20,980 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
dn3_1    | 2022-06-16 01:14:20,987 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
dn3_1    | 2022-06-16 01:14:21,498 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 32c66434-cc2b-41ce-bc06-c42e833faba3
dn3_1    | 2022-06-16 01:14:21,547 [32c66434-cc2b-41ce-bc06-c42e833faba3-impl-thread1] INFO server.RaftServer$Division: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840: start as a follower, conf=3: [32c66434-cc2b-41ce-bc06-c42e833faba3|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-06-16 01:14:21,566 [32c66434-cc2b-41ce-bc06-c42e833faba3-impl-thread1] INFO server.RaftServer$Division: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840: changes role from      null to FOLLOWER at term 3 for startAsFollower
dn3_1    | 2022-06-16 01:14:21,571 [32c66434-cc2b-41ce-bc06-c42e833faba3-impl-thread1] INFO impl.RoleInfo: 32c66434-cc2b-41ce-bc06-c42e833faba3: start 32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-FollowerState
dn3_1    | 2022-06-16 01:14:21,618 [32c66434-cc2b-41ce-bc06-c42e833faba3-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F9ECB8551840,id=32c66434-cc2b-41ce-bc06-c42e833faba3
dn3_1    | 2022-06-16 01:14:21,636 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.RaftServer: 32c66434-cc2b-41ce-bc06-c42e833faba3: start RPC server
dn3_1    | 2022-06-16 01:14:21,660 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 32c66434-cc2b-41ce-bc06-c42e833faba3: GrpcService started, listening on 9856
dn3_1    | 2022-06-16 01:14:21,666 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 32c66434-cc2b-41ce-bc06-c42e833faba3: GrpcService started, listening on 9857
dn2_1    | 2022-06-16 01:14:16,871 [pool-46-thread-1] INFO segmented.LogSegment: Successfully read 10 entries from segment file /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399/current/log_9-18
dn2_1    | 2022-06-16 01:14:16,877 [pool-46-thread-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: set configuration 19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-06-16 01:14:16,890 [pool-46-thread-1] INFO segmented.LogSegment: Successfully read 10 entries from segment file /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399/current/log_inprogress_19
dn2_1    | 2022-06-16 01:14:16,900 [pool-46-thread-1] INFO segmented.SegmentedRaftLogWorker: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 28
dn2_1    | 2022-06-16 01:14:16,901 [pool-46-thread-1] INFO segmented.SegmentedRaftLogWorker: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 18
dn2_1    | 2022-06-16 01:14:16,902 [pool-46-thread-1] INFO raftlog.RaftLog: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-SegmentedRaftLog: commitIndex: updateToMax old=28, new=27, updated? false
dn2_1    | 2022-06-16 01:14:16,902 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn2_1    | 2022-06-16 01:14:16,904 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn2_1    | 2022-06-16 01:14:16,905 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn2_1    | 2022-06-16 01:14:16,905 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn2_1    | 2022-06-16 01:14:16,905 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn2_1    | 2022-06-16 01:14:16,906 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn2_1    | 2022-06-16 01:14:16,908 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn2_1    | 2022-06-16 01:14:16,920 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn2_1    | 2022-06-16 01:14:16,920 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn2_1    | 2022-06-16 01:14:16,920 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn2_1    | 2022-06-16 01:14:16,920 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn2_1    | 2022-06-16 01:14:17,090 [Datanode State Machine Task Thread - 1] WARN statemachine.SCMConnectionManager: Trying to add an existing SCM Machine to Machines group. Ignoring the request.
dn2_1    | 2022-06-16 01:14:20,886 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
dn2_1    | 2022-06-16 01:14:20,899 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
dn2_1    | 2022-06-16 01:14:21,352 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis c7eeb289-59cc-4c90-a00f-b0c50499b5ba
dn2_1    | 2022-06-16 01:14:21,404 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba-impl-thread1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788: start as a follower, conf=3: [c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-06-16 01:14:21,422 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba-impl-thread1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788: changes role from      null to FOLLOWER at term 3 for startAsFollower
dn2_1    | 2022-06-16 01:14:21,423 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba-impl-thread1] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: start c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-FollowerState
dn2_1    | 2022-06-16 01:14:21,435 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba-impl-thread2] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE: start as a follower, conf=22: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-06-16 01:14:21,439 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba-impl-thread2] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE: changes role from      null to FOLLOWER at term 13 for startAsFollower
dn2_1    | 2022-06-16 01:14:21,441 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba-impl-thread3] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: start as a follower, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-06-16 01:14:21,534 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba-impl-thread3] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: changes role from      null to FOLLOWER at term 8 for startAsFollower
dn2_1    | 2022-06-16 01:14:21,534 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba-impl-thread3] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: start c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState
dn2_1    | 2022-06-16 01:14:21,506 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CBCF5E919788,id=c7eeb289-59cc-4c90-a00f-b0c50499b5ba
dn2_1    | 2022-06-16 01:14:21,441 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba-impl-thread2] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: start c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-FollowerState
dn2_1    | 2022-06-16 01:14:21,554 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba-impl-thread3] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8C8526B83399,id=c7eeb289-59cc-4c90-a00f-b0c50499b5ba
dn2_1    | 2022-06-16 01:14:21,602 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba-impl-thread2] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5FC878C6C2DE,id=c7eeb289-59cc-4c90-a00f-b0c50499b5ba
dn2_1    | 2022-06-16 01:14:21,645 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.RaftServer: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: start RPC server
dn2_1    | 2022-06-16 01:14:21,700 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: GrpcService started, listening on 9856
dn2_1    | 2022-06-16 01:14:21,710 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: GrpcService started, listening on 9857
dn2_1    | 2022-06-16 01:14:21,726 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: GrpcService started, listening on 9858
dn2_1    | 2022-06-16 01:14:21,742 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis c7eeb289-59cc-4c90-a00f-b0c50499b5ba is started using port 9858 for RATIS
dn2_1    | 2022-06-16 01:14:21,742 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis c7eeb289-59cc-4c90-a00f-b0c50499b5ba is started using port 9857 for RATIS_ADMIN
dn2_1    | 2022-06-16 01:14:21,742 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis c7eeb289-59cc-4c90-a00f-b0c50499b5ba is started using port 9856 for RATIS_SERVER
dn2_1    | 2022-06-16 01:14:21,794 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$484/0x0000000840568c40@41103998] INFO util.JvmPauseMonitor: JvmPauseMonitor-c7eeb289-59cc-4c90-a00f-b0c50499b5ba: Started
dn1_1    | 2022-06-16 01:14:50,580 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection8] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection8 ELECTION round 0: result REJECTED
dn1_1    | 2022-06-16 01:14:50,581 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection8] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: changes role from CANDIDATE to FOLLOWER at term 13 for REJECTED
dn1_1    | 2022-06-16 01:14:50,581 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection8] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: shutdown 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection8
dn1_1    | 2022-06-16 01:14:50,581 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection8] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState
dn1_1    | 2022-06-16 01:14:55,596 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.FollowerState: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5015612990ns, electionTimeout:5015ms
dn1_1    | 2022-06-16 01:14:55,597 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: shutdown 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState
dn1_1    | 2022-06-16 01:14:55,597 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: changes role from  FOLLOWER to CANDIDATE at term 13 for changeToCandidate
dn1_1    | 2022-06-16 01:14:55,598 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn1_1    | 2022-06-16 01:14:55,598 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection9
dn1_1    | 2022-06-16 01:14:55,601 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection9] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection9 ELECTION round 0: submit vote requests at term 14 for 19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:14:55,614 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection9] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection9: ELECTION REJECTED received 1 response(s) and 0 exception(s):
dn1_1    | 2022-06-16 01:14:55,614 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection9] INFO impl.LeaderElection:   Response 0: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t14
dn1_1    | 2022-06-16 01:14:55,615 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection9] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection9 ELECTION round 0: result REJECTED
dn1_1    | 2022-06-16 01:14:55,615 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection9] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: changes role from CANDIDATE to FOLLOWER at term 14 for REJECTED
dn1_1    | 2022-06-16 01:14:55,615 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection9] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: shutdown 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection9
dn1_1    | 2022-06-16 01:14:55,615 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection9] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState
dn1_1    | 2022-06-16 01:14:57,619 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn1_1    | 2022-06-16 01:14:57,622 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn1_1    | 2022-06-16 01:14:57,623 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn1_1    | 2022-06-16 01:14:57,624 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn1_1    | 2022-06-16 01:14:57,624 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn1_1    | 2022-06-16 01:14:57,625 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:14:57,626 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn3_1    | 2022-06-16 01:14:21,674 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 32c66434-cc2b-41ce-bc06-c42e833faba3: GrpcService started, listening on 9858
dn3_1    | 2022-06-16 01:14:21,682 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$473/0x0000000840523040@2ae6410e] INFO util.JvmPauseMonitor: JvmPauseMonitor-32c66434-cc2b-41ce-bc06-c42e833faba3: Started
dn3_1    | 2022-06-16 01:14:21,682 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 32c66434-cc2b-41ce-bc06-c42e833faba3 is started using port 9858 for RATIS
dn3_1    | 2022-06-16 01:14:21,682 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 32c66434-cc2b-41ce-bc06-c42e833faba3 is started using port 9857 for RATIS_ADMIN
dn4_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
dn4_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
dn4_1    | 2022-06-16 01:13:39,879 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
dn4_1    | /************************************************************
dn4_1    | STARTUP_MSG: Starting HddsDatanodeService
dn4_1    | STARTUP_MSG:   host = 3b053cfb9aaa/10.9.0.18
dn4_1    | STARTUP_MSG:   args = []
dn4_1    | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
dn4_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/gson-2.8.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
dn4_1    | STARTUP_MSG:   build = https://github.com/apache/ozone/17d3301a908af2df7683a0c61b8ee3ae8dd41d6a ; compiled by 'runner' on 2022-06-16T00:51Z
dn4_1    | STARTUP_MSG:   java = 11.0.14.1
dn4_1    | ************************************************************/
dn4_1    | 2022-06-16 01:13:39,916 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
dn4_1    | 2022-06-16 01:13:40,337 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
dn4_1    | 2022-06-16 01:13:41,296 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
dn4_1    | 2022-06-16 01:13:42,492 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
dn4_1    | 2022-06-16 01:13:42,512 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
dn4_1    | 2022-06-16 01:13:44,284 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:3b053cfb9aaa ip:10.9.0.18
dn4_1    | 2022-06-16 01:13:46,020 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = DATANODE_SCHEMA_V3 (version = 4)
dn4_1    | 2022-06-16 01:13:47,419 [main] INFO reflections.Reflections: Reflections took 1040 ms to scan 2 urls, producing 89 keys and 191 values 
dn4_1    | 2022-06-16 01:13:47,866 [main] INFO upgrade.HDDSLayoutVersionManager: Registering Upgrade Action : DatanodeSchemaV3FinalizeAction
dn4_1    | 2022-06-16 01:13:48,096 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
dn4_1    | 2022-06-16 01:13:49,461 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/hdds/scmUsed: 8192 at 2022-06-16T01:13:17.084Z
dn4_1    | 2022-06-16 01:13:49,590 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
dn4_1    | 2022-06-16 01:13:49,592 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
dn4_1    | 2022-06-16 01:13:49,619 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
dn4_1    | 2022-06-16 01:13:49,803 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
dn4_1    | 2022-06-16 01:13:50,007 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn4_1    | 2022-06-16 01:13:50,042 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/metadata/ratis/scmUsed: 4096 at 2022-06-16T01:13:17.091Z
dn4_1    | 2022-06-16 01:13:50,058 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
dn4_1    | 2022-06-16 01:13:50,064 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
dn4_1    | 2022-06-16 01:13:50,064 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
dn4_1    | 2022-06-16 01:13:50,253 [Thread-3] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
dn4_1    | 2022-06-16 01:13:50,258 [Thread-3] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
dn4_1    | 2022-06-16 01:13:50,265 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
dn4_1    | 2022-06-16 01:14:02,996 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
dn4_1    | 2022-06-16 01:14:03,497 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn4_1    | 2022-06-16 01:14:03,892 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
dn4_1    | 2022-06-16 01:14:04,849 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
dn4_1    | 2022-06-16 01:14:04,849 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
dn4_1    | 2022-06-16 01:14:04,884 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
dn4_1    | 2022-06-16 01:14:04,900 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
dn4_1    | 2022-06-16 01:14:04,901 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn4_1    | 2022-06-16 01:14:04,944 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
dn4_1    | 2022-06-16 01:14:04,945 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn4_1    | 2022-06-16 01:14:05,192 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
dn4_1    | 2022-06-16 01:14:05,210 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
dn4_1    | 2022-06-16 01:14:07,686 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
dn4_1    | 2022-06-16 01:14:07,708 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
dn4_1    | 2022-06-16 01:14:07,712 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
dn4_1    | 2022-06-16 01:14:07,718 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn4_1    | 2022-06-16 01:14:07,730 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn4_1    | 2022-06-16 01:14:07,771 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn4_1    | 2022-06-16 01:14:07,790 [835c1189-b066-4617-a285-c9fdbaf1d7b5-impl-thread1] INFO server.RaftServer: 835c1189-b066-4617-a285-c9fdbaf1d7b5: found a subdirectory /data/metadata/ratis/bb9bc3de-e3de-455a-8b75-c8ce16ab84ae
dn4_1    | 2022-06-16 01:14:07,888 [835c1189-b066-4617-a285-c9fdbaf1d7b5-impl-thread1] INFO server.RaftServer: 835c1189-b066-4617-a285-c9fdbaf1d7b5: addNew group-C8CE16AB84AE:[] returns group-C8CE16AB84AE:java.util.concurrent.CompletableFuture@6b619375[Not completed]
dn4_1    | 2022-06-16 01:14:08,082 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
dn4_1    | 2022-06-16 01:14:08,156 [pool-22-thread-1] INFO server.RaftServer$Division: 835c1189-b066-4617-a285-c9fdbaf1d7b5: new RaftServerImpl for group-C8CE16AB84AE:[] with ContainerStateMachine:uninitialized
dn4_1    | 2022-06-16 01:14:08,215 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn4_1    | 2022-06-16 01:14:08,238 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn4_1    | 2022-06-16 01:14:08,244 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn4_1    | 2022-06-16 01:14:08,244 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn4_1    | 2022-06-16 01:14:08,246 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn4_1    | 2022-06-16 01:14:08,259 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn4_1    | 2022-06-16 01:14:08,387 [pool-22-thread-1] INFO server.RaftServer$Division: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn4_1    | 2022-06-16 01:14:08,391 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn4_1    | 2022-06-16 01:14:08,432 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn4_1    | 2022-06-16 01:14:08,432 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn4_1    | 2022-06-16 01:14:08,623 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/bb9bc3de-e3de-455a-8b75-c8ce16ab84ae/in_use.lock acquired by nodename 12@3b053cfb9aaa
dn4_1    | 2022-06-16 01:14:08,690 [pool-22-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=3, votedFor=835c1189-b066-4617-a285-c9fdbaf1d7b5} from /data/metadata/ratis/bb9bc3de-e3de-455a-8b75-c8ce16ab84ae/current/raft-meta
dn4_1    | 2022-06-16 01:14:08,989 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-C8CE16AB84AE: Setting the last applied index to (t:3, i:4)
dn4_1    | 2022-06-16 01:14:09,135 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
dn4_1    | 2022-06-16 01:14:09,306 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
dn4_1    | 2022-06-16 01:14:09,733 [main] INFO util.log: Logging initialized @41979ms to org.eclipse.jetty.util.log.Slf4jLog
dn4_1    | 2022-06-16 01:14:10,584 [pool-22-thread-1] INFO server.RaftServer$Division: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE: set configuration 3: [835c1189-b066-4617-a285-c9fdbaf1d7b5|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1], old=null
dn4_1    | 2022-06-16 01:14:10,593 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn4_1    | 2022-06-16 01:14:10,599 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn4_1    | 2022-06-16 01:14:10,689 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn4_1    | 2022-06-16 01:14:10,702 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn4_1    | 2022-06-16 01:14:10,718 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn4_1    | 2022-06-16 01:14:10,894 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn4_1    | 2022-06-16 01:14:11,019 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn4_1    | 2022-06-16 01:14:11,027 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
dn4_1    | 2022-06-16 01:14:11,034 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn4_1    | 2022-06-16 01:14:11,087 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
dn4_1    | 2022-06-16 01:14:11,103 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/bb9bc3de-e3de-455a-8b75-c8ce16ab84ae
dn4_1    | 2022-06-16 01:14:11,105 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn4_1    | 2022-06-16 01:14:11,106 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn4_1    | 2022-06-16 01:14:11,113 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn4_1    | 2022-06-16 01:14:11,144 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn4_1    | 2022-06-16 01:14:11,154 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn4_1    | 2022-06-16 01:14:11,163 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn4_1    | 2022-06-16 01:14:11,166 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn4_1    | 2022-06-16 01:14:11,178 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn4_1    | 2022-06-16 01:14:11,182 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
dn4_1    | 2022-06-16 01:14:11,207 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
dn4_1    | 2022-06-16 01:14:11,218 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
dn4_1    | 2022-06-16 01:14:11,218 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
dn4_1    | 2022-06-16 01:14:11,280 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn4_1    | 2022-06-16 01:14:11,295 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn4_1    | 2022-06-16 01:14:11,322 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn4_1    | 2022-06-16 01:14:11,712 [main] INFO http.HttpServer2: Jetty bound to port 9882
dn4_1    | 2022-06-16 01:14:11,787 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
dn4_1    | 2022-06-16 01:14:11,815 [pool-22-thread-1] INFO server.RaftServer$Division: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE: set configuration 0: [835c1189-b066-4617-a285-c9fdbaf1d7b5|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1], old=null
dn4_1    | 2022-06-16 01:14:11,856 [pool-22-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/bb9bc3de-e3de-455a-8b75-c8ce16ab84ae/current/log_0-0
dn4_1    | 2022-06-16 01:14:11,914 [pool-22-thread-1] INFO server.RaftServer$Division: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE: set configuration 1: [835c1189-b066-4617-a285-c9fdbaf1d7b5|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1], old=null
dn4_1    | 2022-06-16 01:14:11,924 [pool-22-thread-1] INFO segmented.LogSegment: Successfully read 2 entries from segment file /data/metadata/ratis/bb9bc3de-e3de-455a-8b75-c8ce16ab84ae/current/log_1-2
dn4_1    | 2022-06-16 01:14:11,957 [pool-22-thread-1] INFO server.RaftServer$Division: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE: set configuration 3: [835c1189-b066-4617-a285-c9fdbaf1d7b5|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1], old=null
dn4_1    | 2022-06-16 01:14:11,964 [pool-22-thread-1] INFO segmented.LogSegment: Successfully read 2 entries from segment file /data/metadata/ratis/bb9bc3de-e3de-455a-8b75-c8ce16ab84ae/current/log_inprogress_3
dn3_1    | 2022-06-16 01:14:21,682 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 32c66434-cc2b-41ce-bc06-c42e833faba3 is started using port 9856 for RATIS_SERVER
dn3_1    | 2022-06-16 01:14:26,638 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-FollowerState] INFO impl.FollowerState: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5067786958ns, electionTimeout:5049ms
dn3_1    | 2022-06-16 01:14:26,640 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-FollowerState] INFO impl.RoleInfo: 32c66434-cc2b-41ce-bc06-c42e833faba3: shutdown 32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-FollowerState
dn3_1    | 2022-06-16 01:14:26,640 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-FollowerState] INFO server.RaftServer$Division: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
dn3_1    | 2022-06-16 01:14:26,661 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn3_1    | 2022-06-16 01:14:26,670 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-FollowerState] INFO impl.RoleInfo: 32c66434-cc2b-41ce-bc06-c42e833faba3: start 32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-LeaderElection1
dn3_1    | 2022-06-16 01:14:26,866 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-LeaderElection1] INFO impl.LeaderElection: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-LeaderElection1 ELECTION round 0: submit vote requests at term 4 for 3: [32c66434-cc2b-41ce-bc06-c42e833faba3|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-06-16 01:14:26,874 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-LeaderElection1] INFO impl.LeaderElection: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-LeaderElection1 ELECTION round 0: result PASSED (term=4)
dn3_1    | 2022-06-16 01:14:26,875 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-LeaderElection1] INFO impl.RoleInfo: 32c66434-cc2b-41ce-bc06-c42e833faba3: shutdown 32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-LeaderElection1
dn3_1    | 2022-06-16 01:14:26,878 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-LeaderElection1] INFO server.RaftServer$Division: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840: changes role from CANDIDATE to LEADER at term 4 for changeToLeader
dn3_1    | 2022-06-16 01:14:26,880 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-F9ECB8551840 with new leaderId: 32c66434-cc2b-41ce-bc06-c42e833faba3
dn3_1    | 2022-06-16 01:14:26,899 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-LeaderElection1] INFO server.RaftServer$Division: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840: change Leader from null to 32c66434-cc2b-41ce-bc06-c42e833faba3 at term 4 for becomeLeader, leader elected after 15571ms
dn3_1    | 2022-06-16 01:14:26,978 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn3_1    | 2022-06-16 01:14:27,046 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn3_1    | 2022-06-16 01:14:27,055 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn3_1    | 2022-06-16 01:14:27,150 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn3_1    | 2022-06-16 01:14:27,172 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn3_1    | 2022-06-16 01:14:27,176 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn3_1    | 2022-06-16 01:14:27,237 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn3_1    | 2022-06-16 01:14:27,262 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn3_1    | 2022-06-16 01:14:27,271 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-LeaderElection1] INFO impl.RoleInfo: 32c66434-cc2b-41ce-bc06-c42e833faba3: start 32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-LeaderStateImpl
dn3_1    | 2022-06-16 01:14:27,372 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-SegmentedRaftLogWorker: Rolling segment log-3_4 to index:4
dn3_1    | 2022-06-16 01:14:27,409 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/2577d48d-2a86-4064-a889-f9ecb8551840/current/log_inprogress_3 to /data/metadata/ratis/2577d48d-2a86-4064-a889-f9ecb8551840/current/log_3-4
dn3_1    | 2022-06-16 01:14:27,469 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/2577d48d-2a86-4064-a889-f9ecb8551840/current/log_inprogress_5
dn3_1    | 2022-06-16 01:14:27,501 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840-LeaderElection1] INFO server.RaftServer$Division: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-F9ECB8551840: set configuration 5: [32c66434-cc2b-41ce-bc06-c42e833faba3|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-06-16 01:14:57,903 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn3_1    | 2022-06-16 01:14:57,905 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn3_1    | 2022-06-16 01:14:57,906 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn3_1    | 2022-06-16 01:14:57,906 [Command processor thread] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: ERASURE_CODED_STORAGE_SUPPORT.
dn3_1    | 2022-06-16 01:14:57,913 [Command processor thread] INFO upgrade.AbstractLayoutVersionManager: Layout feature ERASURE_CODED_STORAGE_SUPPORT has been finalized.
dn3_1    | 2022-06-16 01:14:57,914 [Command processor thread] INFO upgrade.UpgradeFinalizer: Running finalization actions for layout feature: DATANODE_SCHEMA_V3
dn3_1    | 2022-06-16 01:14:57,914 [Command processor thread] INFO upgrade.DatanodeSchemaV3FinalizeAction: Upgrading Datanode volume layout for Schema V3 support.
dn3_1    | 2022-06-16 01:14:57,958 [Command processor thread] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-3e3c8fff-8818-4ab8-8118-66b81944a69d/DS-a55e0e94-2126-40a7-9b53-540b0d9a2d0f/container.db for volume DS-a55e0e94-2126-40a7-9b53-540b0d9a2d0f
dn3_1    | 2022-06-16 01:14:57,962 [Command processor thread] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-3e3c8fff-8818-4ab8-8118-66b81944a69d/DS-a55e0e94-2126-40a7-9b53-540b0d9a2d0f/container.db for volume DS-a55e0e94-2126-40a7-9b53-540b0d9a2d0f
dn4_1    | 2022-06-16 01:14:11,994 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 4
dn4_1    | 2022-06-16 01:14:11,996 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 2
dn4_1    | 2022-06-16 01:14:12,357 [main] INFO server.session: DefaultSessionIdManager workerName=node0
dn4_1    | 2022-06-16 01:14:12,380 [main] INFO server.session: No SessionScavenger set, using defaults
dn4_1    | 2022-06-16 01:14:12,395 [main] INFO server.session: node0 Scavenging every 660000ms
dn4_1    | 2022-06-16 01:14:12,571 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4b765e92{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
dn4_1    | 2022-06-16 01:14:12,590 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@261b9a37{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
dn4_1    | 2022-06-16 01:14:12,944 [pool-22-thread-1] INFO raftlog.RaftLog: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-SegmentedRaftLog: commitIndex: updateToMax old=4, new=3, updated? false
dn4_1    | 2022-06-16 01:14:13,003 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn4_1    | 2022-06-16 01:14:13,011 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn4_1    | 2022-06-16 01:14:13,014 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn4_1    | 2022-06-16 01:14:13,016 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn4_1    | 2022-06-16 01:14:13,029 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn4_1    | 2022-06-16 01:14:13,038 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn4_1    | 2022-06-16 01:14:13,500 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn4_1    | 2022-06-16 01:14:13,569 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn4_1    | 2022-06-16 01:14:13,576 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn4_1    | 2022-06-16 01:14:13,580 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn4_1    | 2022-06-16 01:14:13,580 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn4_1    | 2022-06-16 01:14:13,627 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@73a6cc79{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-13748625589580838840/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
dn4_1    | 2022-06-16 01:14:13,703 [main] INFO server.AbstractConnector: Started ServerConnector@3086f480{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
dn4_1    | 2022-06-16 01:14:13,714 [main] INFO server.Server: Started @45961ms
dn4_1    | 2022-06-16 01:14:13,774 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
dn4_1    | 2022-06-16 01:14:13,774 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
dn4_1    | 2022-06-16 01:14:13,776 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
dn4_1    | 2022-06-16 01:14:13,791 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
dn4_1    | 2022-06-16 01:14:13,926 [Datanode State Machine Daemon Thread] INFO upgrade.UpgradeFinalizer: Running pre-finalized state validations for unfinalized layout features.
dn4_1    | 2022-06-16 01:14:13,928 [Datanode State Machine Daemon Thread] INFO upgrade.UpgradeFinalizer: Running first upgrade commands for unfinalized layout features.
dn4_1    | 2022-06-16 01:14:13,972 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@71be25af] INFO util.JvmPauseMonitor: Starting JVM pause monitor
dn4_1    | 2022-06-16 01:14:17,466 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn4_1    | 2022-06-16 01:14:18,467 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn4_1    | 2022-06-16 01:14:19,991 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
dn4_1    | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
dn4_1    | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
dn4_1    | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:660)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:294)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:485)
dn4_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn4_1    | Caused by: java.util.concurrent.TimeoutException
dn4_1    | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
dn4_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn4_1    | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
dn4_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn4_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn4_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn4_1    | 	... 1 more
dn4_1    | 2022-06-16 01:14:20,911 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
dn4_1    | 2022-06-16 01:14:20,932 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
dn4_1    | 2022-06-16 01:14:21,337 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 835c1189-b066-4617-a285-c9fdbaf1d7b5
dn4_1    | 2022-06-16 01:14:21,458 [835c1189-b066-4617-a285-c9fdbaf1d7b5-impl-thread1] INFO server.RaftServer$Division: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE: start as a follower, conf=3: [835c1189-b066-4617-a285-c9fdbaf1d7b5|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-06-16 01:14:57,962 [Command processor thread] INFO upgrade.DatanodeSchemaV3FinalizeAction: Schema V3 is disabled. Won't load RocksDB in upgrade.
dn3_1    | 2022-06-16 01:14:57,964 [Command processor thread] INFO upgrade.AbstractLayoutVersionManager: Layout feature DATANODE_SCHEMA_V3 has been finalized.
dn3_1    | 2022-06-16 01:14:57,964 [Command processor thread] INFO upgrade.AbstractLayoutVersionManager: Finalization is complete.
dn3_1    | 2022-06-16 01:14:57,964 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization is done.
dn3_1    | 2022-06-16 01:15:57,920 [pool-22-thread-1] INFO server.RaftServer$Division: 32c66434-cc2b-41ce-bc06-c42e833faba3: new RaftServerImpl for group-A4053E55F144:[32c66434-cc2b-41ce-bc06-c42e833faba3|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:1] with ContainerStateMachine:uninitialized
dn3_1    | 2022-06-16 01:15:57,920 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn3_1    | 2022-06-16 01:15:57,920 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn3_1    | 2022-06-16 01:15:57,920 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn3_1    | 2022-06-16 01:15:57,921 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn3_1    | 2022-06-16 01:15:57,921 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn3_1    | 2022-06-16 01:15:57,921 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn3_1    | 2022-06-16 01:15:57,921 [pool-22-thread-1] INFO server.RaftServer$Division: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144: ConfigurationManager, init=-1: [32c66434-cc2b-41ce-bc06-c42e833faba3|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:1], old=null, confs=<EMPTY_MAP>
dn3_1    | 2022-06-16 01:15:57,921 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn3_1    | 2022-06-16 01:15:57,922 [Command processor thread] INFO server.RaftServer: 32c66434-cc2b-41ce-bc06-c42e833faba3: addNew group-A4053E55F144:[32c66434-cc2b-41ce-bc06-c42e833faba3|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:1] returns group-A4053E55F144:java.util.concurrent.CompletableFuture@4e4f30d6[Not completed]
dn3_1    | 2022-06-16 01:15:57,923 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn3_1    | 2022-06-16 01:15:57,923 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn3_1    | 2022-06-16 01:15:57,923 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/28ac5e1e-72b1-40fd-a3cf-a4053e55f144 does not exist. Creating ...
dn3_1    | 2022-06-16 01:15:57,926 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/28ac5e1e-72b1-40fd-a3cf-a4053e55f144/in_use.lock acquired by nodename 6@072040935ca7
dn3_1    | 2022-06-16 01:15:57,928 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/28ac5e1e-72b1-40fd-a3cf-a4053e55f144 has been successfully formatted.
dn3_1    | 2022-06-16 01:15:57,928 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-A4053E55F144: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn3_1    | 2022-06-16 01:15:57,928 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn3_1    | 2022-06-16 01:15:57,928 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn3_1    | 2022-06-16 01:15:57,928 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn3_1    | 2022-06-16 01:15:57,928 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2022-06-16 01:15:57,929 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn3_1    | 2022-06-16 01:15:57,929 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2022-06-16 01:15:57,929 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn3_1    | 2022-06-16 01:15:57,930 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn3_1    | 2022-06-16 01:15:57,930 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/28ac5e1e-72b1-40fd-a3cf-a4053e55f144
dn3_1    | 2022-06-16 01:15:57,930 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn3_1    | 2022-06-16 01:15:57,930 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn3_1    | 2022-06-16 01:15:57,930 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2022-06-16 01:15:57,930 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn3_1    | 2022-06-16 01:15:57,930 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn3_1    | 2022-06-16 01:15:57,930 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn3_1    | 2022-06-16 01:15:57,930 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn3_1    | 2022-06-16 01:15:57,930 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn3_1    | 2022-06-16 01:15:57,931 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn3_1    | 2022-06-16 01:15:57,931 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn3_1    | 2022-06-16 01:15:57,931 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn3_1    | 2022-06-16 01:15:57,932 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn3_1    | 2022-06-16 01:15:57,932 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn3_1    | 2022-06-16 01:15:57,934 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn3_1    | 2022-06-16 01:15:57,934 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn3_1    | 2022-06-16 01:15:57,934 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn3_1    | 2022-06-16 01:15:57,934 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn3_1    | 2022-06-16 01:15:57,934 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn3_1    | 2022-06-16 01:15:57,934 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn3_1    | 2022-06-16 01:15:57,935 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn2_1    | 2022-06-16 01:14:26,562 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-FollowerState] INFO impl.FollowerState: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5139408805ns, electionTimeout:5054ms
dn2_1    | 2022-06-16 01:14:26,564 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-FollowerState] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: shutdown c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-FollowerState
dn2_1    | 2022-06-16 01:14:26,564 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-FollowerState] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
dn2_1    | 2022-06-16 01:14:26,578 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn2_1    | 2022-06-16 01:14:26,578 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-FollowerState] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: start c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-LeaderElection1
dn2_1    | 2022-06-16 01:14:26,729 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-FollowerState] INFO impl.FollowerState: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5288179821ns, electionTimeout:5078ms
dn2_1    | 2022-06-16 01:14:26,732 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-FollowerState] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: shutdown c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-FollowerState
dn2_1    | 2022-06-16 01:14:26,732 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-FollowerState] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE: changes role from  FOLLOWER to CANDIDATE at term 13 for changeToCandidate
dn2_1    | 2022-06-16 01:14:26,732 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn2_1    | 2022-06-16 01:14:26,732 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-FollowerState] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: start c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection2
dn2_1    | 2022-06-16 01:14:26,753 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection2] INFO impl.LeaderElection: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection2 ELECTION round 0: submit vote requests at term 14 for 22: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-06-16 01:14:26,789 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState] INFO impl.FollowerState: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5255051879ns, electionTimeout:5151ms
dn2_1    | 2022-06-16 01:14:26,789 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: shutdown c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState
dn2_1    | 2022-06-16 01:14:26,794 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: changes role from  FOLLOWER to CANDIDATE at term 8 for changeToCandidate
dn2_1    | 2022-06-16 01:14:26,794 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn2_1    | 2022-06-16 01:14:26,794 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: start c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection3
dn2_1    | 2022-06-16 01:14:26,767 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-LeaderElection1] INFO impl.LeaderElection: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-LeaderElection1 ELECTION round 0: submit vote requests at term 4 for 3: [c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-06-16 01:14:26,894 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-LeaderElection1] INFO impl.LeaderElection: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-LeaderElection1 ELECTION round 0: result PASSED (term=4)
dn2_1    | 2022-06-16 01:14:26,888 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection3] INFO impl.LeaderElection: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection3 ELECTION round 0: submit vote requests at term 9 for 19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-06-16 01:14:26,904 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-LeaderElection1] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: shutdown c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-LeaderElection1
dn2_1    | 2022-06-16 01:14:26,906 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-LeaderElection1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788: changes role from CANDIDATE to LEADER at term 4 for changeToLeader
dn2_1    | 2022-06-16 01:14:26,908 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-CBCF5E919788 with new leaderId: c7eeb289-59cc-4c90-a00f-b0c50499b5ba
dn2_1    | 2022-06-16 01:14:27,267 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-LeaderElection1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788: change Leader from null to c7eeb289-59cc-4c90-a00f-b0c50499b5ba at term 4 for becomeLeader, leader elected after 10369ms
dn2_1    | 2022-06-16 01:14:27,353 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn2_1    | 2022-06-16 01:14:27,464 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn2_1    | 2022-06-16 01:14:27,494 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn2_1    | 2022-06-16 01:14:27,533 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn2_1    | 2022-06-16 01:14:27,598 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn2_1    | 2022-06-16 01:14:27,626 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn2_1    | 2022-06-16 01:14:27,644 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn3_1    | 2022-06-16 01:15:57,935 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn3_1    | 2022-06-16 01:15:57,936 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn3_1    | 2022-06-16 01:15:57,936 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn3_1    | 2022-06-16 01:15:57,936 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn3_1    | 2022-06-16 01:15:57,936 [pool-22-thread-1] INFO server.RaftServer$Division: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144: start as a follower, conf=-1: [32c66434-cc2b-41ce-bc06-c42e833faba3|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:1], old=null
dn3_1    | 2022-06-16 01:15:57,936 [pool-22-thread-1] INFO server.RaftServer$Division: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn3_1    | 2022-06-16 01:15:57,936 [pool-22-thread-1] INFO impl.RoleInfo: 32c66434-cc2b-41ce-bc06-c42e833faba3: start 32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-FollowerState
dn3_1    | 2022-06-16 01:15:57,946 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A4053E55F144,id=32c66434-cc2b-41ce-bc06-c42e833faba3
dn3_1    | 2022-06-16 01:15:57,955 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=28ac5e1e-72b1-40fd-a3cf-a4053e55f144
dn3_1    | 2022-06-16 01:15:57,956 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=28ac5e1e-72b1-40fd-a3cf-a4053e55f144.
dn3_1    | 2022-06-16 01:16:03,039 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-FollowerState] INFO impl.FollowerState: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5103156255ns, electionTimeout:5092ms
dn3_1    | 2022-06-16 01:16:03,040 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-FollowerState] INFO impl.RoleInfo: 32c66434-cc2b-41ce-bc06-c42e833faba3: shutdown 32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-FollowerState
dn3_1    | 2022-06-16 01:16:03,040 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-FollowerState] INFO server.RaftServer$Division: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
dn3_1    | 2022-06-16 01:16:03,041 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn3_1    | 2022-06-16 01:16:03,041 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-FollowerState] INFO impl.RoleInfo: 32c66434-cc2b-41ce-bc06-c42e833faba3: start 32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-LeaderElection2
dn3_1    | 2022-06-16 01:16:03,047 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-LeaderElection2] INFO impl.LeaderElection: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [32c66434-cc2b-41ce-bc06-c42e833faba3|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:1], old=null
dn3_1    | 2022-06-16 01:16:03,047 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-LeaderElection2] INFO impl.LeaderElection: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-LeaderElection2 ELECTION round 0: result PASSED (term=1)
dn3_1    | 2022-06-16 01:16:03,047 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-LeaderElection2] INFO impl.RoleInfo: 32c66434-cc2b-41ce-bc06-c42e833faba3: shutdown 32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-LeaderElection2
dn3_1    | 2022-06-16 01:16:03,047 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-LeaderElection2] INFO server.RaftServer$Division: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
dn3_1    | 2022-06-16 01:16:03,047 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A4053E55F144 with new leaderId: 32c66434-cc2b-41ce-bc06-c42e833faba3
dn3_1    | 2022-06-16 01:16:03,048 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-LeaderElection2] INFO server.RaftServer$Division: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144: change Leader from null to 32c66434-cc2b-41ce-bc06-c42e833faba3 at term 1 for becomeLeader, leader elected after 5119ms
dn3_1    | 2022-06-16 01:16:03,048 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn3_1    | 2022-06-16 01:16:03,048 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn3_1    | 2022-06-16 01:16:03,048 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn3_1    | 2022-06-16 01:16:03,049 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn3_1    | 2022-06-16 01:16:03,049 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn3_1    | 2022-06-16 01:16:03,049 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn3_1    | 2022-06-16 01:16:03,050 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn3_1    | 2022-06-16 01:16:03,050 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn3_1    | 2022-06-16 01:16:03,050 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-LeaderElection2] INFO impl.RoleInfo: 32c66434-cc2b-41ce-bc06-c42e833faba3: start 32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-LeaderStateImpl
dn3_1    | 2022-06-16 01:16:03,050 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-SegmentedRaftLogWorker: Starting segment from index:0
dn3_1    | 2022-06-16 01:16:03,054 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/28ac5e1e-72b1-40fd-a3cf-a4053e55f144/current/log_inprogress_0
dn3_1    | 2022-06-16 01:16:03,055 [32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144-LeaderElection2] INFO server.RaftServer$Division: 32c66434-cc2b-41ce-bc06-c42e833faba3@group-A4053E55F144: set configuration 0: [32c66434-cc2b-41ce-bc06-c42e833faba3|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:14:57,627 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn1_1    | 2022-06-16 01:14:57,627 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn1_1    | 2022-06-16 01:14:57,627 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn1_1    | 2022-06-16 01:14:57,627 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn1_1    | 2022-06-16 01:14:57,627 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn1_1    | 2022-06-16 01:14:57,627 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:14:57,628 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:14:57,628 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn1_1    | 2022-06-16 01:14:57,629 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn1_1    | 2022-06-16 01:14:57,629 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn1_1    | 2022-06-16 01:14:57,629 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn1_1    | 2022-06-16 01:14:57,629 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn1_1    | 2022-06-16 01:14:57,629 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:14:57,630 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:14:57,630 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn1_1    | 2022-06-16 01:14:57,630 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn1_1    | 2022-06-16 01:14:57,630 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
om1_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1    | 2022-06-16 01:13:42,074 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1    | /************************************************************
om1_1    | STARTUP_MSG: Starting OzoneManager
om1_1    | STARTUP_MSG:   host = 61c78f4b9f66/10.9.0.11
om1_1    | STARTUP_MSG:   args = [--upgrade]
om1_1    | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
dn2_1    | 2022-06-16 01:14:27,709 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn2_1    | 2022-06-16 01:14:27,743 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-LeaderElection1] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: start c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-LeaderStateImpl
dn2_1    | 2022-06-16 01:14:27,837 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-SegmentedRaftLogWorker: Rolling segment log-3_4 to index:4
dn2_1    | 2022-06-16 01:14:27,887 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/0934911a-aba3-405f-94e4-cbcf5e919788/current/log_inprogress_3 to /data/metadata/ratis/0934911a-aba3-405f-94e4-cbcf5e919788/current/log_3-4
dn2_1    | 2022-06-16 01:14:27,929 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/0934911a-aba3-405f-94e4-cbcf5e919788/current/log_inprogress_5
dn2_1    | 2022-06-16 01:14:27,965 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788-LeaderElection1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-CBCF5E919788: set configuration 5: [c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-06-16 01:14:30,093 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE: receive requestVote(ELECTION, c3461ed7-1554-428d-9478-8d95583cf36e, group-5FC878C6C2DE, 14, (t:13, i:38))
dn2_1    | 2022-06-16 01:14:30,097 [grpc-default-executor-1] INFO impl.VoteContext: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-CANDIDATE: reject ELECTION from c3461ed7-1554-428d-9478-8d95583cf36e: already has voted for c7eeb289-59cc-4c90-a00f-b0c50499b5ba at current term 14
dn2_1    | 2022-06-16 01:14:30,108 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE replies to ELECTION vote request: c3461ed7-1554-428d-9478-8d95583cf36e<-c7eeb289-59cc-4c90-a00f-b0c50499b5ba#0:FAIL-t14. Peer's state: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE:t14, leader=null, voted=c7eeb289-59cc-4c90-a00f-b0c50499b5ba, raftlog=c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-SegmentedRaftLog:OPENED:c38, conf=22: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-06-16 01:14:30,109 [grpc-default-executor-0] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: receive requestVote(ELECTION, c3461ed7-1554-428d-9478-8d95583cf36e, group-8C8526B83399, 9, (t:8, i:28))
dn2_1    | 2022-06-16 01:14:30,130 [grpc-default-executor-0] INFO impl.VoteContext: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-CANDIDATE: reject ELECTION from c3461ed7-1554-428d-9478-8d95583cf36e: already has voted for c7eeb289-59cc-4c90-a00f-b0c50499b5ba at current term 9
dn2_1    | 2022-06-16 01:14:30,140 [grpc-default-executor-0] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399 replies to ELECTION vote request: c3461ed7-1554-428d-9478-8d95583cf36e<-c7eeb289-59cc-4c90-a00f-b0c50499b5ba#0:FAIL-t9. Peer's state: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399:t9, leader=null, voted=c7eeb289-59cc-4c90-a00f-b0c50499b5ba, raftlog=c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-06-16 01:14:30,156 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: receive requestVote(ELECTION, 8b366c76-456d-4ec7-ac8e-95910f7eaaa6, group-8C8526B83399, 9, (t:8, i:28))
dn2_1    | 2022-06-16 01:14:30,162 [grpc-default-executor-0] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE: receive requestVote(ELECTION, 8b366c76-456d-4ec7-ac8e-95910f7eaaa6, group-5FC878C6C2DE, 14, (t:13, i:38))
dn2_1    | 2022-06-16 01:14:30,191 [grpc-default-executor-0] INFO impl.VoteContext: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-CANDIDATE: reject ELECTION from 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: already has voted for c7eeb289-59cc-4c90-a00f-b0c50499b5ba at current term 14
dn2_1    | 2022-06-16 01:14:30,192 [grpc-default-executor-0] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE replies to ELECTION vote request: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c7eeb289-59cc-4c90-a00f-b0c50499b5ba#0:FAIL-t14. Peer's state: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE:t14, leader=null, voted=c7eeb289-59cc-4c90-a00f-b0c50499b5ba, raftlog=c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-SegmentedRaftLog:OPENED:c38, conf=22: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-06-16 01:14:30,194 [grpc-default-executor-1] INFO impl.VoteContext: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-CANDIDATE: reject ELECTION from 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: already has voted for c7eeb289-59cc-4c90-a00f-b0c50499b5ba at current term 9
dn2_1    | 2022-06-16 01:14:30,195 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399 replies to ELECTION vote request: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c7eeb289-59cc-4c90-a00f-b0c50499b5ba#0:FAIL-t9. Peer's state: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399:t9, leader=null, voted=c7eeb289-59cc-4c90-a00f-b0c50499b5ba, raftlog=c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-06-16 01:14:30,198 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection2] INFO impl.LeaderElection: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection2: ELECTION REJECTED received 2 response(s) and 0 exception(s):
dn2_1    | 2022-06-16 01:14:30,200 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection2] INFO impl.LeaderElection:   Response 0: c7eeb289-59cc-4c90-a00f-b0c50499b5ba<-8b366c76-456d-4ec7-ac8e-95910f7eaaa6#0:FAIL-t14
dn2_1    | 2022-06-16 01:14:30,200 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection2] INFO impl.LeaderElection:   Response 1: c7eeb289-59cc-4c90-a00f-b0c50499b5ba<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t14
dn2_1    | 2022-06-16 01:14:30,201 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection2] INFO impl.LeaderElection: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection2 ELECTION round 0: result REJECTED
dn2_1    | 2022-06-16 01:14:30,205 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection2] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE: changes role from CANDIDATE to FOLLOWER at term 14 for REJECTED
dn2_1    | 2022-06-16 01:14:30,210 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection2] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: shutdown c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection2
dn2_1    | 2022-06-16 01:14:30,210 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection2] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: start c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-FollowerState
dn2_1    | 2022-06-16 01:14:30,233 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection3] INFO impl.LeaderElection: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection3: ELECTION REJECTED received 2 response(s) and 0 exception(s):
dn2_1    | 2022-06-16 01:14:30,234 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection3] INFO impl.LeaderElection:   Response 0: c7eeb289-59cc-4c90-a00f-b0c50499b5ba<-8b366c76-456d-4ec7-ac8e-95910f7eaaa6#0:FAIL-t9
dn2_1    | 2022-06-16 01:14:30,234 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection3] INFO impl.LeaderElection:   Response 1: c7eeb289-59cc-4c90-a00f-b0c50499b5ba<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t9
dn2_1    | 2022-06-16 01:14:30,234 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection3] INFO impl.LeaderElection: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection3 ELECTION round 0: result REJECTED
dn2_1    | 2022-06-16 01:14:30,237 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection3] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: changes role from CANDIDATE to FOLLOWER at term 9 for REJECTED
dn2_1    | 2022-06-16 01:14:30,237 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection3] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: shutdown c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection3
dn2_1    | 2022-06-16 01:14:30,237 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection3] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: start c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState
dn2_1    | 2022-06-16 01:14:35,281 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState] INFO impl.FollowerState: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5043450635ns, electionTimeout:5027ms
dn2_1    | 2022-06-16 01:14:35,281 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: shutdown c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState
dn2_1    | 2022-06-16 01:14:35,281 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: changes role from  FOLLOWER to CANDIDATE at term 9 for changeToCandidate
dn2_1    | 2022-06-16 01:14:35,282 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn2_1    | 2022-06-16 01:14:35,282 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: start c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection4
dn2_1    | 2022-06-16 01:14:35,288 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection4] INFO impl.LeaderElection: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection4 ELECTION round 0: submit vote requests at term 10 for 19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-06-16 01:14:35,312 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE: receive requestVote(ELECTION, 8b366c76-456d-4ec7-ac8e-95910f7eaaa6, group-5FC878C6C2DE, 15, (t:13, i:38))
dn2_1    | 2022-06-16 01:14:35,314 [grpc-default-executor-1] INFO impl.VoteContext: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-FOLLOWER: reject ELECTION from 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: our priority 1 > candidate's priority 0
dn2_1    | 2022-06-16 01:14:35,314 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE: changes role from  FOLLOWER to FOLLOWER at term 15 for candidate:8b366c76-456d-4ec7-ac8e-95910f7eaaa6
dn2_1    | 2022-06-16 01:14:35,314 [grpc-default-executor-1] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: shutdown c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-FollowerState
dn2_1    | 2022-06-16 01:14:35,314 [grpc-default-executor-1] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: start c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-FollowerState
dn2_1    | 2022-06-16 01:14:35,318 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-FollowerState] INFO impl.FollowerState: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-FollowerState was interrupted
dn2_1    | 2022-06-16 01:14:35,342 [grpc-default-executor-0] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: receive requestVote(ELECTION, 8b366c76-456d-4ec7-ac8e-95910f7eaaa6, group-8C8526B83399, 10, (t:8, i:28))
dn2_1    | 2022-06-16 01:14:35,342 [grpc-default-executor-0] INFO impl.VoteContext: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-CANDIDATE: reject ELECTION from 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: already has voted for c7eeb289-59cc-4c90-a00f-b0c50499b5ba at current term 10
dn2_1    | 2022-06-16 01:14:35,320 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE replies to ELECTION vote request: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c7eeb289-59cc-4c90-a00f-b0c50499b5ba#0:FAIL-t15. Peer's state: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE:t15, leader=null, voted=null, raftlog=c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-SegmentedRaftLog:OPENED:c38, conf=22: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn5_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
dn5_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
dn5_1    | 2022-06-16 01:13:40,464 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
dn5_1    | /************************************************************
dn5_1    | STARTUP_MSG: Starting HddsDatanodeService
dn5_1    | STARTUP_MSG:   host = 5d7def869eda/10.9.0.19
dn5_1    | STARTUP_MSG:   args = []
dn5_1    | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
dn5_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/gson-2.8.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
dn5_1    | STARTUP_MSG:   build = https://github.com/apache/ozone/17d3301a908af2df7683a0c61b8ee3ae8dd41d6a ; compiled by 'runner' on 2022-06-16T00:51Z
dn5_1    | STARTUP_MSG:   java = 11.0.14.1
dn5_1    | ************************************************************/
dn5_1    | 2022-06-16 01:13:40,519 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
dn5_1    | 2022-06-16 01:13:40,906 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
dn5_1    | 2022-06-16 01:13:41,840 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
dn5_1    | 2022-06-16 01:13:43,225 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
dn5_1    | 2022-06-16 01:13:43,225 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
dn5_1    | 2022-06-16 01:13:45,083 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:5d7def869eda ip:10.9.0.19
dn5_1    | 2022-06-16 01:13:47,055 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = DATANODE_SCHEMA_V3 (version = 4)
dn5_1    | 2022-06-16 01:13:48,437 [main] INFO reflections.Reflections: Reflections took 1088 ms to scan 2 urls, producing 89 keys and 191 values 
dn5_1    | 2022-06-16 01:13:49,143 [main] INFO upgrade.HDDSLayoutVersionManager: Registering Upgrade Action : DatanodeSchemaV3FinalizeAction
dn5_1    | 2022-06-16 01:13:49,455 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
dn5_1    | 2022-06-16 01:13:50,730 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/hdds/scmUsed: 4096 at 2022-06-16T01:13:17.098Z
dn5_1    | 2022-06-16 01:13:50,799 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
dn5_1    | 2022-06-16 01:13:50,807 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
dn5_1    | 2022-06-16 01:13:50,817 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
dn5_1    | 2022-06-16 01:13:50,914 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
dn5_1    | 2022-06-16 01:13:51,155 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn5_1    | 2022-06-16 01:13:51,231 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/metadata/ratis/scmUsed: 4096 at 2022-06-16T01:13:17.107Z
dn5_1    | 2022-06-16 01:13:51,268 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
dn5_1    | 2022-06-16 01:13:51,270 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
dn5_1    | 2022-06-16 01:13:51,296 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
dn5_1    | 2022-06-16 01:13:51,473 [Thread-3] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
dn5_1    | 2022-06-16 01:13:53,013 [Thread-3] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
dn5_1    | 2022-06-16 01:13:53,014 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 1s
dn5_1    | 2022-06-16 01:14:04,938 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
dn5_1    | 2022-06-16 01:14:05,523 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn5_1    | 2022-06-16 01:14:05,941 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
dn5_1    | 2022-06-16 01:14:07,026 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
dn5_1    | 2022-06-16 01:14:07,033 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
dn5_1    | 2022-06-16 01:14:07,035 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
dn5_1    | 2022-06-16 01:14:07,042 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
dn5_1    | 2022-06-16 01:14:07,045 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn5_1    | 2022-06-16 01:14:07,047 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
dn5_1    | 2022-06-16 01:14:07,050 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn5_1    | 2022-06-16 01:14:07,223 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
dn5_1    | 2022-06-16 01:14:07,240 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
dn5_1    | 2022-06-16 01:14:10,103 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
dn5_1    | 2022-06-16 01:14:10,158 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
dn5_1    | 2022-06-16 01:14:10,159 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
dn5_1    | 2022-06-16 01:14:10,159 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn5_1    | 2022-06-16 01:14:10,159 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn5_1    | 2022-06-16 01:14:10,224 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn5_1    | 2022-06-16 01:14:10,269 [c3461ed7-1554-428d-9478-8d95583cf36e-impl-thread1] INFO server.RaftServer: c3461ed7-1554-428d-9478-8d95583cf36e: found a subdirectory /data/metadata/ratis/4321e5aa-575a-4764-b053-3d4e612b41cc
dn5_1    | 2022-06-16 01:14:10,362 [c3461ed7-1554-428d-9478-8d95583cf36e-impl-thread1] INFO server.RaftServer: c3461ed7-1554-428d-9478-8d95583cf36e: addNew group-3D4E612B41CC:[] returns group-3D4E612B41CC:java.util.concurrent.CompletableFuture@cae73b9[Not completed]
dn5_1    | 2022-06-16 01:14:10,362 [c3461ed7-1554-428d-9478-8d95583cf36e-impl-thread1] INFO server.RaftServer: c3461ed7-1554-428d-9478-8d95583cf36e: found a subdirectory /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de
dn5_1    | 2022-06-16 01:14:10,387 [c3461ed7-1554-428d-9478-8d95583cf36e-impl-thread1] INFO server.RaftServer: c3461ed7-1554-428d-9478-8d95583cf36e: addNew group-5FC878C6C2DE:[] returns group-5FC878C6C2DE:java.util.concurrent.CompletableFuture@439b1dd4[Not completed]
dn5_1    | 2022-06-16 01:14:10,387 [c3461ed7-1554-428d-9478-8d95583cf36e-impl-thread1] INFO server.RaftServer: c3461ed7-1554-428d-9478-8d95583cf36e: found a subdirectory /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399
dn4_1    | 2022-06-16 01:14:21,466 [835c1189-b066-4617-a285-c9fdbaf1d7b5-impl-thread1] INFO server.RaftServer$Division: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE: changes role from      null to FOLLOWER at term 3 for startAsFollower
dn4_1    | 2022-06-16 01:14:21,470 [835c1189-b066-4617-a285-c9fdbaf1d7b5-impl-thread1] INFO impl.RoleInfo: 835c1189-b066-4617-a285-c9fdbaf1d7b5: start 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-FollowerState
dn4_1    | 2022-06-16 01:14:21,477 [835c1189-b066-4617-a285-c9fdbaf1d7b5-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C8CE16AB84AE,id=835c1189-b066-4617-a285-c9fdbaf1d7b5
dn4_1    | 2022-06-16 01:14:21,574 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.RaftServer: 835c1189-b066-4617-a285-c9fdbaf1d7b5: start RPC server
dn4_1    | 2022-06-16 01:14:21,606 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 835c1189-b066-4617-a285-c9fdbaf1d7b5: GrpcService started, listening on 9856
dn4_1    | 2022-06-16 01:14:21,607 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 835c1189-b066-4617-a285-c9fdbaf1d7b5: GrpcService started, listening on 9857
dn4_1    | 2022-06-16 01:14:21,608 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 835c1189-b066-4617-a285-c9fdbaf1d7b5: GrpcService started, listening on 9858
dn4_1    | 2022-06-16 01:14:21,650 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 835c1189-b066-4617-a285-c9fdbaf1d7b5 is started using port 9858 for RATIS
dn4_1    | 2022-06-16 01:14:21,650 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 835c1189-b066-4617-a285-c9fdbaf1d7b5 is started using port 9857 for RATIS_ADMIN
dn4_1    | 2022-06-16 01:14:21,651 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 835c1189-b066-4617-a285-c9fdbaf1d7b5 is started using port 9856 for RATIS_SERVER
dn4_1    | 2022-06-16 01:14:21,661 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$472/0x0000000840523c40@2c12b06] INFO util.JvmPauseMonitor: JvmPauseMonitor-835c1189-b066-4617-a285-c9fdbaf1d7b5: Started
dn4_1    | 2022-06-16 01:14:26,561 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-FollowerState] INFO impl.FollowerState: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5091090174ns, electionTimeout:5074ms
dn4_1    | 2022-06-16 01:14:26,562 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-FollowerState] INFO impl.RoleInfo: 835c1189-b066-4617-a285-c9fdbaf1d7b5: shutdown 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-FollowerState
dn4_1    | 2022-06-16 01:14:26,563 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-FollowerState] INFO server.RaftServer$Division: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
dn4_1    | 2022-06-16 01:14:26,566 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn4_1    | 2022-06-16 01:14:26,566 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-FollowerState] INFO impl.RoleInfo: 835c1189-b066-4617-a285-c9fdbaf1d7b5: start 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-LeaderElection1
dn4_1    | 2022-06-16 01:14:26,709 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-LeaderElection1] INFO impl.LeaderElection: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-LeaderElection1 ELECTION round 0: submit vote requests at term 4 for 3: [835c1189-b066-4617-a285-c9fdbaf1d7b5|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1], old=null
dn4_1    | 2022-06-16 01:14:26,714 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-LeaderElection1] INFO impl.LeaderElection: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-LeaderElection1 ELECTION round 0: result PASSED (term=4)
dn4_1    | 2022-06-16 01:14:26,717 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-LeaderElection1] INFO impl.RoleInfo: 835c1189-b066-4617-a285-c9fdbaf1d7b5: shutdown 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-LeaderElection1
dn4_1    | 2022-06-16 01:14:26,722 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-LeaderElection1] INFO server.RaftServer$Division: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE: changes role from CANDIDATE to LEADER at term 4 for changeToLeader
dn4_1    | 2022-06-16 01:14:26,726 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-C8CE16AB84AE with new leaderId: 835c1189-b066-4617-a285-c9fdbaf1d7b5
dn4_1    | 2022-06-16 01:14:26,822 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-LeaderElection1] INFO server.RaftServer$Division: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE: change Leader from null to 835c1189-b066-4617-a285-c9fdbaf1d7b5 at term 4 for becomeLeader, leader elected after 16133ms
dn4_1    | 2022-06-16 01:14:26,840 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn4_1    | 2022-06-16 01:14:26,930 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn4_1    | 2022-06-16 01:14:26,940 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn4_1    | 2022-06-16 01:14:26,980 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn4_1    | 2022-06-16 01:14:27,002 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn4_1    | 2022-06-16 01:14:27,002 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn4_1    | 2022-06-16 01:14:27,084 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn4_1    | 2022-06-16 01:14:27,114 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn4_1    | 2022-06-16 01:14:27,124 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-LeaderElection1] INFO impl.RoleInfo: 835c1189-b066-4617-a285-c9fdbaf1d7b5: start 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-LeaderStateImpl
dn4_1    | 2022-06-16 01:14:27,225 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-SegmentedRaftLogWorker: Rolling segment log-3_4 to index:4
dn4_1    | 2022-06-16 01:14:27,326 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/bb9bc3de-e3de-455a-8b75-c8ce16ab84ae/current/log_inprogress_3 to /data/metadata/ratis/bb9bc3de-e3de-455a-8b75-c8ce16ab84ae/current/log_3-4
dn4_1    | 2022-06-16 01:14:27,365 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/bb9bc3de-e3de-455a-8b75-c8ce16ab84ae/current/log_inprogress_5
om1_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.4.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.14.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-intg-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.6.3.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.44.v20210927.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/gson-2.8.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om1_1    | STARTUP_MSG:   build = https://github.com/apache/ozone/17d3301a908af2df7683a0c61b8ee3ae8dd41d6a ; compiled by 'runner' on 2022-06-16T00:51Z
om1_1    | STARTUP_MSG:   java = 11.0.14.1
om1_1    | ************************************************************/
om1_1    | 2022-06-16 01:13:42,155 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1    | 2022-06-16 01:13:51,905 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om1_1    | 2022-06-16 01:13:55,464 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om1_1    | 2022-06-16 01:13:56,540 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: omservice, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1    | 2022-06-16 01:13:56,546 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.omservice.om1: om1
om1_1    | 2022-06-16 01:13:56,557 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1    | 2022-06-16 01:13:56,863 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = MULTITENANCY_SCHEMA (version = 3)
om1_1    | 2022-06-16 01:13:59,370 [main] INFO reflections.Reflections: Reflections took 2056 ms to scan 1 urls, producing 114 keys and 339 values [using 2 cores]
om1_1    | 2022-06-16 01:13:59,507 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1    | 2022-06-16 01:14:01,482 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863]
om1_1    | 2022-06-16 01:14:01,691 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863]
om1_1    | 2022-06-16 01:14:04,594 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 61c78f4b9f66/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1    | 2022-06-16 01:14:06,596 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 61c78f4b9f66/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1    | 2022-06-16 01:14:08,597 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 61c78f4b9f66/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1    | 2022-06-16 01:14:10,606 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 61c78f4b9f66/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1    | 2022-06-16 01:14:12,607 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 61c78f4b9f66/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
dn4_1    | 2022-06-16 01:14:27,390 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE-LeaderElection1] INFO server.RaftServer$Division: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-C8CE16AB84AE: set configuration 5: [835c1189-b066-4617-a285-c9fdbaf1d7b5|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1], old=null
dn4_1    | 2022-06-16 01:15:27,786 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn4_1    | 2022-06-16 01:15:27,788 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn4_1    | 2022-06-16 01:15:27,789 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn4_1    | 2022-06-16 01:15:27,790 [Command processor thread] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: ERASURE_CODED_STORAGE_SUPPORT.
dn4_1    | 2022-06-16 01:15:27,792 [Command processor thread] INFO upgrade.AbstractLayoutVersionManager: Layout feature ERASURE_CODED_STORAGE_SUPPORT has been finalized.
dn4_1    | 2022-06-16 01:15:27,793 [Command processor thread] INFO upgrade.UpgradeFinalizer: Running finalization actions for layout feature: DATANODE_SCHEMA_V3
dn4_1    | 2022-06-16 01:15:27,793 [Command processor thread] INFO upgrade.DatanodeSchemaV3FinalizeAction: Upgrading Datanode volume layout for Schema V3 support.
dn4_1    | 2022-06-16 01:15:27,849 [Command processor thread] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-3e3c8fff-8818-4ab8-8118-66b81944a69d/DS-84b4e24b-7183-4445-b11d-00a3bbb53d9b/container.db for volume DS-84b4e24b-7183-4445-b11d-00a3bbb53d9b
dn4_1    | 2022-06-16 01:15:27,852 [Command processor thread] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-3e3c8fff-8818-4ab8-8118-66b81944a69d/DS-84b4e24b-7183-4445-b11d-00a3bbb53d9b/container.db for volume DS-84b4e24b-7183-4445-b11d-00a3bbb53d9b
dn4_1    | 2022-06-16 01:15:27,853 [Command processor thread] INFO upgrade.DatanodeSchemaV3FinalizeAction: Schema V3 is disabled. Won't load RocksDB in upgrade.
dn4_1    | 2022-06-16 01:15:27,854 [Command processor thread] INFO upgrade.AbstractLayoutVersionManager: Layout feature DATANODE_SCHEMA_V3 has been finalized.
dn4_1    | 2022-06-16 01:15:27,854 [Command processor thread] INFO upgrade.AbstractLayoutVersionManager: Finalization is complete.
dn4_1    | 2022-06-16 01:15:27,854 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization is done.
dn4_1    | 2022-06-16 01:15:57,786 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn4_1    | 2022-06-16 01:16:27,799 [pool-22-thread-1] INFO server.RaftServer$Division: 835c1189-b066-4617-a285-c9fdbaf1d7b5: new RaftServerImpl for group-51DDEED5744F:[835c1189-b066-4617-a285-c9fdbaf1d7b5|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1] with ContainerStateMachine:uninitialized
dn4_1    | 2022-06-16 01:16:27,800 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn4_1    | 2022-06-16 01:16:27,800 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn4_1    | 2022-06-16 01:16:27,801 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn4_1    | 2022-06-16 01:16:27,801 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn4_1    | 2022-06-16 01:16:27,801 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn4_1    | 2022-06-16 01:16:27,801 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn4_1    | 2022-06-16 01:16:27,801 [pool-22-thread-1] INFO server.RaftServer$Division: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F: ConfigurationManager, init=-1: [835c1189-b066-4617-a285-c9fdbaf1d7b5|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1], old=null, confs=<EMPTY_MAP>
dn4_1    | 2022-06-16 01:16:27,802 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn4_1    | 2022-06-16 01:16:27,803 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn4_1    | 2022-06-16 01:16:27,803 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn4_1    | 2022-06-16 01:16:27,803 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/ce5a0a3f-f6c5-4883-b95d-51ddeed5744f does not exist. Creating ...
dn4_1    | 2022-06-16 01:16:27,805 [Command processor thread] INFO server.RaftServer: 835c1189-b066-4617-a285-c9fdbaf1d7b5: addNew group-51DDEED5744F:[835c1189-b066-4617-a285-c9fdbaf1d7b5|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1] returns group-51DDEED5744F:java.util.concurrent.CompletableFuture@209ed3e2[Not completed]
dn4_1    | 2022-06-16 01:16:27,806 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/ce5a0a3f-f6c5-4883-b95d-51ddeed5744f/in_use.lock acquired by nodename 12@3b053cfb9aaa
dn4_1    | 2022-06-16 01:16:27,809 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/ce5a0a3f-f6c5-4883-b95d-51ddeed5744f has been successfully formatted.
dn4_1    | 2022-06-16 01:16:27,810 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-51DDEED5744F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn4_1    | 2022-06-16 01:16:27,810 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn4_1    | 2022-06-16 01:16:27,810 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn4_1    | 2022-06-16 01:16:27,810 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn4_1    | 2022-06-16 01:16:27,810 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn4_1    | 2022-06-16 01:16:27,810 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn4_1    | 2022-06-16 01:16:27,810 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn4_1    | 2022-06-16 01:16:27,811 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn4_1    | 2022-06-16 01:16:27,811 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn4_1    | 2022-06-16 01:16:27,811 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/ce5a0a3f-f6c5-4883-b95d-51ddeed5744f
dn4_1    | 2022-06-16 01:16:27,811 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn4_1    | 2022-06-16 01:16:27,811 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn4_1    | 2022-06-16 01:16:27,811 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn4_1    | 2022-06-16 01:16:27,811 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn4_1    | 2022-06-16 01:16:27,811 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn4_1    | 2022-06-16 01:16:27,811 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om1_1    | 2022-06-16 01:14:14,609 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 61c78f4b9f66/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1    | 2022-06-16 01:14:16,614 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 61c78f4b9f66/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1    | 2022-06-16 01:14:24,235 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1    | 2022-06-16 01:14:25,065 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om1_1    | 2022-06-16 01:14:25,066 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om1_1    | 2022-06-16 01:14:25,498 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om1_1    | 2022-06-16 01:14:25,680 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1    | 2022-06-16 01:14:25,681 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om1_1    | 2022-06-16 01:14:25,691 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om1_1    | 2022-06-16 01:14:26,208 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om1_1    | 2022-06-16 01:14:26,281 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1    | 2022-06-16 01:14:26,510 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: omservice and peers: om1:9872, om3:9872, om2:9872
om1_1    | 2022-06-16 01:14:26,620 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:6, i:98)
om1_1    | 2022-06-16 01:14:27,001 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om1_1    | 2022-06-16 01:14:27,804 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om1_1    | 2022-06-16 01:14:27,821 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1    | 2022-06-16 01:14:27,824 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om1_1    | 2022-06-16 01:14:27,826 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1    | 2022-06-16 01:14:27,826 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1    | 2022-06-16 01:14:27,829 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om1_1    | 2022-06-16 01:14:27,846 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1    | 2022-06-16 01:14:27,847 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om1_1    | 2022-06-16 01:14:27,850 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1    | 2022-06-16 01:14:27,968 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om1_1    | 2022-06-16 01:14:27,979 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om1_1    | 2022-06-16 01:14:29,538 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om1_1    | 2022-06-16 01:14:29,541 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om1_1    | 2022-06-16 01:14:29,541 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om1_1    | 2022-06-16 01:14:29,549 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1    | 2022-06-16 01:14:29,550 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1    | 2022-06-16 01:14:29,628 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1    | 2022-06-16 01:14:29,661 [om1-impl-thread1] INFO server.RaftServer: om1: found a subdirectory /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c
om1_1    | 2022-06-16 01:14:29,695 [main] INFO server.RaftServer: om1: addNew group-D66704EFC61C:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-D66704EFC61C:java.util.concurrent.CompletableFuture@388c519[Not completed]
om1_1    | 2022-06-16 01:14:29,695 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om1_1    | 2022-06-16 01:14:29,840 [main] INFO om.OzoneManager: Creating RPC Server
om1_1    | 2022-06-16 01:14:29,848 [pool-26-thread-1] INFO server.RaftServer$Division: om1: new RaftServerImpl for group-D66704EFC61C:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om1_1    | 2022-06-16 01:14:29,899 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om1_1    | 2022-06-16 01:14:29,899 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om1_1    | 2022-06-16 01:14:29,900 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om1_1    | 2022-06-16 01:14:29,901 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1    | 2022-06-16 01:14:29,901 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1    | 2022-06-16 01:14:29,901 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om1_1    | 2022-06-16 01:14:29,986 [pool-26-thread-1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om1_1    | 2022-06-16 01:14:29,992 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1    | 2022-06-16 01:14:30,072 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om1_1    | 2022-06-16 01:14:30,089 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om1_1    | 2022-06-16 01:14:30,218 [pool-26-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/in_use.lock acquired by nodename 8@61c78f4b9f66
om1_1    | 2022-06-16 01:14:30,304 [pool-26-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=6, votedFor=om2} from /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/raft-meta
om1_1    | 2022-06-16 01:14:30,876 [pool-26-thread-1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: set configuration 63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1    | 2022-06-16 01:14:30,877 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om1_1    | 2022-06-16 01:14:30,878 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1    | 2022-06-16 01:14:30,936 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om1_1    | 2022-06-16 01:14:30,938 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1    | 2022-06-16 01:14:30,939 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om1_1    | 2022-06-16 01:14:31,310 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1    | 2022-06-16 01:14:31,374 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om1_1    | 2022-06-16 01:14:31,386 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om1_1    | 2022-06-16 01:14:31,447 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: new om1@group-D66704EFC61C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c
om1_1    | 2022-06-16 01:14:31,470 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om1_1    | 2022-06-16 01:14:31,470 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om1_1    | 2022-06-16 01:14:31,471 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1    | 2022-06-16 01:14:31,474 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om1_1    | 2022-06-16 01:14:31,479 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om1_1    | 2022-06-16 01:14:31,480 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om1_1    | 2022-06-16 01:14:31,487 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om1_1    | 2022-06-16 01:14:31,492 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om1_1    | 2022-06-16 01:14:31,567 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om1_1    | 2022-06-16 01:14:31,585 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om1_1    | 2022-06-16 01:14:31,586 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om1_1    | 2022-06-16 01:14:31,881 [pool-26-thread-1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1    | 2022-06-16 01:14:31,940 [pool-26-thread-1] INFO segmented.LogSegment: Successfully read 21 entries from segment file /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_0-20
om1_1    | 2022-06-16 01:14:31,976 [pool-26-thread-1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: set configuration 21: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1    | 2022-06-16 01:14:31,990 [pool-26-thread-1] INFO segmented.LogSegment: Successfully read 42 entries from segment file /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_21-62
om1_1    | 2022-06-16 01:14:31,992 [pool-26-thread-1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: set configuration 63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1    | 2022-06-16 01:14:32,014 [pool-26-thread-1] INFO segmented.LogSegment: Successfully read 36 entries from segment file /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_inprogress_63
om1_1    | 2022-06-16 01:14:32,022 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-D66704EFC61C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 98
om1_1    | 2022-06-16 01:14:32,022 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-D66704EFC61C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 62
om1_1    | 2022-06-16 01:14:32,553 [pool-26-thread-1] INFO raftlog.RaftLog: om1@group-D66704EFC61C-SegmentedRaftLog: commitIndex: updateToMax old=98, new=97, updated? false
om1_1    | 2022-06-16 01:14:32,557 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om1_1    | 2022-06-16 01:14:32,582 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om1_1    | 2022-06-16 01:14:32,592 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om1_1    | 2022-06-16 01:14:32,595 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om1_1    | 2022-06-16 01:14:32,601 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om1_1    | 2022-06-16 01:14:32,610 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om1_1    | 2022-06-16 01:14:32,884 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1    | 2022-06-16 01:14:32,893 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om1_1    | 2022-06-16 01:14:32,897 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om1_1    | 2022-06-16 01:14:32,902 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om1_1    | 2022-06-16 01:14:32,905 [main] INFO reflections.Reflections: Reflections took 2727 ms to scan 8 urls, producing 23 keys and 507 values [using 2 cores]
om1_1    | 2022-06-16 01:14:32,957 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om1_1    | 2022-06-16 01:14:33,321 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1    | 2022-06-16 01:14:33,359 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
dn4_1    | 2022-06-16 01:16:27,811 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn4_1    | 2022-06-16 01:16:27,811 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn4_1    | 2022-06-16 01:16:27,811 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn4_1    | 2022-06-16 01:16:27,813 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn4_1    | 2022-06-16 01:16:27,813 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn4_1    | 2022-06-16 01:16:27,815 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn4_1    | 2022-06-16 01:16:27,816 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn4_1    | 2022-06-16 01:16:27,816 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn4_1    | 2022-06-16 01:16:27,828 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn4_1    | 2022-06-16 01:16:27,829 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn4_1    | 2022-06-16 01:16:27,829 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn4_1    | 2022-06-16 01:16:27,829 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn4_1    | 2022-06-16 01:16:27,830 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn4_1    | 2022-06-16 01:16:27,831 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn4_1    | 2022-06-16 01:16:27,832 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn4_1    | 2022-06-16 01:16:27,832 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn4_1    | 2022-06-16 01:16:27,832 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn4_1    | 2022-06-16 01:16:27,833 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn4_1    | 2022-06-16 01:16:27,833 [pool-22-thread-1] INFO server.RaftServer$Division: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F: start as a follower, conf=-1: [835c1189-b066-4617-a285-c9fdbaf1d7b5|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1], old=null
dn4_1    | 2022-06-16 01:16:27,833 [pool-22-thread-1] INFO server.RaftServer$Division: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn4_1    | 2022-06-16 01:16:27,834 [pool-22-thread-1] INFO impl.RoleInfo: 835c1189-b066-4617-a285-c9fdbaf1d7b5: start 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-FollowerState
dn4_1    | 2022-06-16 01:16:27,835 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-51DDEED5744F,id=835c1189-b066-4617-a285-c9fdbaf1d7b5
dn4_1    | 2022-06-16 01:16:27,851 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=ce5a0a3f-f6c5-4883-b95d-51ddeed5744f
dn4_1    | 2022-06-16 01:16:27,852 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=ce5a0a3f-f6c5-4883-b95d-51ddeed5744f.
dn4_1    | 2022-06-16 01:16:32,968 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-FollowerState] INFO impl.FollowerState: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5133998656ns, electionTimeout:5123ms
dn4_1    | 2022-06-16 01:16:32,968 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-FollowerState] INFO impl.RoleInfo: 835c1189-b066-4617-a285-c9fdbaf1d7b5: shutdown 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-FollowerState
dn4_1    | 2022-06-16 01:16:32,968 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-FollowerState] INFO server.RaftServer$Division: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
dn4_1    | 2022-06-16 01:16:32,969 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn4_1    | 2022-06-16 01:16:32,969 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-FollowerState] INFO impl.RoleInfo: 835c1189-b066-4617-a285-c9fdbaf1d7b5: start 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-LeaderElection2
dn4_1    | 2022-06-16 01:16:32,972 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-LeaderElection2] INFO impl.LeaderElection: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [835c1189-b066-4617-a285-c9fdbaf1d7b5|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1], old=null
dn4_1    | 2022-06-16 01:16:32,972 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-LeaderElection2] INFO impl.LeaderElection: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-LeaderElection2 ELECTION round 0: result PASSED (term=1)
dn4_1    | 2022-06-16 01:16:32,972 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-LeaderElection2] INFO impl.RoleInfo: 835c1189-b066-4617-a285-c9fdbaf1d7b5: shutdown 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-LeaderElection2
dn4_1    | 2022-06-16 01:16:32,972 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-LeaderElection2] INFO server.RaftServer$Division: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
dn4_1    | 2022-06-16 01:16:32,973 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-51DDEED5744F with new leaderId: 835c1189-b066-4617-a285-c9fdbaf1d7b5
dn4_1    | 2022-06-16 01:16:32,973 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-LeaderElection2] INFO server.RaftServer$Division: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F: change Leader from null to 835c1189-b066-4617-a285-c9fdbaf1d7b5 at term 1 for becomeLeader, leader elected after 5162ms
dn4_1    | 2022-06-16 01:16:32,978 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn4_1    | 2022-06-16 01:16:32,979 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn4_1    | 2022-06-16 01:16:32,980 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn4_1    | 2022-06-16 01:16:32,981 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn4_1    | 2022-06-16 01:16:32,982 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn2_1    | 2022-06-16 01:14:35,343 [grpc-default-executor-0] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399 replies to ELECTION vote request: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c7eeb289-59cc-4c90-a00f-b0c50499b5ba#0:FAIL-t10. Peer's state: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399:t10, leader=null, voted=c7eeb289-59cc-4c90-a00f-b0c50499b5ba, raftlog=c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-06-16 01:14:35,409 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection4] INFO impl.LeaderElection: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection4: ELECTION REJECTED received 2 response(s) and 0 exception(s):
dn2_1    | 2022-06-16 01:14:35,410 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection4] INFO impl.LeaderElection:   Response 0: c7eeb289-59cc-4c90-a00f-b0c50499b5ba<-8b366c76-456d-4ec7-ac8e-95910f7eaaa6#0:FAIL-t10
dn2_1    | 2022-06-16 01:14:35,410 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection4] INFO impl.LeaderElection:   Response 1: c7eeb289-59cc-4c90-a00f-b0c50499b5ba<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t10
dn2_1    | 2022-06-16 01:14:35,410 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection4] INFO impl.LeaderElection: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection4 ELECTION round 0: result REJECTED
dn2_1    | 2022-06-16 01:14:35,411 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection4] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: changes role from CANDIDATE to FOLLOWER at term 10 for REJECTED
dn2_1    | 2022-06-16 01:14:35,411 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection4] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: shutdown c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection4
dn2_1    | 2022-06-16 01:14:35,411 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection4] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: start c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState
dn2_1    | 2022-06-16 01:14:40,447 [grpc-default-executor-0] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: receive requestVote(ELECTION, 8b366c76-456d-4ec7-ac8e-95910f7eaaa6, group-8C8526B83399, 11, (t:8, i:28))
dn2_1    | 2022-06-16 01:14:40,447 [grpc-default-executor-0] INFO impl.VoteContext: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FOLLOWER: accept ELECTION from 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: our priority 0 <= candidate's priority 0
dn2_1    | 2022-06-16 01:14:40,447 [grpc-default-executor-0] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: changes role from  FOLLOWER to FOLLOWER at term 11 for candidate:8b366c76-456d-4ec7-ac8e-95910f7eaaa6
dn2_1    | 2022-06-16 01:14:40,447 [grpc-default-executor-0] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: shutdown c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState
dn2_1    | 2022-06-16 01:14:40,447 [grpc-default-executor-0] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: start c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState
dn2_1    | 2022-06-16 01:14:40,447 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState] INFO impl.FollowerState: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState was interrupted
dn2_1    | 2022-06-16 01:14:40,453 [grpc-default-executor-0] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399 replies to ELECTION vote request: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c7eeb289-59cc-4c90-a00f-b0c50499b5ba#0:OK-t11. Peer's state: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399:t11, leader=null, voted=8b366c76-456d-4ec7-ac8e-95910f7eaaa6, raftlog=c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-06-16 01:14:40,475 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-FollowerState] INFO impl.FollowerState: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5160646181ns, electionTimeout:5138ms
dn2_1    | 2022-06-16 01:14:40,475 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-FollowerState] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: shutdown c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-FollowerState
dn2_1    | 2022-06-16 01:14:40,475 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-FollowerState] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE: changes role from  FOLLOWER to CANDIDATE at term 15 for changeToCandidate
dn2_1    | 2022-06-16 01:14:40,475 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn2_1    | 2022-06-16 01:14:40,475 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-FollowerState] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: start c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5
dn2_1    | 2022-06-16 01:14:40,484 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO impl.LeaderElection: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5 ELECTION round 0: submit vote requests at term 16 for 22: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-06-16 01:14:40,514 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO impl.LeaderElection: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5: ELECTION PASSED received 1 response(s) and 0 exception(s):
dn2_1    | 2022-06-16 01:14:40,514 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO impl.LeaderElection:   Response 0: c7eeb289-59cc-4c90-a00f-b0c50499b5ba<-c3461ed7-1554-428d-9478-8d95583cf36e#0:OK-t16
dn2_1    | 2022-06-16 01:14:40,514 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO impl.LeaderElection: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5 ELECTION round 0: result PASSED
dn2_1    | 2022-06-16 01:14:40,515 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: shutdown c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5
dn2_1    | 2022-06-16 01:14:40,515 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE: changes role from CANDIDATE to LEADER at term 16 for changeToLeader
dn2_1    | 2022-06-16 01:14:40,515 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-5FC878C6C2DE with new leaderId: c7eeb289-59cc-4c90-a00f-b0c50499b5ba
dn2_1    | 2022-06-16 01:14:40,530 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE: change Leader from null to c7eeb289-59cc-4c90-a00f-b0c50499b5ba at term 16 for becomeLeader, leader elected after 27090ms
dn2_1    | 2022-06-16 01:14:40,530 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn2_1    | 2022-06-16 01:14:40,531 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn2_1    | 2022-06-16 01:14:40,533 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn2_1    | 2022-06-16 01:14:40,534 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn2_1    | 2022-06-16 01:14:40,534 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn2_1    | 2022-06-16 01:14:40,534 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn2_1    | 2022-06-16 01:14:40,537 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn2_1    | 2022-06-16 01:14:40,537 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn2_1    | 2022-06-16 01:14:40,597 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn2_1    | 2022-06-16 01:14:40,597 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2022-06-16 01:14:40,601 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
dn2_1    | 2022-06-16 01:14:40,608 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn2_1    | 2022-06-16 01:14:40,613 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn2_1    | 2022-06-16 01:14:40,614 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn2_1    | 2022-06-16 01:14:40,623 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn2_1    | 2022-06-16 01:14:40,623 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2022-06-16 01:14:40,623 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
dn2_1    | 2022-06-16 01:14:40,623 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn2_1    | 2022-06-16 01:14:40,624 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn2_1    | 2022-06-16 01:14:40,624 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn2_1    | 2022-06-16 01:14:40,625 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: start c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderStateImpl
dn2_1    | 2022-06-16 01:14:40,631 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO segmented.SegmentedRaftLogWorker: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-SegmentedRaftLogWorker: Rolling segment log-22_38 to index:38
dn2_1    | 2022-06-16 01:14:40,638 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de/current/log_inprogress_22 to /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de/current/log_22-38
dn2_1    | 2022-06-16 01:14:40,653 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de/current/log_inprogress_39
dn2_1    | 2022-06-16 01:14:40,706 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE-LeaderElection5] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-5FC878C6C2DE: set configuration 39: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-06-16 01:14:45,553 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: receive requestVote(ELECTION, 8b366c76-456d-4ec7-ac8e-95910f7eaaa6, group-8C8526B83399, 12, (t:8, i:28))
dn2_1    | 2022-06-16 01:14:45,554 [grpc-default-executor-1] INFO impl.VoteContext: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FOLLOWER: accept ELECTION from 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: our priority 0 <= candidate's priority 0
dn2_1    | 2022-06-16 01:14:45,554 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: changes role from  FOLLOWER to FOLLOWER at term 12 for candidate:8b366c76-456d-4ec7-ac8e-95910f7eaaa6
dn2_1    | 2022-06-16 01:14:45,554 [grpc-default-executor-1] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: shutdown c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState
dn2_1    | 2022-06-16 01:14:45,554 [grpc-default-executor-1] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: start c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState
dn2_1    | 2022-06-16 01:14:45,554 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState] INFO impl.FollowerState: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState was interrupted
dn2_1    | 2022-06-16 01:14:45,557 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399 replies to ELECTION vote request: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c7eeb289-59cc-4c90-a00f-b0c50499b5ba#0:OK-t12. Peer's state: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399:t12, leader=null, voted=8b366c76-456d-4ec7-ac8e-95910f7eaaa6, raftlog=c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn4_1    | 2022-06-16 01:16:32,982 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn4_1    | 2022-06-16 01:16:32,982 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn4_1    | 2022-06-16 01:16:32,983 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn4_1    | 2022-06-16 01:16:32,983 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-LeaderElection2] INFO impl.RoleInfo: 835c1189-b066-4617-a285-c9fdbaf1d7b5: start 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-LeaderStateImpl
dn4_1    | 2022-06-16 01:16:32,983 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-SegmentedRaftLogWorker: Starting segment from index:0
dn4_1    | 2022-06-16 01:16:32,985 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/ce5a0a3f-f6c5-4883-b95d-51ddeed5744f/current/log_inprogress_0
dn4_1    | 2022-06-16 01:16:32,990 [835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F-LeaderElection2] INFO server.RaftServer$Division: 835c1189-b066-4617-a285-c9fdbaf1d7b5@group-51DDEED5744F: set configuration 0: [835c1189-b066-4617-a285-c9fdbaf1d7b5|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1], old=null
om3_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1    | 2022-06-16 01:13:40,704 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1    | /************************************************************
om3_1    | STARTUP_MSG: Starting OzoneManager
om3_1    | STARTUP_MSG:   host = 4ceb6711a080/10.9.0.13
om3_1    | STARTUP_MSG:   args = [--upgrade]
om3_1    | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om1_1    | 2022-06-16 01:14:33,827 [Listener at om1/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om1_1    | 2022-06-16 01:14:33,891 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om1_1    | 2022-06-16 01:14:33,892 [Listener at om1/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om1_1    | 2022-06-16 01:14:34,091 [Listener at om1/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om1/10.9.0.11:9862
om1_1    | 2022-06-16 01:14:34,094 [Listener at om1/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
om1_1    | 2022-06-16 01:14:34,098 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: start as a follower, conf=63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1    | 2022-06-16 01:14:34,100 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: changes role from      null to FOLLOWER at term 6 for startAsFollower
dn5_1    | 2022-06-16 01:14:10,387 [c3461ed7-1554-428d-9478-8d95583cf36e-impl-thread1] INFO server.RaftServer: c3461ed7-1554-428d-9478-8d95583cf36e: addNew group-8C8526B83399:[] returns group-8C8526B83399:java.util.concurrent.CompletableFuture@19c7ccc1[Not completed]
dn5_1    | 2022-06-16 01:14:10,650 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
dn5_1    | 2022-06-16 01:14:10,889 [pool-46-thread-1] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e: new RaftServerImpl for group-3D4E612B41CC:[] with ContainerStateMachine:uninitialized
dn5_1    | 2022-06-16 01:14:10,913 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn5_1    | 2022-06-16 01:14:10,928 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn5_1    | 2022-06-16 01:14:10,929 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn5_1    | 2022-06-16 01:14:10,929 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn5_1    | 2022-06-16 01:14:10,929 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn5_1    | 2022-06-16 01:14:10,929 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn5_1    | 2022-06-16 01:14:11,070 [pool-46-thread-1] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn5_1    | 2022-06-16 01:14:11,090 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn5_1    | 2022-06-16 01:14:11,112 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn5_1    | 2022-06-16 01:14:11,136 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn5_1    | 2022-06-16 01:14:11,329 [pool-46-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/4321e5aa-575a-4764-b053-3d4e612b41cc/in_use.lock acquired by nodename 7@5d7def869eda
dn5_1    | 2022-06-16 01:14:11,368 [pool-46-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=3, votedFor=c3461ed7-1554-428d-9478-8d95583cf36e} from /data/metadata/ratis/4321e5aa-575a-4764-b053-3d4e612b41cc/current/raft-meta
dn5_1    | 2022-06-16 01:14:11,677 [pool-46-thread-1] INFO ratis.ContainerStateMachine: group-3D4E612B41CC: Setting the last applied index to (t:3, i:4)
dn5_1    | 2022-06-16 01:14:11,837 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
dn5_1    | 2022-06-16 01:14:12,043 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
dn5_1    | 2022-06-16 01:14:12,430 [main] INFO util.log: Logging initialized @44011ms to org.eclipse.jetty.util.log.Slf4jLog
dn5_1    | 2022-06-16 01:14:13,646 [pool-46-thread-1] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC: set configuration 3: [c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:14:13,653 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn5_1    | 2022-06-16 01:14:13,668 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn5_1    | 2022-06-16 01:14:13,791 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn5_1    | 2022-06-16 01:14:13,800 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn5_1    | 2022-06-16 01:14:13,805 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn5_1    | 2022-06-16 01:14:13,917 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn5_1    | 2022-06-16 01:14:14,055 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
dn5_1    | 2022-06-16 01:14:14,061 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn5_1    | 2022-06-16 01:14:14,062 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn5_1    | 2022-06-16 01:14:14,085 [pool-46-thread-1] INFO segmented.SegmentedRaftLogWorker: new c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/4321e5aa-575a-4764-b053-3d4e612b41cc
dn5_1    | 2022-06-16 01:14:14,098 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
dn5_1    | 2022-06-16 01:14:14,137 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn5_1    | 2022-06-16 01:14:14,141 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn5_1    | 2022-06-16 01:14:14,149 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn5_1    | 2022-06-16 01:14:14,139 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
dn5_1    | 2022-06-16 01:14:14,163 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
dn5_1    | 2022-06-16 01:14:14,169 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
dn5_1    | 2022-06-16 01:14:14,168 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn5_1    | 2022-06-16 01:14:14,170 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn5_1    | 2022-06-16 01:14:14,173 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn5_1    | 2022-06-16 01:14:14,178 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn5_1    | 2022-06-16 01:14:14,178 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn5_1    | 2022-06-16 01:14:14,173 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
dn5_1    | 2022-06-16 01:14:14,317 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn5_1    | 2022-06-16 01:14:14,371 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn5_1    | 2022-06-16 01:14:14,373 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn5_1    | 2022-06-16 01:14:14,664 [main] INFO http.HttpServer2: Jetty bound to port 9882
dn5_1    | 2022-06-16 01:14:14,672 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
dn5_1    | 2022-06-16 01:14:14,700 [pool-46-thread-1] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC: set configuration 0: [c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:14:14,706 [pool-46-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/4321e5aa-575a-4764-b053-3d4e612b41cc/current/log_0-0
om1_1    | 2022-06-16 01:14:34,103 [om1-impl-thread1] INFO impl.RoleInfo: om1: start om1@group-D66704EFC61C-FollowerState
om1_1    | 2022-06-16 01:14:34,135 [om1-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D66704EFC61C,id=om1
om1_1    | 2022-06-16 01:14:34,178 [Listener at om1/9862] INFO server.RaftServer: om1: start RPC server
om1_1    | 2022-06-16 01:14:34,337 [Listener at om1/9862] INFO server.GrpcService: om1: GrpcService started, listening on 9872
om1_1    | 2022-06-16 01:14:34,350 [Listener at om1/9862] INFO upgrade.UpgradeFinalizer: Running pre-finalized state validations for unfinalized layout features.
om1_1    | 2022-06-16 01:14:34,355 [Listener at om1/9862] INFO upgrade.UpgradeFinalizer: Running first upgrade commands for unfinalized layout features.
om1_1    | 2022-06-16 01:14:34,356 [Listener at om1/9862] INFO om.OzoneManager: Version File has different layout version (0) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om1_1    | 2022-06-16 01:14:34,367 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$427/0x000000084055f040@52ecc989] INFO util.JvmPauseMonitor: JvmPauseMonitor-om1: Started
om1_1    | 2022-06-16 01:14:34,547 [Listener at om1/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om1_1    | 2022-06-16 01:14:34,554 [Listener at om1/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om1_1    | 2022-06-16 01:14:34,633 [Listener at om1/9862] INFO util.log: Logging initialized @64076ms to org.eclipse.jetty.util.log.Slf4jLog
om1_1    | 2022-06-16 01:14:35,016 [Listener at om1/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om1_1    | 2022-06-16 01:14:35,034 [Listener at om1/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om1_1    | 2022-06-16 01:14:35,060 [Listener at om1/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om1_1    | 2022-06-16 01:14:35,063 [Listener at om1/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om1_1    | 2022-06-16 01:14:35,070 [Listener at om1/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om1_1    | 2022-06-16 01:14:35,070 [Listener at om1/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om1_1    | 2022-06-16 01:14:35,185 [Listener at om1/9862] INFO http.HttpServer2: Jetty bound to port 9874
om1_1    | 2022-06-16 01:14:35,205 [Listener at om1/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om1_1    | 2022-06-16 01:14:35,366 [Listener at om1/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om1_1    | 2022-06-16 01:14:35,377 [Listener at om1/9862] INFO server.session: No SessionScavenger set, using defaults
om1_1    | 2022-06-16 01:14:35,388 [Listener at om1/9862] INFO server.session: node0 Scavenging every 660000ms
om1_1    | 2022-06-16 01:14:35,426 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7bf018dd{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om1_1    | 2022-06-16 01:14:35,428 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2a484710{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om1_1    | 2022-06-16 01:14:35,836 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@597a7afa{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-11431044723282374928/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om1_1    | 2022-06-16 01:14:35,866 [Listener at om1/9862] INFO server.AbstractConnector: Started ServerConnector@6bb4cc0e{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om1_1    | 2022-06-16 01:14:35,866 [Listener at om1/9862] INFO server.Server: Started @65309ms
om1_1    | 2022-06-16 01:14:35,884 [Listener at om1/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om1_1    | 2022-06-16 01:14:35,886 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om1_1    | 2022-06-16 01:14:35,888 [Listener at om1/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om1_1    | 2022-06-16 01:14:35,893 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om1_1    | 2022-06-16 01:14:35,893 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om1_1    | 2022-06-16 01:14:36,217 [Listener at om1/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted won't move to trash
om1_1    | 2022-06-16 01:14:36,249 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@b75b890] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om1_1    | 2022-06-16 01:14:39,158 [om1@group-D66704EFC61C-FollowerState] INFO impl.FollowerState: om1@group-D66704EFC61C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5055185261ns, electionTimeout:5023ms
om1_1    | 2022-06-16 01:14:39,159 [om1@group-D66704EFC61C-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-D66704EFC61C-FollowerState
om1_1    | 2022-06-16 01:14:39,162 [om1@group-D66704EFC61C-FollowerState] INFO server.RaftServer$Division: om1@group-D66704EFC61C: changes role from  FOLLOWER to CANDIDATE at term 6 for changeToCandidate
om1_1    | 2022-06-16 01:14:39,165 [om1@group-D66704EFC61C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om1_1    | 2022-06-16 01:14:39,165 [om1@group-D66704EFC61C-FollowerState] INFO impl.RoleInfo: om1: start om1@group-D66704EFC61C-LeaderElection1
om1_1    | 2022-06-16 01:14:39,237 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om1@group-D66704EFC61C-LeaderElection1 ELECTION round 0: submit vote requests at term 7 for 63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1    | 2022-06-16 01:14:40,719 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-D66704EFC61C: receive requestVote(ELECTION, om3, group-D66704EFC61C, 7, (t:6, i:98))
om1_1    | 2022-06-16 01:14:40,720 [grpc-default-executor-0] INFO impl.VoteContext: om1@group-D66704EFC61C-CANDIDATE: reject ELECTION from om3: already has voted for om1 at current term 7
om1_1    | 2022-06-16 01:14:40,726 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-D66704EFC61C replies to ELECTION vote request: om3<-om1#0:FAIL-t7. Peer's state: om1@group-D66704EFC61C:t7, leader=null, voted=om1, raftlog=om1@group-D66704EFC61C-SegmentedRaftLog:OPENED:c98, conf=63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1    | 2022-06-16 01:14:40,726 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: receive requestVote(ELECTION, om2, group-D66704EFC61C, 7, (t:6, i:98))
om1_1    | 2022-06-16 01:14:40,726 [grpc-default-executor-1] INFO impl.VoteContext: om1@group-D66704EFC61C-CANDIDATE: reject ELECTION from om2: already has voted for om1 at current term 7
dn1_1    | 2022-06-16 01:14:57,631 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn1_1    | 2022-06-16 01:14:57,631 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn1_1    | 2022-06-16 01:14:57,631 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:14:57,632 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:14:57,632 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn1_1    | 2022-06-16 01:14:57,632 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn1_1    | 2022-06-16 01:14:57,632 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn1_1    | 2022-06-16 01:14:57,632 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn1_1    | 2022-06-16 01:14:57,633 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn1_1    | 2022-06-16 01:14:57,633 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:14:57,633 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:14:57,633 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn1_1    | 2022-06-16 01:14:57,633 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn1_1    | 2022-06-16 01:14:57,634 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn1_1    | 2022-06-16 01:14:57,634 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn1_1    | 2022-06-16 01:14:57,634 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn1_1    | 2022-06-16 01:14:57,634 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:14:57,635 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:15:00,712 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.FollowerState: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5097305185ns, electionTimeout:5090ms
dn1_1    | 2022-06-16 01:15:00,712 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: shutdown 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState
dn1_1    | 2022-06-16 01:15:00,713 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: changes role from  FOLLOWER to CANDIDATE at term 14 for changeToCandidate
dn1_1    | 2022-06-16 01:15:00,713 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn1_1    | 2022-06-16 01:15:00,713 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection10
dn1_1    | 2022-06-16 01:15:00,715 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection10] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection10 ELECTION round 0: submit vote requests at term 15 for 19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:15:00,729 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection10] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection10: ELECTION REJECTED received 1 response(s) and 0 exception(s):
dn1_1    | 2022-06-16 01:15:00,730 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection10] INFO impl.LeaderElection:   Response 0: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t15
dn1_1    | 2022-06-16 01:15:00,730 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection10] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection10 ELECTION round 0: result REJECTED
dn1_1    | 2022-06-16 01:15:00,732 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection10] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: changes role from CANDIDATE to FOLLOWER at term 15 for REJECTED
dn1_1    | 2022-06-16 01:15:00,732 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection10] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: shutdown 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection10
dn1_1    | 2022-06-16 01:15:00,732 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection10] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState
dn1_1    | 2022-06-16 01:15:05,756 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.FollowerState: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5023658637ns, electionTimeout:5019ms
dn1_1    | 2022-06-16 01:15:05,757 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: shutdown 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState
dn1_1    | 2022-06-16 01:15:05,758 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: changes role from  FOLLOWER to CANDIDATE at term 15 for changeToCandidate
dn1_1    | 2022-06-16 01:15:05,758 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn1_1    | 2022-06-16 01:15:05,758 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection11
dn1_1    | 2022-06-16 01:15:05,761 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection11] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection11 ELECTION round 0: submit vote requests at term 16 for 19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:15:05,781 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection11] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection11: ELECTION REJECTED received 1 response(s) and 0 exception(s):
om2_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1    | 2022-06-16 01:13:41,939 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1    | /************************************************************
om2_1    | STARTUP_MSG: Starting OzoneManager
om2_1    | STARTUP_MSG:   host = a30c9296ca2c/10.9.0.12
om2_1    | STARTUP_MSG:   args = [--upgrade]
om2_1    | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om2_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.4.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.14.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-intg-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.6.3.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.44.v20210927.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/gson-2.8.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om2_1    | STARTUP_MSG:   build = https://github.com/apache/ozone/17d3301a908af2df7683a0c61b8ee3ae8dd41d6a ; compiled by 'runner' on 2022-06-16T00:51Z
om2_1    | STARTUP_MSG:   java = 11.0.14.1
om2_1    | ************************************************************/
om2_1    | 2022-06-16 01:13:42,038 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1    | 2022-06-16 01:13:51,985 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om2_1    | 2022-06-16 01:13:54,768 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om2_1    | 2022-06-16 01:13:55,830 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: omservice, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1    | 2022-06-16 01:13:55,834 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.omservice.om2: om2
om2_1    | 2022-06-16 01:13:55,867 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1    | 2022-06-16 01:13:56,227 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = MULTITENANCY_SCHEMA (version = 3)
om2_1    | 2022-06-16 01:13:58,470 [main] INFO reflections.Reflections: Reflections took 1586 ms to scan 1 urls, producing 114 keys and 339 values [using 2 cores]
om2_1    | 2022-06-16 01:13:58,569 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1    | 2022-06-16 01:14:00,791 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863]
om2_1    | 2022-06-16 01:14:00,982 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863]
om2_1    | 2022-06-16 01:14:04,022 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From a30c9296ca2c/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1    | 2022-06-16 01:14:06,023 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From a30c9296ca2c/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1    | 2022-06-16 01:14:08,025 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From a30c9296ca2c/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1    | 2022-06-16 01:14:10,026 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From a30c9296ca2c/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1    | 2022-06-16 01:14:12,028 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From a30c9296ca2c/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1    | 2022-06-16 01:14:14,029 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From a30c9296ca2c/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1    | 2022-06-16 01:14:16,031 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From a30c9296ca2c/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1    | 2022-06-16 01:14:18,032 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From a30c9296ca2c/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1    | 2022-06-16 01:14:24,113 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1    | 2022-06-16 01:14:24,560 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om2_1    | 2022-06-16 01:14:24,577 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om2_1    | 2022-06-16 01:14:25,153 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om2_1    | 2022-06-16 01:14:25,224 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1    | 2022-06-16 01:14:25,225 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om2_1    | 2022-06-16 01:14:25,241 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om2_1    | 2022-06-16 01:14:25,714 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om2_1    | 2022-06-16 01:14:25,745 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1    | 2022-06-16 01:14:25,811 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: omservice and peers: om2:9872, om1:9872, om3:9872
om2_1    | 2022-06-16 01:14:25,852 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:6, i:98)
om2_1    | 2022-06-16 01:14:25,981 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om2_1    | 2022-06-16 01:14:26,935 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om2_1    | 2022-06-16 01:14:26,984 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1    | 2022-06-16 01:14:26,990 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om2_1    | 2022-06-16 01:14:26,995 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1    | 2022-06-16 01:14:27,002 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1    | 2022-06-16 01:14:27,003 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om2_1    | 2022-06-16 01:14:27,033 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1    | 2022-06-16 01:14:27,040 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om2_1    | 2022-06-16 01:14:27,041 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1    | 2022-06-16 01:14:27,196 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om2_1    | 2022-06-16 01:14:27,199 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om2_1    | 2022-06-16 01:14:29,053 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om2_1    | 2022-06-16 01:14:29,060 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om2_1    | 2022-06-16 01:14:29,066 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om2_1    | 2022-06-16 01:14:29,067 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1    | 2022-06-16 01:14:29,067 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1    | 2022-06-16 01:14:29,077 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1    | 2022-06-16 01:14:29,087 [om2-impl-thread1] INFO server.RaftServer: om2: found a subdirectory /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c
om2_1    | 2022-06-16 01:14:29,177 [main] INFO server.RaftServer: om2: addNew group-D66704EFC61C:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-D66704EFC61C:java.util.concurrent.CompletableFuture@198536f6[Not completed]
om2_1    | 2022-06-16 01:14:29,178 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om2_1    | 2022-06-16 01:14:29,280 [main] INFO om.OzoneManager: Creating RPC Server
om2_1    | 2022-06-16 01:14:29,302 [pool-26-thread-1] INFO server.RaftServer$Division: om2: new RaftServerImpl for group-D66704EFC61C:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om2_1    | 2022-06-16 01:14:29,354 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om2_1    | 2022-06-16 01:14:29,363 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om2_1    | 2022-06-16 01:14:29,363 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om2_1    | 2022-06-16 01:14:29,364 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1    | 2022-06-16 01:14:29,364 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1    | 2022-06-16 01:14:29,364 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om2_1    | 2022-06-16 01:14:29,430 [pool-26-thread-1] INFO server.RaftServer$Division: om2@group-D66704EFC61C: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om2_1    | 2022-06-16 01:14:29,431 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1    | 2022-06-16 01:14:29,465 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om2_1    | 2022-06-16 01:14:29,483 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om2_1    | 2022-06-16 01:14:29,610 [pool-26-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/in_use.lock acquired by nodename 8@a30c9296ca2c
om2_1    | 2022-06-16 01:14:29,738 [pool-26-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=6, votedFor=om2} from /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/raft-meta
dn1_1    | 2022-06-16 01:15:05,782 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection11] INFO impl.LeaderElection:   Response 0: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t16
dn1_1    | 2022-06-16 01:15:05,783 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection11] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection11 ELECTION round 0: result REJECTED
dn1_1    | 2022-06-16 01:15:05,783 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection11] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: changes role from CANDIDATE to FOLLOWER at term 16 for REJECTED
dn1_1    | 2022-06-16 01:15:05,783 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection11] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: shutdown 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection11
dn1_1    | 2022-06-16 01:15:05,783 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection11] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState
dn1_1    | 2022-06-16 01:15:05,795 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: receive requestVote(ELECTION, c3461ed7-1554-428d-9478-8d95583cf36e, group-8C8526B83399, 16, (t:8, i:28))
dn1_1    | 2022-06-16 01:15:05,796 [grpc-default-executor-0] INFO impl.VoteContext: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FOLLOWER: reject ELECTION from c3461ed7-1554-428d-9478-8d95583cf36e: already has voted for 8b366c76-456d-4ec7-ac8e-95910f7eaaa6 at current term 16
dn1_1    | 2022-06-16 01:15:05,796 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399 replies to ELECTION vote request: c3461ed7-1554-428d-9478-8d95583cf36e<-8b366c76-456d-4ec7-ac8e-95910f7eaaa6#0:FAIL-t16. Peer's state: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399:t16, leader=null, voted=8b366c76-456d-4ec7-ac8e-95910f7eaaa6, raftlog=8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:15:10,827 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.FollowerState: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5044213614ns, electionTimeout:5035ms
dn1_1    | 2022-06-16 01:15:10,828 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: shutdown 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState
dn1_1    | 2022-06-16 01:15:10,828 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: changes role from  FOLLOWER to CANDIDATE at term 16 for changeToCandidate
dn1_1    | 2022-06-16 01:15:10,828 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn1_1    | 2022-06-16 01:15:10,828 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection12
dn1_1    | 2022-06-16 01:15:10,831 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection12] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection12 ELECTION round 0: submit vote requests at term 17 for 19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:15:10,847 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection12] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection12: ELECTION REJECTED received 2 response(s) and 0 exception(s):
dn1_1    | 2022-06-16 01:15:10,847 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection12] INFO impl.LeaderElection:   Response 0: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c7eeb289-59cc-4c90-a00f-b0c50499b5ba#0:OK-t17
dn1_1    | 2022-06-16 01:15:10,847 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection12] INFO impl.LeaderElection:   Response 1: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t17
dn1_1    | 2022-06-16 01:15:10,847 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection12] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection12 ELECTION round 0: result REJECTED
dn1_1    | 2022-06-16 01:15:10,847 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection12] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: changes role from CANDIDATE to FOLLOWER at term 17 for REJECTED
dn1_1    | 2022-06-16 01:15:10,847 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection12] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: shutdown 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection12
dn1_1    | 2022-06-16 01:15:10,847 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection12] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState
dn1_1    | 2022-06-16 01:15:11,793 [ContainerOp-cfb1d3a9-fa49-4890-85f5-5fc878c6c2de-0] INFO keyvalue.KeyValueContainer: Container 2 is synced with bcsId 2.
dn1_1    | 2022-06-16 01:15:11,795 [ContainerOp-cfb1d3a9-fa49-4890-85f5-5fc878c6c2de-0] INFO keyvalue.KeyValueContainer: Container 2 is synced with bcsId 2.
dn1_1    | 2022-06-16 01:15:11,804 [ContainerOp-cfb1d3a9-fa49-4890-85f5-5fc878c6c2de-0] INFO keyvalue.KeyValueContainer: Container 2 is closed with bcsId 2.
dn1_1    | 2022-06-16 01:15:11,969 [ContainerOp-cfb1d3a9-fa49-4890-85f5-5fc878c6c2de-1] INFO keyvalue.KeyValueContainer: Container 1001 is synced with bcsId 20.
dn1_1    | 2022-06-16 01:15:11,970 [ContainerOp-cfb1d3a9-fa49-4890-85f5-5fc878c6c2de-1] INFO keyvalue.KeyValueContainer: Container 1001 is synced with bcsId 20.
dn1_1    | 2022-06-16 01:15:11,983 [ContainerOp-cfb1d3a9-fa49-4890-85f5-5fc878c6c2de-1] INFO keyvalue.KeyValueContainer: Container 1001 is closed with bcsId 20.
dn1_1    | 2022-06-16 01:15:12,076 [ContainerOp-cfb1d3a9-fa49-4890-85f5-5fc878c6c2de-2] INFO keyvalue.KeyValueContainer: Container 2001 is synced with bcsId 36.
dn1_1    | 2022-06-16 01:15:12,081 [ContainerOp-cfb1d3a9-fa49-4890-85f5-5fc878c6c2de-2] INFO keyvalue.KeyValueContainer: Container 2001 is synced with bcsId 36.
dn1_1    | 2022-06-16 01:15:12,097 [ContainerOp-cfb1d3a9-fa49-4890-85f5-5fc878c6c2de-2] INFO keyvalue.KeyValueContainer: Container 2001 is closed with bcsId 36.
dn1_1    | 2022-06-16 01:15:15,854 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.FollowerState: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5007346937ns, electionTimeout:5004ms
dn2_1    | 2022-06-16 01:14:50,573 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: receive requestVote(ELECTION, 8b366c76-456d-4ec7-ac8e-95910f7eaaa6, group-8C8526B83399, 13, (t:8, i:28))
dn2_1    | 2022-06-16 01:14:50,573 [grpc-default-executor-1] INFO impl.VoteContext: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FOLLOWER: accept ELECTION from 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: our priority 0 <= candidate's priority 0
dn2_1    | 2022-06-16 01:14:50,573 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: changes role from  FOLLOWER to FOLLOWER at term 13 for candidate:8b366c76-456d-4ec7-ac8e-95910f7eaaa6
dn2_1    | 2022-06-16 01:14:50,573 [grpc-default-executor-1] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: shutdown c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState
dn2_1    | 2022-06-16 01:14:50,573 [grpc-default-executor-1] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: start c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState
dn2_1    | 2022-06-16 01:14:50,573 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState] INFO impl.FollowerState: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState was interrupted
dn2_1    | 2022-06-16 01:14:50,582 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399 replies to ELECTION vote request: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c7eeb289-59cc-4c90-a00f-b0c50499b5ba#0:OK-t13. Peer's state: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399:t13, leader=null, voted=8b366c76-456d-4ec7-ac8e-95910f7eaaa6, raftlog=c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-06-16 01:14:55,605 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: receive requestVote(ELECTION, 8b366c76-456d-4ec7-ac8e-95910f7eaaa6, group-8C8526B83399, 14, (t:8, i:28))
dn2_1    | 2022-06-16 01:14:55,607 [grpc-default-executor-1] INFO impl.VoteContext: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FOLLOWER: accept ELECTION from 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: our priority 0 <= candidate's priority 0
dn2_1    | 2022-06-16 01:14:55,608 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: changes role from  FOLLOWER to FOLLOWER at term 14 for candidate:8b366c76-456d-4ec7-ac8e-95910f7eaaa6
dn2_1    | 2022-06-16 01:14:55,608 [grpc-default-executor-1] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: shutdown c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState
dn2_1    | 2022-06-16 01:14:55,608 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState] INFO impl.FollowerState: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState was interrupted
dn2_1    | 2022-06-16 01:14:55,609 [grpc-default-executor-1] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: start c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState
dn2_1    | 2022-06-16 01:14:55,613 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399 replies to ELECTION vote request: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c7eeb289-59cc-4c90-a00f-b0c50499b5ba#0:OK-t14. Peer's state: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399:t14, leader=null, voted=8b366c76-456d-4ec7-ac8e-95910f7eaaa6, raftlog=c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-06-16 01:15:00,721 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: receive requestVote(ELECTION, 8b366c76-456d-4ec7-ac8e-95910f7eaaa6, group-8C8526B83399, 15, (t:8, i:28))
dn2_1    | 2022-06-16 01:15:00,721 [grpc-default-executor-1] INFO impl.VoteContext: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FOLLOWER: accept ELECTION from 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: our priority 0 <= candidate's priority 0
dn2_1    | 2022-06-16 01:15:00,721 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: changes role from  FOLLOWER to FOLLOWER at term 15 for candidate:8b366c76-456d-4ec7-ac8e-95910f7eaaa6
dn2_1    | 2022-06-16 01:15:00,721 [grpc-default-executor-1] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: shutdown c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState
dn2_1    | 2022-06-16 01:15:00,722 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState] INFO impl.FollowerState: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState was interrupted
dn2_1    | 2022-06-16 01:15:00,726 [grpc-default-executor-1] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: start c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState
dn2_1    | 2022-06-16 01:15:00,730 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399 replies to ELECTION vote request: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c7eeb289-59cc-4c90-a00f-b0c50499b5ba#0:OK-t15. Peer's state: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399:t15, leader=null, voted=8b366c76-456d-4ec7-ac8e-95910f7eaaa6, raftlog=c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-06-16 01:15:05,769 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: receive requestVote(ELECTION, 8b366c76-456d-4ec7-ac8e-95910f7eaaa6, group-8C8526B83399, 16, (t:8, i:28))
dn2_1    | 2022-06-16 01:15:05,769 [grpc-default-executor-1] INFO impl.VoteContext: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FOLLOWER: accept ELECTION from 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: our priority 0 <= candidate's priority 0
dn2_1    | 2022-06-16 01:15:05,769 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: changes role from  FOLLOWER to FOLLOWER at term 16 for candidate:8b366c76-456d-4ec7-ac8e-95910f7eaaa6
dn2_1    | 2022-06-16 01:15:05,769 [grpc-default-executor-1] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: shutdown c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState
dn2_1    | 2022-06-16 01:15:05,769 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState] INFO impl.FollowerState: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState was interrupted
dn2_1    | 2022-06-16 01:15:05,770 [grpc-default-executor-1] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: start c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState
dn5_1    | 2022-06-16 01:14:14,791 [pool-46-thread-1] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC: set configuration 1: [c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:14:14,794 [pool-46-thread-1] INFO segmented.LogSegment: Successfully read 2 entries from segment file /data/metadata/ratis/4321e5aa-575a-4764-b053-3d4e612b41cc/current/log_1-2
dn5_1    | 2022-06-16 01:14:14,810 [pool-46-thread-1] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC: set configuration 3: [c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:14:14,834 [pool-46-thread-1] INFO segmented.LogSegment: Successfully read 2 entries from segment file /data/metadata/ratis/4321e5aa-575a-4764-b053-3d4e612b41cc/current/log_inprogress_3
dn5_1    | 2022-06-16 01:14:14,850 [pool-46-thread-1] INFO segmented.SegmentedRaftLogWorker: c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 4
dn5_1    | 2022-06-16 01:14:14,858 [pool-46-thread-1] INFO segmented.SegmentedRaftLogWorker: c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 2
dn5_1    | 2022-06-16 01:14:15,076 [main] INFO server.session: DefaultSessionIdManager workerName=node0
dn5_1    | 2022-06-16 01:14:15,110 [main] INFO server.session: No SessionScavenger set, using defaults
dn5_1    | 2022-06-16 01:14:15,119 [main] INFO server.session: node0 Scavenging every 660000ms
dn5_1    | 2022-06-16 01:14:15,209 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7197b07f{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
dn5_1    | 2022-06-16 01:14:15,259 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@33a8c9c9{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
dn5_1    | 2022-06-16 01:14:15,466 [pool-46-thread-1] INFO raftlog.RaftLog: c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-SegmentedRaftLog: commitIndex: updateToMax old=4, new=3, updated? false
dn5_1    | 2022-06-16 01:14:15,484 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn5_1    | 2022-06-16 01:14:15,485 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn5_1    | 2022-06-16 01:14:15,485 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn5_1    | 2022-06-16 01:14:15,497 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn5_1    | 2022-06-16 01:14:15,500 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn5_1    | 2022-06-16 01:14:15,511 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn5_1    | 2022-06-16 01:14:15,825 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn5_1    | 2022-06-16 01:14:15,830 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn5_1    | 2022-06-16 01:14:15,848 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn5_1    | 2022-06-16 01:14:15,865 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn5_1    | 2022-06-16 01:14:15,866 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn5_1    | 2022-06-16 01:14:15,868 [pool-46-thread-1] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e: new RaftServerImpl for group-5FC878C6C2DE:[] with ContainerStateMachine:uninitialized
dn5_1    | 2022-06-16 01:14:15,876 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn5_1    | 2022-06-16 01:14:15,882 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn5_1    | 2022-06-16 01:14:15,882 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn5_1    | 2022-06-16 01:14:15,892 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn5_1    | 2022-06-16 01:14:15,892 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn5_1    | 2022-06-16 01:14:15,892 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn5_1    | 2022-06-16 01:14:15,892 [pool-46-thread-1] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn5_1    | 2022-06-16 01:14:15,893 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn5_1    | 2022-06-16 01:14:15,893 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn5_1    | 2022-06-16 01:14:15,894 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn5_1    | 2022-06-16 01:14:15,902 [pool-46-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de/in_use.lock acquired by nodename 7@5d7def869eda
dn5_1    | 2022-06-16 01:14:15,903 [pool-46-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=13, votedFor=c7eeb289-59cc-4c90-a00f-b0c50499b5ba} from /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de/current/raft-meta
dn5_1    | 2022-06-16 01:14:15,905 [pool-46-thread-1] INFO ratis.ContainerStateMachine: group-5FC878C6C2DE: Setting the last applied index to (t:13, i:38)
dn5_1    | 2022-06-16 01:14:15,946 [pool-46-thread-1] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE: set configuration 22: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn5_1    | 2022-06-16 01:14:15,950 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn5_1    | 2022-06-16 01:14:15,950 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn5_1    | 2022-06-16 01:14:15,951 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn5_1    | 2022-06-16 01:14:15,953 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn5_1    | 2022-06-16 01:14:15,953 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn5_1    | 2022-06-16 01:14:15,954 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn5_1    | 2022-06-16 01:14:15,958 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn5_1    | 2022-06-16 01:14:15,958 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om2_1    | 2022-06-16 01:14:30,439 [pool-26-thread-1] INFO server.RaftServer$Division: om2@group-D66704EFC61C: set configuration 63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1    | 2022-06-16 01:14:30,446 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om2_1    | 2022-06-16 01:14:30,457 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om2_1    | 2022-06-16 01:14:30,557 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om2_1    | 2022-06-16 01:14:30,589 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1    | 2022-06-16 01:14:30,611 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om2_1    | 2022-06-16 01:14:30,780 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1    | 2022-06-16 01:14:30,851 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om2_1    | 2022-06-16 01:14:30,861 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om2_1    | 2022-06-16 01:14:30,934 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: new om2@group-D66704EFC61C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c
om2_1    | 2022-06-16 01:14:30,945 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om2_1    | 2022-06-16 01:14:30,961 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om2_1    | 2022-06-16 01:14:30,962 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1    | 2022-06-16 01:14:30,966 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om2_1    | 2022-06-16 01:14:30,968 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om2_1    | 2022-06-16 01:14:30,971 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om2_1    | 2022-06-16 01:14:30,990 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om2_1    | 2022-06-16 01:14:30,993 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om2_1    | 2022-06-16 01:14:31,066 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om2_1    | 2022-06-16 01:14:31,091 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om2_1    | 2022-06-16 01:14:31,093 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om2_1    | 2022-06-16 01:14:31,442 [pool-26-thread-1] INFO server.RaftServer$Division: om2@group-D66704EFC61C: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1    | 2022-06-16 01:14:31,492 [pool-26-thread-1] INFO segmented.LogSegment: Successfully read 21 entries from segment file /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_0-20
om2_1    | 2022-06-16 01:14:31,532 [pool-26-thread-1] INFO server.RaftServer$Division: om2@group-D66704EFC61C: set configuration 21: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1    | 2022-06-16 01:14:31,565 [pool-26-thread-1] INFO segmented.LogSegment: Successfully read 42 entries from segment file /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_21-62
om2_1    | 2022-06-16 01:14:31,587 [pool-26-thread-1] INFO server.RaftServer$Division: om2@group-D66704EFC61C: set configuration 63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1    | 2022-06-16 01:14:31,631 [pool-26-thread-1] INFO segmented.LogSegment: Successfully read 36 entries from segment file /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_inprogress_63
om2_1    | 2022-06-16 01:14:31,641 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-D66704EFC61C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 98
om2_1    | 2022-06-16 01:14:31,641 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-D66704EFC61C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 62
om2_1    | 2022-06-16 01:14:32,024 [pool-26-thread-1] INFO raftlog.RaftLog: om2@group-D66704EFC61C-SegmentedRaftLog: commitIndex: updateToMax old=98, new=97, updated? false
om2_1    | 2022-06-16 01:14:32,043 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om2_1    | 2022-06-16 01:14:32,048 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om2_1    | 2022-06-16 01:14:32,055 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om2_1    | 2022-06-16 01:14:32,056 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om2_1    | 2022-06-16 01:14:32,064 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om2_1    | 2022-06-16 01:14:32,068 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om2_1    | 2022-06-16 01:14:32,406 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1    | 2022-06-16 01:14:32,410 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om2_1    | 2022-06-16 01:14:32,413 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om2_1    | 2022-06-16 01:14:32,413 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om2_1    | 2022-06-16 01:14:32,416 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om2_1    | 2022-06-16 01:14:32,724 [main] INFO reflections.Reflections: Reflections took 3224 ms to scan 8 urls, producing 23 keys and 507 values [using 2 cores]
om2_1    | 2022-06-16 01:14:33,114 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om2_1    | 2022-06-16 01:14:33,152 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om2_1    | 2022-06-16 01:14:33,710 [Listener at om2/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om2_1    | 2022-06-16 01:14:33,757 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om2_1    | 2022-06-16 01:14:33,760 [Listener at om2/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om2_1    | 2022-06-16 01:14:33,929 [Listener at om2/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om2/10.9.0.12:9862
om2_1    | 2022-06-16 01:14:33,937 [Listener at om2/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om2 at port 9872
dn1_1    | 2022-06-16 01:15:15,855 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: shutdown 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState
dn1_1    | 2022-06-16 01:15:15,855 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: changes role from  FOLLOWER to CANDIDATE at term 17 for changeToCandidate
dn1_1    | 2022-06-16 01:15:15,855 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn1_1    | 2022-06-16 01:15:15,855 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection13
dn1_1    | 2022-06-16 01:15:15,857 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection13] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection13 ELECTION round 0: submit vote requests at term 18 for 19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:15:15,877 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: receive requestVote(ELECTION, c3461ed7-1554-428d-9478-8d95583cf36e, group-8C8526B83399, 18, (t:8, i:28))
dn1_1    | 2022-06-16 01:15:15,878 [grpc-default-executor-0] INFO impl.VoteContext: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-CANDIDATE: reject ELECTION from c3461ed7-1554-428d-9478-8d95583cf36e: already has voted for 8b366c76-456d-4ec7-ac8e-95910f7eaaa6 at current term 18
dn1_1    | 2022-06-16 01:15:15,878 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399 replies to ELECTION vote request: c3461ed7-1554-428d-9478-8d95583cf36e<-8b366c76-456d-4ec7-ac8e-95910f7eaaa6#0:FAIL-t18. Peer's state: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399:t18, leader=null, voted=8b366c76-456d-4ec7-ac8e-95910f7eaaa6, raftlog=8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:15:15,881 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection13] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection13: ELECTION REJECTED received 1 response(s) and 0 exception(s):
dn1_1    | 2022-06-16 01:15:15,884 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection13] INFO impl.LeaderElection:   Response 0: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t18
dn1_1    | 2022-06-16 01:15:15,884 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection13] INFO impl.LeaderElection: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection13 ELECTION round 0: result REJECTED
dn1_1    | 2022-06-16 01:15:15,884 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection13] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: changes role from CANDIDATE to FOLLOWER at term 18 for REJECTED
dn1_1    | 2022-06-16 01:15:15,884 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection13] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: shutdown 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection13
dn1_1    | 2022-06-16 01:15:15,885 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-LeaderElection13] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState
dn1_1    | 2022-06-16 01:15:15,900 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: receive requestVote(ELECTION, c7eeb289-59cc-4c90-a00f-b0c50499b5ba, group-8C8526B83399, 18, (t:8, i:28))
dn1_1    | 2022-06-16 01:15:15,901 [grpc-default-executor-0] INFO impl.VoteContext: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FOLLOWER: reject ELECTION from c7eeb289-59cc-4c90-a00f-b0c50499b5ba: already has voted for 8b366c76-456d-4ec7-ac8e-95910f7eaaa6 at current term 18
dn1_1    | 2022-06-16 01:15:15,901 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399 replies to ELECTION vote request: c7eeb289-59cc-4c90-a00f-b0c50499b5ba<-8b366c76-456d-4ec7-ac8e-95910f7eaaa6#0:FAIL-t18. Peer's state: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399:t18, leader=null, voted=8b366c76-456d-4ec7-ac8e-95910f7eaaa6, raftlog=8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:15:20,913 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: receive requestVote(ELECTION, c3461ed7-1554-428d-9478-8d95583cf36e, group-8C8526B83399, 19, (t:8, i:28))
dn1_1    | 2022-06-16 01:15:20,913 [grpc-default-executor-0] INFO impl.VoteContext: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FOLLOWER: accept ELECTION from c3461ed7-1554-428d-9478-8d95583cf36e: our priority 0 <= candidate's priority 1
dn1_1    | 2022-06-16 01:15:20,913 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: changes role from  FOLLOWER to FOLLOWER at term 19 for candidate:c3461ed7-1554-428d-9478-8d95583cf36e
dn1_1    | 2022-06-16 01:15:20,913 [grpc-default-executor-0] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: shutdown 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState
dn1_1    | 2022-06-16 01:15:20,913 [grpc-default-executor-0] INFO impl.RoleInfo: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: start 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState
dn1_1    | 2022-06-16 01:15:20,914 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState] INFO impl.FollowerState: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-FollowerState was interrupted
om3_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.4.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.14.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-intg-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.6.3.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.44.v20210927.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/gson-2.8.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om3_1    | STARTUP_MSG:   build = https://github.com/apache/ozone/17d3301a908af2df7683a0c61b8ee3ae8dd41d6a ; compiled by 'runner' on 2022-06-16T00:51Z
om3_1    | STARTUP_MSG:   java = 11.0.14.1
om3_1    | ************************************************************/
om3_1    | 2022-06-16 01:13:40,799 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1    | 2022-06-16 01:13:51,144 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om3_1    | 2022-06-16 01:13:54,454 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om3_1    | 2022-06-16 01:13:55,258 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: omservice, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1    | 2022-06-16 01:13:55,258 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.omservice.om3: om3
om3_1    | 2022-06-16 01:13:55,287 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1    | 2022-06-16 01:13:55,616 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = MULTITENANCY_SCHEMA (version = 3)
om3_1    | 2022-06-16 01:13:58,523 [main] INFO reflections.Reflections: Reflections took 2366 ms to scan 1 urls, producing 114 keys and 339 values [using 2 cores]
om3_1    | 2022-06-16 01:13:58,772 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1    | 2022-06-16 01:14:01,139 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863]
om3_1    | 2022-06-16 01:14:01,355 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863]
om3_1    | 2022-06-16 01:14:04,148 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 4ceb6711a080/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2022-06-16 01:14:06,149 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 4ceb6711a080/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2022-06-16 01:14:08,151 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 4ceb6711a080/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2022-06-16 01:14:10,155 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 4ceb6711a080/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2022-06-16 01:14:12,156 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 4ceb6711a080/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2022-06-16 01:14:14,159 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 4ceb6711a080/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2022-06-16 01:14:16,161 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 4ceb6711a080/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2022-06-16 01:14:18,163 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 4ceb6711a080/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2022-06-16 01:14:24,029 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1    | 2022-06-16 01:14:24,556 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om3_1    | 2022-06-16 01:14:24,561 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om3_1    | 2022-06-16 01:14:25,242 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om3_1    | 2022-06-16 01:14:25,446 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1    | 2022-06-16 01:14:25,448 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om3_1    | 2022-06-16 01:14:25,466 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om3_1    | 2022-06-16 01:14:25,933 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om3_1    | 2022-06-16 01:14:25,976 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1    | 2022-06-16 01:14:26,070 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: omservice and peers: om3:9872, om1:9872, om2:9872
om3_1    | 2022-06-16 01:14:26,240 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:6, i:98)
om3_1    | 2022-06-16 01:14:26,512 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om3_1    | 2022-06-16 01:14:27,376 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om3_1    | 2022-06-16 01:14:27,384 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1    | 2022-06-16 01:14:27,384 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om3_1    | 2022-06-16 01:14:27,386 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1    | 2022-06-16 01:14:27,386 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1    | 2022-06-16 01:14:27,387 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om3_1    | 2022-06-16 01:14:27,388 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1    | 2022-06-16 01:14:27,397 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om3_1    | 2022-06-16 01:14:27,416 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1    | 2022-06-16 01:14:27,492 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om3_1    | 2022-06-16 01:14:27,500 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om3_1    | 2022-06-16 01:14:29,286 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om3_1    | 2022-06-16 01:14:29,302 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om3_1    | 2022-06-16 01:14:29,303 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om3_1    | 2022-06-16 01:14:29,304 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1    | 2022-06-16 01:14:29,304 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1    | 2022-06-16 01:14:29,366 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1    | 2022-06-16 01:14:29,415 [om3-impl-thread1] INFO server.RaftServer: om3: found a subdirectory /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c
om3_1    | 2022-06-16 01:14:29,460 [main] INFO server.RaftServer: om3: addNew group-D66704EFC61C:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-D66704EFC61C:java.util.concurrent.CompletableFuture@388c519[Not completed]
om3_1    | 2022-06-16 01:14:29,460 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om3_1    | 2022-06-16 01:14:29,699 [pool-26-thread-1] INFO server.RaftServer$Division: om3: new RaftServerImpl for group-D66704EFC61C:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om3_1    | 2022-06-16 01:14:29,700 [main] INFO om.OzoneManager: Creating RPC Server
om3_1    | 2022-06-16 01:14:29,729 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om3_1    | 2022-06-16 01:14:29,741 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om3_1    | 2022-06-16 01:14:29,741 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om3_1    | 2022-06-16 01:14:29,741 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1    | 2022-06-16 01:14:29,741 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1    | 2022-06-16 01:14:29,741 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om3_1    | 2022-06-16 01:14:29,835 [pool-26-thread-1] INFO server.RaftServer$Division: om3@group-D66704EFC61C: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om3_1    | 2022-06-16 01:14:29,835 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1    | 2022-06-16 01:14:29,898 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om3_1    | 2022-06-16 01:14:29,905 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om3_1    | 2022-06-16 01:14:30,076 [pool-26-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/in_use.lock acquired by nodename 7@4ceb6711a080
om3_1    | 2022-06-16 01:14:30,105 [pool-26-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=6, votedFor=om2} from /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/raft-meta
dn1_1    | 2022-06-16 01:15:20,918 [grpc-default-executor-0] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399 replies to ELECTION vote request: c3461ed7-1554-428d-9478-8d95583cf36e<-8b366c76-456d-4ec7-ac8e-95910f7eaaa6#0:OK-t19. Peer's state: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399:t19, leader=null, voted=c3461ed7-1554-428d-9478-8d95583cf36e, raftlog=8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:15:20,995 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-8C8526B83399 with new leaderId: c3461ed7-1554-428d-9478-8d95583cf36e
dn1_1    | 2022-06-16 01:15:20,995 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6-server-thread1] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: change Leader from null to c3461ed7-1554-428d-9478-8d95583cf36e at term 19 for appendEntries, leader elected after 63456ms
dn1_1    | 2022-06-16 01:15:21,015 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6-server-thread1] INFO server.RaftServer$Division: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399: set configuration 29: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-06-16 01:15:21,015 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6-server-thread1] INFO segmented.SegmentedRaftLogWorker: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-SegmentedRaftLogWorker: Rolling segment log-19_28 to index:28
dn1_1    | 2022-06-16 01:15:21,016 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399/current/log_inprogress_19 to /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399/current/log_19-28
dn1_1    | 2022-06-16 01:15:21,022 [8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6@group-8C8526B83399-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399/current/log_inprogress_29
dn1_1    | 2022-06-16 01:15:28,619 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn1_1    | 2022-06-16 01:15:28,620 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn1_1    | 2022-06-16 01:15:28,620 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn1_1    | 2022-06-16 01:15:28,620 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn1_1    | 2022-06-16 01:15:28,620 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn1_1    | 2022-06-16 01:15:28,620 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:15:28,620 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:15:28,620 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn1_1    | 2022-06-16 01:15:28,620 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn1_1    | 2022-06-16 01:15:28,620 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn1_1    | 2022-06-16 01:15:28,620 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn1_1    | 2022-06-16 01:15:28,620 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn1_1    | 2022-06-16 01:15:28,620 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
om2_1    | 2022-06-16 01:14:33,946 [om2-impl-thread1] INFO server.RaftServer$Division: om2@group-D66704EFC61C: start as a follower, conf=63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1    | 2022-06-16 01:14:33,947 [om2-impl-thread1] INFO server.RaftServer$Division: om2@group-D66704EFC61C: changes role from      null to FOLLOWER at term 6 for startAsFollower
om2_1    | 2022-06-16 01:14:33,950 [om2-impl-thread1] INFO impl.RoleInfo: om2: start om2@group-D66704EFC61C-FollowerState
om2_1    | 2022-06-16 01:14:33,980 [om2-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D66704EFC61C,id=om2
om2_1    | 2022-06-16 01:14:33,996 [Listener at om2/9862] INFO server.RaftServer: om2: start RPC server
om2_1    | 2022-06-16 01:14:34,214 [Listener at om2/9862] INFO server.GrpcService: om2: GrpcService started, listening on 9872
om2_1    | 2022-06-16 01:14:34,222 [Listener at om2/9862] INFO upgrade.UpgradeFinalizer: Running pre-finalized state validations for unfinalized layout features.
om2_1    | 2022-06-16 01:14:34,224 [Listener at om2/9862] INFO upgrade.UpgradeFinalizer: Running first upgrade commands for unfinalized layout features.
om2_1    | 2022-06-16 01:14:34,224 [Listener at om2/9862] INFO om.OzoneManager: Version File has different layout version (0) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om2_1    | 2022-06-16 01:14:34,233 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$427/0x000000084055f040@52f8a6f4] INFO util.JvmPauseMonitor: JvmPauseMonitor-om2: Started
om2_1    | 2022-06-16 01:14:34,365 [Listener at om2/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om2_1    | 2022-06-16 01:14:34,366 [Listener at om2/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om2_1    | 2022-06-16 01:14:34,569 [Listener at om2/9862] INFO util.log: Logging initialized @64671ms to org.eclipse.jetty.util.log.Slf4jLog
om2_1    | 2022-06-16 01:14:34,882 [Listener at om2/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om2_1    | 2022-06-16 01:14:34,899 [Listener at om2/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om2_1    | 2022-06-16 01:14:34,916 [Listener at om2/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om2_1    | 2022-06-16 01:14:34,920 [Listener at om2/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om2_1    | 2022-06-16 01:14:34,920 [Listener at om2/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om2_1    | 2022-06-16 01:14:34,920 [Listener at om2/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om2_1    | 2022-06-16 01:14:35,009 [Listener at om2/9862] INFO http.HttpServer2: Jetty bound to port 9874
om2_1    | 2022-06-16 01:14:35,025 [Listener at om2/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om2_1    | 2022-06-16 01:14:35,173 [Listener at om2/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om2_1    | 2022-06-16 01:14:35,177 [Listener at om2/9862] INFO server.session: No SessionScavenger set, using defaults
om2_1    | 2022-06-16 01:14:35,191 [Listener at om2/9862] INFO server.session: node0 Scavenging every 600000ms
om2_1    | 2022-06-16 01:14:35,227 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3f6c2763{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om2_1    | 2022-06-16 01:14:35,238 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3ffd4b12{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om2_1    | 2022-06-16 01:14:35,817 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7cdb7fc{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-13484338735967963442/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om2_1    | 2022-06-16 01:14:35,854 [Listener at om2/9862] INFO server.AbstractConnector: Started ServerConnector@2e3f324e{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om2_1    | 2022-06-16 01:14:35,854 [Listener at om2/9862] INFO server.Server: Started @65957ms
om2_1    | 2022-06-16 01:14:35,876 [Listener at om2/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om2_1    | 2022-06-16 01:14:35,877 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om2_1    | 2022-06-16 01:14:35,879 [Listener at om2/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om2_1    | 2022-06-16 01:14:35,890 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1    | 2022-06-16 01:14:35,901 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om2_1    | 2022-06-16 01:14:36,119 [Listener at om2/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted won't move to trash
om2_1    | 2022-06-16 01:14:36,140 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@439d545c] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om2_1    | 2022-06-16 01:14:39,113 [om2@group-D66704EFC61C-FollowerState] INFO impl.FollowerState: om2@group-D66704EFC61C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5165425263ns, electionTimeout:5145ms
om2_1    | 2022-06-16 01:14:39,115 [om2@group-D66704EFC61C-FollowerState] INFO impl.RoleInfo: om2: shutdown om2@group-D66704EFC61C-FollowerState
om2_1    | 2022-06-16 01:14:39,116 [om2@group-D66704EFC61C-FollowerState] INFO server.RaftServer$Division: om2@group-D66704EFC61C: changes role from  FOLLOWER to CANDIDATE at term 6 for changeToCandidate
om2_1    | 2022-06-16 01:14:39,119 [om2@group-D66704EFC61C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om2_1    | 2022-06-16 01:14:39,120 [om2@group-D66704EFC61C-FollowerState] INFO impl.RoleInfo: om2: start om2@group-D66704EFC61C-LeaderElection1
om2_1    | 2022-06-16 01:14:39,148 [om2@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om2@group-D66704EFC61C-LeaderElection1 ELECTION round 0: submit vote requests at term 7 for 63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1    | 2022-06-16 01:14:40,591 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-D66704EFC61C: receive requestVote(ELECTION, om1, group-D66704EFC61C, 7, (t:6, i:98))
om2_1    | 2022-06-16 01:14:40,595 [grpc-default-executor-0] INFO impl.VoteContext: om2@group-D66704EFC61C-CANDIDATE: reject ELECTION from om1: already has voted for om2 at current term 7
om2_1    | 2022-06-16 01:14:40,613 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-D66704EFC61C: receive requestVote(ELECTION, om3, group-D66704EFC61C, 7, (t:6, i:98))
dn5_1    | 2022-06-16 01:14:15,958 [pool-46-thread-1] INFO segmented.SegmentedRaftLogWorker: new c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de
dn5_1    | 2022-06-16 01:14:15,958 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn5_1    | 2022-06-16 01:14:15,958 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn5_1    | 2022-06-16 01:14:15,967 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn5_1    | 2022-06-16 01:14:15,968 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn5_1    | 2022-06-16 01:14:15,968 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn5_1    | 2022-06-16 01:14:15,969 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn5_1    | 2022-06-16 01:14:15,970 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn5_1    | 2022-06-16 01:14:15,970 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn5_1    | 2022-06-16 01:14:15,971 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn5_1    | 2022-06-16 01:14:15,979 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn5_1    | 2022-06-16 01:14:15,990 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn5_1    | 2022-06-16 01:14:15,991 [pool-46-thread-1] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE: set configuration 0: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn5_1    | 2022-06-16 01:14:16,038 [pool-46-thread-1] INFO segmented.LogSegment: Successfully read 4 entries from segment file /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de/current/log_0-3
dn5_1    | 2022-06-16 01:14:16,039 [pool-46-thread-1] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE: set configuration 4: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn5_1    | 2022-06-16 01:14:16,060 [pool-46-thread-1] INFO segmented.LogSegment: Successfully read 18 entries from segment file /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de/current/log_4-21
dn5_1    | 2022-06-16 01:14:16,073 [pool-46-thread-1] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE: set configuration 22: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn5_1    | 2022-06-16 01:14:16,090 [pool-46-thread-1] INFO segmented.LogSegment: Successfully read 17 entries from segment file /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de/current/log_inprogress_22
dn5_1    | 2022-06-16 01:14:16,109 [pool-46-thread-1] INFO segmented.SegmentedRaftLogWorker: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 38
dn5_1    | 2022-06-16 01:14:16,110 [pool-46-thread-1] INFO segmented.SegmentedRaftLogWorker: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 21
dn5_1    | 2022-06-16 01:14:16,110 [pool-46-thread-1] INFO raftlog.RaftLog: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-SegmentedRaftLog: commitIndex: updateToMax old=38, new=36, updated? false
dn5_1    | 2022-06-16 01:14:16,114 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn5_1    | 2022-06-16 01:14:16,114 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn5_1    | 2022-06-16 01:14:16,117 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn5_1    | 2022-06-16 01:14:16,117 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn5_1    | 2022-06-16 01:14:16,120 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn5_1    | 2022-06-16 01:14:16,120 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn5_1    | 2022-06-16 01:14:16,128 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn5_1    | 2022-06-16 01:14:16,134 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn5_1    | 2022-06-16 01:14:16,140 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn5_1    | 2022-06-16 01:14:16,140 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn5_1    | 2022-06-16 01:14:16,141 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn5_1    | 2022-06-16 01:14:16,223 [pool-46-thread-1] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e: new RaftServerImpl for group-8C8526B83399:[] with ContainerStateMachine:uninitialized
dn5_1    | 2022-06-16 01:14:16,243 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn5_1    | 2022-06-16 01:14:16,254 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn5_1    | 2022-06-16 01:14:16,254 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn5_1    | 2022-06-16 01:14:16,255 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn5_1    | 2022-06-16 01:14:16,256 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn5_1    | 2022-06-16 01:14:16,257 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn5_1    | 2022-06-16 01:14:16,258 [pool-46-thread-1] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn5_1    | 2022-06-16 01:14:16,259 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn5_1    | 2022-06-16 01:14:16,282 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn5_1    | 2022-06-16 01:14:16,286 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn5_1    | 2022-06-16 01:14:16,347 [pool-46-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399/in_use.lock acquired by nodename 7@5d7def869eda
om2_1    | 2022-06-16 01:14:40,645 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-D66704EFC61C replies to ELECTION vote request: om1<-om2#0:FAIL-t7. Peer's state: om2@group-D66704EFC61C:t7, leader=null, voted=om2, raftlog=om2@group-D66704EFC61C-SegmentedRaftLog:OPENED:c98, conf=63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1    | 2022-06-16 01:14:40,652 [grpc-default-executor-1] INFO impl.VoteContext: om2@group-D66704EFC61C-CANDIDATE: reject ELECTION from om3: already has voted for om2 at current term 7
om2_1    | 2022-06-16 01:14:40,661 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-D66704EFC61C replies to ELECTION vote request: om3<-om2#0:FAIL-t7. Peer's state: om2@group-D66704EFC61C:t7, leader=null, voted=om2, raftlog=om2@group-D66704EFC61C-SegmentedRaftLog:OPENED:c98, conf=63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1    | 2022-06-16 01:14:40,795 [om2@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om2@group-D66704EFC61C-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om2_1    | 2022-06-16 01:14:40,797 [om2@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection:   Response 0: om2<-om1#0:FAIL-t7
om2_1    | 2022-06-16 01:14:40,797 [om2@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection:   Response 1: om2<-om3#0:FAIL-t7
om2_1    | 2022-06-16 01:14:40,798 [om2@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om2@group-D66704EFC61C-LeaderElection1 ELECTION round 0: result REJECTED
om2_1    | 2022-06-16 01:14:40,808 [om2@group-D66704EFC61C-LeaderElection1] INFO server.RaftServer$Division: om2@group-D66704EFC61C: changes role from CANDIDATE to FOLLOWER at term 7 for REJECTED
om2_1    | 2022-06-16 01:14:40,808 [om2@group-D66704EFC61C-LeaderElection1] INFO impl.RoleInfo: om2: shutdown om2@group-D66704EFC61C-LeaderElection1
om2_1    | 2022-06-16 01:14:40,818 [om2@group-D66704EFC61C-LeaderElection1] INFO impl.RoleInfo: om2: start om2@group-D66704EFC61C-FollowerState
om2_1    | 2022-06-16 01:14:45,859 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-D66704EFC61C: receive requestVote(ELECTION, om1, group-D66704EFC61C, 8, (t:6, i:98))
om2_1    | 2022-06-16 01:14:45,863 [grpc-default-executor-0] INFO impl.VoteContext: om2@group-D66704EFC61C-FOLLOWER: accept ELECTION from om1: our priority 0 <= candidate's priority 0
om2_1    | 2022-06-16 01:14:45,864 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-D66704EFC61C: changes role from  FOLLOWER to FOLLOWER at term 8 for candidate:om1
om2_1    | 2022-06-16 01:14:45,864 [grpc-default-executor-0] INFO impl.RoleInfo: om2: shutdown om2@group-D66704EFC61C-FollowerState
om2_1    | 2022-06-16 01:14:45,865 [grpc-default-executor-0] INFO impl.RoleInfo: om2: start om2@group-D66704EFC61C-FollowerState
om2_1    | 2022-06-16 01:14:45,865 [om2@group-D66704EFC61C-FollowerState] INFO impl.FollowerState: om2@group-D66704EFC61C-FollowerState was interrupted
om2_1    | 2022-06-16 01:14:45,870 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-D66704EFC61C replies to ELECTION vote request: om1<-om2#0:OK-t8. Peer's state: om2@group-D66704EFC61C:t8, leader=null, voted=om1, raftlog=om2@group-D66704EFC61C-SegmentedRaftLog:OPENED:c98, conf=63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1    | 2022-06-16 01:14:46,017 [om2-server-thread1] INFO server.RaftServer$Division: om2@group-D66704EFC61C: change Leader from null to om1 at term 8 for appendEntries, leader elected after 15570ms
om2_1    | 2022-06-16 01:14:46,082 [om2-server-thread1] INFO server.RaftServer$Division: om2@group-D66704EFC61C: set configuration 99: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1    | 2022-06-16 01:14:46,085 [om2-server-thread1] INFO segmented.SegmentedRaftLogWorker: om2@group-D66704EFC61C-SegmentedRaftLogWorker: Rolling segment log-63_98 to index:98
om2_1    | 2022-06-16 01:14:46,091 [om2@group-D66704EFC61C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om2@group-D66704EFC61C-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_inprogress_63 to /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_63-98
om2_1    | 2022-06-16 01:14:46,136 [om2@group-D66704EFC61C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om2@group-D66704EFC61C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_inprogress_99
om2_1    | 2022-06-16 01:14:46,363 [om2@group-D66704EFC61C-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om2_1    | [id: "om1"
om2_1    | address: "om1:9872"
om2_1    | , id: "om3"
om2_1    | address: "om3:9872"
om2_1    | , id: "om2"
om2_1    | address: "om2:9872"
om2_1    | ]
om2_1    | 2022-06-16 01:19:51,821 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: Finalization started.
om2_1    | 2022-06-16 01:19:51,824 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: ERASURE_CODED_STORAGE_SUPPORT.
om2_1    | 2022-06-16 01:19:51,832 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.AbstractLayoutVersionManager: Layout feature ERASURE_CODED_STORAGE_SUPPORT has been finalized.
om2_1    | 2022-06-16 01:19:51,833 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: BUCKET_LAYOUT_SUPPORT.
om2_1    | 2022-06-16 01:19:51,835 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.AbstractLayoutVersionManager: Layout feature BUCKET_LAYOUT_SUPPORT has been finalized.
om2_1    | 2022-06-16 01:19:51,835 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: MULTITENANCY_SCHEMA.
om2_1    | 2022-06-16 01:19:51,839 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.AbstractLayoutVersionManager: Layout feature MULTITENANCY_SCHEMA has been finalized.
om2_1    | 2022-06-16 01:19:51,839 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.AbstractLayoutVersionManager: Finalization is complete.
om2_1    | 2022-06-16 01:19:51,841 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: Finalization is done.
om2_1    | 2022-06-16 01:19:51,858 [OMDoubleBufferFlushThread] INFO upgrade.OMFinalizeUpgradeResponse: Layout version to persist to DB : 3
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:15:28,620 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:15:28,620 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn1_1    | 2022-06-16 01:15:28,621 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn1_1    | 2022-06-16 01:15:28,621 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn1_1    | 2022-06-16 01:15:28,621 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn1_1    | 2022-06-16 01:15:28,621 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn1_1    | 2022-06-16 01:15:28,621 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:15:28,621 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:15:28,621 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn1_1    | 2022-06-16 01:15:28,621 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn1_1    | 2022-06-16 01:15:28,621 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn1_1    | 2022-06-16 01:15:28,621 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn1_1    | 2022-06-16 01:15:28,621 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn1_1    | 2022-06-16 01:15:28,621 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:15:28,621 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
om1_1    | 2022-06-16 01:14:40,733 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-D66704EFC61C replies to ELECTION vote request: om2<-om1#0:FAIL-t7. Peer's state: om1@group-D66704EFC61C:t7, leader=null, voted=om1, raftlog=om1@group-D66704EFC61C-SegmentedRaftLog:OPENED:c98, conf=63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1    | 2022-06-16 01:14:40,748 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om1@group-D66704EFC61C-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om1_1    | 2022-06-16 01:14:40,750 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection:   Response 0: om1<-om3#0:FAIL-t7
om1_1    | 2022-06-16 01:14:40,750 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection:   Response 1: om1<-om2#0:FAIL-t7
om1_1    | 2022-06-16 01:14:40,751 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om1@group-D66704EFC61C-LeaderElection1 ELECTION round 0: result REJECTED
om1_1    | 2022-06-16 01:14:40,752 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: changes role from CANDIDATE to FOLLOWER at term 7 for REJECTED
om1_1    | 2022-06-16 01:14:40,752 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.RoleInfo: om1: shutdown om1@group-D66704EFC61C-LeaderElection1
om1_1    | 2022-06-16 01:14:40,753 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.RoleInfo: om1: start om1@group-D66704EFC61C-FollowerState
om1_1    | 2022-06-16 01:14:45,849 [om1@group-D66704EFC61C-FollowerState] INFO impl.FollowerState: om1@group-D66704EFC61C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5096540112ns, electionTimeout:5083ms
om1_1    | 2022-06-16 01:14:45,850 [om1@group-D66704EFC61C-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-D66704EFC61C-FollowerState
om1_1    | 2022-06-16 01:14:45,850 [om1@group-D66704EFC61C-FollowerState] INFO server.RaftServer$Division: om1@group-D66704EFC61C: changes role from  FOLLOWER to CANDIDATE at term 7 for changeToCandidate
om1_1    | 2022-06-16 01:14:45,850 [om1@group-D66704EFC61C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om1_1    | 2022-06-16 01:14:45,850 [om1@group-D66704EFC61C-FollowerState] INFO impl.RoleInfo: om1: start om1@group-D66704EFC61C-LeaderElection2
om1_1    | 2022-06-16 01:14:45,852 [om1@group-D66704EFC61C-LeaderElection2] INFO impl.LeaderElection: om1@group-D66704EFC61C-LeaderElection2 ELECTION round 0: submit vote requests at term 8 for 63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1    | 2022-06-16 01:14:45,879 [om1@group-D66704EFC61C-LeaderElection2] INFO impl.LeaderElection: om1@group-D66704EFC61C-LeaderElection2: ELECTION PASSED received 1 response(s) and 0 exception(s):
om1_1    | 2022-06-16 01:14:45,880 [om1@group-D66704EFC61C-LeaderElection2] INFO impl.LeaderElection:   Response 0: om1<-om2#0:OK-t8
om1_1    | 2022-06-16 01:14:45,880 [om1@group-D66704EFC61C-LeaderElection2] INFO impl.LeaderElection: om1@group-D66704EFC61C-LeaderElection2 ELECTION round 0: result PASSED
om1_1    | 2022-06-16 01:14:45,880 [om1@group-D66704EFC61C-LeaderElection2] INFO impl.RoleInfo: om1: shutdown om1@group-D66704EFC61C-LeaderElection2
om1_1    | 2022-06-16 01:14:45,880 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServer$Division: om1@group-D66704EFC61C: changes role from CANDIDATE to LEADER at term 8 for changeToLeader
om1_1    | 2022-06-16 01:14:45,881 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServer$Division: om1@group-D66704EFC61C: change Leader from null to om1 at term 8 for becomeLeader, leader elected after 15003ms
om1_1    | 2022-06-16 01:14:45,888 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om1_1    | 2022-06-16 01:14:45,893 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om1_1    | 2022-06-16 01:14:45,893 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
om1_1    | 2022-06-16 01:14:45,904 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om1_1    | 2022-06-16 01:14:45,904 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om1_1    | 2022-06-16 01:14:45,905 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om1_1    | 2022-06-16 01:14:45,909 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om1_1    | 2022-06-16 01:14:45,912 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
om1_1    | 2022-06-16 01:14:45,926 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om1_1    | 2022-06-16 01:14:45,927 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1    | 2022-06-16 01:14:45,928 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om1_1    | 2022-06-16 01:14:45,931 [om1@group-D66704EFC61C-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om1_1    | 2022-06-16 01:14:45,932 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1    | 2022-06-16 01:14:45,932 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1    | 2022-06-16 01:14:45,935 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om1_1    | 2022-06-16 01:14:45,936 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1    | 2022-06-16 01:14:45,936 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om1_1    | 2022-06-16 01:14:45,936 [om1@group-D66704EFC61C-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om1_1    | 2022-06-16 01:14:45,937 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1    | 2022-06-16 01:14:45,937 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1    | 2022-06-16 01:14:45,939 [om1@group-D66704EFC61C-LeaderElection2] INFO impl.RoleInfo: om1: start om1@group-D66704EFC61C-LeaderStateImpl
om1_1    | 2022-06-16 01:14:45,948 [om1@group-D66704EFC61C-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: om1@group-D66704EFC61C-SegmentedRaftLogWorker: Rolling segment log-63_98 to index:98
om1_1    | 2022-06-16 01:14:45,952 [om1@group-D66704EFC61C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-D66704EFC61C-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_inprogress_63 to /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_63-98
om3_1    | 2022-06-16 01:14:30,758 [pool-26-thread-1] INFO server.RaftServer$Division: om3@group-D66704EFC61C: set configuration 63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1    | 2022-06-16 01:14:30,777 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om3_1    | 2022-06-16 01:14:30,905 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om3_1    | 2022-06-16 01:14:31,037 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om3_1    | 2022-06-16 01:14:31,069 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1    | 2022-06-16 01:14:31,072 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om3_1    | 2022-06-16 01:14:31,240 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1    | 2022-06-16 01:14:31,297 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om3_1    | 2022-06-16 01:14:31,307 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om3_1    | 2022-06-16 01:14:31,340 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: new om3@group-D66704EFC61C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c
om3_1    | 2022-06-16 01:14:31,358 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om3_1    | 2022-06-16 01:14:31,367 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om3_1    | 2022-06-16 01:14:31,368 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1    | 2022-06-16 01:14:31,402 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om3_1    | 2022-06-16 01:14:31,410 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om3_1    | 2022-06-16 01:14:31,418 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om3_1    | 2022-06-16 01:14:31,428 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om3_1    | 2022-06-16 01:14:31,431 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om3_1    | 2022-06-16 01:14:31,499 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om3_1    | 2022-06-16 01:14:31,514 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om3_1    | 2022-06-16 01:14:31,517 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om3_1    | 2022-06-16 01:14:31,830 [pool-26-thread-1] INFO server.RaftServer$Division: om3@group-D66704EFC61C: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1    | 2022-06-16 01:14:31,878 [pool-26-thread-1] INFO segmented.LogSegment: Successfully read 21 entries from segment file /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_0-20
om3_1    | 2022-06-16 01:14:31,894 [pool-26-thread-1] INFO server.RaftServer$Division: om3@group-D66704EFC61C: set configuration 21: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1    | 2022-06-16 01:14:31,937 [pool-26-thread-1] INFO segmented.LogSegment: Successfully read 42 entries from segment file /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_21-62
om3_1    | 2022-06-16 01:14:31,938 [pool-26-thread-1] INFO server.RaftServer$Division: om3@group-D66704EFC61C: set configuration 63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1    | 2022-06-16 01:14:32,008 [pool-26-thread-1] INFO segmented.LogSegment: Successfully read 36 entries from segment file /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_inprogress_63
om3_1    | 2022-06-16 01:14:32,010 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-D66704EFC61C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 98
om3_1    | 2022-06-16 01:14:32,043 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-D66704EFC61C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 62
om3_1    | 2022-06-16 01:14:32,362 [main] INFO reflections.Reflections: Reflections took 2347 ms to scan 8 urls, producing 23 keys and 507 values [using 2 cores]
om3_1    | 2022-06-16 01:14:32,472 [pool-26-thread-1] INFO raftlog.RaftLog: om3@group-D66704EFC61C-SegmentedRaftLog: commitIndex: updateToMax old=98, new=97, updated? false
om3_1    | 2022-06-16 01:14:32,521 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om3_1    | 2022-06-16 01:14:32,537 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om3_1    | 2022-06-16 01:14:32,538 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om3_1    | 2022-06-16 01:14:32,539 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om3_1    | 2022-06-16 01:14:32,551 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om3_1    | 2022-06-16 01:14:32,560 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om3_1    | 2022-06-16 01:14:32,810 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1    | 2022-06-16 01:14:32,811 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om3_1    | 2022-06-16 01:14:32,815 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om3_1    | 2022-06-16 01:14:32,817 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om3_1    | 2022-06-16 01:14:32,817 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om3_1    | 2022-06-16 01:14:32,956 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1    | 2022-06-16 01:14:33,006 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om3_1    | 2022-06-16 01:14:33,501 [Listener at om3/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om3_1    | 2022-06-16 01:14:33,555 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om3_1    | 2022-06-16 01:14:33,559 [Listener at om3/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om3_1    | 2022-06-16 01:14:33,752 [Listener at om3/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om3/10.9.0.13:9862
om3_1    | 2022-06-16 01:14:33,752 [Listener at om3/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om3 at port 9872
dn2_1    | 2022-06-16 01:15:05,773 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399 replies to ELECTION vote request: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c7eeb289-59cc-4c90-a00f-b0c50499b5ba#0:OK-t16. Peer's state: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399:t16, leader=null, voted=8b366c76-456d-4ec7-ac8e-95910f7eaaa6, raftlog=c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-06-16 01:15:05,784 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: receive requestVote(ELECTION, c3461ed7-1554-428d-9478-8d95583cf36e, group-8C8526B83399, 16, (t:8, i:28))
dn2_1    | 2022-06-16 01:15:05,785 [grpc-default-executor-1] INFO impl.VoteContext: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FOLLOWER: reject ELECTION from c3461ed7-1554-428d-9478-8d95583cf36e: already has voted for 8b366c76-456d-4ec7-ac8e-95910f7eaaa6 at current term 16
dn2_1    | 2022-06-16 01:15:05,785 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399 replies to ELECTION vote request: c3461ed7-1554-428d-9478-8d95583cf36e<-c7eeb289-59cc-4c90-a00f-b0c50499b5ba#0:FAIL-t16. Peer's state: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399:t16, leader=null, voted=8b366c76-456d-4ec7-ac8e-95910f7eaaa6, raftlog=c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-06-16 01:15:10,836 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: receive requestVote(ELECTION, 8b366c76-456d-4ec7-ac8e-95910f7eaaa6, group-8C8526B83399, 17, (t:8, i:28))
dn2_1    | 2022-06-16 01:15:10,837 [grpc-default-executor-1] INFO impl.VoteContext: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FOLLOWER: accept ELECTION from 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: our priority 0 <= candidate's priority 0
dn2_1    | 2022-06-16 01:15:10,837 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: changes role from  FOLLOWER to FOLLOWER at term 17 for candidate:8b366c76-456d-4ec7-ac8e-95910f7eaaa6
dn2_1    | 2022-06-16 01:15:10,837 [grpc-default-executor-1] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: shutdown c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState
dn2_1    | 2022-06-16 01:15:10,837 [grpc-default-executor-1] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: start c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState
dn2_1    | 2022-06-16 01:15:10,838 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState] INFO impl.FollowerState: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState was interrupted
dn2_1    | 2022-06-16 01:15:10,844 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399 replies to ELECTION vote request: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c7eeb289-59cc-4c90-a00f-b0c50499b5ba#0:OK-t17. Peer's state: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399:t17, leader=null, voted=8b366c76-456d-4ec7-ac8e-95910f7eaaa6, raftlog=c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-06-16 01:15:11,748 [ContainerOp-cfb1d3a9-fa49-4890-85f5-5fc878c6c2de-0] INFO keyvalue.KeyValueContainer: Container 2 is synced with bcsId 2.
dn2_1    | 2022-06-16 01:15:11,753 [ContainerOp-cfb1d3a9-fa49-4890-85f5-5fc878c6c2de-0] INFO keyvalue.KeyValueContainer: Container 2 is synced with bcsId 2.
dn2_1    | 2022-06-16 01:15:11,781 [ContainerOp-cfb1d3a9-fa49-4890-85f5-5fc878c6c2de-0] INFO keyvalue.KeyValueContainer: Container 2 is closed with bcsId 2.
dn2_1    | 2022-06-16 01:15:11,954 [ContainerOp-cfb1d3a9-fa49-4890-85f5-5fc878c6c2de-1] INFO keyvalue.KeyValueContainer: Container 1001 is synced with bcsId 20.
dn2_1    | 2022-06-16 01:15:11,961 [ContainerOp-cfb1d3a9-fa49-4890-85f5-5fc878c6c2de-1] INFO keyvalue.KeyValueContainer: Container 1001 is synced with bcsId 20.
dn2_1    | 2022-06-16 01:15:11,968 [ContainerOp-cfb1d3a9-fa49-4890-85f5-5fc878c6c2de-1] INFO keyvalue.KeyValueContainer: Container 1001 is closed with bcsId 20.
dn2_1    | 2022-06-16 01:15:12,085 [ContainerOp-cfb1d3a9-fa49-4890-85f5-5fc878c6c2de-2] INFO keyvalue.KeyValueContainer: Container 2001 is synced with bcsId 36.
dn2_1    | 2022-06-16 01:15:12,086 [ContainerOp-cfb1d3a9-fa49-4890-85f5-5fc878c6c2de-2] INFO keyvalue.KeyValueContainer: Container 2001 is synced with bcsId 36.
dn2_1    | 2022-06-16 01:15:12,097 [ContainerOp-cfb1d3a9-fa49-4890-85f5-5fc878c6c2de-2] INFO keyvalue.KeyValueContainer: Container 2001 is closed with bcsId 36.
dn2_1    | 2022-06-16 01:15:12,143 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn2_1    | 2022-06-16 01:15:12,145 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn2_1    | 2022-06-16 01:15:12,146 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn2_1    | 2022-06-16 01:15:12,147 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn2_1    | 2022-06-16 01:15:12,147 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn2_1    | 2022-06-16 01:15:12,148 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:15:43,975 [org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@1ca3d25b] INFO commandhandler.DeleteBlocksCommandHandler: Start to delete container blocks, TXIDs=[2(0)], numOfContainers=1, numOfBlocks=1
dn1_1    | 2022-06-16 01:16:13,097 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn1_1    | 2022-06-16 01:16:13,098 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn1_1    | 2022-06-16 01:16:13,098 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn1_1    | 2022-06-16 01:16:13,098 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn1_1    | 2022-06-16 01:16:13,098 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn1_1    | 2022-06-16 01:16:13,098 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:16:13,098 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:16:21,671 [BlockDeletingService#0] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-3e3c8fff-8818-4ab8-8118-66b81944a69d/current/containerDir0/2/chunks/109611004723200002.block
dn1_1    | 2022-06-16 01:16:43,097 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn1_1    | 2022-06-16 01:16:43,098 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn1_1    | 2022-06-16 01:16:43,098 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn1_1    | 2022-06-16 01:16:43,098 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn1_1    | 2022-06-16 01:16:43,098 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn1_1    | 2022-06-16 01:16:43,098 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:16:43,098 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
om3_1    | 2022-06-16 01:14:33,753 [om3-impl-thread1] INFO server.RaftServer$Division: om3@group-D66704EFC61C: start as a follower, conf=63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1    | 2022-06-16 01:14:33,758 [om3-impl-thread1] INFO server.RaftServer$Division: om3@group-D66704EFC61C: changes role from      null to FOLLOWER at term 6 for startAsFollower
om3_1    | 2022-06-16 01:14:33,759 [om3-impl-thread1] INFO impl.RoleInfo: om3: start om3@group-D66704EFC61C-FollowerState
om3_1    | 2022-06-16 01:14:33,769 [om3-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D66704EFC61C,id=om3
om3_1    | 2022-06-16 01:14:33,778 [Listener at om3/9862] INFO server.RaftServer: om3: start RPC server
om3_1    | 2022-06-16 01:14:34,052 [Listener at om3/9862] INFO server.GrpcService: om3: GrpcService started, listening on 9872
om3_1    | 2022-06-16 01:14:34,056 [Listener at om3/9862] INFO upgrade.UpgradeFinalizer: Running pre-finalized state validations for unfinalized layout features.
om3_1    | 2022-06-16 01:14:34,065 [Listener at om3/9862] INFO upgrade.UpgradeFinalizer: Running first upgrade commands for unfinalized layout features.
om3_1    | 2022-06-16 01:14:34,067 [Listener at om3/9862] INFO om.OzoneManager: Version File has different layout version (0) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om3_1    | 2022-06-16 01:14:34,074 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$427/0x000000084055fc40@52ecc989] INFO util.JvmPauseMonitor: JvmPauseMonitor-om3: Started
om3_1    | 2022-06-16 01:14:34,254 [Listener at om3/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om3_1    | 2022-06-16 01:14:34,258 [Listener at om3/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om3_1    | 2022-06-16 01:14:34,388 [Listener at om3/9862] INFO util.log: Logging initialized @65358ms to org.eclipse.jetty.util.log.Slf4jLog
om3_1    | 2022-06-16 01:14:34,793 [Listener at om3/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om3_1    | 2022-06-16 01:14:34,827 [Listener at om3/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om3_1    | 2022-06-16 01:14:34,883 [Listener at om3/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om3_1    | 2022-06-16 01:14:34,896 [Listener at om3/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om3_1    | 2022-06-16 01:14:34,898 [Listener at om3/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om3_1    | 2022-06-16 01:14:34,899 [Listener at om3/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om3_1    | 2022-06-16 01:14:35,044 [Listener at om3/9862] INFO http.HttpServer2: Jetty bound to port 9874
om3_1    | 2022-06-16 01:14:35,049 [Listener at om3/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om3_1    | 2022-06-16 01:14:35,179 [Listener at om3/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om3_1    | 2022-06-16 01:14:35,179 [Listener at om3/9862] INFO server.session: No SessionScavenger set, using defaults
om3_1    | 2022-06-16 01:14:35,190 [Listener at om3/9862] INFO server.session: node0 Scavenging every 600000ms
om3_1    | 2022-06-16 01:14:35,225 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7bf018dd{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om3_1    | 2022-06-16 01:14:35,232 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2a484710{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om3_1    | 2022-06-16 01:14:35,714 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@597a7afa{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-8506295544313139254/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om3_1    | 2022-06-16 01:14:35,735 [Listener at om3/9862] INFO server.AbstractConnector: Started ServerConnector@6bb4cc0e{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om3_1    | 2022-06-16 01:14:35,739 [Listener at om3/9862] INFO server.Server: Started @66711ms
om3_1    | 2022-06-16 01:14:35,753 [Listener at om3/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om3_1    | 2022-06-16 01:14:35,753 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om3_1    | 2022-06-16 01:14:35,756 [Listener at om3/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om3_1    | 2022-06-16 01:14:35,756 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om3_1    | 2022-06-16 01:14:35,782 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om3_1    | 2022-06-16 01:14:35,921 [Listener at om3/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted won't move to trash
om3_1    | 2022-06-16 01:14:35,956 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@b75b890] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om3_1    | 2022-06-16 01:14:38,960 [om3@group-D66704EFC61C-FollowerState] INFO impl.FollowerState: om3@group-D66704EFC61C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5201406648ns, electionTimeout:5199ms
om3_1    | 2022-06-16 01:14:38,962 [om3@group-D66704EFC61C-FollowerState] INFO impl.RoleInfo: om3: shutdown om3@group-D66704EFC61C-FollowerState
om3_1    | 2022-06-16 01:14:38,963 [om3@group-D66704EFC61C-FollowerState] INFO server.RaftServer$Division: om3@group-D66704EFC61C: changes role from  FOLLOWER to CANDIDATE at term 6 for changeToCandidate
om3_1    | 2022-06-16 01:14:38,968 [om3@group-D66704EFC61C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om3_1    | 2022-06-16 01:14:38,969 [om3@group-D66704EFC61C-FollowerState] INFO impl.RoleInfo: om3: start om3@group-D66704EFC61C-LeaderElection1
om3_1    | 2022-06-16 01:14:39,000 [om3@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om3@group-D66704EFC61C-LeaderElection1 ELECTION round 0: submit vote requests at term 7 for 63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1    | 2022-06-16 01:14:40,598 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-D66704EFC61C: receive requestVote(ELECTION, om1, group-D66704EFC61C, 7, (t:6, i:98))
om3_1    | 2022-06-16 01:14:40,603 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-D66704EFC61C: receive requestVote(ELECTION, om2, group-D66704EFC61C, 7, (t:6, i:98))
om3_1    | 2022-06-16 01:14:40,613 [grpc-default-executor-1] INFO impl.VoteContext: om3@group-D66704EFC61C-CANDIDATE: reject ELECTION from om1: already has voted for om3 at current term 7
om1_1    | 2022-06-16 01:14:45,967 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServer$Division: om1@group-D66704EFC61C: set configuration 99: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1    | 2022-06-16 01:14:45,971 [om1@group-D66704EFC61C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-D66704EFC61C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_inprogress_99
om1_1    | 2022-06-16 01:14:46,386 [om1@group-D66704EFC61C-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om1_1    | [id: "om1"
om1_1    | address: "om1:9872"
om1_1    | , id: "om3"
om1_1    | address: "om3:9872"
om1_1    | , id: "om2"
om1_1    | address: "om2:9872"
om1_1    | ]
om1_1    | 2022-06-16 01:19:51,507 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: Finalization started.
om1_1    | 2022-06-16 01:19:51,519 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: ERASURE_CODED_STORAGE_SUPPORT.
om1_1    | 2022-06-16 01:19:51,557 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.AbstractLayoutVersionManager: Layout feature ERASURE_CODED_STORAGE_SUPPORT has been finalized.
om1_1    | 2022-06-16 01:19:51,559 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: BUCKET_LAYOUT_SUPPORT.
om1_1    | 2022-06-16 01:19:51,566 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.AbstractLayoutVersionManager: Layout feature BUCKET_LAYOUT_SUPPORT has been finalized.
om1_1    | 2022-06-16 01:19:51,567 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: MULTITENANCY_SCHEMA.
om1_1    | 2022-06-16 01:19:51,568 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.AbstractLayoutVersionManager: Layout feature MULTITENANCY_SCHEMA has been finalized.
om1_1    | 2022-06-16 01:19:51,568 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.AbstractLayoutVersionManager: Finalization is complete.
om1_1    | 2022-06-16 01:19:51,568 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: Finalization is done.
om1_1    | 2022-06-16 01:19:51,584 [OMDoubleBufferFlushThread] INFO upgrade.OMFinalizeUpgradeResponse: Layout version to persist to DB : 3
om3_1    | 2022-06-16 01:14:40,620 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-D66704EFC61C replies to ELECTION vote request: om1<-om3#0:FAIL-t7. Peer's state: om3@group-D66704EFC61C:t7, leader=null, voted=om3, raftlog=om3@group-D66704EFC61C-SegmentedRaftLog:OPENED:c98, conf=63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1    | 2022-06-16 01:14:40,623 [grpc-default-executor-0] INFO impl.VoteContext: om3@group-D66704EFC61C-CANDIDATE: reject ELECTION from om2: already has voted for om3 at current term 7
om3_1    | 2022-06-16 01:14:40,627 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-D66704EFC61C replies to ELECTION vote request: om2<-om3#0:FAIL-t7. Peer's state: om3@group-D66704EFC61C:t7, leader=null, voted=om3, raftlog=om3@group-D66704EFC61C-SegmentedRaftLog:OPENED:c98, conf=63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1    | 2022-06-16 01:14:40,772 [om3@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om3@group-D66704EFC61C-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om3_1    | 2022-06-16 01:14:40,772 [om3@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection:   Response 0: om3<-om1#0:FAIL-t7
om3_1    | 2022-06-16 01:14:40,772 [om3@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection:   Response 1: om3<-om2#0:FAIL-t7
om3_1    | 2022-06-16 01:14:40,772 [om3@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om3@group-D66704EFC61C-LeaderElection1 ELECTION round 0: result REJECTED
om3_1    | 2022-06-16 01:14:40,775 [om3@group-D66704EFC61C-LeaderElection1] INFO server.RaftServer$Division: om3@group-D66704EFC61C: changes role from CANDIDATE to FOLLOWER at term 7 for REJECTED
om3_1    | 2022-06-16 01:14:40,776 [om3@group-D66704EFC61C-LeaderElection1] INFO impl.RoleInfo: om3: shutdown om3@group-D66704EFC61C-LeaderElection1
om3_1    | 2022-06-16 01:14:40,776 [om3@group-D66704EFC61C-LeaderElection1] INFO impl.RoleInfo: om3: start om3@group-D66704EFC61C-FollowerState
om3_1    | 2022-06-16 01:14:45,860 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-D66704EFC61C: receive requestVote(ELECTION, om1, group-D66704EFC61C, 8, (t:6, i:98))
om3_1    | 2022-06-16 01:14:45,859 [om3@group-D66704EFC61C-FollowerState] INFO impl.FollowerState: om3@group-D66704EFC61C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5082460235ns, electionTimeout:5082ms
om3_1    | 2022-06-16 01:14:45,861 [om3@group-D66704EFC61C-FollowerState] INFO impl.RoleInfo: om3: shutdown om3@group-D66704EFC61C-FollowerState
om3_1    | 2022-06-16 01:14:45,861 [om3@group-D66704EFC61C-FollowerState] INFO server.RaftServer$Division: om3@group-D66704EFC61C: changes role from  FOLLOWER to CANDIDATE at term 7 for changeToCandidate
om3_1    | 2022-06-16 01:14:45,861 [om3@group-D66704EFC61C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om3_1    | 2022-06-16 01:14:45,862 [om3@group-D66704EFC61C-FollowerState] INFO impl.RoleInfo: om3: start om3@group-D66704EFC61C-LeaderElection2
om3_1    | 2022-06-16 01:14:45,863 [grpc-default-executor-1] INFO impl.VoteContext: om3@group-D66704EFC61C-CANDIDATE: accept ELECTION from om1: our priority 0 <= candidate's priority 0
om3_1    | 2022-06-16 01:14:45,864 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-D66704EFC61C: changes role from CANDIDATE to FOLLOWER at term 8 for candidate:om1
om3_1    | 2022-06-16 01:14:45,866 [grpc-default-executor-1] INFO impl.RoleInfo: om3: shutdown om3@group-D66704EFC61C-LeaderElection2
om3_1    | 2022-06-16 01:14:45,866 [grpc-default-executor-1] INFO impl.RoleInfo: om3: start om3@group-D66704EFC61C-FollowerState
om3_1    | 2022-06-16 01:14:45,867 [om3@group-D66704EFC61C-LeaderElection2] INFO impl.LeaderElection: om3@group-D66704EFC61C-LeaderElection2: skip running since this is already CLOSING
om3_1    | 2022-06-16 01:14:45,879 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-D66704EFC61C replies to ELECTION vote request: om1<-om3#0:OK-t8. Peer's state: om3@group-D66704EFC61C:t8, leader=null, voted=om1, raftlog=om3@group-D66704EFC61C-SegmentedRaftLog:OPENED:c98, conf=63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1    | 2022-06-16 01:14:46,012 [om3-server-thread1] INFO server.RaftServer$Division: om3@group-D66704EFC61C: change Leader from null to om1 at term 8 for appendEntries, leader elected after 15235ms
om3_1    | 2022-06-16 01:14:46,090 [om3-server-thread1] INFO server.RaftServer$Division: om3@group-D66704EFC61C: set configuration 99: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1    | 2022-06-16 01:14:46,095 [om3-server-thread1] INFO segmented.SegmentedRaftLogWorker: om3@group-D66704EFC61C-SegmentedRaftLogWorker: Rolling segment log-63_98 to index:98
om3_1    | 2022-06-16 01:14:46,113 [om3@group-D66704EFC61C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om3@group-D66704EFC61C-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_inprogress_63 to /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_63-98
om3_1    | 2022-06-16 01:14:46,154 [om3@group-D66704EFC61C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om3@group-D66704EFC61C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_inprogress_99
om3_1    | 2022-06-16 01:14:46,341 [om3@group-D66704EFC61C-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om3_1    | [id: "om1"
om3_1    | address: "om1:9872"
om3_1    | , id: "om3"
om3_1    | address: "om3:9872"
om3_1    | , id: "om2"
om3_1    | address: "om2:9872"
om3_1    | ]
om3_1    | 2022-06-16 01:19:51,775 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: Finalization started.
om3_1    | 2022-06-16 01:19:51,778 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: ERASURE_CODED_STORAGE_SUPPORT.
om3_1    | 2022-06-16 01:19:51,780 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.AbstractLayoutVersionManager: Layout feature ERASURE_CODED_STORAGE_SUPPORT has been finalized.
om3_1    | 2022-06-16 01:19:51,781 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: BUCKET_LAYOUT_SUPPORT.
om3_1    | 2022-06-16 01:19:51,783 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.AbstractLayoutVersionManager: Layout feature BUCKET_LAYOUT_SUPPORT has been finalized.
om3_1    | 2022-06-16 01:19:51,783 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: MULTITENANCY_SCHEMA.
om3_1    | 2022-06-16 01:19:51,784 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.AbstractLayoutVersionManager: Layout feature MULTITENANCY_SCHEMA has been finalized.
om3_1    | 2022-06-16 01:19:51,784 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.AbstractLayoutVersionManager: Finalization is complete.
om3_1    | 2022-06-16 01:19:51,784 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: Finalization is done.
om3_1    | 2022-06-16 01:19:51,803 [OMDoubleBufferFlushThread] INFO upgrade.OMFinalizeUpgradeResponse: Layout version to persist to DB : 3
dn5_1    | 2022-06-16 01:14:16,352 [pool-46-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=8, votedFor=c3461ed7-1554-428d-9478-8d95583cf36e} from /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399/current/raft-meta
dn5_1    | 2022-06-16 01:14:16,360 [pool-46-thread-1] INFO ratis.ContainerStateMachine: group-8C8526B83399: Setting the last applied index to (t:8, i:28)
dn5_1    | 2022-06-16 01:14:16,366 [pool-46-thread-1] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: set configuration 19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:14:16,367 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn5_1    | 2022-06-16 01:14:16,371 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn5_1    | 2022-06-16 01:14:16,378 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn5_1    | 2022-06-16 01:14:16,383 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn5_1    | 2022-06-16 01:14:16,390 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn5_1    | 2022-06-16 01:14:16,390 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn5_1    | 2022-06-16 01:14:16,397 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn5_1    | 2022-06-16 01:14:16,398 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn5_1    | 2022-06-16 01:14:16,398 [pool-46-thread-1] INFO segmented.SegmentedRaftLogWorker: new c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399
dn5_1    | 2022-06-16 01:14:16,398 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn5_1    | 2022-06-16 01:14:16,402 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn5_1    | 2022-06-16 01:14:16,402 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn5_1    | 2022-06-16 01:14:16,402 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn5_1    | 2022-06-16 01:14:16,402 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn5_1    | 2022-06-16 01:14:16,415 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn5_1    | 2022-06-16 01:14:16,416 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn5_1    | 2022-06-16 01:14:16,420 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn5_1    | 2022-06-16 01:14:16,421 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn5_1    | 2022-06-16 01:14:16,425 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn5_1    | 2022-06-16 01:14:16,426 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn5_1    | 2022-06-16 01:14:16,369 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7a65c995{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-6928023506583803607/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
dn5_1    | 2022-06-16 01:14:16,466 [pool-46-thread-1] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: set configuration 0: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:14:16,479 [pool-46-thread-1] INFO segmented.LogSegment: Successfully read 9 entries from segment file /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399/current/log_0-8
dn5_1    | 2022-06-16 01:14:16,502 [pool-46-thread-1] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: set configuration 9: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:14:16,510 [pool-46-thread-1] INFO segmented.LogSegment: Successfully read 10 entries from segment file /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399/current/log_9-18
dn5_1    | 2022-06-16 01:14:16,520 [pool-46-thread-1] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: set configuration 19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:14:16,529 [pool-46-thread-1] INFO segmented.LogSegment: Successfully read 10 entries from segment file /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399/current/log_inprogress_19
dn5_1    | 2022-06-16 01:14:16,533 [pool-46-thread-1] INFO segmented.SegmentedRaftLogWorker: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 28
dn5_1    | 2022-06-16 01:14:16,533 [pool-46-thread-1] INFO segmented.SegmentedRaftLogWorker: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 18
dn5_1    | 2022-06-16 01:14:16,529 [main] INFO server.AbstractConnector: Started ServerConnector@d653e41{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
dn5_1    | 2022-06-16 01:14:16,555 [main] INFO server.Server: Started @48147ms
dn5_1    | 2022-06-16 01:14:16,563 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
dn5_1    | 2022-06-16 01:14:16,563 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
dn5_1    | 2022-06-16 01:14:16,563 [pool-46-thread-1] INFO raftlog.RaftLog: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-SegmentedRaftLog: commitIndex: updateToMax old=28, new=27, updated? false
dn5_1    | 2022-06-16 01:14:16,564 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn5_1    | 2022-06-16 01:14:16,565 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn5_1    | 2022-06-16 01:14:16,566 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn2_1    | 2022-06-16 01:15:12,151 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:15:12,152 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn2_1    | 2022-06-16 01:15:12,152 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn2_1    | 2022-06-16 01:15:12,152 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn2_1    | 2022-06-16 01:15:12,153 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn2_1    | 2022-06-16 01:15:12,153 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn2_1    | 2022-06-16 01:15:12,153 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:15:12,153 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:15:12,153 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn2_1    | 2022-06-16 01:15:12,153 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn2_1    | 2022-06-16 01:15:12,154 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn2_1    | 2022-06-16 01:15:12,154 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn2_1    | 2022-06-16 01:15:12,155 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn2_1    | 2022-06-16 01:15:12,155 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:15:12,155 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
recon_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
recon_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1  | 2022-06-16 01:13:39,725 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1  | /************************************************************
recon_1  | STARTUP_MSG: Starting ReconServer
recon_1  | STARTUP_MSG:   host = 9891f85b5a88/10.9.0.20
recon_1  | STARTUP_MSG:   args = []
recon_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
recon_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.4.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.33.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/ranger-intg-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-tools-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.44.v20210927.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.33.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.13.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/gson-2.8.9.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.14.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.6.3.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.33.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/ozone-reconcodegen-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar
recon_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/17d3301a908af2df7683a0c61b8ee3ae8dd41d6a ; compiled by 'runner' on 2022-06-16T00:51Z
recon_1  | STARTUP_MSG:   java = 11.0.14.1
recon_1  | ************************************************************/
recon_1  | 2022-06-16 01:13:39,780 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1  | WARNING: An illegal reflective access operation has occurred
recon_1  | WARNING: Illegal reflective access by com.google.inject.internal.cglib.core.$ReflectUtils$2 (file:/opt/hadoop/share/ozone/lib/guice-4.0.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int,java.security.ProtectionDomain)
recon_1  | WARNING: Please consider reporting this to the maintainers of com.google.inject.internal.cglib.core.$ReflectUtils$2
recon_1  | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1  | WARNING: All illegal access operations will be denied in a future release
recon_1  | 2022-06-16 01:13:45,110 [main] INFO reflections.Reflections: Reflections took 685 ms to scan 1 urls, producing 13 keys and 35 values 
recon_1  | 2022-06-16 01:13:50,593 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1  | 2022-06-16 01:13:50,666 [main] INFO impl.ReconDBProvider: Last known Recon DB : /data/metadata/recon/recon-container-key.db_1655341510453
recon_1  | 2022-06-16 01:13:52,424 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1  | 2022-06-16 01:13:57,266 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1  | 2022-06-16 01:14:00,760 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1  | 2022-06-16 01:14:00,779 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1  | 2022-06-16 01:14:00,794 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1  | 2022-06-16 01:14:05,031 [main] INFO codegen.SqlDbUtils: UNHEALTHY_CONTAINERS table already exists, skipping creation.
recon_1  | 2022-06-16 01:14:05,151 [main] INFO codegen.SqlDbUtils: GLOBAL_STATS table already exists, skipping creation.
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:17:13,097 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn1_1    | 2022-06-16 01:17:13,098 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn1_1    | 2022-06-16 01:17:13,098 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn1_1    | 2022-06-16 01:17:13,098 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn1_1    | 2022-06-16 01:17:13,098 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn1_1    | 2022-06-16 01:17:13,098 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:17:13,098 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:17:43,097 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn1_1    | 2022-06-16 01:17:43,097 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn1_1    | 2022-06-16 01:17:43,097 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn1_1    | 2022-06-16 01:17:43,097 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn1_1    | 2022-06-16 01:17:43,097 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn1_1    | 2022-06-16 01:17:43,097 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:17:43,098 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
recon_1  | 2022-06-16 01:14:05,265 [main] INFO codegen.SqlDbUtils: RECON_TASK_STATUS table already exists, skipping creation.
recon_1  | 2022-06-16 01:14:07,876 [main] INFO codegen.SqlDbUtils: FILE_COUNT_BY_SIZE table already exists, skipping creation.
recon_1  | 2022-06-16 01:14:08,000 [main] INFO codegen.SqlDbUtils: CLUSTER_GROWTH_DAILY table already exists, skipping creation.
recon_1  | 2022-06-16 01:14:08,666 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1  | 2022-06-16 01:14:08,851 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
recon_1  | 2022-06-16 01:14:08,966 [main] INFO util.log: Logging initialized @40357ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1  | 2022-06-16 01:14:09,652 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
recon_1  | 2022-06-16 01:14:09,706 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1  | 2022-06-16 01:14:09,741 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1  | 2022-06-16 01:14:09,771 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context recon
recon_1  | 2022-06-16 01:14:09,771 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
recon_1  | 2022-06-16 01:14:09,771 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
recon_1  | 2022-06-16 01:14:10,637 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1  | 2022-06-16 01:14:11,309 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1  | 2022-06-16 01:14:11,340 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
recon_1  | 2022-06-16 01:14:11,414 [main] INFO tasks.ReconTaskControllerImpl: Registered task NSSummaryTask with controller.
recon_1  | 2022-06-16 01:14:11,525 [main] INFO ozone.OmUtils: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
recon_1  | 2022-06-16 01:14:11,525 [main] INFO ozone.OmUtils: Using OzoneManager ServiceID 'omservice'.
recon_1  | 2022-06-16 01:14:14,189 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1  | 2022-06-16 01:14:14,826 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1  | 2022-06-16 01:14:15,422 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
recon_1  | 2022-06-16 01:14:15,424 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1  | 2022-06-16 01:14:15,816 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1  | 2022-06-16 01:14:16,064 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
recon_1  | 2022-06-16 01:14:16,492 [main] INFO reflections.Reflections: Reflections took 384 ms to scan 3 urls, producing 109 keys and 239 values 
recon_1  | 2022-06-16 01:14:16,706 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
recon_1  | 2022-06-16 01:14:16,778 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1  | 2022-06-16 01:14:16,932 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
recon_1  | 2022-06-16 01:14:16,935 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1  | 2022-06-16 01:14:17,142 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
recon_1  | 2022-06-16 01:14:17,286 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1  | 2022-06-16 01:14:17,401 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1  | 2022-06-16 01:14:17,622 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
recon_1  | 2022-06-16 01:14:17,626 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
recon_1  | 2022-06-16 01:14:17,743 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1  | 2022-06-16 01:14:17,753 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1  | 2022-06-16 01:14:17,753 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1  | 2022-06-16 01:14:18,154 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1  | 2022-06-16 01:14:18,156 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
recon_1  | 2022-06-16 01:14:18,201 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1  | 2022-06-16 01:14:18,202 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1  | 2022-06-16 01:14:18,204 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 600000ms
recon_1  | 2022-06-16 01:14:18,220 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@491cafec{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1  | 2022-06-16 01:14:18,220 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@76a7fcbd{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1  | 2022-06-16 01:14:23,922 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@28b7646{recon,/,file:///tmp/jetty-0_0_0_0-9888-ozone-recon-1_3_0-SNAPSHOT_jar-_-any-17413144627827580196/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/recon}
recon_1  | 2022-06-16 01:14:23,966 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@5bda157e{HTTP/1.1, (http/1.1)}{0.0.0.0:9888}
recon_1  | 2022-06-16 01:14:23,968 [Listener at 0.0.0.0/9891] INFO server.Server: Started @55361ms
recon_1  | 2022-06-16 01:14:23,973 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1  | 2022-06-16 01:14:23,974 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1  | 2022-06-16 01:14:23,976 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1  | 2022-06-16 01:14:23,976 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1  | 2022-06-16 01:14:23,995 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:15:12,155 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn2_1    | 2022-06-16 01:15:12,155 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn2_1    | 2022-06-16 01:15:12,156 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn2_1    | 2022-06-16 01:15:12,156 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn2_1    | 2022-06-16 01:15:12,156 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn2_1    | 2022-06-16 01:15:12,156 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:15:12,156 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:15:12,158 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn2_1    | 2022-06-16 01:15:12,158 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn2_1    | 2022-06-16 01:15:12,158 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn2_1    | 2022-06-16 01:15:12,158 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn2_1    | 2022-06-16 01:15:12,158 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn2_1    | 2022-06-16 01:15:12,159 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:15:12,159 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 2022-06-16 01:14:16,568 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn5_1    | 2022-06-16 01:14:16,572 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn5_1    | 2022-06-16 01:14:16,572 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn5_1    | 2022-06-16 01:14:16,573 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn5_1    | 2022-06-16 01:14:16,593 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn5_1    | 2022-06-16 01:14:16,593 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn5_1    | 2022-06-16 01:14:16,593 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn5_1    | 2022-06-16 01:14:16,593 [pool-46-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn5_1    | 2022-06-16 01:14:16,592 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
dn5_1    | 2022-06-16 01:14:16,611 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
dn5_1    | 2022-06-16 01:14:16,655 [Datanode State Machine Daemon Thread] INFO upgrade.UpgradeFinalizer: Running pre-finalized state validations for unfinalized layout features.
dn5_1    | 2022-06-16 01:14:16,679 [Datanode State Machine Daemon Thread] INFO upgrade.UpgradeFinalizer: Running first upgrade commands for unfinalized layout features.
dn5_1    | 2022-06-16 01:14:16,746 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@55f113d] INFO util.JvmPauseMonitor: Starting JVM pause monitor
dn5_1    | 2022-06-16 01:14:20,926 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
dn5_1    | 2022-06-16 01:14:20,991 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
dn5_1    | 2022-06-16 01:14:21,541 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis c3461ed7-1554-428d-9478-8d95583cf36e
dn5_1    | 2022-06-16 01:14:21,631 [c3461ed7-1554-428d-9478-8d95583cf36e-impl-thread1] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE: start as a follower, conf=22: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn5_1    | 2022-06-16 01:14:21,667 [c3461ed7-1554-428d-9478-8d95583cf36e-impl-thread1] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE: changes role from      null to FOLLOWER at term 13 for startAsFollower
dn5_1    | 2022-06-16 01:14:21,671 [c3461ed7-1554-428d-9478-8d95583cf36e-impl-thread1] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: start c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-FollowerState
dn5_1    | 2022-06-16 01:14:21,631 [c3461ed7-1554-428d-9478-8d95583cf36e-impl-thread2] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: start as a follower, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:14:21,724 [c3461ed7-1554-428d-9478-8d95583cf36e-impl-thread2] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: changes role from      null to FOLLOWER at term 8 for startAsFollower
dn5_1    | 2022-06-16 01:14:21,723 [c3461ed7-1554-428d-9478-8d95583cf36e-impl-thread3] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC: start as a follower, conf=3: [c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:14:21,726 [c3461ed7-1554-428d-9478-8d95583cf36e-impl-thread3] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC: changes role from      null to FOLLOWER at term 3 for startAsFollower
dn5_1    | 2022-06-16 01:14:21,724 [c3461ed7-1554-428d-9478-8d95583cf36e-impl-thread2] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: start c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState
dn5_1    | 2022-06-16 01:14:21,726 [c3461ed7-1554-428d-9478-8d95583cf36e-impl-thread3] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: start c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-FollowerState
dn5_1    | 2022-06-16 01:14:21,776 [c3461ed7-1554-428d-9478-8d95583cf36e-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5FC878C6C2DE,id=c3461ed7-1554-428d-9478-8d95583cf36e
dn5_1    | 2022-06-16 01:14:21,777 [c3461ed7-1554-428d-9478-8d95583cf36e-impl-thread2] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8C8526B83399,id=c3461ed7-1554-428d-9478-8d95583cf36e
dn5_1    | 2022-06-16 01:14:21,809 [c3461ed7-1554-428d-9478-8d95583cf36e-impl-thread3] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3D4E612B41CC,id=c3461ed7-1554-428d-9478-8d95583cf36e
dn5_1    | 2022-06-16 01:14:21,878 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.RaftServer: c3461ed7-1554-428d-9478-8d95583cf36e: start RPC server
dn5_1    | 2022-06-16 01:14:21,898 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: c3461ed7-1554-428d-9478-8d95583cf36e: GrpcService started, listening on 9856
dn5_1    | 2022-06-16 01:14:21,916 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: c3461ed7-1554-428d-9478-8d95583cf36e: GrpcService started, listening on 9857
dn5_1    | 2022-06-16 01:14:21,940 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: c3461ed7-1554-428d-9478-8d95583cf36e: GrpcService started, listening on 9858
dn5_1    | 2022-06-16 01:14:21,988 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis c3461ed7-1554-428d-9478-8d95583cf36e is started using port 9858 for RATIS
dn5_1    | 2022-06-16 01:14:21,988 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis c3461ed7-1554-428d-9478-8d95583cf36e is started using port 9857 for RATIS_ADMIN
dn5_1    | 2022-06-16 01:14:21,989 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis c3461ed7-1554-428d-9478-8d95583cf36e is started using port 9856 for RATIS_SERVER
dn5_1    | 2022-06-16 01:14:21,990 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$484/0x0000000840568c40@259e2162] INFO util.JvmPauseMonitor: JvmPauseMonitor-c3461ed7-1554-428d-9478-8d95583cf36e: Started
dn5_1    | 2022-06-16 01:14:26,884 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState] INFO impl.FollowerState: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5160005922ns, electionTimeout:5150ms
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:15:12,159 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn2_1    | 2022-06-16 01:15:12,159 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn2_1    | 2022-06-16 01:15:12,159 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn2_1    | 2022-06-16 01:15:12,160 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn2_1    | 2022-06-16 01:15:12,160 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn2_1    | 2022-06-16 01:15:12,160 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:15:12,160 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:15:12,160 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn2_1    | 2022-06-16 01:15:12,161 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn2_1    | 2022-06-16 01:15:12,161 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn2_1    | 2022-06-16 01:15:12,161 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn2_1    | 2022-06-16 01:15:12,161 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn2_1    | 2022-06-16 01:15:12,161 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:15:12,165 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:15:12,165 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn2_1    | 2022-06-16 01:15:12,165 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn2_1    | 2022-06-16 01:15:12,165 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn2_1    | 2022-06-16 01:15:12,165 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn2_1    | 2022-06-16 01:15:12,165 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn2_1    | 2022-06-16 01:15:12,166 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:15:12,166 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:15:12,166 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn2_1    | 2022-06-16 01:15:12,166 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn2_1    | 2022-06-16 01:15:12,166 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn2_1    | 2022-06-16 01:15:12,167 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn2_1    | 2022-06-16 01:15:12,167 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn2_1    | 2022-06-16 01:15:12,167 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:15:12,168 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 2022-06-16 01:14:26,886 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: shutdown c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState
dn5_1    | 2022-06-16 01:14:26,886 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: changes role from  FOLLOWER to CANDIDATE at term 8 for changeToCandidate
dn5_1    | 2022-06-16 01:14:26,891 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn5_1    | 2022-06-16 01:14:26,891 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: start c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection1
dn5_1    | 2022-06-16 01:14:26,937 [c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-FollowerState] INFO impl.FollowerState: c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5211003179ns, electionTimeout:5115ms
dn5_1    | 2022-06-16 01:14:26,938 [c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-FollowerState] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: shutdown c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-FollowerState
dn5_1    | 2022-06-16 01:14:26,939 [c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-FollowerState] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
dn5_1    | 2022-06-16 01:14:26,939 [c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn5_1    | 2022-06-16 01:14:26,939 [c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-FollowerState] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: start c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-LeaderElection2
dn5_1    | 2022-06-16 01:14:26,964 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection1] INFO impl.LeaderElection: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection1 ELECTION round 0: submit vote requests at term 9 for 19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:14:26,967 [c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-FollowerState] INFO impl.FollowerState: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5296586192ns, electionTimeout:5158ms
dn5_1    | 2022-06-16 01:14:26,967 [c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-FollowerState] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: shutdown c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-FollowerState
dn5_1    | 2022-06-16 01:14:26,968 [c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-FollowerState] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE: changes role from  FOLLOWER to CANDIDATE at term 13 for changeToCandidate
dn5_1    | 2022-06-16 01:14:26,968 [c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn5_1    | 2022-06-16 01:14:26,968 [c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-FollowerState] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: start c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-LeaderElection3
dn5_1    | 2022-06-16 01:14:27,042 [c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-LeaderElection2] INFO impl.LeaderElection: c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-LeaderElection2 ELECTION round 0: submit vote requests at term 4 for 3: [c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:14:27,065 [c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-LeaderElection2] INFO impl.LeaderElection: c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-LeaderElection2 ELECTION round 0: result PASSED (term=4)
dn5_1    | 2022-06-16 01:14:27,065 [c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-LeaderElection2] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: shutdown c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-LeaderElection2
dn5_1    | 2022-06-16 01:14:27,068 [c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-LeaderElection2] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC: changes role from CANDIDATE to LEADER at term 4 for changeToLeader
dn5_1    | 2022-06-16 01:14:27,068 [c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-LeaderElection3] INFO impl.LeaderElection: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-LeaderElection3 ELECTION round 0: submit vote requests at term 14 for 22: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn5_1    | 2022-06-16 01:14:27,069 [c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-3D4E612B41CC with new leaderId: c3461ed7-1554-428d-9478-8d95583cf36e
dn5_1    | 2022-06-16 01:14:27,106 [c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-LeaderElection2] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC: change Leader from null to c3461ed7-1554-428d-9478-8d95583cf36e at term 4 for becomeLeader, leader elected after 13416ms
dn5_1    | 2022-06-16 01:14:27,230 [c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn5_1    | 2022-06-16 01:14:27,336 [c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn5_1    | 2022-06-16 01:14:27,340 [c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn5_1    | 2022-06-16 01:14:27,441 [c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn5_1    | 2022-06-16 01:14:27,449 [c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn5_1    | 2022-06-16 01:14:27,450 [c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn5_1    | 2022-06-16 01:14:27,558 [c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn5_1    | 2022-06-16 01:14:27,559 [c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:18:13,097 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn1_1    | 2022-06-16 01:18:13,097 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn1_1    | 2022-06-16 01:18:13,097 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn1_1    | 2022-06-16 01:18:13,097 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn1_1    | 2022-06-16 01:18:13,097 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn1_1    | 2022-06-16 01:18:13,097 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:18:13,102 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:18:13,102 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn1_1    | 2022-06-16 01:18:13,102 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn1_1    | 2022-06-16 01:18:13,102 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn1_1    | 2022-06-16 01:18:13,103 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn1_1    | 2022-06-16 01:18:13,103 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn1_1    | 2022-06-16 01:18:13,103 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:18:13,103 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:19:13,097 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
s3g_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
s3g_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1    | 2022-06-16 01:13:38,569 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1    | 2022-06-16 01:13:38,590 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
s3g_1    | 2022-06-16 01:13:38,899 [main] INFO util.log: Logging initialized @11120ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1    | 2022-06-16 01:13:40,325 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g_1    | 2022-06-16 01:13:40,514 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1    | 2022-06-16 01:13:40,587 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1    | 2022-06-16 01:13:40,619 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context s3gateway
s3g_1    | 2022-06-16 01:13:40,634 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
s3g_1    | 2022-06-16 01:13:40,637 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
s3g_1    | 2022-06-16 01:13:41,229 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1    | /************************************************************
s3g_1    | STARTUP_MSG: Starting Gateway
s3g_1    | STARTUP_MSG:   host = 550016d3cea3/10.9.0.21
s3g_1    | STARTUP_MSG:   args = []
s3g_1    | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:15:12,168 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn2_1    | 2022-06-16 01:15:12,168 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn2_1    | 2022-06-16 01:15:12,169 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn2_1    | 2022-06-16 01:15:12,169 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn2_1    | 2022-06-16 01:15:12,169 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn1_1    | 2022-06-16 01:19:13,097 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn1_1    | 2022-06-16 01:19:13,097 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn1_1    | 2022-06-16 01:19:13,098 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn1_1    | 2022-06-16 01:19:13,098 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn1_1    | 2022-06-16 01:19:13,098 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:19:13,098 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:19:43,097 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn1_1    | 2022-06-16 01:19:43,097 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn1_1    | 2022-06-16 01:19:43,097 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn1_1    | 2022-06-16 01:19:43,097 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn1_1    | 2022-06-16 01:19:43,097 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn1_1    | 2022-06-16 01:19:43,097 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | 2022-06-16 01:19:43,098 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn1_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn1_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn1_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1  | 2022-06-16 01:14:24,005 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1  | 2022-06-16 01:14:24,006 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Last known snapshot for OM : /data/metadata/om.snapshot.db_1655341954970
recon_1  | 2022-06-16 01:14:24,015 [Listener at 0.0.0.0/9891] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1  | 2022-06-16 01:14:24,019 [Listener at 0.0.0.0/9891] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
recon_1  | 2022-06-16 01:14:24,149 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Created OM DB handle from snapshot at /data/metadata/om.snapshot.db_1655341954970.
recon_1  | 2022-06-16 01:14:24,187 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1  | 2022-06-16 01:14:24,193 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1  | 2022-06-16 01:14:24,807 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 7 pipelines from SCM.
recon_1  | 2022-06-16 01:14:24,808 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 7 pipelines in house.
recon_1  | 2022-06-16 01:14:24,899 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1  | 2022-06-16 01:14:24,927 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1  | 2022-06-16 01:14:24,910 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1  | 2022-06-16 01:14:25,196 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting ContainerHealthTask Thread.
recon_1  | 2022-06-16 01:14:25,253 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1  | 2022-06-16 01:14:25,289 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 7 pipelines in house.
recon_1  | 2022-06-16 01:14:25,328 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 72 milliseconds.
recon_1  | 2022-06-16 01:15:24,188 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1  | 2022-06-16 01:15:24,191 [pool-16-thread-1] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
recon_1  | 2022-06-16 01:15:24,192 [pool-16-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1  | 2022-06-16 01:15:24,192 [pool-16-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1  | 2022-06-16 01:15:24,192 [pool-16-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1  | 2022-06-16 01:15:24,192 [pool-16-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1  | 2022-06-16 01:15:24,192 [pool-16-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1  | 2022-06-16 01:15:24,192 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1  | 2022-06-16 01:15:24,192 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 100 
recon_1  | 2022-06-16 01:15:24,294 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0.
recon_1  | 2022-06-16 01:15:24,294 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 0 records
recon_1  | 2022-06-16 01:16:24,300 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1  | 2022-06-16 01:16:24,301 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1  | 2022-06-16 01:16:24,301 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 100 
recon_1  | 2022-06-16 01:16:24,307 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0.
recon_1  | 2022-06-16 01:16:24,307 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 0 records
recon_1  | 2022-06-16 01:17:24,311 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1  | 2022-06-16 01:17:24,311 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1  | 2022-06-16 01:17:24,311 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 100 
recon_1  | 2022-06-16 01:17:24,316 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0.
recon_1  | 2022-06-16 01:17:24,316 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 0 records
recon_1  | 2022-06-16 01:18:24,320 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1  | 2022-06-16 01:18:24,320 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1  | 2022-06-16 01:18:24,320 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 100 
recon_1  | 2022-06-16 01:18:24,330 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0.
recon_1  | 2022-06-16 01:18:24,330 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 0 records
recon_1  | 2022-06-16 01:19:24,333 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1  | 2022-06-16 01:19:24,333 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1  | 2022-06-16 01:19:24,333 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 100 
recon_1  | 2022-06-16 01:19:24,348 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0.
recon_1  | 2022-06-16 01:19:24,348 [pool-16-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 0 records
recon_1  | 2022-06-16 01:19:25,284 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 30 milliseconds to process 0 existing database records.
recon_1  | 2022-06-16 01:19:25,290 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 5 milliseconds for processing 0 containers.
recon_1  | 2022-06-16 01:19:25,666 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 7 pipelines in house.
recon_1  | 2022-06-16 01:19:25,670 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=28ac5e1e-72b1-40fd-a3cf-a4053e55f144 from SCM.
recon_1  | 2022-06-16 01:19:25,671 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 28ac5e1e-72b1-40fd-a3cf-a4053e55f144, Nodes: 32c66434-cc2b-41ce-bc06-c42e833faba3{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:32c66434-cc2b-41ce-bc06-c42e833faba3, CreationTimestamp2022-06-16T01:15:28.902Z[UTC]].
recon_1  | 2022-06-16 01:19:25,672 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=ce5a0a3f-f6c5-4883-b95d-51ddeed5744f from SCM.
dn2_1    | 2022-06-16 01:15:12,169 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:15:12,169 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:15:15,858 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState] INFO impl.FollowerState: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5014204915ns, electionTimeout:5012ms
dn2_1    | 2022-06-16 01:15:15,860 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: shutdown c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState
dn2_1    | 2022-06-16 01:15:15,860 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: changes role from  FOLLOWER to CANDIDATE at term 17 for changeToCandidate
dn2_1    | 2022-06-16 01:15:15,860 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn2_1    | 2022-06-16 01:15:15,860 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: start c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection6
dn2_1    | 2022-06-16 01:15:15,876 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: receive requestVote(ELECTION, 8b366c76-456d-4ec7-ac8e-95910f7eaaa6, group-8C8526B83399, 18, (t:8, i:28))
dn2_1    | 2022-06-16 01:15:15,876 [grpc-default-executor-0] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: receive requestVote(ELECTION, c3461ed7-1554-428d-9478-8d95583cf36e, group-8C8526B83399, 18, (t:8, i:28))
dn2_1    | 2022-06-16 01:15:15,879 [grpc-default-executor-1] INFO impl.VoteContext: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-CANDIDATE: reject ELECTION from 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: already has voted for c7eeb289-59cc-4c90-a00f-b0c50499b5ba at current term 18
dn2_1    | 2022-06-16 01:15:15,879 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399 replies to ELECTION vote request: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c7eeb289-59cc-4c90-a00f-b0c50499b5ba#0:FAIL-t18. Peer's state: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399:t18, leader=null, voted=c7eeb289-59cc-4c90-a00f-b0c50499b5ba, raftlog=c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-06-16 01:15:15,879 [grpc-default-executor-0] INFO impl.VoteContext: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-CANDIDATE: reject ELECTION from c3461ed7-1554-428d-9478-8d95583cf36e: already has voted for c7eeb289-59cc-4c90-a00f-b0c50499b5ba at current term 18
dn2_1    | 2022-06-16 01:15:15,879 [grpc-default-executor-0] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399 replies to ELECTION vote request: c3461ed7-1554-428d-9478-8d95583cf36e<-c7eeb289-59cc-4c90-a00f-b0c50499b5ba#0:FAIL-t18. Peer's state: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399:t18, leader=null, voted=c7eeb289-59cc-4c90-a00f-b0c50499b5ba, raftlog=c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-06-16 01:15:15,884 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection6] INFO impl.LeaderElection: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection6 ELECTION round 0: submit vote requests at term 18 for 19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-06-16 01:15:15,897 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection6] INFO impl.LeaderElection: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection6: ELECTION REJECTED received 1 response(s) and 0 exception(s):
dn5_1    | 2022-06-16 01:14:27,601 [c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-LeaderElection2] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: start c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-LeaderStateImpl
dn5_1    | 2022-06-16 01:14:27,688 [c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-SegmentedRaftLogWorker: Rolling segment log-3_4 to index:4
dn5_1    | 2022-06-16 01:14:27,807 [c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/4321e5aa-575a-4764-b053-3d4e612b41cc/current/log_inprogress_3 to /data/metadata/ratis/4321e5aa-575a-4764-b053-3d4e612b41cc/current/log_3-4
dn5_1    | 2022-06-16 01:14:27,910 [c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/4321e5aa-575a-4764-b053-3d4e612b41cc/current/log_inprogress_5
dn5_1    | 2022-06-16 01:14:27,932 [c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC-LeaderElection2] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-3D4E612B41CC: set configuration 5: [c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:14:29,950 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: receive requestVote(ELECTION, c7eeb289-59cc-4c90-a00f-b0c50499b5ba, group-8C8526B83399, 9, (t:8, i:28))
dn5_1    | 2022-06-16 01:14:29,952 [grpc-default-executor-0] INFO impl.VoteContext: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-CANDIDATE: reject ELECTION from c7eeb289-59cc-4c90-a00f-b0c50499b5ba: already has voted for c3461ed7-1554-428d-9478-8d95583cf36e at current term 9
dn5_1    | 2022-06-16 01:14:29,992 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399 replies to ELECTION vote request: c7eeb289-59cc-4c90-a00f-b0c50499b5ba<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t9. Peer's state: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399:t9, leader=null, voted=c3461ed7-1554-428d-9478-8d95583cf36e, raftlog=c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:14:30,007 [grpc-default-executor-3] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE: receive requestVote(ELECTION, 8b366c76-456d-4ec7-ac8e-95910f7eaaa6, group-5FC878C6C2DE, 14, (t:13, i:38))
dn5_1    | 2022-06-16 01:14:30,003 [grpc-default-executor-1] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: receive requestVote(ELECTION, 8b366c76-456d-4ec7-ac8e-95910f7eaaa6, group-8C8526B83399, 9, (t:8, i:28))
dn5_1    | 2022-06-16 01:14:30,002 [grpc-default-executor-2] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE: receive requestVote(ELECTION, c7eeb289-59cc-4c90-a00f-b0c50499b5ba, group-5FC878C6C2DE, 14, (t:13, i:38))
dn5_1    | 2022-06-16 01:14:30,045 [grpc-default-executor-3] INFO impl.VoteContext: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-CANDIDATE: reject ELECTION from 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: already has voted for c3461ed7-1554-428d-9478-8d95583cf36e at current term 14
dn5_1    | 2022-06-16 01:14:30,046 [grpc-default-executor-1] INFO impl.VoteContext: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-CANDIDATE: reject ELECTION from 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: already has voted for c3461ed7-1554-428d-9478-8d95583cf36e at current term 9
dn5_1    | 2022-06-16 01:14:30,047 [grpc-default-executor-3] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE replies to ELECTION vote request: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t14. Peer's state: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE:t14, leader=null, voted=c3461ed7-1554-428d-9478-8d95583cf36e, raftlog=c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-SegmentedRaftLog:OPENED:c38, conf=22: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn5_1    | 2022-06-16 01:14:30,047 [grpc-default-executor-2] INFO impl.VoteContext: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-CANDIDATE: reject ELECTION from c7eeb289-59cc-4c90-a00f-b0c50499b5ba: already has voted for c3461ed7-1554-428d-9478-8d95583cf36e at current term 14
dn5_1    | 2022-06-16 01:14:30,047 [grpc-default-executor-2] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE replies to ELECTION vote request: c7eeb289-59cc-4c90-a00f-b0c50499b5ba<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t14. Peer's state: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE:t14, leader=null, voted=c3461ed7-1554-428d-9478-8d95583cf36e, raftlog=c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-SegmentedRaftLog:OPENED:c38, conf=22: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn5_1    | 2022-06-16 01:14:30,047 [grpc-default-executor-1] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399 replies to ELECTION vote request: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t9. Peer's state: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399:t9, leader=null, voted=c3461ed7-1554-428d-9478-8d95583cf36e, raftlog=c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:14:30,276 [c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-LeaderElection3] INFO impl.LeaderElection: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-LeaderElection3: ELECTION REJECTED received 2 response(s) and 0 exception(s):
dn5_1    | 2022-06-16 01:14:30,295 [c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-LeaderElection3] INFO impl.LeaderElection:   Response 0: c3461ed7-1554-428d-9478-8d95583cf36e<-8b366c76-456d-4ec7-ac8e-95910f7eaaa6#0:FAIL-t14
dn5_1    | 2022-06-16 01:14:30,295 [c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-LeaderElection3] INFO impl.LeaderElection:   Response 1: c3461ed7-1554-428d-9478-8d95583cf36e<-c7eeb289-59cc-4c90-a00f-b0c50499b5ba#0:FAIL-t14
s3g_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.13.2.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.33.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/gson-2.8.9.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar
s3g_1    | STARTUP_MSG:   build = https://github.com/apache/ozone/17d3301a908af2df7683a0c61b8ee3ae8dd41d6a ; compiled by 'runner' on 2022-06-16T00:51Z
s3g_1    | STARTUP_MSG:   java = 11.0.14.1
s3g_1    | ************************************************************/
s3g_1    | 2022-06-16 01:13:41,326 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1    | 2022-06-16 01:13:41,440 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1    | 2022-06-16 01:13:42,130 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1    | 2022-06-16 01:13:43,493 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1    | 2022-06-16 01:13:43,494 [main] INFO impl.MetricsSystemImpl: S3Gateway metrics system started
s3g_1    | 2022-06-16 01:13:44,106 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1    | 2022-06-16 01:13:44,134 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
s3g_1    | 2022-06-16 01:13:44,599 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1    | 2022-06-16 01:13:44,599 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1    | 2022-06-16 01:13:44,627 [main] INFO server.session: node0 Scavenging every 660000ms
s3g_1    | 2022-06-16 01:13:44,740 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1bae316d{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1    | 2022-06-16 01:13:44,755 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@11f0a5a1{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1    | WARNING: An illegal reflective access operation has occurred
s3g_1    | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1    | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1    | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1    | WARNING: All illegal access operations will be denied in a future release
s3g_1    | Jun 16, 2022 1:14:13 AM org.glassfish.jersey.internal.Errors logErrors
s3g_1    | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1    | 
s3g_1    | 2022-06-16 01:14:13,391 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5be51aa{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-ozone-s3gateway-1_3_0-SNAPSHOT_jar-_-any-16698683192273130516/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1    | 2022-06-16 01:14:13,477 [main] INFO server.AbstractConnector: Started ServerConnector@16eccb2e{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1    | 2022-06-16 01:14:13,489 [main] INFO server.Server: Started @45710ms
s3g_1    | 2022-06-16 01:14:13,534 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
s3g_1    | 2022-06-16 01:14:13,534 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
s3g_1    | 2022-06-16 01:14:13,538 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
dn2_1    | 2022-06-16 01:15:15,898 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection6] INFO impl.LeaderElection:   Response 0: c7eeb289-59cc-4c90-a00f-b0c50499b5ba<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t18
dn2_1    | 2022-06-16 01:15:15,898 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection6] INFO impl.LeaderElection: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection6 ELECTION round 0: result REJECTED
dn2_1    | 2022-06-16 01:15:15,898 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection6] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: changes role from CANDIDATE to FOLLOWER at term 18 for REJECTED
dn2_1    | 2022-06-16 01:15:15,898 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection6] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: shutdown c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection6
dn2_1    | 2022-06-16 01:15:15,898 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-LeaderElection6] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: start c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState
dn2_1    | 2022-06-16 01:15:20,921 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: receive requestVote(ELECTION, c3461ed7-1554-428d-9478-8d95583cf36e, group-8C8526B83399, 19, (t:8, i:28))
dn2_1    | 2022-06-16 01:15:20,922 [grpc-default-executor-1] INFO impl.VoteContext: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FOLLOWER: accept ELECTION from c3461ed7-1554-428d-9478-8d95583cf36e: our priority 0 <= candidate's priority 1
dn2_1    | 2022-06-16 01:15:20,922 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: changes role from  FOLLOWER to FOLLOWER at term 19 for candidate:c3461ed7-1554-428d-9478-8d95583cf36e
dn2_1    | 2022-06-16 01:15:20,922 [grpc-default-executor-1] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: shutdown c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState
dn2_1    | 2022-06-16 01:15:20,922 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState] INFO impl.FollowerState: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState was interrupted
dn2_1    | 2022-06-16 01:15:20,922 [grpc-default-executor-1] INFO impl.RoleInfo: c7eeb289-59cc-4c90-a00f-b0c50499b5ba: start c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-FollowerState
dn2_1    | 2022-06-16 01:15:20,924 [grpc-default-executor-1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399 replies to ELECTION vote request: c3461ed7-1554-428d-9478-8d95583cf36e<-c7eeb289-59cc-4c90-a00f-b0c50499b5ba#0:OK-t19. Peer's state: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399:t19, leader=null, voted=c3461ed7-1554-428d-9478-8d95583cf36e, raftlog=c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-06-16 01:15:20,986 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-8C8526B83399 with new leaderId: c3461ed7-1554-428d-9478-8d95583cf36e
dn2_1    | 2022-06-16 01:15:20,986 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba-server-thread1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: change Leader from null to c3461ed7-1554-428d-9478-8d95583cf36e at term 19 for appendEntries, leader elected after 64197ms
dn2_1    | 2022-06-16 01:15:21,027 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba-server-thread1] INFO server.RaftServer$Division: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399: set configuration 29: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-06-16 01:15:21,028 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba-server-thread1] INFO segmented.SegmentedRaftLogWorker: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-SegmentedRaftLogWorker: Rolling segment log-19_28 to index:28
dn2_1    | 2022-06-16 01:15:21,030 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399/current/log_inprogress_19 to /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399/current/log_19-28
dn2_1    | 2022-06-16 01:15:21,033 [c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c7eeb289-59cc-4c90-a00f-b0c50499b5ba@group-8C8526B83399-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399/current/log_inprogress_29
dn2_1    | 2022-06-16 01:15:43,248 [org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@1ca3d25b] INFO commandhandler.DeleteBlocksCommandHandler: Start to delete container blocks, TXIDs=[2(0)], numOfContainers=1, numOfBlocks=1
dn2_1    | 2022-06-16 01:16:13,140 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn2_1    | 2022-06-16 01:16:13,140 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn2_1    | 2022-06-16 01:16:13,140 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn2_1    | 2022-06-16 01:16:13,140 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn2_1    | 2022-06-16 01:16:13,140 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn2_1    | 2022-06-16 01:16:13,140 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:16:13,140 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn5_1    | 2022-06-16 01:14:30,295 [c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-LeaderElection3] INFO impl.LeaderElection: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-LeaderElection3 ELECTION round 0: result REJECTED
dn5_1    | 2022-06-16 01:14:30,296 [c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-LeaderElection3] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE: changes role from CANDIDATE to FOLLOWER at term 14 for REJECTED
dn5_1    | 2022-06-16 01:14:30,296 [c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-LeaderElection3] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: shutdown c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-LeaderElection3
dn5_1    | 2022-06-16 01:14:30,297 [c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-LeaderElection3] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: start c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-FollowerState
dn5_1    | 2022-06-16 01:14:30,286 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection1] INFO impl.LeaderElection: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
dn5_1    | 2022-06-16 01:14:30,318 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection1] INFO impl.LeaderElection:   Response 0: c3461ed7-1554-428d-9478-8d95583cf36e<-8b366c76-456d-4ec7-ac8e-95910f7eaaa6#0:FAIL-t9
dn5_1    | 2022-06-16 01:14:30,318 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection1] INFO impl.LeaderElection:   Response 1: c3461ed7-1554-428d-9478-8d95583cf36e<-c7eeb289-59cc-4c90-a00f-b0c50499b5ba#0:FAIL-t9
dn5_1    | 2022-06-16 01:14:30,318 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection1] INFO impl.LeaderElection: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection1 ELECTION round 0: result REJECTED
dn5_1    | 2022-06-16 01:14:30,318 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection1] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: changes role from CANDIDATE to FOLLOWER at term 9 for REJECTED
dn5_1    | 2022-06-16 01:14:30,320 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection1] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: shutdown c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection1
dn5_1    | 2022-06-16 01:14:30,320 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection1] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: start c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState
dn5_1    | 2022-06-16 01:14:35,277 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE: receive requestVote(ELECTION, 8b366c76-456d-4ec7-ac8e-95910f7eaaa6, group-5FC878C6C2DE, 15, (t:13, i:38))
dn5_1    | 2022-06-16 01:14:35,277 [grpc-default-executor-0] INFO impl.VoteContext: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-FOLLOWER: accept ELECTION from 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: our priority 0 <= candidate's priority 0
dn5_1    | 2022-06-16 01:14:35,278 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE: changes role from  FOLLOWER to FOLLOWER at term 15 for candidate:8b366c76-456d-4ec7-ac8e-95910f7eaaa6
dn5_1    | 2022-06-16 01:14:35,278 [grpc-default-executor-0] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: shutdown c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-FollowerState
dn5_1    | 2022-06-16 01:14:35,278 [c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-FollowerState] INFO impl.FollowerState: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-FollowerState was interrupted
dn5_1    | 2022-06-16 01:14:35,278 [grpc-default-executor-0] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: start c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-FollowerState
dn5_1    | 2022-06-16 01:14:35,284 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE replies to ELECTION vote request: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c3461ed7-1554-428d-9478-8d95583cf36e#0:OK-t15. Peer's state: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE:t15, leader=null, voted=8b366c76-456d-4ec7-ac8e-95910f7eaaa6, raftlog=c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-SegmentedRaftLog:OPENED:c38, conf=22: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn5_1    | 2022-06-16 01:14:35,358 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: receive requestVote(ELECTION, 8b366c76-456d-4ec7-ac8e-95910f7eaaa6, group-8C8526B83399, 10, (t:8, i:28))
dn5_1    | 2022-06-16 01:14:35,358 [grpc-default-executor-0] INFO impl.VoteContext: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FOLLOWER: reject ELECTION from 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: our priority 1 > candidate's priority 0
dn5_1    | 2022-06-16 01:14:35,358 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: changes role from  FOLLOWER to FOLLOWER at term 10 for candidate:8b366c76-456d-4ec7-ac8e-95910f7eaaa6
dn5_1    | 2022-06-16 01:14:35,359 [grpc-default-executor-0] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: shutdown c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState
dn5_1    | 2022-06-16 01:14:35,359 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState] INFO impl.FollowerState: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState was interrupted
dn5_1    | 2022-06-16 01:14:35,359 [grpc-default-executor-0] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: start c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState
dn5_1    | 2022-06-16 01:14:35,361 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399 replies to ELECTION vote request: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t10. Peer's state: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399:t10, leader=null, voted=null, raftlog=c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:14:35,374 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: receive requestVote(ELECTION, c7eeb289-59cc-4c90-a00f-b0c50499b5ba, group-8C8526B83399, 10, (t:8, i:28))
dn5_1    | 2022-06-16 01:14:35,374 [grpc-default-executor-0] INFO impl.VoteContext: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FOLLOWER: reject ELECTION from c7eeb289-59cc-4c90-a00f-b0c50499b5ba: our priority 1 > candidate's priority 0
dn5_1    | 2022-06-16 01:14:35,375 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: changes role from  FOLLOWER to FOLLOWER at term 10 for candidate:c7eeb289-59cc-4c90-a00f-b0c50499b5ba
dn5_1    | 2022-06-16 01:14:35,375 [grpc-default-executor-0] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: shutdown c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState
recon_1  | 2022-06-16 01:19:25,673 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: ce5a0a3f-f6c5-4883-b95d-51ddeed5744f, Nodes: 835c1189-b066-4617-a285-c9fdbaf1d7b5{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:835c1189-b066-4617-a285-c9fdbaf1d7b5, CreationTimestamp2022-06-16T01:15:58.904Z[UTC]].
recon_1  | 2022-06-16 01:19:25,674 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 16 milliseconds.
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:16:13,140 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn2_1    | 2022-06-16 01:16:13,140 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn2_1    | 2022-06-16 01:16:13,141 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn2_1    | 2022-06-16 01:16:13,141 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn2_1    | 2022-06-16 01:16:13,141 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn2_1    | 2022-06-16 01:16:13,141 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:16:13,141 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:16:21,897 [BlockDeletingService#0] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-3e3c8fff-8818-4ab8-8118-66b81944a69d/current/containerDir0/2/chunks/109611004723200002.block
dn2_1    | 2022-06-16 01:16:43,140 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn2_1    | 2022-06-16 01:16:43,140 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn2_1    | 2022-06-16 01:16:43,140 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn2_1    | 2022-06-16 01:16:43,140 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn2_1    | 2022-06-16 01:16:43,140 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn2_1    | 2022-06-16 01:16:43,140 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:16:43,140 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 2022-06-16 01:14:35,375 [grpc-default-executor-0] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: start c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState
dn5_1    | 2022-06-16 01:14:35,375 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState] INFO impl.FollowerState: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState was interrupted
dn5_1    | 2022-06-16 01:14:35,379 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399 replies to ELECTION vote request: c7eeb289-59cc-4c90-a00f-b0c50499b5ba<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t10. Peer's state: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399:t10, leader=null, voted=null, raftlog=c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:14:40,442 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: receive requestVote(ELECTION, 8b366c76-456d-4ec7-ac8e-95910f7eaaa6, group-8C8526B83399, 11, (t:8, i:28))
dn5_1    | 2022-06-16 01:14:40,443 [grpc-default-executor-0] INFO impl.VoteContext: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FOLLOWER: reject ELECTION from 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: our priority 1 > candidate's priority 0
dn5_1    | 2022-06-16 01:14:40,443 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: changes role from  FOLLOWER to FOLLOWER at term 11 for candidate:8b366c76-456d-4ec7-ac8e-95910f7eaaa6
dn5_1    | 2022-06-16 01:14:40,443 [grpc-default-executor-0] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: shutdown c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState
dn5_1    | 2022-06-16 01:14:40,443 [grpc-default-executor-0] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: start c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState
dn5_1    | 2022-06-16 01:14:40,443 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState] INFO impl.FollowerState: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState was interrupted
dn5_1    | 2022-06-16 01:14:40,457 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399 replies to ELECTION vote request: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t11. Peer's state: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399:t11, leader=null, voted=null, raftlog=c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:14:40,490 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE: receive requestVote(ELECTION, c7eeb289-59cc-4c90-a00f-b0c50499b5ba, group-5FC878C6C2DE, 16, (t:13, i:38))
dn5_1    | 2022-06-16 01:14:40,490 [grpc-default-executor-0] INFO impl.VoteContext: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-FOLLOWER: accept ELECTION from c7eeb289-59cc-4c90-a00f-b0c50499b5ba: our priority 0 <= candidate's priority 1
dn5_1    | 2022-06-16 01:14:40,490 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE: changes role from  FOLLOWER to FOLLOWER at term 16 for candidate:c7eeb289-59cc-4c90-a00f-b0c50499b5ba
dn5_1    | 2022-06-16 01:14:40,490 [grpc-default-executor-0] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: shutdown c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-FollowerState
dn5_1    | 2022-06-16 01:14:40,490 [grpc-default-executor-0] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: start c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-FollowerState
dn5_1    | 2022-06-16 01:14:40,490 [c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-FollowerState] INFO impl.FollowerState: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-FollowerState was interrupted
dn5_1    | 2022-06-16 01:14:40,495 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE replies to ELECTION vote request: c7eeb289-59cc-4c90-a00f-b0c50499b5ba<-c3461ed7-1554-428d-9478-8d95583cf36e#0:OK-t16. Peer's state: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE:t16, leader=null, voted=c7eeb289-59cc-4c90-a00f-b0c50499b5ba, raftlog=c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-SegmentedRaftLog:OPENED:c38, conf=22: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn5_1    | 2022-06-16 01:14:40,796 [c3461ed7-1554-428d-9478-8d95583cf36e-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-5FC878C6C2DE with new leaderId: c7eeb289-59cc-4c90-a00f-b0c50499b5ba
dn5_1    | 2022-06-16 01:14:40,796 [c3461ed7-1554-428d-9478-8d95583cf36e-server-thread1] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE: change Leader from null to c7eeb289-59cc-4c90-a00f-b0c50499b5ba at term 16 for appendEntries, leader elected after 24846ms
dn5_1    | 2022-06-16 01:14:40,898 [c3461ed7-1554-428d-9478-8d95583cf36e-server-thread1] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE: set configuration 39: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn5_1    | 2022-06-16 01:14:40,906 [c3461ed7-1554-428d-9478-8d95583cf36e-server-thread1] INFO segmented.SegmentedRaftLogWorker: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-SegmentedRaftLogWorker: Rolling segment log-22_38 to index:38
dn5_1    | 2022-06-16 01:14:40,907 [c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de/current/log_inprogress_22 to /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de/current/log_22-38
dn5_1    | 2022-06-16 01:14:40,913 [c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c3461ed7-1554-428d-9478-8d95583cf36e@group-5FC878C6C2DE-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/cfb1d3a9-fa49-4890-85f5-5fc878c6c2de/current/log_inprogress_39
dn5_1    | 2022-06-16 01:14:45,539 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: receive requestVote(ELECTION, 8b366c76-456d-4ec7-ac8e-95910f7eaaa6, group-8C8526B83399, 12, (t:8, i:28))
dn5_1    | 2022-06-16 01:14:45,539 [grpc-default-executor-0] INFO impl.VoteContext: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FOLLOWER: reject ELECTION from 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: our priority 1 > candidate's priority 0
dn5_1    | 2022-06-16 01:14:45,539 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: changes role from  FOLLOWER to FOLLOWER at term 12 for candidate:8b366c76-456d-4ec7-ac8e-95910f7eaaa6
dn5_1    | 2022-06-16 01:14:45,539 [grpc-default-executor-0] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: shutdown c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState
dn5_1    | 2022-06-16 01:14:45,539 [grpc-default-executor-0] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: start c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState
dn5_1    | 2022-06-16 01:14:45,539 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState] INFO impl.FollowerState: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState was interrupted
dn5_1    | 2022-06-16 01:14:45,544 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399 replies to ELECTION vote request: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t12. Peer's state: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399:t12, leader=null, voted=null, raftlog=c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:14:50,565 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: receive requestVote(ELECTION, 8b366c76-456d-4ec7-ac8e-95910f7eaaa6, group-8C8526B83399, 13, (t:8, i:28))
dn5_1    | 2022-06-16 01:14:50,565 [grpc-default-executor-0] INFO impl.VoteContext: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FOLLOWER: reject ELECTION from 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: our priority 1 > candidate's priority 0
dn5_1    | 2022-06-16 01:14:50,566 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: changes role from  FOLLOWER to FOLLOWER at term 13 for candidate:8b366c76-456d-4ec7-ac8e-95910f7eaaa6
dn5_1    | 2022-06-16 01:14:50,566 [grpc-default-executor-0] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: shutdown c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState
dn5_1    | 2022-06-16 01:14:50,566 [grpc-default-executor-0] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: start c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState
dn5_1    | 2022-06-16 01:14:50,566 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState] INFO impl.FollowerState: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState was interrupted
dn5_1    | 2022-06-16 01:14:50,576 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399 replies to ELECTION vote request: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t13. Peer's state: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399:t13, leader=null, voted=null, raftlog=c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:14:55,607 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: receive requestVote(ELECTION, 8b366c76-456d-4ec7-ac8e-95910f7eaaa6, group-8C8526B83399, 14, (t:8, i:28))
dn5_1    | 2022-06-16 01:14:55,607 [grpc-default-executor-0] INFO impl.VoteContext: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FOLLOWER: reject ELECTION from 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: our priority 1 > candidate's priority 0
dn5_1    | 2022-06-16 01:14:55,607 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: changes role from  FOLLOWER to FOLLOWER at term 14 for candidate:8b366c76-456d-4ec7-ac8e-95910f7eaaa6
dn5_1    | 2022-06-16 01:14:55,607 [grpc-default-executor-0] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: shutdown c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState
dn5_1    | 2022-06-16 01:14:55,607 [grpc-default-executor-0] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: start c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState
dn5_1    | 2022-06-16 01:14:55,608 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState] INFO impl.FollowerState: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState was interrupted
dn5_1    | 2022-06-16 01:14:55,612 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399 replies to ELECTION vote request: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t14. Peer's state: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399:t14, leader=null, voted=null, raftlog=c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:14:58,170 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | 2022-06-16 01:14:58,174 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn5_1    | 2022-06-16 01:14:58,175 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn5_1    | 2022-06-16 01:14:58,177 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn5_1    | 2022-06-16 01:14:58,177 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn5_1    | 2022-06-16 01:14:58,178 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:17:43,141 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn2_1    | 2022-06-16 01:17:43,141 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn2_1    | 2022-06-16 01:17:43,141 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn2_1    | 2022-06-16 01:17:43,141 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn2_1    | 2022-06-16 01:17:43,141 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn2_1    | 2022-06-16 01:17:43,141 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:17:43,142 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:17:43,142 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn2_1    | 2022-06-16 01:17:43,142 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn2_1    | 2022-06-16 01:17:43,142 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn2_1    | 2022-06-16 01:17:43,142 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn2_1    | 2022-06-16 01:17:43,142 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn2_1    | 2022-06-16 01:17:43,142 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:17:43,146 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:18:13,141 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn2_1    | 2022-06-16 01:18:13,141 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn2_1    | 2022-06-16 01:18:13,141 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn2_1    | 2022-06-16 01:18:13,141 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn2_1    | 2022-06-16 01:18:13,141 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn2_1    | 2022-06-16 01:18:13,141 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:18:13,142 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:19:13,142 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn2_1    | 2022-06-16 01:19:13,142 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn2_1    | 2022-06-16 01:19:13,142 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn2_1    | 2022-06-16 01:19:13,142 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn2_1    | 2022-06-16 01:19:13,142 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn2_1    | 2022-06-16 01:19:13,142 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:19:13,143 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:19:43,142 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn2_1    | 2022-06-16 01:19:43,142 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn2_1    | 2022-06-16 01:19:43,142 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn2_1    | 2022-06-16 01:19:43,143 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn2_1    | 2022-06-16 01:19:43,143 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn2_1    | 2022-06-16 01:19:43,143 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-06-16 01:19:43,143 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1    | 2022-06-16 01:13:39,757 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1    | /************************************************************
scm_1    | STARTUP_MSG: Starting StorageContainerManager
scm_1    | STARTUP_MSG:   host = 2299bb28ca0a/10.9.0.14
scm_1    | STARTUP_MSG:   args = []
scm_1    | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/gson-2.8.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm_1    | STARTUP_MSG:   build = https://github.com/apache/ozone/17d3301a908af2df7683a0c61b8ee3ae8dd41d6a ; compiled by 'runner' on 2022-06-16T00:51Z
scm_1    | STARTUP_MSG:   java = 11.0.14.1
scm_1    | ************************************************************/
scm_1    | 2022-06-16 01:13:39,961 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1    | 2022-06-16 01:13:41,079 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm_1    | 2022-06-16 01:13:41,140 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm_1    | 2022-06-16 01:13:42,536 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1    | 2022-06-16 01:13:53,517 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1    | 2022-06-16 01:13:57,309 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1    | 2022-06-16 01:13:59,580 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm_1    | 2022-06-16 01:13:59,702 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1    | 2022-06-16 01:14:00,961 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm_1    | 2022-06-16 01:14:01,392 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = DATANODE_SCHEMA_V3 (version = 4)
scm_1    | 2022-06-16 01:14:06,024 [main] INFO reflections.Reflections: Reflections took 1690 ms to scan 3 urls, producing 109 keys and 239 values 
scm_1    | 2022-06-16 01:14:06,960 [main] INFO upgrade.HDDSLayoutVersionManager: Registering Upgrade Action : DatanodeSchemaV3FinalizeAction
scm_1    | 2022-06-16 01:14:07,154 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm_1    | 2022-06-16 01:14:07,813 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1    | 2022-06-16 01:14:08,015 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm_1    | 2022-06-16 01:14:08,919 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm_1    | 2022-06-16 01:14:08,942 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm_1    | 2022-06-16 01:14:09,002 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm_1    | 2022-06-16 01:14:09,068 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm_1    | 2022-06-16 01:14:09,100 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm_1    | 2022-06-16 01:14:09,100 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
scm_1    | 2022-06-16 01:14:09,203 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
scm_1    | 2022-06-16 01:14:09,212 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
scm_1    | 2022-06-16 01:14:09,666 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm_1    | 2022-06-16 01:14:09,992 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm_1    | 2022-06-16 01:14:10,266 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm_1    | 2022-06-16 01:14:10,267 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm_1    | 2022-06-16 01:14:10,776 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1    | 2022-06-16 01:14:10,862 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm_1    | 2022-06-16 01:14:10,908 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 2, healthy pipeline threshold count is 1
scm_1    | 2022-06-16 01:14:10,973 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 2, pipeline's with at least one datanode reported threshold count is 2
scm_1    | 2022-06-16 01:14:17,984 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm_1    | 2022-06-16 01:14:18,057 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1    | 2022-06-16 01:14:18,181 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1    | 2022-06-16 01:14:18,236 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm_1    | 2022-06-16 01:14:18,242 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1    | 2022-06-16 01:14:18,243 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1    | 2022-06-16 01:14:18,275 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm_1    | 2022-06-16 01:14:18,282 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1    | 2022-06-16 01:14:18,298 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1    | 2022-06-16 01:14:18,425 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
scm_1    | 2022-06-16 01:14:18,426 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm_1    | Container Balancer status:
scm_1    | Key                            Value
scm_1    | Running                        false
scm_1    | Container Balancer Configuration values:
scm_1    | Key                                                Value
scm_1    | Threshold                                          10
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:14:58,179 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:14:58,180 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | 2022-06-16 01:14:58,180 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn5_1    | 2022-06-16 01:14:58,180 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn5_1    | 2022-06-16 01:14:58,180 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn5_1    | 2022-06-16 01:14:58,180 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn5_1    | 2022-06-16 01:14:58,180 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:14:58,181 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:14:58,181 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | 2022-06-16 01:14:58,181 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn5_1    | 2022-06-16 01:14:58,181 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn5_1    | 2022-06-16 01:14:58,181 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn5_1    | 2022-06-16 01:14:58,181 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn5_1    | 2022-06-16 01:14:58,181 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1    | Max Datanodes to Involve per Iteration(percent)    20
scm_1    | Max Size to Move per Iteration                     500GB
scm_1    | Max Size Entering Target per Iteration             26GB
scm_1    | Max Size Leaving Source per Iteration              26GB
scm_1    | 
scm_1    | 2022-06-16 01:14:18,426 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm_1    | 2022-06-16 01:14:18,427 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm_1    | 2022-06-16 01:14:18,432 [Listener at 0.0.0.0/9860] INFO upgrade.UpgradeFinalizer: Running pre-finalized state validations for unfinalized layout features.
scm_1    | 2022-06-16 01:14:18,438 [Listener at 0.0.0.0/9860] INFO upgrade.UpgradeFinalizer: Running first upgrade commands for unfinalized layout features.
scm_1    | 2022-06-16 01:14:18,438 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1    | 2022-06-16 01:14:18,758 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1    | 2022-06-16 01:14:18,848 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1    | 2022-06-16 01:14:18,848 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1    | 2022-06-16 01:14:19,464 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1    | 2022-06-16 01:14:19,472 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1    | 2022-06-16 01:14:19,473 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1    | 2022-06-16 01:14:19,860 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1    | 2022-06-16 01:14:19,861 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1    | 2022-06-16 01:14:19,880 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1    | 2022-06-16 01:14:19,932 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1    | 2022-06-16 01:14:20,166 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1    | 2022-06-16 01:14:20,177 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1    | 2022-06-16 01:14:20,177 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm_1    | 2022-06-16 01:14:20,297 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2c748a15] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1    | 2022-06-16 01:14:20,319 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm_1    | 2022-06-16 01:14:20,320 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
scm_1    | 2022-06-16 01:14:20,417 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @53441ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1    | 2022-06-16 01:14:21,607 [Listener at 0.0.0.0/9860] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1    | 2022-06-16 01:14:21,659 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1    | 2022-06-16 01:14:21,736 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1    | 2022-06-16 01:14:21,747 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
scm_1    | 2022-06-16 01:14:21,798 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
scm_1    | 2022-06-16 01:14:21,798 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
scm_1    | 2022-06-16 01:14:21,970 [IPC Server handler 4 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/8b366c76-456d-4ec7-ac8e-95910f7eaaa6
scm_1    | 2022-06-16 01:14:22,042 [IPC Server handler 4 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 8b366c76-456d-4ec7-ac8e-95910f7eaaa6{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
scm_1    | 2022-06-16 01:14:22,118 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1    | 2022-06-16 01:14:22,138 [IPC Server handler 6 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/835c1189-b066-4617-a285-c9fdbaf1d7b5
scm_1    | 2022-06-16 01:14:22,214 [IPC Server handler 6 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 835c1189-b066-4617-a285-c9fdbaf1d7b5{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
scm_1    | 2022-06-16 01:14:22,218 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm_1    | 2022-06-16 01:14:22,219 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm_1    | 2022-06-16 01:14:22,231 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1    | 2022-06-16 01:14:22,461 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Pipelines with at least one datanode reported count is 2, required at least one datanode reported per pipeline count is 2
scm_1    | 2022-06-16 01:14:22,474 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1    | 2022-06-16 01:14:22,483 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1    | 2022-06-16 01:14:22,484 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1    | 2022-06-16 01:14:22,540 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1    | 2022-06-16 01:14:22,614 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm_1    | 2022-06-16 01:14:22,615 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
dn5_1    | 2022-06-16 01:14:58,181 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:14:58,182 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | 2022-06-16 01:14:58,182 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn5_1    | 2022-06-16 01:14:58,182 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn5_1    | 2022-06-16 01:14:58,182 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn5_1    | 2022-06-16 01:14:58,183 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn5_1    | 2022-06-16 01:14:58,183 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:14:58,184 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:14:58,184 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | 2022-06-16 01:14:58,184 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn5_1    | 2022-06-16 01:14:58,184 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn5_1    | 2022-06-16 01:14:58,185 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn5_1    | 2022-06-16 01:14:58,185 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn5_1    | 2022-06-16 01:14:58,185 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:14:58,185 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
scm_1    | 2022-06-16 01:14:22,909 [IPC Server handler 7 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/32c66434-cc2b-41ce-bc06-c42e833faba3
scm_1    | 2022-06-16 01:14:22,909 [IPC Server handler 7 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 32c66434-cc2b-41ce-bc06-c42e833faba3{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
scm_1    | 2022-06-16 01:14:22,909 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1    | 2022-06-16 01:14:22,909 [IPC Server handler 5 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/c7eeb289-59cc-4c90-a00f-b0c50499b5ba
scm_1    | 2022-06-16 01:14:22,914 [IPC Server handler 5 on default port 9861] INFO node.SCMNodeManager: Registered Data node : c7eeb289-59cc-4c90-a00f-b0c50499b5ba{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
scm_1    | 2022-06-16 01:14:22,917 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm_1    | 2022-06-16 01:14:22,922 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1    | 2022-06-16 01:14:22,926 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm_1    | 2022-06-16 01:14:22,926 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1    | 2022-06-16 01:14:22,932 [IPC Server handler 18 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/c3461ed7-1554-428d-9478-8d95583cf36e
scm_1    | 2022-06-16 01:14:22,932 [IPC Server handler 18 on default port 9861] INFO node.SCMNodeManager: Registered Data node : c3461ed7-1554-428d-9478-8d95583cf36e{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
scm_1    | 2022-06-16 01:14:22,934 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1    | 2022-06-16 01:14:22,950 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1    | 2022-06-16 01:14:22,950 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1    | 2022-06-16 01:14:22,957 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm_1    | 2022-06-16 01:14:22,926 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm_1    | 2022-06-16 01:14:23,015 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm_1    | 2022-06-16 01:14:23,119 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1    | 2022-06-16 01:14:23,121 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1    | 2022-06-16 01:14:23,126 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1    | 2022-06-16 01:14:23,126 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm_1    | 2022-06-16 01:14:23,126 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm_1    | 2022-06-16 01:14:23,127 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm_1    | 2022-06-16 01:14:23,129 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
scm_1    | 2022-06-16 01:14:23,134 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO BackgroundPipelineScrubber: Service BackgroundPipelineScrubber transitions to RUNNING.
scm_1    | 2022-06-16 01:14:23,192 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ExpiredContainerReplicaOpScrubber: Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
scm_1    | 2022-06-16 01:14:23,243 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO replication.ReplicationManager: Service ReplicationManager transitions to RUNNING.
scm_1    | 2022-06-16 01:14:23,247 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
scm_1    | 2022-06-16 01:14:23,263 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1    | 2022-06-16 01:14:23,269 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm_1    | 2022-06-16 01:14:23,269 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm_1    | 2022-06-16 01:14:23,269 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=false, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm_1    | 2022-06-16 01:14:23,304 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1    | 2022-06-16 01:14:23,304 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm_1    | 2022-06-16 01:14:23,316 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
scm_1    | 2022-06-16 01:14:23,270 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
scm_1    | 2022-06-16 01:14:23,334 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1    | 2022-06-16 01:14:23,335 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm_1    | 2022-06-16 01:14:23,335 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm_1    | 2022-06-16 01:14:23,335 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=false, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm_1    | 2022-06-16 01:14:23,335 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
scm_1    | 2022-06-16 01:14:23,448 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@739e8b96{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1    | 2022-06-16 01:14:23,482 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@30aec673{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1    | 2022-06-16 01:14:24,430 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@b5ac0c1{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-7316418848521690682/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm_1    | 2022-06-16 01:14:24,465 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@4d0cc83e{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm_1    | 2022-06-16 01:14:24,465 [Listener at 0.0.0.0/9860] INFO server.Server: Started @57488ms
scm_1    | 2022-06-16 01:14:24,478 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1    | 2022-06-16 01:14:24,478 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1    | 2022-06-16 01:14:24,481 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm_1    | 2022-06-16 01:14:51,564 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Finalization started.
scm_1    | 2022-06-16 01:14:51,566 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: SCM Finalization has crossed checkpoint FINALIZATION_STARTED
scm_1    | 2022-06-16 01:14:51,567 [IPC Server handler 2 on default port 9860] INFO pipeline.BackgroundPipelineCreator: Stopping RatisPipelineUtilsThread.
scm_1    | 2022-06-16 01:14:51,567 [RatisPipelineUtilsThread - 0] WARN pipeline.BackgroundPipelineCreator: RatisPipelineUtilsThread is interrupted.
scm_1    | 2022-06-16 01:14:51,570 [IPC Server handler 2 on default port 9860] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 0934911a-aba3-405f-94e4-cbcf5e919788, Nodes: c7eeb289-59cc-4c90-a00f-b0c50499b5ba{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:c7eeb289-59cc-4c90-a00f-b0c50499b5ba, CreationTimestamp2022-06-16T01:14:08.748991Z[UTC]] moved to CLOSED state
scm_1    | 2022-06-16 01:14:51,577 [IPC Server handler 2 on default port 9860] INFO pipeline.PipelineManagerImpl: Container #2 closed for pipeline=PipelineID=cfb1d3a9-fa49-4890-85f5-5fc878c6c2de
scm_1    | 2022-06-16 01:14:51,578 [IPC Server handler 2 on default port 9860] INFO pipeline.PipelineManagerImpl: Container #1001 closed for pipeline=PipelineID=cfb1d3a9-fa49-4890-85f5-5fc878c6c2de
scm_1    | 2022-06-16 01:14:51,578 [IPC Server handler 2 on default port 9860] INFO pipeline.PipelineManagerImpl: Container #2001 closed for pipeline=PipelineID=cfb1d3a9-fa49-4890-85f5-5fc878c6c2de
scm_1    | 2022-06-16 01:14:51,579 [IPC Server handler 2 on default port 9860] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: cfb1d3a9-fa49-4890-85f5-5fc878c6c2de, Nodes: c3461ed7-1554-428d-9478-8d95583cf36e{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c7eeb289-59cc-4c90-a00f-b0c50499b5ba{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8b366c76-456d-4ec7-ac8e-95910f7eaaa6{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:c7eeb289-59cc-4c90-a00f-b0c50499b5ba, CreationTimestamp2022-06-16T01:14:08.789591Z[UTC]] moved to CLOSED state
scm_1    | 2022-06-16 01:14:51,580 [IPC Server handler 2 on default port 9860] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 2577d48d-2a86-4064-a889-f9ecb8551840, Nodes: 32c66434-cc2b-41ce-bc06-c42e833faba3{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:32c66434-cc2b-41ce-bc06-c42e833faba3, CreationTimestamp2022-06-16T01:14:08.762065Z[UTC]] moved to CLOSED state
scm_1    | 2022-06-16 01:14:51,580 [IPC Server handler 2 on default port 9860] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: ae07a9fd-bfc0-4f3c-b02e-a4b953253c7c, Nodes: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:8b366c76-456d-4ec7-ac8e-95910f7eaaa6, CreationTimestamp2022-06-16T01:14:08.762736Z[UTC]] moved to CLOSED state
scm_1    | 2022-06-16 01:14:51,580 [IPC Server handler 2 on default port 9860] INFO pipeline.PipelineManagerImpl: Container #1 closed for pipeline=PipelineID=377f6c61-bebc-49cf-9883-8c8526b83399
scm_1    | 2022-06-16 01:14:51,581 [IPC Server handler 2 on default port 9860] INFO pipeline.PipelineManagerImpl: Container #1002 closed for pipeline=PipelineID=377f6c61-bebc-49cf-9883-8c8526b83399
scm_1    | 2022-06-16 01:14:51,581 [IPC Server handler 2 on default port 9860] INFO pipeline.PipelineManagerImpl: Container #2002 closed for pipeline=PipelineID=377f6c61-bebc-49cf-9883-8c8526b83399
scm_1    | 2022-06-16 01:14:51,582 [IPC Server handler 2 on default port 9860] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 377f6c61-bebc-49cf-9883-8c8526b83399, Nodes: c3461ed7-1554-428d-9478-8d95583cf36e{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8b366c76-456d-4ec7-ac8e-95910f7eaaa6{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c7eeb289-59cc-4c90-a00f-b0c50499b5ba{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:c3461ed7-1554-428d-9478-8d95583cf36e, CreationTimestamp2022-06-16T01:14:08.762413Z[UTC]] moved to CLOSED state
scm_1    | 2022-06-16 01:14:51,582 [IPC Server handler 2 on default port 9860] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 4321e5aa-575a-4764-b053-3d4e612b41cc, Nodes: c3461ed7-1554-428d-9478-8d95583cf36e{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:c3461ed7-1554-428d-9478-8d95583cf36e, CreationTimestamp2022-06-16T01:14:08.762587Z[UTC]] moved to CLOSED state
scm_1    | 2022-06-16 01:14:51,583 [IPC Server handler 2 on default port 9860] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: bb9bc3de-e3de-455a-8b75-c8ce16ab84ae, Nodes: 835c1189-b066-4617-a285-c9fdbaf1d7b5{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:835c1189-b066-4617-a285-c9fdbaf1d7b5, CreationTimestamp2022-06-16T01:14:08.762903Z[UTC]] moved to CLOSED state
scm_1    | 2022-06-16 01:14:51,583 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer:   Existing pipelines and containers will be closed during Upgrade.
scm_1    |   New pipelines creation will remain frozen until Upgrade is finalized.
scm_1    | 2022-06-16 01:14:51,583 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: ERASURE_CODED_STORAGE_SUPPORT.
scm_1    | 2022-06-16 01:14:51,584 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #2
scm_1    | 2022-06-16 01:14:51,608 [IPC Server handler 2 on default port 9860] INFO upgrade.AbstractLayoutVersionManager: Layout feature ERASURE_CODED_STORAGE_SUPPORT has been finalized.
scm_1    | 2022-06-16 01:14:51,609 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #1001
scm_1    | 2022-06-16 01:14:51,609 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: DATANODE_SCHEMA_V3.
scm_1    | 2022-06-16 01:14:51,609 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #2001
scm_1    | 2022-06-16 01:14:51,610 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #1
scm_1    | 2022-06-16 01:14:51,610 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #1002
scm_1    | 2022-06-16 01:14:51,610 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #2002
scm_1    | 2022-06-16 01:14:51,610 [IPC Server handler 2 on default port 9860] INFO upgrade.AbstractLayoutVersionManager: Layout feature DATANODE_SCHEMA_V3 has been finalized.
scm_1    | 2022-06-16 01:14:51,611 [IPC Server handler 2 on default port 9860] INFO upgrade.AbstractLayoutVersionManager: Finalization is complete.
scm_1    | 2022-06-16 01:14:51,623 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: SCM Finalization has crossed checkpoint MLV_EQUALS_SLV
scm_1    | 2022-06-16 01:14:51,623 [IPC Server handler 2 on default port 9860] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm_1    | 2022-06-16 01:14:51,624 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Datanode c7eeb289-59cc-4c90-a00f-b0c50499b5ba{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to HEALTHY READONLY state.
scm_1    | 2022-06-16 01:14:51,624 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=0934911a-aba3-405f-94e4-cbcf5e919788 in state CLOSED which uses HEALTHY_READONLY datanode c7eeb289-59cc-4c90-a00f-b0c50499b5ba. This will send close commands for its containers.
scm_1    | 2022-06-16 01:14:51,627 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=cfb1d3a9-fa49-4890-85f5-5fc878c6c2de in state CLOSED which uses HEALTHY_READONLY datanode c7eeb289-59cc-4c90-a00f-b0c50499b5ba. This will send close commands for its containers.
scm_1    | 2022-06-16 01:14:51,627 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=377f6c61-bebc-49cf-9883-8c8526b83399 in state CLOSED which uses HEALTHY_READONLY datanode c7eeb289-59cc-4c90-a00f-b0c50499b5ba. This will send close commands for its containers.
scm_1    | 2022-06-16 01:14:51,627 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:14:51,627 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Datanode 32c66434-cc2b-41ce-bc06-c42e833faba3{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to HEALTHY READONLY state.
scm_1    | 2022-06-16 01:14:51,633 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=2577d48d-2a86-4064-a889-f9ecb8551840 in state CLOSED which uses HEALTHY_READONLY datanode 32c66434-cc2b-41ce-bc06-c42e833faba3. This will send close commands for its containers.
scm_1    | 2022-06-16 01:14:51,634 [RatisPipelineUtilsThread - 0] ERROR scm.SCMCommonPlacementPolicy: Unable to find enough nodes that meet the space requirement of 1073741824 bytes for metadata and 1073741824 bytes for data in healthy node set. Required 3. Found 0.
scm_1    | 2022-06-16 01:14:51,635 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Datanode c3461ed7-1554-428d-9478-8d95583cf36e{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to HEALTHY READONLY state.
scm_1    | 2022-06-16 01:14:51,635 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=cfb1d3a9-fa49-4890-85f5-5fc878c6c2de in state CLOSED which uses HEALTHY_READONLY datanode c3461ed7-1554-428d-9478-8d95583cf36e. This will send close commands for its containers.
scm_1    | 2022-06-16 01:14:51,636 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=377f6c61-bebc-49cf-9883-8c8526b83399 in state CLOSED which uses HEALTHY_READONLY datanode c3461ed7-1554-428d-9478-8d95583cf36e. This will send close commands for its containers.
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:14:58,185 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | 2022-06-16 01:14:58,185 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn5_1    | 2022-06-16 01:14:58,185 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn5_1    | 2022-06-16 01:14:58,186 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn5_1    | 2022-06-16 01:14:58,186 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn5_1    | 2022-06-16 01:14:58,186 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:14:58,186 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:15:00,722 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: receive requestVote(ELECTION, 8b366c76-456d-4ec7-ac8e-95910f7eaaa6, group-8C8526B83399, 15, (t:8, i:28))
dn5_1    | 2022-06-16 01:15:00,723 [grpc-default-executor-0] INFO impl.VoteContext: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FOLLOWER: reject ELECTION from 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: our priority 1 > candidate's priority 0
dn5_1    | 2022-06-16 01:15:00,723 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: changes role from  FOLLOWER to FOLLOWER at term 15 for candidate:8b366c76-456d-4ec7-ac8e-95910f7eaaa6
dn5_1    | 2022-06-16 01:15:00,723 [grpc-default-executor-0] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: shutdown c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState
dn5_1    | 2022-06-16 01:15:00,723 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState] INFO impl.FollowerState: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState was interrupted
dn5_1    | 2022-06-16 01:15:00,723 [grpc-default-executor-0] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: start c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState
dn5_1    | 2022-06-16 01:15:00,727 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399 replies to ELECTION vote request: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t15. Peer's state: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399:t15, leader=null, voted=null, raftlog=c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:15:05,761 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState] INFO impl.FollowerState: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5037287997ns, electionTimeout:5036ms
dn5_1    | 2022-06-16 01:15:05,761 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: shutdown c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState
dn5_1    | 2022-06-16 01:15:05,761 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: changes role from  FOLLOWER to CANDIDATE at term 15 for changeToCandidate
dn5_1    | 2022-06-16 01:15:05,761 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn5_1    | 2022-06-16 01:15:05,762 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: start c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection4
scm_1    | 2022-06-16 01:14:51,636 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=4321e5aa-575a-4764-b053-3d4e612b41cc in state CLOSED which uses HEALTHY_READONLY datanode c3461ed7-1554-428d-9478-8d95583cf36e. This will send close commands for its containers.
scm_1    | 2022-06-16 01:14:51,636 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Datanode 835c1189-b066-4617-a285-c9fdbaf1d7b5{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to HEALTHY READONLY state.
scm_1    | 2022-06-16 01:14:51,636 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=bb9bc3de-e3de-455a-8b75-c8ce16ab84ae in state CLOSED which uses HEALTHY_READONLY datanode 835c1189-b066-4617-a285-c9fdbaf1d7b5. This will send close commands for its containers.
scm_1    | 2022-06-16 01:14:51,636 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Datanode 8b366c76-456d-4ec7-ac8e-95910f7eaaa6{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to HEALTHY READONLY state.
scm_1    | 2022-06-16 01:14:51,641 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=cfb1d3a9-fa49-4890-85f5-5fc878c6c2de in state CLOSED which uses HEALTHY_READONLY datanode 8b366c76-456d-4ec7-ac8e-95910f7eaaa6. This will send close commands for its containers.
scm_1    | 2022-06-16 01:14:51,642 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=ae07a9fd-bfc0-4f3c-b02e-a4b953253c7c in state CLOSED which uses HEALTHY_READONLY datanode 8b366c76-456d-4ec7-ac8e-95910f7eaaa6. This will send close commands for its containers.
scm_1    | 2022-06-16 01:14:51,643 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=377f6c61-bebc-49cf-9883-8c8526b83399 in state CLOSED which uses HEALTHY_READONLY datanode 8b366c76-456d-4ec7-ac8e-95910f7eaaa6. This will send close commands for its containers.
scm_1    | 2022-06-16 01:14:56,508 [IPC Server handler 2 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:14:56,628 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:14:56,790 [IPC Server handler 0 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:14:56,909 [IPC Server handler 18 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:14:57,085 [IPC Server handler 7 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:14:57,544 [IPC Server handler 2 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:14:57,584 [IPC Server handler 0 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:14:57,597 [IPC Server handler 1 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:14:57,608 [IPC Server handler 5 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:14:57,615 [IPC Server handler 18 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:14:57,620 [IPC Server handler 7 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:14:58,095 [IPC Server handler 20 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:14:58,143 [IPC Server handler 24 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:14:58,148 [IPC Server handler 19 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:14:58,158 [IPC Server handler 25 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:14:58,171 [IPC Server handler 22 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:14:58,174 [IPC Server handler 31 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:15:01,628 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:15:06,628 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:15:10,543 [IPC Server handler 2 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:15:11,557 [IPC Server handler 0 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:15:11,629 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:15:11,773 [IPC Server handler 20 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:15:11,775 [FixedThreadPoolWithAffinityExecutor-1-0] INFO container.IncrementalContainerReportHandler: Moving container #2 to CLOSED state, datanode c3461ed7-1554-428d-9478-8d95583cf36e{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm_1    | 2022-06-16 01:15:11,784 [IPC Server handler 24 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:15:11,826 [IPC Server handler 19 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:15:11,865 [IPC Server handler 25 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:15:11,983 [IPC Server handler 22 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:15:11,985 [FixedThreadPoolWithAffinityExecutor-1-0] INFO container.IncrementalContainerReportHandler: Moving container #1001 to CLOSED state, datanode c7eeb289-59cc-4c90-a00f-b0c50499b5ba{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm_1    | 2022-06-16 01:15:12,004 [IPC Server handler 31 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:15:12,010 [IPC Server handler 23 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:15:12,025 [IPC Server handler 30 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:15:12,100 [IPC Server handler 29 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:15:12,102 [FixedThreadPoolWithAffinityExecutor-1-0] INFO container.IncrementalContainerReportHandler: Moving container #2001 to CLOSED state, datanode 8b366c76-456d-4ec7-ac8e-95910f7eaaa6{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm_1    | 2022-06-16 01:15:12,107 [IPC Server handler 32 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:15:12,117 [IPC Server handler 12 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:15:12,122 [IPC Server handler 98 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:15:12,132 [IPC Server handler 11 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:15:12,143 [IPC Server handler 10 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:15:16,629 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:15:20,308 [SCMBlockDeletingService#0] INFO block.SCMBlockDeletingService: Totally added 3 blocks to be deleted for 3 datanodes, task elapsed time: 3ms
scm_1    | 2022-06-16 01:15:20,932 [IPC Server handler 22 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:15:21,630 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:15:21,636 [RatisPipelineUtilsThread - 0] ERROR scm.SCMCommonPlacementPolicy: Unable to find enough nodes that meet the space requirement of 1073741824 bytes for metadata and 1073741824 bytes for data in healthy node set. Required 3. Found 0.
scm_1    | 2022-06-16 01:15:26,630 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:15:26,790 [IPC Server handler 19 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:15:28,900 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO node.ReadOnlyHealthyToHealthyNodeHandler: Datanode 32c66434-cc2b-41ce-bc06-c42e833faba3{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to HEALTHY state.
scm_1    | 2022-06-16 01:15:28,900 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1    | 2022-06-16 01:15:28,903 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=28ac5e1e-72b1-40fd-a3cf-a4053e55f144 to datanode:32c66434-cc2b-41ce-bc06-c42e833faba3
scm_1    | 2022-06-16 01:15:28,905 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 28ac5e1e-72b1-40fd-a3cf-a4053e55f144, Nodes: 32c66434-cc2b-41ce-bc06-c42e833faba3{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-16T01:15:28.902Z[UTC]].
scm_1    | 2022-06-16 01:15:28,908 [RatisPipelineUtilsThread - 0] ERROR scm.SCMCommonPlacementPolicy: Unable to find enough nodes that meet the space requirement of 1073741824 bytes for metadata and 1073741824 bytes for data in healthy node set. Required 3. Found 1.
scm_1    | 2022-06-16 01:15:31,630 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:15:36,632 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
dn5_1    | 2022-06-16 01:15:05,764 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection4] INFO impl.LeaderElection: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection4 ELECTION round 0: submit vote requests at term 16 for 19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:15:05,772 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: receive requestVote(ELECTION, 8b366c76-456d-4ec7-ac8e-95910f7eaaa6, group-8C8526B83399, 16, (t:8, i:28))
dn5_1    | 2022-06-16 01:15:05,776 [grpc-default-executor-0] INFO impl.VoteContext: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-CANDIDATE: reject ELECTION from 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: already has voted for c3461ed7-1554-428d-9478-8d95583cf36e at current term 16
dn5_1    | 2022-06-16 01:15:05,777 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399 replies to ELECTION vote request: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t16. Peer's state: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399:t16, leader=null, voted=c3461ed7-1554-428d-9478-8d95583cf36e, raftlog=c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:15:05,798 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection4] INFO impl.LeaderElection: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection4: ELECTION REJECTED received 2 response(s) and 0 exception(s):
dn5_1    | 2022-06-16 01:15:05,798 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection4] INFO impl.LeaderElection:   Response 0: c3461ed7-1554-428d-9478-8d95583cf36e<-8b366c76-456d-4ec7-ac8e-95910f7eaaa6#0:FAIL-t16
dn5_1    | 2022-06-16 01:15:05,799 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection4] INFO impl.LeaderElection:   Response 1: c3461ed7-1554-428d-9478-8d95583cf36e<-c7eeb289-59cc-4c90-a00f-b0c50499b5ba#0:FAIL-t16
dn5_1    | 2022-06-16 01:15:05,799 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection4] INFO impl.LeaderElection: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection4 ELECTION round 0: result REJECTED
dn5_1    | 2022-06-16 01:15:05,800 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection4] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: changes role from CANDIDATE to FOLLOWER at term 16 for REJECTED
dn5_1    | 2022-06-16 01:15:05,800 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection4] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: shutdown c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection4
dn5_1    | 2022-06-16 01:15:05,800 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection4] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: start c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState
dn5_1    | 2022-06-16 01:15:10,838 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: receive requestVote(ELECTION, 8b366c76-456d-4ec7-ac8e-95910f7eaaa6, group-8C8526B83399, 17, (t:8, i:28))
dn5_1    | 2022-06-16 01:15:10,839 [grpc-default-executor-0] INFO impl.VoteContext: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FOLLOWER: reject ELECTION from 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: our priority 1 > candidate's priority 0
dn5_1    | 2022-06-16 01:15:10,839 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: changes role from  FOLLOWER to FOLLOWER at term 17 for candidate:8b366c76-456d-4ec7-ac8e-95910f7eaaa6
dn5_1    | 2022-06-16 01:15:10,839 [grpc-default-executor-0] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: shutdown c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState
dn5_1    | 2022-06-16 01:15:10,839 [grpc-default-executor-0] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: start c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState
dn5_1    | 2022-06-16 01:15:10,839 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState] INFO impl.FollowerState: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState was interrupted
dn5_1    | 2022-06-16 01:15:10,844 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399 replies to ELECTION vote request: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t17. Peer's state: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399:t17, leader=null, voted=null, raftlog=c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:15:11,747 [ContainerOp-cfb1d3a9-fa49-4890-85f5-5fc878c6c2de-0] INFO keyvalue.KeyValueContainer: Container 2 is synced with bcsId 2.
dn5_1    | 2022-06-16 01:15:11,748 [ContainerOp-cfb1d3a9-fa49-4890-85f5-5fc878c6c2de-0] INFO keyvalue.KeyValueContainer: Container 2 is synced with bcsId 2.
dn5_1    | 2022-06-16 01:15:11,754 [ContainerOp-cfb1d3a9-fa49-4890-85f5-5fc878c6c2de-0] INFO keyvalue.KeyValueContainer: Container 2 is closed with bcsId 2.
dn5_1    | 2022-06-16 01:15:11,982 [ContainerOp-cfb1d3a9-fa49-4890-85f5-5fc878c6c2de-1] INFO keyvalue.KeyValueContainer: Container 1001 is synced with bcsId 20.
dn5_1    | 2022-06-16 01:15:11,991 [ContainerOp-cfb1d3a9-fa49-4890-85f5-5fc878c6c2de-1] INFO keyvalue.KeyValueContainer: Container 1001 is synced with bcsId 20.
dn5_1    | 2022-06-16 01:15:12,004 [ContainerOp-cfb1d3a9-fa49-4890-85f5-5fc878c6c2de-1] INFO keyvalue.KeyValueContainer: Container 1001 is closed with bcsId 20.
dn5_1    | 2022-06-16 01:15:12,094 [ContainerOp-cfb1d3a9-fa49-4890-85f5-5fc878c6c2de-2] INFO keyvalue.KeyValueContainer: Container 2001 is synced with bcsId 36.
dn5_1    | 2022-06-16 01:15:12,095 [ContainerOp-cfb1d3a9-fa49-4890-85f5-5fc878c6c2de-2] INFO keyvalue.KeyValueContainer: Container 2001 is synced with bcsId 36.
dn5_1    | 2022-06-16 01:15:12,114 [ContainerOp-cfb1d3a9-fa49-4890-85f5-5fc878c6c2de-2] INFO keyvalue.KeyValueContainer: Container 2001 is closed with bcsId 36.
dn5_1    | 2022-06-16 01:15:15,858 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState] INFO impl.FollowerState: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5018328863ns, electionTimeout:5016ms
dn5_1    | 2022-06-16 01:15:15,858 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: shutdown c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState
scm_1    | 2022-06-16 01:15:41,632 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:15:42,108 [IPC Server handler 32 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:15:42,144 [IPC Server handler 10 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:15:46,633 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:15:50,940 [IPC Server handler 31 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:15:51,633 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:15:56,633 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:15:57,933 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 28ac5e1e-72b1-40fd-a3cf-a4053e55f144, Nodes: 32c66434-cc2b-41ce-bc06-c42e833faba3{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:32c66434-cc2b-41ce-bc06-c42e833faba3, CreationTimestamp2022-06-16T01:15:28.902Z[UTC]] moved to OPEN state
scm_1    | 2022-06-16 01:15:58,903 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO node.ReadOnlyHealthyToHealthyNodeHandler: Datanode 835c1189-b066-4617-a285-c9fdbaf1d7b5{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to HEALTHY state.
scm_1    | 2022-06-16 01:15:58,903 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1    | 2022-06-16 01:15:58,904 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=ce5a0a3f-f6c5-4883-b95d-51ddeed5744f to datanode:835c1189-b066-4617-a285-c9fdbaf1d7b5
scm_1    | 2022-06-16 01:15:58,905 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: ce5a0a3f-f6c5-4883-b95d-51ddeed5744f, Nodes: 835c1189-b066-4617-a285-c9fdbaf1d7b5{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-16T01:15:58.904Z[UTC]].
scm_1    | 2022-06-16 01:15:58,906 [RatisPipelineUtilsThread - 0] ERROR scm.SCMCommonPlacementPolicy: Unable to find enough nodes that meet the space requirement of 1073741824 bytes for metadata and 1073741824 bytes for data in healthy node set. Required 3. Found 2.
scm_1    | 2022-06-16 01:16:01,634 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:16:06,635 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:16:11,635 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:16:12,100 [IPC Server handler 32 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:16:12,144 [IPC Server handler 10 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:16:16,635 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:16:20,932 [IPC Server handler 31 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:16:21,636 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:16:26,636 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:16:27,827 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: ce5a0a3f-f6c5-4883-b95d-51ddeed5744f, Nodes: 835c1189-b066-4617-a285-c9fdbaf1d7b5{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:835c1189-b066-4617-a285-c9fdbaf1d7b5, CreationTimestamp2022-06-16T01:15:58.904Z[UTC]] moved to OPEN state
scm_1    | 2022-06-16 01:16:28,907 [RatisPipelineUtilsThread - 0] ERROR scm.SCMCommonPlacementPolicy: Unable to find enough nodes that meet the space requirement of 1073741824 bytes for metadata and 1073741824 bytes for data in healthy node set. Required 3. Found 2.
scm_1    | 2022-06-16 01:16:31,637 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:16:36,638 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:16:41,638 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:16:42,101 [IPC Server handler 32 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:16:42,144 [IPC Server handler 11 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:16:46,638 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:16:50,933 [IPC Server handler 31 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:16:51,639 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:16:56,639 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:16:58,908 [RatisPipelineUtilsThread - 0] ERROR scm.SCMCommonPlacementPolicy: Unable to find enough nodes that meet the space requirement of 1073741824 bytes for metadata and 1073741824 bytes for data in healthy node set. Required 3. Found 2.
scm_1    | 2022-06-16 01:17:01,640 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:17:06,640 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:17:11,640 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:17:12,101 [IPC Server handler 32 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:17:12,147 [IPC Server handler 11 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:17:16,641 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:17:20,934 [IPC Server handler 31 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:17:21,641 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:17:26,641 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:17:28,909 [RatisPipelineUtilsThread - 0] ERROR scm.SCMCommonPlacementPolicy: Unable to find enough nodes that meet the space requirement of 1073741824 bytes for metadata and 1073741824 bytes for data in healthy node set. Required 3. Found 2.
scm_1    | 2022-06-16 01:17:31,642 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:17:36,642 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:17:41,642 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:17:42,102 [IPC Server handler 32 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:17:42,145 [IPC Server handler 11 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:17:46,643 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:17:50,933 [IPC Server handler 31 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:17:51,643 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:17:56,643 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:17:58,910 [RatisPipelineUtilsThread - 0] ERROR scm.SCMCommonPlacementPolicy: Unable to find enough nodes that meet the space requirement of 1073741824 bytes for metadata and 1073741824 bytes for data in healthy node set. Required 3. Found 2.
scm_1    | 2022-06-16 01:18:01,644 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:18:06,644 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:18:11,644 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:18:12,101 [IPC Server handler 32 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:18:12,145 [IPC Server handler 98 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:18:16,645 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:18:20,933 [IPC Server handler 31 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:18:21,645 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:18:26,646 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:18:28,911 [RatisPipelineUtilsThread - 0] ERROR scm.SCMCommonPlacementPolicy: Unable to find enough nodes that meet the space requirement of 1073741824 bytes for metadata and 1073741824 bytes for data in healthy node set. Required 3. Found 2.
scm_1    | 2022-06-16 01:18:31,646 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:18:36,646 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:18:41,647 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:18:42,104 [IPC Server handler 32 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:18:42,144 [IPC Server handler 12 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:18:46,647 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
dn5_1    | 2022-06-16 01:15:15,858 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: changes role from  FOLLOWER to CANDIDATE at term 17 for changeToCandidate
dn5_1    | 2022-06-16 01:15:15,858 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn5_1    | 2022-06-16 01:15:15,859 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: start c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection5
dn5_1    | 2022-06-16 01:15:15,864 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection5] INFO impl.LeaderElection: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection5 ELECTION round 0: submit vote requests at term 18 for 19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:15:15,871 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: receive requestVote(ELECTION, 8b366c76-456d-4ec7-ac8e-95910f7eaaa6, group-8C8526B83399, 18, (t:8, i:28))
dn5_1    | 2022-06-16 01:15:15,871 [grpc-default-executor-0] INFO impl.VoteContext: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-CANDIDATE: reject ELECTION from 8b366c76-456d-4ec7-ac8e-95910f7eaaa6: already has voted for c3461ed7-1554-428d-9478-8d95583cf36e at current term 18
dn5_1    | 2022-06-16 01:15:15,872 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399 replies to ELECTION vote request: 8b366c76-456d-4ec7-ac8e-95910f7eaaa6<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t18. Peer's state: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399:t18, leader=null, voted=c3461ed7-1554-428d-9478-8d95583cf36e, raftlog=c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:15:15,894 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: receive requestVote(ELECTION, c7eeb289-59cc-4c90-a00f-b0c50499b5ba, group-8C8526B83399, 18, (t:8, i:28))
dn5_1    | 2022-06-16 01:15:15,895 [grpc-default-executor-0] INFO impl.VoteContext: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-CANDIDATE: reject ELECTION from c7eeb289-59cc-4c90-a00f-b0c50499b5ba: already has voted for c3461ed7-1554-428d-9478-8d95583cf36e at current term 18
dn5_1    | 2022-06-16 01:15:15,895 [grpc-default-executor-0] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399 replies to ELECTION vote request: c7eeb289-59cc-4c90-a00f-b0c50499b5ba<-c3461ed7-1554-428d-9478-8d95583cf36e#0:FAIL-t18. Peer's state: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399:t18, leader=null, voted=c3461ed7-1554-428d-9478-8d95583cf36e, raftlog=c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-SegmentedRaftLog:OPENED:c28, conf=19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:15:15,899 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection5] INFO impl.LeaderElection: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection5: ELECTION REJECTED received 2 response(s) and 0 exception(s):
dn5_1    | 2022-06-16 01:15:15,900 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection5] INFO impl.LeaderElection:   Response 0: c3461ed7-1554-428d-9478-8d95583cf36e<-8b366c76-456d-4ec7-ac8e-95910f7eaaa6#0:FAIL-t18
dn5_1    | 2022-06-16 01:15:15,900 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection5] INFO impl.LeaderElection:   Response 1: c3461ed7-1554-428d-9478-8d95583cf36e<-c7eeb289-59cc-4c90-a00f-b0c50499b5ba#0:FAIL-t18
dn5_1    | 2022-06-16 01:15:15,900 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection5] INFO impl.LeaderElection: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection5 ELECTION round 0: result REJECTED
dn5_1    | 2022-06-16 01:15:15,900 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection5] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: changes role from CANDIDATE to FOLLOWER at term 18 for REJECTED
dn5_1    | 2022-06-16 01:15:15,900 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection5] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: shutdown c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection5
dn5_1    | 2022-06-16 01:15:15,901 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection5] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: start c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState
dn5_1    | 2022-06-16 01:15:20,907 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState] INFO impl.FollowerState: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5005736875ns, electionTimeout:5003ms
dn5_1    | 2022-06-16 01:15:20,907 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: shutdown c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState
dn5_1    | 2022-06-16 01:15:20,907 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: changes role from  FOLLOWER to CANDIDATE at term 18 for changeToCandidate
dn5_1    | 2022-06-16 01:15:20,907 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn5_1    | 2022-06-16 01:15:20,907 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-FollowerState] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: start c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6
dn5_1    | 2022-06-16 01:15:20,910 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO impl.LeaderElection: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6 ELECTION round 0: submit vote requests at term 19 for 19: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:15:20,924 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO impl.LeaderElection: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6: ELECTION PASSED received 1 response(s) and 0 exception(s):
dn5_1    | 2022-06-16 01:15:20,924 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO impl.LeaderElection:   Response 0: c3461ed7-1554-428d-9478-8d95583cf36e<-8b366c76-456d-4ec7-ac8e-95910f7eaaa6#0:OK-t19
scm_1    | 2022-06-16 01:18:50,934 [IPC Server handler 31 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:18:51,647 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:18:56,648 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:18:58,912 [RatisPipelineUtilsThread - 0] ERROR scm.SCMCommonPlacementPolicy: Unable to find enough nodes that meet the space requirement of 1073741824 bytes for metadata and 1073741824 bytes for data in healthy node set. Required 3. Found 2.
scm_1    | 2022-06-16 01:19:01,648 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:19:06,648 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:19:10,849 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1    | 2022-06-16 01:19:11,649 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:19:12,102 [IPC Server handler 32 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:19:12,146 [IPC Server handler 12 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:19:16,649 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:19:20,934 [IPC Server handler 22 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:19:21,650 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:19:26,650 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:19:28,913 [RatisPipelineUtilsThread - 0] ERROR scm.SCMCommonPlacementPolicy: Unable to find enough nodes that meet the space requirement of 1073741824 bytes for metadata and 1073741824 bytes for data in healthy node set. Required 3. Found 2.
scm_1    | 2022-06-16 01:19:31,650 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:19:36,651 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:19:41,651 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:19:42,104 [IPC Server handler 32 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:19:42,146 [IPC Server handler 12 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:19:46,651 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:19:50,933 [IPC Server handler 22 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-06-16 01:19:51,652 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:19:56,652 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-06-16 01:19:58,914 [RatisPipelineUtilsThread - 0] ERROR scm.SCMCommonPlacementPolicy: Unable to find enough nodes that meet the space requirement of 1073741824 bytes for metadata and 1073741824 bytes for data in healthy node set. Required 3. Found 2.
scm_1    | 2022-06-16 01:20:01,653 [IPC Server handler 2 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
dn5_1    | 2022-06-16 01:15:20,925 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO impl.LeaderElection: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6 ELECTION round 0: result PASSED
dn5_1    | 2022-06-16 01:15:20,928 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: shutdown c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6
dn5_1    | 2022-06-16 01:15:20,928 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: changes role from CANDIDATE to LEADER at term 19 for changeToLeader
dn5_1    | 2022-06-16 01:15:20,928 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-8C8526B83399 with new leaderId: c3461ed7-1554-428d-9478-8d95583cf36e
dn5_1    | 2022-06-16 01:15:20,929 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: change Leader from null to c3461ed7-1554-428d-9478-8d95583cf36e at term 19 for becomeLeader, leader elected after 64561ms
dn5_1    | 2022-06-16 01:15:20,929 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn5_1    | 2022-06-16 01:15:20,929 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn5_1    | 2022-06-16 01:15:20,929 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn5_1    | 2022-06-16 01:15:20,930 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn5_1    | 2022-06-16 01:15:20,930 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn5_1    | 2022-06-16 01:15:20,930 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn5_1    | 2022-06-16 01:15:20,930 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn5_1    | 2022-06-16 01:15:20,930 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn5_1    | 2022-06-16 01:15:20,947 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn5_1    | 2022-06-16 01:15:20,948 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn5_1    | 2022-06-16 01:15:20,948 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
dn5_1    | 2022-06-16 01:15:20,951 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn5_1    | 2022-06-16 01:15:20,951 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn5_1    | 2022-06-16 01:15:20,951 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn5_1    | 2022-06-16 01:15:20,954 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn5_1    | 2022-06-16 01:15:20,954 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn5_1    | 2022-06-16 01:15:20,954 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
dn5_1    | 2022-06-16 01:15:20,955 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn5_1    | 2022-06-16 01:15:20,955 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn5_1    | 2022-06-16 01:15:20,955 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn5_1    | 2022-06-16 01:15:20,956 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO impl.RoleInfo: c3461ed7-1554-428d-9478-8d95583cf36e: start c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderStateImpl
dn5_1    | 2022-06-16 01:15:20,957 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO segmented.SegmentedRaftLogWorker: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-SegmentedRaftLogWorker: Rolling segment log-19_28 to index:28
dn5_1    | 2022-06-16 01:15:20,963 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399/current/log_inprogress_19 to /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399/current/log_19-28
dn5_1    | 2022-06-16 01:15:20,963 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-LeaderElection6] INFO server.RaftServer$Division: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399: set configuration 29: [8b366c76-456d-4ec7-ac8e-95910f7eaaa6|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0, c7eeb289-59cc-4c90-a00f-b0c50499b5ba|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, c3461ed7-1554-428d-9478-8d95583cf36e|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-06-16 01:15:20,966 [c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c3461ed7-1554-428d-9478-8d95583cf36e@group-8C8526B83399-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/377f6c61-bebc-49cf-9883-8c8526b83399/current/log_inprogress_29
dn5_1    | 2022-06-16 01:15:29,170 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | 2022-06-16 01:15:29,171 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn5_1    | 2022-06-16 01:15:29,172 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn5_1    | 2022-06-16 01:15:29,172 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn5_1    | 2022-06-16 01:15:29,172 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn5_1    | 2022-06-16 01:15:29,172 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:15:29,172 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:15:29,173 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | 2022-06-16 01:15:29,173 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn5_1    | 2022-06-16 01:15:29,173 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn5_1    | 2022-06-16 01:15:29,173 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn5_1    | 2022-06-16 01:15:29,173 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn5_1    | 2022-06-16 01:15:29,173 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:15:29,174 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:15:29,174 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | 2022-06-16 01:15:29,174 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn5_1    | 2022-06-16 01:15:29,174 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn5_1    | 2022-06-16 01:15:29,174 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn5_1    | 2022-06-16 01:15:29,174 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn5_1    | 2022-06-16 01:15:29,174 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:15:29,175 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:15:29,175 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | 2022-06-16 01:15:29,175 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn5_1    | 2022-06-16 01:15:29,175 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn5_1    | 2022-06-16 01:15:29,175 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn5_1    | 2022-06-16 01:15:29,175 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn5_1    | 2022-06-16 01:15:29,176 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:15:29,176 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:15:29,181 [org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@1ca3d25b] INFO commandhandler.DeleteBlocksCommandHandler: Start to delete container blocks, TXIDs=[2(0)], numOfContainers=1, numOfBlocks=1
dn5_1    | 2022-06-16 01:15:51,928 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | 2022-06-16 01:15:51,928 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn5_1    | 2022-06-16 01:15:51,928 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn5_1    | 2022-06-16 01:15:51,928 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn5_1    | 2022-06-16 01:15:51,928 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn5_1    | 2022-06-16 01:15:51,928 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:15:51,929 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:15:51,930 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | 2022-06-16 01:15:51,930 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn5_1    | 2022-06-16 01:15:51,930 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn5_1    | 2022-06-16 01:15:51,930 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn5_1    | 2022-06-16 01:15:51,930 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn5_1    | 2022-06-16 01:15:51,930 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:15:51,931 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:16:22,091 [BlockDeletingService#0] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-3e3c8fff-8818-4ab8-8118-66b81944a69d/current/containerDir0/2/chunks/109611004723200002.block
dn5_1    | 2022-06-16 01:16:51,928 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | 2022-06-16 01:16:51,928 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn5_1    | 2022-06-16 01:16:51,928 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn5_1    | 2022-06-16 01:16:51,928 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn5_1    | 2022-06-16 01:16:51,928 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn5_1    | 2022-06-16 01:16:51,928 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:16:51,929 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:17:21,928 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | 2022-06-16 01:17:21,928 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn5_1    | 2022-06-16 01:17:21,929 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn5_1    | 2022-06-16 01:17:21,929 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn5_1    | 2022-06-16 01:17:21,929 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn5_1    | 2022-06-16 01:17:21,929 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:17:21,929 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:17:21,929 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | 2022-06-16 01:17:21,930 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn5_1    | 2022-06-16 01:17:21,930 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn5_1    | 2022-06-16 01:17:21,930 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn5_1    | 2022-06-16 01:17:21,930 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn5_1    | 2022-06-16 01:17:21,930 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:17:21,930 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:18:21,929 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | 2022-06-16 01:18:21,929 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn5_1    | 2022-06-16 01:18:21,929 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn5_1    | 2022-06-16 01:18:21,929 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn5_1    | 2022-06-16 01:18:21,929 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn5_1    | 2022-06-16 01:18:21,930 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:18:21,930 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:18:51,929 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | 2022-06-16 01:18:51,929 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn5_1    | 2022-06-16 01:18:51,929 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn5_1    | 2022-06-16 01:18:51,929 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn5_1    | 2022-06-16 01:18:51,929 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn5_1    | 2022-06-16 01:18:51,929 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:18:51,930 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:19:21,929 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | 2022-06-16 01:19:21,929 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn5_1    | 2022-06-16 01:19:21,929 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn5_1    | 2022-06-16 01:19:21,929 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn5_1    | 2022-06-16 01:19:21,929 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn5_1    | 2022-06-16 01:19:21,929 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:19:21,930 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:19:51,929 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | 2022-06-16 01:19:51,929 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn5_1    | 2022-06-16 01:19:51,929 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn5_1    | 2022-06-16 01:19:51,930 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn5_1    | 2022-06-16 01:19:51,930 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn5_1    | 2022-06-16 01:19:51,930 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-06-16 01:19:51,930 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:56)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:40)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:49)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:93)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:684)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:613)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
