2022-06-25 01:08:30,972 [Mini-Cluster-Provider-Create] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-06-25 01:08:31,041 [Mini-Cluster-Provider-Create] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-06-25 01:08:31,041 [Mini-Cluster-Provider-Create] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(209)) - ServiceID for StorageContainerManager is null
2022-06-25 01:08:31,041 [Mini-Cluster-Provider-Create] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(214)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2022-06-25 01:08:31,042 [Mini-Cluster-Provider-Create] WARN  utils.HAUtils (HAUtils.java:getMetaDir(342)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-06-25 01:08:31,047 [Mini-Cluster-Provider-Create] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-06-25 01:08:31,523 [Mini-Cluster-Provider-Create] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.3.0-SNAPSHOT/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
2022-06-25 01:08:31,523 [Mini-Cluster-Provider-Create] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2022-06-25 01:08:31,542 [Mini-Cluster-Provider-Create] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:08:31,542 [Mini-Cluster-Provider-Create] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:08:31,542 [Mini-Cluster-Provider-Create] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(82)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2022-06-25 01:08:31,656 [Mini-Cluster-Provider-Create] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 113 ms to scan 7 urls, producing 131 keys and 316 values 
2022-06-25 01:08:31,658 [Mini-Cluster-Provider-Create] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(347)) - upgrade localId to 109611004723200000
2022-06-25 01:08:31,658 [Mini-Cluster-Provider-Create] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(357)) - upgrade delTxnId to 0
2022-06-25 01:08:31,658 [Mini-Cluster-Provider-Create] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(374)) - upgrade containerId to 0
2022-06-25 01:08:31,658 [Mini-Cluster-Provider-Create] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(218)) - Init the HA SequenceIdGenerator.
2022-06-25 01:08:31,660 [Mini-Cluster-Provider-Create] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(149)) - Entering startup safe mode.
2022-06-25 01:08:31,660 [Mini-Cluster-Provider-Create] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2022-06-25 01:08:31,661 [Mini-Cluster-Provider-Create] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(78)) - No pipeline exists in current db
2022-06-25 01:08:31,661 [Mini-Cluster-Provider-Create] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2022-06-25 01:08:31,661 [Mini-Cluster-Provider-Create] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2022-06-25 01:08:31,661 [Mini-Cluster-Provider-Create] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(127)) - Starting RatisPipelineUtilsThread.
2022-06-25 01:08:31,670 [Mini-Cluster-Provider-Create] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(68)) - Starting BackgroundPipelineScrubber Service.
2022-06-25 01:08:31,675 [Mini-Cluster-Provider-Create] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2022-06-25 01:08:31,675 [Mini-Cluster-Provider-Create] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2022-06-25 01:08:31,675 [Mini-Cluster-Provider-Create] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(68)) - Starting ExpiredContainerReplicaOpScrubber Service.
2022-06-25 01:08:31,681 [Mini-Cluster-Provider-Create] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2022-06-25 01:08:31,681 [Mini-Cluster-Provider-Create] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(73)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2022-06-25 01:08:31,681 [Mini-Cluster-Provider-Create] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2022-06-25 01:08:31,682 [Mini-Cluster-Provider-Create] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2022-06-25 01:08:31,682 [Mini-Cluster-Provider-Create] INFO  replication.ReplicationManager (ReplicationManager.java:start(179)) - Starting Replication Monitor Thread.
2022-06-25 01:08:31,685 [Mini-Cluster-Provider-Create] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 0
2022-06-25 01:08:31,685 [Mini-Cluster-Provider-Create] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(156)) - Total pipeline count is 0, healthy pipeline threshold count is 1
2022-06-25 01:08:31,686 [Mini-Cluster-Provider-Create] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2022-06-25 01:08:31,687 [Mini-Cluster-Provider-Create] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-06-25 01:08:31,688 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 0
2022-06-25 01:08:31,689 [Listener at 0.0.0.0/36557] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-06-25 01:08:31,691 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 0
2022-06-25 01:08:31,692 [Listener at 0.0.0.0/44789] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-06-25 01:08:31,694 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 0
2022-06-25 01:08:31,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:31,764 [Listener at 0.0.0.0/38653] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2022-06-25 01:08:31,764 [Listener at 0.0.0.0/38653] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(400)) - 
Container Balancer status:
Key                            Value
Running                        false
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2022-06-25 01:08:31,765 [Listener at 0.0.0.0/38653] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2022-06-25 01:08:31,765 [Listener at 0.0.0.0/38653] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2022-06-25 01:08:31,765 [Listener at 0.0.0.0/38653] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1418)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:38653
2022-06-25 01:08:31,785 [Listener at 0.0.0.0/38653] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(136)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2022-06-25 01:08:31,794 [Listener at 0.0.0.0/38653] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 10 second(s).
2022-06-25 01:08:31,794 [Listener at 0.0.0.0/38653] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2022-06-25 01:08:31,805 [Listener at 0.0.0.0/38653] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2022-06-25 01:08:31,805 [Listener at 0.0.0.0/38653] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(305)) - Registered sink prometheus
2022-06-25 01:08:31,825 [Listener at 0.0.0.0/38653] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(169)) - RPC server for Client  is listening at /0.0.0.0:38653
2022-06-25 01:08:31,826 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-06-25 01:08:31,826 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 0: starting
2022-06-25 01:08:31,828 [Listener at 0.0.0.0/38653] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1433)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:44789
2022-06-25 01:08:31,828 [Listener at 0.0.0.0/38653] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(151)) - RPC server for Block Protocol is listening at /0.0.0.0:44789
2022-06-25 01:08:31,829 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-06-25 01:08:31,829 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 0: starting
2022-06-25 01:08:31,998 [Listener at 0.0.0.0/38653] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(185)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:36557
2022-06-25 01:08:31,998 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-06-25 01:08:31,998 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 0: starting
2022-06-25 01:08:32,053 [Listener at 0.0.0.0/38653] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for scm at: http://0.0.0.0:0
2022-06-25 01:08:32,054 [Listener at 0.0.0.0/38653] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-06-25 01:08:32,055 [Listener at 0.0.0.0/38653] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-06-25 01:08:32,055 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3ccd5352] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-06-25 01:08:32,083 [Listener at 0.0.0.0/38653] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-06-25 01:08:32,179 [Listener at 0.0.0.0/38653] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1029)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-06-25 01:08:32,180 [Listener at 0.0.0.0/38653] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1005)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2022-06-25 01:08:32,180 [Listener at 0.0.0.0/38653] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-06-25 01:08:32,180 [Listener at 0.0.0.0/38653] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-06-25 01:08:32,180 [Listener at 0.0.0.0/38653] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1248)) - Jetty bound to port 35763
2022-06-25 01:08:32,180 [Listener at 0.0.0.0/38653] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-06-25 01:08:32,192 [Listener at 0.0.0.0/38653] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-06-25 01:08:32,193 [Listener at 0.0.0.0/38653] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-06-25 01:08:32,193 [Listener at 0.0.0.0/38653] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2022-06-25 01:08:32,195 [Listener at 0.0.0.0/38653] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@20f16681{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-06-25 01:08:32,195 [Listener at 0.0.0.0/38653] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@7e7b9904{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2022-06-25 01:08:32,197 [Listener at 0.0.0.0/38653] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@4ce57534{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2022-06-25 01:08:32,345 [Listener at 0.0.0.0/38653] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@5828c18f{HTTP/1.1, (http/1.1)}{0.0.0.0:35763}
2022-06-25 01:08:32,345 [Listener at 0.0.0.0/38653] INFO  server.Server (Server.java:doStart(415)) - Started @346242ms
2022-06-25 01:08:32,346 [Listener at 0.0.0.0/38653] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-06-25 01:08:32,348 [Listener at 0.0.0.0/38653] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of scm listening at http://0.0.0.0:35763
2022-06-25 01:08:32,348 [Listener at 0.0.0.0/38653] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-06-25 01:08:32,350 [Listener at 0.0.0.0/38653] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(115)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2022-06-25 01:08:32,350 [Listener at 0.0.0.0/38653] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(226)) - Configuration does not have ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2022-06-25 01:08:32,350 [Listener at 0.0.0.0/38653] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(254)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2022-06-25 01:08:32,350 [Listener at 0.0.0.0/38653] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(261)) - OM Node ID is not set. Setting it to the default ID: om1
2022-06-25 01:08:32,351 [Listener at 0.0.0.0/38653] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-06-25 01:08:32,351 [Listener at 0.0.0.0/38653] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(82)) - Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
2022-06-25 01:08:32,572 [Listener at 0.0.0.0/38653] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 220 ms to scan 2 urls, producing 152 keys and 429 values [using 2 cores]
2022-06-25 01:08:32,572 [Listener at 0.0.0.0/38653] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(115)) - Skipping Upgrade Action MockOmUpgradeAction since it has been finalized.
2022-06-25 01:08:32,572 [Listener at 0.0.0.0/38653] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-06-25 01:08:32,573 [Listener at 0.0.0.0/38653] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:44789]
2022-06-25 01:08:32,574 [Listener at 0.0.0.0/38653] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:44789]
2022-06-25 01:08:32,662 [Listener at 0.0.0.0/38653] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-06-25 01:08:32,662 [Listener at 0.0.0.0/38653] INFO  codec.OmKeyInfoCodec (OmKeyInfoCodec.java:<init>(49)) - OmKeyInfoCodec ignorePipeline = true
2022-06-25 01:08:32,662 [Listener at 0.0.0.0/38653] INFO  codec.RepeatedOmKeyInfoCodec (RepeatedOmKeyInfoCodec.java:<init>(41)) - RepeatedOmKeyInfoCodec ignorePipeline = true
2022-06-25 01:08:32,710 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:33,426 [Listener at 0.0.0.0/38653] INFO  om.OzoneManager (OzoneManager.java:instantiateServices(692)) - S3 Multi-Tenancy is disabled
2022-06-25 01:08:33,640 [Listener at 0.0.0.0/38653] INFO  om.OzoneManager (OzoneManager.java:addS3GVolumeToDB(4259)) - Created Volume s3v With Owner runner required for S3Gateway operations.
2022-06-25 01:08:33,640 [Listener at 0.0.0.0/38653] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(237)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2022-06-25 01:08:33,641 [Listener at 0.0.0.0/38653] WARN  utils.OzoneManagerRatisUtils (OzoneManagerRatisUtils.java:getOMRatisSnapshotDirectory(431)) - ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
2022-06-25 01:08:33,641 [Listener at 0.0.0.0/38653] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:08:33,641 [Listener at 0.0.0.0/38653] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:08:33,641 [Listener at 0.0.0.0/38653] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(237)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2022-06-25 01:08:33,642 [Listener at 0.0.0.0/38653] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(159)) - Instantiating OM Ratis server with groupID: omServiceIdDefault and peers: localhost:41635
2022-06-25 01:08:33,642 [Listener at 0.0.0.0/38653] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:loadSnapshotInfoFromDB(632)) - LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
2022-06-25 01:08:33,675 [Listener at 0.0.0.0/38653] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-06-25 01:08:33,675 [Listener at 0.0.0.0/38653] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-06-25 01:08:33,675 [Listener at 0.0.0.0/38653] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = -1 (default)
2022-06-25 01:08:33,675 [Listener at 0.0.0.0/38653] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 41635 (custom)
2022-06-25 01:08:33,675 [Listener at 0.0.0.0/38653] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = -1 (default)
2022-06-25 01:08:33,675 [Listener at 0.0.0.0/38653] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 41635 (custom)
2022-06-25 01:08:33,676 [Listener at 0.0.0.0/38653] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 41635 (custom)
2022-06-25 01:08:33,676 [Listener at 0.0.0.0/38653] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 33554432 (custom)
2022-06-25 01:08:33,676 [Listener at 0.0.0.0/38653] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:08:33,676 [Listener at 0.0.0.0/38653] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2022-06-25 01:08:33,676 [Listener at 0.0.0.0/38653] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2022-06-25 01:08:33,676 [Listener at 0.0.0.0/38653] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-06-25 01:08:33,676 [Listener at 0.0.0.0/38653] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-06-25 01:08:33,677 [Listener at 0.0.0.0/38653] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-06-25 01:08:33,677 [Listener at 0.0.0.0/38653] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-06-25 01:08:33,678 [Listener at 0.0.0.0/38653] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-06-25 01:08:33,678 [Listener at 0.0.0.0/38653] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2022-06-25 01:08:33,678 [Listener at 0.0.0.0/38653] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:08:33,678 [Listener at 0.0.0.0/38653] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/ozone-meta/ratis] (custom)
2022-06-25 01:08:33,685 [Listener at 0.0.0.0/38653] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - om1: addNew group-C5BA1605619E:[om1|rpc:localhost:41635|priority:0] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@b6ca8fd[Not completed]
2022-06-25 01:08:33,685 [Listener at 0.0.0.0/38653] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(1961)) - OzoneManager Ratis server initialized at port 41635
2022-06-25 01:08:33,691 [Listener at 0.0.0.0/38653] INFO  om.OzoneManager (OzoneManager.java:getRpcServer(1081)) - Creating RPC Server
2022-06-25 01:08:33,702 [pool-4085-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - om1: new RaftServerImpl for group-C5BA1605619E:[om1|rpc:localhost:41635|priority:0] with OzoneManagerStateMachine:uninitialized
2022-06-25 01:08:33,702 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2022-06-25 01:08:33,702 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 1200ms (custom)
2022-06-25 01:08:33,702 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:08:33,702 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2022-06-25 01:08:33,702 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:08:33,702 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:08:33,702 [pool-4085-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - om1@group-C5BA1605619E: ConfigurationManager, init=-1: [om1|rpc:localhost:41635|priority:0], old=null, confs=<EMPTY_MAP>
2022-06-25 01:08:33,703 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/ozone-meta/ratis] (custom)
2022-06-25 01:08:33,703 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:08:33,703 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:08:33,703 [pool-4085-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
2022-06-25 01:08:33,710 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:33,740 [pool-4085-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:08:33,826 [pool-4085-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
2022-06-25 01:08:33,827 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 120s (custom)
2022-06-25 01:08:33,827 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:08:33,827 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:08:33,827 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:08:33,827 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:08:33,827 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2022-06-25 01:08:33,850 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:08:33,851 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:08:33,851 [pool-4085-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e
2022-06-25 01:08:33,851 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2022-06-25 01:08:33,851 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 4096 (default)
2022-06-25 01:08:33,851 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2022-06-25 01:08:33,851 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2022-06-25 01:08:33,851 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:08:33,851 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:08:33,851 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:08:33,851 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:08:33,856 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2022-06-25 01:08:33,856 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:08:33,856 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2022-06-25 01:08:33,856 [pool-4085-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:08:33,856 [pool-4085-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:08:33,857 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:08:33,857 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2022-06-25 01:08:33,857 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = -1 (default)
2022-06-25 01:08:33,857 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = true (custom)
2022-06-25 01:08:33,857 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 300s (custom)
2022-06-25 01:08:33,857 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:08:33,860 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:08:33,860 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:08:33,861 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:08:33,861 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:08:33,861 [pool-4085-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:08:34,711 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:34,909 [Listener at 0.0.0.0/38653] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 1217 ms to scan 19 urls, producing 66 keys and 4066 values [using 2 cores]
2022-06-25 01:08:34,910 [Listener at 0.0.0.0/38653] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-06-25 01:08:34,917 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 0
2022-06-25 01:08:35,101 [Listener at 127.0.0.1/35133] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2022-06-25 01:08:35,116 [Listener at 127.0.0.1/35133] INFO  om.OzoneManager (OzoneManager.java:start(1465)) - OzoneManager RPC server is listening at localhost/127.0.0.1:35133
2022-06-25 01:08:35,116 [Listener at 127.0.0.1/35133] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(554)) - Starting OzoneManagerRatisServer om1 at port 41635
2022-06-25 01:08:35,116 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - om1@group-C5BA1605619E: start as a follower, conf=-1: [om1|rpc:localhost:41635|priority:0], old=null
2022-06-25 01:08:35,116 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:08:35,116 [om1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-FollowerState
2022-06-25 01:08:35,121 [om1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2022-06-25 01:08:35,122 [Listener at 127.0.0.1/35133] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - om1: start RPC server
2022-06-25 01:08:35,123 [Listener at 127.0.0.1/35133] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - om1: GrpcService started, listening on 41635
2022-06-25 01:08:35,123 [Listener at 127.0.0.1/35133] INFO  om.OzoneManager (OzoneManager.java:start(1481)) - Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
2022-06-25 01:08:35,123 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@59be0973] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-om1: Started
2022-06-25 01:08:35,125 [Listener at 127.0.0.1/35133] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2022-06-25 01:08:35,125 [Listener at 127.0.0.1/35133] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-06-25 01:08:35,134 [Listener at 127.0.0.1/35133] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-06-25 01:08:35,141 [Listener at 127.0.0.1/35133] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-06-25 01:08:35,142 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1029)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-06-25 01:08:35,142 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1005)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2022-06-25 01:08:35,142 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-06-25 01:08:35,142 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-06-25 01:08:35,142 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1248)) - Jetty bound to port 39019
2022-06-25 01:08:35,143 [Listener at 127.0.0.1/35133] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-06-25 01:08:35,213 [Listener at 127.0.0.1/35133] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-06-25 01:08:35,214 [Listener at 127.0.0.1/35133] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-06-25 01:08:35,214 [Listener at 127.0.0.1/35133] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-06-25 01:08:35,215 [Listener at 127.0.0.1/35133] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@7e2d6cc7{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-06-25 01:08:35,216 [Listener at 127.0.0.1/35133] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@3ffe6ccd{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2022-06-25 01:08:35,218 [Listener at 127.0.0.1/35133] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@1387d972{ozoneManager,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2022-06-25 01:08:35,226 [Listener at 127.0.0.1/35133] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@6d997b5a{HTTP/1.1, (http/1.1)}{0.0.0.0:39019}
2022-06-25 01:08:35,226 [Listener at 127.0.0.1/35133] INFO  server.Server (Server.java:doStart(415)) - Started @349123ms
2022-06-25 01:08:35,226 [Listener at 127.0.0.1/35133] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-06-25 01:08:35,227 [Listener at 127.0.0.1/35133] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of ozoneManager listening at http://0.0.0.0:39019
2022-06-25 01:08:35,237 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-06-25 01:08:35,258 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 0: starting
2022-06-25 01:08:35,266 [Listener at 127.0.0.1/35133] INFO  om.OzoneManager (OzoneManager.java:startTrashEmptier(1905)) - Trash Interval set to 0. Files deleted won't move to trash
2022-06-25 01:08:35,346 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@61e7021d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-06-25 01:08:35,354 [Listener at 127.0.0.1/35133] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:08:35,354 [Listener at 127.0.0.1/35133] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:08:35,354 [Listener at 127.0.0.1/35133] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-06-25 01:08:35,384 [Listener at 127.0.0.1/35133] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net ip:10.1.0.8
2022-06-25 01:08:35,439 [Listener at 127.0.0.1/35133] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(82)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2022-06-25 01:08:35,507 [Listener at 127.0.0.1/35133] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 63 ms to scan 7 urls, producing 131 keys and 316 values 
2022-06-25 01:08:35,514 [Listener at 127.0.0.1/35133] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(237)) - Datanode State Machine Task Thread Pool size 2
2022-06-25 01:08:35,523 [Listener at 127.0.0.1/35133] INFO  volume.HddsVolume (HddsVolume.java:<init>(116)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-06-25 01:08:35,523 [Listener at 127.0.0.1/35133] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data-0/containers/hdds to VolumeSet
2022-06-25 01:08:35,523 [Listener at 127.0.0.1/35133] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data-0/containers/hdds
2022-06-25 01:08:35,529 [Listener at 127.0.0.1/35133] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data-0/containers/hdds
2022-06-25 01:08:35,583 [Listener at 127.0.0.1/35133] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis to VolumeSet
2022-06-25 01:08:35,583 [Listener at 127.0.0.1/35133] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis
2022-06-25 01:08:35,589 [Listener at 127.0.0.1/35133] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis
2022-06-25 01:08:35,610 [Thread-5567] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data-0/containers/hdds
2022-06-25 01:08:35,610 [Listener at 127.0.0.1/35133] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(266)) - Build ContainerSet costs 0s
2022-06-25 01:08:35,612 [Listener at 127.0.0.1/35133] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-06-25 01:08:35,612 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-06-25 01:08:35,612 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-06-25 01:08:35,612 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-06-25 01:08:35,612 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-06-25 01:08:35,612 [Listener at 127.0.0.1/35133] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-06-25 01:08:35,612 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:08:35,612 [Listener at 127.0.0.1/35133] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-06-25 01:08:35,612 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:08:35,612 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-06-25 01:08:35,613 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-06-25 01:08:35,614 [Listener at 127.0.0.1/35133] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-06-25 01:08:35,614 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-06-25 01:08:35,614 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-06-25 01:08:35,614 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:08:35,614 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:08:35,614 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis] (custom)
2022-06-25 01:08:35,615 [Listener at 127.0.0.1/35133] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-06-25 01:08:35,624 [Listener at 127.0.0.1/35133] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-06-25 01:08:35,624 [Listener at 127.0.0.1/35133] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-06-25 01:08:35,629 [Listener at 127.0.0.1/35133] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-06-25 01:08:35,630 [Listener at 127.0.0.1/35133] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-06-25 01:08:35,631 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1029)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-06-25 01:08:35,631 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1005)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-06-25 01:08:35,631 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-06-25 01:08:35,631 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-06-25 01:08:35,632 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1248)) - Jetty bound to port 45929
2022-06-25 01:08:35,632 [Listener at 127.0.0.1/35133] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-06-25 01:08:35,639 [Listener at 127.0.0.1/35133] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-06-25 01:08:35,639 [Listener at 127.0.0.1/35133] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-06-25 01:08:35,648 [Listener at 127.0.0.1/35133] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2022-06-25 01:08:35,650 [Listener at 127.0.0.1/35133] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@9ebdb37{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-06-25 01:08:35,650 [Listener at 127.0.0.1/35133] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@47701f4d{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-06-25 01:08:35,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:36,152 [Listener at 127.0.0.1/35133] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@31373d8c{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-45929-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-2255463261147391743/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-25 01:08:36,283 [Listener at 127.0.0.1/35133] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@3e96590c{HTTP/1.1, (http/1.1)}{0.0.0.0:45929}
2022-06-25 01:08:36,284 [Listener at 127.0.0.1/35133] INFO  server.Server (Server.java:doStart(415)) - Started @350180ms
2022-06-25 01:08:36,284 [Listener at 127.0.0.1/35133] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-06-25 01:08:36,327 [om1@group-C5BA1605619E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1210380594ns, electionTimeout:1200ms
2022-06-25 01:08:36,327 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - om1: shutdown om1@group-C5BA1605619E-FollowerState
2022-06-25 01:08:36,327 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:08:36,327 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:08:36,327 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderElection143
2022-06-25 01:08:36,357 [Listener at 127.0.0.1/35133] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:45929
2022-06-25 01:08:36,378 [Listener at 127.0.0.1/35133] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:08:36,378 [Listener at 127.0.0.1/35133] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:08:36,378 [Listener at 127.0.0.1/35133] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-06-25 01:08:36,397 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(492)) - Ozone container server started.
2022-06-25 01:08:36,420 [Listener at 127.0.0.1/35133] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net ip:10.1.0.8
2022-06-25 01:08:36,427 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@37724c3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-06-25 01:08:36,435 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/meta/datanode.id
2022-06-25 01:08:36,444 [om1@group-C5BA1605619E-LeaderElection143] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - om1@group-C5BA1605619E-LeaderElection143 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:localhost:41635|priority:0], old=null
2022-06-25 01:08:36,444 [om1@group-C5BA1605619E-LeaderElection143] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - om1@group-C5BA1605619E-LeaderElection143 ELECTION round 0: result PASSED (term=1)
2022-06-25 01:08:36,444 [om1@group-C5BA1605619E-LeaderElection143] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - om1: shutdown om1@group-C5BA1605619E-LeaderElection143
2022-06-25 01:08:36,444 [om1@group-C5BA1605619E-LeaderElection143] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-06-25 01:08:36,444 [om1@group-C5BA1605619E-LeaderElection143] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 2617ms
2022-06-25 01:08:36,444 [om1@group-C5BA1605619E-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-25 01:08:36,445 [om1@group-C5BA1605619E-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2022-06-25 01:08:36,445 [om1@group-C5BA1605619E-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2022-06-25 01:08:36,445 [om1@group-C5BA1605619E-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 10s (default)
2022-06-25 01:08:36,445 [om1@group-C5BA1605619E-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-25 01:08:36,445 [om1@group-C5BA1605619E-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-25 01:08:36,445 [om1@group-C5BA1605619E-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2022-06-25 01:08:36,446 [om1@group-C5BA1605619E-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-25 01:08:36,446 [om1@group-C5BA1605619E-LeaderElection143] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderStateImpl
2022-06-25 01:08:36,446 [om1@group-C5BA1605619E-LeaderElection143] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:08:36,464 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
2022-06-25 01:08:36,506 [Listener at 127.0.0.1/35133] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(82)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2022-06-25 01:08:36,524 [om1@group-C5BA1605619E-LeaderElection143] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - om1@group-C5BA1605619E: set configuration 0: [om1|rpc:localhost:41635|admin:|client:|dataStream:|priority:0], old=null
2022-06-25 01:08:36,529 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:notifyConfigurationChanged(192)) - Received Configuration change notification from Ratis. New Peer list:
[id: "om1"
address: "localhost:41635"
]
2022-06-25 01:08:36,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:36,782 [Listener at 127.0.0.1/35133] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 274 ms to scan 7 urls, producing 131 keys and 316 values 
2022-06-25 01:08:36,791 [Listener at 127.0.0.1/35133] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(237)) - Datanode State Machine Task Thread Pool size 2
2022-06-25 01:08:36,795 [Listener at 127.0.0.1/35133] INFO  volume.HddsVolume (HddsVolume.java:<init>(116)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-06-25 01:08:36,795 [Listener at 127.0.0.1/35133] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data-0/containers/hdds to VolumeSet
2022-06-25 01:08:36,795 [Listener at 127.0.0.1/35133] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data-0/containers/hdds
2022-06-25 01:08:36,795 [Listener at 127.0.0.1/35133] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data-0/containers/hdds
2022-06-25 01:08:36,810 [Listener at 127.0.0.1/35133] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data/ratis to VolumeSet
2022-06-25 01:08:36,812 [Listener at 127.0.0.1/35133] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data/ratis
2022-06-25 01:08:36,812 [Listener at 127.0.0.1/35133] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data/ratis
2022-06-25 01:08:36,915 [Thread-5582] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data-0/containers/hdds
2022-06-25 01:08:36,915 [Listener at 127.0.0.1/35133] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(266)) - Build ContainerSet costs 0s
2022-06-25 01:08:36,918 [Listener at 127.0.0.1/35133] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-06-25 01:08:36,918 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-06-25 01:08:36,919 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-06-25 01:08:36,919 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-06-25 01:08:36,919 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-06-25 01:08:36,919 [Listener at 127.0.0.1/35133] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-06-25 01:08:36,919 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:08:36,919 [Listener at 127.0.0.1/35133] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-06-25 01:08:36,919 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:08:36,919 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-06-25 01:08:36,919 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-06-25 01:08:36,920 [Listener at 127.0.0.1/35133] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-06-25 01:08:36,920 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-06-25 01:08:36,920 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-06-25 01:08:36,921 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:08:36,921 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:08:36,921 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data/ratis] (custom)
2022-06-25 01:08:36,922 [Listener at 127.0.0.1/35133] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-06-25 01:08:37,010 [Listener at 127.0.0.1/35133] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-06-25 01:08:37,010 [Listener at 127.0.0.1/35133] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-06-25 01:08:37,013 [Listener at 127.0.0.1/35133] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-06-25 01:08:37,013 [Listener at 127.0.0.1/35133] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-06-25 01:08:37,014 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1029)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-06-25 01:08:37,014 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1005)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-06-25 01:08:37,014 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-06-25 01:08:37,014 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-06-25 01:08:37,015 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1248)) - Jetty bound to port 39923
2022-06-25 01:08:37,015 [Listener at 127.0.0.1/35133] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-06-25 01:08:37,049 [Listener at 127.0.0.1/35133] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-06-25 01:08:37,049 [Listener at 127.0.0.1/35133] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-06-25 01:08:37,049 [Listener at 127.0.0.1/35133] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2022-06-25 01:08:37,058 [Listener at 127.0.0.1/35133] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@69d956ec{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-06-25 01:08:37,058 [Listener at 127.0.0.1/35133] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@5f16a448{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-06-25 01:08:37,472 [Listener at 127.0.0.1/35133] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@19ac7358{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-39923-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-5562058992666572192/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-25 01:08:37,497 [Listener at 127.0.0.1/35133] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@18e05852{HTTP/1.1, (http/1.1)}{0.0.0.0:39923}
2022-06-25 01:08:37,497 [Listener at 127.0.0.1/35133] INFO  server.Server (Server.java:doStart(415)) - Started @351394ms
2022-06-25 01:08:37,497 [Listener at 127.0.0.1/35133] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-06-25 01:08:37,506 [Listener at 127.0.0.1/35133] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:39923
2022-06-25 01:08:37,514 [Listener at 127.0.0.1/35133] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:08:37,514 [Listener at 127.0.0.1/35133] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:08:37,514 [Listener at 127.0.0.1/35133] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-06-25 01:08:37,523 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(492)) - Ozone container server started.
2022-06-25 01:08:37,541 [Listener at 127.0.0.1/35133] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net ip:10.1.0.8
2022-06-25 01:08:37,640 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@450886b4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-06-25 01:08:37,647 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/meta/datanode.id
2022-06-25 01:08:37,689 [Listener at 127.0.0.1/35133] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(82)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2022-06-25 01:08:37,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:37,810 [Listener at 127.0.0.1/35133] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 115 ms to scan 7 urls, producing 131 keys and 316 values 
2022-06-25 01:08:37,811 [Listener at 127.0.0.1/35133] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(237)) - Datanode State Machine Task Thread Pool size 2
2022-06-25 01:08:37,847 [Listener at 127.0.0.1/35133] INFO  volume.HddsVolume (HddsVolume.java:<init>(116)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-06-25 01:08:37,847 [Listener at 127.0.0.1/35133] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data-0/containers/hdds to VolumeSet
2022-06-25 01:08:37,847 [Listener at 127.0.0.1/35133] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data-0/containers/hdds
2022-06-25 01:08:37,874 [Listener at 127.0.0.1/35133] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data-0/containers/hdds
2022-06-25 01:08:37,885 [Listener at 127.0.0.1/35133] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data/ratis to VolumeSet
2022-06-25 01:08:37,886 [Listener at 127.0.0.1/35133] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data/ratis
2022-06-25 01:08:37,886 [Listener at 127.0.0.1/35133] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data/ratis
2022-06-25 01:08:37,901 [Thread-5595] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data-0/containers/hdds
2022-06-25 01:08:37,901 [Listener at 127.0.0.1/35133] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(266)) - Build ContainerSet costs 0s
2022-06-25 01:08:37,914 [Listener at 127.0.0.1/35133] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-06-25 01:08:37,914 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-06-25 01:08:37,914 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-06-25 01:08:37,914 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-06-25 01:08:37,915 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-06-25 01:08:37,915 [Listener at 127.0.0.1/35133] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-06-25 01:08:37,915 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:08:37,915 [Listener at 127.0.0.1/35133] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-06-25 01:08:37,915 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:08:37,915 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-06-25 01:08:37,915 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-06-25 01:08:37,916 [Listener at 127.0.0.1/35133] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-06-25 01:08:37,916 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-06-25 01:08:37,916 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-06-25 01:08:37,917 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:08:37,917 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:08:37,917 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data/ratis] (custom)
2022-06-25 01:08:37,929 [Listener at 127.0.0.1/35133] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-06-25 01:08:37,947 [Listener at 127.0.0.1/35133] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-06-25 01:08:37,947 [Listener at 127.0.0.1/35133] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-06-25 01:08:37,948 [Listener at 127.0.0.1/35133] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-06-25 01:08:37,951 [Listener at 127.0.0.1/35133] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-06-25 01:08:37,952 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1029)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-06-25 01:08:37,952 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1005)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-06-25 01:08:37,952 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-06-25 01:08:37,952 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-06-25 01:08:37,952 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1248)) - Jetty bound to port 38317
2022-06-25 01:08:37,953 [Listener at 127.0.0.1/35133] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-06-25 01:08:37,987 [Listener at 127.0.0.1/35133] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-06-25 01:08:37,987 [Listener at 127.0.0.1/35133] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-06-25 01:08:37,988 [Listener at 127.0.0.1/35133] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2022-06-25 01:08:37,991 [Listener at 127.0.0.1/35133] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@3df34d10{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-06-25 01:08:37,992 [Listener at 127.0.0.1/35133] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@4fd3e0e9{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-06-25 01:08:38,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:38,741 [Listener at 127.0.0.1/35133] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@11725f6b{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-38317-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-720009584994489196/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-25 01:08:38,751 [Listener at 127.0.0.1/35133] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@2622fda1{HTTP/1.1, (http/1.1)}{0.0.0.0:38317}
2022-06-25 01:08:38,751 [Listener at 127.0.0.1/35133] INFO  server.Server (Server.java:doStart(415)) - Started @352648ms
2022-06-25 01:08:38,751 [Listener at 127.0.0.1/35133] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-06-25 01:08:38,752 [Listener at 127.0.0.1/35133] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:38317
2022-06-25 01:08:38,753 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(309)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data-0/containers/hdds/84da1e05-86d5-4b42-9168-65f6ed46dc76/DS-96a682fe-0d56-46bf-bfe8-846315532790/container.db for volume DS-96a682fe-0d56-46bf-bfe8-846315532790
2022-06-25 01:08:38,753 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(340)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data-0/containers/hdds/84da1e05-86d5-4b42-9168-65f6ed46dc76/DS-96a682fe-0d56-46bf-bfe8-846315532790/container.db for volume DS-96a682fe-0d56-46bf-bfe8-846315532790
2022-06-25 01:08:38,753 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(344)) - Attempting to start container services.
2022-06-25 01:08:38,754 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(279)) - Background container scanner has been disabled.
2022-06-25 01:08:38,754 [Listener at 127.0.0.1/35133] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:08:38,754 [Listener at 127.0.0.1/35133] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:08:38,754 [Listener at 127.0.0.1/35133] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-06-25 01:08:38,778 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 41637
2022-06-25 01:08:38,854 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis be67eb5e-e62d-4374-a142-8db592db20d7
2022-06-25 01:08:38,866 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - be67eb5e-e62d-4374-a142-8db592db20d7: start RPC server
2022-06-25 01:08:38,867 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(492)) - Ozone container server started.
2022-06-25 01:08:38,867 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - be67eb5e-e62d-4374-a142-8db592db20d7: GrpcService started, listening on 39697
2022-06-25 01:08:38,874 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@419993f7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-06-25 01:08:38,895 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/meta/datanode.id
2022-06-25 01:08:38,945 [Listener at 127.0.0.1/35133] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net ip:10.1.0.8
2022-06-25 01:08:38,946 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis be67eb5e-e62d-4374-a142-8db592db20d7 is started using port 39697 for RATIS
2022-06-25 01:08:38,947 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis be67eb5e-e62d-4374-a142-8db592db20d7 is started using port 39697 for RATIS_ADMIN
2022-06-25 01:08:38,947 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis be67eb5e-e62d-4374-a142-8db592db20d7 is started using port 39697 for RATIS_SERVER
2022-06-25 01:08:38,947 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@539049cd] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-be67eb5e-e62d-4374-a142-8db592db20d7: Started
2022-06-25 01:08:38,949 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc be67eb5e-e62d-4374-a142-8db592db20d7 is started using port 37213
2022-06-25 01:08:39,074 [Listener at 127.0.0.1/35133] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(82)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2022-06-25 01:08:39,174 [Listener at 127.0.0.1/35133] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 91 ms to scan 7 urls, producing 131 keys and 316 values 
2022-06-25 01:08:39,175 [Listener at 127.0.0.1/35133] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(237)) - Datanode State Machine Task Thread Pool size 2
2022-06-25 01:08:39,176 [Listener at 127.0.0.1/35133] INFO  volume.HddsVolume (HddsVolume.java:<init>(116)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-06-25 01:08:39,176 [Listener at 127.0.0.1/35133] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/data-0/containers/hdds to VolumeSet
2022-06-25 01:08:39,176 [Listener at 127.0.0.1/35133] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/data-0/containers/hdds
2022-06-25 01:08:39,177 [Listener at 127.0.0.1/35133] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/data-0/containers/hdds
2022-06-25 01:08:39,215 [Listener at 127.0.0.1/35133] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/data/ratis to VolumeSet
2022-06-25 01:08:39,215 [Listener at 127.0.0.1/35133] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/data/ratis
2022-06-25 01:08:39,215 [Listener at 127.0.0.1/35133] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/data/ratis
2022-06-25 01:08:39,242 [Thread-5612] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/data-0/containers/hdds
2022-06-25 01:08:39,242 [Listener at 127.0.0.1/35133] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(266)) - Build ContainerSet costs 0s
2022-06-25 01:08:39,243 [Listener at 127.0.0.1/35133] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-06-25 01:08:39,243 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-06-25 01:08:39,243 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-06-25 01:08:39,243 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-06-25 01:08:39,243 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-06-25 01:08:39,244 [Listener at 127.0.0.1/35133] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-06-25 01:08:39,244 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:08:39,244 [Listener at 127.0.0.1/35133] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-06-25 01:08:39,244 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:08:39,244 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-06-25 01:08:39,244 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-06-25 01:08:39,245 [Listener at 127.0.0.1/35133] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-06-25 01:08:39,245 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-06-25 01:08:39,245 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-06-25 01:08:39,245 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:08:39,245 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:08:39,245 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/data/ratis] (custom)
2022-06-25 01:08:39,263 [Listener at 127.0.0.1/35133] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-06-25 01:08:39,286 [Listener at 127.0.0.1/35133] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-06-25 01:08:39,286 [Listener at 127.0.0.1/35133] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-06-25 01:08:39,288 [Listener at 127.0.0.1/35133] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-06-25 01:08:39,310 [Listener at 127.0.0.1/35133] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-06-25 01:08:39,311 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1029)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-06-25 01:08:39,312 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1005)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-06-25 01:08:39,312 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-06-25 01:08:39,312 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-06-25 01:08:39,319 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1248)) - Jetty bound to port 41325
2022-06-25 01:08:39,319 [Listener at 127.0.0.1/35133] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-06-25 01:08:39,343 [Listener at 127.0.0.1/35133] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-06-25 01:08:39,343 [Listener at 127.0.0.1/35133] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-06-25 01:08:39,343 [Listener at 127.0.0.1/35133] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2022-06-25 01:08:39,352 [Listener at 127.0.0.1/35133] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@303ff6b7{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-06-25 01:08:39,352 [Listener at 127.0.0.1/35133] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@2644ff79{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-06-25 01:08:39,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:39,938 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(309)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data-0/containers/hdds/84da1e05-86d5-4b42-9168-65f6ed46dc76/DS-b0ea6763-be5e-4b98-965e-a90976b40e26/container.db for volume DS-b0ea6763-be5e-4b98-965e-a90976b40e26
2022-06-25 01:08:39,939 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(340)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data-0/containers/hdds/84da1e05-86d5-4b42-9168-65f6ed46dc76/DS-b0ea6763-be5e-4b98-965e-a90976b40e26/container.db for volume DS-b0ea6763-be5e-4b98-965e-a90976b40e26
2022-06-25 01:08:39,939 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(344)) - Attempting to start container services.
2022-06-25 01:08:39,939 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(279)) - Background container scanner has been disabled.
2022-06-25 01:08:39,942 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 43059
2022-06-25 01:08:40,009 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf
2022-06-25 01:08:40,020 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: start RPC server
2022-06-25 01:08:40,020 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: GrpcService started, listening on 39033
2022-06-25 01:08:40,026 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf is started using port 39033 for RATIS
2022-06-25 01:08:40,026 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf is started using port 39033 for RATIS_ADMIN
2022-06-25 01:08:40,026 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf is started using port 39033 for RATIS_SERVER
2022-06-25 01:08:40,027 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@3a3a1bd4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: Started
2022-06-25 01:08:40,056 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf is started using port 36009
2022-06-25 01:08:40,378 [Listener at 127.0.0.1/35133] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@612b3831{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-41325-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-1988611427955377867/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-25 01:08:40,525 [Listener at 127.0.0.1/35133] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@7c6f01e2{HTTP/1.1, (http/1.1)}{0.0.0.0:41325}
2022-06-25 01:08:40,525 [Listener at 127.0.0.1/35133] INFO  server.Server (Server.java:doStart(415)) - Started @354422ms
2022-06-25 01:08:40,525 [Listener at 127.0.0.1/35133] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-06-25 01:08:40,526 [Listener at 127.0.0.1/35133] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:41325
2022-06-25 01:08:40,527 [IPC Server handler 1 on default port 36557] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/be67eb5e-e62d-4374-a142-8db592db20d7
2022-06-25 01:08:40,527 [IPC Server handler 1 on default port 36557] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:08:40,542 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - ContainerSafeModeRule rule is successfully validated
2022-06-25 01:08:40,543 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2022-06-25 01:08:40,597 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(492)) - Ozone container server started.
2022-06-25 01:08:40,597 [Listener at 127.0.0.1/35133] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:08:40,597 [Listener at 127.0.0.1/35133] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:08:40,597 [Listener at 127.0.0.1/35133] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-06-25 01:08:40,636 [Listener at 127.0.0.1/35133] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net ip:10.1.0.8
2022-06-25 01:08:40,663 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@28193874] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-06-25 01:08:40,666 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(275)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-06-25 01:08:40,666 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - AtleastOneDatanodeReportedRule rule is successfully validated
2022-06-25 01:08:40,666 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=be334d2b-9e4d-429c-8f2f-5f6f11ee7da8 to datanode:be67eb5e-e62d-4374-a142-8db592db20d7
2022-06-25 01:08:40,667 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: be334d2b-9e4d-429c-8f2f-5f6f11ee7da8, Nodes: be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-25T01:08:40.666Z[Etc/UTC]].
2022-06-25 01:08:40,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:40,731 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/meta/datanode.id
2022-06-25 01:08:40,770 [Listener at 127.0.0.1/35133] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(82)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2022-06-25 01:08:40,871 [Listener at 127.0.0.1/35133] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 98 ms to scan 7 urls, producing 131 keys and 316 values 
2022-06-25 01:08:40,872 [Listener at 127.0.0.1/35133] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(237)) - Datanode State Machine Task Thread Pool size 2
2022-06-25 01:08:40,874 [Listener at 127.0.0.1/35133] INFO  volume.HddsVolume (HddsVolume.java:<init>(116)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-06-25 01:08:40,874 [Listener at 127.0.0.1/35133] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data-0/containers/hdds to VolumeSet
2022-06-25 01:08:40,874 [Listener at 127.0.0.1/35133] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data-0/containers/hdds
2022-06-25 01:08:40,879 [Listener at 127.0.0.1/35133] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data-0/containers/hdds
2022-06-25 01:08:40,897 [Listener at 127.0.0.1/35133] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data/ratis to VolumeSet
2022-06-25 01:08:40,897 [Listener at 127.0.0.1/35133] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data/ratis
2022-06-25 01:08:40,897 [Listener at 127.0.0.1/35133] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data/ratis
2022-06-25 01:08:40,941 [Thread-5634] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data-0/containers/hdds
2022-06-25 01:08:40,941 [Listener at 127.0.0.1/35133] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(266)) - Build ContainerSet costs 0s
2022-06-25 01:08:40,944 [Listener at 127.0.0.1/35133] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-06-25 01:08:40,944 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-06-25 01:08:40,944 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-06-25 01:08:40,944 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-06-25 01:08:40,944 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-06-25 01:08:40,944 [Listener at 127.0.0.1/35133] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-06-25 01:08:40,944 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:08:40,944 [Listener at 127.0.0.1/35133] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-06-25 01:08:40,944 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:08:40,944 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-06-25 01:08:40,944 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-06-25 01:08:40,952 [Listener at 127.0.0.1/35133] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-06-25 01:08:40,952 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-06-25 01:08:40,952 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-06-25 01:08:40,952 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:08:40,952 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:08:40,952 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data/ratis] (custom)
2022-06-25 01:08:40,986 [Listener at 127.0.0.1/35133] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-06-25 01:08:40,990 [Listener at 127.0.0.1/35133] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-06-25 01:08:40,990 [Listener at 127.0.0.1/35133] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-06-25 01:08:40,991 [Listener at 127.0.0.1/35133] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-06-25 01:08:41,010 [Listener at 127.0.0.1/35133] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-06-25 01:08:41,011 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1029)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-06-25 01:08:41,011 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1005)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-06-25 01:08:41,011 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-06-25 01:08:41,011 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-06-25 01:08:41,012 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1248)) - Jetty bound to port 41321
2022-06-25 01:08:41,012 [Listener at 127.0.0.1/35133] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-06-25 01:08:41,016 [Listener at 127.0.0.1/35133] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-06-25 01:08:41,016 [Listener at 127.0.0.1/35133] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-06-25 01:08:41,016 [Listener at 127.0.0.1/35133] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-06-25 01:08:41,016 [Listener at 127.0.0.1/35133] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@4996659d{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-06-25 01:08:41,017 [Listener at 127.0.0.1/35133] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@73b20ca2{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-06-25 01:08:41,056 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(309)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data-0/containers/hdds/84da1e05-86d5-4b42-9168-65f6ed46dc76/DS-7c902f6d-a3f2-469e-afcc-9f2432a62d92/container.db for volume DS-7c902f6d-a3f2-469e-afcc-9f2432a62d92
2022-06-25 01:08:41,057 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(340)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data-0/containers/hdds/84da1e05-86d5-4b42-9168-65f6ed46dc76/DS-7c902f6d-a3f2-469e-afcc-9f2432a62d92/container.db for volume DS-7c902f6d-a3f2-469e-afcc-9f2432a62d92
2022-06-25 01:08:41,057 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(344)) - Attempting to start container services.
2022-06-25 01:08:41,057 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(279)) - Background container scanner has been disabled.
2022-06-25 01:08:41,068 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 42673
2022-06-25 01:08:41,070 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis 3c6128f4-7bf2-4a55-83fb-21add5186158
2022-06-25 01:08:41,078 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: start RPC server
2022-06-25 01:08:41,079 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: GrpcService started, listening on 46801
2022-06-25 01:08:41,086 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 3c6128f4-7bf2-4a55-83fb-21add5186158 is started using port 46801 for RATIS
2022-06-25 01:08:41,087 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 3c6128f4-7bf2-4a55-83fb-21add5186158 is started using port 46801 for RATIS_ADMIN
2022-06-25 01:08:41,087 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 3c6128f4-7bf2-4a55-83fb-21add5186158 is started using port 46801 for RATIS_SERVER
2022-06-25 01:08:41,087 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@4240468b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-3c6128f4-7bf2-4a55-83fb-21add5186158: Started
2022-06-25 01:08:41,088 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 3c6128f4-7bf2-4a55-83fb-21add5186158 is started using port 39955
2022-06-25 01:08:41,546 [Listener at 127.0.0.1/35133] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@d6a6be7{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-41321-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-2388225877149488190/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-25 01:08:41,615 [Listener at 127.0.0.1/35133] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@e43c54{HTTP/1.1, (http/1.1)}{0.0.0.0:41321}
2022-06-25 01:08:41,615 [Listener at 127.0.0.1/35133] INFO  server.Server (Server.java:doStart(415)) - Started @355512ms
2022-06-25 01:08:41,615 [Listener at 127.0.0.1/35133] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-06-25 01:08:41,616 [Listener at 127.0.0.1/35133] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:41321
2022-06-25 01:08:41,627 [Listener at 127.0.0.1/35133] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:08:41,627 [Listener at 127.0.0.1/35133] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:08:41,627 [Listener at 127.0.0.1/35133] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-06-25 01:08:41,634 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(492)) - Ozone container server started.
2022-06-25 01:08:41,658 [Listener at 127.0.0.1/35133] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net ip:10.1.0.8
2022-06-25 01:08:41,693 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@56ee6e8d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-06-25 01:08:41,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:41,731 [IPC Server handler 2 on default port 36557] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf
2022-06-25 01:08:41,731 [IPC Server handler 2 on default port 36557] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:08:41,731 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(275)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-06-25 01:08:41,742 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2022-06-25 01:08:41,764 [Listener at 127.0.0.1/35133] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(82)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2022-06-25 01:08:41,820 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/meta/datanode.id
2022-06-25 01:08:41,898 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=ecaf046a-409f-4687-9322-92e04f1b2936 to datanode:09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf
2022-06-25 01:08:41,899 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: ecaf046a-409f-4687-9322-92e04f1b2936, Nodes: 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-25T01:08:41.898Z[Etc/UTC]].
2022-06-25 01:08:42,315 [Listener at 127.0.0.1/35133] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 550 ms to scan 7 urls, producing 131 keys and 316 values 
2022-06-25 01:08:42,316 [Listener at 127.0.0.1/35133] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(237)) - Datanode State Machine Task Thread Pool size 2
2022-06-25 01:08:42,357 [Listener at 127.0.0.1/35133] INFO  volume.HddsVolume (HddsVolume.java:<init>(116)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-06-25 01:08:42,357 [Listener at 127.0.0.1/35133] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data-0/containers/hdds to VolumeSet
2022-06-25 01:08:42,357 [Listener at 127.0.0.1/35133] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data-0/containers/hdds
2022-06-25 01:08:42,387 [Listener at 127.0.0.1/35133] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data-0/containers/hdds
2022-06-25 01:08:42,527 [Listener at 127.0.0.1/35133] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data/ratis to VolumeSet
2022-06-25 01:08:42,527 [Listener at 127.0.0.1/35133] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data/ratis
2022-06-25 01:08:42,527 [Listener at 127.0.0.1/35133] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data/ratis
2022-06-25 01:08:42,643 [Thread-5652] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data-0/containers/hdds
2022-06-25 01:08:42,643 [Listener at 127.0.0.1/35133] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(266)) - Build ContainerSet costs 0s
2022-06-25 01:08:42,645 [Listener at 127.0.0.1/35133] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-06-25 01:08:42,645 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-06-25 01:08:42,645 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-06-25 01:08:42,645 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-06-25 01:08:42,645 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-06-25 01:08:42,645 [Listener at 127.0.0.1/35133] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-06-25 01:08:42,645 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:08:42,645 [Listener at 127.0.0.1/35133] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-06-25 01:08:42,645 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:08:42,645 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-06-25 01:08:42,646 [Listener at 127.0.0.1/35133] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-06-25 01:08:42,651 [Listener at 127.0.0.1/35133] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-06-25 01:08:42,651 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-06-25 01:08:42,652 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-06-25 01:08:42,652 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:08:42,652 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:08:42,652 [Listener at 127.0.0.1/35133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data/ratis] (custom)
2022-06-25 01:08:42,683 [Listener at 127.0.0.1/35133] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-06-25 01:08:42,693 [Listener at 127.0.0.1/35133] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-06-25 01:08:42,693 [Listener at 127.0.0.1/35133] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-06-25 01:08:42,694 [Listener at 127.0.0.1/35133] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-06-25 01:08:42,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:42,794 [Listener at 127.0.0.1/35133] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-06-25 01:08:42,867 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(309)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/data-0/containers/hdds/84da1e05-86d5-4b42-9168-65f6ed46dc76/DS-31cfe8b2-de6d-4c69-b4fe-2267d22bbec4/container.db for volume DS-31cfe8b2-de6d-4c69-b4fe-2267d22bbec4
2022-06-25 01:08:42,867 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(340)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/data-0/containers/hdds/84da1e05-86d5-4b42-9168-65f6ed46dc76/DS-31cfe8b2-de6d-4c69-b4fe-2267d22bbec4/container.db for volume DS-31cfe8b2-de6d-4c69-b4fe-2267d22bbec4
2022-06-25 01:08:42,867 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(344)) - Attempting to start container services.
2022-06-25 01:08:42,867 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(279)) - Background container scanner has been disabled.
2022-06-25 01:08:42,871 [IPC Server handler 3 on default port 36557] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/3c6128f4-7bf2-4a55-83fb-21add5186158
2022-06-25 01:08:42,871 [IPC Server handler 3 on default port 36557] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:08:42,872 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(275)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-06-25 01:08:42,876 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 40691
2022-06-25 01:08:42,876 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2022-06-25 01:08:42,884 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - DataNodeSafeModeRule rule is successfully validated
2022-06-25 01:08:42,884 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(233)) - All SCM safe mode pre check rules have passed
2022-06-25 01:08:42,884 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2022-06-25 01:08:42,884 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2022-06-25 01:08:42,884 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(275)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-06-25 01:08:42,884 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis fc692a40-1ae9-40b7-8d63-7e46f51df1ef
2022-06-25 01:08:42,884 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=5525c833-6a53-417b-b57e-c2534272b3f4 to datanode:3c6128f4-7bf2-4a55-83fb-21add5186158
2022-06-25 01:08:42,890 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 5525c833-6a53-417b-b57e-c2534272b3f4, Nodes: 3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-25T01:08:42.884Z[Etc/UTC]].
2022-06-25 01:08:42,891 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=68648fa3-5dbc-4304-8297-eabd1be7e846 to datanode:be67eb5e-e62d-4374-a142-8db592db20d7
2022-06-25 01:08:42,891 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=68648fa3-5dbc-4304-8297-eabd1be7e846 to datanode:3c6128f4-7bf2-4a55-83fb-21add5186158
2022-06-25 01:08:42,891 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=68648fa3-5dbc-4304-8297-eabd1be7e846 to datanode:09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf
2022-06-25 01:08:42,891 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 68648fa3-5dbc-4304-8297-eabd1be7e846, Nodes: be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-25T01:08:42.891Z[Etc/UTC]].
2022-06-25 01:08:42,942 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1029)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-06-25 01:08:42,943 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1005)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-06-25 01:08:42,943 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-06-25 01:08:42,943 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-06-25 01:08:42,944 [Listener at 127.0.0.1/35133] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1248)) - Jetty bound to port 41227
2022-06-25 01:08:42,944 [Listener at 127.0.0.1/35133] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-06-25 01:08:42,972 [Listener at 127.0.0.1/35133] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-06-25 01:08:42,972 [Listener at 127.0.0.1/35133] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-06-25 01:08:42,972 [Listener at 127.0.0.1/35133] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-06-25 01:08:42,973 [Listener at 127.0.0.1/35133] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@6f836b3a{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-06-25 01:08:42,973 [Listener at 127.0.0.1/35133] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@50a196c4{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-06-25 01:08:42,998 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: start RPC server
2022-06-25 01:08:43,006 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: GrpcService started, listening on 39343
2022-06-25 01:08:43,008 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis fc692a40-1ae9-40b7-8d63-7e46f51df1ef is started using port 39343 for RATIS
2022-06-25 01:08:43,008 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis fc692a40-1ae9-40b7-8d63-7e46f51df1ef is started using port 39343 for RATIS_ADMIN
2022-06-25 01:08:43,008 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis fc692a40-1ae9-40b7-8d63-7e46f51df1ef is started using port 39343 for RATIS_SERVER
2022-06-25 01:08:43,008 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@58e06509] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-fc692a40-1ae9-40b7-8d63-7e46f51df1ef: Started
2022-06-25 01:08:43,010 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc fc692a40-1ae9-40b7-8d63-7e46f51df1ef is started using port 32859
2022-06-25 01:08:43,374 [Listener at 127.0.0.1/35133] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@225aebe9{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-41227-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-2839759996012719920/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-25 01:08:43,388 [Listener at 127.0.0.1/35133] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@3f73a3d2{HTTP/1.1, (http/1.1)}{0.0.0.0:41227}
2022-06-25 01:08:43,388 [Listener at 127.0.0.1/35133] INFO  server.Server (Server.java:doStart(415)) - Started @357285ms
2022-06-25 01:08:43,391 [Listener at 127.0.0.1/35133] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-06-25 01:08:43,392 [Listener at 127.0.0.1/35133] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:41227
2022-06-25 01:08:43,393 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Waiting for nodes to be ready. Got 3 of 6 DN Heartbeats.
2022-06-25 01:08:43,393 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Waiting for cluster to exit safe mode
2022-06-25 01:08:43,393 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:08:43,405 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(492)) - Ozone container server started.
2022-06-25 01:08:43,434 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - be67eb5e-e62d-4374-a142-8db592db20d7: addNew group-5F6F11EE7DA8:[be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:1] returns group-5F6F11EE7DA8:java.util.concurrent.CompletableFuture@4ee3bfb0[Not completed]
2022-06-25 01:08:43,471 [pool-4099-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - be67eb5e-e62d-4374-a142-8db592db20d7: new RaftServerImpl for group-5F6F11EE7DA8:[be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:1] with ContainerStateMachine:uninitialized
2022-06-25 01:08:43,471 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:08:43,471 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:08:43,471 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:08:43,471 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:08:43,471 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:08:43,471 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:08:43,471 [pool-4099-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8: ConfigurationManager, init=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:1], old=null, confs=<EMPTY_MAP>
2022-06-25 01:08:43,471 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis] (custom)
2022-06-25 01:08:43,472 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:08:43,472 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:08:43,472 [pool-4099-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis/be334d2b-9e4d-429c-8f2f-5f6f11ee7da8 does not exist. Creating ...
2022-06-25 01:08:43,491 [pool-4099-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis/be334d2b-9e4d-429c-8f2f-5f6f11ee7da8/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:08:43,498 [pool-4099-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis/be334d2b-9e4d-429c-8f2f-5f6f11ee7da8 has been successfully formatted.
2022-06-25 01:08:43,540 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@27a84be8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-06-25 01:08:43,546 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/meta/datanode.id
2022-06-25 01:08:43,564 [pool-4099-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-5F6F11EE7DA8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:08:43,564 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:08:43,564 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:08:43,564 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:08:43,564 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:08:43,564 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:08:43,565 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:08:43,622 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:08:43,622 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:08:43,622 [pool-4099-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis/be334d2b-9e4d-429c-8f2f-5f6f11ee7da8
2022-06-25 01:08:43,622 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:08:43,622 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:08:43,622 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:08:43,622 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:08:43,622 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:08:43,622 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:08:43,622 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:08:43,622 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:08:43,625 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:08:43,626 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:08:43,626 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:08:43,639 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(358)) - Pipeline Pipeline[ Id: be334d2b-9e4d-429c-8f2f-5f6f11ee7da8, Nodes: be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:be67eb5e-e62d-4374-a142-8db592db20d7, CreationTimestamp2022-06-25T01:08:40.666Z[Etc/UTC]] moved to OPEN state
2022-06-25 01:08:43,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:43,782 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:43,783 [pool-4099-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:08:43,783 [pool-4099-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:08:43,786 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:08:43,786 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:08:43,786 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:08:43,786 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:08:43,786 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:08:43,786 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:08:43,795 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:08:43,795 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:08:43,795 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:08:43,795 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:08:43,795 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:08:43,795 [pool-4099-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8: start as a follower, conf=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:1], old=null
2022-06-25 01:08:43,795 [pool-4099-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:08:43,795 [pool-4099-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - be67eb5e-e62d-4374-a142-8db592db20d7: start be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-FollowerState
2022-06-25 01:08:43,796 [pool-4099-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5F6F11EE7DA8,id=be67eb5e-e62d-4374-a142-8db592db20d7
2022-06-25 01:08:43,797 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=be334d2b-9e4d-429c-8f2f-5f6f11ee7da8
2022-06-25 01:08:43,797 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=be334d2b-9e4d-429c-8f2f-5f6f11ee7da8.
2022-06-25 01:08:43,798 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - be67eb5e-e62d-4374-a142-8db592db20d7: addNew group-EABD1BE7E846:[be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|priority:0] returns group-EABD1BE7E846:java.util.concurrent.CompletableFuture@4adc32b4[Not completed]
2022-06-25 01:08:43,798 [pool-4099-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - be67eb5e-e62d-4374-a142-8db592db20d7: new RaftServerImpl for group-EABD1BE7E846:[be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|priority:0] with ContainerStateMachine:uninitialized
2022-06-25 01:08:43,800 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:08:43,800 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:08:43,800 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:08:43,800 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:08:43,800 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:08:43,800 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:08:43,800 [pool-4099-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846: ConfigurationManager, init=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|priority:0], old=null, confs=<EMPTY_MAP>
2022-06-25 01:08:43,801 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis] (custom)
2022-06-25 01:08:43,801 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:08:43,801 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:08:43,801 [pool-4099-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis/68648fa3-5dbc-4304-8297-eabd1be7e846 does not exist. Creating ...
2022-06-25 01:08:43,806 [pool-4099-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis/68648fa3-5dbc-4304-8297-eabd1be7e846/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:08:43,862 [pool-4099-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis/68648fa3-5dbc-4304-8297-eabd1be7e846 has been successfully formatted.
2022-06-25 01:08:43,862 [pool-4099-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-EABD1BE7E846: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:08:43,863 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:08:43,863 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:08:43,863 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:08:43,863 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:08:43,863 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:08:43,863 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:08:43,865 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:08:43,865 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:08:43,865 [pool-4099-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis/68648fa3-5dbc-4304-8297-eabd1be7e846
2022-06-25 01:08:43,865 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:08:43,865 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:08:43,865 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:08:43,865 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:08:43,865 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:08:43,865 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:08:43,865 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:08:43,865 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:08:43,868 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:43,886 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:08:43,889 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:08:43,889 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:08:43,889 [pool-4099-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:08:43,889 [pool-4099-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:08:43,901 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:08:43,902 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:08:43,902 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:08:43,902 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:08:43,902 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:08:43,902 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:08:43,942 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:08:43,947 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:08:43,947 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:08:43,947 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:08:43,947 [pool-4099-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:08:43,952 [pool-4099-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846: start as a follower, conf=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|priority:0], old=null
2022-06-25 01:08:43,952 [pool-4099-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:08:43,953 [pool-4099-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - be67eb5e-e62d-4374-a142-8db592db20d7: start be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-FollowerState
2022-06-25 01:08:43,953 [pool-4099-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-EABD1BE7E846,id=be67eb5e-e62d-4374-a142-8db592db20d7
2022-06-25 01:08:43,955 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(309)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data-0/containers/hdds/84da1e05-86d5-4b42-9168-65f6ed46dc76/DS-6e3b6d4a-dced-44ef-8116-6944fe63bf46/container.db for volume DS-6e3b6d4a-dced-44ef-8116-6944fe63bf46
2022-06-25 01:08:43,955 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(340)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data-0/containers/hdds/84da1e05-86d5-4b42-9168-65f6ed46dc76/DS-6e3b6d4a-dced-44ef-8116-6944fe63bf46/container.db for volume DS-6e3b6d4a-dced-44ef-8116-6944fe63bf46
2022-06-25 01:08:43,955 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(344)) - Attempting to start container services.
2022-06-25 01:08:43,955 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(279)) - Background container scanner has been disabled.
2022-06-25 01:08:43,966 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 37711
2022-06-25 01:08:43,966 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=68648fa3-5dbc-4304-8297-eabd1be7e846
2022-06-25 01:08:44,050 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis 97d08340-a146-41c4-a759-b3b136c7fb6d
2022-06-25 01:08:44,059 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: start RPC server
2022-06-25 01:08:44,059 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: GrpcService started, listening on 43169
2022-06-25 01:08:44,066 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 97d08340-a146-41c4-a759-b3b136c7fb6d is started using port 43169 for RATIS
2022-06-25 01:08:44,066 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 97d08340-a146-41c4-a759-b3b136c7fb6d is started using port 43169 for RATIS_ADMIN
2022-06-25 01:08:44,066 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 97d08340-a146-41c4-a759-b3b136c7fb6d is started using port 43169 for RATIS_SERVER
2022-06-25 01:08:44,066 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@3534c0d2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-97d08340-a146-41c4-a759-b3b136c7fb6d: Started
2022-06-25 01:08:44,087 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 97d08340-a146-41c4-a759-b3b136c7fb6d is started using port 44433
2022-06-25 01:08:44,110 [grpc-default-executor-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: addNew group-EABD1BE7E846:[be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:0] returns group-EABD1BE7E846:java.util.concurrent.CompletableFuture@6c2b69a8[Not completed]
2022-06-25 01:08:44,111 [pool-4145-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: new RaftServerImpl for group-EABD1BE7E846:[be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:0] with ContainerStateMachine:uninitialized
2022-06-25 01:08:44,112 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:08:44,112 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:08:44,112 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:08:44,112 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:08:44,112 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:08:44,112 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:08:44,112 [pool-4145-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846: ConfigurationManager, init=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
2022-06-25 01:08:44,112 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data/ratis] (custom)
2022-06-25 01:08:44,112 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:08:44,112 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:08:44,112 [pool-4145-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data/ratis/68648fa3-5dbc-4304-8297-eabd1be7e846 does not exist. Creating ...
2022-06-25 01:08:44,122 [pool-4145-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data/ratis/68648fa3-5dbc-4304-8297-eabd1be7e846/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:08:44,128 [pool-4145-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data/ratis/68648fa3-5dbc-4304-8297-eabd1be7e846 has been successfully formatted.
2022-06-25 01:08:44,129 [pool-4145-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-EABD1BE7E846: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:08:44,129 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:08:44,129 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:08:44,129 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:08:44,129 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:08:44,129 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:08:44,129 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:08:44,131 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:08:44,131 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:08:44,131 [pool-4145-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data/ratis/68648fa3-5dbc-4304-8297-eabd1be7e846
2022-06-25 01:08:44,131 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:08:44,131 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:08:44,131 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:08:44,131 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:08:44,131 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:08:44,131 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:08:44,132 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:08:44,132 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:08:44,135 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:08:44,136 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:08:44,136 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:08:44,136 [pool-4145-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:08:44,136 [pool-4145-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:08:44,137 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:08:44,137 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:08:44,137 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:08:44,137 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:08:44,137 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:08:44,137 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:08:44,141 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:08:44,141 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:08:44,141 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:08:44,141 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:08:44,141 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:08:44,141 [pool-4145-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846: start as a follower, conf=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:0], old=null
2022-06-25 01:08:44,141 [pool-4145-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:08:44,142 [pool-4145-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: start 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-FollowerState
2022-06-25 01:08:44,230 [pool-4145-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-EABD1BE7E846,id=3c6128f4-7bf2-4a55-83fb-21add5186158
2022-06-25 01:08:44,316 [grpc-default-executor-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: addNew group-EABD1BE7E846:[be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:0] returns group-EABD1BE7E846:java.util.concurrent.CompletableFuture@6530a6d9[Not completed]
2022-06-25 01:08:44,318 [pool-4122-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: new RaftServerImpl for group-EABD1BE7E846:[be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:0] with ContainerStateMachine:uninitialized
2022-06-25 01:08:44,318 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:08:44,319 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:08:44,319 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:08:44,319 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:08:44,319 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:08:44,319 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:08:44,319 [pool-4122-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846: ConfigurationManager, init=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
2022-06-25 01:08:44,319 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data/ratis] (custom)
2022-06-25 01:08:44,319 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:08:44,319 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:08:44,319 [pool-4122-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data/ratis/68648fa3-5dbc-4304-8297-eabd1be7e846 does not exist. Creating ...
2022-06-25 01:08:44,322 [pool-4122-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data/ratis/68648fa3-5dbc-4304-8297-eabd1be7e846/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:08:44,336 [pool-4122-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data/ratis/68648fa3-5dbc-4304-8297-eabd1be7e846 has been successfully formatted.
2022-06-25 01:08:44,337 [pool-4122-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-EABD1BE7E846: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:08:44,337 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:08:44,337 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:08:44,337 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:08:44,337 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:08:44,337 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:08:44,338 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:08:44,339 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:08:44,339 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:08:44,339 [pool-4122-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data/ratis/68648fa3-5dbc-4304-8297-eabd1be7e846
2022-06-25 01:08:44,339 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:08:44,339 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:08:44,339 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:08:44,339 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:08:44,339 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:08:44,340 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:08:44,340 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:08:44,340 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:08:44,351 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:08:44,352 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:08:44,352 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:08:44,352 [pool-4122-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:08:44,352 [pool-4122-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:08:44,353 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:08:44,353 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:08:44,353 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:08:44,353 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:08:44,353 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:08:44,353 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:08:44,357 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:08:44,357 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:08:44,357 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:08:44,357 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:08:44,357 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:08:44,357 [pool-4122-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846: start as a follower, conf=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:0], old=null
2022-06-25 01:08:44,357 [pool-4122-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:08:44,357 [pool-4122-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: start 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-FollowerState
2022-06-25 01:08:44,385 [pool-4122-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-EABD1BE7E846,id=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf
2022-06-25 01:08:44,454 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Waiting for nodes to be ready. Got 3 of 6 DN Heartbeats.
2022-06-25 01:08:44,454 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Waiting for cluster to exit safe mode
2022-06-25 01:08:44,454 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:08:44,460 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=68648fa3-5dbc-4304-8297-eabd1be7e846.
2022-06-25 01:08:44,625 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: addNew group-92E04F1B2936:[09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|priority:1] returns group-92E04F1B2936:java.util.concurrent.CompletableFuture@15147205[Not completed]
2022-06-25 01:08:44,625 [pool-4122-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: new RaftServerImpl for group-92E04F1B2936:[09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|priority:1] with ContainerStateMachine:uninitialized
2022-06-25 01:08:44,626 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:08:44,626 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:08:44,626 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:08:44,626 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:08:44,626 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:08:44,626 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:08:44,626 [pool-4122-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936: ConfigurationManager, init=-1: [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|priority:1], old=null, confs=<EMPTY_MAP>
2022-06-25 01:08:44,626 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data/ratis] (custom)
2022-06-25 01:08:44,626 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:08:44,626 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:08:44,626 [pool-4122-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data/ratis/ecaf046a-409f-4687-9322-92e04f1b2936 does not exist. Creating ...
2022-06-25 01:08:44,631 [pool-4122-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data/ratis/ecaf046a-409f-4687-9322-92e04f1b2936/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:08:44,637 [pool-4122-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data/ratis/ecaf046a-409f-4687-9322-92e04f1b2936 has been successfully formatted.
2022-06-25 01:08:44,638 [pool-4122-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-92E04F1B2936: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:08:44,638 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:08:44,638 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(358)) - Pipeline Pipeline[ Id: ecaf046a-409f-4687-9322-92e04f1b2936, Nodes: 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, CreationTimestamp2022-06-25T01:08:41.898Z[Etc/UTC]] moved to OPEN state
2022-06-25 01:08:44,640 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:44,641 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:08:44,641 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:08:44,641 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:08:44,641 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:08:44,641 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:08:44,642 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:08:44,642 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:08:44,643 [pool-4122-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data/ratis/ecaf046a-409f-4687-9322-92e04f1b2936
2022-06-25 01:08:44,643 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:08:44,643 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:08:44,643 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:08:44,643 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:08:44,643 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:08:44,643 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:08:44,643 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:08:44,643 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:08:44,662 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:08:44,662 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:08:44,662 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:08:44,665 [pool-4122-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:08:44,665 [pool-4122-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:08:44,675 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:08:44,675 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:08:44,676 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:08:44,676 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:08:44,676 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:08:44,676 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:08:44,686 [IPC Server handler 5 on default port 36557] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/fc692a40-1ae9-40b7-8d63-7e46f51df1ef
2022-06-25 01:08:44,687 [IPC Server handler 5 on default port 36557] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : fc692a40-1ae9-40b7-8d63-7e46f51df1ef{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=40691, RATIS=39343, RATIS_ADMIN=39343, RATIS_SERVER=39343, STANDALONE=32859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:08:44,687 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(275)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-06-25 01:08:44,687 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=a58b823e-be03-49ee-a4ae-23927eca553c to datanode:fc692a40-1ae9-40b7-8d63-7e46f51df1ef
2022-06-25 01:08:44,688 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: a58b823e-be03-49ee-a4ae-23927eca553c, Nodes: fc692a40-1ae9-40b7-8d63-7e46f51df1ef{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=40691, RATIS=39343, RATIS_ADMIN=39343, RATIS_SERVER=39343, STANDALONE=32859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-25T01:08:44.687Z[Etc/UTC]].
2022-06-25 01:08:44,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:44,740 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:08:44,740 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:08:44,740 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:08:44,740 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:08:44,741 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:08:44,741 [pool-4122-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936: start as a follower, conf=-1: [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|priority:1], old=null
2022-06-25 01:08:44,741 [pool-4122-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:08:44,741 [pool-4122-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: start 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-FollowerState
2022-06-25 01:08:44,750 [pool-4122-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-92E04F1B2936,id=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf
2022-06-25 01:08:44,770 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=ecaf046a-409f-4687-9322-92e04f1b2936
2022-06-25 01:08:44,770 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=ecaf046a-409f-4687-9322-92e04f1b2936.
2022-06-25 01:08:44,872 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:45,455 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Waiting for nodes to be ready. Got 4 of 6 DN Heartbeats.
2022-06-25 01:08:45,455 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Waiting for cluster to exit safe mode
2022-06-25 01:08:45,455 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:08:45,646 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:45,698 [IPC Server handler 4 on default port 36557] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/97d08340-a146-41c4-a759-b3b136c7fb6d
2022-06-25 01:08:45,698 [IPC Server handler 4 on default port 36557] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 97d08340-a146-41c4-a759-b3b136c7fb6d{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=37711, RATIS=43169, RATIS_ADMIN=43169, RATIS_SERVER=43169, STANDALONE=44433], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:08:45,699 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(275)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-06-25 01:08:45,699 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=cdbaaf97-8e9b-4256-80e1-298c63fec351 to datanode:97d08340-a146-41c4-a759-b3b136c7fb6d
2022-06-25 01:08:45,699 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: cdbaaf97-8e9b-4256-80e1-298c63fec351, Nodes: 97d08340-a146-41c4-a759-b3b136c7fb6d{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=37711, RATIS=43169, RATIS_ADMIN=43169, RATIS_SERVER=43169, STANDALONE=44433], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-25T01:08:45.699Z[Etc/UTC]].
2022-06-25 01:08:45,710 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(309)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data-0/containers/hdds/84da1e05-86d5-4b42-9168-65f6ed46dc76/DS-be8a863c-0fc6-4b4f-a7aa-a48c77d11c95/container.db for volume DS-be8a863c-0fc6-4b4f-a7aa-a48c77d11c95
2022-06-25 01:08:45,711 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(340)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data-0/containers/hdds/84da1e05-86d5-4b42-9168-65f6ed46dc76/DS-be8a863c-0fc6-4b4f-a7aa-a48c77d11c95/container.db for volume DS-be8a863c-0fc6-4b4f-a7aa-a48c77d11c95
2022-06-25 01:08:45,711 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(344)) - Attempting to start container services.
2022-06-25 01:08:45,711 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(279)) - Background container scanner has been disabled.
2022-06-25 01:08:45,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:45,720 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 43029
2022-06-25 01:08:45,730 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9
2022-06-25 01:08:45,780 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: start RPC server
2022-06-25 01:08:45,780 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: GrpcService started, listening on 44897
2022-06-25 01:08:45,790 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9 is started using port 44897 for RATIS
2022-06-25 01:08:45,790 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9 is started using port 44897 for RATIS_ADMIN
2022-06-25 01:08:45,790 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9 is started using port 44897 for RATIS_SERVER
2022-06-25 01:08:45,791 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@1067788d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: Started
2022-06-25 01:08:45,791 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9 is started using port 37333
2022-06-25 01:08:45,868 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:45,872 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: addNew group-C2534272B3F4:[3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|priority:1] returns group-C2534272B3F4:java.util.concurrent.CompletableFuture@42bebb6e[Not completed]
2022-06-25 01:08:45,872 [pool-4145-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: new RaftServerImpl for group-C2534272B3F4:[3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|priority:1] with ContainerStateMachine:uninitialized
2022-06-25 01:08:45,872 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:08:45,872 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:08:45,872 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:08:45,872 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:08:45,872 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:08:45,873 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:08:45,873 [pool-4145-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4: ConfigurationManager, init=-1: [3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|priority:1], old=null, confs=<EMPTY_MAP>
2022-06-25 01:08:45,873 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data/ratis] (custom)
2022-06-25 01:08:45,873 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:08:45,873 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:08:45,873 [pool-4145-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data/ratis/5525c833-6a53-417b-b57e-c2534272b3f4 does not exist. Creating ...
2022-06-25 01:08:45,880 [pool-4145-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data/ratis/5525c833-6a53-417b-b57e-c2534272b3f4/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:08:45,885 [pool-4145-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data/ratis/5525c833-6a53-417b-b57e-c2534272b3f4 has been successfully formatted.
2022-06-25 01:08:45,886 [pool-4145-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-C2534272B3F4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:08:45,886 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:08:45,886 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:08:45,886 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:08:45,886 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:08:45,886 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:08:45,886 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:08:45,888 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:08:45,888 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:08:45,888 [pool-4145-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data/ratis/5525c833-6a53-417b-b57e-c2534272b3f4
2022-06-25 01:08:45,888 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:08:45,888 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:08:45,888 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:08:45,888 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:08:45,888 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:08:45,888 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:08:45,888 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:08:45,888 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:08:45,893 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:08:45,894 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:08:45,894 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:08:45,894 [pool-4145-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:08:45,894 [pool-4145-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:08:45,918 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:08:45,918 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:08:45,919 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:08:45,919 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:08:45,919 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:08:45,919 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:08:45,923 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:08:45,923 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:08:45,923 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:08:45,923 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:08:45,923 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:08:45,923 [pool-4145-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4: start as a follower, conf=-1: [3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|priority:1], old=null
2022-06-25 01:08:45,923 [pool-4145-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:08:45,923 [pool-4145-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: start 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-FollowerState
2022-06-25 01:08:45,934 [pool-4145-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C2534272B3F4,id=3c6128f4-7bf2-4a55-83fb-21add5186158
2022-06-25 01:08:45,936 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(358)) - Pipeline Pipeline[ Id: 5525c833-6a53-417b-b57e-c2534272b3f4, Nodes: 3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:3c6128f4-7bf2-4a55-83fb-21add5186158, CreationTimestamp2022-06-25T01:08:42.884Z[Etc/UTC]] moved to OPEN state
2022-06-25 01:08:45,936 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:45,942 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=5525c833-6a53-417b-b57e-c2534272b3f4
2022-06-25 01:08:45,943 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=5525c833-6a53-417b-b57e-c2534272b3f4.
2022-06-25 01:08:46,463 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Waiting for nodes to be ready. Got 5 of 6 DN Heartbeats.
2022-06-25 01:08:46,463 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Waiting for cluster to exit safe mode
2022-06-25 01:08:46,463 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:08:46,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:46,890 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:47,465 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Waiting for nodes to be ready. Got 5 of 6 DN Heartbeats.
2022-06-25 01:08:47,465 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Waiting for cluster to exit safe mode
2022-06-25 01:08:47,465 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:08:47,548 [IPC Server handler 2 on default port 36557] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/4943f96b-6a06-411a-b0ee-4ab66ab6f7f9
2022-06-25 01:08:47,548 [IPC Server handler 2 on default port 36557] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43029, RATIS=44897, RATIS_ADMIN=44897, RATIS_SERVER=44897, STANDALONE=37333], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:08:47,548 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(275)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-06-25 01:08:47,549 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=b31a673a-3cb5-496f-b87f-d427a30f5985 to datanode:4943f96b-6a06-411a-b0ee-4ab66ab6f7f9
2022-06-25 01:08:47,549 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: b31a673a-3cb5-496f-b87f-d427a30f5985, Nodes: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43029, RATIS=44897, RATIS_ADMIN=44897, RATIS_SERVER=44897, STANDALONE=37333], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-25T01:08:47.549Z[Etc/UTC]].
2022-06-25 01:08:47,549 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=1a613b2a-b322-4f7f-932c-b6b9df3cef32 to datanode:4943f96b-6a06-411a-b0ee-4ab66ab6f7f9
2022-06-25 01:08:47,549 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=1a613b2a-b322-4f7f-932c-b6b9df3cef32 to datanode:97d08340-a146-41c4-a759-b3b136c7fb6d
2022-06-25 01:08:47,549 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=1a613b2a-b322-4f7f-932c-b6b9df3cef32 to datanode:fc692a40-1ae9-40b7-8d63-7e46f51df1ef
2022-06-25 01:08:47,550 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 1a613b2a-b322-4f7f-932c-b6b9df3cef32, Nodes: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43029, RATIS=44897, RATIS_ADMIN=44897, RATIS_SERVER=44897, STANDALONE=37333], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}97d08340-a146-41c4-a759-b3b136c7fb6d{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=37711, RATIS=43169, RATIS_ADMIN=43169, RATIS_SERVER=43169, STANDALONE=44433], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}fc692a40-1ae9-40b7-8d63-7e46f51df1ef{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=40691, RATIS=39343, RATIS_ADMIN=39343, RATIS_SERVER=39343, STANDALONE=32859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-25T01:08:47.549Z[Etc/UTC]].
2022-06-25 01:08:47,652 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:47,685 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: addNew group-23927ECA553C:[fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|priority:1] returns group-23927ECA553C:java.util.concurrent.CompletableFuture@38642faa[Not completed]
2022-06-25 01:08:47,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:47,732 [pool-4172-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: new RaftServerImpl for group-23927ECA553C:[fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|priority:1] with ContainerStateMachine:uninitialized
2022-06-25 01:08:47,732 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:08:47,732 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:08:47,732 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:08:47,732 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:08:47,732 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:08:47,733 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:08:47,733 [pool-4172-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C: ConfigurationManager, init=-1: [fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|priority:1], old=null, confs=<EMPTY_MAP>
2022-06-25 01:08:47,733 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/data/ratis] (custom)
2022-06-25 01:08:47,733 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:08:47,733 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:08:47,733 [pool-4172-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/data/ratis/a58b823e-be03-49ee-a4ae-23927eca553c does not exist. Creating ...
2022-06-25 01:08:47,766 [pool-4172-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/data/ratis/a58b823e-be03-49ee-a4ae-23927eca553c/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:08:47,837 [pool-4172-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/data/ratis/a58b823e-be03-49ee-a4ae-23927eca553c has been successfully formatted.
2022-06-25 01:08:47,837 [pool-4172-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-23927ECA553C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:08:47,837 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:08:47,837 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:08:47,837 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:08:47,837 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:08:47,837 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:08:47,838 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:08:47,839 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:08:47,839 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:08:47,839 [pool-4172-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/data/ratis/a58b823e-be03-49ee-a4ae-23927eca553c
2022-06-25 01:08:47,839 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:08:47,839 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:08:47,839 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:08:47,840 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:08:47,840 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:08:47,840 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:08:47,840 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:08:47,840 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:08:47,850 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(358)) - Pipeline Pipeline[ Id: a58b823e-be03-49ee-a4ae-23927eca553c, Nodes: fc692a40-1ae9-40b7-8d63-7e46f51df1ef{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=40691, RATIS=39343, RATIS_ADMIN=39343, RATIS_SERVER=39343, STANDALONE=32859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:fc692a40-1ae9-40b7-8d63-7e46f51df1ef, CreationTimestamp2022-06-25T01:08:44.687Z[Etc/UTC]] moved to OPEN state
2022-06-25 01:08:47,942 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:08:47,942 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:08:47,943 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:08:47,943 [pool-4172-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:08:47,943 [pool-4172-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:08:47,949 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:08:47,949 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:08:47,949 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:08:47,949 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:08:47,949 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:08:47,949 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:08:47,953 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:08:47,953 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:08:47,953 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:08:47,953 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:08:47,954 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:08:47,954 [pool-4172-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C: start as a follower, conf=-1: [fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|priority:1], old=null
2022-06-25 01:08:47,954 [pool-4172-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:08:47,954 [pool-4172-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: start fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-FollowerState
2022-06-25 01:08:47,962 [pool-4172-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-23927ECA553C,id=fc692a40-1ae9-40b7-8d63-7e46f51df1ef
2022-06-25 01:08:47,969 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:47,969 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:47,969 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=a58b823e-be03-49ee-a4ae-23927eca553c
2022-06-25 01:08:47,969 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=a58b823e-be03-49ee-a4ae-23927eca553c.
2022-06-25 01:08:47,969 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: addNew group-B6B9DF3CEF32:[4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|priority:0] returns group-B6B9DF3CEF32:java.util.concurrent.CompletableFuture@3c5bac7e[Not completed]
2022-06-25 01:08:47,970 [pool-4172-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: new RaftServerImpl for group-B6B9DF3CEF32:[4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|priority:0] with ContainerStateMachine:uninitialized
2022-06-25 01:08:47,970 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:08:47,970 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:08:47,970 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:08:47,970 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:08:47,970 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:08:47,971 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:08:47,971 [pool-4172-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: ConfigurationManager, init=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|priority:0], old=null, confs=<EMPTY_MAP>
2022-06-25 01:08:47,971 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/data/ratis] (custom)
2022-06-25 01:08:47,971 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:08:47,971 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:08:47,971 [pool-4172-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/data/ratis/1a613b2a-b322-4f7f-932c-b6b9df3cef32 does not exist. Creating ...
2022-06-25 01:08:47,969 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:47,983 [pool-4172-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/data/ratis/1a613b2a-b322-4f7f-932c-b6b9df3cef32/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:08:47,998 [pool-4172-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/data/ratis/1a613b2a-b322-4f7f-932c-b6b9df3cef32 has been successfully formatted.
2022-06-25 01:08:47,998 [pool-4172-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-B6B9DF3CEF32: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:08:47,998 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:08:47,998 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:08:47,999 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:47,999 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:08:47,999 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:08:47,999 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:08:48,000 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:08:48,002 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:08:48,002 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:08:48,002 [pool-4172-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/data/ratis/1a613b2a-b322-4f7f-932c-b6b9df3cef32
2022-06-25 01:08:48,002 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:08:48,002 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:08:48,002 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:08:48,002 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:08:48,002 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:08:48,002 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:08:48,002 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:08:48,002 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:08:48,010 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:08:48,016 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:08:48,016 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:08:48,016 [pool-4172-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:08:48,016 [pool-4172-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:08:48,017 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:08:48,017 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:08:48,017 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:08:48,017 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:08:48,017 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:08:48,017 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:08:48,022 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:08:48,022 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:08:48,022 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:08:48,022 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:08:48,022 [pool-4172-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:08:48,022 [pool-4172-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: start as a follower, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|priority:0], old=null
2022-06-25 01:08:48,022 [pool-4172-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:08:48,022 [pool-4172-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: start fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:08:48,023 [pool-4172-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B6B9DF3CEF32,id=fc692a40-1ae9-40b7-8d63-7e46f51df1ef
2022-06-25 01:08:48,024 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=1a613b2a-b322-4f7f-932c-b6b9df3cef32
2022-06-25 01:08:48,043 [grpc-default-executor-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: addNew group-B6B9DF3CEF32:[4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0] returns group-B6B9DF3CEF32:java.util.concurrent.CompletableFuture@7031eee7[Not completed]
2022-06-25 01:08:48,044 [pool-4226-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: new RaftServerImpl for group-B6B9DF3CEF32:[4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0] with ContainerStateMachine:uninitialized
2022-06-25 01:08:48,044 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:08:48,044 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:08:48,044 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:08:48,044 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:08:48,044 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:08:48,044 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:08:48,044 [pool-4226-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: ConfigurationManager, init=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
2022-06-25 01:08:48,044 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data/ratis] (custom)
2022-06-25 01:08:48,044 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:08:48,045 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:08:48,045 [pool-4226-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data/ratis/1a613b2a-b322-4f7f-932c-b6b9df3cef32 does not exist. Creating ...
2022-06-25 01:08:48,048 [pool-4226-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data/ratis/1a613b2a-b322-4f7f-932c-b6b9df3cef32/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:08:48,054 [pool-4226-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data/ratis/1a613b2a-b322-4f7f-932c-b6b9df3cef32 has been successfully formatted.
2022-06-25 01:08:48,054 [pool-4226-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-B6B9DF3CEF32: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:08:48,138 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:08:48,138 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:08:48,138 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:08:48,138 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:08:48,138 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:08:48,139 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:08:48,140 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:08:48,140 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:08:48,140 [pool-4226-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data/ratis/1a613b2a-b322-4f7f-932c-b6b9df3cef32
2022-06-25 01:08:48,140 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:08:48,140 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:08:48,140 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:08:48,140 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:08:48,140 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:08:48,140 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:08:48,140 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:08:48,140 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:08:48,185 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:08:48,185 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:08:48,185 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:08:48,186 [pool-4226-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:08:48,186 [pool-4226-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:08:48,192 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:08:48,192 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:08:48,192 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:08:48,193 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:08:48,193 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:08:48,193 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:08:48,197 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:08:48,197 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:08:48,197 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:08:48,197 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:08:48,197 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:08:48,197 [pool-4226-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: start as a follower, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:08:48,197 [pool-4226-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:08:48,197 [pool-4226-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: start 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:08:48,210 [pool-4226-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B6B9DF3CEF32,id=4943f96b-6a06-411a-b0ee-4ab66ab6f7f9
2022-06-25 01:08:48,243 [grpc-default-executor-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: addNew group-B6B9DF3CEF32:[4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0] returns group-B6B9DF3CEF32:java.util.concurrent.CompletableFuture@2704803b[Not completed]
2022-06-25 01:08:48,283 [pool-4199-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: new RaftServerImpl for group-B6B9DF3CEF32:[4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0] with ContainerStateMachine:uninitialized
2022-06-25 01:08:48,283 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:08:48,283 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:08:48,283 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:08:48,283 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:08:48,283 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:08:48,284 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:08:48,284 [pool-4199-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: ConfigurationManager, init=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
2022-06-25 01:08:48,284 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data/ratis] (custom)
2022-06-25 01:08:48,284 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:08:48,284 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:08:48,284 [pool-4199-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data/ratis/1a613b2a-b322-4f7f-932c-b6b9df3cef32 does not exist. Creating ...
2022-06-25 01:08:48,292 [pool-4199-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data/ratis/1a613b2a-b322-4f7f-932c-b6b9df3cef32/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:08:48,297 [pool-4199-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data/ratis/1a613b2a-b322-4f7f-932c-b6b9df3cef32 has been successfully formatted.
2022-06-25 01:08:48,297 [pool-4199-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-B6B9DF3CEF32: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:08:48,298 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:08:48,298 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:08:48,298 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:08:48,298 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:08:48,298 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:08:48,298 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:08:48,300 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:08:48,300 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:08:48,300 [pool-4199-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data/ratis/1a613b2a-b322-4f7f-932c-b6b9df3cef32
2022-06-25 01:08:48,300 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:08:48,300 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:08:48,300 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:08:48,300 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:08:48,300 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:08:48,300 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:08:48,300 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:08:48,300 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:08:48,303 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:08:48,304 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:08:48,304 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:08:48,304 [pool-4199-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:08:48,304 [pool-4199-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:08:48,305 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:08:48,305 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:08:48,305 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:08:48,305 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:08:48,305 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:08:48,305 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:08:48,310 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:08:48,310 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:08:48,312 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:08:48,312 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:08:48,312 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:08:48,312 [pool-4199-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: start as a follower, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:08:48,312 [pool-4199-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:08:48,312 [pool-4199-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: start 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:08:48,336 [pool-4199-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B6B9DF3CEF32,id=97d08340-a146-41c4-a759-b3b136c7fb6d
2022-06-25 01:08:48,364 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=1a613b2a-b322-4f7f-932c-b6b9df3cef32.
2022-06-25 01:08:48,466 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-06-25 01:08:48,466 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Waiting for cluster to exit safe mode
2022-06-25 01:08:48,466 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:08:48,541 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: addNew group-D427A30F5985:[4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|priority:1] returns group-D427A30F5985:java.util.concurrent.CompletableFuture@e4b94c5[Not completed]
2022-06-25 01:08:48,541 [pool-4226-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: new RaftServerImpl for group-D427A30F5985:[4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|priority:1] with ContainerStateMachine:uninitialized
2022-06-25 01:08:48,541 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:08:48,541 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:08:48,542 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:08:48,542 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:08:48,542 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:08:48,542 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:08:48,542 [pool-4226-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985: ConfigurationManager, init=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|priority:1], old=null, confs=<EMPTY_MAP>
2022-06-25 01:08:48,542 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data/ratis] (custom)
2022-06-25 01:08:48,542 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:08:48,542 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:08:48,542 [pool-4226-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data/ratis/b31a673a-3cb5-496f-b87f-d427a30f5985 does not exist. Creating ...
2022-06-25 01:08:48,549 [pool-4226-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data/ratis/b31a673a-3cb5-496f-b87f-d427a30f5985/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:08:48,551 [pool-4226-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data/ratis/b31a673a-3cb5-496f-b87f-d427a30f5985 has been successfully formatted.
2022-06-25 01:08:48,552 [pool-4226-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-D427A30F5985: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:08:48,552 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:08:48,552 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:08:48,552 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:08:48,552 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:08:48,552 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:08:48,552 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:08:48,554 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:08:48,554 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:08:48,554 [pool-4226-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data/ratis/b31a673a-3cb5-496f-b87f-d427a30f5985
2022-06-25 01:08:48,554 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:08:48,554 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:08:48,554 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:08:48,554 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:08:48,554 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:08:48,554 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:08:48,554 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:08:48,554 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:08:48,556 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(358)) - Pipeline Pipeline[ Id: b31a673a-3cb5-496f-b87f-d427a30f5985, Nodes: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43029, RATIS=44897, RATIS_ADMIN=44897, RATIS_SERVER=44897, STANDALONE=37333], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:4943f96b-6a06-411a-b0ee-4ab66ab6f7f9, CreationTimestamp2022-06-25T01:08:47.549Z[Etc/UTC]] moved to OPEN state
2022-06-25 01:08:48,557 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:48,558 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:08:48,558 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:08:48,558 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:08:48,559 [pool-4226-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:08:48,559 [pool-4226-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:08:48,559 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:08:48,559 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:08:48,559 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:08:48,559 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:08:48,559 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:08:48,559 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:08:48,571 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:08:48,571 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:08:48,571 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:08:48,572 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:08:48,572 [pool-4226-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:08:48,572 [pool-4226-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985: start as a follower, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|priority:1], old=null
2022-06-25 01:08:48,572 [pool-4226-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:08:48,572 [pool-4226-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: start 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-FollowerState
2022-06-25 01:08:48,586 [pool-4226-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D427A30F5985,id=4943f96b-6a06-411a-b0ee-4ab66ab6f7f9
2022-06-25 01:08:48,596 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=b31a673a-3cb5-496f-b87f-d427a30f5985
2022-06-25 01:08:48,596 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=b31a673a-3cb5-496f-b87f-d427a30f5985.
2022-06-25 01:08:48,693 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: addNew group-298C63FEC351:[97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|priority:1] returns group-298C63FEC351:java.util.concurrent.CompletableFuture@b46fb91[Not completed]
2022-06-25 01:08:48,694 [pool-4199-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: new RaftServerImpl for group-298C63FEC351:[97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|priority:1] with ContainerStateMachine:uninitialized
2022-06-25 01:08:48,694 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:08:48,694 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:08:48,694 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:08:48,694 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:08:48,694 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:08:48,694 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:08:48,694 [pool-4199-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351: ConfigurationManager, init=-1: [97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|priority:1], old=null, confs=<EMPTY_MAP>
2022-06-25 01:08:48,694 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data/ratis] (custom)
2022-06-25 01:08:48,694 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:08:48,695 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:08:48,695 [pool-4199-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data/ratis/cdbaaf97-8e9b-4256-80e1-298c63fec351 does not exist. Creating ...
2022-06-25 01:08:48,696 [pool-4199-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data/ratis/cdbaaf97-8e9b-4256-80e1-298c63fec351/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:08:48,698 [pool-4199-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data/ratis/cdbaaf97-8e9b-4256-80e1-298c63fec351 has been successfully formatted.
2022-06-25 01:08:48,698 [pool-4199-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-298C63FEC351: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:08:48,698 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:08:48,698 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:08:48,698 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:08:48,698 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:08:48,698 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:08:48,699 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(358)) - Pipeline Pipeline[ Id: cdbaaf97-8e9b-4256-80e1-298c63fec351, Nodes: 97d08340-a146-41c4-a759-b3b136c7fb6d{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=37711, RATIS=43169, RATIS_ADMIN=43169, RATIS_SERVER=43169, STANDALONE=44433], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:97d08340-a146-41c4-a759-b3b136c7fb6d, CreationTimestamp2022-06-25T01:08:45.699Z[Etc/UTC]] moved to OPEN state
2022-06-25 01:08:48,699 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:48,699 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:08:48,701 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:08:48,701 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:08:48,701 [pool-4199-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data/ratis/cdbaaf97-8e9b-4256-80e1-298c63fec351
2022-06-25 01:08:48,701 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:08:48,701 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:08:48,701 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:08:48,701 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:08:48,701 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:08:48,701 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:08:48,701 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:08:48,701 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:08:48,716 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:08:48,717 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:08:48,717 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:08:48,717 [pool-4199-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:08:48,717 [pool-4199-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:08:48,720 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:48,730 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:08:48,730 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:08:48,730 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:08:48,730 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:08:48,730 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:08:48,731 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:08:48,741 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:08:48,741 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:08:48,741 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:08:48,741 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:08:48,741 [pool-4199-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:08:48,741 [pool-4199-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351: start as a follower, conf=-1: [97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|priority:1], old=null
2022-06-25 01:08:48,742 [pool-4199-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:08:48,742 [pool-4199-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: start 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-FollowerState
2022-06-25 01:08:48,742 [pool-4199-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-298C63FEC351,id=97d08340-a146-41c4-a759-b3b136c7fb6d
2022-06-25 01:08:48,747 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=cdbaaf97-8e9b-4256-80e1-298c63fec351
2022-06-25 01:08:48,747 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=cdbaaf97-8e9b-4256-80e1-298c63fec351.
2022-06-25 01:08:48,840 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5044738202ns, electionTimeout:5043ms
2022-06-25 01:08:48,840 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - be67eb5e-e62d-4374-a142-8db592db20d7: shutdown be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-FollowerState
2022-06-25 01:08:48,841 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:08:48,841 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:08:48,841 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - be67eb5e-e62d-4374-a142-8db592db20d7: start be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-LeaderElection144
2022-06-25 01:08:48,870 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:48,898 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:48,921 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-LeaderElection144] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-LeaderElection144 ELECTION round 0: submit vote requests at term 1 for -1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:1], old=null
2022-06-25 01:08:48,921 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-LeaderElection144] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-LeaderElection144 ELECTION round 0: result PASSED (term=1)
2022-06-25 01:08:48,921 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-LeaderElection144] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - be67eb5e-e62d-4374-a142-8db592db20d7: shutdown be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-LeaderElection144
2022-06-25 01:08:48,921 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-LeaderElection144] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-06-25 01:08:48,921 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-LeaderElection144] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-5F6F11EE7DA8 with new leaderId: be67eb5e-e62d-4374-a142-8db592db20d7
2022-06-25 01:08:48,921 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-LeaderElection144] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8: change Leader from null to be67eb5e-e62d-4374-a142-8db592db20d7 at term 1 for becomeLeader, leader elected after 5357ms
2022-06-25 01:08:48,922 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-LeaderElection144] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-25 01:08:48,922 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-LeaderElection144] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:08:48,922 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-LeaderElection144] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-06-25 01:08:48,923 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-LeaderElection144] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-06-25 01:08:48,923 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-LeaderElection144] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-25 01:08:48,923 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-LeaderElection144] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-25 01:08:48,923 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-LeaderElection144] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:08:48,923 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-LeaderElection144] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-25 01:08:48,923 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-LeaderElection144] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - be67eb5e-e62d-4374-a142-8db592db20d7: start be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-LeaderStateImpl
2022-06-25 01:08:48,924 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:48,924 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-LeaderElection144] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:08:48,926 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis/be334d2b-9e4d-429c-8f2f-5f6f11ee7da8/current/log_inprogress_0
2022-06-25 01:08:49,000 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:49,001 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-LeaderElection144] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8: set configuration 0: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:1], old=null
2022-06-25 01:08:49,251 [be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5298473608ns, electionTimeout:5192ms
2022-06-25 01:08:49,251 [be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - be67eb5e-e62d-4374-a142-8db592db20d7: shutdown be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-FollowerState
2022-06-25 01:08:49,252 [be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:08:49,252 [be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:08:49,252 [be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - be67eb5e-e62d-4374-a142-8db592db20d7: start be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-LeaderElection145
2022-06-25 01:08:49,333 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5191344583ns, electionTimeout:5097ms
2022-06-25 01:08:49,333 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: shutdown 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-FollowerState
2022-06-25 01:08:49,333 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:08:49,334 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:08:49,334 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: start 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-LeaderElection146
2022-06-25 01:08:49,430 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5073149315ns, electionTimeout:5044ms
2022-06-25 01:08:49,431 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: shutdown 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-FollowerState
2022-06-25 01:08:49,431 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:08:49,431 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:08:49,431 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: start 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection147
2022-06-25 01:08:49,466 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-06-25 01:08:49,466 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Waiting for cluster to exit safe mode
2022-06-25 01:08:49,466 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:08:49,471 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection147] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection147 ELECTION round 0: submit vote requests at term 1 for -1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:0], old=null
2022-06-25 01:08:49,502 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846: receive requestVote(ELECTION, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, group-EABD1BE7E846, 1, (t:0, i:0))
2022-06-25 01:08:49,514 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-LeaderElection146] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-LeaderElection146 ELECTION round 0: submit vote requests at term 1 for -1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:0], old=null
2022-06-25 01:08:49,519 [be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-LeaderElection145] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-LeaderElection145 ELECTION round 0: submit vote requests at term 1 for -1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|priority:0], old=null
2022-06-25 01:08:49,519 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(48)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-CANDIDATE: reject ELECTION from 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: already has voted for be67eb5e-e62d-4374-a142-8db592db20d7 at current term 1
2022-06-25 01:08:49,520 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846 replies to ELECTION vote request: 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf<-be67eb5e-e62d-4374-a142-8db592db20d7#0:FAIL-t1. Peer's state: be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846:t1, leader=null, voted=be67eb5e-e62d-4374-a142-8db592db20d7, raftlog=be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-SegmentedRaftLog:OPENED:c-1, conf=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|priority:0], old=null
2022-06-25 01:08:49,570 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:49,655 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:49,699 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846: receive requestVote(ELECTION, 3c6128f4-7bf2-4a55-83fb-21add5186158, group-EABD1BE7E846, 1, (t:0, i:0))
2022-06-25 01:08:49,699 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(48)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-CANDIDATE: reject ELECTION from 3c6128f4-7bf2-4a55-83fb-21add5186158: already has voted for be67eb5e-e62d-4374-a142-8db592db20d7 at current term 1
2022-06-25 01:08:49,699 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846 replies to ELECTION vote request: 3c6128f4-7bf2-4a55-83fb-21add5186158<-be67eb5e-e62d-4374-a142-8db592db20d7#0:FAIL-t1. Peer's state: be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846:t1, leader=null, voted=be67eb5e-e62d-4374-a142-8db592db20d7, raftlog=be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-SegmentedRaftLog:OPENED:c-1, conf=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|priority:0], old=null
2022-06-25 01:08:49,718 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:49,719 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846: receive requestVote(ELECTION, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, group-EABD1BE7E846, 1, (t:0, i:0))
2022-06-25 01:08:49,719 [grpc-default-executor-8] INFO  impl.VoteContext (VoteContext.java:log(48)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-CANDIDATE: reject ELECTION from 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: already has voted for 3c6128f4-7bf2-4a55-83fb-21add5186158 at current term 1
2022-06-25 01:08:49,719 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846 replies to ELECTION vote request: 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf<-3c6128f4-7bf2-4a55-83fb-21add5186158#0:FAIL-t1. Peer's state: 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846:t1, leader=null, voted=3c6128f4-7bf2-4a55-83fb-21add5186158, raftlog=3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-SegmentedRaftLog:OPENED:c-1, conf=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:0], old=null
2022-06-25 01:08:49,721 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:49,721 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846: receive requestVote(ELECTION, be67eb5e-e62d-4374-a142-8db592db20d7, group-EABD1BE7E846, 1, (t:0, i:0))
2022-06-25 01:08:49,721 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(48)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-CANDIDATE: reject ELECTION from be67eb5e-e62d-4374-a142-8db592db20d7: already has voted for 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf at current term 1
2022-06-25 01:08:49,721 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846 replies to ELECTION vote request: be67eb5e-e62d-4374-a142-8db592db20d7<-09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf#0:FAIL-t1. Peer's state: 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846:t1, leader=null, voted=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, raftlog=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-SegmentedRaftLog:OPENED:c-1, conf=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:0], old=null
2022-06-25 01:08:49,723 [be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-LeaderElection145] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-LeaderElection145: ELECTION REJECTED received 1 response(s) and 0 exception(s):
2022-06-25 01:08:49,723 [be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-LeaderElection145] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: be67eb5e-e62d-4374-a142-8db592db20d7<-09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf#0:FAIL-t1
2022-06-25 01:08:49,723 [be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-LeaderElection145] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-LeaderElection145 ELECTION round 0: result REJECTED
2022-06-25 01:08:49,723 [be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-LeaderElection145] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
2022-06-25 01:08:49,724 [be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-LeaderElection145] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - be67eb5e-e62d-4374-a142-8db592db20d7: shutdown be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-LeaderElection145
2022-06-25 01:08:49,724 [be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-LeaderElection145] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - be67eb5e-e62d-4374-a142-8db592db20d7: start be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-FollowerState
2022-06-25 01:08:49,724 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846: receive requestVote(ELECTION, be67eb5e-e62d-4374-a142-8db592db20d7, group-EABD1BE7E846, 1, (t:0, i:0))
2022-06-25 01:08:49,724 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-CANDIDATE: reject ELECTION from be67eb5e-e62d-4374-a142-8db592db20d7: already has voted for 3c6128f4-7bf2-4a55-83fb-21add5186158 at current term 1
2022-06-25 01:08:49,724 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846 replies to ELECTION vote request: be67eb5e-e62d-4374-a142-8db592db20d7<-3c6128f4-7bf2-4a55-83fb-21add5186158#0:FAIL-t1. Peer's state: 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846:t1, leader=null, voted=3c6128f4-7bf2-4a55-83fb-21add5186158, raftlog=3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-SegmentedRaftLog:OPENED:c-1, conf=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:0], old=null
2022-06-25 01:08:49,724 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846: receive requestVote(ELECTION, 3c6128f4-7bf2-4a55-83fb-21add5186158, group-EABD1BE7E846, 1, (t:0, i:0))
2022-06-25 01:08:49,725 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-CANDIDATE: reject ELECTION from 3c6128f4-7bf2-4a55-83fb-21add5186158: already has voted for 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf at current term 1
2022-06-25 01:08:49,725 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846 replies to ELECTION vote request: 3c6128f4-7bf2-4a55-83fb-21add5186158<-09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf#0:FAIL-t1. Peer's state: 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846:t1, leader=null, voted=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, raftlog=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-SegmentedRaftLog:OPENED:c-1, conf=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:0], old=null
2022-06-25 01:08:49,725 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-LeaderElection146] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-LeaderElection146: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-06-25 01:08:49,725 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-LeaderElection146] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 3c6128f4-7bf2-4a55-83fb-21add5186158<-be67eb5e-e62d-4374-a142-8db592db20d7#0:FAIL-t1
2022-06-25 01:08:49,725 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-LeaderElection146] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 3c6128f4-7bf2-4a55-83fb-21add5186158<-09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf#0:FAIL-t1
2022-06-25 01:08:49,726 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection147] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection147: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-06-25 01:08:49,726 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection147] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf<-be67eb5e-e62d-4374-a142-8db592db20d7#0:FAIL-t1
2022-06-25 01:08:49,726 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection147] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf<-3c6128f4-7bf2-4a55-83fb-21add5186158#0:FAIL-t1
2022-06-25 01:08:49,747 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection147] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection147 ELECTION round 0: result REJECTED
2022-06-25 01:08:49,747 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection147] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
2022-06-25 01:08:49,747 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection147] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: shutdown 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection147
2022-06-25 01:08:49,747 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection147] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: start 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-FollowerState
2022-06-25 01:08:49,747 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-LeaderElection146] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-LeaderElection146 ELECTION round 0: result REJECTED
2022-06-25 01:08:49,748 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-LeaderElection146] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
2022-06-25 01:08:49,748 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-LeaderElection146] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: shutdown 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-LeaderElection146
2022-06-25 01:08:49,748 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-LeaderElection146] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: start 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-FollowerState
2022-06-25 01:08:49,782 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5041316690ns, electionTimeout:5030ms
2022-06-25 01:08:49,783 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: shutdown 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-FollowerState
2022-06-25 01:08:49,783 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:08:49,783 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:08:49,783 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: start 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-LeaderElection148
2022-06-25 01:08:49,818 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-LeaderElection148] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-LeaderElection148 ELECTION round 0: submit vote requests at term 1 for -1: [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|priority:1], old=null
2022-06-25 01:08:49,818 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-LeaderElection148] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-LeaderElection148 ELECTION round 0: result PASSED (term=1)
2022-06-25 01:08:49,818 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-LeaderElection148] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: shutdown 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-LeaderElection148
2022-06-25 01:08:49,818 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-LeaderElection148] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-06-25 01:08:49,818 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-LeaderElection148] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-92E04F1B2936 with new leaderId: 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf
2022-06-25 01:08:49,818 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-LeaderElection148] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936: change Leader from null to 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf at term 1 for becomeLeader, leader elected after 5179ms
2022-06-25 01:08:49,819 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-LeaderElection148] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-25 01:08:49,825 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-LeaderElection148] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:08:49,826 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-LeaderElection148] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-06-25 01:08:49,826 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-LeaderElection148] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-06-25 01:08:49,827 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-LeaderElection148] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-25 01:08:49,827 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-LeaderElection148] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-25 01:08:49,827 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-LeaderElection148] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:08:49,827 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-LeaderElection148] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-25 01:08:49,827 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-LeaderElection148] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: start 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-LeaderStateImpl
2022-06-25 01:08:49,827 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-LeaderElection148] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:08:49,834 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-LeaderElection148] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936: set configuration 0: [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1], old=null
2022-06-25 01:08:49,907 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@1067788d] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: Detected pause in JVM or host machine (eg GC): pause of approximately 109122315ns. No GCs detected.
2022-06-25 01:08:49,918 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:49,984 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data/ratis/ecaf046a-409f-4687-9322-92e04f1b2936/current/log_inprogress_0
2022-06-25 01:08:50,003 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:50,471 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-06-25 01:08:50,471 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Waiting for cluster to exit safe mode
2022-06-25 01:08:50,471 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:08:50,721 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:50,827 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:50,897 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:50,922 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:51,010 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:51,129 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5205669244ns, electionTimeout:5193ms
2022-06-25 01:08:51,129 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: shutdown 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-FollowerState
2022-06-25 01:08:51,129 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:08:51,129 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:08:51,129 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: start 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-LeaderElection149
2022-06-25 01:08:51,263 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-LeaderElection149] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-LeaderElection149 ELECTION round 0: submit vote requests at term 1 for -1: [3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|priority:1], old=null
2022-06-25 01:08:51,263 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-LeaderElection149] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-LeaderElection149 ELECTION round 0: result PASSED (term=1)
2022-06-25 01:08:51,263 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-LeaderElection149] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: shutdown 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-LeaderElection149
2022-06-25 01:08:51,263 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-LeaderElection149] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-06-25 01:08:51,263 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-LeaderElection149] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-C2534272B3F4 with new leaderId: 3c6128f4-7bf2-4a55-83fb-21add5186158
2022-06-25 01:08:51,263 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-LeaderElection149] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4: change Leader from null to 3c6128f4-7bf2-4a55-83fb-21add5186158 at term 1 for becomeLeader, leader elected after 5377ms
2022-06-25 01:08:51,263 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-LeaderElection149] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-25 01:08:51,264 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-LeaderElection149] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:08:51,264 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-LeaderElection149] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-06-25 01:08:51,265 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-LeaderElection149] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-06-25 01:08:51,265 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-LeaderElection149] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-25 01:08:51,265 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-LeaderElection149] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-25 01:08:51,265 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-LeaderElection149] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:08:51,265 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-LeaderElection149] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-25 01:08:51,265 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-LeaderElection149] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: start 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-LeaderStateImpl
2022-06-25 01:08:51,266 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-LeaderElection149] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:08:51,267 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:51,269 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-LeaderElection149] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4: set configuration 0: [3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:1], old=null
2022-06-25 01:08:51,269 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data/ratis/5525c833-6a53-417b-b57e-c2534272b3f4/current/log_inprogress_0
2022-06-25 01:08:51,471 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-06-25 01:08:51,472 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Waiting for cluster to exit safe mode
2022-06-25 01:08:51,472 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:08:51,557 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:51,701 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:51,721 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:51,938 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:52,331 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:52,472 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-06-25 01:08:52,472 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Waiting for cluster to exit safe mode
2022-06-25 01:08:52,472 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:08:52,564 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:52,730 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:52,823 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:52,935 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:53,007 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:53,136 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5113284581ns, electionTimeout:5110ms
2022-06-25 01:08:53,136 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: shutdown fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:08:53,136 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:08:53,136 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:08:53,136 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: start fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection150
2022-06-25 01:08:53,156 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5202150934ns, electionTimeout:5192ms
2022-06-25 01:08:53,156 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: shutdown fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-FollowerState
2022-06-25 01:08:53,156 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:08:53,157 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:08:53,157 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: start fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-LeaderElection151
2022-06-25 01:08:53,241 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5043925406ns, electionTimeout:5022ms
2022-06-25 01:08:53,242 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: shutdown 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:08:53,242 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:08:53,242 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:08:53,242 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: start 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection152
2022-06-25 01:08:53,292 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-LeaderElection151] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-LeaderElection151 ELECTION round 0: submit vote requests at term 1 for -1: [fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|priority:1], old=null
2022-06-25 01:08:53,292 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-LeaderElection151] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-LeaderElection151 ELECTION round 0: result PASSED (term=1)
2022-06-25 01:08:53,292 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-LeaderElection151] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: shutdown fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-LeaderElection151
2022-06-25 01:08:53,292 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-LeaderElection151] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-06-25 01:08:53,292 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-LeaderElection151] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-23927ECA553C with new leaderId: fc692a40-1ae9-40b7-8d63-7e46f51df1ef
2022-06-25 01:08:53,292 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-LeaderElection151] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C: change Leader from null to fc692a40-1ae9-40b7-8d63-7e46f51df1ef at term 1 for becomeLeader, leader elected after 5455ms
2022-06-25 01:08:53,293 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-LeaderElection151] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-25 01:08:53,293 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-LeaderElection151] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:08:53,293 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-LeaderElection151] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-06-25 01:08:53,294 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-LeaderElection151] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-06-25 01:08:53,294 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-LeaderElection151] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-25 01:08:53,294 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-LeaderElection151] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-25 01:08:53,298 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:53,294 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection150] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection150 ELECTION round 0: submit vote requests at term 1 for -1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|priority:0], old=null
2022-06-25 01:08:53,299 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-LeaderElection151] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:08:53,299 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-LeaderElection151] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-25 01:08:53,299 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-LeaderElection151] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: start fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-LeaderStateImpl
2022-06-25 01:08:53,300 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-LeaderElection151] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:08:53,312 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/data/ratis/a58b823e-be03-49ee-a4ae-23927eca553c/current/log_inprogress_0
2022-06-25 01:08:53,387 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5074729029ns, electionTimeout:5042ms
2022-06-25 01:08:53,387 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: shutdown 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:08:53,387 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:08:53,387 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:08:53,388 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: start 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection153
2022-06-25 01:08:53,414 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-LeaderElection151] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C: set configuration 0: [fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:1], old=null
2022-06-25 01:08:53,418 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection152] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection152 ELECTION round 0: submit vote requests at term 1 for -1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:08:53,430 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: receive requestVote(ELECTION, fc692a40-1ae9-40b7-8d63-7e46f51df1ef, group-B6B9DF3CEF32, 1, (t:0, i:0))
2022-06-25 01:08:53,431 [grpc-default-executor-8] INFO  impl.VoteContext (VoteContext.java:log(48)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-CANDIDATE: reject ELECTION from fc692a40-1ae9-40b7-8d63-7e46f51df1ef: already has voted for 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9 at current term 1
2022-06-25 01:08:53,431 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32 replies to ELECTION vote request: fc692a40-1ae9-40b7-8d63-7e46f51df1ef<-4943f96b-6a06-411a-b0ee-4ab66ab6f7f9#0:FAIL-t1. Peer's state: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32:t1, leader=null, voted=4943f96b-6a06-411a-b0ee-4ab66ab6f7f9, raftlog=4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:08:53,431 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection153] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection153 ELECTION round 0: submit vote requests at term 1 for -1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:08:53,472 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-06-25 01:08:53,472 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Waiting for cluster to exit safe mode
2022-06-25 01:08:53,472 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:08:53,490 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: receive requestVote(ELECTION, 97d08340-a146-41c4-a759-b3b136c7fb6d, group-B6B9DF3CEF32, 1, (t:0, i:0))
2022-06-25 01:08:53,490 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-CANDIDATE: reject ELECTION from 97d08340-a146-41c4-a759-b3b136c7fb6d: already has voted for 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9 at current term 1
2022-06-25 01:08:53,490 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32 replies to ELECTION vote request: 97d08340-a146-41c4-a759-b3b136c7fb6d<-4943f96b-6a06-411a-b0ee-4ab66ab6f7f9#0:FAIL-t1. Peer's state: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32:t1, leader=null, voted=4943f96b-6a06-411a-b0ee-4ab66ab6f7f9, raftlog=4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:08:53,492 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: receive requestVote(ELECTION, fc692a40-1ae9-40b7-8d63-7e46f51df1ef, group-B6B9DF3CEF32, 1, (t:0, i:0))
2022-06-25 01:08:53,492 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-CANDIDATE: reject ELECTION from fc692a40-1ae9-40b7-8d63-7e46f51df1ef: already has voted for 97d08340-a146-41c4-a759-b3b136c7fb6d at current term 1
2022-06-25 01:08:53,492 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32 replies to ELECTION vote request: fc692a40-1ae9-40b7-8d63-7e46f51df1ef<-97d08340-a146-41c4-a759-b3b136c7fb6d#0:FAIL-t1. Peer's state: 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32:t1, leader=null, voted=97d08340-a146-41c4-a759-b3b136c7fb6d, raftlog=97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:08:53,493 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: receive requestVote(ELECTION, 97d08340-a146-41c4-a759-b3b136c7fb6d, group-B6B9DF3CEF32, 1, (t:0, i:0))
2022-06-25 01:08:53,493 [grpc-default-executor-8] INFO  impl.VoteContext (VoteContext.java:log(48)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-CANDIDATE: reject ELECTION from 97d08340-a146-41c4-a759-b3b136c7fb6d: already has voted for fc692a40-1ae9-40b7-8d63-7e46f51df1ef at current term 1
2022-06-25 01:08:53,494 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32 replies to ELECTION vote request: 97d08340-a146-41c4-a759-b3b136c7fb6d<-fc692a40-1ae9-40b7-8d63-7e46f51df1ef#0:FAIL-t1. Peer's state: fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32:t1, leader=null, voted=fc692a40-1ae9-40b7-8d63-7e46f51df1ef, raftlog=fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|priority:0], old=null
2022-06-25 01:08:53,495 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection150] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection150: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-06-25 01:08:53,495 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection150] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: fc692a40-1ae9-40b7-8d63-7e46f51df1ef<-4943f96b-6a06-411a-b0ee-4ab66ab6f7f9#0:FAIL-t1
2022-06-25 01:08:53,495 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection150] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: fc692a40-1ae9-40b7-8d63-7e46f51df1ef<-97d08340-a146-41c4-a759-b3b136c7fb6d#0:FAIL-t1
2022-06-25 01:08:53,495 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection150] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection150 ELECTION round 0: result REJECTED
2022-06-25 01:08:53,495 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection150] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
2022-06-25 01:08:53,495 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection150] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: shutdown fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection150
2022-06-25 01:08:53,496 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection150] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: start fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:08:53,497 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection153] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection153: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-06-25 01:08:53,497 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection153] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 97d08340-a146-41c4-a759-b3b136c7fb6d<-4943f96b-6a06-411a-b0ee-4ab66ab6f7f9#0:FAIL-t1
2022-06-25 01:08:53,497 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection153] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 97d08340-a146-41c4-a759-b3b136c7fb6d<-fc692a40-1ae9-40b7-8d63-7e46f51df1ef#0:FAIL-t1
2022-06-25 01:08:53,497 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: receive requestVote(ELECTION, 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9, group-B6B9DF3CEF32, 1, (t:0, i:0))
2022-06-25 01:08:53,497 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-CANDIDATE: reject ELECTION from 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: already has voted for 97d08340-a146-41c4-a759-b3b136c7fb6d at current term 1
2022-06-25 01:08:53,497 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32 replies to ELECTION vote request: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9<-97d08340-a146-41c4-a759-b3b136c7fb6d#0:FAIL-t1. Peer's state: 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32:t1, leader=null, voted=97d08340-a146-41c4-a759-b3b136c7fb6d, raftlog=97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:08:53,499 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: receive requestVote(ELECTION, 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9, group-B6B9DF3CEF32, 1, (t:0, i:0))
2022-06-25 01:08:53,515 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FOLLOWER: reject ELECTION from 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: already has voted for fc692a40-1ae9-40b7-8d63-7e46f51df1ef at current term 1
2022-06-25 01:08:53,515 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32 replies to ELECTION vote request: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9<-fc692a40-1ae9-40b7-8d63-7e46f51df1ef#0:FAIL-t1. Peer's state: fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32:t1, leader=null, voted=fc692a40-1ae9-40b7-8d63-7e46f51df1ef, raftlog=fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|priority:0], old=null
2022-06-25 01:08:53,515 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection152] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection152: ELECTION REJECTED received 1 response(s) and 0 exception(s):
2022-06-25 01:08:53,515 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection152] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9<-97d08340-a146-41c4-a759-b3b136c7fb6d#0:FAIL-t1
2022-06-25 01:08:53,515 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection152] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection152 ELECTION round 0: result REJECTED
2022-06-25 01:08:53,515 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection152] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
2022-06-25 01:08:53,515 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection152] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: shutdown 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection152
2022-06-25 01:08:53,515 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection152] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: start 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:08:53,515 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection153] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection153 ELECTION round 0: result REJECTED
2022-06-25 01:08:53,516 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection153] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
2022-06-25 01:08:53,516 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection153] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: shutdown 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection153
2022-06-25 01:08:53,522 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection153] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: start 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:08:53,702 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:53,721 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5149172325ns, electionTimeout:5133ms
2022-06-25 01:08:53,721 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: shutdown 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-FollowerState
2022-06-25 01:08:53,721 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:08:53,722 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:08:53,722 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: start 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-LeaderElection154
2022-06-25 01:08:53,730 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:53,794 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-LeaderElection154] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-LeaderElection154 ELECTION round 0: submit vote requests at term 1 for -1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|priority:1], old=null
2022-06-25 01:08:53,794 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-LeaderElection154] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-LeaderElection154 ELECTION round 0: result PASSED (term=1)
2022-06-25 01:08:53,794 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-LeaderElection154] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: shutdown 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-LeaderElection154
2022-06-25 01:08:53,794 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-LeaderElection154] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-06-25 01:08:53,794 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-LeaderElection154] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-D427A30F5985 with new leaderId: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9
2022-06-25 01:08:53,795 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-LeaderElection154] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985: change Leader from null to 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9 at term 1 for becomeLeader, leader elected after 5242ms
2022-06-25 01:08:53,795 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-LeaderElection154] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-25 01:08:53,795 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:53,796 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-LeaderElection154] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:08:53,796 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-LeaderElection154] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-06-25 01:08:53,797 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-LeaderElection154] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-06-25 01:08:53,797 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-LeaderElection154] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-25 01:08:53,797 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-LeaderElection154] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-25 01:08:53,797 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-LeaderElection154] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:08:53,797 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-LeaderElection154] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-25 01:08:53,797 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-LeaderElection154] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: start 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-LeaderStateImpl
2022-06-25 01:08:53,798 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-LeaderElection154] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:08:53,802 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data/ratis/b31a673a-3cb5-496f-b87f-d427a30f5985/current/log_inprogress_0
2022-06-25 01:08:53,822 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-LeaderElection154] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985: set configuration 0: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:1], old=null
2022-06-25 01:08:53,829 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:53,860 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5118240403ns, electionTimeout:5113ms
2022-06-25 01:08:53,860 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: shutdown 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-FollowerState
2022-06-25 01:08:53,860 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:08:53,860 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:08:53,861 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: start 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-LeaderElection155
2022-06-25 01:08:53,972 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-LeaderElection155] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-LeaderElection155 ELECTION round 0: submit vote requests at term 1 for -1: [97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|priority:1], old=null
2022-06-25 01:08:53,972 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-LeaderElection155] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-LeaderElection155 ELECTION round 0: result PASSED (term=1)
2022-06-25 01:08:53,972 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-LeaderElection155] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: shutdown 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-LeaderElection155
2022-06-25 01:08:53,972 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-LeaderElection155] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-06-25 01:08:53,972 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-LeaderElection155] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-298C63FEC351 with new leaderId: 97d08340-a146-41c4-a759-b3b136c7fb6d
2022-06-25 01:08:53,972 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-LeaderElection155] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351: change Leader from null to 97d08340-a146-41c4-a759-b3b136c7fb6d at term 1 for becomeLeader, leader elected after 5273ms
2022-06-25 01:08:53,972 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-25 01:08:53,973 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:08:53,973 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-06-25 01:08:53,974 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-06-25 01:08:53,974 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-25 01:08:53,974 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-25 01:08:53,974 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:08:53,974 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-LeaderElection155] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-25 01:08:53,976 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:53,995 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-LeaderElection155] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: start 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-LeaderStateImpl
2022-06-25 01:08:53,996 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-LeaderElection155] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:08:54,002 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data/ratis/cdbaaf97-8e9b-4256-80e1-298c63fec351/current/log_inprogress_0
2022-06-25 01:08:54,017 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-LeaderElection155] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351: set configuration 0: [97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1], old=null
2022-06-25 01:08:54,279 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:54,296 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:54,473 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-06-25 01:08:54,473 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Waiting for cluster to exit safe mode
2022-06-25 01:08:54,473 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:08:54,734 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:54,752 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5004996455ns, electionTimeout:5003ms
2022-06-25 01:08:54,752 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: shutdown 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-FollowerState
2022-06-25 01:08:54,752 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2022-06-25 01:08:54,752 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:08:54,752 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: start 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156
2022-06-25 01:08:54,758 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156 ELECTION round 0: submit vote requests at term 2 for -1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:0], old=null
2022-06-25 01:08:54,761 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846: receive requestVote(ELECTION, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, group-EABD1BE7E846, 2, (t:0, i:0))
2022-06-25 01:08:54,761 [grpc-default-executor-8] INFO  impl.VoteContext (VoteContext.java:log(48)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-FOLLOWER: accept ELECTION from 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: our priority 0 <= candidate's priority 1
2022-06-25 01:08:54,761 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf
2022-06-25 01:08:54,761 [grpc-default-executor-8] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: shutdown 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-FollowerState
2022-06-25 01:08:54,761 [grpc-default-executor-8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: start 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-FollowerState
2022-06-25 01:08:54,761 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-FollowerState was interrupted
2022-06-25 01:08:54,762 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846: receive requestVote(ELECTION, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, group-EABD1BE7E846, 2, (t:0, i:0))
2022-06-25 01:08:54,762 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-FOLLOWER: accept ELECTION from 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: our priority 0 <= candidate's priority 1
2022-06-25 01:08:54,762 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf
2022-06-25 01:08:54,762 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - be67eb5e-e62d-4374-a142-8db592db20d7: shutdown be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-FollowerState
2022-06-25 01:08:54,764 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - be67eb5e-e62d-4374-a142-8db592db20d7: start be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-FollowerState
2022-06-25 01:08:54,764 [be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-FollowerState was interrupted
2022-06-25 01:08:54,769 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846 replies to ELECTION vote request: 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf<-be67eb5e-e62d-4374-a142-8db592db20d7#0:OK-t2. Peer's state: be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846:t2, leader=null, voted=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, raftlog=be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-SegmentedRaftLog:OPENED:c-1, conf=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|priority:0], old=null
2022-06-25 01:08:54,771 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156: ELECTION PASSED received 1 response(s) and 0 exception(s):
2022-06-25 01:08:54,771 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf<-be67eb5e-e62d-4374-a142-8db592db20d7#0:OK-t2
2022-06-25 01:08:54,771 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156 ELECTION round 0: result PASSED
2022-06-25 01:08:54,771 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: shutdown 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156
2022-06-25 01:08:54,771 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2022-06-25 01:08:54,771 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-EABD1BE7E846 with new leaderId: 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf
2022-06-25 01:08:54,771 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846: change Leader from null to 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf at term 2 for becomeLeader, leader elected after 10434ms
2022-06-25 01:08:54,771 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-25 01:08:54,772 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:08:54,772 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-06-25 01:08:54,772 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-06-25 01:08:54,773 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-25 01:08:54,773 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-25 01:08:54,773 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:08:54,773 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-25 01:08:54,775 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2022-06-25 01:08:54,775 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:08:54,775 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2022-06-25 01:08:54,777 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2022-06-25 01:08:54,777 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:08:54,777 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:08:54,780 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846 replies to ELECTION vote request: 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf<-3c6128f4-7bf2-4a55-83fb-21add5186158#0:OK-t2. Peer's state: 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846:t2, leader=null, voted=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, raftlog=3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-SegmentedRaftLog:OPENED:c-1, conf=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:0], old=null
2022-06-25 01:08:54,790 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(358)) - Pipeline Pipeline[ Id: 68648fa3-5dbc-4304-8297-eabd1be7e846, Nodes: be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, CreationTimestamp2022-06-25T01:08:42.891Z[Etc/UTC]] moved to OPEN state
2022-06-25 01:08:54,790 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:08:54,790 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2022-06-25 01:08:54,790 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - HealthyPipelineSafeModeRule rule is successfully validated
2022-06-25 01:08:54,790 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(219)) - ScmSafeModeManager, all rules are successfully validated
2022-06-25 01:08:54,790 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(248)) - SCM exiting safe mode.
2022-06-25 01:08:54,791 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2022-06-25 01:08:54,791 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2022-06-25 01:08:54,791 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(253)) - Service BackgroundPipelineCreator transitions to RUNNING.
2022-06-25 01:08:54,791 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2022-06-25 01:08:54,791 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2022-06-25 01:08:54,791 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(372)) - Service ReplicationManager transitions to RUNNING.
2022-06-25 01:08:54,791 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(875)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2022-06-25 01:08:54,808 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2022-06-25 01:08:54,809 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:08:54,809 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2022-06-25 01:08:54,809 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2022-06-25 01:08:54,809 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:08:54,809 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:08:54,810 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: start 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderStateImpl
2022-06-25 01:08:54,810 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:08:54,819 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data/ratis/68648fa3-5dbc-4304-8297-eabd1be7e846/current/log_inprogress_0
2022-06-25 01:08:54,855 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderElection156] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846: set configuration 0: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:0], old=null
2022-06-25 01:08:54,882 [be67eb5e-e62d-4374-a142-8db592db20d7-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-EABD1BE7E846 with new leaderId: 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf
2022-06-25 01:08:54,882 [be67eb5e-e62d-4374-a142-8db592db20d7-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846: change Leader from null to 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf at term 2 for appendEntries, leader elected after 11019ms
2022-06-25 01:08:54,945 [be67eb5e-e62d-4374-a142-8db592db20d7-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846: set configuration 0: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:0], old=null
2022-06-25 01:08:54,965 [be67eb5e-e62d-4374-a142-8db592db20d7-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:08:55,040 [3c6128f4-7bf2-4a55-83fb-21add5186158-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-EABD1BE7E846 with new leaderId: 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf
2022-06-25 01:08:55,040 [3c6128f4-7bf2-4a55-83fb-21add5186158-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846: change Leader from null to 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf at term 2 for appendEntries, leader elected after 10911ms
2022-06-25 01:08:55,042 [be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis/68648fa3-5dbc-4304-8297-eabd1be7e846/current/log_inprogress_0
2022-06-25 01:08:55,058 [3c6128f4-7bf2-4a55-83fb-21add5186158-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846: set configuration 0: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:0], old=null
2022-06-25 01:08:55,059 [3c6128f4-7bf2-4a55-83fb-21add5186158-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:08:55,063 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data/ratis/68648fa3-5dbc-4304-8297-eabd1be7e846/current/log_inprogress_0
2022-06-25 01:08:55,473 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-06-25 01:08:55,473 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Cluster exits safe mode
2022-06-25 01:08:55,473 [Listener at 127.0.0.1/35133] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:08:55,476 [Listener at 127.0.0.1/35133] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-06-25 01:08:55,562 [Listener at 127.0.0.1/35133] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-06-25 01:08:55,562 [Listener at 127.0.0.1/35133] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(209)) - ServiceID for StorageContainerManager is null
2022-06-25 01:08:55,562 [Listener at 127.0.0.1/35133] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(214)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2022-06-25 01:08:55,563 [Listener at 127.0.0.1/35133] WARN  utils.HAUtils (HAUtils.java:getMetaDir(342)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-06-25 01:08:55,563 [Listener at 127.0.0.1/35133] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-06-25 01:08:55,736 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:55,921 [Listener at 0.0.0.0/45907] INFO  rpc.RpcClient (RpcClient.java:createVolume(466)) - Creating Volume: vol1, with user00441 as owner and space quota set to -1 bytes, counts quota set to -1
2022-06-25 01:08:56,127 [OM StateMachine ApplyTransaction Thread - 0] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(195)) - created volume:vol1 for user:user00441
2022-06-25 01:08:56,194 [Listener at 127.0.0.1/35133] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.3.0-SNAPSHOT/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
2022-06-25 01:08:56,194 [Listener at 127.0.0.1/35133] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2022-06-25 01:08:56,222 [Listener at 127.0.0.1/35133] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:08:56,222 [Listener at 127.0.0.1/35133] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:08:56,222 [Listener at 127.0.0.1/35133] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(82)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2022-06-25 01:08:56,226 [Listener at 0.0.0.0/45907] INFO  rpc.RpcClient (RpcClient.java:createBucket(666)) - Creating Bucket: vol1/bucket1, with the Bucket Layout LEGACY, runner as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
2022-06-25 01:08:56,241 [OM StateMachine ApplyTransaction Thread - 0] INFO  bucket.OMBucketCreateRequest (OMBucketCreateRequest.java:validateAndUpdateCache(260)) - created bucket: bucket1 of layout LEGACY in volume: vol1
2022-06-25 01:08:56,320 [IPC Server handler 0 on default port 44789] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(127)) - Allocate a batch for containerId, change lastId from 0 to 1000.
2022-06-25 01:08:56,321 [IPC Server handler 0 on default port 44789] WARN  ha.SequenceIdGenerator (SequenceIdGenerator.java:allocateBatch(235)) - Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
2022-06-25 01:08:56,321 [IPC Server handler 0 on default port 44789] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(127)) - Allocate a batch for localId, change lastId from 109611004723200000 to 109611004723201000.
2022-06-25 01:08:56,646 [Listener at 127.0.0.1/35133] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 422 ms to scan 7 urls, producing 131 keys and 316 values 
2022-06-25 01:08:56,647 [Listener at 127.0.0.1/35133] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(347)) - upgrade localId to 109611004723200000
2022-06-25 01:08:56,647 [Listener at 127.0.0.1/35133] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(357)) - upgrade delTxnId to 0
2022-06-25 01:08:56,648 [Listener at 127.0.0.1/35133] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(374)) - upgrade containerId to 0
2022-06-25 01:08:56,648 [Listener at 127.0.0.1/35133] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(218)) - Init the HA SequenceIdGenerator.
2022-06-25 01:08:56,648 [Listener at 127.0.0.1/35133] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(149)) - Entering startup safe mode.
2022-06-25 01:08:56,648 [Listener at 127.0.0.1/35133] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2022-06-25 01:08:56,649 [Listener at 127.0.0.1/35133] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(78)) - No pipeline exists in current db
2022-06-25 01:08:56,649 [Listener at 127.0.0.1/35133] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2022-06-25 01:08:56,649 [Listener at 127.0.0.1/35133] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2022-06-25 01:08:56,649 [Listener at 127.0.0.1/35133] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(127)) - Starting RatisPipelineUtilsThread.
2022-06-25 01:08:56,649 [Listener at 127.0.0.1/35133] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(68)) - Starting BackgroundPipelineScrubber Service.
2022-06-25 01:08:56,650 [Listener at 127.0.0.1/35133] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2022-06-25 01:08:56,650 [Listener at 127.0.0.1/35133] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2022-06-25 01:08:56,650 [Listener at 127.0.0.1/35133] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(68)) - Starting ExpiredContainerReplicaOpScrubber Service.
2022-06-25 01:08:56,650 [Listener at 127.0.0.1/35133] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2022-06-25 01:08:56,650 [Listener at 127.0.0.1/35133] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(73)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2022-06-25 01:08:56,651 [Listener at 127.0.0.1/35133] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2022-06-25 01:08:56,651 [Listener at 127.0.0.1/35133] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2022-06-25 01:08:56,651 [Listener at 127.0.0.1/35133] INFO  replication.ReplicationManager (ReplicationManager.java:start(179)) - Starting Replication Monitor Thread.
2022-06-25 01:08:56,652 [Listener at 127.0.0.1/35133] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 0
2022-06-25 01:08:56,652 [Listener at 127.0.0.1/35133] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(156)) - Total pipeline count is 0, healthy pipeline threshold count is 1
2022-06-25 01:08:56,652 [Listener at 127.0.0.1/35133] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2022-06-25 01:08:56,654 [Listener at 127.0.0.1/35133] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-06-25 01:08:56,655 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 0
2022-06-25 01:08:56,655 [Listener at 0.0.0.0/37947] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-06-25 01:08:56,656 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 0
2022-06-25 01:08:56,657 [Listener at 0.0.0.0/38175] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-06-25 01:08:56,659 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 0
2022-06-25 01:08:56,738 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:56,739 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:56,836 [Listener at 0.0.0.0/42961] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2022-06-25 01:08:56,837 [Listener at 0.0.0.0/42961] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(400)) - 
Container Balancer status:
Key                            Value
Running                        false
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2022-06-25 01:08:56,837 [Listener at 0.0.0.0/42961] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2022-06-25 01:08:56,837 [Listener at 0.0.0.0/42961] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2022-06-25 01:08:56,837 [Listener at 0.0.0.0/42961] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1418)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:42961
2022-06-25 01:08:56,837 [Listener at 0.0.0.0/42961] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - StorageContainerManager metrics system started (again)
2022-06-25 01:08:56,944 [Listener at 0.0.0.0/42961] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(169)) - RPC server for Client  is listening at /0.0.0.0:42961
2022-06-25 01:08:56,945 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-06-25 01:08:56,945 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 0: starting
2022-06-25 01:08:56,968 [Listener at 0.0.0.0/42961] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1433)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:38175
2022-06-25 01:08:56,968 [Listener at 0.0.0.0/42961] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(151)) - RPC server for Block Protocol is listening at /0.0.0.0:38175
2022-06-25 01:08:56,968 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-06-25 01:08:56,968 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 0: starting
2022-06-25 01:08:57,002 [Listener at 0.0.0.0/42961] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(185)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:37947
2022-06-25 01:08:57,007 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-06-25 01:08:57,008 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 0: starting
2022-06-25 01:08:57,030 [Listener at 0.0.0.0/42961] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for scm at: http://0.0.0.0:0
2022-06-25 01:08:57,031 [Listener at 0.0.0.0/42961] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-06-25 01:08:57,031 [Listener at 0.0.0.0/42961] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-06-25 01:08:57,044 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6eb62591] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-06-25 01:08:57,083 [Listener at 0.0.0.0/42961] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-06-25 01:08:57,131 [Listener at 0.0.0.0/42961] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1029)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-06-25 01:08:57,132 [Listener at 0.0.0.0/42961] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1005)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2022-06-25 01:08:57,132 [Listener at 0.0.0.0/42961] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-06-25 01:08:57,132 [Listener at 0.0.0.0/42961] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-06-25 01:08:57,132 [Listener at 0.0.0.0/42961] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1248)) - Jetty bound to port 39423
2022-06-25 01:08:57,132 [Listener at 0.0.0.0/42961] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-06-25 01:08:57,286 [Listener at 0.0.0.0/42961] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-06-25 01:08:57,286 [Listener at 0.0.0.0/42961] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-06-25 01:08:57,286 [Listener at 0.0.0.0/42961] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-06-25 01:08:57,290 [Listener at 0.0.0.0/42961] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@59df6269{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-06-25 01:08:57,291 [Listener at 0.0.0.0/42961] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@607411a5{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2022-06-25 01:08:57,360 [Listener at 0.0.0.0/42961] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@77163ecc{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2022-06-25 01:08:57,372 [Listener at 0.0.0.0/42961] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@3df05b20{HTTP/1.1, (http/1.1)}{0.0.0.0:39423}
2022-06-25 01:08:57,373 [Listener at 0.0.0.0/42961] INFO  server.Server (Server.java:doStart(415)) - Started @371269ms
2022-06-25 01:08:57,373 [Listener at 0.0.0.0/42961] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-06-25 01:08:57,374 [Listener at 0.0.0.0/42961] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of scm listening at http://0.0.0.0:39423
2022-06-25 01:08:57,374 [Listener at 0.0.0.0/42961] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-06-25 01:08:57,380 [Listener at 0.0.0.0/42961] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(115)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2022-06-25 01:08:57,380 [Listener at 0.0.0.0/42961] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(226)) - Configuration does not have ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2022-06-25 01:08:57,380 [Listener at 0.0.0.0/42961] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(254)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2022-06-25 01:08:57,380 [Listener at 0.0.0.0/42961] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(261)) - OM Node ID is not set. Setting it to the default ID: om1
2022-06-25 01:08:57,380 [Listener at 0.0.0.0/42961] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-06-25 01:08:57,380 [Listener at 0.0.0.0/42961] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(82)) - Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
2022-06-25 01:08:57,740 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:57,742 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:58,027 [Listener at 0.0.0.0/42961] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 646 ms to scan 2 urls, producing 152 keys and 429 values [using 2 cores]
2022-06-25 01:08:58,027 [Listener at 0.0.0.0/42961] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(115)) - Skipping Upgrade Action MockOmUpgradeAction since it has been finalized.
2022-06-25 01:08:58,027 [Listener at 0.0.0.0/42961] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-06-25 01:08:58,027 [Listener at 0.0.0.0/42961] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:38175]
2022-06-25 01:08:58,028 [Listener at 0.0.0.0/42961] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:38175]
2022-06-25 01:08:58,135 [Listener at 0.0.0.0/42961] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-06-25 01:08:58,135 [Listener at 0.0.0.0/42961] INFO  codec.OmKeyInfoCodec (OmKeyInfoCodec.java:<init>(49)) - OmKeyInfoCodec ignorePipeline = true
2022-06-25 01:08:58,135 [Listener at 0.0.0.0/42961] INFO  codec.RepeatedOmKeyInfoCodec (RepeatedOmKeyInfoCodec.java:<init>(41)) - RepeatedOmKeyInfoCodec ignorePipeline = true
2022-06-25 01:08:58,518 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5022401430ns, electionTimeout:5001ms
2022-06-25 01:08:58,518 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: shutdown fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:08:58,518 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2022-06-25 01:08:58,518 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:08:58,518 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: start fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection157
2022-06-25 01:08:58,558 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection157] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection157 ELECTION round 0: submit vote requests at term 2 for -1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|priority:0], old=null
2022-06-25 01:08:58,591 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: receive requestVote(ELECTION, fc692a40-1ae9-40b7-8d63-7e46f51df1ef, group-B6B9DF3CEF32, 2, (t:0, i:0))
2022-06-25 01:08:58,591 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FOLLOWER: accept ELECTION from fc692a40-1ae9-40b7-8d63-7e46f51df1ef: our priority 0 <= candidate's priority 0
2022-06-25 01:08:58,591 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:fc692a40-1ae9-40b7-8d63-7e46f51df1ef
2022-06-25 01:08:58,591 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: shutdown 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:08:58,594 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: start 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:08:58,594 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState was interrupted
2022-06-25 01:08:58,600 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: receive requestVote(ELECTION, fc692a40-1ae9-40b7-8d63-7e46f51df1ef, group-B6B9DF3CEF32, 2, (t:0, i:0))
2022-06-25 01:08:58,600 [grpc-default-executor-8] INFO  impl.VoteContext (VoteContext.java:log(48)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FOLLOWER: reject ELECTION from fc692a40-1ae9-40b7-8d63-7e46f51df1ef: our priority 1 > candidate's priority 0
2022-06-25 01:08:58,600 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:fc692a40-1ae9-40b7-8d63-7e46f51df1ef
2022-06-25 01:08:58,600 [grpc-default-executor-8] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: shutdown 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:08:58,604 [grpc-default-executor-8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: start 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:08:58,606 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState was interrupted
2022-06-25 01:08:58,607 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32 replies to ELECTION vote request: fc692a40-1ae9-40b7-8d63-7e46f51df1ef<-4943f96b-6a06-411a-b0ee-4ab66ab6f7f9#0:OK-t2. Peer's state: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32:t2, leader=null, voted=fc692a40-1ae9-40b7-8d63-7e46f51df1ef, raftlog=4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:08:58,615 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32 replies to ELECTION vote request: fc692a40-1ae9-40b7-8d63-7e46f51df1ef<-97d08340-a146-41c4-a759-b3b136c7fb6d#0:FAIL-t2. Peer's state: 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32:t2, leader=null, voted=null, raftlog=97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:08:58,666 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection157] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection157: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-06-25 01:08:58,666 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection157] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: fc692a40-1ae9-40b7-8d63-7e46f51df1ef<-4943f96b-6a06-411a-b0ee-4ab66ab6f7f9#0:OK-t2
2022-06-25 01:08:58,666 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection157] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: fc692a40-1ae9-40b7-8d63-7e46f51df1ef<-97d08340-a146-41c4-a759-b3b136c7fb6d#0:FAIL-t2
2022-06-25 01:08:58,666 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection157] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection157 ELECTION round 0: result REJECTED
2022-06-25 01:08:58,666 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection157] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
2022-06-25 01:08:58,667 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection157] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: shutdown fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection157
2022-06-25 01:08:58,667 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection157] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: start fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:08:58,740 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:58,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:08:59,156 [Listener at 0.0.0.0/42961] INFO  om.OzoneManager (OzoneManager.java:instantiateServices(692)) - S3 Multi-Tenancy is disabled
2022-06-25 01:08:59,157 [Listener at 0.0.0.0/42961] INFO  om.OzoneManager (OzoneManager.java:addS3GVolumeToDB(4259)) - Created Volume s3v With Owner runner required for S3Gateway operations.
2022-06-25 01:08:59,157 [Listener at 0.0.0.0/42961] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(237)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2022-06-25 01:08:59,157 [Listener at 0.0.0.0/42961] WARN  utils.OzoneManagerRatisUtils (OzoneManagerRatisUtils.java:getOMRatisSnapshotDirectory(431)) - ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
2022-06-25 01:08:59,157 [Listener at 0.0.0.0/42961] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:08:59,157 [Listener at 0.0.0.0/42961] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:08:59,158 [Listener at 0.0.0.0/42961] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(237)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2022-06-25 01:08:59,158 [Listener at 0.0.0.0/42961] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(159)) - Instantiating OM Ratis server with groupID: omServiceIdDefault and peers: localhost:45963
2022-06-25 01:08:59,158 [Listener at 0.0.0.0/42961] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:loadSnapshotInfoFromDB(632)) - LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
2022-06-25 01:08:59,159 [Listener at 0.0.0.0/42961] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-06-25 01:08:59,159 [Listener at 0.0.0.0/42961] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-06-25 01:08:59,159 [Listener at 0.0.0.0/42961] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = -1 (default)
2022-06-25 01:08:59,159 [Listener at 0.0.0.0/42961] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 45963 (custom)
2022-06-25 01:08:59,159 [Listener at 0.0.0.0/42961] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = -1 (default)
2022-06-25 01:08:59,159 [Listener at 0.0.0.0/42961] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 45963 (custom)
2022-06-25 01:08:59,159 [Listener at 0.0.0.0/42961] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 45963 (custom)
2022-06-25 01:08:59,159 [Listener at 0.0.0.0/42961] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 33554432 (custom)
2022-06-25 01:08:59,159 [Listener at 0.0.0.0/42961] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:08:59,160 [Listener at 0.0.0.0/42961] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2022-06-25 01:08:59,160 [Listener at 0.0.0.0/42961] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2022-06-25 01:08:59,160 [Listener at 0.0.0.0/42961] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-06-25 01:08:59,160 [Listener at 0.0.0.0/42961] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-06-25 01:08:59,161 [Listener at 0.0.0.0/42961] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-06-25 01:08:59,161 [Listener at 0.0.0.0/42961] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-06-25 01:08:59,161 [Listener at 0.0.0.0/42961] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-06-25 01:08:59,161 [Listener at 0.0.0.0/42961] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2022-06-25 01:08:59,161 [Listener at 0.0.0.0/42961] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:08:59,161 [Listener at 0.0.0.0/42961] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/ozone-meta/ratis] (custom)
2022-06-25 01:08:59,163 [Listener at 0.0.0.0/42961] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - om1: addNew group-C5BA1605619E:[om1|rpc:localhost:45963|priority:0] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@38cbe0a7[Not completed]
2022-06-25 01:08:59,163 [Listener at 0.0.0.0/42961] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(1961)) - OzoneManager Ratis server initialized at port 45963
2022-06-25 01:08:59,164 [Listener at 0.0.0.0/42961] INFO  om.OzoneManager (OzoneManager.java:getRpcServer(1081)) - Creating RPC Server
2022-06-25 01:08:59,164 [pool-4355-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - om1: new RaftServerImpl for group-C5BA1605619E:[om1|rpc:localhost:45963|priority:0] with OzoneManagerStateMachine:uninitialized
2022-06-25 01:08:59,164 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2022-06-25 01:08:59,165 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 1200ms (custom)
2022-06-25 01:08:59,165 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:08:59,165 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2022-06-25 01:08:59,165 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:08:59,165 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:08:59,165 [pool-4355-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - om1@group-C5BA1605619E: ConfigurationManager, init=-1: [om1|rpc:localhost:45963|priority:0], old=null, confs=<EMPTY_MAP>
2022-06-25 01:08:59,165 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/ozone-meta/ratis] (custom)
2022-06-25 01:08:59,165 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:08:59,165 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:08:59,165 [pool-4355-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
2022-06-25 01:08:59,176 [pool-4355-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:08:59,269 [pool-4355-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
2022-06-25 01:08:59,269 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 120s (custom)
2022-06-25 01:08:59,269 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:08:59,270 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:08:59,270 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:08:59,270 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:08:59,270 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2022-06-25 01:08:59,270 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:08:59,270 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:08:59,270 [pool-4355-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e
2022-06-25 01:08:59,270 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2022-06-25 01:08:59,270 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 4096 (default)
2022-06-25 01:08:59,270 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2022-06-25 01:08:59,270 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2022-06-25 01:08:59,270 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:08:59,270 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:08:59,270 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:08:59,270 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:08:59,300 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2022-06-25 01:08:59,300 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:08:59,301 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2022-06-25 01:08:59,301 [pool-4355-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:08:59,301 [pool-4355-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:08:59,306 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:08:59,306 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2022-06-25 01:08:59,307 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = -1 (default)
2022-06-25 01:08:59,307 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = true (custom)
2022-06-25 01:08:59,307 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 300s (custom)
2022-06-25 01:08:59,307 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:08:59,307 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:08:59,307 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:08:59,307 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:08:59,307 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:08:59,307 [pool-4355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:08:59,740 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:08:59,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:00,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:00,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:01,340 [Listener at 0.0.0.0/42961] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 2125 ms to scan 19 urls, producing 66 keys and 4066 values [using 2 cores]
2022-06-25 01:09:01,341 [Listener at 0.0.0.0/42961] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-06-25 01:09:01,355 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 0
2022-06-25 01:09:01,509 [Listener at 127.0.0.1/39461] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2022-06-25 01:09:01,559 [Listener at 127.0.0.1/39461] INFO  om.OzoneManager (OzoneManager.java:start(1465)) - OzoneManager RPC server is listening at localhost/127.0.0.1:39461
2022-06-25 01:09:01,559 [Listener at 127.0.0.1/39461] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(554)) - Starting OzoneManagerRatisServer om1 at port 45963
2022-06-25 01:09:01,559 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - om1@group-C5BA1605619E: start as a follower, conf=-1: [om1|rpc:localhost:45963|priority:0], old=null
2022-06-25 01:09:01,559 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:01,559 [om1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-FollowerState
2022-06-25 01:09:01,560 [om1-impl-thread1] ERROR util.JmxRegister (JmxRegister.java:tryRegister(40)) - Failed to register JMX Bean with name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
javax.management.InstanceAlreadyExistsException: Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.ratis.util.JmxRegister.tryRegister(JmxRegister.java:38)
	at org.apache.ratis.util.JmxRegister.register(JmxRegister.java:56)
	at org.apache.ratis.server.impl.RaftServerImpl.registerMBean(RaftServerImpl.java:329)
	at org.apache.ratis.server.impl.RaftServerImpl.start(RaftServerImpl.java:320)
	at org.apache.ratis.util.ConcurrentUtils.lambda$null$3(ConcurrentUtils.java:162)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2022-06-25 01:09:01,560 [om1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id="om1"
2022-06-25 01:09:01,560 [Listener at 127.0.0.1/39461] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - om1: start RPC server
2022-06-25 01:09:01,565 [Listener at 127.0.0.1/39461] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - om1: GrpcService started, listening on 45963
2022-06-25 01:09:01,578 [Listener at 127.0.0.1/39461] INFO  om.OzoneManager (OzoneManager.java:start(1481)) - Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
2022-06-25 01:09:01,579 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@596aab5f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-om1: Started
2022-06-25 01:09:01,581 [Listener at 127.0.0.1/39461] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2022-06-25 01:09:01,581 [Listener at 127.0.0.1/39461] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-06-25 01:09:01,582 [Listener at 127.0.0.1/39461] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-06-25 01:09:01,599 [Listener at 127.0.0.1/39461] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-06-25 01:09:01,600 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1029)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-06-25 01:09:01,600 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1005)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2022-06-25 01:09:01,600 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-06-25 01:09:01,600 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-06-25 01:09:01,601 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1248)) - Jetty bound to port 32789
2022-06-25 01:09:01,601 [Listener at 127.0.0.1/39461] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-06-25 01:09:01,669 [Listener at 127.0.0.1/39461] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-06-25 01:09:01,670 [Listener at 127.0.0.1/39461] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-06-25 01:09:01,670 [Listener at 127.0.0.1/39461] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-06-25 01:09:01,670 [Listener at 127.0.0.1/39461] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@4684e1b6{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-06-25 01:09:01,670 [Listener at 127.0.0.1/39461] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@518addae{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2022-06-25 01:09:01,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:01,759 [Listener at 127.0.0.1/39461] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@a1afb0e{ozoneManager,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2022-06-25 01:09:01,858 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:01,896 [Listener at 127.0.0.1/39461] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@78b1550{HTTP/1.1, (http/1.1)}{0.0.0.0:32789}
2022-06-25 01:09:01,896 [Listener at 127.0.0.1/39461] INFO  server.Server (Server.java:doStart(415)) - Started @375793ms
2022-06-25 01:09:02,515 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@3534c0d2] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-97d08340-a146-41c4-a759-b3b136c7fb6d: Detected pause in JVM or host machine (eg GC): pause of approximately 286756324ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=391ms
GC pool 'PS Scavenge' had collection(s): count=1 time=52ms
2022-06-25 01:09:02,516 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@59be0973] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-om1: Detected pause in JVM or host machine (eg GC): pause of approximately 318557150ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=391ms
GC pool 'PS Scavenge' had collection(s): count=1 time=52ms
2022-06-25 01:09:02,516 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@4240468b] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-3c6128f4-7bf2-4a55-83fb-21add5186158: Detected pause in JVM or host machine (eg GC): pause of approximately 361763922ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=391ms
GC pool 'PS Scavenge' had collection(s): count=1 time=52ms
2022-06-25 01:09:02,516 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@596aab5f] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-om1: Detected pause in JVM or host machine (eg GC): pause of approximately 437344721ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=391ms
GC pool 'PS Scavenge' had collection(s): count=1 time=52ms
2022-06-25 01:09:02,636 [Listener at 127.0.0.1/39461] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-06-25 01:09:02,637 [Listener at 127.0.0.1/39461] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of ozoneManager listening at http://0.0.0.0:32789
2022-06-25 01:09:02,637 [om1@group-C5BA1605619E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1077913280ns, electionTimeout:1077ms
2022-06-25 01:09:02,637 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - om1: shutdown om1@group-C5BA1605619E-FollowerState
2022-06-25 01:09:02,638 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:09:02,653 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-06-25 01:09:02,662 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 0: starting
2022-06-25 01:09:02,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:02,798 [Listener at 127.0.0.1/39461] INFO  om.OzoneManager (OzoneManager.java:startTrashEmptier(1905)) - Trash Interval set to 0. Files deleted won't move to trash
2022-06-25 01:09:02,803 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3fe5abd6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-06-25 01:09:02,851 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:02,851 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderElection158
2022-06-25 01:09:02,880 [om1@group-C5BA1605619E-LeaderElection158] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - om1@group-C5BA1605619E-LeaderElection158 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:localhost:45963|priority:0], old=null
2022-06-25 01:09:02,880 [om1@group-C5BA1605619E-LeaderElection158] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - om1@group-C5BA1605619E-LeaderElection158 ELECTION round 0: result PASSED (term=1)
2022-06-25 01:09:02,881 [om1@group-C5BA1605619E-LeaderElection158] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - om1: shutdown om1@group-C5BA1605619E-LeaderElection158
2022-06-25 01:09:02,881 [om1@group-C5BA1605619E-LeaderElection158] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-06-25 01:09:02,881 [om1@group-C5BA1605619E-LeaderElection158] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 3611ms
2022-06-25 01:09:02,881 [om1@group-C5BA1605619E-LeaderElection158] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-25 01:09:02,881 [om1@group-C5BA1605619E-LeaderElection158] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2022-06-25 01:09:02,881 [om1@group-C5BA1605619E-LeaderElection158] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2022-06-25 01:09:02,881 [om1@group-C5BA1605619E-LeaderElection158] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 10s (default)
2022-06-25 01:09:02,881 [om1@group-C5BA1605619E-LeaderElection158] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-25 01:09:02,881 [om1@group-C5BA1605619E-LeaderElection158] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-25 01:09:02,881 [om1@group-C5BA1605619E-LeaderElection158] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2022-06-25 01:09:02,881 [om1@group-C5BA1605619E-LeaderElection158] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-25 01:09:02,881 [om1@group-C5BA1605619E-LeaderElection158] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderStateImpl
2022-06-25 01:09:02,881 [om1@group-C5BA1605619E-LeaderElection158] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:02,888 [om1@group-C5BA1605619E-LeaderElection158] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - om1@group-C5BA1605619E: set configuration 0: [om1|rpc:localhost:45963|admin:|client:|dataStream:|priority:0], old=null
2022-06-25 01:09:02,895 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
2022-06-25 01:09:02,960 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:02,970 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:notifyConfigurationChanged(192)) - Received Configuration change notification from Ratis. New Peer list:
[id: "om1"
address: "localhost:45963"
]
2022-06-25 01:09:02,979 [Listener at 127.0.0.1/39461] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:02,979 [Listener at 127.0.0.1/39461] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:02,979 [Listener at 127.0.0.1/39461] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-06-25 01:09:03,025 [Listener at 127.0.0.1/39461] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net ip:10.1.0.8
2022-06-25 01:09:03,269 [Listener at 127.0.0.1/39461] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(82)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2022-06-25 01:09:03,401 [Listener at 127.0.0.1/39461] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 117 ms to scan 7 urls, producing 131 keys and 316 values 
2022-06-25 01:09:03,402 [Listener at 127.0.0.1/39461] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(237)) - Datanode State Machine Task Thread Pool size 2
2022-06-25 01:09:03,403 [Listener at 127.0.0.1/39461] INFO  volume.HddsVolume (HddsVolume.java:<init>(116)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-0/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-06-25 01:09:03,403 [Listener at 127.0.0.1/39461] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-0/data-0/containers/hdds to VolumeSet
2022-06-25 01:09:03,403 [Listener at 127.0.0.1/39461] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-0/data-0/containers/hdds
2022-06-25 01:09:03,408 [Listener at 127.0.0.1/39461] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-0/data-0/containers/hdds
2022-06-25 01:09:03,468 [Listener at 127.0.0.1/39461] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-0/data/ratis to VolumeSet
2022-06-25 01:09:03,468 [Listener at 127.0.0.1/39461] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-0/data/ratis
2022-06-25 01:09:03,469 [Listener at 127.0.0.1/39461] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-0/data/ratis
2022-06-25 01:09:03,614 [Thread-6020] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-0/data-0/containers/hdds
2022-06-25 01:09:03,615 [Listener at 127.0.0.1/39461] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(266)) - Build ContainerSet costs 0s
2022-06-25 01:09:03,616 [Listener at 127.0.0.1/39461] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-06-25 01:09:03,616 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-06-25 01:09:03,616 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-06-25 01:09:03,616 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-06-25 01:09:03,616 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-06-25 01:09:03,616 [Listener at 127.0.0.1/39461] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-06-25 01:09:03,617 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:03,617 [Listener at 127.0.0.1/39461] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-06-25 01:09:03,617 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:09:03,617 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-06-25 01:09:03,617 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-06-25 01:09:03,628 [Listener at 127.0.0.1/39461] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-06-25 01:09:03,628 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-06-25 01:09:03,628 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-06-25 01:09:03,629 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:03,629 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:03,629 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-0/data/ratis] (custom)
2022-06-25 01:09:03,639 [Listener at 127.0.0.1/39461] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-06-25 01:09:03,640 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5035444691ns, electionTimeout:5021ms
2022-06-25 01:09:03,640 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: shutdown 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:03,640 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2022-06-25 01:09:03,640 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:03,640 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: start 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection159
2022-06-25 01:09:03,642 [Listener at 127.0.0.1/39461] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-06-25 01:09:03,642 [Listener at 127.0.0.1/39461] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-06-25 01:09:03,643 [Listener at 127.0.0.1/39461] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-06-25 01:09:03,644 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection159] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection159 ELECTION round 0: submit vote requests at term 3 for -1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:09:03,646 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5039376807ns, electionTimeout:5038ms
2022-06-25 01:09:03,646 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: shutdown 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:03,646 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2022-06-25 01:09:03,707 [Listener at 127.0.0.1/39461] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-06-25 01:09:03,708 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1029)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-06-25 01:09:03,709 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1005)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-06-25 01:09:03,709 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-06-25 01:09:03,709 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-06-25 01:09:03,709 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1248)) - Jetty bound to port 37849
2022-06-25 01:09:03,709 [Listener at 127.0.0.1/39461] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-06-25 01:09:03,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:03,752 [Listener at 127.0.0.1/39461] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-06-25 01:09:03,752 [Listener at 127.0.0.1/39461] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-06-25 01:09:03,752 [Listener at 127.0.0.1/39461] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-06-25 01:09:03,769 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5102824759ns, electionTimeout:5096ms
2022-06-25 01:09:03,770 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: shutdown fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:03,770 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2022-06-25 01:09:03,773 [Listener at 127.0.0.1/39461] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@2d064cf5{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-06-25 01:09:03,773 [Listener at 127.0.0.1/39461] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@1f3c14af{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-06-25 01:09:03,778 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:03,778 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: start 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection160
2022-06-25 01:09:03,853 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection160] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection160 ELECTION round 0: submit vote requests at term 3 for -1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:09:03,885 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: receive requestVote(ELECTION, 97d08340-a146-41c4-a759-b3b136c7fb6d, group-B6B9DF3CEF32, 3, (t:0, i:0))
2022-06-25 01:09:03,886 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(48)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-CANDIDATE: reject ELECTION from 97d08340-a146-41c4-a759-b3b136c7fb6d: already has voted for 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9 at current term 3
2022-06-25 01:09:03,886 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32 replies to ELECTION vote request: 97d08340-a146-41c4-a759-b3b136c7fb6d<-4943f96b-6a06-411a-b0ee-4ab66ab6f7f9#0:FAIL-t3. Peer's state: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32:t3, leader=null, voted=4943f96b-6a06-411a-b0ee-4ab66ab6f7f9, raftlog=4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:09:03,909 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:03,909 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: start fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection161
2022-06-25 01:09:03,921 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: receive requestVote(ELECTION, 97d08340-a146-41c4-a759-b3b136c7fb6d, group-B6B9DF3CEF32, 3, (t:0, i:0))
2022-06-25 01:09:03,924 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: receive requestVote(ELECTION, 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9, group-B6B9DF3CEF32, 3, (t:0, i:0))
2022-06-25 01:09:03,925 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(48)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-CANDIDATE: reject ELECTION from 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: already has voted for 97d08340-a146-41c4-a759-b3b136c7fb6d at current term 3
2022-06-25 01:09:03,925 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32 replies to ELECTION vote request: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9<-97d08340-a146-41c4-a759-b3b136c7fb6d#0:FAIL-t3. Peer's state: 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32:t3, leader=null, voted=97d08340-a146-41c4-a759-b3b136c7fb6d, raftlog=97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:09:03,931 [grpc-default-executor-8] INFO  impl.VoteContext (VoteContext.java:log(48)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-CANDIDATE: reject ELECTION from 97d08340-a146-41c4-a759-b3b136c7fb6d: already has voted for fc692a40-1ae9-40b7-8d63-7e46f51df1ef at current term 3
2022-06-25 01:09:03,931 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32 replies to ELECTION vote request: 97d08340-a146-41c4-a759-b3b136c7fb6d<-fc692a40-1ae9-40b7-8d63-7e46f51df1ef#0:FAIL-t3. Peer's state: fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32:t3, leader=null, voted=fc692a40-1ae9-40b7-8d63-7e46f51df1ef, raftlog=fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|priority:0], old=null
2022-06-25 01:09:03,931 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection161] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection161 ELECTION round 0: submit vote requests at term 3 for -1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|priority:0], old=null
2022-06-25 01:09:03,932 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection160] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection160: ELECTION REJECTED received 1 response(s) and 0 exception(s):
2022-06-25 01:09:03,932 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection160] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9<-97d08340-a146-41c4-a759-b3b136c7fb6d#0:FAIL-t3
2022-06-25 01:09:03,932 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection160] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection160 ELECTION round 0: result REJECTED
2022-06-25 01:09:03,932 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection160] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
2022-06-25 01:09:03,932 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection160] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: shutdown 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection160
2022-06-25 01:09:03,932 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection160] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: start 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:03,933 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: receive requestVote(ELECTION, 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9, group-B6B9DF3CEF32, 3, (t:0, i:0))
2022-06-25 01:09:03,933 [grpc-default-executor-8] INFO  impl.VoteContext (VoteContext.java:log(48)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-CANDIDATE: reject ELECTION from 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: already has voted for fc692a40-1ae9-40b7-8d63-7e46f51df1ef at current term 3
2022-06-25 01:09:03,933 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32 replies to ELECTION vote request: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9<-fc692a40-1ae9-40b7-8d63-7e46f51df1ef#0:FAIL-t3. Peer's state: fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32:t3, leader=null, voted=fc692a40-1ae9-40b7-8d63-7e46f51df1ef, raftlog=fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|priority:0], old=null
2022-06-25 01:09:03,940 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection159] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection159: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-06-25 01:09:03,940 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection159] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 97d08340-a146-41c4-a759-b3b136c7fb6d<-4943f96b-6a06-411a-b0ee-4ab66ab6f7f9#0:FAIL-t3
2022-06-25 01:09:03,940 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection159] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 97d08340-a146-41c4-a759-b3b136c7fb6d<-fc692a40-1ae9-40b7-8d63-7e46f51df1ef#0:FAIL-t3
2022-06-25 01:09:03,940 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection159] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection159 ELECTION round 0: result REJECTED
2022-06-25 01:09:03,940 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection159] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
2022-06-25 01:09:03,940 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection159] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: shutdown 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection159
2022-06-25 01:09:03,940 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection159] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: start 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:03,940 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: receive requestVote(ELECTION, fc692a40-1ae9-40b7-8d63-7e46f51df1ef, group-B6B9DF3CEF32, 3, (t:0, i:0))
2022-06-25 01:09:03,941 [grpc-default-executor-8] INFO  impl.VoteContext (VoteContext.java:log(48)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FOLLOWER: reject ELECTION from fc692a40-1ae9-40b7-8d63-7e46f51df1ef: already has voted for 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9 at current term 3
2022-06-25 01:09:03,941 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32 replies to ELECTION vote request: fc692a40-1ae9-40b7-8d63-7e46f51df1ef<-4943f96b-6a06-411a-b0ee-4ab66ab6f7f9#0:FAIL-t3. Peer's state: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32:t3, leader=null, voted=4943f96b-6a06-411a-b0ee-4ab66ab6f7f9, raftlog=4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:09:03,942 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: receive requestVote(ELECTION, fc692a40-1ae9-40b7-8d63-7e46f51df1ef, group-B6B9DF3CEF32, 3, (t:0, i:0))
2022-06-25 01:09:03,942 [grpc-default-executor-8] INFO  impl.VoteContext (VoteContext.java:log(48)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FOLLOWER: reject ELECTION from fc692a40-1ae9-40b7-8d63-7e46f51df1ef: already has voted for 97d08340-a146-41c4-a759-b3b136c7fb6d at current term 3
2022-06-25 01:09:03,942 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32 replies to ELECTION vote request: fc692a40-1ae9-40b7-8d63-7e46f51df1ef<-97d08340-a146-41c4-a759-b3b136c7fb6d#0:FAIL-t3. Peer's state: 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32:t3, leader=null, voted=97d08340-a146-41c4-a759-b3b136c7fb6d, raftlog=97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:09:03,943 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection161] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection161: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-06-25 01:09:03,943 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection161] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: fc692a40-1ae9-40b7-8d63-7e46f51df1ef<-4943f96b-6a06-411a-b0ee-4ab66ab6f7f9#0:FAIL-t3
2022-06-25 01:09:03,943 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection161] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: fc692a40-1ae9-40b7-8d63-7e46f51df1ef<-97d08340-a146-41c4-a759-b3b136c7fb6d#0:FAIL-t3
2022-06-25 01:09:03,943 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection161] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection161 ELECTION round 0: result REJECTED
2022-06-25 01:09:03,943 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection161] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
2022-06-25 01:09:03,943 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection161] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: shutdown fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection161
2022-06-25 01:09:03,943 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection161] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: start fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:03,961 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:04,747 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:04,970 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:05,688 [Listener at 127.0.0.1/39461] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@7b22deda{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-37849-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-3318394600604285107/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-25 01:09:05,742 [Listener at 127.0.0.1/39461] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@46b4a75f{HTTP/1.1, (http/1.1)}{0.0.0.0:37849}
2022-06-25 01:09:05,742 [Listener at 127.0.0.1/39461] INFO  server.Server (Server.java:doStart(415)) - Started @379639ms
2022-06-25 01:09:05,742 [Listener at 127.0.0.1/39461] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-06-25 01:09:05,743 [Listener at 127.0.0.1/39461] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:37849
2022-06-25 01:09:05,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:05,777 [Listener at 127.0.0.1/39461] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:05,777 [Listener at 127.0.0.1/39461] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:05,777 [Listener at 127.0.0.1/39461] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-06-25 01:09:05,786 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(492)) - Ozone container server started.
2022-06-25 01:09:05,810 [Listener at 127.0.0.1/39461] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net ip:10.1.0.8
2022-06-25 01:09:05,811 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@176b7187] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-06-25 01:09:05,828 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-0/meta/datanode.id
2022-06-25 01:09:05,899 [Listener at 127.0.0.1/39461] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(82)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2022-06-25 01:09:05,970 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:05,986 [Listener at 127.0.0.1/39461] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 86 ms to scan 7 urls, producing 131 keys and 316 values 
2022-06-25 01:09:05,987 [Listener at 127.0.0.1/39461] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(237)) - Datanode State Machine Task Thread Pool size 2
2022-06-25 01:09:05,988 [Listener at 127.0.0.1/39461] INFO  volume.HddsVolume (HddsVolume.java:<init>(116)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-1/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-06-25 01:09:05,989 [Listener at 127.0.0.1/39461] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-1/data-0/containers/hdds to VolumeSet
2022-06-25 01:09:05,989 [Listener at 127.0.0.1/39461] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-1/data-0/containers/hdds
2022-06-25 01:09:06,006 [Listener at 127.0.0.1/39461] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-1/data-0/containers/hdds
2022-06-25 01:09:06,029 [Listener at 127.0.0.1/39461] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-1/data/ratis to VolumeSet
2022-06-25 01:09:06,029 [Listener at 127.0.0.1/39461] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-1/data/ratis
2022-06-25 01:09:06,029 [Listener at 127.0.0.1/39461] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-1/data/ratis
2022-06-25 01:09:06,048 [Thread-6090] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-1/data-0/containers/hdds
2022-06-25 01:09:06,048 [Listener at 127.0.0.1/39461] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(266)) - Build ContainerSet costs 0s
2022-06-25 01:09:06,049 [Listener at 127.0.0.1/39461] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-06-25 01:09:06,050 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-06-25 01:09:06,050 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-06-25 01:09:06,050 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-06-25 01:09:06,050 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-06-25 01:09:06,050 [Listener at 127.0.0.1/39461] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-06-25 01:09:06,050 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:06,050 [Listener at 127.0.0.1/39461] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-06-25 01:09:06,059 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:09:06,059 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-06-25 01:09:06,059 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-06-25 01:09:06,060 [Listener at 127.0.0.1/39461] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-06-25 01:09:06,060 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-06-25 01:09:06,062 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-06-25 01:09:06,062 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:06,062 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:06,063 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-1/data/ratis] (custom)
2022-06-25 01:09:06,083 [Listener at 127.0.0.1/39461] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-06-25 01:09:06,090 [Listener at 127.0.0.1/39461] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-06-25 01:09:06,090 [Listener at 127.0.0.1/39461] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-06-25 01:09:06,091 [Listener at 127.0.0.1/39461] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-06-25 01:09:06,104 [Listener at 127.0.0.1/39461] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-06-25 01:09:06,105 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1029)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-06-25 01:09:06,111 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1005)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-06-25 01:09:06,111 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-06-25 01:09:06,111 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-06-25 01:09:06,111 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1248)) - Jetty bound to port 45119
2022-06-25 01:09:06,112 [Listener at 127.0.0.1/39461] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-06-25 01:09:06,147 [Listener at 127.0.0.1/39461] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-06-25 01:09:06,147 [Listener at 127.0.0.1/39461] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-06-25 01:09:06,147 [Listener at 127.0.0.1/39461] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2022-06-25 01:09:06,148 [Listener at 127.0.0.1/39461] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@7b6183f8{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-06-25 01:09:06,148 [Listener at 127.0.0.1/39461] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@16d2429f{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-06-25 01:09:06,624 [Listener at 127.0.0.1/39461] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@3831a3e6{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-45119-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-4127918045872416775/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-25 01:09:06,627 [Listener at 127.0.0.1/39461] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@7b0b3070{HTTP/1.1, (http/1.1)}{0.0.0.0:45119}
2022-06-25 01:09:06,627 [Listener at 127.0.0.1/39461] INFO  server.Server (Server.java:doStart(415)) - Started @380524ms
2022-06-25 01:09:06,627 [Listener at 127.0.0.1/39461] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-06-25 01:09:06,627 [Listener at 127.0.0.1/39461] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:45119
2022-06-25 01:09:06,630 [Listener at 127.0.0.1/39461] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:06,630 [Listener at 127.0.0.1/39461] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:06,630 [Listener at 127.0.0.1/39461] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-06-25 01:09:06,642 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(492)) - Ozone container server started.
2022-06-25 01:09:06,648 [Listener at 127.0.0.1/39461] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net ip:10.1.0.8
2022-06-25 01:09:06,673 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@16b04c13] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-06-25 01:09:06,732 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-1/meta/datanode.id
2022-06-25 01:09:06,745 [Listener at 127.0.0.1/39461] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(82)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2022-06-25 01:09:06,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:06,866 [Listener at 127.0.0.1/39461] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 119 ms to scan 7 urls, producing 131 keys and 316 values 
2022-06-25 01:09:06,867 [Listener at 127.0.0.1/39461] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(237)) - Datanode State Machine Task Thread Pool size 2
2022-06-25 01:09:06,868 [Listener at 127.0.0.1/39461] INFO  volume.HddsVolume (HddsVolume.java:<init>(116)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-2/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-06-25 01:09:06,868 [Listener at 127.0.0.1/39461] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-2/data-0/containers/hdds to VolumeSet
2022-06-25 01:09:06,868 [Listener at 127.0.0.1/39461] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-2/data-0/containers/hdds
2022-06-25 01:09:06,869 [Listener at 127.0.0.1/39461] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-2/data-0/containers/hdds
2022-06-25 01:09:06,921 [Listener at 127.0.0.1/39461] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-2/data/ratis to VolumeSet
2022-06-25 01:09:06,922 [Listener at 127.0.0.1/39461] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-2/data/ratis
2022-06-25 01:09:06,922 [Listener at 127.0.0.1/39461] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-2/data/ratis
2022-06-25 01:09:06,971 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:06,972 [Thread-6103] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-2/data-0/containers/hdds
2022-06-25 01:09:06,972 [Listener at 127.0.0.1/39461] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(266)) - Build ContainerSet costs 0s
2022-06-25 01:09:06,973 [Listener at 127.0.0.1/39461] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-06-25 01:09:06,973 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-06-25 01:09:06,974 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-06-25 01:09:06,974 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-06-25 01:09:06,974 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-06-25 01:09:06,974 [Listener at 127.0.0.1/39461] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-06-25 01:09:06,974 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:06,974 [Listener at 127.0.0.1/39461] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-06-25 01:09:06,995 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:09:06,996 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-06-25 01:09:06,996 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-06-25 01:09:06,997 [Listener at 127.0.0.1/39461] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-06-25 01:09:06,997 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-06-25 01:09:06,997 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-06-25 01:09:06,997 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:06,997 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:06,997 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-2/data/ratis] (custom)
2022-06-25 01:09:07,004 [Listener at 127.0.0.1/39461] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-06-25 01:09:07,007 [Listener at 127.0.0.1/39461] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-06-25 01:09:07,007 [Listener at 127.0.0.1/39461] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-06-25 01:09:07,008 [Listener at 127.0.0.1/39461] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-06-25 01:09:07,008 [Listener at 127.0.0.1/39461] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-06-25 01:09:07,016 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1029)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-06-25 01:09:07,016 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1005)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-06-25 01:09:07,016 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-06-25 01:09:07,016 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-06-25 01:09:07,018 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1248)) - Jetty bound to port 43537
2022-06-25 01:09:07,018 [Listener at 127.0.0.1/39461] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-06-25 01:09:07,086 [Listener at 127.0.0.1/39461] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-06-25 01:09:07,087 [Listener at 127.0.0.1/39461] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-06-25 01:09:07,087 [Listener at 127.0.0.1/39461] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2022-06-25 01:09:07,090 [Listener at 127.0.0.1/39461] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@6452cebc{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-06-25 01:09:07,090 [Listener at 127.0.0.1/39461] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@75873139{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-06-25 01:09:07,633 [Listener at 127.0.0.1/39461] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@fdc20d6{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-43537-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-5184580127660008775/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-25 01:09:07,636 [Listener at 127.0.0.1/39461] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@39a70175{HTTP/1.1, (http/1.1)}{0.0.0.0:43537}
2022-06-25 01:09:07,636 [Listener at 127.0.0.1/39461] INFO  server.Server (Server.java:doStart(415)) - Started @381533ms
2022-06-25 01:09:07,636 [Listener at 127.0.0.1/39461] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-06-25 01:09:07,637 [Listener at 127.0.0.1/39461] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:43537
2022-06-25 01:09:07,637 [Listener at 127.0.0.1/39461] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:07,637 [Listener at 127.0.0.1/39461] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:07,637 [Listener at 127.0.0.1/39461] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-06-25 01:09:07,667 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(492)) - Ozone container server started.
2022-06-25 01:09:07,676 [Listener at 127.0.0.1/39461] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net ip:10.1.0.8
2022-06-25 01:09:07,683 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3ee05424] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-06-25 01:09:07,690 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-2/meta/datanode.id
2022-06-25 01:09:07,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:07,761 [Listener at 127.0.0.1/39461] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(82)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2022-06-25 01:09:07,973 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:08,057 [Listener at 127.0.0.1/39461] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 295 ms to scan 7 urls, producing 131 keys and 316 values 
2022-06-25 01:09:08,064 [Listener at 127.0.0.1/39461] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(237)) - Datanode State Machine Task Thread Pool size 2
2022-06-25 01:09:08,065 [Listener at 127.0.0.1/39461] INFO  volume.HddsVolume (HddsVolume.java:<init>(116)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-3/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-06-25 01:09:08,065 [Listener at 127.0.0.1/39461] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-3/data-0/containers/hdds to VolumeSet
2022-06-25 01:09:08,065 [Listener at 127.0.0.1/39461] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-3/data-0/containers/hdds
2022-06-25 01:09:08,066 [Listener at 127.0.0.1/39461] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-3/data-0/containers/hdds
2022-06-25 01:09:08,099 [Listener at 127.0.0.1/39461] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-3/data/ratis to VolumeSet
2022-06-25 01:09:08,099 [Listener at 127.0.0.1/39461] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-3/data/ratis
2022-06-25 01:09:08,102 [Listener at 127.0.0.1/39461] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-3/data/ratis
2022-06-25 01:09:08,118 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(309)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-0/data-0/containers/hdds/5319b9db-8434-46dc-af7a-58e933abef82/DS-1fde27f3-33d6-4f77-a148-ea9be06838ca/container.db for volume DS-1fde27f3-33d6-4f77-a148-ea9be06838ca
2022-06-25 01:09:08,128 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(340)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-0/data-0/containers/hdds/5319b9db-8434-46dc-af7a-58e933abef82/DS-1fde27f3-33d6-4f77-a148-ea9be06838ca/container.db for volume DS-1fde27f3-33d6-4f77-a148-ea9be06838ca
2022-06-25 01:09:08,128 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(344)) - Attempting to start container services.
2022-06-25 01:09:08,128 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(279)) - Background container scanner has been disabled.
2022-06-25 01:09:08,128 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 34007
2022-06-25 01:09:08,139 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis 489bfe9a-d541-48f0-84f9-7976b526cd96
2022-06-25 01:09:08,239 [Thread-6121] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-3/data-0/containers/hdds
2022-06-25 01:09:08,242 [Listener at 127.0.0.1/39461] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(266)) - Build ContainerSet costs 0s
2022-06-25 01:09:08,244 [Listener at 127.0.0.1/39461] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-06-25 01:09:08,244 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-06-25 01:09:08,244 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-06-25 01:09:08,244 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-06-25 01:09:08,244 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-06-25 01:09:08,244 [Listener at 127.0.0.1/39461] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-06-25 01:09:08,244 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:08,244 [Listener at 127.0.0.1/39461] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-06-25 01:09:08,244 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:09:08,244 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-06-25 01:09:08,244 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-06-25 01:09:08,246 [Listener at 127.0.0.1/39461] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-06-25 01:09:08,246 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-06-25 01:09:08,246 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-06-25 01:09:08,246 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:08,246 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:08,246 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-3/data/ratis] (custom)
2022-06-25 01:09:08,255 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - 489bfe9a-d541-48f0-84f9-7976b526cd96: start RPC server
2022-06-25 01:09:08,265 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - 489bfe9a-d541-48f0-84f9-7976b526cd96: GrpcService started, listening on 43031
2022-06-25 01:09:08,267 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 489bfe9a-d541-48f0-84f9-7976b526cd96 is started using port 43031 for RATIS
2022-06-25 01:09:08,267 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 489bfe9a-d541-48f0-84f9-7976b526cd96 is started using port 43031 for RATIS_ADMIN
2022-06-25 01:09:08,267 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 489bfe9a-d541-48f0-84f9-7976b526cd96 is started using port 43031 for RATIS_SERVER
2022-06-25 01:09:08,268 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@4db088e8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-489bfe9a-d541-48f0-84f9-7976b526cd96: Started
2022-06-25 01:09:08,308 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 489bfe9a-d541-48f0-84f9-7976b526cd96 is started using port 40687
2022-06-25 01:09:08,333 [Listener at 127.0.0.1/39461] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-06-25 01:09:08,348 [Listener at 127.0.0.1/39461] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-06-25 01:09:08,348 [Listener at 127.0.0.1/39461] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-06-25 01:09:08,349 [Listener at 127.0.0.1/39461] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-06-25 01:09:08,349 [Listener at 127.0.0.1/39461] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-06-25 01:09:08,350 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1029)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-06-25 01:09:08,350 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1005)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-06-25 01:09:08,350 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-06-25 01:09:08,350 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-06-25 01:09:08,357 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1248)) - Jetty bound to port 42415
2022-06-25 01:09:08,357 [IPC Server handler 12 on default port 38653] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:startDecommission(272)) - Starting Decommission for node be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:09:08,357 [Listener at 127.0.0.1/39461] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-06-25 01:09:08,384 [Listener at 127.0.0.1/39461] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-06-25 01:09:08,384 [Listener at 127.0.0.1/39461] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-06-25 01:09:08,384 [Listener at 127.0.0.1/39461] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-06-25 01:09:08,385 [Listener at 127.0.0.1/39461] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@3a5f9156{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-06-25 01:09:08,385 [Listener at 127.0.0.1/39461] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@1f01ca2d{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-06-25 01:09:08,515 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to HEALTHY state.
2022-06-25 01:09:08,515 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(275)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-06-25 01:09:08,539 [IPC Server handler 10 on default port 36557] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0} as the reported value does not match the value stored in SCM (DECOMMISSIONING, 0)
2022-06-25 01:09:08,697 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(279)) - Waiting for pipelines to close for be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}. There are 2 pipelines
2022-06-25 01:09:08,697 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(148)) - There are 1 nodes tracked for decommission and maintenance. 0 pending nodes.
2022-06-25 01:09:08,697 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(56)) - Admin start on datanode be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}. Finalizing its pipelines [PipelineID=68648fa3-5dbc-4304-8297-eabd1be7e846, PipelineID=be334d2b-9e4d-429c-8f2f-5f6f11ee7da8]
2022-06-25 01:09:08,698 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(411)) - Container #1 closed for pipeline=PipelineID=68648fa3-5dbc-4304-8297-eabd1be7e846
2022-06-25 01:09:08,698 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(411)) - Container #2 closed for pipeline=PipelineID=68648fa3-5dbc-4304-8297-eabd1be7e846
2022-06-25 01:09:08,698 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(411)) - Container #3 closed for pipeline=PipelineID=68648fa3-5dbc-4304-8297-eabd1be7e846
2022-06-25 01:09:08,698 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(432)) - Pipeline Pipeline[ Id: 68648fa3-5dbc-4304-8297-eabd1be7e846, Nodes: be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, CreationTimestamp2022-06-25T01:08:42.891Z[Etc/UTC]] moved to CLOSED state
2022-06-25 01:09:08,699 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=68648fa3-5dbc-4304-8297-eabd1be7e846 close command to datanode be67eb5e-e62d-4374-a142-8db592db20d7
2022-06-25 01:09:08,699 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=68648fa3-5dbc-4304-8297-eabd1be7e846 close command to datanode 3c6128f4-7bf2-4a55-83fb-21add5186158
2022-06-25 01:09:08,699 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=68648fa3-5dbc-4304-8297-eabd1be7e846 close command to datanode 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf
2022-06-25 01:09:08,701 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(243)) - Pipeline Pipeline[ Id: 68648fa3-5dbc-4304-8297-eabd1be7e846, Nodes: be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, CreationTimestamp2022-06-25T01:08:42.891Z[Etc/UTC]] removed.
2022-06-25 01:09:08,711 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(432)) - Pipeline Pipeline[ Id: be334d2b-9e4d-429c-8f2f-5f6f11ee7da8, Nodes: be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:be67eb5e-e62d-4374-a142-8db592db20d7, CreationTimestamp2022-06-25T01:08:40.666Z[Etc/UTC]] moved to CLOSED state
2022-06-25 01:09:08,711 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=be334d2b-9e4d-429c-8f2f-5f6f11ee7da8 close command to datanode be67eb5e-e62d-4374-a142-8db592db20d7
2022-06-25 01:09:08,712 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(243)) - Pipeline Pipeline[ Id: be334d2b-9e4d-429c-8f2f-5f6f11ee7da8, Nodes: be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:be67eb5e-e62d-4374-a142-8db592db20d7, CreationTimestamp2022-06-25T01:08:40.666Z[Etc/UTC]] removed.
2022-06-25 01:09:08,750 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(70)) - Close container Event triggered for container : #1
2022-06-25 01:09:08,750 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(70)) - Close container Event triggered for container : #2
2022-06-25 01:09:08,751 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(70)) - Close container Event triggered for container : #3
2022-06-25 01:09:08,756 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:08,888 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(309)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-1/data-0/containers/hdds/5319b9db-8434-46dc-af7a-58e933abef82/DS-96d8f7de-a731-408e-a2aa-d2026942b381/container.db for volume DS-96d8f7de-a731-408e-a2aa-d2026942b381
2022-06-25 01:09:08,889 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(340)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-1/data-0/containers/hdds/5319b9db-8434-46dc-af7a-58e933abef82/DS-96d8f7de-a731-408e-a2aa-d2026942b381/container.db for volume DS-96d8f7de-a731-408e-a2aa-d2026942b381
2022-06-25 01:09:08,889 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(344)) - Attempting to start container services.
2022-06-25 01:09:08,889 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(279)) - Background container scanner has been disabled.
2022-06-25 01:09:08,970 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 44807
2022-06-25 01:09:08,974 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #1 to datanode be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:08,974 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #1 to datanode 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:08,974 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #1 to datanode 3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:08,974 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #2 to datanode 3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:08,974 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #2 to datanode be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:08,974 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #2 to datanode 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:08,974 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #3 to datanode 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:08,974 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #3 to datanode 3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:08,974 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #3 to datanode be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:08,974 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:08,995 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2
2022-06-25 01:09:09,018 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2: start RPC server
2022-06-25 01:09:09,026 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2: GrpcService started, listening on 43289
2022-06-25 01:09:09,030 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2 is started using port 43289 for RATIS
2022-06-25 01:09:09,030 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2 is started using port 43289 for RATIS_ADMIN
2022-06-25 01:09:09,030 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2 is started using port 43289 for RATIS_SERVER
2022-06-25 01:09:09,030 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@aa6ee36] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2: Started
2022-06-25 01:09:09,042 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5109963496ns, electionTimeout:5103ms
2022-06-25 01:09:09,042 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: shutdown 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:09,042 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
2022-06-25 01:09:09,044 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2 is started using port 40157
2022-06-25 01:09:09,091 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5148046147ns, electionTimeout:5147ms
2022-06-25 01:09:09,091 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: shutdown fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:09,091 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
2022-06-25 01:09:09,092 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:09,092 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: start fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection163
2022-06-25 01:09:09,109 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:09,109 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: start 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection162
2022-06-25 01:09:09,110 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5170332935ns, electionTimeout:5167ms
2022-06-25 01:09:09,111 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: shutdown 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:09,111 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
2022-06-25 01:09:09,123 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@1067788d] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: Detected pause in JVM or host machine (eg GC): pause of approximately 108388316ns. No GCs detected.
2022-06-25 01:09:09,126 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:09,126 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: start 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection164
2022-06-25 01:09:09,134 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection163] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection163 ELECTION round 0: submit vote requests at term 4 for -1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|priority:0], old=null
2022-06-25 01:09:09,145 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection162] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection162 ELECTION round 0: submit vote requests at term 4 for -1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:09:09,147 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection164] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection164 ELECTION round 0: submit vote requests at term 4 for -1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:09:09,157 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: receive requestVote(ELECTION, 97d08340-a146-41c4-a759-b3b136c7fb6d, group-B6B9DF3CEF32, 4, (t:0, i:0))
2022-06-25 01:09:09,157 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(48)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-CANDIDATE: reject ELECTION from 97d08340-a146-41c4-a759-b3b136c7fb6d: already has voted for 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9 at current term 4
2022-06-25 01:09:09,157 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32 replies to ELECTION vote request: 97d08340-a146-41c4-a759-b3b136c7fb6d<-4943f96b-6a06-411a-b0ee-4ab66ab6f7f9#0:FAIL-t4. Peer's state: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32:t4, leader=null, voted=4943f96b-6a06-411a-b0ee-4ab66ab6f7f9, raftlog=4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:09:09,175 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: receive requestVote(ELECTION, fc692a40-1ae9-40b7-8d63-7e46f51df1ef, group-B6B9DF3CEF32, 4, (t:0, i:0))
2022-06-25 01:09:09,175 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-CANDIDATE: reject ELECTION from fc692a40-1ae9-40b7-8d63-7e46f51df1ef: already has voted for 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9 at current term 4
2022-06-25 01:09:09,175 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32 replies to ELECTION vote request: fc692a40-1ae9-40b7-8d63-7e46f51df1ef<-4943f96b-6a06-411a-b0ee-4ab66ab6f7f9#0:FAIL-t4. Peer's state: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32:t4, leader=null, voted=4943f96b-6a06-411a-b0ee-4ab66ab6f7f9, raftlog=4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:09:09,175 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: receive requestVote(ELECTION, 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9, group-B6B9DF3CEF32, 4, (t:0, i:0))
2022-06-25 01:09:09,175 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-CANDIDATE: reject ELECTION from 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: already has voted for fc692a40-1ae9-40b7-8d63-7e46f51df1ef at current term 4
2022-06-25 01:09:09,175 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32 replies to ELECTION vote request: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9<-fc692a40-1ae9-40b7-8d63-7e46f51df1ef#0:FAIL-t4. Peer's state: fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32:t4, leader=null, voted=fc692a40-1ae9-40b7-8d63-7e46f51df1ef, raftlog=fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|priority:0], old=null
2022-06-25 01:09:09,177 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: receive requestVote(ELECTION, 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9, group-B6B9DF3CEF32, 4, (t:0, i:0))
2022-06-25 01:09:09,177 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(48)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-CANDIDATE: reject ELECTION from 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: already has voted for 97d08340-a146-41c4-a759-b3b136c7fb6d at current term 4
2022-06-25 01:09:09,177 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32 replies to ELECTION vote request: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9<-97d08340-a146-41c4-a759-b3b136c7fb6d#0:FAIL-t4. Peer's state: 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32:t4, leader=null, voted=97d08340-a146-41c4-a759-b3b136c7fb6d, raftlog=97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:09:09,178 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: receive requestVote(ELECTION, fc692a40-1ae9-40b7-8d63-7e46f51df1ef, group-B6B9DF3CEF32, 4, (t:0, i:0))
2022-06-25 01:09:09,178 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-CANDIDATE: reject ELECTION from fc692a40-1ae9-40b7-8d63-7e46f51df1ef: already has voted for 97d08340-a146-41c4-a759-b3b136c7fb6d at current term 4
2022-06-25 01:09:09,178 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32 replies to ELECTION vote request: fc692a40-1ae9-40b7-8d63-7e46f51df1ef<-97d08340-a146-41c4-a759-b3b136c7fb6d#0:FAIL-t4. Peer's state: 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32:t4, leader=null, voted=97d08340-a146-41c4-a759-b3b136c7fb6d, raftlog=97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:09:09,178 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: receive requestVote(ELECTION, 97d08340-a146-41c4-a759-b3b136c7fb6d, group-B6B9DF3CEF32, 4, (t:0, i:0))
2022-06-25 01:09:09,178 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(48)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-CANDIDATE: reject ELECTION from 97d08340-a146-41c4-a759-b3b136c7fb6d: already has voted for fc692a40-1ae9-40b7-8d63-7e46f51df1ef at current term 4
2022-06-25 01:09:09,178 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32 replies to ELECTION vote request: 97d08340-a146-41c4-a759-b3b136c7fb6d<-fc692a40-1ae9-40b7-8d63-7e46f51df1ef#0:FAIL-t4. Peer's state: fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32:t4, leader=null, voted=fc692a40-1ae9-40b7-8d63-7e46f51df1ef, raftlog=fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|priority:0], old=null
2022-06-25 01:09:09,198 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection164] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection164: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-06-25 01:09:09,198 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection164] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 97d08340-a146-41c4-a759-b3b136c7fb6d<-4943f96b-6a06-411a-b0ee-4ab66ab6f7f9#0:FAIL-t4
2022-06-25 01:09:09,198 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection164] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 97d08340-a146-41c4-a759-b3b136c7fb6d<-fc692a40-1ae9-40b7-8d63-7e46f51df1ef#0:FAIL-t4
2022-06-25 01:09:09,198 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection164] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection164 ELECTION round 0: result REJECTED
2022-06-25 01:09:09,198 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection164] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
2022-06-25 01:09:09,198 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection164] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: shutdown 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection164
2022-06-25 01:09:09,199 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection164] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: start 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:09,199 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection163] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection163: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-06-25 01:09:09,199 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection163] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: fc692a40-1ae9-40b7-8d63-7e46f51df1ef<-4943f96b-6a06-411a-b0ee-4ab66ab6f7f9#0:FAIL-t4
2022-06-25 01:09:09,199 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection163] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: fc692a40-1ae9-40b7-8d63-7e46f51df1ef<-97d08340-a146-41c4-a759-b3b136c7fb6d#0:FAIL-t4
2022-06-25 01:09:09,199 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection162] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection162: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-06-25 01:09:09,199 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection162] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9<-97d08340-a146-41c4-a759-b3b136c7fb6d#0:FAIL-t4
2022-06-25 01:09:09,199 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection162] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9<-fc692a40-1ae9-40b7-8d63-7e46f51df1ef#0:FAIL-t4
2022-06-25 01:09:09,250 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection162] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection162 ELECTION round 0: result REJECTED
2022-06-25 01:09:09,250 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection162] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
2022-06-25 01:09:09,250 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection162] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: shutdown 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection162
2022-06-25 01:09:09,250 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection162] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: start 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:09,296 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection163] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection163 ELECTION round 0: result REJECTED
2022-06-25 01:09:09,296 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection163] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
2022-06-25 01:09:09,296 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection163] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: shutdown fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection163
2022-06-25 01:09:09,296 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection163] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: start fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:09,346 [Listener at 127.0.0.1/39461] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@45b9cd5d{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-42415-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-5137013258953331021/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-25 01:09:09,368 [Listener at 127.0.0.1/39461] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@354ca53d{HTTP/1.1, (http/1.1)}{0.0.0.0:42415}
2022-06-25 01:09:09,368 [Listener at 127.0.0.1/39461] INFO  server.Server (Server.java:doStart(415)) - Started @383265ms
2022-06-25 01:09:09,368 [Listener at 127.0.0.1/39461] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-06-25 01:09:09,379 [Listener at 127.0.0.1/39461] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:42415
2022-06-25 01:09:09,393 [Listener at 127.0.0.1/39461] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:09,393 [Listener at 127.0.0.1/39461] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:09,393 [Listener at 127.0.0.1/39461] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-06-25 01:09:09,436 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(492)) - Ozone container server started.
2022-06-25 01:09:09,467 [Listener at 127.0.0.1/39461] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net ip:10.1.0.8
2022-06-25 01:09:09,482 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@24f75010] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-06-25 01:09:09,504 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-3/meta/datanode.id
2022-06-25 01:09:09,539 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=68648fa3-5dbc-4304-8297-eabd1be7e846 is not found
2022-06-25 01:09:09,541 [IPC Server handler 12 on default port 36557] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0} as the reported value does not match the value stored in SCM (DECOMMISSIONING, 0)
2022-06-25 01:09:09,544 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=68648fa3-5dbc-4304-8297-eabd1be7e846 is not found
2022-06-25 01:09:09,544 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=be334d2b-9e4d-429c-8f2f-5f6f11ee7da8 is not found
2022-06-25 01:09:09,614 [Listener at 127.0.0.1/39461] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(82)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2022-06-25 01:09:09,686 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(148)) - There are 1 nodes tracked for decommission and maintenance. 0 pending nodes.
2022-06-25 01:09:09,699 [Listener at 127.0.0.1/39461] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 71 ms to scan 7 urls, producing 131 keys and 316 values 
2022-06-25 01:09:09,699 [Listener at 127.0.0.1/39461] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(237)) - Datanode State Machine Task Thread Pool size 2
2022-06-25 01:09:09,729 [Listener at 127.0.0.1/39461] INFO  volume.HddsVolume (HddsVolume.java:<init>(116)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-4/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-06-25 01:09:09,729 [Listener at 127.0.0.1/39461] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-4/data-0/containers/hdds to VolumeSet
2022-06-25 01:09:09,730 [Listener at 127.0.0.1/39461] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-4/data-0/containers/hdds
2022-06-25 01:09:09,744 [Listener at 127.0.0.1/39461] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-4/data-0/containers/hdds
2022-06-25 01:09:09,757 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:09,815 [IPC Server handler 2 on default port 37947] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/489bfe9a-d541-48f0-84f9-7976b526cd96
2022-06-25 01:09:09,815 [IPC Server handler 2 on default port 37947] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 489bfe9a-d541-48f0-84f9-7976b526cd96{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=34007, RATIS=43031, RATIS_ADMIN=43031, RATIS_SERVER=43031, STANDALONE=40687], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:09:09,826 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - ContainerSafeModeRule rule is successfully validated
2022-06-25 01:09:09,827 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2022-06-25 01:09:09,901 [Listener at 127.0.0.1/39461] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-4/data/ratis to VolumeSet
2022-06-25 01:09:09,901 [Listener at 127.0.0.1/39461] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-4/data/ratis
2022-06-25 01:09:09,914 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(275)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-06-25 01:09:09,914 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=52590cf4-4638-492f-824a-d55e57c271a7 to datanode:489bfe9a-d541-48f0-84f9-7976b526cd96
2022-06-25 01:09:09,928 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 52590cf4-4638-492f-824a-d55e57c271a7, Nodes: 489bfe9a-d541-48f0-84f9-7976b526cd96{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=34007, RATIS=43031, RATIS_ADMIN=43031, RATIS_SERVER=43031, STANDALONE=40687], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-25T01:09:09.914Z[Etc/UTC]].
2022-06-25 01:09:09,934 [Listener at 127.0.0.1/39461] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-4/data/ratis
2022-06-25 01:09:09,976 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #1 to datanode be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:09,976 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #1 to datanode 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:09,976 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #1 to datanode 3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:09,976 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #2 to datanode 3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:09,976 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #2 to datanode be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:09,976 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #2 to datanode 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:09,976 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #3 to datanode 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:09,976 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #3 to datanode 3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:09,976 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #3 to datanode be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:09,976 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:09,991 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - AtleastOneDatanodeReportedRule rule is successfully validated
2022-06-25 01:09:10,056 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(309)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-2/data-0/containers/hdds/5319b9db-8434-46dc-af7a-58e933abef82/DS-c9379822-2835-41a8-9712-cafce171d202/container.db for volume DS-c9379822-2835-41a8-9712-cafce171d202
2022-06-25 01:09:10,057 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(340)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-2/data-0/containers/hdds/5319b9db-8434-46dc-af7a-58e933abef82/DS-c9379822-2835-41a8-9712-cafce171d202/container.db for volume DS-c9379822-2835-41a8-9712-cafce171d202
2022-06-25 01:09:10,057 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(344)) - Attempting to start container services.
2022-06-25 01:09:10,057 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(279)) - Background container scanner has been disabled.
2022-06-25 01:09:10,058 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 37533
2022-06-25 01:09:10,158 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis a39a8077-0667-4534-bc11-ae9dd274a08a
2022-06-25 01:09:10,195 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - a39a8077-0667-4534-bc11-ae9dd274a08a: start RPC server
2022-06-25 01:09:10,202 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - a39a8077-0667-4534-bc11-ae9dd274a08a: GrpcService started, listening on 35251
2022-06-25 01:09:10,208 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis a39a8077-0667-4534-bc11-ae9dd274a08a is started using port 35251 for RATIS
2022-06-25 01:09:10,208 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis a39a8077-0667-4534-bc11-ae9dd274a08a is started using port 35251 for RATIS_ADMIN
2022-06-25 01:09:10,208 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis a39a8077-0667-4534-bc11-ae9dd274a08a is started using port 35251 for RATIS_SERVER
2022-06-25 01:09:10,208 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@451ea648] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-a39a8077-0667-4534-bc11-ae9dd274a08a: Started
2022-06-25 01:09:10,215 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc a39a8077-0667-4534-bc11-ae9dd274a08a is started using port 42177
2022-06-25 01:09:10,269 [Thread-6161] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-4/data-0/containers/hdds
2022-06-25 01:09:10,269 [Listener at 127.0.0.1/39461] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(266)) - Build ContainerSet costs 0s
2022-06-25 01:09:10,271 [Listener at 127.0.0.1/39461] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-06-25 01:09:10,271 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-06-25 01:09:10,271 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-06-25 01:09:10,271 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-06-25 01:09:10,271 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-06-25 01:09:10,272 [Listener at 127.0.0.1/39461] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-06-25 01:09:10,272 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:10,272 [Listener at 127.0.0.1/39461] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-06-25 01:09:10,278 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:09:10,278 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-06-25 01:09:10,278 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-06-25 01:09:10,280 [Listener at 127.0.0.1/39461] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-06-25 01:09:10,280 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-06-25 01:09:10,280 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-06-25 01:09:10,280 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:10,280 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:10,280 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-4/data/ratis] (custom)
2022-06-25 01:09:10,288 [Listener at 127.0.0.1/39461] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-06-25 01:09:10,312 [Listener at 127.0.0.1/39461] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-06-25 01:09:10,312 [Listener at 127.0.0.1/39461] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-06-25 01:09:10,313 [Listener at 127.0.0.1/39461] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-06-25 01:09:10,314 [Listener at 127.0.0.1/39461] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-06-25 01:09:10,314 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1029)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-06-25 01:09:10,315 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1005)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-06-25 01:09:10,315 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-06-25 01:09:10,315 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-06-25 01:09:10,315 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1248)) - Jetty bound to port 41181
2022-06-25 01:09:10,315 [Listener at 127.0.0.1/39461] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-06-25 01:09:10,349 [Listener at 127.0.0.1/39461] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-06-25 01:09:10,349 [Listener at 127.0.0.1/39461] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-06-25 01:09:10,349 [Listener at 127.0.0.1/39461] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2022-06-25 01:09:10,359 [Listener at 127.0.0.1/39461] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@52e3984d{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-06-25 01:09:10,359 [Listener at 127.0.0.1/39461] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@3fffd26d{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-06-25 01:09:10,513 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: remove  FOLLOWER 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846:t2, leader=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, voted=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, raftlog=3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-SegmentedRaftLog:OPENED:c77, conf=0: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:0], old=null RUNNING
2022-06-25 01:09:10,513 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846: shutdown
2022-06-25 01:09:10,514 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-EABD1BE7E846,id=3c6128f4-7bf2-4a55-83fb-21add5186158
2022-06-25 01:09:10,514 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: shutdown 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-FollowerState
2022-06-25 01:09:10,514 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-StateMachineUpdater: set stopIndex = 77
2022-06-25 01:09:10,514 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-FollowerState was interrupted
2022-06-25 01:09:10,515 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-EABD1BE7E846: Taking a snapshot at:(t:2, i:77) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data/ratis/68648fa3-5dbc-4304-8297-eabd1be7e846/sm/snapshot.2_77
2022-06-25 01:09:10,519 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=68648fa3-5dbc-4304-8297-eabd1be7e846 is not found
2022-06-25 01:09:10,521 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-EABD1BE7E846: Finished taking a snapshot at:(t:2, i:77) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data/ratis/68648fa3-5dbc-4304-8297-eabd1be7e846/sm/snapshot.2_77 took: 6 ms
2022-06-25 01:09:10,521 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-StateMachineUpdater: Took a snapshot at index 77
2022-06-25 01:09:10,521 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 77
2022-06-25 01:09:10,528 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(429)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846: closes. applyIndex: 77
2022-06-25 01:09:10,530 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-25 01:09:10,539 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: remove    LEADER 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846:t2, leader=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, voted=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, raftlog=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-SegmentedRaftLog:OPENED:c77, conf=0: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:0], old=null RUNNING
2022-06-25 01:09:10,539 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846: shutdown
2022-06-25 01:09:10,539 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-EABD1BE7E846,id=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf
2022-06-25 01:09:10,539 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: shutdown 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-LeaderStateImpl
2022-06-25 01:09:10,539 [Command processor thread] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-PendingRequests: sendNotLeaderResponses
2022-06-25 01:09:10,540 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846->be67eb5e-e62d-4374-a142-8db592db20d7-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(171)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846->be67eb5e-e62d-4374-a142-8db592db20d7-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2022-06-25 01:09:10,548 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-EABD1BE7E846: Taking a snapshot at:(t:2, i:77) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data/ratis/68648fa3-5dbc-4304-8297-eabd1be7e846/sm/snapshot.2_77
2022-06-25 01:09:10,548 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-StateMachineUpdater: set stopIndex = 77
2022-06-25 01:09:10,557 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-EABD1BE7E846: Finished taking a snapshot at:(t:2, i:77) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data/ratis/68648fa3-5dbc-4304-8297-eabd1be7e846/sm/snapshot.2_77 took: 9 ms
2022-06-25 01:09:10,557 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-StateMachineUpdater: Took a snapshot at index 77
2022-06-25 01:09:10,557 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 77
2022-06-25 01:09:10,558 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(429)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846: closes. applyIndex: 77
2022-06-25 01:09:10,558 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-25 01:09:10,558 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846-SegmentedRaftLogWorker close()
2022-06-25 01:09:10,619 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 1 is synced with bcsId 72.
2022-06-25 01:09:10,619 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 1 is synced with bcsId 72.
2022-06-25 01:09:10,623 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(140)) - be67eb5e-e62d-4374-a142-8db592db20d7: Completed APPEND_ENTRIES, lastRequest: 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf->be67eb5e-e62d-4374-a142-8db592db20d7#757-t2,previous=(t:2, i:76),leaderCommit=75,initializing? true,entries: size=1, first=(t:2, i:77), METADATAENTRY(c:75)
2022-06-25 01:09:10,624 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(339)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846->be67eb5e-e62d-4374-a142-8db592db20d7-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2022-06-25 01:09:10,625 [grpc-default-executor-0] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846->be67eb5e-e62d-4374-a142-8db592db20d7: nextIndex: updateUnconditionally 78 -> 77
2022-06-25 01:09:10,635 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846-SegmentedRaftLogWorker close()
2022-06-25 01:09:10,675 [IPC Server handler 0 on default port 37947] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2
2022-06-25 01:09:10,705 [IPC Server handler 0 on default port 37947] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=44807, RATIS=43289, RATIS_ADMIN=43289, RATIS_SERVER=43289, STANDALONE=40157], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:09:10,706 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(275)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-06-25 01:09:10,670 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 2 is synced with bcsId 76.
2022-06-25 01:09:10,706 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 2 is synced with bcsId 76.
2022-06-25 01:09:10,636 [FixedThreadPoolWithAffinityExecutor-8-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(281)) - Moving container #1 to QUASI_CLOSED state, datanode 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported QUASI_CLOSED replica.
2022-06-25 01:09:10,635 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846->3c6128f4-7bf2-4a55-83fb-21add5186158-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(171)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846->3c6128f4-7bf2-4a55-83fb-21add5186158-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2022-06-25 01:09:10,708 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(140)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: Completed APPEND_ENTRIES, lastRequest: 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf->3c6128f4-7bf2-4a55-83fb-21add5186158#735-t2,previous=(t:2, i:76),leaderCommit=75,initializing? true,entries: size=1, first=(t:2, i:77), METADATAENTRY(c:75)
2022-06-25 01:09:10,709 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(306)) - Under Replicated Container #1 Container State: QUASI_CLOSED Replica Count: 3 Healthy Count: 2 Decommission Count: 1 Maintenance Count: 0 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=be67eb5e-e62d-4374-a142-8db592db20d7, sequenceId=72, keyCount=7, bytesUsed=133},ContainerReplica{containerID=#1, state=QUASI_CLOSED, datanodeDetails=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, sequenceId=72, keyCount=7, bytesUsed=133},ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=3c6128f4-7bf2-4a55-83fb-21add5186158, sequenceId=72, keyCount=7, bytesUsed=133}}
2022-06-25 01:09:10,709 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(317)) - Unhealthy Container #1 Container State: QUASI_CLOSED Replica Count: 3 Healthy Count: 2 Decommission Count: 1 Maintenance Count: 0 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=be67eb5e-e62d-4374-a142-8db592db20d7, sequenceId=72, keyCount=7, bytesUsed=133},ContainerReplica{containerID=#1, state=QUASI_CLOSED, datanodeDetails=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, sequenceId=72, keyCount=7, bytesUsed=133},ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=3c6128f4-7bf2-4a55-83fb-21add5186158, sequenceId=72, keyCount=7, bytesUsed=133}}
2022-06-25 01:09:10,709 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(306)) - Under Replicated Container #2 Container State: CLOSING Replica Count: 3 Healthy Count: 2 Decommission Count: 1 Maintenance Count: 0 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#2, state=OPEN, datanodeDetails=3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=3c6128f4-7bf2-4a55-83fb-21add5186158, sequenceId=76, keyCount=7, bytesUsed=133},ContainerReplica{containerID=#2, state=OPEN, datanodeDetails=be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=be67eb5e-e62d-4374-a142-8db592db20d7, sequenceId=76, keyCount=7, bytesUsed=133},ContainerReplica{containerID=#2, state=OPEN, datanodeDetails=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, sequenceId=76, keyCount=7, bytesUsed=133}}
2022-06-25 01:09:10,709 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(317)) - Unhealthy Container #2 Container State: CLOSING Replica Count: 3 Healthy Count: 2 Decommission Count: 1 Maintenance Count: 0 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#2, state=OPEN, datanodeDetails=3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=3c6128f4-7bf2-4a55-83fb-21add5186158, sequenceId=76, keyCount=7, bytesUsed=133},ContainerReplica{containerID=#2, state=OPEN, datanodeDetails=be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=be67eb5e-e62d-4374-a142-8db592db20d7, sequenceId=76, keyCount=7, bytesUsed=133},ContainerReplica{containerID=#2, state=OPEN, datanodeDetails=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, sequenceId=76, keyCount=7, bytesUsed=133}}
2022-06-25 01:09:10,709 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(306)) - Under Replicated Container #3 Container State: CLOSING Replica Count: 3 Healthy Count: 2 Decommission Count: 1 Maintenance Count: 0 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#3, state=OPEN, datanodeDetails=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, sequenceId=68, keyCount=6, bytesUsed=114},ContainerReplica{containerID=#3, state=OPEN, datanodeDetails=3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=3c6128f4-7bf2-4a55-83fb-21add5186158, sequenceId=68, keyCount=6, bytesUsed=114},ContainerReplica{containerID=#3, state=OPEN, datanodeDetails=be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=be67eb5e-e62d-4374-a142-8db592db20d7, sequenceId=68, keyCount=6, bytesUsed=114}}
2022-06-25 01:09:10,709 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(317)) - Unhealthy Container #3 Container State: CLOSING Replica Count: 3 Healthy Count: 2 Decommission Count: 1 Maintenance Count: 0 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#3, state=OPEN, datanodeDetails=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, sequenceId=68, keyCount=6, bytesUsed=114},ContainerReplica{containerID=#3, state=OPEN, datanodeDetails=3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=3c6128f4-7bf2-4a55-83fb-21add5186158, sequenceId=68, keyCount=6, bytesUsed=114},ContainerReplica{containerID=#3, state=OPEN, datanodeDetails=be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=be67eb5e-e62d-4374-a142-8db592db20d7, sequenceId=68, keyCount=6, bytesUsed=114}}
2022-06-25 01:09:10,709 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(327)) - be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0} has 0 sufficientlyReplicated, 3 underReplicated and 3 unhealthy containers
2022-06-25 01:09:10,710 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(148)) - There are 1 nodes tracked for decommission and maintenance. 0 pending nodes.
2022-06-25 01:09:10,710 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(339)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846->3c6128f4-7bf2-4a55-83fb-21add5186158-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2022-06-25 01:09:10,710 [grpc-default-executor-0] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846->3c6128f4-7bf2-4a55-83fb-21add5186158: nextIndex: updateUnconditionally 78 -> 77
2022-06-25 01:09:10,720 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2022-06-25 01:09:10,743 [FixedThreadPoolWithAffinityExecutor-9-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(281)) - Moving container #2 to QUASI_CLOSED state, datanode 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported QUASI_CLOSED replica.
2022-06-25 01:09:10,755 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=c5771680-4e41-48dc-b9eb-facd38847a24 to datanode:d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2
2022-06-25 01:09:10,755 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: c5771680-4e41-48dc-b9eb-facd38847a24, Nodes: d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=44807, RATIS=43289, RATIS_ADMIN=43289, RATIS_SERVER=43289, STANDALONE=40157], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-25T01:09:10.755Z[Etc/UTC]].
2022-06-25 01:09:10,759 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:10,759 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 3 is synced with bcsId 68.
2022-06-25 01:09:10,759 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 3 is synced with bcsId 68.
2022-06-25 01:09:10,766 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(404)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-EABD1BE7E846: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data/ratis/68648fa3-5dbc-4304-8297-eabd1be7e846
2022-06-25 01:09:10,766 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=68648fa3-5dbc-4304-8297-eabd1be7e846 command on datanode 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf.
2022-06-25 01:09:10,770 [FixedThreadPoolWithAffinityExecutor-9-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(281)) - Moving container #3 to QUASI_CLOSED state, datanode 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported QUASI_CLOSED replica.
2022-06-25 01:09:10,772 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 1 is synced with bcsId 72.
2022-06-25 01:09:10,773 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 1 is synced with bcsId 72.
2022-06-25 01:09:10,785 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 2 is synced with bcsId 76.
2022-06-25 01:09:10,785 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 2 is synced with bcsId 76.
2022-06-25 01:09:10,796 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 3 is synced with bcsId 68.
2022-06-25 01:09:10,796 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 3 is synced with bcsId 68.
2022-06-25 01:09:10,856 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(404)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-EABD1BE7E846: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data/ratis/68648fa3-5dbc-4304-8297-eabd1be7e846
2022-06-25 01:09:10,856 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=68648fa3-5dbc-4304-8297-eabd1be7e846 command on datanode 3c6128f4-7bf2-4a55-83fb-21add5186158.
2022-06-25 01:09:10,977 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(1105)) - Force closing container #1 with BCSID 72, which is in QUASI_CLOSED state.
2022-06-25 01:09:10,977 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #1 to datanode 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:10,977 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #1 to datanode 3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:10,977 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(1105)) - Force closing container #2 with BCSID 76, which is in QUASI_CLOSED state.
2022-06-25 01:09:10,977 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #2 to datanode 3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:10,977 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #2 to datanode 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:10,977 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(1105)) - Force closing container #3 with BCSID 68, which is in QUASI_CLOSED state.
2022-06-25 01:09:10,977 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #3 to datanode 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:10,977 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #3 to datanode 3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:10,977 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:11,423 [Listener at 127.0.0.1/39461] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@39565e99{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-41181-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-5324221176766371229/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-25 01:09:11,445 [Listener at 127.0.0.1/39461] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@6825689f{HTTP/1.1, (http/1.1)}{0.0.0.0:41181}
2022-06-25 01:09:11,445 [Listener at 127.0.0.1/39461] INFO  server.Server (Server.java:doStart(415)) - Started @385342ms
2022-06-25 01:09:11,445 [Listener at 127.0.0.1/39461] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-06-25 01:09:11,446 [Listener at 127.0.0.1/39461] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:41181
2022-06-25 01:09:11,450 [Listener at 127.0.0.1/39461] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:11,450 [Listener at 127.0.0.1/39461] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:11,450 [Listener at 127.0.0.1/39461] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-06-25 01:09:11,465 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(492)) - Ozone container server started.
2022-06-25 01:09:11,467 [Listener at 127.0.0.1/39461] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net ip:10.1.0.8
2022-06-25 01:09:11,514 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@423261c0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-06-25 01:09:11,542 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - be67eb5e-e62d-4374-a142-8db592db20d7: remove  FOLLOWER be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846:t2, leader=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, voted=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, raftlog=be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-SegmentedRaftLog:OPENED:c77, conf=0: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:0], old=null RUNNING
2022-06-25 01:09:11,542 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846: shutdown
2022-06-25 01:09:11,542 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-EABD1BE7E846,id=be67eb5e-e62d-4374-a142-8db592db20d7
2022-06-25 01:09:11,542 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - be67eb5e-e62d-4374-a142-8db592db20d7: shutdown be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-FollowerState
2022-06-25 01:09:11,542 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-StateMachineUpdater: set stopIndex = 77
2022-06-25 01:09:11,543 [be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-FollowerState was interrupted
2022-06-25 01:09:11,543 [be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-EABD1BE7E846: Taking a snapshot at:(t:2, i:77) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis/68648fa3-5dbc-4304-8297-eabd1be7e846/sm/snapshot.2_77
2022-06-25 01:09:11,545 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=68648fa3-5dbc-4304-8297-eabd1be7e846 is not found
2022-06-25 01:09:11,545 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=be334d2b-9e4d-429c-8f2f-5f6f11ee7da8 is not found
2022-06-25 01:09:11,547 [be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-EABD1BE7E846: Finished taking a snapshot at:(t:2, i:77) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis/68648fa3-5dbc-4304-8297-eabd1be7e846/sm/snapshot.2_77 took: 3 ms
2022-06-25 01:09:11,547 [be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-StateMachineUpdater: Took a snapshot at index 77
2022-06-25 01:09:11,547 [be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 77
2022-06-25 01:09:11,554 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-4/meta/datanode.id
2022-06-25 01:09:11,583 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(429)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846: closes. applyIndex: 77
2022-06-25 01:09:11,583 [be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-25 01:09:11,583 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846-SegmentedRaftLogWorker close()
2022-06-25 01:09:11,590 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 1 is synced with bcsId 72.
2022-06-25 01:09:11,591 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 1 is synced with bcsId 72.
2022-06-25 01:09:11,604 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 2 is synced with bcsId 76.
2022-06-25 01:09:11,604 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 2 is synced with bcsId 76.
2022-06-25 01:09:11,628 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 3 is synced with bcsId 68.
2022-06-25 01:09:11,628 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 3 is synced with bcsId 68.
2022-06-25 01:09:11,632 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(404)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-EABD1BE7E846: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis/68648fa3-5dbc-4304-8297-eabd1be7e846
2022-06-25 01:09:11,632 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=68648fa3-5dbc-4304-8297-eabd1be7e846 command on datanode be67eb5e-e62d-4374-a142-8db592db20d7.
2022-06-25 01:09:11,633 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - be67eb5e-e62d-4374-a142-8db592db20d7: remove    LEADER be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8:t1, leader=be67eb5e-e62d-4374-a142-8db592db20d7, voted=be67eb5e-e62d-4374-a142-8db592db20d7, raftlog=be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-SegmentedRaftLog:OPENED:c0, conf=0: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:1], old=null RUNNING
2022-06-25 01:09:11,633 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8: shutdown
2022-06-25 01:09:11,639 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-5F6F11EE7DA8,id=be67eb5e-e62d-4374-a142-8db592db20d7
2022-06-25 01:09:11,639 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - be67eb5e-e62d-4374-a142-8db592db20d7: shutdown be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-LeaderStateImpl
2022-06-25 01:09:11,639 [Command processor thread] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-PendingRequests: sendNotLeaderResponses
2022-06-25 01:09:11,641 [Listener at 127.0.0.1/39461] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(82)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2022-06-25 01:09:11,648 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-5F6F11EE7DA8: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis/be334d2b-9e4d-429c-8f2f-5f6f11ee7da8/sm/snapshot.1_0
2022-06-25 01:09:11,648 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-StateMachineUpdater: set stopIndex = 0
2022-06-25 01:09:11,649 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-5F6F11EE7DA8: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis/be334d2b-9e4d-429c-8f2f-5f6f11ee7da8/sm/snapshot.1_0 took: 1 ms
2022-06-25 01:09:11,649 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-StateMachineUpdater: Took a snapshot at index 0
2022-06-25 01:09:11,649 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-06-25 01:09:11,651 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(429)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8: closes. applyIndex: 0
2022-06-25 01:09:11,651 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-25 01:09:11,651 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8-SegmentedRaftLogWorker close()
2022-06-25 01:09:11,652 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(404)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F6F11EE7DA8: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis/be334d2b-9e4d-429c-8f2f-5f6f11ee7da8
2022-06-25 01:09:11,652 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=be334d2b-9e4d-429c-8f2f-5f6f11ee7da8 command on datanode be67eb5e-e62d-4374-a142-8db592db20d7.
2022-06-25 01:09:11,687 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(306)) - Under Replicated Container #1 Container State: QUASI_CLOSED Replica Count: 3 Healthy Count: 2 Decommission Count: 1 Maintenance Count: 0 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#1, state=QUASI_CLOSED, datanodeDetails=be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=be67eb5e-e62d-4374-a142-8db592db20d7, sequenceId=72, keyCount=7, bytesUsed=133},ContainerReplica{containerID=#1, state=QUASI_CLOSED, datanodeDetails=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, sequenceId=72, keyCount=7, bytesUsed=133},ContainerReplica{containerID=#1, state=QUASI_CLOSED, datanodeDetails=3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=3c6128f4-7bf2-4a55-83fb-21add5186158, sequenceId=72, keyCount=7, bytesUsed=133}}
2022-06-25 01:09:11,687 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(306)) - Under Replicated Container #2 Container State: QUASI_CLOSED Replica Count: 3 Healthy Count: 2 Decommission Count: 1 Maintenance Count: 0 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#2, state=QUASI_CLOSED, datanodeDetails=3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=3c6128f4-7bf2-4a55-83fb-21add5186158, sequenceId=76, keyCount=7, bytesUsed=133},ContainerReplica{containerID=#2, state=QUASI_CLOSED, datanodeDetails=be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=be67eb5e-e62d-4374-a142-8db592db20d7, sequenceId=76, keyCount=7, bytesUsed=133},ContainerReplica{containerID=#2, state=QUASI_CLOSED, datanodeDetails=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, sequenceId=76, keyCount=7, bytesUsed=133}}
2022-06-25 01:09:11,687 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(306)) - Under Replicated Container #3 Container State: QUASI_CLOSED Replica Count: 3 Healthy Count: 2 Decommission Count: 1 Maintenance Count: 0 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#3, state=QUASI_CLOSED, datanodeDetails=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, sequenceId=68, keyCount=6, bytesUsed=114},ContainerReplica{containerID=#3, state=QUASI_CLOSED, datanodeDetails=3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=3c6128f4-7bf2-4a55-83fb-21add5186158, sequenceId=68, keyCount=6, bytesUsed=114},ContainerReplica{containerID=#3, state=QUASI_CLOSED, datanodeDetails=be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=be67eb5e-e62d-4374-a142-8db592db20d7, sequenceId=68, keyCount=6, bytesUsed=114}}
2022-06-25 01:09:11,687 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(327)) - be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0} has 0 sufficientlyReplicated, 3 underReplicated and 0 unhealthy containers
2022-06-25 01:09:11,687 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(148)) - There are 1 nodes tracked for decommission and maintenance. 0 pending nodes.
2022-06-25 01:09:11,688 [IPC Server handler 1 on default port 37947] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/a39a8077-0667-4534-bc11-ae9dd274a08a
2022-06-25 01:09:11,688 [IPC Server handler 1 on default port 37947] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : a39a8077-0667-4534-bc11-ae9dd274a08a{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=37533, RATIS=35251, RATIS_ADMIN=35251, RATIS_SERVER=35251, STANDALONE=42177], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:09:11,690 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(275)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-06-25 01:09:11,698 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2022-06-25 01:09:11,698 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - DataNodeSafeModeRule rule is successfully validated
2022-06-25 01:09:11,698 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(233)) - All SCM safe mode pre check rules have passed
2022-06-25 01:09:11,699 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2022-06-25 01:09:11,699 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2022-06-25 01:09:11,699 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(275)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-06-25 01:09:11,702 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=422c7861-ced3-461a-a0fc-8b004ca1ad68 to datanode:a39a8077-0667-4534-bc11-ae9dd274a08a
2022-06-25 01:09:11,703 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 422c7861-ced3-461a-a0fc-8b004ca1ad68, Nodes: a39a8077-0667-4534-bc11-ae9dd274a08a{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=37533, RATIS=35251, RATIS_ADMIN=35251, RATIS_SERVER=35251, STANDALONE=42177], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-25T01:09:11.702Z[Etc/UTC]].
2022-06-25 01:09:11,703 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=f02b0cd8-3fde-485f-9ca2-812a35e9d7fa to datanode:a39a8077-0667-4534-bc11-ae9dd274a08a
2022-06-25 01:09:11,703 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=f02b0cd8-3fde-485f-9ca2-812a35e9d7fa to datanode:489bfe9a-d541-48f0-84f9-7976b526cd96
2022-06-25 01:09:11,703 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=f02b0cd8-3fde-485f-9ca2-812a35e9d7fa to datanode:d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2
2022-06-25 01:09:11,703 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: f02b0cd8-3fde-485f-9ca2-812a35e9d7fa, Nodes: a39a8077-0667-4534-bc11-ae9dd274a08a{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=37533, RATIS=35251, RATIS_ADMIN=35251, RATIS_SERVER=35251, STANDALONE=42177], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}489bfe9a-d541-48f0-84f9-7976b526cd96{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=34007, RATIS=43031, RATIS_ADMIN=43031, RATIS_SERVER=43031, STANDALONE=40687], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=44807, RATIS=43289, RATIS_ADMIN=43289, RATIS_SERVER=43289, STANDALONE=40157], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-25T01:09:11.703Z[Etc/UTC]].
2022-06-25 01:09:11,727 [Listener at 127.0.0.1/39461] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 85 ms to scan 7 urls, producing 131 keys and 316 values 
2022-06-25 01:09:11,728 [Listener at 127.0.0.1/39461] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(237)) - Datanode State Machine Task Thread Pool size 2
2022-06-25 01:09:11,729 [Listener at 127.0.0.1/39461] INFO  volume.HddsVolume (HddsVolume.java:<init>(116)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-5/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-06-25 01:09:11,729 [Listener at 127.0.0.1/39461] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-5/data-0/containers/hdds to VolumeSet
2022-06-25 01:09:11,729 [Listener at 127.0.0.1/39461] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-5/data-0/containers/hdds
2022-06-25 01:09:11,736 [Listener at 127.0.0.1/39461] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-5/data-0/containers/hdds
2022-06-25 01:09:11,759 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:11,782 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(309)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-3/data-0/containers/hdds/5319b9db-8434-46dc-af7a-58e933abef82/DS-cb549a62-c4a0-41bf-a50a-cf5cdf03210e/container.db for volume DS-cb549a62-c4a0-41bf-a50a-cf5cdf03210e
2022-06-25 01:09:11,784 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(340)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-3/data-0/containers/hdds/5319b9db-8434-46dc-af7a-58e933abef82/DS-cb549a62-c4a0-41bf-a50a-cf5cdf03210e/container.db for volume DS-cb549a62-c4a0-41bf-a50a-cf5cdf03210e
2022-06-25 01:09:11,784 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(344)) - Attempting to start container services.
2022-06-25 01:09:11,784 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(279)) - Background container scanner has been disabled.
2022-06-25 01:09:11,786 [Listener at 127.0.0.1/39461] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-5/data/ratis to VolumeSet
2022-06-25 01:09:11,786 [Listener at 127.0.0.1/39461] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-5/data/ratis
2022-06-25 01:09:11,786 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 33555
2022-06-25 01:09:11,818 [Listener at 127.0.0.1/39461] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-5/data/ratis
2022-06-25 01:09:11,929 [Thread-6177] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-5/data-0/containers/hdds
2022-06-25 01:09:11,929 [Listener at 127.0.0.1/39461] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(266)) - Build ContainerSet costs 0s
2022-06-25 01:09:11,972 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis fb218fe0-94a8-44a0-a252-d3cae8685c6f
2022-06-25 01:09:11,978 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(1105)) - Force closing container #1 with BCSID 72, which is in QUASI_CLOSED state.
2022-06-25 01:09:11,978 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #1 to datanode be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:11,978 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #1 to datanode 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:11,978 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #1 to datanode 3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:11,978 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(1105)) - Force closing container #2 with BCSID 76, which is in QUASI_CLOSED state.
2022-06-25 01:09:11,978 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #2 to datanode 3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:11,978 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #2 to datanode be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:11,978 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #2 to datanode 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:11,978 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(1105)) - Force closing container #3 with BCSID 68, which is in QUASI_CLOSED state.
2022-06-25 01:09:11,978 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #3 to datanode 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:11,978 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #3 to datanode 3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:11,978 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #3 to datanode be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0}.
2022-06-25 01:09:11,978 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 2 milliseconds for processing 3 containers.
2022-06-25 01:09:11,983 [Listener at 127.0.0.1/39461] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-06-25 01:09:11,983 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-06-25 01:09:11,983 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-06-25 01:09:11,983 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-06-25 01:09:11,984 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-06-25 01:09:11,984 [Listener at 127.0.0.1/39461] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-06-25 01:09:11,984 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:11,984 [Listener at 127.0.0.1/39461] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-06-25 01:09:11,984 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:09:11,984 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-06-25 01:09:11,984 [Listener at 127.0.0.1/39461] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-06-25 01:09:11,985 [Listener at 127.0.0.1/39461] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-06-25 01:09:11,985 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-06-25 01:09:11,985 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-06-25 01:09:11,985 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:11,986 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:11,986 [Listener at 127.0.0.1/39461] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-5/data/ratis] (custom)
2022-06-25 01:09:12,020 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f: start RPC server
2022-06-25 01:09:12,028 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f: GrpcService started, listening on 45009
2022-06-25 01:09:12,058 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis fb218fe0-94a8-44a0-a252-d3cae8685c6f is started using port 45009 for RATIS
2022-06-25 01:09:12,058 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis fb218fe0-94a8-44a0-a252-d3cae8685c6f is started using port 45009 for RATIS_ADMIN
2022-06-25 01:09:12,058 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis fb218fe0-94a8-44a0-a252-d3cae8685c6f is started using port 45009 for RATIS_SERVER
2022-06-25 01:09:12,059 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@37a08f49] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-fb218fe0-94a8-44a0-a252-d3cae8685c6f: Started
2022-06-25 01:09:12,069 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc fb218fe0-94a8-44a0-a252-d3cae8685c6f is started using port 37667
2022-06-25 01:09:12,184 [Listener at 127.0.0.1/39461] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-06-25 01:09:12,316 [Listener at 127.0.0.1/39461] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-06-25 01:09:12,316 [Listener at 127.0.0.1/39461] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-06-25 01:09:12,317 [Listener at 127.0.0.1/39461] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-06-25 01:09:12,355 [Listener at 127.0.0.1/39461] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-06-25 01:09:12,356 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1029)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-06-25 01:09:12,356 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1005)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-06-25 01:09:12,356 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-06-25 01:09:12,357 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-06-25 01:09:12,357 [Listener at 127.0.0.1/39461] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1248)) - Jetty bound to port 45121
2022-06-25 01:09:12,357 [Listener at 127.0.0.1/39461] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-06-25 01:09:12,391 [Listener at 127.0.0.1/39461] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-06-25 01:09:12,391 [Listener at 127.0.0.1/39461] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-06-25 01:09:12,391 [Listener at 127.0.0.1/39461] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2022-06-25 01:09:12,392 [Listener at 127.0.0.1/39461] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@186bd84b{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-06-25 01:09:12,392 [Listener at 127.0.0.1/39461] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@6811cc9f{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-06-25 01:09:12,687 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(306)) - Under Replicated Container #1 Container State: QUASI_CLOSED Replica Count: 3 Healthy Count: 2 Decommission Count: 1 Maintenance Count: 0 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#1, state=QUASI_CLOSED, datanodeDetails=be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=be67eb5e-e62d-4374-a142-8db592db20d7, sequenceId=72, keyCount=7, bytesUsed=133},ContainerReplica{containerID=#1, state=QUASI_CLOSED, datanodeDetails=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, sequenceId=72, keyCount=7, bytesUsed=133},ContainerReplica{containerID=#1, state=QUASI_CLOSED, datanodeDetails=3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=3c6128f4-7bf2-4a55-83fb-21add5186158, sequenceId=72, keyCount=7, bytesUsed=133}}
2022-06-25 01:09:12,687 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(306)) - Under Replicated Container #2 Container State: QUASI_CLOSED Replica Count: 3 Healthy Count: 2 Decommission Count: 1 Maintenance Count: 0 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#2, state=QUASI_CLOSED, datanodeDetails=3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=3c6128f4-7bf2-4a55-83fb-21add5186158, sequenceId=76, keyCount=7, bytesUsed=133},ContainerReplica{containerID=#2, state=QUASI_CLOSED, datanodeDetails=be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=be67eb5e-e62d-4374-a142-8db592db20d7, sequenceId=76, keyCount=7, bytesUsed=133},ContainerReplica{containerID=#2, state=QUASI_CLOSED, datanodeDetails=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, sequenceId=76, keyCount=7, bytesUsed=133}}
2022-06-25 01:09:12,687 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(306)) - Under Replicated Container #3 Container State: QUASI_CLOSED Replica Count: 3 Healthy Count: 2 Decommission Count: 1 Maintenance Count: 0 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#3, state=QUASI_CLOSED, datanodeDetails=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, sequenceId=68, keyCount=6, bytesUsed=114},ContainerReplica{containerID=#3, state=QUASI_CLOSED, datanodeDetails=3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=3c6128f4-7bf2-4a55-83fb-21add5186158, sequenceId=68, keyCount=6, bytesUsed=114},ContainerReplica{containerID=#3, state=QUASI_CLOSED, datanodeDetails=be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=be67eb5e-e62d-4374-a142-8db592db20d7, sequenceId=68, keyCount=6, bytesUsed=114}}
2022-06-25 01:09:12,687 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(327)) - be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0} has 0 sufficientlyReplicated, 3 underReplicated and 0 unhealthy containers
2022-06-25 01:09:12,687 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(148)) - There are 1 nodes tracked for decommission and maintenance. 0 pending nodes.
2022-06-25 01:09:12,759 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 1 is synced with bcsId 72.
2022-06-25 01:09:12,759 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:12,759 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 1 is synced with bcsId 72.
2022-06-25 01:09:12,768 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(346)) - Container 1 is closed with bcsId 72.
2022-06-25 01:09:12,769 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 2 is synced with bcsId 76.
2022-06-25 01:09:12,769 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 2 is synced with bcsId 76.
2022-06-25 01:09:12,769 [FixedThreadPoolWithAffinityExecutor-0-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(314)) - Moving container #1 to CLOSED state, datanode 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
2022-06-25 01:09:12,786 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(346)) - Container 2 is closed with bcsId 76.
2022-06-25 01:09:12,787 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 3 is synced with bcsId 68.
2022-06-25 01:09:12,787 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 3 is synced with bcsId 68.
2022-06-25 01:09:12,789 [FixedThreadPoolWithAffinityExecutor-9-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(314)) - Moving container #2 to CLOSED state, datanode 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
2022-06-25 01:09:12,798 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(346)) - Container 3 is closed with bcsId 68.
2022-06-25 01:09:12,798 [FixedThreadPoolWithAffinityExecutor-8-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(314)) - Moving container #3 to CLOSED state, datanode 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
2022-06-25 01:09:12,843 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 489bfe9a-d541-48f0-84f9-7976b526cd96: addNew group-D55E57C271A7:[489bfe9a-d541-48f0-84f9-7976b526cd96|rpc:10.1.0.8:43031|priority:1] returns group-D55E57C271A7:java.util.concurrent.CompletableFuture@98c2385[Not completed]
2022-06-25 01:09:12,844 [pool-4378-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 489bfe9a-d541-48f0-84f9-7976b526cd96: new RaftServerImpl for group-D55E57C271A7:[489bfe9a-d541-48f0-84f9-7976b526cd96|rpc:10.1.0.8:43031|priority:1] with ContainerStateMachine:uninitialized
2022-06-25 01:09:12,844 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:09:12,844 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:09:12,844 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:12,845 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:12,845 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:12,845 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:12,845 [pool-4378-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7: ConfigurationManager, init=-1: [489bfe9a-d541-48f0-84f9-7976b526cd96|rpc:10.1.0.8:43031|priority:1], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:12,845 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-0/data/ratis] (custom)
2022-06-25 01:09:12,845 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:12,845 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:12,845 [pool-4378-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-0/data/ratis/52590cf4-4638-492f-824a-d55e57c271a7 does not exist. Creating ...
2022-06-25 01:09:12,856 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 1 is synced with bcsId 72.
2022-06-25 01:09:12,856 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 1 is synced with bcsId 72.
2022-06-25 01:09:12,857 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(346)) - Container 1 is closed with bcsId 72.
2022-06-25 01:09:12,858 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 2 is synced with bcsId 76.
2022-06-25 01:09:12,858 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 2 is synced with bcsId 76.
2022-06-25 01:09:12,866 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(346)) - Container 2 is closed with bcsId 76.
2022-06-25 01:09:12,867 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 3 is synced with bcsId 68.
2022-06-25 01:09:12,867 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 3 is synced with bcsId 68.
2022-06-25 01:09:12,869 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(346)) - Container 3 is closed with bcsId 68.
2022-06-25 01:09:12,888 [pool-4378-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-0/data/ratis/52590cf4-4638-492f-824a-d55e57c271a7/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:12,925 [pool-4378-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-0/data/ratis/52590cf4-4638-492f-824a-d55e57c271a7 has been successfully formatted.
2022-06-25 01:09:12,926 [pool-4378-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-D55E57C271A7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:09:12,926 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:09:12,926 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:12,926 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:12,926 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:12,926 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:12,926 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:12,971 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(358)) - Pipeline Pipeline[ Id: 52590cf4-4638-492f-824a-d55e57c271a7, Nodes: 489bfe9a-d541-48f0-84f9-7976b526cd96{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=34007, RATIS=43031, RATIS_ADMIN=43031, RATIS_SERVER=43031, STANDALONE=40687], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:489bfe9a-d541-48f0-84f9-7976b526cd96, CreationTimestamp2022-06-25T01:09:09.914Z[Etc/UTC]] moved to OPEN state
2022-06-25 01:09:12,979 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1192)) - Container #1 is under replicated. Expected replica count is 3, but found 2.
2022-06-25 01:09:12,979 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1555)) - Sending replicate container command for container #1 to datanode 97d08340-a146-41c4-a759-b3b136c7fb6d{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=37711, RATIS=43169, RATIS_ADMIN=43169, RATIS_SERVER=43169, STANDALONE=44433], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0}, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-25 01:09:12,979 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1192)) - Container #2 is under replicated. Expected replica count is 3, but found 2.
2022-06-25 01:09:12,979 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1555)) - Sending replicate container command for container #2 to datanode 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43029, RATIS=44897, RATIS_ADMIN=44897, RATIS_SERVER=44897, STANDALONE=37333], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0}, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-25 01:09:12,979 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1192)) - Container #3 is under replicated. Expected replica count is 3, but found 2.
2022-06-25 01:09:12,979 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1555)) - Sending replicate container command for container #3 to datanode fc692a40-1ae9-40b7-8d63-7e46f51df1ef{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=40691, RATIS=39343, RATIS_ADMIN=39343, RATIS_SERVER=39343, STANDALONE=32859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0}]
2022-06-25 01:09:12,979 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:13,076 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:13,081 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:13,082 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:13,082 [pool-4378-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-0/data/ratis/52590cf4-4638-492f-824a-d55e57c271a7
2022-06-25 01:09:13,082 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:09:13,082 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:09:13,082 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:13,082 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:09:13,082 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:13,082 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:13,082 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:13,082 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:13,085 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:09:13,086 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:13,086 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:09:13,086 [pool-4378-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:13,086 [pool-4378-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:13,090 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:13,090 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:09:13,090 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:09:13,091 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:09:13,091 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:09:13,091 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:13,128 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:13,128 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:13,128 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:13,128 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:13,128 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:13,128 [pool-4378-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7: start as a follower, conf=-1: [489bfe9a-d541-48f0-84f9-7976b526cd96|rpc:10.1.0.8:43031|priority:1], old=null
2022-06-25 01:09:13,128 [pool-4378-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:13,128 [pool-4378-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 489bfe9a-d541-48f0-84f9-7976b526cd96: start 489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-FollowerState
2022-06-25 01:09:13,144 [pool-4378-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D55E57C271A7,id=489bfe9a-d541-48f0-84f9-7976b526cd96
2022-06-25 01:09:13,164 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=52590cf4-4638-492f-824a-d55e57c271a7
2022-06-25 01:09:13,164 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=52590cf4-4638-492f-824a-d55e57c271a7.
2022-06-25 01:09:13,165 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 489bfe9a-d541-48f0-84f9-7976b526cd96: addNew group-812A35E9D7FA:[a39a8077-0667-4534-bc11-ae9dd274a08a|rpc:10.1.0.8:35251|priority:0, d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2|rpc:10.1.0.8:43289|priority:1, 489bfe9a-d541-48f0-84f9-7976b526cd96|rpc:10.1.0.8:43031|priority:0] returns group-812A35E9D7FA:java.util.concurrent.CompletableFuture@db3a66c[Not completed]
2022-06-25 01:09:13,165 [pool-4378-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 489bfe9a-d541-48f0-84f9-7976b526cd96: new RaftServerImpl for group-812A35E9D7FA:[a39a8077-0667-4534-bc11-ae9dd274a08a|rpc:10.1.0.8:35251|priority:0, d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2|rpc:10.1.0.8:43289|priority:1, 489bfe9a-d541-48f0-84f9-7976b526cd96|rpc:10.1.0.8:43031|priority:0] with ContainerStateMachine:uninitialized
2022-06-25 01:09:13,165 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:09:13,166 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:09:13,166 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:13,166 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:13,166 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:13,166 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:13,166 [pool-4378-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA: ConfigurationManager, init=-1: [a39a8077-0667-4534-bc11-ae9dd274a08a|rpc:10.1.0.8:35251|priority:0, d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2|rpc:10.1.0.8:43289|priority:1, 489bfe9a-d541-48f0-84f9-7976b526cd96|rpc:10.1.0.8:43031|priority:0], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:13,166 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-0/data/ratis] (custom)
2022-06-25 01:09:13,166 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:13,166 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:13,166 [pool-4378-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-0/data/ratis/f02b0cd8-3fde-485f-9ca2-812a35e9d7fa does not exist. Creating ...
2022-06-25 01:09:13,173 [pool-4378-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-0/data/ratis/f02b0cd8-3fde-485f-9ca2-812a35e9d7fa/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:13,253 [pool-4378-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-0/data/ratis/f02b0cd8-3fde-485f-9ca2-812a35e9d7fa has been successfully formatted.
2022-06-25 01:09:13,253 [pool-4378-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-812A35E9D7FA: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:09:13,254 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:09:13,254 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:13,254 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:13,254 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:13,254 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:13,254 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:13,256 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:13,256 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:13,256 [pool-4378-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-0/data/ratis/f02b0cd8-3fde-485f-9ca2-812a35e9d7fa
2022-06-25 01:09:13,256 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:09:13,256 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:09:13,256 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:13,256 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:09:13,256 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:13,256 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:13,256 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:13,258 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:13,270 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:13,273 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:09:13,286 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:13,286 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:09:13,286 [pool-4378-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:13,286 [pool-4378-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:13,303 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:13,303 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:09:13,303 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:09:13,303 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:09:13,304 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:09:13,304 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:13,308 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:13,308 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:13,308 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:13,308 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:13,308 [pool-4378-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:13,308 [pool-4378-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA: start as a follower, conf=-1: [a39a8077-0667-4534-bc11-ae9dd274a08a|rpc:10.1.0.8:35251|priority:0, d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2|rpc:10.1.0.8:43289|priority:1, 489bfe9a-d541-48f0-84f9-7976b526cd96|rpc:10.1.0.8:43031|priority:0], old=null
2022-06-25 01:09:13,309 [pool-4378-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:13,309 [pool-4378-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 489bfe9a-d541-48f0-84f9-7976b526cd96: start 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-FollowerState
2022-06-25 01:09:13,309 [pool-4378-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-812A35E9D7FA,id=489bfe9a-d541-48f0-84f9-7976b526cd96
2022-06-25 01:09:13,342 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=f02b0cd8-3fde-485f-9ca2-812a35e9d7fa
Jun 25, 2022 1:09:13 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1046, target=10.1.0.8:42907} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.buildChannel(GrpcClientProtocolClient.java:161)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.<init>(GrpcClientProtocolClient.java:113)
	at org.apache.ratis.grpc.client.GrpcClientRpc.lambda$new$0(GrpcClientRpc.java:59)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$getProxy$0(PeerProxyMap.java:64)
	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:270)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:63)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:69)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:241)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:194)
	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:280)
	at org.apache.ratis.util.SlidingWindow$Client.submitNewRequest(SlidingWindow.java:259)
	at org.apache.ratis.client.impl.OrderedAsync.send(OrderedAsync.java:170)
	at org.apache.ratis.client.impl.OrderedAsync.newInstance(OrderedAsync.java:118)
	at org.apache.ratis.client.impl.RaftClientImpl.lambda$new$0(RaftClientImpl.java:169)
	at org.apache.ratis.util.MemoizedSupplier.get(MemoizedSupplier.java:62)
	at org.apache.ratis.client.impl.RaftClientImpl.getOrderedAsync(RaftClientImpl.java:223)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:41)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:46)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.lambda$sendRequestAsync$2(XceiverClientRatis.java:242)
	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInNewSpan(TracingUtil.java:162)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendRequestAsync(XceiverClientRatis.java:227)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendCommandAsync(XceiverClientRatis.java:329)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.writeChunkAsync(ContainerProtocolCalls.java:357)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunkToContainer(BlockOutputStream.java:687)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunk(BlockOutputStream.java:525)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:539)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
	at org.apache.hadoop.ozone.TestDataUtil.createKey(TestDataUtil.java:106)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.generateData(TestDecommissionAndMaintenance.java:557)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testSCMHandlesRestartForMaintenanceNode(TestDecommissionAndMaintenance.java:485)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)

Jun 25, 2022 1:09:13 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=480, target=10.1.0.8:36287} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.buildChannel(GrpcClientProtocolClient.java:161)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.<init>(GrpcClientProtocolClient.java:113)
	at org.apache.ratis.grpc.client.GrpcClientRpc.lambda$new$0(GrpcClientRpc.java:59)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$getProxy$0(PeerProxyMap.java:64)
	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:270)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:63)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:69)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:241)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:194)
	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:280)
	at org.apache.ratis.util.SlidingWindow$Client.submitNewRequest(SlidingWindow.java:259)
	at org.apache.ratis.client.impl.OrderedAsync.send(OrderedAsync.java:170)
	at org.apache.ratis.client.impl.OrderedAsync.newInstance(OrderedAsync.java:118)
	at org.apache.ratis.client.impl.RaftClientImpl.lambda$new$0(RaftClientImpl.java:169)
	at org.apache.ratis.util.MemoizedSupplier.get(MemoizedSupplier.java:62)
	at org.apache.ratis.client.impl.RaftClientImpl.getOrderedAsync(RaftClientImpl.java:223)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:41)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:46)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.lambda$sendRequestAsync$2(XceiverClientRatis.java:242)
	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInNewSpan(TracingUtil.java:162)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendRequestAsync(XceiverClientRatis.java:227)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendCommandAsync(XceiverClientRatis.java:329)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.writeChunkAsync(ContainerProtocolCalls.java:357)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunkToContainer(BlockOutputStream.java:687)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunk(BlockOutputStream.java:525)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:539)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
	at org.apache.hadoop.ozone.TestDataUtil.createKey(TestDataUtil.java:106)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.generateData(TestDecommissionAndMaintenance.java:557)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testMaintenanceEndsAutomaticallyAtTimeout(TestDecommissionAndMaintenance.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)

Jun 25, 2022 1:09:13 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=797, target=10.1.0.8:39533} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.buildChannel(GrpcClientProtocolClient.java:161)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.<init>(GrpcClientProtocolClient.java:113)
	at org.apache.ratis.grpc.client.GrpcClientRpc.lambda$new$0(GrpcClientRpc.java:59)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$getProxy$0(PeerProxyMap.java:64)
	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:270)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:63)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:69)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:241)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:194)
	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:280)
	at org.apache.ratis.util.SlidingWindow$Client.submitNewRequest(SlidingWindow.java:259)
	at org.apache.ratis.client.impl.OrderedAsync.send(OrderedAsync.java:170)
	at org.apache.ratis.client.impl.OrderedAsync.newInstance(OrderedAsync.java:118)
	at org.apache.ratis.client.impl.RaftClientImpl.lambda$new$0(RaftClientImpl.java:169)
	at org.apache.ratis.util.MemoizedSupplier.get(MemoizedSupplier.java:62)
	at org.apache.ratis.client.impl.RaftClientImpl.getOrderedAsync(RaftClientImpl.java:223)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:41)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:46)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.lambda$sendRequestAsync$2(XceiverClientRatis.java:242)
	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInNewSpan(TracingUtil.java:162)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendRequestAsync(XceiverClientRatis.java:227)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendCommandAsync(XceiverClientRatis.java:329)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.writeChunkAsync(ContainerProtocolCalls.java:357)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunkToContainer(BlockOutputStream.java:687)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunk(BlockOutputStream.java:525)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:539)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
	at org.apache.hadoop.ozone.TestDataUtil.createKey(TestDataUtil.java:106)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.generateData(TestDecommissionAndMaintenance.java:557)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testSingleNodeWithOpenPipelineCanGotoMaintenance(TestDecommissionAndMaintenance.java:293)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)

2022-06-25 01:09:13,484 [IPC Server handler 1 on default port 37947] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/fb218fe0-94a8-44a0-a252-d3cae8685c6f
2022-06-25 01:09:13,484 [IPC Server handler 1 on default port 37947] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : fb218fe0-94a8-44a0-a252-d3cae8685c6f{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=33555, RATIS=45009, RATIS_ADMIN=45009, RATIS_SERVER=45009, STANDALONE=37667], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:09:13,484 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(275)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-06-25 01:09:13,486 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=7f03d426-270f-432f-9697-9fa706f8f5ed to datanode:fb218fe0-94a8-44a0-a252-d3cae8685c6f
2022-06-25 01:09:13,486 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 7f03d426-270f-432f-9697-9fa706f8f5ed, Nodes: fb218fe0-94a8-44a0-a252-d3cae8685c6f{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=33555, RATIS=45009, RATIS_ADMIN=45009, RATIS_SERVER=45009, STANDALONE=37667], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-25T01:09:13.486Z[Etc/UTC]].
2022-06-25 01:09:13,549 [Listener at 127.0.0.1/39461] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@57d23e95{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-45121-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-8493858738305400964/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
Jun 25, 2022 1:09:13 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=299, target=10.1.0.8:37869} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.buildChannel(GrpcClientProtocolClient.java:161)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.<init>(GrpcClientProtocolClient.java:113)
	at org.apache.ratis.grpc.client.GrpcClientRpc.lambda$new$0(GrpcClientRpc.java:59)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$getProxy$0(PeerProxyMap.java:64)
	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:270)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:63)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:69)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:241)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:194)
	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:280)
	at org.apache.ratis.util.SlidingWindow$Client.submitNewRequest(SlidingWindow.java:259)
	at org.apache.ratis.client.impl.OrderedAsync.send(OrderedAsync.java:170)
	at org.apache.ratis.client.impl.OrderedAsync.newInstance(OrderedAsync.java:118)
	at org.apache.ratis.client.impl.RaftClientImpl.lambda$new$0(RaftClientImpl.java:169)
	at org.apache.ratis.util.MemoizedSupplier.get(MemoizedSupplier.java:62)
	at org.apache.ratis.client.impl.RaftClientImpl.getOrderedAsync(RaftClientImpl.java:223)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:41)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:46)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.lambda$sendRequestAsync$2(XceiverClientRatis.java:242)
	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInNewSpan(TracingUtil.java:162)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendRequestAsync(XceiverClientRatis.java:227)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendCommandAsync(XceiverClientRatis.java:329)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.writeChunkAsync(ContainerProtocolCalls.java:357)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunkToContainer(BlockOutputStream.java:687)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunk(BlockOutputStream.java:525)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:539)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
	at org.apache.hadoop.ozone.TestDataUtil.createKey(TestDataUtil.java:106)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.generateData(TestDecommissionAndMaintenance.java:557)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testContainerIsReplicatedWhenAllNodesGotoMaintenance(TestDecommissionAndMaintenance.java:358)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)

2022-06-25 01:09:13,601 [Listener at 127.0.0.1/39461] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@2067e512{HTTP/1.1, (http/1.1)}{0.0.0.0:45121}
2022-06-25 01:09:13,601 [Listener at 127.0.0.1/39461] INFO  server.Server (Server.java:doStart(415)) - Started @387498ms
2022-06-25 01:09:13,601 [Listener at 127.0.0.1/39461] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-06-25 01:09:13,602 [Listener at 127.0.0.1/39461] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:45121
Jun 25, 2022 1:09:13 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1056, target=10.1.0.8:33641} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.buildChannel(GrpcClientProtocolClient.java:161)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.<init>(GrpcClientProtocolClient.java:113)
	at org.apache.ratis.grpc.client.GrpcClientRpc.lambda$new$0(GrpcClientRpc.java:59)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$getProxy$0(PeerProxyMap.java:64)
	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:270)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:63)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:69)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:241)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:194)
	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:280)
	at org.apache.ratis.util.SlidingWindow$Client.submitNewRequest(SlidingWindow.java:259)
	at org.apache.ratis.client.impl.OrderedAsync.send(OrderedAsync.java:170)
	at org.apache.ratis.client.impl.OrderedAsync.newInstance(OrderedAsync.java:118)
	at org.apache.ratis.client.impl.RaftClientImpl.lambda$new$0(RaftClientImpl.java:169)
	at org.apache.ratis.util.MemoizedSupplier.get(MemoizedSupplier.java:62)
	at org.apache.ratis.client.impl.RaftClientImpl.getOrderedAsync(RaftClientImpl.java:223)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:41)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:46)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.lambda$sendRequestAsync$2(XceiverClientRatis.java:242)
	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInNewSpan(TracingUtil.java:162)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendRequestAsync(XceiverClientRatis.java:227)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendCommandAsync(XceiverClientRatis.java:329)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.writeChunkAsync(ContainerProtocolCalls.java:357)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunkToContainer(BlockOutputStream.java:687)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunk(BlockOutputStream.java:525)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:539)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
	at org.apache.hadoop.ozone.TestDataUtil.createKey(TestDataUtil.java:106)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.generateData(TestDecommissionAndMaintenance.java:557)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testSCMHandlesRestartForMaintenanceNode(TestDecommissionAndMaintenance.java:485)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)

2022-06-25 01:09:13,615 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Waiting for nodes to be ready. Got 4 of 6 DN Heartbeats.
2022-06-25 01:09:13,615 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Waiting for cluster to exit safe mode
2022-06-25 01:09:13,615 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:09:13,626 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(492)) - Ozone container server started.
2022-06-25 01:09:13,633 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 1 is synced with bcsId 72.
2022-06-25 01:09:13,633 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 1 is synced with bcsId 72.
2022-06-25 01:09:13,635 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(346)) - Container 1 is closed with bcsId 72.
2022-06-25 01:09:13,686 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(306)) - Under Replicated Container #1 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Decommission Count: 1 Maintenance Count: 0 inFlightAdd Count: 1 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#1, state=QUASI_CLOSED, datanodeDetails=be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=be67eb5e-e62d-4374-a142-8db592db20d7, sequenceId=72, keyCount=7, bytesUsed=133},ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, sequenceId=72, keyCount=7, bytesUsed=133},ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=3c6128f4-7bf2-4a55-83fb-21add5186158, sequenceId=72, keyCount=7, bytesUsed=133}}
2022-06-25 01:09:13,686 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(306)) - Under Replicated Container #2 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Decommission Count: 1 Maintenance Count: 0 inFlightAdd Count: 1 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#2, state=CLOSED, datanodeDetails=3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=3c6128f4-7bf2-4a55-83fb-21add5186158, sequenceId=76, keyCount=7, bytesUsed=133},ContainerReplica{containerID=#2, state=QUASI_CLOSED, datanodeDetails=be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=be67eb5e-e62d-4374-a142-8db592db20d7, sequenceId=76, keyCount=7, bytesUsed=133},ContainerReplica{containerID=#2, state=CLOSED, datanodeDetails=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, sequenceId=76, keyCount=7, bytesUsed=133}}
2022-06-25 01:09:13,686 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(306)) - Under Replicated Container #3 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Decommission Count: 1 Maintenance Count: 0 inFlightAdd Count: 1 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#3, state=CLOSED, datanodeDetails=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, sequenceId=68, keyCount=6, bytesUsed=114},ContainerReplica{containerID=#3, state=CLOSED, datanodeDetails=3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=3c6128f4-7bf2-4a55-83fb-21add5186158, sequenceId=68, keyCount=6, bytesUsed=114},ContainerReplica{containerID=#3, state=QUASI_CLOSED, datanodeDetails=be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=be67eb5e-e62d-4374-a142-8db592db20d7, sequenceId=68, keyCount=6, bytesUsed=114}}
2022-06-25 01:09:13,686 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(327)) - be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0} has 0 sufficientlyReplicated, 3 underReplicated and 0 unhealthy containers
2022-06-25 01:09:13,687 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(148)) - There are 1 nodes tracked for decommission and maintenance. 0 pending nodes.
2022-06-25 01:09:13,738 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@36083259] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-06-25 01:09:13,761 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:13,767 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-5/meta/datanode.id
2022-06-25 01:09:13,768 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2: addNew group-FACD38847A24:[d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2|rpc:10.1.0.8:43289|priority:1] returns group-FACD38847A24:java.util.concurrent.CompletableFuture@a264bce[Not completed]
2022-06-25 01:09:13,768 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 2 is synced with bcsId 76.
2022-06-25 01:09:13,768 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 2 is synced with bcsId 76.
Jun 25, 2022 1:09:13 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=136, target=10.1.0.8:46353} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.buildChannel(GrpcClientProtocolClient.java:161)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.<init>(GrpcClientProtocolClient.java:113)
	at org.apache.ratis.grpc.client.GrpcClientRpc.lambda$new$0(GrpcClientRpc.java:59)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$getProxy$0(PeerProxyMap.java:64)
	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:270)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:63)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:69)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:241)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:194)
	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:280)
	at org.apache.ratis.util.SlidingWindow$Client.submitNewRequest(SlidingWindow.java:259)
	at org.apache.ratis.client.impl.OrderedAsync.send(OrderedAsync.java:170)
	at org.apache.ratis.client.impl.OrderedAsync.newInstance(OrderedAsync.java:118)
	at org.apache.ratis.client.impl.RaftClientImpl.lambda$new$0(RaftClientImpl.java:169)
	at org.apache.ratis.util.MemoizedSupplier.get(MemoizedSupplier.java:62)
	at org.apache.ratis.client.impl.RaftClientImpl.getOrderedAsync(RaftClientImpl.java:223)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:41)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:46)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.lambda$sendRequestAsync$2(XceiverClientRatis.java:242)
	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInNewSpan(TracingUtil.java:162)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendRequestAsync(XceiverClientRatis.java:227)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendCommandAsync(XceiverClientRatis.java:329)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.writeChunkAsync(ContainerProtocolCalls.java:357)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunkToContainer(BlockOutputStream.java:687)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunk(BlockOutputStream.java:525)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:539)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
	at org.apache.hadoop.ozone.TestDataUtil.createKey(TestDataUtil.java:106)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.generateData(TestDecommissionAndMaintenance.java:557)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testNodeWithOpenPipelineCanBeDecommissionedAndRecommissioned(TestDecommissionAndMaintenance.java:166)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)

Jun 25, 2022 1:09:13 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=130, target=10.1.0.8:34569} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.buildChannel(GrpcClientProtocolClient.java:161)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.<init>(GrpcClientProtocolClient.java:113)
	at org.apache.ratis.grpc.client.GrpcClientRpc.lambda$new$0(GrpcClientRpc.java:59)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$getProxy$0(PeerProxyMap.java:64)
	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:270)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:63)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:69)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:241)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:194)
	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:280)
	at org.apache.ratis.util.SlidingWindow$Client.submitNewRequest(SlidingWindow.java:259)
	at org.apache.ratis.client.impl.OrderedAsync.send(OrderedAsync.java:170)
	at org.apache.ratis.client.impl.OrderedAsync.newInstance(OrderedAsync.java:118)
	at org.apache.ratis.client.impl.RaftClientImpl.lambda$new$0(RaftClientImpl.java:169)
	at org.apache.ratis.util.MemoizedSupplier.get(MemoizedSupplier.java:62)
	at org.apache.ratis.client.impl.RaftClientImpl.getOrderedAsync(RaftClientImpl.java:223)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:41)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:46)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.lambda$sendRequestAsync$2(XceiverClientRatis.java:242)
	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInNewSpan(TracingUtil.java:162)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendRequestAsync(XceiverClientRatis.java:227)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendCommandAsync(XceiverClientRatis.java:329)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.writeChunkAsync(ContainerProtocolCalls.java:357)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunkToContainer(BlockOutputStream.java:687)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunk(BlockOutputStream.java:525)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:539)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
	at org.apache.hadoop.ozone.TestDataUtil.createKey(TestDataUtil.java:106)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.generateData(TestDecommissionAndMaintenance.java:557)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testNodeWithOpenPipelineCanBeDecommissionedAndRecommissioned(TestDecommissionAndMaintenance.java:166)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)

2022-06-25 01:09:13,812 [pool-4406-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2: new RaftServerImpl for group-FACD38847A24:[d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2|rpc:10.1.0.8:43289|priority:1] with ContainerStateMachine:uninitialized
2022-06-25 01:09:13,817 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:09:13,817 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:09:13,821 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:13,821 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:13,821 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:13,821 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:13,821 [pool-4406-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24: ConfigurationManager, init=-1: [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2|rpc:10.1.0.8:43289|priority:1], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:13,821 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-1/data/ratis] (custom)
2022-06-25 01:09:13,821 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:13,821 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:13,821 [pool-4406-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-1/data/ratis/c5771680-4e41-48dc-b9eb-facd38847a24 does not exist. Creating ...
Jun 25, 2022 1:09:13 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=792, target=10.1.0.8:41829} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.buildChannel(GrpcClientProtocolClient.java:161)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.<init>(GrpcClientProtocolClient.java:113)
	at org.apache.ratis.grpc.client.GrpcClientRpc.lambda$new$0(GrpcClientRpc.java:59)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$getProxy$0(PeerProxyMap.java:64)
	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:270)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:63)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:69)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:241)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:194)
	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:280)
	at org.apache.ratis.util.SlidingWindow$Client.submitNewRequest(SlidingWindow.java:259)
	at org.apache.ratis.client.impl.OrderedAsync.send(OrderedAsync.java:170)
	at org.apache.ratis.client.impl.OrderedAsync.newInstance(OrderedAsync.java:118)
	at org.apache.ratis.client.impl.RaftClientImpl.lambda$new$0(RaftClientImpl.java:169)
	at org.apache.ratis.util.MemoizedSupplier.get(MemoizedSupplier.java:62)
	at org.apache.ratis.client.impl.RaftClientImpl.getOrderedAsync(RaftClientImpl.java:223)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:41)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:46)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.lambda$sendRequestAsync$2(XceiverClientRatis.java:242)
	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInNewSpan(TracingUtil.java:162)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendRequestAsync(XceiverClientRatis.java:227)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendCommandAsync(XceiverClientRatis.java:329)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.writeChunkAsync(ContainerProtocolCalls.java:357)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunkToContainer(BlockOutputStream.java:687)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunk(BlockOutputStream.java:525)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:539)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
	at org.apache.hadoop.ozone.TestDataUtil.createKey(TestDataUtil.java:106)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.generateData(TestDecommissionAndMaintenance.java:557)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testSingleNodeWithOpenPipelineCanGotoMaintenance(TestDecommissionAndMaintenance.java:293)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)

Jun 25, 2022 1:09:13 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=491, target=10.1.0.8:35553} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.buildChannel(GrpcClientProtocolClient.java:161)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.<init>(GrpcClientProtocolClient.java:113)
	at org.apache.ratis.grpc.client.GrpcClientRpc.lambda$new$0(GrpcClientRpc.java:59)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.lambda$getProxy$0(PeerProxyMap.java:64)
	at org.apache.ratis.util.LifeCycle.startAndTransition(LifeCycle.java:270)
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:63)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequestAsync(GrpcClientRpc.java:69)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequest(OrderedAsync.java:241)
	at org.apache.ratis.client.impl.OrderedAsync.sendRequestWithRetry(OrderedAsync.java:194)
	at org.apache.ratis.util.SlidingWindow$Client.sendOrDelayRequest(SlidingWindow.java:280)
	at org.apache.ratis.util.SlidingWindow$Client.submitNewRequest(SlidingWindow.java:259)
	at org.apache.ratis.client.impl.OrderedAsync.send(OrderedAsync.java:170)
	at org.apache.ratis.client.impl.OrderedAsync.newInstance(OrderedAsync.java:118)
	at org.apache.ratis.client.impl.RaftClientImpl.lambda$new$0(RaftClientImpl.java:169)
	at org.apache.ratis.util.MemoizedSupplier.get(MemoizedSupplier.java:62)
	at org.apache.ratis.client.impl.RaftClientImpl.getOrderedAsync(RaftClientImpl.java:223)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:41)
	at org.apache.ratis.client.impl.AsyncImpl.send(AsyncImpl.java:46)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.lambda$sendRequestAsync$2(XceiverClientRatis.java:242)
	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInNewSpan(TracingUtil.java:162)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendRequestAsync(XceiverClientRatis.java:227)
	at org.apache.hadoop.hdds.scm.XceiverClientRatis.sendCommandAsync(XceiverClientRatis.java:329)
	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.writeChunkAsync(ContainerProtocolCalls.java:357)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunkToContainer(BlockOutputStream.java:687)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.writeChunk(BlockOutputStream.java:525)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:539)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
	at org.apache.hadoop.ozone.TestDataUtil.createKey(TestDataUtil.java:106)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.generateData(TestDecommissionAndMaintenance.java:557)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testMaintenanceEndsAutomaticallyAtTimeout(TestDecommissionAndMaintenance.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)

2022-06-25 01:09:13,826 [pool-4406-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-1/data/ratis/c5771680-4e41-48dc-b9eb-facd38847a24/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:13,898 [pool-4406-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-1/data/ratis/c5771680-4e41-48dc-b9eb-facd38847a24 has been successfully formatted.
2022-06-25 01:09:13,899 [pool-4406-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-FACD38847A24: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:09:13,899 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:09:13,899 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:13,899 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:13,899 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:13,899 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:13,900 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:13,901 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:13,901 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:13,901 [pool-4406-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-1/data/ratis/c5771680-4e41-48dc-b9eb-facd38847a24
2022-06-25 01:09:13,901 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:09:13,901 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:09:13,901 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:13,901 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:09:13,901 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:13,901 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:13,902 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:13,902 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:13,903 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(358)) - Pipeline Pipeline[ Id: c5771680-4e41-48dc-b9eb-facd38847a24, Nodes: d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=44807, RATIS=43289, RATIS_ADMIN=43289, RATIS_SERVER=43289, STANDALONE=40157], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2, CreationTimestamp2022-06-25T01:09:10.755Z[Etc/UTC]] moved to OPEN state
2022-06-25 01:09:13,903 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:13,905 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:09:13,906 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:13,906 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:09:13,906 [pool-4406-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:13,926 [pool-4406-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:13,876 [pool-4429-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - a39a8077-0667-4534-bc11-ae9dd274a08a: new RaftServerImpl for group-812A35E9D7FA:[a39a8077-0667-4534-bc11-ae9dd274a08a|rpc:10.1.0.8:35251|dataStream:|priority:0, d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2|rpc:10.1.0.8:43289|dataStream:|priority:1, 489bfe9a-d541-48f0-84f9-7976b526cd96|rpc:10.1.0.8:43031|dataStream:|priority:0] with ContainerStateMachine:uninitialized
2022-06-25 01:09:13,876 [grpc-default-executor-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - a39a8077-0667-4534-bc11-ae9dd274a08a: addNew group-812A35E9D7FA:[a39a8077-0667-4534-bc11-ae9dd274a08a|rpc:10.1.0.8:35251|dataStream:|priority:0, d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2|rpc:10.1.0.8:43289|dataStream:|priority:1, 489bfe9a-d541-48f0-84f9-7976b526cd96|rpc:10.1.0.8:43031|dataStream:|priority:0] returns group-812A35E9D7FA:java.util.concurrent.CompletableFuture@5a94d3a8[Not completed]
2022-06-25 01:09:13,927 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:09:13,927 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:09:13,927 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:13,927 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:13,927 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:13,927 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:13,927 [pool-4429-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA: ConfigurationManager, init=-1: [a39a8077-0667-4534-bc11-ae9dd274a08a|rpc:10.1.0.8:35251|dataStream:|priority:0, d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2|rpc:10.1.0.8:43289|dataStream:|priority:1, 489bfe9a-d541-48f0-84f9-7976b526cd96|rpc:10.1.0.8:43031|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:13,927 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-2/data/ratis] (custom)
2022-06-25 01:09:13,927 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:13,927 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:13,928 [pool-4429-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-2/data/ratis/f02b0cd8-3fde-485f-9ca2-812a35e9d7fa does not exist. Creating ...
2022-06-25 01:09:13,931 [pool-4429-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-2/data/ratis/f02b0cd8-3fde-485f-9ca2-812a35e9d7fa/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:13,859 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(346)) - Container 2 is closed with bcsId 76.
2022-06-25 01:09:13,933 [pool-4429-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-2/data/ratis/f02b0cd8-3fde-485f-9ca2-812a35e9d7fa has been successfully formatted.
2022-06-25 01:09:13,965 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:13,965 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:09:13,965 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:09:13,965 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:09:13,965 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:09:13,965 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:13,966 [pool-4429-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-812A35E9D7FA: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:09:13,966 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 3 is synced with bcsId 68.
2022-06-25 01:09:13,967 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 3 is synced with bcsId 68.
2022-06-25 01:09:13,968 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:09:13,968 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:13,968 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:13,968 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:13,968 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(346)) - Container 3 is closed with bcsId 68.
2022-06-25 01:09:13,968 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:13,999 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 18 milliseconds for processing 3 containers.
2022-06-25 01:09:14,000 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:14,001 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:14,001 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:14,001 [pool-4429-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-2/data/ratis/f02b0cd8-3fde-485f-9ca2-812a35e9d7fa
2022-06-25 01:09:14,001 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:09:14,002 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:09:14,002 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:14,002 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:09:14,002 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:14,002 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:14,002 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:14,002 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:14,027 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 1 from [be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0}, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-25 01:09:14,047 [grpc-default-executor-1] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(52)) - Streaming container data (1) to other datanode
2022-06-25 01:09:14,051 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:09:14,052 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:14,052 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:09:14,052 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:14,052 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:14,053 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:14,053 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:14,053 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:14,053 [pool-4406-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24: start as a follower, conf=-1: [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2|rpc:10.1.0.8:43289|priority:1], old=null
2022-06-25 01:09:14,053 [pool-4406-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:14,053 [pool-4406-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2: start d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-FollowerState
2022-06-25 01:09:14,053 [pool-4429-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:14,053 [pool-4429-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:14,074 [grpc-default-executor-1] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 10689 bytes for container 1
2022-06-25 01:09:14,078 [grpc-default-executor-0] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(197)) - Container 1 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data/replication/work/container-1.tar.gz
2022-06-25 01:09:14,104 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:14,104 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:09:14,104 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:09:14,104 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:09:14,104 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:09:14,104 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:14,107 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 1 is downloaded with size 10689, starting to import.
2022-06-25 01:09:14,110 [pool-4406-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FACD38847A24,id=d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2
2022-06-25 01:09:14,122 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:14,122 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:14,122 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:14,122 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:14,122 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:14,123 [pool-4429-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA: start as a follower, conf=-1: [a39a8077-0667-4534-bc11-ae9dd274a08a|rpc:10.1.0.8:35251|dataStream:|priority:0, d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2|rpc:10.1.0.8:43289|dataStream:|priority:1, 489bfe9a-d541-48f0-84f9-7976b526cd96|rpc:10.1.0.8:43031|dataStream:|priority:0], old=null
2022-06-25 01:09:14,123 [pool-4429-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:14,134 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=c5771680-4e41-48dc-b9eb-facd38847a24
2022-06-25 01:09:14,134 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=c5771680-4e41-48dc-b9eb-facd38847a24.
2022-06-25 01:09:14,134 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2: addNew group-812A35E9D7FA:[a39a8077-0667-4534-bc11-ae9dd274a08a|rpc:10.1.0.8:35251|priority:0, d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2|rpc:10.1.0.8:43289|priority:1, 489bfe9a-d541-48f0-84f9-7976b526cd96|rpc:10.1.0.8:43031|priority:0] returns group-812A35E9D7FA:java.util.concurrent.CompletableFuture@e19ce52[Not completed]
2022-06-25 01:09:14,139 [pool-4406-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2: new RaftServerImpl for group-812A35E9D7FA:[a39a8077-0667-4534-bc11-ae9dd274a08a|rpc:10.1.0.8:35251|priority:0, d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2|rpc:10.1.0.8:43289|priority:1, 489bfe9a-d541-48f0-84f9-7976b526cd96|rpc:10.1.0.8:43031|priority:0] with ContainerStateMachine:uninitialized
2022-06-25 01:09:14,139 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:09:14,139 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:09:14,139 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:14,139 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:14,139 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:14,140 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:14,140 [pool-4406-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA: ConfigurationManager, init=-1: [a39a8077-0667-4534-bc11-ae9dd274a08a|rpc:10.1.0.8:35251|priority:0, d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2|rpc:10.1.0.8:43289|priority:1, 489bfe9a-d541-48f0-84f9-7976b526cd96|rpc:10.1.0.8:43031|priority:0], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:14,140 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-1/data/ratis] (custom)
2022-06-25 01:09:14,140 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:14,140 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:14,140 [pool-4406-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-1/data/ratis/f02b0cd8-3fde-485f-9ca2-812a35e9d7fa does not exist. Creating ...
2022-06-25 01:09:14,150 [pool-4406-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-1/data/ratis/f02b0cd8-3fde-485f-9ca2-812a35e9d7fa/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:14,152 [pool-4406-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-1/data/ratis/f02b0cd8-3fde-485f-9ca2-812a35e9d7fa has been successfully formatted.
2022-06-25 01:09:14,152 [pool-4406-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-812A35E9D7FA: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:09:14,152 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:09:14,152 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:14,152 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:14,153 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:14,153 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:14,153 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:14,153 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:14,154 [pool-4429-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a39a8077-0667-4534-bc11-ae9dd274a08a: start a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA-FollowerState
2022-06-25 01:09:14,154 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:14,154 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:14,155 [pool-4406-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-1/data/ratis/f02b0cd8-3fde-485f-9ca2-812a35e9d7fa
2022-06-25 01:09:14,155 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:09:14,155 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:09:14,155 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:14,155 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:09:14,155 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:14,155 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:14,155 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:14,155 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:14,155 [pool-4429-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-812A35E9D7FA,id=a39a8077-0667-4534-bc11-ae9dd274a08a
2022-06-25 01:09:14,160 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:09:14,160 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:14,160 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:09:14,160 [pool-4406-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:14,160 [pool-4406-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:14,174 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(309)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-4/data-0/containers/hdds/5319b9db-8434-46dc-af7a-58e933abef82/DS-1ef2ec96-90af-468a-bc21-c1a1dfd7a4b7/container.db for volume DS-1ef2ec96-90af-468a-bc21-c1a1dfd7a4b7
2022-06-25 01:09:14,175 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(340)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-4/data-0/containers/hdds/5319b9db-8434-46dc-af7a-58e933abef82/DS-1ef2ec96-90af-468a-bc21-c1a1dfd7a4b7/container.db for volume DS-1ef2ec96-90af-468a-bc21-c1a1dfd7a4b7
2022-06-25 01:09:14,175 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(344)) - Attempting to start container services.
2022-06-25 01:09:14,175 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(279)) - Background container scanner has been disabled.
2022-06-25 01:09:14,176 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:14,176 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:09:14,176 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:09:14,176 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:09:14,176 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:09:14,176 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:14,183 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 37707
2022-06-25 01:09:14,198 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 1 is replicated successfully
2022-06-25 01:09:14,198 [ContainerReplicationThread-0] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(176)) - Container 1 is replicated.
2022-06-25 01:09:14,249 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:14,249 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:14,249 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:14,249 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:14,249 [pool-4406-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:14,249 [pool-4406-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA: start as a follower, conf=-1: [a39a8077-0667-4534-bc11-ae9dd274a08a|rpc:10.1.0.8:35251|priority:0, d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2|rpc:10.1.0.8:43289|priority:1, 489bfe9a-d541-48f0-84f9-7976b526cd96|rpc:10.1.0.8:43031|priority:0], old=null
2022-06-25 01:09:14,249 [pool-4406-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:14,249 [pool-4406-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2: start d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-FollowerState
2022-06-25 01:09:14,249 [pool-4406-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-812A35E9D7FA,id=d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2
2022-06-25 01:09:14,258 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=f02b0cd8-3fde-485f-9ca2-812a35e9d7fa
2022-06-25 01:09:14,265 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:14,297 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis d5d86ba7-8a8a-4b58-b698-440423a66b5d
2022-06-25 01:09:14,338 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d: start RPC server
2022-06-25 01:09:14,345 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d: GrpcService started, listening on 41783
2022-06-25 01:09:14,365 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis d5d86ba7-8a8a-4b58-b698-440423a66b5d is started using port 41783 for RATIS
2022-06-25 01:09:14,365 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis d5d86ba7-8a8a-4b58-b698-440423a66b5d is started using port 41783 for RATIS_ADMIN
2022-06-25 01:09:14,365 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis d5d86ba7-8a8a-4b58-b698-440423a66b5d is started using port 41783 for RATIS_SERVER
2022-06-25 01:09:14,366 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@1a74e36] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-d5d86ba7-8a8a-4b58-b698-440423a66b5d: Started
2022-06-25 01:09:14,368 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5168940039ns, electionTimeout:5117ms
2022-06-25 01:09:14,368 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: shutdown 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:14,368 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
2022-06-25 01:09:14,368 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5072010254ns, electionTimeout:5044ms
2022-06-25 01:09:14,368 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: shutdown fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:14,368 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
2022-06-25 01:09:14,372 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5122017553ns, electionTimeout:5076ms
2022-06-25 01:09:14,372 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: shutdown 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:14,372 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
2022-06-25 01:09:14,378 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc d5d86ba7-8a8a-4b58-b698-440423a66b5d is started using port 44275
2022-06-25 01:09:14,430 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:14,430 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: start 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection167
2022-06-25 01:09:14,449 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:14,449 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: start fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection166
2022-06-25 01:09:14,450 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:14,536 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: start 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection165
2022-06-25 01:09:14,455 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection167] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection167 ELECTION round 0: submit vote requests at term 5 for -1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:09:14,550 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=f02b0cd8-3fde-485f-9ca2-812a35e9d7fa.
2022-06-25 01:09:14,579 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection166] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection166 ELECTION round 0: submit vote requests at term 5 for -1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|priority:0], old=null
2022-06-25 01:09:14,581 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection165] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection165 ELECTION round 0: submit vote requests at term 5 for -1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:09:14,583 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: receive requestVote(ELECTION, fc692a40-1ae9-40b7-8d63-7e46f51df1ef, group-B6B9DF3CEF32, 5, (t:0, i:0))
2022-06-25 01:09:14,583 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-CANDIDATE: reject ELECTION from fc692a40-1ae9-40b7-8d63-7e46f51df1ef: already has voted for 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9 at current term 5
2022-06-25 01:09:14,583 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32 replies to ELECTION vote request: fc692a40-1ae9-40b7-8d63-7e46f51df1ef<-4943f96b-6a06-411a-b0ee-4ab66ab6f7f9#0:FAIL-t5. Peer's state: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32:t5, leader=null, voted=4943f96b-6a06-411a-b0ee-4ab66ab6f7f9, raftlog=4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:09:14,586 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 3 from [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0}]
2022-06-25 01:09:14,586 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: receive requestVote(ELECTION, fc692a40-1ae9-40b7-8d63-7e46f51df1ef, group-B6B9DF3CEF32, 5, (t:0, i:0))
2022-06-25 01:09:14,586 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(48)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-CANDIDATE: reject ELECTION from fc692a40-1ae9-40b7-8d63-7e46f51df1ef: already has voted for 97d08340-a146-41c4-a759-b3b136c7fb6d at current term 5
2022-06-25 01:09:14,586 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32 replies to ELECTION vote request: fc692a40-1ae9-40b7-8d63-7e46f51df1ef<-97d08340-a146-41c4-a759-b3b136c7fb6d#0:FAIL-t5. Peer's state: 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32:t5, leader=null, voted=97d08340-a146-41c4-a759-b3b136c7fb6d, raftlog=97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:09:14,615 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Waiting for nodes to be ready. Got 4 of 6 DN Heartbeats.
2022-06-25 01:09:14,615 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Waiting for cluster to exit safe mode
2022-06-25 01:09:14,615 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:09:14,661 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection166] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection166: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-06-25 01:09:14,661 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection166] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: fc692a40-1ae9-40b7-8d63-7e46f51df1ef<-4943f96b-6a06-411a-b0ee-4ab66ab6f7f9#0:FAIL-t5
2022-06-25 01:09:14,661 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection166] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: fc692a40-1ae9-40b7-8d63-7e46f51df1ef<-97d08340-a146-41c4-a759-b3b136c7fb6d#0:FAIL-t5
2022-06-25 01:09:14,661 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: receive requestVote(ELECTION, 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9, group-B6B9DF3CEF32, 5, (t:0, i:0))
2022-06-25 01:09:14,661 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-CANDIDATE: reject ELECTION from 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: already has voted for 97d08340-a146-41c4-a759-b3b136c7fb6d at current term 5
2022-06-25 01:09:14,661 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32 replies to ELECTION vote request: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9<-97d08340-a146-41c4-a759-b3b136c7fb6d#0:FAIL-t5. Peer's state: 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32:t5, leader=null, voted=97d08340-a146-41c4-a759-b3b136c7fb6d, raftlog=97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:09:14,662 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: receive requestVote(ELECTION, 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9, group-B6B9DF3CEF32, 5, (t:0, i:0))
2022-06-25 01:09:14,662 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(48)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-CANDIDATE: reject ELECTION from 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: already has voted for fc692a40-1ae9-40b7-8d63-7e46f51df1ef at current term 5
2022-06-25 01:09:14,662 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32 replies to ELECTION vote request: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9<-fc692a40-1ae9-40b7-8d63-7e46f51df1ef#0:FAIL-t5. Peer's state: fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32:t5, leader=null, voted=fc692a40-1ae9-40b7-8d63-7e46f51df1ef, raftlog=fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|priority:0], old=null
2022-06-25 01:09:14,663 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: receive requestVote(ELECTION, 97d08340-a146-41c4-a759-b3b136c7fb6d, group-B6B9DF3CEF32, 5, (t:0, i:0))
2022-06-25 01:09:14,664 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(48)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-CANDIDATE: reject ELECTION from 97d08340-a146-41c4-a759-b3b136c7fb6d: already has voted for 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9 at current term 5
2022-06-25 01:09:14,664 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32 replies to ELECTION vote request: 97d08340-a146-41c4-a759-b3b136c7fb6d<-4943f96b-6a06-411a-b0ee-4ab66ab6f7f9#0:FAIL-t5. Peer's state: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32:t5, leader=null, voted=4943f96b-6a06-411a-b0ee-4ab66ab6f7f9, raftlog=4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:09:14,683 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - a39a8077-0667-4534-bc11-ae9dd274a08a: addNew group-8B004CA1AD68:[a39a8077-0667-4534-bc11-ae9dd274a08a|rpc:10.1.0.8:35251|priority:1] returns group-8B004CA1AD68:java.util.concurrent.CompletableFuture@62c4c604[Not completed]
2022-06-25 01:09:14,684 [pool-4429-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - a39a8077-0667-4534-bc11-ae9dd274a08a: new RaftServerImpl for group-8B004CA1AD68:[a39a8077-0667-4534-bc11-ae9dd274a08a|rpc:10.1.0.8:35251|priority:1] with ContainerStateMachine:uninitialized
2022-06-25 01:09:14,684 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:09:14,684 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:09:14,684 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:14,684 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:14,684 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:14,684 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:14,684 [pool-4429-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68: ConfigurationManager, init=-1: [a39a8077-0667-4534-bc11-ae9dd274a08a|rpc:10.1.0.8:35251|priority:1], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:14,684 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-2/data/ratis] (custom)
2022-06-25 01:09:14,685 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:14,685 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:14,685 [pool-4429-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-2/data/ratis/422c7861-ced3-461a-a0fc-8b004ca1ad68 does not exist. Creating ...
2022-06-25 01:09:14,686 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(306)) - Under Replicated Container #2 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Decommission Count: 1 Maintenance Count: 0 inFlightAdd Count: 1 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#2, state=CLOSED, datanodeDetails=3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=3c6128f4-7bf2-4a55-83fb-21add5186158, sequenceId=76, keyCount=7, bytesUsed=133},ContainerReplica{containerID=#2, state=CLOSED, datanodeDetails=be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=be67eb5e-e62d-4374-a142-8db592db20d7, sequenceId=76, keyCount=7, bytesUsed=133},ContainerReplica{containerID=#2, state=CLOSED, datanodeDetails=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, sequenceId=76, keyCount=7, bytesUsed=133}}
2022-06-25 01:09:14,686 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(306)) - Under Replicated Container #3 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Decommission Count: 1 Maintenance Count: 0 inFlightAdd Count: 1 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#3, state=CLOSED, datanodeDetails=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, sequenceId=68, keyCount=6, bytesUsed=114},ContainerReplica{containerID=#3, state=CLOSED, datanodeDetails=3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=3c6128f4-7bf2-4a55-83fb-21add5186158, sequenceId=68, keyCount=6, bytesUsed=114},ContainerReplica{containerID=#3, state=CLOSED, datanodeDetails=be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=be67eb5e-e62d-4374-a142-8db592db20d7, sequenceId=68, keyCount=6, bytesUsed=114}}
2022-06-25 01:09:14,686 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(327)) - be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0} has 1 sufficientlyReplicated, 2 underReplicated and 0 unhealthy containers
2022-06-25 01:09:14,686 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(148)) - There are 1 nodes tracked for decommission and maintenance. 0 pending nodes.
2022-06-25 01:09:14,687 [pool-4429-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-2/data/ratis/422c7861-ced3-461a-a0fc-8b004ca1ad68/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:14,688 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection167] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection167: ELECTION REJECTED received 1 response(s) and 0 exception(s):
2022-06-25 01:09:14,688 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection167] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9<-97d08340-a146-41c4-a759-b3b136c7fb6d#0:FAIL-t5
2022-06-25 01:09:14,688 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection167] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection167 ELECTION round 0: result REJECTED
2022-06-25 01:09:14,688 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection167] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: changes role from CANDIDATE to FOLLOWER at term 5 for REJECTED
2022-06-25 01:09:14,688 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection167] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: shutdown 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection167
2022-06-25 01:09:14,689 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection167] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: start 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:14,689 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: receive requestVote(ELECTION, 97d08340-a146-41c4-a759-b3b136c7fb6d, group-B6B9DF3CEF32, 5, (t:0, i:0))
2022-06-25 01:09:14,689 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-CANDIDATE: reject ELECTION from 97d08340-a146-41c4-a759-b3b136c7fb6d: already has voted for fc692a40-1ae9-40b7-8d63-7e46f51df1ef at current term 5
2022-06-25 01:09:14,689 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32 replies to ELECTION vote request: 97d08340-a146-41c4-a759-b3b136c7fb6d<-fc692a40-1ae9-40b7-8d63-7e46f51df1ef#0:FAIL-t5. Peer's state: fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32:t5, leader=null, voted=fc692a40-1ae9-40b7-8d63-7e46f51df1ef, raftlog=fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|priority:0], old=null
2022-06-25 01:09:14,690 [pool-4429-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-2/data/ratis/422c7861-ced3-461a-a0fc-8b004ca1ad68 has been successfully formatted.
2022-06-25 01:09:14,697 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection166] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection166 ELECTION round 0: result REJECTED
2022-06-25 01:09:14,697 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection166] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: changes role from CANDIDATE to FOLLOWER at term 5 for REJECTED
2022-06-25 01:09:14,697 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection166] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: shutdown fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection166
2022-06-25 01:09:14,697 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-LeaderElection166] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: start fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:14,697 [pool-4429-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-8B004CA1AD68: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:09:14,697 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:09:14,697 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:14,697 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:14,697 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:14,697 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:14,698 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:14,699 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:14,700 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:14,700 [pool-4429-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-2/data/ratis/422c7861-ced3-461a-a0fc-8b004ca1ad68
2022-06-25 01:09:14,700 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:09:14,700 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:09:14,700 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:14,700 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:09:14,700 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:14,700 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:14,700 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:14,700 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:14,754 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:09:14,754 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:14,755 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:09:14,755 [pool-4429-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:14,755 [pool-4429-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:14,755 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:14,755 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:09:14,755 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:09:14,755 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:09:14,755 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:09:14,755 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:14,761 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:14,775 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(358)) - Pipeline Pipeline[ Id: 422c7861-ced3-461a-a0fc-8b004ca1ad68, Nodes: a39a8077-0667-4534-bc11-ae9dd274a08a{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=37533, RATIS=35251, RATIS_ADMIN=35251, RATIS_SERVER=35251, STANDALONE=42177], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:a39a8077-0667-4534-bc11-ae9dd274a08a, CreationTimestamp2022-06-25T01:09:11.702Z[Etc/UTC]] moved to OPEN state
2022-06-25 01:09:14,829 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 2 from [3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0}, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-25 01:09:14,860 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:14,860 [grpc-default-executor-6] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(52)) - Streaming container data (3) to other datanode
2022-06-25 01:09:14,860 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection165] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection165: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-06-25 01:09:14,860 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection165] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 97d08340-a146-41c4-a759-b3b136c7fb6d<-4943f96b-6a06-411a-b0ee-4ab66ab6f7f9#0:FAIL-t5
2022-06-25 01:09:14,860 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection165] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 97d08340-a146-41c4-a759-b3b136c7fb6d<-fc692a40-1ae9-40b7-8d63-7e46f51df1ef#0:FAIL-t5
2022-06-25 01:09:14,860 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection165] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection165 ELECTION round 0: result REJECTED
2022-06-25 01:09:14,860 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection165] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: changes role from CANDIDATE to FOLLOWER at term 5 for REJECTED
2022-06-25 01:09:14,860 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection165] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: shutdown 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection165
2022-06-25 01:09:14,861 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection165] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: start 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:14,880 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:14,880 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:14,880 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:14,880 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:14,880 [pool-4429-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:14,880 [pool-4429-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68: start as a follower, conf=-1: [a39a8077-0667-4534-bc11-ae9dd274a08a|rpc:10.1.0.8:35251|priority:1], old=null
2022-06-25 01:09:14,881 [pool-4429-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:14,900 [pool-4429-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a39a8077-0667-4534-bc11-ae9dd274a08a: start a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-FollowerState
2022-06-25 01:09:14,903 [grpc-default-executor-0] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(52)) - Streaming container data (2) to other datanode
2022-06-25 01:09:14,915 [grpc-default-executor-0] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 10754 bytes for container 2
2022-06-25 01:09:14,924 [grpc-default-executor-6] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 10700 bytes for container 3
2022-06-25 01:09:14,928 [grpc-default-executor-0] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(197)) - Container 3 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/data/replication/work/container-3.tar.gz
2022-06-25 01:09:14,934 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 3 is downloaded with size 10700, starting to import.
2022-06-25 01:09:14,983 [pool-4429-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8B004CA1AD68,id=a39a8077-0667-4534-bc11-ae9dd274a08a
2022-06-25 01:09:15,000 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:15,018 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=422c7861-ced3-461a-a0fc-8b004ca1ad68
2022-06-25 01:09:15,018 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=422c7861-ced3-461a-a0fc-8b004ca1ad68.
2022-06-25 01:09:15,032 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=f02b0cd8-3fde-485f-9ca2-812a35e9d7fa.
2022-06-25 01:09:15,067 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 3 is replicated successfully
2022-06-25 01:09:15,067 [ContainerReplicationThread-0] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(176)) - Container 3 is replicated.
2022-06-25 01:09:15,068 [grpc-default-executor-5] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(197)) - Container 2 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data/replication/work/container-2.tar.gz
2022-06-25 01:09:15,074 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 2 is downloaded with size 10754, starting to import.
2022-06-25 01:09:15,157 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:15,165 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 2 is replicated successfully
2022-06-25 01:09:15,165 [ContainerReplicationThread-0] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(176)) - Container 2 is replicated.
2022-06-25 01:09:15,266 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:15,524 [IPC Server handler 3 on default port 37947] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/d5d86ba7-8a8a-4b58-b698-440423a66b5d
2022-06-25 01:09:15,524 [IPC Server handler 3 on default port 37947] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : d5d86ba7-8a8a-4b58-b698-440423a66b5d{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=37707, RATIS=41783, RATIS_ADMIN=41783, RATIS_SERVER=41783, STANDALONE=44275], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:09:15,524 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(275)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-06-25 01:09:15,524 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=a7dc16f4-8814-423a-a883-252483a22734 to datanode:d5d86ba7-8a8a-4b58-b698-440423a66b5d
2022-06-25 01:09:15,525 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: a7dc16f4-8814-423a-a883-252483a22734, Nodes: d5d86ba7-8a8a-4b58-b698-440423a66b5d{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=37707, RATIS=41783, RATIS_ADMIN=41783, RATIS_SERVER=41783, STANDALONE=44275], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-25T01:09:15.524Z[Etc/UTC]].
2022-06-25 01:09:15,618 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Waiting for nodes to be ready. Got 5 of 6 DN Heartbeats.
2022-06-25 01:09:15,618 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Waiting for cluster to exit safe mode
2022-06-25 01:09:15,618 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:09:15,702 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(327)) - be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0} has 3 sufficientlyReplicated, 0 underReplicated and 0 unhealthy containers
2022-06-25 01:09:15,703 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:completeDecommission(355)) - Datanode be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0} has completed the admin workflow. The operational state has been set to DECOMMISSIONED
2022-06-25 01:09:15,703 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0} moved to HEALTHY state.
2022-06-25 01:09:15,703 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(275)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-06-25 01:09:15,703 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:15,819 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:15,981 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(309)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-5/data-0/containers/hdds/5319b9db-8434-46dc-af7a-58e933abef82/DS-a2ff7142-4889-48ac-8029-74e36da10125/container.db for volume DS-a2ff7142-4889-48ac-8029-74e36da10125
2022-06-25 01:09:15,982 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(340)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-5/data-0/containers/hdds/5319b9db-8434-46dc-af7a-58e933abef82/DS-a2ff7142-4889-48ac-8029-74e36da10125/container.db for volume DS-a2ff7142-4889-48ac-8029-74e36da10125
2022-06-25 01:09:15,982 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(344)) - Attempting to start container services.
2022-06-25 01:09:15,982 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(279)) - Background container scanner has been disabled.
2022-06-25 01:09:15,986 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 44821
2022-06-25 01:09:16,001 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:16,053 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis a2e7c5f8-591a-42df-bc70-018e5970ca84
2022-06-25 01:09:16,087 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - a2e7c5f8-591a-42df-bc70-018e5970ca84: start RPC server
2022-06-25 01:09:16,097 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - a2e7c5f8-591a-42df-bc70-018e5970ca84: GrpcService started, listening on 44971
2022-06-25 01:09:16,104 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis a2e7c5f8-591a-42df-bc70-018e5970ca84 is started using port 44971 for RATIS
2022-06-25 01:09:16,104 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis a2e7c5f8-591a-42df-bc70-018e5970ca84 is started using port 44971 for RATIS_ADMIN
2022-06-25 01:09:16,104 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis a2e7c5f8-591a-42df-bc70-018e5970ca84 is started using port 44971 for RATIS_SERVER
2022-06-25 01:09:16,104 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@3babaf97] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-a2e7c5f8-591a-42df-bc70-018e5970ca84: Started
2022-06-25 01:09:16,131 [EndpointStateMachine task thread for /0.0.0.0:37947 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc a2e7c5f8-591a-42df-bc70-018e5970ca84 is started using port 40483
2022-06-25 01:09:16,511 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f: addNew group-9FA706F8F5ED:[fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|priority:1] returns group-9FA706F8F5ED:java.util.concurrent.CompletableFuture@77569e1a[Not completed]
2022-06-25 01:09:16,512 [pool-4456-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f: new RaftServerImpl for group-9FA706F8F5ED:[fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|priority:1] with ContainerStateMachine:uninitialized
2022-06-25 01:09:16,512 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:09:16,512 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:09:16,512 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:16,512 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:16,512 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:16,512 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:16,512 [pool-4456-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED: ConfigurationManager, init=-1: [fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|priority:1], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:16,512 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-3/data/ratis] (custom)
2022-06-25 01:09:16,513 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:16,513 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:16,513 [pool-4456-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-3/data/ratis/7f03d426-270f-432f-9697-9fa706f8f5ed does not exist. Creating ...
2022-06-25 01:09:16,538 [pool-4456-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-3/data/ratis/7f03d426-270f-432f-9697-9fa706f8f5ed/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:16,544 [pool-4456-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-3/data/ratis/7f03d426-270f-432f-9697-9fa706f8f5ed has been successfully formatted.
2022-06-25 01:09:16,544 [pool-4456-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-9FA706F8F5ED: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:09:16,544 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:09:16,544 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:16,545 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:16,545 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(358)) - Pipeline Pipeline[ Id: 7f03d426-270f-432f-9697-9fa706f8f5ed, Nodes: fb218fe0-94a8-44a0-a252-d3cae8685c6f{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=33555, RATIS=45009, RATIS_ADMIN=45009, RATIS_SERVER=45009, STANDALONE=37667], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:fb218fe0-94a8-44a0-a252-d3cae8685c6f, CreationTimestamp2022-06-25T01:09:13.486Z[Etc/UTC]] moved to OPEN state
2022-06-25 01:09:16,546 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:16,546 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:16,546 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:16,546 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:16,547 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:16,548 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:16,548 [pool-4456-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-3/data/ratis/7f03d426-270f-432f-9697-9fa706f8f5ed
2022-06-25 01:09:16,548 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:09:16,548 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:09:16,548 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:16,548 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:09:16,548 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:16,548 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:16,548 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:16,548 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:16,601 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:09:16,602 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:16,602 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:09:16,602 [pool-4456-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:16,602 [pool-4456-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:16,604 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:16,604 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:09:16,604 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:09:16,604 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:09:16,604 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:09:16,604 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:16,609 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:16,609 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:16,609 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:16,609 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:16,609 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:16,609 [pool-4456-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED: start as a follower, conf=-1: [fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|priority:1], old=null
2022-06-25 01:09:16,609 [pool-4456-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:16,609 [pool-4456-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f: start fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-FollowerState
2022-06-25 01:09:16,622 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Waiting for nodes to be ready. Got 5 of 6 DN Heartbeats.
2022-06-25 01:09:16,622 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Waiting for cluster to exit safe mode
2022-06-25 01:09:16,622 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:09:16,622 [pool-4456-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9FA706F8F5ED,id=fb218fe0-94a8-44a0-a252-d3cae8685c6f
2022-06-25 01:09:16,624 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=7f03d426-270f-432f-9697-9fa706f8f5ed
2022-06-25 01:09:16,624 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=7f03d426-270f-432f-9697-9fa706f8f5ed.
2022-06-25 01:09:16,819 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:17,002 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:17,158 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:17,260 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:17,622 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Waiting for nodes to be ready. Got 5 of 6 DN Heartbeats.
2022-06-25 01:09:17,622 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Waiting for cluster to exit safe mode
2022-06-25 01:09:17,622 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:09:17,752 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:17,753 [IPC Server handler 9 on default port 37947] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/a2e7c5f8-591a-42df-bc70-018e5970ca84
2022-06-25 01:09:17,753 [IPC Server handler 9 on default port 37947] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : a2e7c5f8-591a-42df-bc70-018e5970ca84{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=44821, RATIS=44971, RATIS_ADMIN=44971, RATIS_SERVER=44971, STANDALONE=40483], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:09:17,753 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(275)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-06-25 01:09:17,758 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=349de946-adbc-4715-b282-faa751117728 to datanode:a2e7c5f8-591a-42df-bc70-018e5970ca84
2022-06-25 01:09:17,759 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 349de946-adbc-4715-b282-faa751117728, Nodes: a2e7c5f8-591a-42df-bc70-018e5970ca84{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=44821, RATIS=44971, RATIS_ADMIN=44971, RATIS_SERVER=44971, STANDALONE=40483], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-25T01:09:17.758Z[Etc/UTC]].
2022-06-25 01:09:17,759 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=2bdffe63-c296-423e-8231-09829804023a to datanode:d5d86ba7-8a8a-4b58-b698-440423a66b5d
2022-06-25 01:09:17,759 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=2bdffe63-c296-423e-8231-09829804023a to datanode:fb218fe0-94a8-44a0-a252-d3cae8685c6f
2022-06-25 01:09:17,759 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=2bdffe63-c296-423e-8231-09829804023a to datanode:a2e7c5f8-591a-42df-bc70-018e5970ca84
2022-06-25 01:09:17,759 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 2bdffe63-c296-423e-8231-09829804023a, Nodes: d5d86ba7-8a8a-4b58-b698-440423a66b5d{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=37707, RATIS=41783, RATIS_ADMIN=41783, RATIS_SERVER=41783, STANDALONE=44275], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}fb218fe0-94a8-44a0-a252-d3cae8685c6f{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=33555, RATIS=45009, RATIS_ADMIN=45009, RATIS_SERVER=45009, STANDALONE=37667], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a2e7c5f8-591a-42df-bc70-018e5970ca84{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=44821, RATIS=44971, RATIS_ADMIN=44971, RATIS_SERVER=44971, STANDALONE=40483], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-25T01:09:17.759Z[Etc/UTC]].
2022-06-25 01:09:17,819 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:18,002 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-06-25 01:09:18,047 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines []
2022-06-25 01:09:18,193 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5064077128ns, electionTimeout:5047ms
2022-06-25 01:09:18,193 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 489bfe9a-d541-48f0-84f9-7976b526cd96: shutdown 489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-FollowerState
2022-06-25 01:09:18,193 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:09:18,193 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:18,193 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 489bfe9a-d541-48f0-84f9-7976b526cd96: start 489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-LeaderElection168
2022-06-25 01:09:18,254 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-LeaderElection168] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-LeaderElection168 ELECTION round 0: submit vote requests at term 1 for -1: [489bfe9a-d541-48f0-84f9-7976b526cd96|rpc:10.1.0.8:43031|priority:1], old=null
2022-06-25 01:09:18,254 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-LeaderElection168] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-LeaderElection168 ELECTION round 0: result PASSED (term=1)
2022-06-25 01:09:18,254 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-LeaderElection168] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 489bfe9a-d541-48f0-84f9-7976b526cd96: shutdown 489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-LeaderElection168
2022-06-25 01:09:18,254 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-LeaderElection168] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-06-25 01:09:18,254 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-LeaderElection168] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-D55E57C271A7 with new leaderId: 489bfe9a-d541-48f0-84f9-7976b526cd96
2022-06-25 01:09:18,255 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-LeaderElection168] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7: change Leader from null to 489bfe9a-d541-48f0-84f9-7976b526cd96 at term 1 for becomeLeader, leader elected after 5328ms
2022-06-25 01:09:18,255 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-LeaderElection168] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-25 01:09:18,255 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-LeaderElection168] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:18,255 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-LeaderElection168] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-06-25 01:09:18,256 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-LeaderElection168] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-06-25 01:09:18,256 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-LeaderElection168] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-25 01:09:18,256 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-LeaderElection168] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-25 01:09:18,256 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-LeaderElection168] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:18,256 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-LeaderElection168] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-25 01:09:18,256 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-LeaderElection168] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 489bfe9a-d541-48f0-84f9-7976b526cd96: start 489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-LeaderStateImpl
2022-06-25 01:09:18,257 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-LeaderElection168] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:18,274 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-LeaderElection168] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7: set configuration 0: [489bfe9a-d541-48f0-84f9-7976b526cd96|rpc:10.1.0.8:43031|dataStream:|priority:1], old=null
2022-06-25 01:09:18,330 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-D55E57C271A7-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-0/data/ratis/52590cf4-4638-492f-824a-d55e57c271a7/current/log_inprogress_0
2022-06-25 01:09:18,334 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:18,393 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5084455909ns, electionTimeout:5044ms
2022-06-25 01:09:18,394 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 489bfe9a-d541-48f0-84f9-7976b526cd96: shutdown 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-FollowerState
2022-06-25 01:09:18,394 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:09:18,394 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:18,394 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 489bfe9a-d541-48f0-84f9-7976b526cd96: start 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-LeaderElection169
2022-06-25 01:09:18,483 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-LeaderElection169] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-LeaderElection169 ELECTION round 0: submit vote requests at term 1 for -1: [a39a8077-0667-4534-bc11-ae9dd274a08a|rpc:10.1.0.8:35251|priority:0, d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2|rpc:10.1.0.8:43289|priority:1, 489bfe9a-d541-48f0-84f9-7976b526cd96|rpc:10.1.0.8:43031|priority:0], old=null
2022-06-25 01:09:18,501 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA: receive requestVote(ELECTION, 489bfe9a-d541-48f0-84f9-7976b526cd96, group-812A35E9D7FA, 1, (t:0, i:0))
2022-06-25 01:09:18,501 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA-FOLLOWER: accept ELECTION from 489bfe9a-d541-48f0-84f9-7976b526cd96: our priority 0 <= candidate's priority 0
2022-06-25 01:09:18,501 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:489bfe9a-d541-48f0-84f9-7976b526cd96
2022-06-25 01:09:18,501 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a39a8077-0667-4534-bc11-ae9dd274a08a: shutdown a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA-FollowerState
2022-06-25 01:09:18,501 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a39a8077-0667-4534-bc11-ae9dd274a08a: start a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA-FollowerState
2022-06-25 01:09:18,501 [a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA-FollowerState was interrupted
2022-06-25 01:09:18,511 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA replies to ELECTION vote request: 489bfe9a-d541-48f0-84f9-7976b526cd96<-a39a8077-0667-4534-bc11-ae9dd274a08a#0:OK-t1. Peer's state: a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA:t1, leader=null, voted=489bfe9a-d541-48f0-84f9-7976b526cd96, raftlog=a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA-SegmentedRaftLog:OPENED:c-1, conf=-1: [a39a8077-0667-4534-bc11-ae9dd274a08a|rpc:10.1.0.8:35251|dataStream:|priority:0, d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2|rpc:10.1.0.8:43289|dataStream:|priority:1, 489bfe9a-d541-48f0-84f9-7976b526cd96|rpc:10.1.0.8:43031|dataStream:|priority:0], old=null
2022-06-25 01:09:18,534 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d: addNew group-252483A22734:[d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|priority:1] returns group-252483A22734:java.util.concurrent.CompletableFuture@6e549d3d[Not completed]
2022-06-25 01:09:18,555 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:18,577 [pool-4487-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d: new RaftServerImpl for group-252483A22734:[d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|priority:1] with ContainerStateMachine:uninitialized
2022-06-25 01:09:18,577 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:09:18,577 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:09:18,577 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:18,584 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA: receive requestVote(ELECTION, 489bfe9a-d541-48f0-84f9-7976b526cd96, group-812A35E9D7FA, 1, (t:0, i:0))
2022-06-25 01:09:18,584 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-FOLLOWER: reject ELECTION from 489bfe9a-d541-48f0-84f9-7976b526cd96: our priority 1 > candidate's priority 0
2022-06-25 01:09:18,584 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:489bfe9a-d541-48f0-84f9-7976b526cd96
2022-06-25 01:09:18,584 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2: shutdown d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-FollowerState
2022-06-25 01:09:18,584 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2: start d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-FollowerState
2022-06-25 01:09:18,584 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-FollowerState was interrupted
2022-06-25 01:09:18,586 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA replies to ELECTION vote request: 489bfe9a-d541-48f0-84f9-7976b526cd96<-d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2#0:FAIL-t1. Peer's state: d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA:t1, leader=null, voted=null, raftlog=d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-SegmentedRaftLog:OPENED:c-1, conf=-1: [a39a8077-0667-4534-bc11-ae9dd274a08a|rpc:10.1.0.8:35251|priority:0, d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2|rpc:10.1.0.8:43289|priority:1, 489bfe9a-d541-48f0-84f9-7976b526cd96|rpc:10.1.0.8:43031|priority:0], old=null
2022-06-25 01:09:18,622 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-06-25 01:09:18,622 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Waiting for cluster to exit safe mode
2022-06-25 01:09:18,622 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:09:18,670 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:18,670 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:18,670 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:18,670 [pool-4487-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734: ConfigurationManager, init=-1: [d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|priority:1], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:18,671 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-4/data/ratis] (custom)
2022-06-25 01:09:18,671 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:18,671 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:18,671 [pool-4487-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-4/data/ratis/a7dc16f4-8814-423a-a883-252483a22734 does not exist. Creating ...
2022-06-25 01:09:18,671 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-LeaderElection169] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-LeaderElection169: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-06-25 01:09:18,671 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-LeaderElection169] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 489bfe9a-d541-48f0-84f9-7976b526cd96<-a39a8077-0667-4534-bc11-ae9dd274a08a#0:OK-t1
2022-06-25 01:09:18,671 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-LeaderElection169] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 489bfe9a-d541-48f0-84f9-7976b526cd96<-d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2#0:FAIL-t1
2022-06-25 01:09:18,671 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-LeaderElection169] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-LeaderElection169 ELECTION round 0: result REJECTED
2022-06-25 01:09:18,671 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-LeaderElection169] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
2022-06-25 01:09:18,671 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-LeaderElection169] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 489bfe9a-d541-48f0-84f9-7976b526cd96: shutdown 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-LeaderElection169
2022-06-25 01:09:18,671 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-LeaderElection169] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 489bfe9a-d541-48f0-84f9-7976b526cd96: start 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-FollowerState
2022-06-25 01:09:18,675 [pool-4487-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-4/data/ratis/a7dc16f4-8814-423a-a883-252483a22734/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:18,679 [pool-4487-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-4/data/ratis/a7dc16f4-8814-423a-a883-252483a22734 has been successfully formatted.
2022-06-25 01:09:18,686 [pool-4487-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-252483A22734: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:09:18,686 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:09:18,686 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:18,687 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:18,687 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:18,687 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:18,687 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(358)) - Pipeline Pipeline[ Id: a7dc16f4-8814-423a-a883-252483a22734, Nodes: d5d86ba7-8a8a-4b58-b698-440423a66b5d{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=37707, RATIS=41783, RATIS_ADMIN=41783, RATIS_SERVER=41783, STANDALONE=44275], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:d5d86ba7-8a8a-4b58-b698-440423a66b5d, CreationTimestamp2022-06-25T01:09:15.524Z[Etc/UTC]] moved to OPEN state
2022-06-25 01:09:18,687 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:18,687 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:18,688 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:18,688 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:18,689 [pool-4487-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-4/data/ratis/a7dc16f4-8814-423a-a883-252483a22734
2022-06-25 01:09:18,689 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:09:18,689 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:09:18,689 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:18,689 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:09:18,689 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:18,689 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:18,689 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:18,689 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:18,693 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:09:18,694 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:18,694 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:09:18,694 [pool-4487-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:18,694 [pool-4487-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:18,694 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:18,694 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:09:18,694 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:09:18,694 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:09:18,694 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:09:18,695 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:18,699 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:18,699 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:18,699 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:18,699 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:18,699 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:18,699 [pool-4487-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734: start as a follower, conf=-1: [d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|priority:1], old=null
2022-06-25 01:09:18,699 [pool-4487-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:18,699 [pool-4487-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d: start d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-FollowerState
2022-06-25 01:09:18,700 [pool-4487-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-252483A22734,id=d5d86ba7-8a8a-4b58-b698-440423a66b5d
2022-06-25 01:09:18,701 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=a7dc16f4-8814-423a-a883-252483a22734
2022-06-25 01:09:18,701 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=a7dc16f4-8814-423a-a883-252483a22734.
2022-06-25 01:09:18,701 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d: addNew group-09829804023A:[d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|priority:0, fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|priority:0, a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|priority:1] returns group-09829804023A:java.util.concurrent.CompletableFuture@6a6b042f[Not completed]
2022-06-25 01:09:18,702 [pool-4487-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d: new RaftServerImpl for group-09829804023A:[d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|priority:0, fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|priority:0, a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|priority:1] with ContainerStateMachine:uninitialized
2022-06-25 01:09:18,702 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:09:18,702 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:09:18,702 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:18,702 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:18,702 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:18,702 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:18,702 [pool-4487-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A: ConfigurationManager, init=-1: [d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|priority:0, fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|priority:0, a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|priority:1], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:18,703 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-4/data/ratis] (custom)
2022-06-25 01:09:18,703 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:18,703 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:18,703 [pool-4487-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-4/data/ratis/2bdffe63-c296-423e-8231-09829804023a does not exist. Creating ...
2022-06-25 01:09:18,706 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:18,712 [pool-4487-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-4/data/ratis/2bdffe63-c296-423e-8231-09829804023a/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:18,723 [pool-4487-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-4/data/ratis/2bdffe63-c296-423e-8231-09829804023a has been successfully formatted.
2022-06-25 01:09:18,723 [pool-4487-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-09829804023A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:09:18,730 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:18,731 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:09:18,731 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:18,731 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:18,731 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:18,731 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:18,731 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:18,733 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:18,733 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:18,733 [pool-4487-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-4/data/ratis/2bdffe63-c296-423e-8231-09829804023a
2022-06-25 01:09:18,733 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:09:18,733 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:09:18,733 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:18,733 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:09:18,733 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:18,733 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:18,734 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:18,734 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:18,741 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:09:18,741 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:18,741 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:09:18,742 [pool-4487-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:18,742 [pool-4487-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:18,742 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:18,742 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:09:18,742 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:09:18,742 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:09:18,742 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:09:18,742 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:18,753 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:18,753 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:18,753 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:18,753 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:18,753 [pool-4487-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:18,753 [pool-4487-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A: start as a follower, conf=-1: [d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|priority:0, fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|priority:0, a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|priority:1], old=null
2022-06-25 01:09:18,753 [pool-4487-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:18,754 [pool-4487-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d: start d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-FollowerState
2022-06-25 01:09:18,758 [pool-4487-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-09829804023A,id=d5d86ba7-8a8a-4b58-b698-440423a66b5d
2022-06-25 01:09:18,765 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=2bdffe63-c296-423e-8231-09829804023a
2022-06-25 01:09:18,778 [grpc-default-executor-5] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f: addNew group-09829804023A:[d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|dataStream:|priority:0, fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|dataStream:|priority:0, a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|dataStream:|priority:1] returns group-09829804023A:java.util.concurrent.CompletableFuture@1ea09fc0[Not completed]
2022-06-25 01:09:18,779 [pool-4456-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f: new RaftServerImpl for group-09829804023A:[d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|dataStream:|priority:0, fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|dataStream:|priority:0, a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|dataStream:|priority:1] with ContainerStateMachine:uninitialized
2022-06-25 01:09:18,779 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:09:18,779 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:09:18,779 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:18,780 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:18,780 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:18,780 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:18,780 [pool-4456-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A: ConfigurationManager, init=-1: [d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|dataStream:|priority:0, fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|dataStream:|priority:0, a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|dataStream:|priority:1], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:18,780 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-3/data/ratis] (custom)
2022-06-25 01:09:18,780 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:18,780 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:18,780 [pool-4456-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-3/data/ratis/2bdffe63-c296-423e-8231-09829804023a does not exist. Creating ...
2022-06-25 01:09:18,802 [pool-4456-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-3/data/ratis/2bdffe63-c296-423e-8231-09829804023a/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:18,818 [pool-4456-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-3/data/ratis/2bdffe63-c296-423e-8231-09829804023a has been successfully formatted.
2022-06-25 01:09:18,820 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:18,825 [pool-4456-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-09829804023A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:09:18,825 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:09:18,825 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:18,825 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:18,826 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:18,826 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:18,827 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:18,827 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:18,828 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:18,828 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:18,828 [pool-4456-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-3/data/ratis/2bdffe63-c296-423e-8231-09829804023a
2022-06-25 01:09:18,828 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:09:18,828 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:09:18,829 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:18,829 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:09:18,829 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:18,829 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:18,829 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:18,829 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:18,834 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:09:18,835 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:18,835 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:09:18,835 [pool-4456-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:18,836 [pool-4456-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:18,842 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:18,843 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:09:18,843 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:09:18,843 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:09:18,843 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:09:18,843 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:18,847 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:18,847 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:18,847 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:18,847 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:18,847 [pool-4456-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:18,847 [pool-4456-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A: start as a follower, conf=-1: [d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|dataStream:|priority:0, fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|dataStream:|priority:0, a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|dataStream:|priority:1], old=null
2022-06-25 01:09:18,848 [pool-4456-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:18,848 [pool-4456-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f: start fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-FollowerState
2022-06-25 01:09:18,848 [pool-4456-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-09829804023A,id=fb218fe0-94a8-44a0-a252-d3cae8685c6f
2022-06-25 01:09:18,902 [grpc-default-executor-5] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - a2e7c5f8-591a-42df-bc70-018e5970ca84: addNew group-09829804023A:[d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|dataStream:|priority:0, fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|dataStream:|priority:0, a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|dataStream:|priority:1] returns group-09829804023A:java.util.concurrent.CompletableFuture@71c01f1a[Not completed]
2022-06-25 01:09:18,903 [pool-4514-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - a2e7c5f8-591a-42df-bc70-018e5970ca84: new RaftServerImpl for group-09829804023A:[d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|dataStream:|priority:0, fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|dataStream:|priority:0, a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|dataStream:|priority:1] with ContainerStateMachine:uninitialized
2022-06-25 01:09:18,903 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:09:18,903 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:09:18,903 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:18,903 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:18,903 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:18,903 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:18,903 [pool-4514-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A: ConfigurationManager, init=-1: [d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|dataStream:|priority:0, fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|dataStream:|priority:0, a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|dataStream:|priority:1], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:18,903 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-5/data/ratis] (custom)
2022-06-25 01:09:18,903 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:18,903 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:18,904 [pool-4514-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-5/data/ratis/2bdffe63-c296-423e-8231-09829804023a does not exist. Creating ...
2022-06-25 01:09:18,910 [pool-4514-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-5/data/ratis/2bdffe63-c296-423e-8231-09829804023a/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:18,918 [pool-4514-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-5/data/ratis/2bdffe63-c296-423e-8231-09829804023a has been successfully formatted.
2022-06-25 01:09:18,918 [pool-4514-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-09829804023A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:09:18,919 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:09:18,919 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:18,919 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:18,919 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:18,919 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:18,919 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:18,921 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:18,921 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:18,921 [pool-4514-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-5/data/ratis/2bdffe63-c296-423e-8231-09829804023a
2022-06-25 01:09:18,921 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:09:18,921 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:09:18,921 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:18,921 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:09:18,921 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:18,921 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:18,921 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:18,921 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:18,925 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:09:18,925 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:18,925 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:09:18,925 [pool-4514-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:18,926 [pool-4514-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:18,926 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:18,926 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:09:18,926 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:09:18,926 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:09:18,926 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:09:18,926 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:18,930 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:18,930 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:18,930 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:18,931 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:18,931 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:18,931 [pool-4514-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A: start as a follower, conf=-1: [d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|dataStream:|priority:0, fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|dataStream:|priority:0, a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|dataStream:|priority:1], old=null
2022-06-25 01:09:18,931 [pool-4514-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:18,931 [pool-4514-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a2e7c5f8-591a-42df-bc70-018e5970ca84: start a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-FollowerState
2022-06-25 01:09:18,931 [pool-4514-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-09829804023A,id=a2e7c5f8-591a-42df-bc70-018e5970ca84
2022-06-25 01:09:19,003 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:19,060 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=2bdffe63-c296-423e-8231-09829804023a.
2022-06-25 01:09:19,168 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:19,197 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5143748046ns, electionTimeout:5057ms
2022-06-25 01:09:19,198 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2: shutdown d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-FollowerState
2022-06-25 01:09:19,198 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:09:19,198 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:19,198 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2: start d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-LeaderElection170
2022-06-25 01:09:19,258 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-LeaderElection170] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-LeaderElection170 ELECTION round 0: submit vote requests at term 1 for -1: [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2|rpc:10.1.0.8:43289|priority:1], old=null
2022-06-25 01:09:19,258 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-LeaderElection170] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-LeaderElection170 ELECTION round 0: result PASSED (term=1)
2022-06-25 01:09:19,258 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-LeaderElection170] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2: shutdown d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-LeaderElection170
2022-06-25 01:09:19,258 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-LeaderElection170] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-06-25 01:09:19,258 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-LeaderElection170] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-FACD38847A24 with new leaderId: d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2
2022-06-25 01:09:19,258 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-LeaderElection170] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24: change Leader from null to d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2 at term 1 for becomeLeader, leader elected after 5358ms
2022-06-25 01:09:19,258 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-LeaderElection170] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-25 01:09:19,259 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-LeaderElection170] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:19,259 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-LeaderElection170] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-06-25 01:09:19,260 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:19,260 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-LeaderElection170] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-06-25 01:09:19,261 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-LeaderElection170] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-25 01:09:19,261 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-LeaderElection170] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-25 01:09:19,261 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-LeaderElection170] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:19,261 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-LeaderElection170] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-25 01:09:19,261 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-LeaderElection170] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2: start d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-LeaderStateImpl
2022-06-25 01:09:19,262 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-LeaderElection170] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:19,328 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-1/data/ratis/c5771680-4e41-48dc-b9eb-facd38847a24/current/log_inprogress_0
2022-06-25 01:09:19,330 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24-LeaderElection170] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-FACD38847A24: set configuration 0: [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2|rpc:10.1.0.8:43289|dataStream:|priority:1], old=null
2022-06-25 01:09:19,625 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-06-25 01:09:19,625 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Waiting for cluster to exit safe mode
2022-06-25 01:09:19,625 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:09:19,710 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:19,725 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:19,819 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5130555095ns, electionTimeout:5121ms
2022-06-25 01:09:19,819 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: shutdown 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:19,819 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: changes role from  FOLLOWER to CANDIDATE at term 5 for changeToCandidate
2022-06-25 01:09:19,819 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:19,820 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: start 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection171
2022-06-25 01:09:19,820 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:19,825 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:19,834 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection171] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection171 ELECTION round 0: submit vote requests at term 6 for -1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:09:19,849 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: receive requestVote(ELECTION, 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9, group-B6B9DF3CEF32, 6, (t:0, i:0))
2022-06-25 01:09:19,849 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FOLLOWER: reject ELECTION from 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: our priority 1 > candidate's priority 0
2022-06-25 01:09:19,850 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: changes role from  FOLLOWER to FOLLOWER at term 6 for candidate:4943f96b-6a06-411a-b0ee-4ab66ab6f7f9
2022-06-25 01:09:19,850 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: shutdown 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:19,850 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: start 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:19,850 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState was interrupted
2022-06-25 01:09:19,857 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: receive requestVote(ELECTION, 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9, group-B6B9DF3CEF32, 6, (t:0, i:0))
2022-06-25 01:09:19,858 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FOLLOWER: accept ELECTION from 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: our priority 0 <= candidate's priority 0
2022-06-25 01:09:19,858 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: changes role from  FOLLOWER to FOLLOWER at term 6 for candidate:4943f96b-6a06-411a-b0ee-4ab66ab6f7f9
2022-06-25 01:09:19,858 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: shutdown fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:19,858 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: start fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:19,858 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState was interrupted
2022-06-25 01:09:19,862 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32 replies to ELECTION vote request: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9<-97d08340-a146-41c4-a759-b3b136c7fb6d#0:FAIL-t6. Peer's state: 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32:t6, leader=null, voted=null, raftlog=97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:09:19,864 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection171] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection171: ELECTION REJECTED received 1 response(s) and 0 exception(s):
2022-06-25 01:09:19,864 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection171] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9<-97d08340-a146-41c4-a759-b3b136c7fb6d#0:FAIL-t6
2022-06-25 01:09:19,864 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection171] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection171 ELECTION round 0: result REJECTED
2022-06-25 01:09:19,864 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection171] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: changes role from CANDIDATE to FOLLOWER at term 6 for REJECTED
2022-06-25 01:09:19,864 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection171] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: shutdown 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection171
2022-06-25 01:09:19,864 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection171] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: start 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:19,874 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32 replies to ELECTION vote request: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9<-fc692a40-1ae9-40b7-8d63-7e46f51df1ef#0:OK-t6. Peer's state: fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32:t6, leader=null, voted=4943f96b-6a06-411a-b0ee-4ab66ab6f7f9, raftlog=fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|priority:0], old=null
2022-06-25 01:09:20,003 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:20,019 [a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5119312051ns, electionTimeout:5001ms
2022-06-25 01:09:20,020 [a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a39a8077-0667-4534-bc11-ae9dd274a08a: shutdown a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-FollowerState
2022-06-25 01:09:20,020 [a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:09:20,020 [a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:20,020 [a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a39a8077-0667-4534-bc11-ae9dd274a08a: start a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-LeaderElection172
2022-06-25 01:09:20,063 [a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-LeaderElection172] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-LeaderElection172 ELECTION round 0: submit vote requests at term 1 for -1: [a39a8077-0667-4534-bc11-ae9dd274a08a|rpc:10.1.0.8:35251|priority:1], old=null
2022-06-25 01:09:20,063 [a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-LeaderElection172] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-LeaderElection172 ELECTION round 0: result PASSED (term=1)
2022-06-25 01:09:20,063 [a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-LeaderElection172] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - a39a8077-0667-4534-bc11-ae9dd274a08a: shutdown a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-LeaderElection172
2022-06-25 01:09:20,064 [a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-LeaderElection172] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-06-25 01:09:20,064 [a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-LeaderElection172] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-8B004CA1AD68 with new leaderId: a39a8077-0667-4534-bc11-ae9dd274a08a
2022-06-25 01:09:20,066 [a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-LeaderElection172] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68: change Leader from null to a39a8077-0667-4534-bc11-ae9dd274a08a at term 1 for becomeLeader, leader elected after 5366ms
2022-06-25 01:09:20,066 [a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-LeaderElection172] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-25 01:09:20,067 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:20,067 [a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-LeaderElection172] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:20,067 [a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-LeaderElection172] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-06-25 01:09:20,068 [a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-LeaderElection172] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-06-25 01:09:20,068 [a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-LeaderElection172] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-25 01:09:20,068 [a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-LeaderElection172] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-25 01:09:20,068 [a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-LeaderElection172] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:20,068 [a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-LeaderElection172] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-25 01:09:20,069 [a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-LeaderElection172] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a39a8077-0667-4534-bc11-ae9dd274a08a: start a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-LeaderStateImpl
2022-06-25 01:09:20,069 [a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-LeaderElection172] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:20,086 [a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-2/data/ratis/422c7861-ced3-461a-a0fc-8b004ca1ad68/current/log_inprogress_0
2022-06-25 01:09:20,149 [a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68-LeaderElection172] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-8B004CA1AD68: set configuration 0: [a39a8077-0667-4534-bc11-ae9dd274a08a|rpc:10.1.0.8:35251|dataStream:|priority:1], old=null
2022-06-25 01:09:20,260 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:20,314 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:20,625 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-06-25 01:09:20,626 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Waiting for cluster to exit safe mode
2022-06-25 01:09:20,626 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:09:20,726 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:20,748 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - a2e7c5f8-591a-42df-bc70-018e5970ca84: addNew group-FAA751117728:[a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|priority:1] returns group-FAA751117728:java.util.concurrent.CompletableFuture@33cc114a[Not completed]
2022-06-25 01:09:20,749 [pool-4514-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - a2e7c5f8-591a-42df-bc70-018e5970ca84: new RaftServerImpl for group-FAA751117728:[a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|priority:1] with ContainerStateMachine:uninitialized
2022-06-25 01:09:20,749 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:09:20,749 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:09:20,749 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:20,749 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:20,749 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:20,749 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:20,750 [pool-4514-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728: ConfigurationManager, init=-1: [a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|priority:1], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:20,750 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-5/data/ratis] (custom)
2022-06-25 01:09:20,750 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:20,750 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:20,750 [pool-4514-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-5/data/ratis/349de946-adbc-4715-b282-faa751117728 does not exist. Creating ...
2022-06-25 01:09:20,754 [pool-4514-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-5/data/ratis/349de946-adbc-4715-b282-faa751117728/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:20,756 [pool-4514-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-5/data/ratis/349de946-adbc-4715-b282-faa751117728 has been successfully formatted.
2022-06-25 01:09:20,757 [pool-4514-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-FAA751117728: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:09:20,757 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:09:20,757 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:20,757 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:20,757 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:20,757 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:20,758 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:20,759 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:20,759 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:20,759 [pool-4514-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-5/data/ratis/349de946-adbc-4715-b282-faa751117728
2022-06-25 01:09:20,759 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:09:20,759 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:09:20,759 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:20,759 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:09:20,759 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:20,759 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:20,760 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:20,760 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:20,763 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(358)) - Pipeline Pipeline[ Id: 349de946-adbc-4715-b282-faa751117728, Nodes: a2e7c5f8-591a-42df-bc70-018e5970ca84{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=44821, RATIS=44971, RATIS_ADMIN=44971, RATIS_SERVER=44971, STANDALONE=40483], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:a2e7c5f8-591a-42df-bc70-018e5970ca84, CreationTimestamp2022-06-25T01:09:17.758Z[Etc/UTC]] moved to OPEN state
2022-06-25 01:09:20,763 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:20,768 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:09:20,768 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:20,768 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:09:20,769 [pool-4514-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:20,769 [pool-4514-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:20,769 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:20,769 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:09:20,769 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:09:20,769 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:09:20,769 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:09:20,769 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:20,773 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:20,773 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:20,773 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:20,774 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:20,782 [pool-4514-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:20,782 [pool-4514-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728: start as a follower, conf=-1: [a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|priority:1], old=null
2022-06-25 01:09:20,782 [pool-4514-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:20,782 [pool-4514-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a2e7c5f8-591a-42df-bc70-018e5970ca84: start a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-FollowerState
2022-06-25 01:09:20,783 [pool-4514-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FAA751117728,id=a2e7c5f8-591a-42df-bc70-018e5970ca84
2022-06-25 01:09:20,784 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=349de946-adbc-4715-b282-faa751117728
2022-06-25 01:09:20,784 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=349de946-adbc-4715-b282-faa751117728.
2022-06-25 01:09:20,822 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:20,826 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:20,903 [Listener at 0.0.0.0/45907] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(365)) - Attempting to stop container services.
2022-06-25 01:09:20,966 [Listener at 0.0.0.0/45907] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$7(398)) - be67eb5e-e62d-4374-a142-8db592db20d7: close
2022-06-25 01:09:20,967 [Listener at 0.0.0.0/45907] INFO  server.GrpcService (GrpcService.java:closeImpl(269)) - be67eb5e-e62d-4374-a142-8db592db20d7: shutdown server with port 39697 now
2022-06-25 01:09:20,975 [Listener at 0.0.0.0/45907] INFO  server.GrpcService (GrpcService.java:closeImpl(278)) - be67eb5e-e62d-4374-a142-8db592db20d7: shutdown server with port 39697 successfully
2022-06-25 01:09:20,976 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@539049cd] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-be67eb5e-e62d-4374-a142-8db592db20d7: Stopped
2022-06-25 01:09:20,978 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:09:20,978 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/be67eb5e-e62d-4374-a142-8db592db20d7
2022-06-25 01:09:21,003 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-06-25 01:09:21,071 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:21,343 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:21,626 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-06-25 01:09:21,626 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Waiting for cluster to exit safe mode
2022-06-25 01:09:21,626 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:09:21,696 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5086692324ns, electionTimeout:5070ms
2022-06-25 01:09:21,696 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f: shutdown fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-FollowerState
2022-06-25 01:09:21,697 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:09:21,697 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:21,697 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f: start fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-LeaderElection173
2022-06-25 01:09:21,746 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-LeaderElection173] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-LeaderElection173 ELECTION round 0: submit vote requests at term 1 for -1: [fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|priority:1], old=null
2022-06-25 01:09:21,746 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-LeaderElection173] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-LeaderElection173 ELECTION round 0: result PASSED (term=1)
2022-06-25 01:09:21,747 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-LeaderElection173] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f: shutdown fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-LeaderElection173
2022-06-25 01:09:21,747 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-LeaderElection173] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-06-25 01:09:21,747 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-LeaderElection173] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-9FA706F8F5ED with new leaderId: fb218fe0-94a8-44a0-a252-d3cae8685c6f
2022-06-25 01:09:21,747 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-LeaderElection173] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED: change Leader from null to fb218fe0-94a8-44a0-a252-d3cae8685c6f at term 1 for becomeLeader, leader elected after 5202ms
2022-06-25 01:09:21,747 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-LeaderElection173] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-25 01:09:21,748 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-LeaderElection173] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:21,748 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-LeaderElection173] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-06-25 01:09:21,749 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-LeaderElection173] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-06-25 01:09:21,749 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-LeaderElection173] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-25 01:09:21,749 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-LeaderElection173] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-25 01:09:21,749 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-LeaderElection173] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:21,749 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-LeaderElection173] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-25 01:09:21,749 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-LeaderElection173] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f: start fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-LeaderStateImpl
2022-06-25 01:09:21,750 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-LeaderElection173] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:21,776 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-LeaderElection173] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED: set configuration 0: [fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|dataStream:|priority:1], old=null
2022-06-25 01:09:21,789 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:21,790 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:21,823 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:21,839 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-9FA706F8F5ED-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-3/data/ratis/7f03d426-270f-432f-9697-9fa706f8f5ed/current/log_inprogress_0
2022-06-25 01:09:21,841 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:22,004 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:22,279 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:22,630 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-06-25 01:09:22,630 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Waiting for cluster to exit safe mode
2022-06-25 01:09:22,630 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:09:22,752 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:22,832 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:23,004 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:23,070 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:23,247 [Listener at 0.0.0.0/45907] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-06-25 01:09:23,318 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:23,633 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-06-25 01:09:23,633 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Waiting for cluster to exit safe mode
2022-06-25 01:09:23,633 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:09:23,649 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5064515238ns, electionTimeout:5060ms
2022-06-25 01:09:23,649 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2: shutdown d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-FollowerState
2022-06-25 01:09:23,649 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2022-06-25 01:09:23,650 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:23,650 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2: start d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174
2022-06-25 01:09:23,667 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174 ELECTION round 0: submit vote requests at term 2 for -1: [a39a8077-0667-4534-bc11-ae9dd274a08a|rpc:10.1.0.8:35251|priority:0, d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2|rpc:10.1.0.8:43289|priority:1, 489bfe9a-d541-48f0-84f9-7976b526cd96|rpc:10.1.0.8:43031|priority:0], old=null
2022-06-25 01:09:23,678 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA: receive requestVote(ELECTION, d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2, group-812A35E9D7FA, 2, (t:0, i:0))
2022-06-25 01:09:23,679 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA-FOLLOWER: accept ELECTION from d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2: our priority 0 <= candidate's priority 1
2022-06-25 01:09:23,679 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2
2022-06-25 01:09:23,679 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a39a8077-0667-4534-bc11-ae9dd274a08a: shutdown a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA-FollowerState
2022-06-25 01:09:23,720 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA: receive requestVote(ELECTION, d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2, group-812A35E9D7FA, 2, (t:0, i:0))
2022-06-25 01:09:23,720 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-FOLLOWER: accept ELECTION from d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2: our priority 0 <= candidate's priority 1
2022-06-25 01:09:23,720 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2
2022-06-25 01:09:23,720 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 489bfe9a-d541-48f0-84f9-7976b526cd96: shutdown 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-FollowerState
2022-06-25 01:09:23,720 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 489bfe9a-d541-48f0-84f9-7976b526cd96: start 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-FollowerState
2022-06-25 01:09:23,720 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-FollowerState was interrupted
2022-06-25 01:09:23,726 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:23,730 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA replies to ELECTION vote request: d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2<-489bfe9a-d541-48f0-84f9-7976b526cd96#0:OK-t2. Peer's state: 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA:t2, leader=null, voted=d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2, raftlog=489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-SegmentedRaftLog:OPENED:c-1, conf=-1: [a39a8077-0667-4534-bc11-ae9dd274a08a|rpc:10.1.0.8:35251|priority:0, d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2|rpc:10.1.0.8:43289|priority:1, 489bfe9a-d541-48f0-84f9-7976b526cd96|rpc:10.1.0.8:43031|priority:0], old=null
2022-06-25 01:09:23,732 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174: ELECTION PASSED received 1 response(s) and 0 exception(s):
2022-06-25 01:09:23,732 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2<-489bfe9a-d541-48f0-84f9-7976b526cd96#0:OK-t2
2022-06-25 01:09:23,732 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174 ELECTION round 0: result PASSED
2022-06-25 01:09:23,732 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2: shutdown d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174
2022-06-25 01:09:23,732 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2022-06-25 01:09:23,732 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-812A35E9D7FA with new leaderId: d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2
2022-06-25 01:09:23,732 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA: change Leader from null to d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2 at term 2 for becomeLeader, leader elected after 9579ms
2022-06-25 01:09:23,732 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-25 01:09:23,733 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:23,733 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-06-25 01:09:23,734 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-06-25 01:09:23,734 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-25 01:09:23,734 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-25 01:09:23,739 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(358)) - Pipeline Pipeline[ Id: f02b0cd8-3fde-485f-9ca2-812a35e9d7fa, Nodes: a39a8077-0667-4534-bc11-ae9dd274a08a{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=37533, RATIS=35251, RATIS_ADMIN=35251, RATIS_SERVER=35251, STANDALONE=42177], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}489bfe9a-d541-48f0-84f9-7976b526cd96{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=34007, RATIS=43031, RATIS_ADMIN=43031, RATIS_SERVER=43031, STANDALONE=40687], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=44807, RATIS=43289, RATIS_ADMIN=43289, RATIS_SERVER=43289, STANDALONE=40157], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2, CreationTimestamp2022-06-25T01:09:11.703Z[Etc/UTC]] moved to OPEN state
2022-06-25 01:09:23,739 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a39a8077-0667-4534-bc11-ae9dd274a08a: start a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA-FollowerState
2022-06-25 01:09:23,734 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:23,740 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-25 01:09:23,742 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2022-06-25 01:09:23,742 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - HealthyPipelineSafeModeRule rule is successfully validated
2022-06-25 01:09:23,742 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(219)) - ScmSafeModeManager, all rules are successfully validated
2022-06-25 01:09:23,742 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(248)) - SCM exiting safe mode.
2022-06-25 01:09:23,742 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2022-06-25 01:09:23,742 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2022-06-25 01:09:23,742 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(253)) - Service BackgroundPipelineCreator transitions to RUNNING.
2022-06-25 01:09:23,742 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2022-06-25 01:09:23,742 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2022-06-25 01:09:23,743 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(372)) - Service ReplicationManager transitions to RUNNING.
2022-06-25 01:09:23,743 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(875)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2022-06-25 01:09:23,744 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5044789360ns, electionTimeout:5043ms
2022-06-25 01:09:23,762 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA replies to ELECTION vote request: d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2<-a39a8077-0667-4534-bc11-ae9dd274a08a#0:OK-t2. Peer's state: a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA:t2, leader=null, voted=d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2, raftlog=a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA-SegmentedRaftLog:OPENED:c-1, conf=-1: [a39a8077-0667-4534-bc11-ae9dd274a08a|rpc:10.1.0.8:35251|dataStream:|priority:0, d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2|rpc:10.1.0.8:43289|dataStream:|priority:1, 489bfe9a-d541-48f0-84f9-7976b526cd96|rpc:10.1.0.8:43031|dataStream:|priority:0], old=null
2022-06-25 01:09:23,764 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d: shutdown d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-FollowerState
2022-06-25 01:09:23,764 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:09:23,764 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:23,764 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d: start d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-LeaderElection175
2022-06-25 01:09:23,765 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2022-06-25 01:09:23,765 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:23,765 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2022-06-25 01:09:23,769 [a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA-FollowerState was interrupted
2022-06-25 01:09:23,772 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2022-06-25 01:09:23,772 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:09:23,772 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:23,776 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2022-06-25 01:09:23,776 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:23,776 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2022-06-25 01:09:23,776 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2022-06-25 01:09:23,776 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:09:23,776 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:23,777 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2: start d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderStateImpl
2022-06-25 01:09:23,777 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:23,789 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-1/data/ratis/f02b0cd8-3fde-485f-9ca2-812a35e9d7fa/current/log_inprogress_0
2022-06-25 01:09:23,806 [d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA-LeaderElection174] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2@group-812A35E9D7FA: set configuration 0: [a39a8077-0667-4534-bc11-ae9dd274a08a|rpc:10.1.0.8:35251|dataStream:|priority:0, d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2|rpc:10.1.0.8:43289|dataStream:|priority:1, 489bfe9a-d541-48f0-84f9-7976b526cd96|rpc:10.1.0.8:43031|dataStream:|priority:0], old=null
2022-06-25 01:09:23,809 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-LeaderElection175] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-LeaderElection175 ELECTION round 0: submit vote requests at term 1 for -1: [d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|priority:1], old=null
2022-06-25 01:09:23,809 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-LeaderElection175] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-LeaderElection175 ELECTION round 0: result PASSED (term=1)
2022-06-25 01:09:23,809 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-LeaderElection175] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d: shutdown d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-LeaderElection175
2022-06-25 01:09:23,809 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-LeaderElection175] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-06-25 01:09:23,809 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-LeaderElection175] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-252483A22734 with new leaderId: d5d86ba7-8a8a-4b58-b698-440423a66b5d
2022-06-25 01:09:23,810 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-LeaderElection175] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734: change Leader from null to d5d86ba7-8a8a-4b58-b698-440423a66b5d at term 1 for becomeLeader, leader elected after 5123ms
2022-06-25 01:09:23,810 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-LeaderElection175] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-25 01:09:23,812 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-LeaderElection175] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:23,812 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-LeaderElection175] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-06-25 01:09:23,861 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:23,870 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5115325641ns, electionTimeout:5107ms
2022-06-25 01:09:23,945 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5014248739ns, electionTimeout:5000ms
2022-06-25 01:09:23,961 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-LeaderElection175] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-06-25 01:09:23,961 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-LeaderElection175] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-25 01:09:23,961 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-LeaderElection175] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-25 01:09:23,961 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-LeaderElection175] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:23,961 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-LeaderElection175] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-25 01:09:23,961 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-LeaderElection175] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d: start d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-LeaderStateImpl
2022-06-25 01:09:23,962 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d: shutdown d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-FollowerState
2022-06-25 01:09:23,962 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:09:23,962 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:23,962 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d: start d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-LeaderElection176
2022-06-25 01:09:23,964 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a2e7c5f8-591a-42df-bc70-018e5970ca84: shutdown a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-FollowerState
2022-06-25 01:09:23,964 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:09:23,967 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:23,967 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a2e7c5f8-591a-42df-bc70-018e5970ca84: start a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection177
2022-06-25 01:09:23,996 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-LeaderElection175] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:24,003 [a39a8077-0667-4534-bc11-ae9dd274a08a-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-812A35E9D7FA with new leaderId: d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2
2022-06-25 01:09:24,003 [a39a8077-0667-4534-bc11-ae9dd274a08a-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA: change Leader from null to d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2 at term 2 for appendEntries, leader elected after 10035ms
2022-06-25 01:09:24,005 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5157247607ns, electionTimeout:5155ms
2022-06-25 01:09:24,005 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:24,006 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f: shutdown fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-FollowerState
2022-06-25 01:09:24,006 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:09:24,009 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:24,009 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f: start fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-LeaderElection178
2022-06-25 01:09:24,014 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-LeaderElection176] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-LeaderElection176 ELECTION round 0: submit vote requests at term 1 for -1: [d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|priority:0, fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|priority:0, a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|priority:1], old=null
2022-06-25 01:09:24,068 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-4/data/ratis/a7dc16f4-8814-423a-a883-252483a22734/current/log_inprogress_0
2022-06-25 01:09:24,085 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734-LeaderElection175] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-252483A22734: set configuration 0: [d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|dataStream:|priority:1], old=null
2022-06-25 01:09:24,130 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-LeaderElection178] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-LeaderElection178 ELECTION round 0: submit vote requests at term 1 for -1: [d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|dataStream:|priority:0, fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|dataStream:|priority:0, a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|dataStream:|priority:1], old=null
2022-06-25 01:09:24,217 [grpc-default-executor-9] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A: receive requestVote(ELECTION, fb218fe0-94a8-44a0-a252-d3cae8685c6f, group-09829804023A, 1, (t:0, i:0))
2022-06-25 01:09:24,229 [489bfe9a-d541-48f0-84f9-7976b526cd96-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-812A35E9D7FA with new leaderId: d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2
2022-06-25 01:09:24,230 [489bfe9a-d541-48f0-84f9-7976b526cd96-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA: change Leader from null to d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2 at term 2 for appendEntries, leader elected after 10975ms
2022-06-25 01:09:24,230 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A: receive requestVote(ELECTION, d5d86ba7-8a8a-4b58-b698-440423a66b5d, group-09829804023A, 1, (t:0, i:0))
2022-06-25 01:09:24,231 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(48)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-CANDIDATE: reject ELECTION from d5d86ba7-8a8a-4b58-b698-440423a66b5d: already has voted for fb218fe0-94a8-44a0-a252-d3cae8685c6f at current term 1
2022-06-25 01:09:24,231 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A replies to ELECTION vote request: d5d86ba7-8a8a-4b58-b698-440423a66b5d<-fb218fe0-94a8-44a0-a252-d3cae8685c6f#0:FAIL-t1. Peer's state: fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A:t1, leader=null, voted=fb218fe0-94a8-44a0-a252-d3cae8685c6f, raftlog=fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-SegmentedRaftLog:OPENED:c-1, conf=-1: [d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|dataStream:|priority:0, fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|dataStream:|priority:0, a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|dataStream:|priority:1], old=null
2022-06-25 01:09:24,233 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A: receive requestVote(ELECTION, d5d86ba7-8a8a-4b58-b698-440423a66b5d, group-09829804023A, 1, (t:0, i:0))
2022-06-25 01:09:24,245 [grpc-default-executor-10] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A: receive requestVote(ELECTION, fb218fe0-94a8-44a0-a252-d3cae8685c6f, group-09829804023A, 1, (t:0, i:0))
2022-06-25 01:09:24,245 [grpc-default-executor-10] INFO  impl.VoteContext (VoteContext.java:log(48)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-CANDIDATE: reject ELECTION from fb218fe0-94a8-44a0-a252-d3cae8685c6f: already has voted for d5d86ba7-8a8a-4b58-b698-440423a66b5d at current term 1
2022-06-25 01:09:24,246 [grpc-default-executor-10] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A replies to ELECTION vote request: fb218fe0-94a8-44a0-a252-d3cae8685c6f<-d5d86ba7-8a8a-4b58-b698-440423a66b5d#0:FAIL-t1. Peer's state: d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A:t1, leader=null, voted=d5d86ba7-8a8a-4b58-b698-440423a66b5d, raftlog=d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-SegmentedRaftLog:OPENED:c-1, conf=-1: [d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|priority:0, fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|priority:0, a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|priority:1], old=null
2022-06-25 01:09:24,260 [grpc-default-executor-9] INFO  impl.VoteContext (VoteContext.java:log(48)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-CANDIDATE: reject ELECTION from fb218fe0-94a8-44a0-a252-d3cae8685c6f: our priority 1 > candidate's priority 0
2022-06-25 01:09:24,261 [grpc-default-executor-9] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A: changes role from CANDIDATE to FOLLOWER at term 1 for candidate:fb218fe0-94a8-44a0-a252-d3cae8685c6f
2022-06-25 01:09:24,261 [grpc-default-executor-9] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - a2e7c5f8-591a-42df-bc70-018e5970ca84: shutdown a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection177
2022-06-25 01:09:24,261 [grpc-default-executor-9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a2e7c5f8-591a-42df-bc70-018e5970ca84: start a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-FollowerState
2022-06-25 01:09:24,261 [a39a8077-0667-4534-bc11-ae9dd274a08a-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA: set configuration 0: [a39a8077-0667-4534-bc11-ae9dd274a08a|rpc:10.1.0.8:35251|dataStream:|priority:0, d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2|rpc:10.1.0.8:43289|dataStream:|priority:1, 489bfe9a-d541-48f0-84f9-7976b526cd96|rpc:10.1.0.8:43031|dataStream:|priority:0], old=null
2022-06-25 01:09:24,271 [grpc-default-executor-9] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A replies to ELECTION vote request: fb218fe0-94a8-44a0-a252-d3cae8685c6f<-a2e7c5f8-591a-42df-bc70-018e5970ca84#0:FAIL-t1. Peer's state: a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A:t1, leader=null, voted=null, raftlog=a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-SegmentedRaftLog:OPENED:c-1, conf=-1: [d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|dataStream:|priority:0, fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|dataStream:|priority:0, a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|dataStream:|priority:1], old=null
2022-06-25 01:09:24,272 [grpc-default-executor-8] INFO  impl.VoteContext (VoteContext.java:log(48)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-FOLLOWER: reject ELECTION from d5d86ba7-8a8a-4b58-b698-440423a66b5d: our priority 1 > candidate's priority 0
2022-06-25 01:09:24,272 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:d5d86ba7-8a8a-4b58-b698-440423a66b5d
2022-06-25 01:09:24,272 [grpc-default-executor-8] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a2e7c5f8-591a-42df-bc70-018e5970ca84: shutdown a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-FollowerState
2022-06-25 01:09:24,272 [grpc-default-executor-8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a2e7c5f8-591a-42df-bc70-018e5970ca84: start a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-FollowerState
2022-06-25 01:09:24,278 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-FollowerState] INFO  impl.FollowerState (FollowerState.java:shouldRun(117)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-FollowerState: Stopping now (isRunning? false, role = FOLLOWER)
2022-06-25 01:09:24,283 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-LeaderElection178] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-LeaderElection178: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-06-25 01:09:24,283 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-LeaderElection178] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: fb218fe0-94a8-44a0-a252-d3cae8685c6f<-d5d86ba7-8a8a-4b58-b698-440423a66b5d#0:FAIL-t1
2022-06-25 01:09:24,283 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-LeaderElection178] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: fb218fe0-94a8-44a0-a252-d3cae8685c6f<-a2e7c5f8-591a-42df-bc70-018e5970ca84#0:FAIL-t1
2022-06-25 01:09:24,282 [a39a8077-0667-4534-bc11-ae9dd274a08a-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:24,284 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A replies to ELECTION vote request: d5d86ba7-8a8a-4b58-b698-440423a66b5d<-a2e7c5f8-591a-42df-bc70-018e5970ca84#0:FAIL-t1. Peer's state: a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A:t1, leader=null, voted=null, raftlog=a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-SegmentedRaftLog:OPENED:c-1, conf=-1: [d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|dataStream:|priority:0, fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|dataStream:|priority:0, a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|dataStream:|priority:1], old=null
2022-06-25 01:09:24,286 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-LeaderElection176] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-LeaderElection176: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-06-25 01:09:24,286 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-LeaderElection176] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: d5d86ba7-8a8a-4b58-b698-440423a66b5d<-fb218fe0-94a8-44a0-a252-d3cae8685c6f#0:FAIL-t1
2022-06-25 01:09:24,286 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-LeaderElection176] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: d5d86ba7-8a8a-4b58-b698-440423a66b5d<-a2e7c5f8-591a-42df-bc70-018e5970ca84#0:FAIL-t1
2022-06-25 01:09:24,286 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-LeaderElection176] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-LeaderElection176 ELECTION round 0: result REJECTED
2022-06-25 01:09:24,286 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-LeaderElection176] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
2022-06-25 01:09:24,286 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-LeaderElection176] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d: shutdown d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-LeaderElection176
2022-06-25 01:09:24,286 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-LeaderElection176] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d: start d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-FollowerState
2022-06-25 01:09:24,327 [489bfe9a-d541-48f0-84f9-7976b526cd96-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA: set configuration 0: [a39a8077-0667-4534-bc11-ae9dd274a08a|rpc:10.1.0.8:35251|dataStream:|priority:0, d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2|rpc:10.1.0.8:43289|dataStream:|priority:1, 489bfe9a-d541-48f0-84f9-7976b526cd96|rpc:10.1.0.8:43031|dataStream:|priority:0], old=null
2022-06-25 01:09:24,328 [489bfe9a-d541-48f0-84f9-7976b526cd96-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:24,328 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-LeaderElection178] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-LeaderElection178 ELECTION round 0: result REJECTED
2022-06-25 01:09:24,328 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-LeaderElection178] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
2022-06-25 01:09:24,328 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-LeaderElection178] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f: shutdown fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-LeaderElection178
2022-06-25 01:09:24,328 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-LeaderElection178] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f: start fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-FollowerState
2022-06-25 01:09:24,331 [a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - a39a8077-0667-4534-bc11-ae9dd274a08a@group-812A35E9D7FA-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-2/data/ratis/f02b0cd8-3fde-485f-9ca2-812a35e9d7fa/current/log_inprogress_0
2022-06-25 01:09:24,333 [489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 489bfe9a-d541-48f0-84f9-7976b526cd96@group-812A35E9D7FA-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-0/data/ratis/f02b0cd8-3fde-485f-9ca2-812a35e9d7fa/current/log_inprogress_0
2022-06-25 01:09:24,634 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-06-25 01:09:24,634 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Cluster exits safe mode
2022-06-25 01:09:24,634 [Listener at 127.0.0.1/39461] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:09:24,635 [Listener at 127.0.0.1/39461] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-06-25 01:09:24,637 [Listener at 127.0.0.1/39461] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-06-25 01:09:24,637 [Listener at 127.0.0.1/39461] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(209)) - ServiceID for StorageContainerManager is null
2022-06-25 01:09:24,638 [Listener at 127.0.0.1/39461] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(214)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2022-06-25 01:09:24,638 [Listener at 127.0.0.1/39461] WARN  utils.HAUtils (HAUtils.java:getMetaDir(342)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-06-25 01:09:24,639 [Listener at 127.0.0.1/39461] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-06-25 01:09:24,864 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:24,932 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5067720553ns, electionTimeout:5064ms
2022-06-25 01:09:24,932 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: shutdown 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:24,932 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: changes role from  FOLLOWER to CANDIDATE at term 6 for changeToCandidate
2022-06-25 01:09:24,932 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:24,932 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: start 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection179
2022-06-25 01:09:24,966 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection179] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection179 ELECTION round 0: submit vote requests at term 7 for -1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:09:24,983 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5133106013ns, electionTimeout:5130ms
2022-06-25 01:09:24,983 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: shutdown 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:24,983 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: changes role from  FOLLOWER to CANDIDATE at term 6 for changeToCandidate
2022-06-25 01:09:25,006 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:25,017 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:25,017 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: start 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection180
2022-06-25 01:09:25,027 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: receive requestVote(ELECTION, 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9, group-B6B9DF3CEF32, 7, (t:0, i:0))
2022-06-25 01:09:25,027 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: receive requestVote(ELECTION, 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9, group-B6B9DF3CEF32, 7, (t:0, i:0))
2022-06-25 01:09:25,027 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FOLLOWER: accept ELECTION from 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: our priority 0 <= candidate's priority 0
2022-06-25 01:09:25,028 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: changes role from  FOLLOWER to FOLLOWER at term 7 for candidate:4943f96b-6a06-411a-b0ee-4ab66ab6f7f9
2022-06-25 01:09:25,028 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: shutdown fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:25,041 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: start fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:25,041 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(48)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-CANDIDATE: reject ELECTION from 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: our priority 1 > candidate's priority 0
2022-06-25 01:09:25,041 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: changes role from CANDIDATE to FOLLOWER at term 7 for candidate:4943f96b-6a06-411a-b0ee-4ab66ab6f7f9
2022-06-25 01:09:25,041 [grpc-default-executor-6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: shutdown 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection180
2022-06-25 01:09:25,042 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState was interrupted
2022-06-25 01:09:25,069 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection180] INFO  impl.LeaderElection (LeaderElection.java:run(231)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection180: skip running since this is already CLOSING
2022-06-25 01:09:25,077 [grpc-default-executor-6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: start 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:25,083 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32 replies to ELECTION vote request: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9<-fc692a40-1ae9-40b7-8d63-7e46f51df1ef#0:OK-t7. Peer's state: fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32:t7, leader=null, voted=4943f96b-6a06-411a-b0ee-4ab66ab6f7f9, raftlog=fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|priority:0], old=null
2022-06-25 01:09:25,094 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32 replies to ELECTION vote request: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9<-97d08340-a146-41c4-a759-b3b136c7fb6d#0:FAIL-t7. Peer's state: 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32:t7, leader=null, voted=null, raftlog=97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:09:25,095 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection179] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection179: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-06-25 01:09:25,095 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection179] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9<-97d08340-a146-41c4-a759-b3b136c7fb6d#0:FAIL-t7
2022-06-25 01:09:25,095 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection179] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9<-fc692a40-1ae9-40b7-8d63-7e46f51df1ef#0:OK-t7
2022-06-25 01:09:25,095 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection179] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection179 ELECTION round 0: result REJECTED
2022-06-25 01:09:25,095 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection179] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: changes role from CANDIDATE to FOLLOWER at term 7 for REJECTED
2022-06-25 01:09:25,095 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection179] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: shutdown 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection179
2022-06-25 01:09:25,095 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-LeaderElection179] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: start 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:25,263 [Listener at 127.0.0.1/39461] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.3.0-SNAPSHOT/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
2022-06-25 01:09:25,263 [Listener at 127.0.0.1/39461] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2022-06-25 01:09:25,266 [Listener at 127.0.0.1/39461] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:25,267 [Listener at 127.0.0.1/39461] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:25,267 [Listener at 127.0.0.1/39461] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(82)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2022-06-25 01:09:25,413 [Listener at 127.0.0.1/39461] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 145 ms to scan 7 urls, producing 131 keys and 316 values 
2022-06-25 01:09:25,434 [Listener at 127.0.0.1/39461] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(347)) - upgrade localId to 109611004723200000
2022-06-25 01:09:25,434 [Listener at 127.0.0.1/39461] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(357)) - upgrade delTxnId to 0
2022-06-25 01:09:25,435 [Listener at 127.0.0.1/39461] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(374)) - upgrade containerId to 0
2022-06-25 01:09:25,435 [Listener at 127.0.0.1/39461] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(218)) - Init the HA SequenceIdGenerator.
2022-06-25 01:09:25,451 [Listener at 127.0.0.1/39461] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(149)) - Entering startup safe mode.
2022-06-25 01:09:25,452 [Listener at 127.0.0.1/39461] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2022-06-25 01:09:25,453 [Listener at 127.0.0.1/39461] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(78)) - No pipeline exists in current db
2022-06-25 01:09:25,453 [Listener at 127.0.0.1/39461] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2022-06-25 01:09:25,453 [Listener at 127.0.0.1/39461] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2022-06-25 01:09:25,454 [Listener at 127.0.0.1/39461] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(127)) - Starting RatisPipelineUtilsThread.
2022-06-25 01:09:25,489 [Listener at 127.0.0.1/39461] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(68)) - Starting BackgroundPipelineScrubber Service.
2022-06-25 01:09:25,526 [Listener at 127.0.0.1/39461] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2022-06-25 01:09:25,526 [Listener at 127.0.0.1/39461] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2022-06-25 01:09:25,527 [Listener at 127.0.0.1/39461] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(68)) - Starting ExpiredContainerReplicaOpScrubber Service.
2022-06-25 01:09:25,530 [Listener at 127.0.0.1/39461] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2022-06-25 01:09:25,531 [Listener at 127.0.0.1/39461] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(73)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2022-06-25 01:09:25,532 [Listener at 127.0.0.1/39461] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2022-06-25 01:09:25,533 [Listener at 127.0.0.1/39461] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2022-06-25 01:09:25,533 [Listener at 127.0.0.1/39461] INFO  replication.ReplicationManager (ReplicationManager.java:start(179)) - Starting Replication Monitor Thread.
2022-06-25 01:09:25,578 [Listener at 127.0.0.1/39461] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 0
2022-06-25 01:09:25,578 [Listener at 127.0.0.1/39461] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(156)) - Total pipeline count is 0, healthy pipeline threshold count is 1
2022-06-25 01:09:25,578 [Listener at 127.0.0.1/39461] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2022-06-25 01:09:25,581 [Listener at 127.0.0.1/39461] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-06-25 01:09:25,585 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 0
2022-06-25 01:09:25,591 [Listener at 0.0.0.0/44773] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-06-25 01:09:25,591 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 0
2022-06-25 01:09:25,592 [Listener at 0.0.0.0/45845] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-06-25 01:09:25,592 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 0
2022-06-25 01:09:25,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:25,698 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@aa6ee36] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2: Detected pause in JVM or host machine (eg GC): pause of approximately 100413588ns. No GCs detected.
2022-06-25 01:09:25,698 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@3534c0d2] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-97d08340-a146-41c4-a759-b3b136c7fb6d: Detected pause in JVM or host machine (eg GC): pause of approximately 103623701ns. No GCs detected.
2022-06-25 01:09:25,745 [Listener at 0.0.0.0/34403] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2022-06-25 01:09:25,745 [Listener at 0.0.0.0/34403] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(400)) - 
Container Balancer status:
Key                            Value
Running                        false
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2022-06-25 01:09:25,745 [Listener at 0.0.0.0/34403] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2022-06-25 01:09:25,746 [Listener at 0.0.0.0/34403] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2022-06-25 01:09:25,746 [Listener at 0.0.0.0/34403] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1418)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:34403
2022-06-25 01:09:25,746 [Listener at 0.0.0.0/34403] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - StorageContainerManager metrics system started (again)
2022-06-25 01:09:25,768 [Listener at 0.0.0.0/34403] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(169)) - RPC server for Client  is listening at /0.0.0.0:34403
2022-06-25 01:09:25,768 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-06-25 01:09:25,777 [Listener at 0.0.0.0/34403] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1433)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:45845
2022-06-25 01:09:25,777 [Listener at 0.0.0.0/34403] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(151)) - RPC server for Block Protocol is listening at /0.0.0.0:45845
2022-06-25 01:09:25,777 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-06-25 01:09:25,777 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 0: starting
2022-06-25 01:09:25,784 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 0: starting
2022-06-25 01:09:25,864 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:25,868 [Listener at 0.0.0.0/34403] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(185)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:44773
2022-06-25 01:09:25,869 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-06-25 01:09:25,869 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 0: starting
2022-06-25 01:09:25,943 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5161036525ns, electionTimeout:5159ms
2022-06-25 01:09:25,944 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a2e7c5f8-591a-42df-bc70-018e5970ca84: shutdown a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-FollowerState
2022-06-25 01:09:25,944 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:09:25,944 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:25,944 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a2e7c5f8-591a-42df-bc70-018e5970ca84: start a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-LeaderElection181
2022-06-25 01:09:25,966 [Listener at 0.0.0.0/34403] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for scm at: http://0.0.0.0:0
2022-06-25 01:09:25,966 [Listener at 0.0.0.0/34403] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-06-25 01:09:25,967 [Listener at 0.0.0.0/34403] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-06-25 01:09:25,982 [Listener at 0.0.0.0/34403] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-06-25 01:09:25,983 [Listener at 0.0.0.0/34403] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1029)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-06-25 01:09:25,983 [Listener at 0.0.0.0/34403] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1005)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2022-06-25 01:09:25,983 [Listener at 0.0.0.0/34403] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-06-25 01:09:25,983 [Listener at 0.0.0.0/34403] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-06-25 01:09:25,984 [Listener at 0.0.0.0/34403] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1248)) - Jetty bound to port 41125
2022-06-25 01:09:25,984 [Listener at 0.0.0.0/34403] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-06-25 01:09:25,994 [Listener at 0.0.0.0/34403] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-06-25 01:09:25,994 [Listener at 0.0.0.0/34403] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-06-25 01:09:25,994 [Listener at 0.0.0.0/34403] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-06-25 01:09:25,995 [Listener at 0.0.0.0/34403] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@337cbe86{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-06-25 01:09:25,995 [Listener at 0.0.0.0/34403] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@291a8a42{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2022-06-25 01:09:25,997 [Listener at 0.0.0.0/34403] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@377f8ca6{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2022-06-25 01:09:25,997 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5ff4c4e4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-06-25 01:09:26,007 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:26,144 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-LeaderElection181] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-LeaderElection181 ELECTION round 0: submit vote requests at term 1 for -1: [a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|priority:1], old=null
2022-06-25 01:09:26,144 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-LeaderElection181] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-LeaderElection181 ELECTION round 0: result PASSED (term=1)
2022-06-25 01:09:26,144 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-LeaderElection181] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - a2e7c5f8-591a-42df-bc70-018e5970ca84: shutdown a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-LeaderElection181
2022-06-25 01:09:26,144 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-LeaderElection181] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-06-25 01:09:26,144 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-LeaderElection181] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-FAA751117728 with new leaderId: a2e7c5f8-591a-42df-bc70-018e5970ca84
2022-06-25 01:09:26,144 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-LeaderElection181] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728: change Leader from null to a2e7c5f8-591a-42df-bc70-018e5970ca84 at term 1 for becomeLeader, leader elected after 5387ms
2022-06-25 01:09:26,144 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-LeaderElection181] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-25 01:09:26,145 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-LeaderElection181] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:26,145 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-LeaderElection181] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-06-25 01:09:26,146 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-LeaderElection181] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-06-25 01:09:26,146 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-LeaderElection181] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-25 01:09:26,146 [Listener at 0.0.0.0/34403] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@45b84060{HTTP/1.1, (http/1.1)}{0.0.0.0:41125}
2022-06-25 01:09:26,149 [Listener at 0.0.0.0/34403] INFO  server.Server (Server.java:doStart(415)) - Started @400046ms
2022-06-25 01:09:26,149 [Listener at 0.0.0.0/34403] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-06-25 01:09:26,149 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-LeaderElection181] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-25 01:09:26,149 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-LeaderElection181] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:26,149 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-LeaderElection181] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-25 01:09:26,149 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-LeaderElection181] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a2e7c5f8-591a-42df-bc70-018e5970ca84: start a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-LeaderStateImpl
2022-06-25 01:09:26,150 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-LeaderElection181] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:26,151 [Listener at 0.0.0.0/34403] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of scm listening at http://0.0.0.0:41125
2022-06-25 01:09:26,151 [Listener at 0.0.0.0/34403] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-06-25 01:09:26,157 [Listener at 0.0.0.0/34403] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(115)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2022-06-25 01:09:26,157 [Listener at 0.0.0.0/34403] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(226)) - Configuration does not have ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2022-06-25 01:09:26,157 [Listener at 0.0.0.0/34403] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(254)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2022-06-25 01:09:26,157 [Listener at 0.0.0.0/34403] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(261)) - OM Node ID is not set. Setting it to the default ID: om1
2022-06-25 01:09:26,157 [Listener at 0.0.0.0/34403] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-06-25 01:09:26,157 [Listener at 0.0.0.0/34403] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(82)) - Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
2022-06-25 01:09:26,163 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-5/data/ratis/349de946-adbc-4715-b282-faa751117728/current/log_inprogress_0
2022-06-25 01:09:26,259 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728-LeaderElection181] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-FAA751117728: set configuration 0: [a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|dataStream:|priority:1], old=null
2022-06-25 01:09:26,271 [Listener at 0.0.0.0/45907] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(580)) - Ozone container server stopped.
2022-06-25 01:09:26,458 [Listener at 0.0.0.0/45907] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@31373d8c{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-25 01:09:26,459 [Listener at 0.0.0.0/45907] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@3e96590c{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-06-25 01:09:26,459 [Listener at 0.0.0.0/45907] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-06-25 01:09:26,462 [Listener at 0.0.0.0/45907] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@47701f4d{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-06-25 01:09:26,464 [Listener at 0.0.0.0/45907] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@9ebdb37{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-06-25 01:09:26,478 [Listener at 0.0.0.0/45907] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:26,478 [Listener at 0.0.0.0/45907] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:26,479 [Listener at 0.0.0.0/45907] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-06-25 01:09:26,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:26,680 [Listener at 0.0.0.0/45907] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net ip:10.1.0.8
2022-06-25 01:09:26,766 [Listener at 0.0.0.0/45907] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(82)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2022-06-25 01:09:26,864 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:26,891 [Listener at 0.0.0.0/34403] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 733 ms to scan 2 urls, producing 152 keys and 429 values [using 2 cores]
2022-06-25 01:09:26,892 [Listener at 0.0.0.0/34403] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(115)) - Skipping Upgrade Action MockOmUpgradeAction since it has been finalized.
2022-06-25 01:09:26,892 [Listener at 0.0.0.0/34403] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-06-25 01:09:26,892 [Listener at 0.0.0.0/34403] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:45845]
2022-06-25 01:09:26,893 [Listener at 0.0.0.0/34403] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:45845]
2022-06-25 01:09:26,988 [Listener at 0.0.0.0/34403] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2022-06-25 01:09:26,988 [Listener at 0.0.0.0/34403] INFO  codec.OmKeyInfoCodec (OmKeyInfoCodec.java:<init>(49)) - OmKeyInfoCodec ignorePipeline = true
2022-06-25 01:09:26,988 [Listener at 0.0.0.0/34403] INFO  codec.RepeatedOmKeyInfoCodec (RepeatedOmKeyInfoCodec.java:<init>(41)) - RepeatedOmKeyInfoCodec ignorePipeline = true
2022-06-25 01:09:27,007 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:27,320 [Listener at 0.0.0.0/45907] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 552 ms to scan 7 urls, producing 131 keys and 316 values 
2022-06-25 01:09:27,368 [Listener at 0.0.0.0/45907] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(237)) - Datanode State Machine Task Thread Pool size 2
2022-06-25 01:09:27,395 [Listener at 0.0.0.0/45907] INFO  volume.HddsVolume (HddsVolume.java:<init>(116)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-06-25 01:09:27,395 [Listener at 0.0.0.0/45907] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data-0/containers/hdds to VolumeSet
2022-06-25 01:09:27,395 [Listener at 0.0.0.0/45907] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data-0/containers/hdds
2022-06-25 01:09:27,396 [Listener at 0.0.0.0/45907] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data-0/containers/hdds
2022-06-25 01:09:27,438 [Listener at 0.0.0.0/45907] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis to VolumeSet
2022-06-25 01:09:27,439 [Listener at 0.0.0.0/45907] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis
2022-06-25 01:09:27,439 [Listener at 0.0.0.0/45907] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis
2022-06-25 01:09:27,450 [Thread-6389] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(142)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data-0/containers/hdds
2022-06-25 01:09:27,479 [Thread-6389] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data-0/containers/hdds
2022-06-25 01:09:27,479 [Listener at 0.0.0.0/45907] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(266)) - Build ContainerSet costs 0s
2022-06-25 01:09:27,480 [Listener at 0.0.0.0/45907] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-06-25 01:09:27,481 [Listener at 0.0.0.0/45907] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-06-25 01:09:27,481 [Listener at 0.0.0.0/45907] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 39697 (custom)
2022-06-25 01:09:27,481 [Listener at 0.0.0.0/45907] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 39697 (custom)
2022-06-25 01:09:27,481 [Listener at 0.0.0.0/45907] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 39697 (custom)
2022-06-25 01:09:27,481 [Listener at 0.0.0.0/45907] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-06-25 01:09:27,481 [Listener at 0.0.0.0/45907] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:27,482 [Listener at 0.0.0.0/45907] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-06-25 01:09:27,482 [Listener at 0.0.0.0/45907] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:09:27,482 [Listener at 0.0.0.0/45907] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-06-25 01:09:27,482 [Listener at 0.0.0.0/45907] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-06-25 01:09:27,483 [Listener at 0.0.0.0/45907] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-06-25 01:09:27,484 [Listener at 0.0.0.0/45907] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-06-25 01:09:27,484 [Listener at 0.0.0.0/45907] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-06-25 01:09:27,484 [Listener at 0.0.0.0/45907] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:27,484 [Listener at 0.0.0.0/45907] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:27,484 [Listener at 0.0.0.0/45907] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis] (custom)
2022-06-25 01:09:27,486 [Listener at 0.0.0.0/45907] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-06-25 01:09:27,488 [Listener at 0.0.0.0/45907] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:45929
2022-06-25 01:09:27,488 [Listener at 0.0.0.0/45907] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-06-25 01:09:27,489 [Listener at 0.0.0.0/45907] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-06-25 01:09:27,489 [Listener at 0.0.0.0/45907] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-06-25 01:09:27,490 [Listener at 0.0.0.0/45907] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1029)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-06-25 01:09:27,491 [Listener at 0.0.0.0/45907] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1005)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-06-25 01:09:27,491 [Listener at 0.0.0.0/45907] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-06-25 01:09:27,491 [Listener at 0.0.0.0/45907] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-06-25 01:09:27,491 [Listener at 0.0.0.0/45907] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1248)) - Jetty bound to port 45929
2022-06-25 01:09:27,491 [Listener at 0.0.0.0/45907] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-06-25 01:09:27,492 [Listener at 0.0.0.0/45907] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-06-25 01:09:27,493 [Listener at 0.0.0.0/45907] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-06-25 01:09:27,493 [Listener at 0.0.0.0/45907] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2022-06-25 01:09:27,493 [Listener at 0.0.0.0/45907] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@155767a7{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-06-25 01:09:27,494 [Listener at 0.0.0.0/45907] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@46067a74{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-06-25 01:09:27,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:27,865 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:28,008 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:28,184 [Listener at 0.0.0.0/34403] INFO  om.OzoneManager (OzoneManager.java:instantiateServices(692)) - S3 Multi-Tenancy is disabled
2022-06-25 01:09:28,185 [Listener at 0.0.0.0/34403] INFO  om.OzoneManager (OzoneManager.java:addS3GVolumeToDB(4259)) - Created Volume s3v With Owner runner required for S3Gateway operations.
2022-06-25 01:09:28,185 [Listener at 0.0.0.0/34403] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(237)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2022-06-25 01:09:28,185 [Listener at 0.0.0.0/34403] WARN  utils.OzoneManagerRatisUtils (OzoneManagerRatisUtils.java:getOMRatisSnapshotDirectory(431)) - ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
2022-06-25 01:09:28,186 [Listener at 0.0.0.0/34403] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:28,186 [Listener at 0.0.0.0/34403] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:28,186 [Listener at 0.0.0.0/34403] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(237)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2022-06-25 01:09:28,186 [Listener at 0.0.0.0/34403] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(159)) - Instantiating OM Ratis server with groupID: omServiceIdDefault and peers: localhost:38887
2022-06-25 01:09:28,187 [Listener at 0.0.0.0/34403] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:loadSnapshotInfoFromDB(632)) - LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
2022-06-25 01:09:28,202 [Listener at 0.0.0.0/34403] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-06-25 01:09:28,202 [Listener at 0.0.0.0/34403] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-06-25 01:09:28,202 [Listener at 0.0.0.0/34403] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = -1 (default)
2022-06-25 01:09:28,202 [Listener at 0.0.0.0/34403] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 38887 (custom)
2022-06-25 01:09:28,202 [Listener at 0.0.0.0/34403] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = -1 (default)
2022-06-25 01:09:28,202 [Listener at 0.0.0.0/34403] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 38887 (custom)
2022-06-25 01:09:28,203 [Listener at 0.0.0.0/34403] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 38887 (custom)
2022-06-25 01:09:28,203 [Listener at 0.0.0.0/34403] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 33554432 (custom)
2022-06-25 01:09:28,203 [Listener at 0.0.0.0/34403] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:28,203 [Listener at 0.0.0.0/34403] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2022-06-25 01:09:28,203 [Listener at 0.0.0.0/34403] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2022-06-25 01:09:28,203 [Listener at 0.0.0.0/34403] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-06-25 01:09:28,203 [Listener at 0.0.0.0/34403] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-06-25 01:09:28,204 [Listener at 0.0.0.0/34403] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-06-25 01:09:28,204 [Listener at 0.0.0.0/34403] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-06-25 01:09:28,204 [Listener at 0.0.0.0/34403] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-06-25 01:09:28,204 [Listener at 0.0.0.0/34403] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2022-06-25 01:09:28,205 [Listener at 0.0.0.0/34403] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:28,205 [Listener at 0.0.0.0/34403] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/ozone-meta/ratis] (custom)
2022-06-25 01:09:28,225 [Listener at 0.0.0.0/34403] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - om1: addNew group-C5BA1605619E:[om1|rpc:localhost:38887|priority:0] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@46972030[Not completed]
2022-06-25 01:09:28,225 [Listener at 0.0.0.0/34403] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(1961)) - OzoneManager Ratis server initialized at port 38887
2022-06-25 01:09:28,226 [Listener at 0.0.0.0/34403] INFO  om.OzoneManager (OzoneManager.java:getRpcServer(1081)) - Creating RPC Server
2022-06-25 01:09:28,238 [pool-4642-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - om1: new RaftServerImpl for group-C5BA1605619E:[om1|rpc:localhost:38887|priority:0] with OzoneManagerStateMachine:uninitialized
2022-06-25 01:09:28,238 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2022-06-25 01:09:28,238 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 1200ms (custom)
2022-06-25 01:09:28,238 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:28,238 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2022-06-25 01:09:28,238 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:28,238 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:28,238 [pool-4642-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - om1@group-C5BA1605619E: ConfigurationManager, init=-1: [om1|rpc:localhost:38887|priority:0], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:28,239 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/ozone-meta/ratis] (custom)
2022-06-25 01:09:28,246 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:28,246 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:28,246 [pool-4642-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
2022-06-25 01:09:28,248 [pool-4642-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:28,267 [pool-4642-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
2022-06-25 01:09:28,268 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 120s (custom)
2022-06-25 01:09:28,268 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:28,268 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:28,268 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:28,268 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:28,268 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2022-06-25 01:09:28,268 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:28,268 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:28,268 [pool-4642-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e
2022-06-25 01:09:28,268 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2022-06-25 01:09:28,268 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 4096 (default)
2022-06-25 01:09:28,268 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2022-06-25 01:09:28,268 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2022-06-25 01:09:28,268 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:28,270 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:28,270 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:28,270 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:28,281 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2022-06-25 01:09:28,281 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:28,281 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2022-06-25 01:09:28,281 [pool-4642-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:28,281 [pool-4642-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:28,282 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:28,282 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2022-06-25 01:09:28,282 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = -1 (default)
2022-06-25 01:09:28,282 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = true (custom)
2022-06-25 01:09:28,282 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 300s (custom)
2022-06-25 01:09:28,282 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:28,282 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:28,283 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:28,283 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:28,283 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:28,283 [pool-4642-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:28,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:28,712 [Listener at 0.0.0.0/45907] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@2c02cf78{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-45929-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-5878437305103930881/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-25 01:09:28,771 [Listener at 0.0.0.0/45907] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@68303aad{HTTP/1.1, (http/1.1)}{0.0.0.0:45929}
2022-06-25 01:09:28,771 [Listener at 0.0.0.0/45907] INFO  server.Server (Server.java:doStart(415)) - Started @402668ms
2022-06-25 01:09:28,771 [Listener at 0.0.0.0/45907] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-06-25 01:09:28,772 [Listener at 0.0.0.0/45907] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:45929
2022-06-25 01:09:28,795 [Listener at 0.0.0.0/45907] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Waiting for nodes to be ready. Got 5 of 6 DN Heartbeats.
2022-06-25 01:09:28,795 [Listener at 0.0.0.0/45907] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Cluster exits safe mode
2022-06-25 01:09:28,795 [Listener at 0.0.0.0/45907] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:09:28,795 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(492)) - Ozone container server started.
2022-06-25 01:09:28,810 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7fa32ffd] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-06-25 01:09:28,850 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/meta/datanode.id
2022-06-25 01:09:28,850 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@aa6ee36] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2: Detected pause in JVM or host machine (eg GC): pause of approximately 137504236ns. No GCs detected.
2022-06-25 01:09:28,865 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:29,008 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:29,384 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5112547338ns, electionTimeout:5097ms
2022-06-25 01:09:29,384 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a2e7c5f8-591a-42df-bc70-018e5970ca84: shutdown a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-FollowerState
2022-06-25 01:09:29,384 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2022-06-25 01:09:29,385 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:29,385 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a2e7c5f8-591a-42df-bc70-018e5970ca84: start a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182
2022-06-25 01:09:29,407 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182 ELECTION round 0: submit vote requests at term 2 for -1: [d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|dataStream:|priority:0, fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|dataStream:|priority:0, a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|dataStream:|priority:1], old=null
2022-06-25 01:09:29,504 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A: receive requestVote(ELECTION, a2e7c5f8-591a-42df-bc70-018e5970ca84, group-09829804023A, 2, (t:0, i:0))
2022-06-25 01:09:29,504 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-FOLLOWER: accept ELECTION from a2e7c5f8-591a-42df-bc70-018e5970ca84: our priority 0 <= candidate's priority 1
2022-06-25 01:09:29,504 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:a2e7c5f8-591a-42df-bc70-018e5970ca84
2022-06-25 01:09:29,504 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d: shutdown d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-FollowerState
2022-06-25 01:09:29,504 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-FollowerState was interrupted
2022-06-25 01:09:29,504 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d: start d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-FollowerState
2022-06-25 01:09:29,511 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A replies to ELECTION vote request: a2e7c5f8-591a-42df-bc70-018e5970ca84<-d5d86ba7-8a8a-4b58-b698-440423a66b5d#0:OK-t2. Peer's state: d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A:t2, leader=null, voted=a2e7c5f8-591a-42df-bc70-018e5970ca84, raftlog=d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-SegmentedRaftLog:OPENED:c-1, conf=-1: [d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|priority:0, fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|priority:0, a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|priority:1], old=null
2022-06-25 01:09:29,514 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182: ELECTION PASSED received 1 response(s) and 0 exception(s):
2022-06-25 01:09:29,514 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: a2e7c5f8-591a-42df-bc70-018e5970ca84<-d5d86ba7-8a8a-4b58-b698-440423a66b5d#0:OK-t2
2022-06-25 01:09:29,515 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182 ELECTION round 0: result PASSED
2022-06-25 01:09:29,515 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - a2e7c5f8-591a-42df-bc70-018e5970ca84: shutdown a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182
2022-06-25 01:09:29,515 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2022-06-25 01:09:29,515 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-09829804023A with new leaderId: a2e7c5f8-591a-42df-bc70-018e5970ca84
2022-06-25 01:09:29,515 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A: change Leader from null to a2e7c5f8-591a-42df-bc70-018e5970ca84 at term 2 for becomeLeader, leader elected after 10596ms
2022-06-25 01:09:29,515 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-25 01:09:29,515 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:29,515 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-06-25 01:09:29,516 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-06-25 01:09:29,516 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-25 01:09:29,516 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-25 01:09:29,516 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:29,516 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-25 01:09:29,520 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2022-06-25 01:09:29,520 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:29,520 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2022-06-25 01:09:29,520 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2022-06-25 01:09:29,520 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:09:29,523 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(358)) - Pipeline Pipeline[ Id: 2bdffe63-c296-423e-8231-09829804023a, Nodes: d5d86ba7-8a8a-4b58-b698-440423a66b5d{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=37707, RATIS=41783, RATIS_ADMIN=41783, RATIS_SERVER=41783, STANDALONE=44275], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}fb218fe0-94a8-44a0-a252-d3cae8685c6f{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=33555, RATIS=45009, RATIS_ADMIN=45009, RATIS_SERVER=45009, STANDALONE=37667], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a2e7c5f8-591a-42df-bc70-018e5970ca84{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=44821, RATIS=44971, RATIS_ADMIN=44971, RATIS_SERVER=44971, STANDALONE=40483], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:a2e7c5f8-591a-42df-bc70-018e5970ca84, CreationTimestamp2022-06-25T01:09:17.759Z[Etc/UTC]] moved to OPEN state
2022-06-25 01:09:29,523 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5194189862ns, electionTimeout:5191ms
2022-06-25 01:09:29,523 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f: shutdown fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-FollowerState
2022-06-25 01:09:29,523 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2022-06-25 01:09:29,523 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:29,523 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f: start fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-LeaderElection183
2022-06-25 01:09:29,523 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:29,533 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2022-06-25 01:09:29,533 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:29,534 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2022-06-25 01:09:29,534 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2022-06-25 01:09:29,534 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:09:29,534 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:29,535 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a2e7c5f8-591a-42df-bc70-018e5970ca84: start a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderStateImpl
2022-06-25 01:09:29,535 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:29,544 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-LeaderElection183] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-LeaderElection183 ELECTION round 0: submit vote requests at term 2 for -1: [d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|dataStream:|priority:0, fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|dataStream:|priority:0, a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|dataStream:|priority:1], old=null
2022-06-25 01:09:29,546 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-5/data/ratis/2bdffe63-c296-423e-8231-09829804023a/current/log_inprogress_0
2022-06-25 01:09:29,597 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A: receive requestVote(ELECTION, a2e7c5f8-591a-42df-bc70-018e5970ca84, group-09829804023A, 2, (t:0, i:0))
2022-06-25 01:09:29,598 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(48)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-CANDIDATE: reject ELECTION from a2e7c5f8-591a-42df-bc70-018e5970ca84: already has voted for fb218fe0-94a8-44a0-a252-d3cae8685c6f at current term 2
2022-06-25 01:09:29,598 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A replies to ELECTION vote request: a2e7c5f8-591a-42df-bc70-018e5970ca84<-fb218fe0-94a8-44a0-a252-d3cae8685c6f#0:FAIL-t2. Peer's state: fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A:t2, leader=null, voted=fb218fe0-94a8-44a0-a252-d3cae8685c6f, raftlog=fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-SegmentedRaftLog:OPENED:c-1, conf=-1: [d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|dataStream:|priority:0, fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|dataStream:|priority:0, a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|dataStream:|priority:1], old=null
2022-06-25 01:09:29,605 [a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LeaderElection182] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A: set configuration 0: [d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|dataStream:|priority:0, fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|dataStream:|priority:0, a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|dataStream:|priority:1], old=null
2022-06-25 01:09:29,607 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A: receive requestVote(ELECTION, fb218fe0-94a8-44a0-a252-d3cae8685c6f, group-09829804023A, 2, (t:0, i:0))
2022-06-25 01:09:29,607 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(48)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-FOLLOWER: reject ELECTION from fb218fe0-94a8-44a0-a252-d3cae8685c6f: already has voted for a2e7c5f8-591a-42df-bc70-018e5970ca84 at current term 2
2022-06-25 01:09:29,607 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A replies to ELECTION vote request: fb218fe0-94a8-44a0-a252-d3cae8685c6f<-d5d86ba7-8a8a-4b58-b698-440423a66b5d#0:FAIL-t2. Peer's state: d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A:t2, leader=null, voted=a2e7c5f8-591a-42df-bc70-018e5970ca84, raftlog=d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-SegmentedRaftLog:OPENED:c-1, conf=-1: [d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|priority:0, fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|priority:0, a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|priority:1], old=null
2022-06-25 01:09:29,608 [d5d86ba7-8a8a-4b58-b698-440423a66b5d-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-09829804023A with new leaderId: a2e7c5f8-591a-42df-bc70-018e5970ca84
2022-06-25 01:09:29,608 [d5d86ba7-8a8a-4b58-b698-440423a66b5d-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A: change Leader from null to a2e7c5f8-591a-42df-bc70-018e5970ca84 at term 2 for appendEntries, leader elected after 10884ms
2022-06-25 01:09:29,614 [grpc-default-executor-10] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A: receive requestVote(ELECTION, fb218fe0-94a8-44a0-a252-d3cae8685c6f, group-09829804023A, 2, (t:0, i:0))
2022-06-25 01:09:29,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:29,631 [fb218fe0-94a8-44a0-a252-d3cae8685c6f-server-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A: changes role from CANDIDATE to FOLLOWER at term 2 for appendEntries
2022-06-25 01:09:29,638 [fb218fe0-94a8-44a0-a252-d3cae8685c6f-server-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f: shutdown fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-LeaderElection183
2022-06-25 01:09:29,638 [fb218fe0-94a8-44a0-a252-d3cae8685c6f-server-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f: start fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-FollowerState
2022-06-25 01:09:29,638 [grpc-default-executor-10] INFO  impl.VoteContext (VoteContext.java:log(48)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-LEADER: reject ELECTION from fb218fe0-94a8-44a0-a252-d3cae8685c6f: already has voted for a2e7c5f8-591a-42df-bc70-018e5970ca84 at current term 2
2022-06-25 01:09:29,639 [grpc-default-executor-10] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A replies to ELECTION vote request: fb218fe0-94a8-44a0-a252-d3cae8685c6f<-a2e7c5f8-591a-42df-bc70-018e5970ca84#0:FAIL-t2. Peer's state: a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A:t2, leader=a2e7c5f8-591a-42df-bc70-018e5970ca84, voted=a2e7c5f8-591a-42df-bc70-018e5970ca84, raftlog=a2e7c5f8-591a-42df-bc70-018e5970ca84@group-09829804023A-SegmentedRaftLog:OPENED:c0, conf=0: [d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|dataStream:|priority:0, fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|dataStream:|priority:0, a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|dataStream:|priority:1], old=null
2022-06-25 01:09:29,639 [fb218fe0-94a8-44a0-a252-d3cae8685c6f-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-09829804023A with new leaderId: a2e7c5f8-591a-42df-bc70-018e5970ca84
2022-06-25 01:09:29,639 [fb218fe0-94a8-44a0-a252-d3cae8685c6f-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A: change Leader from null to a2e7c5f8-591a-42df-bc70-018e5970ca84 at term 2 for appendEntries, leader elected after 10813ms
2022-06-25 01:09:29,637 [d5d86ba7-8a8a-4b58-b698-440423a66b5d-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A: set configuration 0: [d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|dataStream:|priority:0, fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|dataStream:|priority:0, a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|dataStream:|priority:1], old=null
2022-06-25 01:09:29,647 [d5d86ba7-8a8a-4b58-b698-440423a66b5d-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:29,659 [fb218fe0-94a8-44a0-a252-d3cae8685c6f-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A: set configuration 0: [d5d86ba7-8a8a-4b58-b698-440423a66b5d|rpc:10.1.0.8:41783|dataStream:|priority:0, fb218fe0-94a8-44a0-a252-d3cae8685c6f|rpc:10.1.0.8:45009|dataStream:|priority:0, a2e7c5f8-591a-42df-bc70-018e5970ca84|rpc:10.1.0.8:44971|dataStream:|priority:1], old=null
2022-06-25 01:09:29,660 [fb218fe0-94a8-44a0-a252-d3cae8685c6f-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:29,662 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-3/data/ratis/2bdffe63-c296-423e-8231-09829804023a/current/log_inprogress_0
2022-06-25 01:09:29,756 [d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - d5d86ba7-8a8a-4b58-b698-440423a66b5d@group-09829804023A-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5319b9db-8434-46dc-af7a-58e933abef82/datanode-4/data/ratis/2bdffe63-c296-423e-8231-09829804023a/current/log_inprogress_0
2022-06-25 01:09:29,758 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-LeaderElection183] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-LeaderElection183: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-06-25 01:09:29,759 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-LeaderElection183] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: fb218fe0-94a8-44a0-a252-d3cae8685c6f<-d5d86ba7-8a8a-4b58-b698-440423a66b5d#0:FAIL-t2
2022-06-25 01:09:29,759 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-LeaderElection183] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: fb218fe0-94a8-44a0-a252-d3cae8685c6f<-a2e7c5f8-591a-42df-bc70-018e5970ca84#0:FAIL-t2
2022-06-25 01:09:29,759 [fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-LeaderElection183] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - fb218fe0-94a8-44a0-a252-d3cae8685c6f@group-09829804023A-LeaderElection183 ELECTION round 0: result REJECTED
2022-06-25 01:09:29,796 [Listener at 0.0.0.0/45907] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Waiting for nodes to be ready. Got 5 of 6 DN Heartbeats.
2022-06-25 01:09:29,801 [Listener at 0.0.0.0/45907] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Cluster exits safe mode
2022-06-25 01:09:29,802 [Listener at 0.0.0.0/45907] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:09:29,865 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:30,008 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-06-25 01:09:30,094 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5016880758ns, electionTimeout:5000ms
2022-06-25 01:09:30,094 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: shutdown 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:30,094 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: changes role from  FOLLOWER to CANDIDATE at term 7 for changeToCandidate
2022-06-25 01:09:30,094 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:30,094 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: start 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184
2022-06-25 01:09:30,110 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184 ELECTION round 0: submit vote requests at term 8 for -1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:09:30,129 [grpc-default-executor-9] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: receive requestVote(ELECTION, 97d08340-a146-41c4-a759-b3b136c7fb6d, group-B6B9DF3CEF32, 8, (t:0, i:0))
2022-06-25 01:09:30,129 [grpc-default-executor-9] INFO  impl.VoteContext (VoteContext.java:log(48)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FOLLOWER: accept ELECTION from 97d08340-a146-41c4-a759-b3b136c7fb6d: our priority 0 <= candidate's priority 1
2022-06-25 01:09:30,129 [grpc-default-executor-9] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: changes role from  FOLLOWER to FOLLOWER at term 8 for candidate:97d08340-a146-41c4-a759-b3b136c7fb6d
2022-06-25 01:09:30,129 [grpc-default-executor-9] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: shutdown 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:30,150 [grpc-default-executor-9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: start 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:30,160 [Listener at 0.0.0.0/34403] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 1933 ms to scan 19 urls, producing 66 keys and 4066 values [using 2 cores]
2022-06-25 01:09:30,161 [Listener at 0.0.0.0/34403] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-06-25 01:09:30,166 [grpc-default-executor-9] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32 replies to ELECTION vote request: 97d08340-a146-41c4-a759-b3b136c7fb6d<-4943f96b-6a06-411a-b0ee-4ab66ab6f7f9#0:OK-t8. Peer's state: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32:t8, leader=null, voted=97d08340-a146-41c4-a759-b3b136c7fb6d, raftlog=4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:09:30,173 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1265)) - Starting Socket Reader #1 for port 0
2022-06-25 01:09:30,206 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState was interrupted
2022-06-25 01:09:30,246 [grpc-default-executor-9] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: receive requestVote(ELECTION, 97d08340-a146-41c4-a759-b3b136c7fb6d, group-B6B9DF3CEF32, 8, (t:0, i:0))
2022-06-25 01:09:30,247 [grpc-default-executor-9] INFO  impl.VoteContext (VoteContext.java:log(48)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FOLLOWER: accept ELECTION from 97d08340-a146-41c4-a759-b3b136c7fb6d: our priority 0 <= candidate's priority 1
2022-06-25 01:09:30,247 [grpc-default-executor-9] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: changes role from  FOLLOWER to FOLLOWER at term 8 for candidate:97d08340-a146-41c4-a759-b3b136c7fb6d
2022-06-25 01:09:30,247 [grpc-default-executor-9] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: shutdown fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:30,247 [grpc-default-executor-9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: start fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:30,247 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184: ELECTION PASSED received 1 response(s) and 0 exception(s):
2022-06-25 01:09:30,247 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 97d08340-a146-41c4-a759-b3b136c7fb6d<-4943f96b-6a06-411a-b0ee-4ab66ab6f7f9#0:OK-t8
2022-06-25 01:09:30,247 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState was interrupted
2022-06-25 01:09:30,252 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184 ELECTION round 0: result PASSED
2022-06-25 01:09:30,252 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: shutdown 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184
2022-06-25 01:09:30,253 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: changes role from CANDIDATE to LEADER at term 8 for changeToLeader
2022-06-25 01:09:30,253 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-B6B9DF3CEF32 with new leaderId: 97d08340-a146-41c4-a759-b3b136c7fb6d
2022-06-25 01:09:30,253 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: change Leader from null to 97d08340-a146-41c4-a759-b3b136c7fb6d at term 8 for becomeLeader, leader elected after 41954ms
2022-06-25 01:09:30,253 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-25 01:09:30,253 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:30,253 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-06-25 01:09:30,255 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-06-25 01:09:30,255 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-25 01:09:30,255 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-25 01:09:30,255 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:30,255 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-25 01:09:30,261 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2022-06-25 01:09:30,261 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:30,261 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2022-06-25 01:09:30,261 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2022-06-25 01:09:30,261 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:09:30,261 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:30,255 [grpc-default-executor-9] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32 replies to ELECTION vote request: 97d08340-a146-41c4-a759-b3b136c7fb6d<-fc692a40-1ae9-40b7-8d63-7e46f51df1ef#0:OK-t8. Peer's state: fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32:t8, leader=null, voted=97d08340-a146-41c4-a759-b3b136c7fb6d, raftlog=fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c-1, conf=-1: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|priority:0], old=null
2022-06-25 01:09:30,263 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(358)) - Pipeline Pipeline[ Id: 1a613b2a-b322-4f7f-932c-b6b9df3cef32, Nodes: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43029, RATIS=44897, RATIS_ADMIN=44897, RATIS_SERVER=44897, STANDALONE=37333], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}97d08340-a146-41c4-a759-b3b136c7fb6d{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=37711, RATIS=43169, RATIS_ADMIN=43169, RATIS_SERVER=43169, STANDALONE=44433], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}fc692a40-1ae9-40b7-8d63-7e46f51df1ef{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=40691, RATIS=39343, RATIS_ADMIN=39343, RATIS_SERVER=39343, STANDALONE=32859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:97d08340-a146-41c4-a759-b3b136c7fb6d, CreationTimestamp2022-06-25T01:08:47.549Z[Etc/UTC]] moved to OPEN state
2022-06-25 01:09:30,268 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2022-06-25 01:09:30,268 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:30,268 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2022-06-25 01:09:30,268 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2022-06-25 01:09:30,268 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:09:30,269 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:30,269 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: start 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderStateImpl
2022-06-25 01:09:30,270 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:30,272 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data/ratis/1a613b2a-b322-4f7f-932c-b6b9df3cef32/current/log_inprogress_0
2022-06-25 01:09:30,278 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderElection184] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: set configuration 0: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:09:30,283 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-B6B9DF3CEF32 with new leaderId: 97d08340-a146-41c4-a759-b3b136c7fb6d
2022-06-25 01:09:30,283 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: change Leader from null to 97d08340-a146-41c4-a759-b3b136c7fb6d at term 8 for appendEntries, leader elected after 42144ms
2022-06-25 01:09:30,285 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-B6B9DF3CEF32 with new leaderId: 97d08340-a146-41c4-a759-b3b136c7fb6d
2022-06-25 01:09:30,285 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: change Leader from null to 97d08340-a146-41c4-a759-b3b136c7fb6d at term 8 for appendEntries, leader elected after 42286ms
2022-06-25 01:09:30,285 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: set configuration 0: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:09:30,286 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:30,289 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: set configuration 0: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null
2022-06-25 01:09:30,289 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:30,388 [Listener at 127.0.0.1/44435] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2022-06-25 01:09:30,472 [Listener at 127.0.0.1/44435] INFO  om.OzoneManager (OzoneManager.java:start(1465)) - OzoneManager RPC server is listening at localhost/127.0.0.1:44435
2022-06-25 01:09:30,472 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/data/ratis/1a613b2a-b322-4f7f-932c-b6b9df3cef32/current/log_inprogress_0
2022-06-25 01:09:30,475 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data/ratis/1a613b2a-b322-4f7f-932c-b6b9df3cef32/current/log_inprogress_0
2022-06-25 01:09:30,476 [Listener at 127.0.0.1/44435] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(554)) - Starting OzoneManagerRatisServer om1 at port 38887
2022-06-25 01:09:30,476 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - om1@group-C5BA1605619E: start as a follower, conf=-1: [om1|rpc:localhost:38887|priority:0], old=null
2022-06-25 01:09:30,477 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:30,477 [om1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-FollowerState
2022-06-25 01:09:30,477 [om1-impl-thread1] ERROR util.JmxRegister (JmxRegister.java:tryRegister(40)) - Failed to register JMX Bean with name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
javax.management.InstanceAlreadyExistsException: Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.ratis.util.JmxRegister.tryRegister(JmxRegister.java:38)
	at org.apache.ratis.util.JmxRegister.register(JmxRegister.java:56)
	at org.apache.ratis.server.impl.RaftServerImpl.registerMBean(RaftServerImpl.java:329)
	at org.apache.ratis.server.impl.RaftServerImpl.start(RaftServerImpl.java:320)
	at org.apache.ratis.util.ConcurrentUtils.lambda$null$3(ConcurrentUtils.java:162)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2022-06-25 01:09:30,477 [om1-impl-thread1] ERROR util.JmxRegister (JmxRegister.java:tryRegister(40)) - Failed to register JMX Bean with name Ratis:service=RaftServer,group=group-C5BA1605619E,id="om1"
javax.management.InstanceAlreadyExistsException: Ratis:service=RaftServer,group=group-C5BA1605619E,id="om1"
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.ratis.util.JmxRegister.tryRegister(JmxRegister.java:38)
	at org.apache.ratis.util.JmxRegister.register(JmxRegister.java:56)
	at org.apache.ratis.server.impl.RaftServerImpl.registerMBean(RaftServerImpl.java:329)
	at org.apache.ratis.server.impl.RaftServerImpl.start(RaftServerImpl.java:320)
	at org.apache.ratis.util.ConcurrentUtils.lambda$null$3(ConcurrentUtils.java:162)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2022-06-25 01:09:30,478 [Listener at 127.0.0.1/44435] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - om1: start RPC server
2022-06-25 01:09:30,482 [Listener at 127.0.0.1/44435] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - om1: GrpcService started, listening on 38887
2022-06-25 01:09:30,499 [Listener at 127.0.0.1/44435] INFO  om.OzoneManager (OzoneManager.java:start(1481)) - Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
2022-06-25 01:09:30,499 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@3eab238f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-om1: Started
2022-06-25 01:09:30,570 [Listener at 127.0.0.1/44435] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2022-06-25 01:09:30,570 [Listener at 127.0.0.1/44435] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-06-25 01:09:30,571 [Listener at 127.0.0.1/44435] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-06-25 01:09:30,593 [Listener at 127.0.0.1/44435] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-06-25 01:09:30,594 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1029)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-06-25 01:09:30,594 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1005)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2022-06-25 01:09:30,594 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-06-25 01:09:30,594 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-06-25 01:09:30,598 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1248)) - Jetty bound to port 45123
2022-06-25 01:09:30,599 [Listener at 127.0.0.1/44435] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-06-25 01:09:30,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:30,628 [Listener at 127.0.0.1/44435] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-06-25 01:09:30,628 [Listener at 127.0.0.1/44435] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-06-25 01:09:30,628 [Listener at 127.0.0.1/44435] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-06-25 01:09:30,629 [Listener at 127.0.0.1/44435] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@16090c27{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-06-25 01:09:30,629 [Listener at 127.0.0.1/44435] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@2079f5d1{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2022-06-25 01:09:30,645 [Listener at 127.0.0.1/44435] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@29ffa17b{ozoneManager,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2022-06-25 01:09:30,706 [Listener at 127.0.0.1/44435] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@4ce10ed1{HTTP/1.1, (http/1.1)}{0.0.0.0:45123}
2022-06-25 01:09:30,706 [Listener at 127.0.0.1/44435] INFO  server.Server (Server.java:doStart(415)) - Started @404603ms
2022-06-25 01:09:30,706 [Listener at 127.0.0.1/44435] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-06-25 01:09:30,707 [Listener at 127.0.0.1/44435] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of ozoneManager listening at http://0.0.0.0:45123
2022-06-25 01:09:30,729 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1507)) - IPC Server Responder: starting
2022-06-25 01:09:30,749 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1344)) - IPC Server listener on 0: starting
2022-06-25 01:09:30,802 [Listener at 0.0.0.0/45907] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Waiting for nodes to be ready. Got 5 of 6 DN Heartbeats.
2022-06-25 01:09:30,802 [Listener at 0.0.0.0/45907] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Cluster exits safe mode
2022-06-25 01:09:30,802 [Listener at 0.0.0.0/45907] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:09:30,811 [Listener at 127.0.0.1/44435] INFO  om.OzoneManager (OzoneManager.java:startTrashEmptier(1905)) - Trash Interval set to 0. Files deleted won't move to trash
2022-06-25 01:09:30,865 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:30,876 [Listener at 127.0.0.1/44435] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:30,877 [Listener at 127.0.0.1/44435] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:30,877 [Listener at 127.0.0.1/44435] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-06-25 01:09:30,888 [Listener at 127.0.0.1/44435] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net ip:10.1.0.8
2022-06-25 01:09:30,891 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@37bd8b2d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-06-25 01:09:30,892 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(344)) - Attempting to start container services.
2022-06-25 01:09:30,892 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(279)) - Background container scanner has been disabled.
2022-06-25 01:09:30,925 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis be67eb5e-e62d-4374-a142-8db592db20d7
2022-06-25 01:09:30,945 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - be67eb5e-e62d-4374-a142-8db592db20d7: start RPC server
2022-06-25 01:09:30,946 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - be67eb5e-e62d-4374-a142-8db592db20d7: GrpcService started, listening on 39697
2022-06-25 01:09:30,954 [Listener at 127.0.0.1/44435] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(82)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2022-06-25 01:09:30,974 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis be67eb5e-e62d-4374-a142-8db592db20d7 is started using port 39697 for RATIS
2022-06-25 01:09:30,974 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis be67eb5e-e62d-4374-a142-8db592db20d7 is started using port 39697 for RATIS_ADMIN
2022-06-25 01:09:30,974 [EndpointStateMachine task thread for /0.0.0.0:36557 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis be67eb5e-e62d-4374-a142-8db592db20d7 is started using port 39697 for RATIS_SERVER
2022-06-25 01:09:30,975 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@95dd22] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-be67eb5e-e62d-4374-a142-8db592db20d7: Started
2022-06-25 01:09:31,010 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:31,220 [Listener at 127.0.0.1/44435] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 259 ms to scan 7 urls, producing 131 keys and 316 values 
2022-06-25 01:09:31,221 [Listener at 127.0.0.1/44435] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(237)) - Datanode State Machine Task Thread Pool size 2
2022-06-25 01:09:31,229 [Listener at 127.0.0.1/44435] INFO  volume.HddsVolume (HddsVolume.java:<init>(116)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-0/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-06-25 01:09:31,229 [Listener at 127.0.0.1/44435] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-0/data-0/containers/hdds to VolumeSet
2022-06-25 01:09:31,229 [Listener at 127.0.0.1/44435] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-0/data-0/containers/hdds
2022-06-25 01:09:31,246 [Listener at 127.0.0.1/44435] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-0/data-0/containers/hdds
2022-06-25 01:09:31,273 [Listener at 127.0.0.1/44435] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-0/data/ratis to VolumeSet
2022-06-25 01:09:31,273 [Listener at 127.0.0.1/44435] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-0/data/ratis
2022-06-25 01:09:31,278 [Listener at 127.0.0.1/44435] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-0/data/ratis
2022-06-25 01:09:31,318 [Thread-6482] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-0/data-0/containers/hdds
2022-06-25 01:09:31,319 [Listener at 127.0.0.1/44435] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(266)) - Build ContainerSet costs 0s
2022-06-25 01:09:31,320 [Listener at 127.0.0.1/44435] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-06-25 01:09:31,320 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-06-25 01:09:31,320 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-06-25 01:09:31,320 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-06-25 01:09:31,320 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-06-25 01:09:31,320 [Listener at 127.0.0.1/44435] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-06-25 01:09:31,320 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:31,321 [Listener at 127.0.0.1/44435] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-06-25 01:09:31,321 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:09:31,321 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-06-25 01:09:31,321 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-06-25 01:09:31,322 [Listener at 127.0.0.1/44435] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-06-25 01:09:31,322 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-06-25 01:09:31,322 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-06-25 01:09:31,323 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:31,323 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:31,323 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-0/data/ratis] (custom)
2022-06-25 01:09:31,340 [Listener at 127.0.0.1/44435] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-06-25 01:09:31,343 [Listener at 127.0.0.1/44435] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-06-25 01:09:31,343 [Listener at 127.0.0.1/44435] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-06-25 01:09:31,344 [Listener at 127.0.0.1/44435] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-06-25 01:09:31,351 [Listener at 127.0.0.1/44435] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-06-25 01:09:31,352 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1029)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-06-25 01:09:31,352 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1005)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-06-25 01:09:31,352 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-06-25 01:09:31,352 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-06-25 01:09:31,353 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1248)) - Jetty bound to port 45467
2022-06-25 01:09:31,353 [Listener at 127.0.0.1/44435] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-06-25 01:09:31,354 [Listener at 127.0.0.1/44435] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-06-25 01:09:31,354 [Listener at 127.0.0.1/44435] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-06-25 01:09:31,354 [Listener at 127.0.0.1/44435] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-06-25 01:09:31,357 [Listener at 127.0.0.1/44435] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@6001a6e1{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-06-25 01:09:31,357 [Listener at 127.0.0.1/44435] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@57c26e{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-06-25 01:09:31,554 [om1@group-C5BA1605619E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1077091286ns, electionTimeout:1076ms
2022-06-25 01:09:31,554 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - om1: shutdown om1@group-C5BA1605619E-FollowerState
2022-06-25 01:09:31,554 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:09:31,554 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:31,554 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderElection185
2022-06-25 01:09:31,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:31,681 [om1@group-C5BA1605619E-LeaderElection185] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - om1@group-C5BA1605619E-LeaderElection185 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:localhost:38887|priority:0], old=null
2022-06-25 01:09:31,681 [om1@group-C5BA1605619E-LeaderElection185] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - om1@group-C5BA1605619E-LeaderElection185 ELECTION round 0: result PASSED (term=1)
2022-06-25 01:09:31,681 [om1@group-C5BA1605619E-LeaderElection185] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - om1: shutdown om1@group-C5BA1605619E-LeaderElection185
2022-06-25 01:09:31,681 [om1@group-C5BA1605619E-LeaderElection185] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-06-25 01:09:31,681 [om1@group-C5BA1605619E-LeaderElection185] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 3413ms
2022-06-25 01:09:31,681 [om1@group-C5BA1605619E-LeaderElection185] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-25 01:09:31,682 [om1@group-C5BA1605619E-LeaderElection185] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2022-06-25 01:09:31,682 [om1@group-C5BA1605619E-LeaderElection185] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2022-06-25 01:09:31,682 [om1@group-C5BA1605619E-LeaderElection185] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 10s (default)
2022-06-25 01:09:31,682 [om1@group-C5BA1605619E-LeaderElection185] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-25 01:09:31,682 [om1@group-C5BA1605619E-LeaderElection185] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-25 01:09:31,682 [om1@group-C5BA1605619E-LeaderElection185] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2022-06-25 01:09:31,682 [om1@group-C5BA1605619E-LeaderElection185] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-25 01:09:31,682 [om1@group-C5BA1605619E-LeaderElection185] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderStateImpl
2022-06-25 01:09:31,682 [om1@group-C5BA1605619E-LeaderElection185] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:31,718 [om1@group-C5BA1605619E-LeaderElection185] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - om1@group-C5BA1605619E: set configuration 0: [om1|rpc:localhost:38887|admin:|client:|dataStream:|priority:0], old=null
2022-06-25 01:09:31,762 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
2022-06-25 01:09:31,764 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:notifyConfigurationChanged(192)) - Received Configuration change notification from Ratis. New Peer list:
[id: "om1"
address: "localhost:38887"
]
2022-06-25 01:09:31,802 [Listener at 0.0.0.0/45907] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Waiting for nodes to be ready. Got 5 of 6 DN Heartbeats.
2022-06-25 01:09:31,803 [Listener at 0.0.0.0/45907] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Cluster exits safe mode
2022-06-25 01:09:31,803 [Listener at 0.0.0.0/45907] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:09:31,866 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:32,010 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:32,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:32,699 [Listener at 127.0.0.1/44435] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@29882a0d{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-45467-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-1101137174967356505/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-25 01:09:32,782 [Listener at 127.0.0.1/44435] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@376b1535{HTTP/1.1, (http/1.1)}{0.0.0.0:45467}
2022-06-25 01:09:32,783 [Listener at 127.0.0.1/44435] INFO  server.Server (Server.java:doStart(415)) - Started @406679ms
2022-06-25 01:09:32,783 [Listener at 127.0.0.1/44435] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-06-25 01:09:32,791 [Listener at 127.0.0.1/44435] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:45467
2022-06-25 01:09:32,803 [Listener at 0.0.0.0/45907] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Waiting for nodes to be ready. Got 5 of 6 DN Heartbeats.
2022-06-25 01:09:32,803 [Listener at 0.0.0.0/45907] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Cluster exits safe mode
2022-06-25 01:09:32,803 [Listener at 0.0.0.0/45907] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:09:32,808 [Listener at 127.0.0.1/44435] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:32,808 [Listener at 127.0.0.1/44435] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:32,808 [Listener at 127.0.0.1/44435] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-06-25 01:09:32,866 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:32,912 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(492)) - Ozone container server started.
2022-06-25 01:09:32,994 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@55440714] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-06-25 01:09:33,013 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:33,020 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-0/meta/datanode.id
2022-06-25 01:09:33,062 [Listener at 127.0.0.1/44435] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net ip:10.1.0.8
2022-06-25 01:09:33,119 [Listener at 127.0.0.1/44435] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(82)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2022-06-25 01:09:33,374 [Listener at 127.0.0.1/44435] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 254 ms to scan 7 urls, producing 131 keys and 316 values 
2022-06-25 01:09:33,375 [Listener at 127.0.0.1/44435] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(237)) - Datanode State Machine Task Thread Pool size 2
2022-06-25 01:09:33,387 [Listener at 127.0.0.1/44435] INFO  volume.HddsVolume (HddsVolume.java:<init>(116)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-1/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-06-25 01:09:33,387 [Listener at 127.0.0.1/44435] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-1/data-0/containers/hdds to VolumeSet
2022-06-25 01:09:33,387 [Listener at 127.0.0.1/44435] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-1/data-0/containers/hdds
2022-06-25 01:09:33,434 [Listener at 127.0.0.1/44435] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-1/data-0/containers/hdds
2022-06-25 01:09:33,467 [Listener at 127.0.0.1/44435] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-1/data/ratis to VolumeSet
2022-06-25 01:09:33,467 [Listener at 127.0.0.1/44435] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-1/data/ratis
2022-06-25 01:09:33,468 [Listener at 127.0.0.1/44435] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-1/data/ratis
2022-06-25 01:09:33,493 [Thread-6503] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-1/data-0/containers/hdds
2022-06-25 01:09:33,493 [Listener at 127.0.0.1/44435] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(266)) - Build ContainerSet costs 0s
2022-06-25 01:09:33,495 [Listener at 127.0.0.1/44435] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-06-25 01:09:33,495 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-06-25 01:09:33,495 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-06-25 01:09:33,495 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-06-25 01:09:33,495 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-06-25 01:09:33,495 [Listener at 127.0.0.1/44435] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-06-25 01:09:33,495 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:33,495 [Listener at 127.0.0.1/44435] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-06-25 01:09:33,495 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:09:33,496 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-06-25 01:09:33,496 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-06-25 01:09:33,497 [Listener at 127.0.0.1/44435] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-06-25 01:09:33,498 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-06-25 01:09:33,498 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-06-25 01:09:33,498 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:33,498 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:33,498 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-1/data/ratis] (custom)
2022-06-25 01:09:33,499 [Listener at 127.0.0.1/44435] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-06-25 01:09:33,546 [Listener at 127.0.0.1/44435] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-06-25 01:09:33,546 [Listener at 127.0.0.1/44435] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-06-25 01:09:33,547 [Listener at 127.0.0.1/44435] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-06-25 01:09:33,548 [Listener at 127.0.0.1/44435] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-06-25 01:09:33,549 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1029)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-06-25 01:09:33,549 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1005)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-06-25 01:09:33,549 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-06-25 01:09:33,550 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-06-25 01:09:33,550 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1248)) - Jetty bound to port 45595
2022-06-25 01:09:33,550 [Listener at 127.0.0.1/44435] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-06-25 01:09:33,571 [Listener at 127.0.0.1/44435] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-06-25 01:09:33,571 [Listener at 127.0.0.1/44435] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-06-25 01:09:33,571 [Listener at 127.0.0.1/44435] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2022-06-25 01:09:33,572 [Listener at 127.0.0.1/44435] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@5c76891c{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-06-25 01:09:33,572 [Listener at 127.0.0.1/44435] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@2fa6c3a9{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-06-25 01:09:33,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:33,804 [Listener at 0.0.0.0/45907] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Waiting for nodes to be ready. Got 5 of 6 DN Heartbeats.
2022-06-25 01:09:33,804 [Listener at 0.0.0.0/45907] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Cluster exits safe mode
2022-06-25 01:09:33,804 [Listener at 0.0.0.0/45907] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:09:33,866 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:34,013 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:34,157 [Listener at 127.0.0.1/44435] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@35c0bc60{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-45595-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-4826779575966305324/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-25 01:09:34,161 [Listener at 127.0.0.1/44435] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@146b7b38{HTTP/1.1, (http/1.1)}{0.0.0.0:45595}
2022-06-25 01:09:34,161 [Listener at 127.0.0.1/44435] INFO  server.Server (Server.java:doStart(415)) - Started @408058ms
2022-06-25 01:09:34,161 [Listener at 127.0.0.1/44435] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-06-25 01:09:34,162 [Listener at 127.0.0.1/44435] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:45595
2022-06-25 01:09:34,170 [Listener at 127.0.0.1/44435] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:34,170 [Listener at 127.0.0.1/44435] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:34,170 [Listener at 127.0.0.1/44435] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-06-25 01:09:34,172 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(492)) - Ozone container server started.
2022-06-25 01:09:34,182 [Listener at 127.0.0.1/44435] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net ip:10.1.0.8
2022-06-25 01:09:34,215 [Listener at 127.0.0.1/44435] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(82)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2022-06-25 01:09:34,218 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7d9ce720] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-06-25 01:09:34,224 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-1/meta/datanode.id
2022-06-25 01:09:34,377 [Listener at 127.0.0.1/44435] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 161 ms to scan 7 urls, producing 131 keys and 316 values 
2022-06-25 01:09:34,393 [Listener at 127.0.0.1/44435] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(237)) - Datanode State Machine Task Thread Pool size 2
2022-06-25 01:09:34,397 [Listener at 127.0.0.1/44435] INFO  volume.HddsVolume (HddsVolume.java:<init>(116)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-2/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-06-25 01:09:34,397 [Listener at 127.0.0.1/44435] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-2/data-0/containers/hdds to VolumeSet
2022-06-25 01:09:34,397 [Listener at 127.0.0.1/44435] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-2/data-0/containers/hdds
2022-06-25 01:09:34,398 [Listener at 127.0.0.1/44435] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-2/data-0/containers/hdds
2022-06-25 01:09:34,409 [Listener at 127.0.0.1/44435] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-2/data/ratis to VolumeSet
2022-06-25 01:09:34,409 [Listener at 127.0.0.1/44435] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-2/data/ratis
2022-06-25 01:09:34,409 [Listener at 127.0.0.1/44435] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-2/data/ratis
2022-06-25 01:09:34,462 [Thread-6516] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-2/data-0/containers/hdds
2022-06-25 01:09:34,462 [Listener at 127.0.0.1/44435] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(266)) - Build ContainerSet costs 0s
2022-06-25 01:09:34,464 [Listener at 127.0.0.1/44435] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-06-25 01:09:34,464 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-06-25 01:09:34,464 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-06-25 01:09:34,464 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-06-25 01:09:34,464 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-06-25 01:09:34,464 [Listener at 127.0.0.1/44435] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-06-25 01:09:34,464 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:34,464 [Listener at 127.0.0.1/44435] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-06-25 01:09:34,464 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:09:34,465 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-06-25 01:09:34,465 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-06-25 01:09:34,466 [Listener at 127.0.0.1/44435] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-06-25 01:09:34,466 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-06-25 01:09:34,466 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-06-25 01:09:34,466 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:34,466 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:34,466 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-2/data/ratis] (custom)
2022-06-25 01:09:34,468 [Listener at 127.0.0.1/44435] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-06-25 01:09:34,477 [Listener at 127.0.0.1/44435] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-06-25 01:09:34,477 [Listener at 127.0.0.1/44435] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-06-25 01:09:34,478 [Listener at 127.0.0.1/44435] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-06-25 01:09:34,488 [Listener at 127.0.0.1/44435] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-06-25 01:09:34,489 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1029)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-06-25 01:09:34,489 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1005)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-06-25 01:09:34,489 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-06-25 01:09:34,489 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-06-25 01:09:34,489 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1248)) - Jetty bound to port 34051
2022-06-25 01:09:34,489 [Listener at 127.0.0.1/44435] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-06-25 01:09:34,522 [Listener at 127.0.0.1/44435] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-06-25 01:09:34,522 [Listener at 127.0.0.1/44435] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-06-25 01:09:34,522 [Listener at 127.0.0.1/44435] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-06-25 01:09:34,535 [Listener at 127.0.0.1/44435] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@33392bab{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-06-25 01:09:34,535 [Listener at 127.0.0.1/44435] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@429700bf{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-06-25 01:09:34,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:34,804 [Listener at 0.0.0.0/45907] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Waiting for nodes to be ready. Got 5 of 6 DN Heartbeats.
2022-06-25 01:09:34,805 [Listener at 0.0.0.0/45907] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Cluster exits safe mode
2022-06-25 01:09:34,805 [Listener at 0.0.0.0/45907] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:09:34,814 [IPC Server handler 18 on default port 36557] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0} as the reported value does not match the value stored in SCM (DECOMMISSIONED, 0)
2022-06-25 01:09:34,870 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:34,882 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(55)) - Datanode be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0} moved to HEALTHY READONLY state.
2022-06-25 01:09:34,882 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/be67eb5e-e62d-4374-a142-8db592db20d7
2022-06-25 01:09:34,969 [Listener at 127.0.0.1/44435] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@30a4bec0{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-34051-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-545078616688244967/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-25 01:09:34,974 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONING, persistedOpStateExpiryEpochSec: 0} moved to HEALTHY state.
2022-06-25 01:09:34,974 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(275)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-06-25 01:09:35,016 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:35,042 [Listener at 127.0.0.1/44435] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@40265062{HTTP/1.1, (http/1.1)}{0.0.0.0:34051}
2022-06-25 01:09:35,042 [Listener at 127.0.0.1/44435] INFO  server.Server (Server.java:doStart(415)) - Started @408939ms
2022-06-25 01:09:35,042 [Listener at 127.0.0.1/44435] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-06-25 01:09:35,043 [Listener at 127.0.0.1/44435] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:34051
2022-06-25 01:09:35,074 [Listener at 127.0.0.1/44435] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:35,075 [Listener at 127.0.0.1/44435] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:35,075 [Listener at 127.0.0.1/44435] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-06-25 01:09:35,082 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(492)) - Ozone container server started.
2022-06-25 01:09:35,091 [Listener at 127.0.0.1/44435] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net ip:10.1.0.8
2022-06-25 01:09:35,203 [Listener at 127.0.0.1/44435] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(82)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2022-06-25 01:09:35,238 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4fbda532] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-06-25 01:09:35,261 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-2/meta/datanode.id
2022-06-25 01:09:35,304 [Listener at 127.0.0.1/44435] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 100 ms to scan 7 urls, producing 131 keys and 316 values 
2022-06-25 01:09:35,305 [Listener at 127.0.0.1/44435] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(237)) - Datanode State Machine Task Thread Pool size 2
2022-06-25 01:09:35,306 [Listener at 127.0.0.1/44435] INFO  volume.HddsVolume (HddsVolume.java:<init>(116)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-3/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-06-25 01:09:35,306 [Listener at 127.0.0.1/44435] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-3/data-0/containers/hdds to VolumeSet
2022-06-25 01:09:35,306 [Listener at 127.0.0.1/44435] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-3/data-0/containers/hdds
2022-06-25 01:09:35,307 [Listener at 127.0.0.1/44435] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-3/data-0/containers/hdds
2022-06-25 01:09:35,357 [Listener at 127.0.0.1/44435] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-3/data/ratis to VolumeSet
2022-06-25 01:09:35,359 [Listener at 127.0.0.1/44435] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-3/data/ratis
2022-06-25 01:09:35,359 [Listener at 127.0.0.1/44435] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-3/data/ratis
2022-06-25 01:09:35,411 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(309)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-0/data-0/containers/hdds/e228e9f1-8cea-4b31-8b4b-3b149b9026ba/DS-3fa9edae-d786-4798-97ca-9ee342b7c772/container.db for volume DS-3fa9edae-d786-4798-97ca-9ee342b7c772
2022-06-25 01:09:35,479 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(340)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-0/data-0/containers/hdds/e228e9f1-8cea-4b31-8b4b-3b149b9026ba/DS-3fa9edae-d786-4798-97ca-9ee342b7c772/container.db for volume DS-3fa9edae-d786-4798-97ca-9ee342b7c772
2022-06-25 01:09:35,479 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(344)) - Attempting to start container services.
2022-06-25 01:09:35,480 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(279)) - Background container scanner has been disabled.
2022-06-25 01:09:35,480 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 36553
2022-06-25 01:09:35,489 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis f368a730-3857-4d18-b0ff-e0c952296109
2022-06-25 01:09:35,496 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - f368a730-3857-4d18-b0ff-e0c952296109: start RPC server
2022-06-25 01:09:35,497 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - f368a730-3857-4d18-b0ff-e0c952296109: GrpcService started, listening on 46119
2022-06-25 01:09:35,502 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis f368a730-3857-4d18-b0ff-e0c952296109 is started using port 46119 for RATIS
2022-06-25 01:09:35,502 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis f368a730-3857-4d18-b0ff-e0c952296109 is started using port 46119 for RATIS_ADMIN
2022-06-25 01:09:35,502 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis f368a730-3857-4d18-b0ff-e0c952296109 is started using port 46119 for RATIS_SERVER
2022-06-25 01:09:35,503 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@27040a78] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-f368a730-3857-4d18-b0ff-e0c952296109: Started
2022-06-25 01:09:35,503 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc f368a730-3857-4d18-b0ff-e0c952296109 is started using port 36013
2022-06-25 01:09:35,575 [Thread-6538] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-3/data-0/containers/hdds
2022-06-25 01:09:35,575 [Listener at 127.0.0.1/44435] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(266)) - Build ContainerSet costs 0s
2022-06-25 01:09:35,577 [Listener at 127.0.0.1/44435] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-06-25 01:09:35,577 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-06-25 01:09:35,577 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-06-25 01:09:35,577 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-06-25 01:09:35,577 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-06-25 01:09:35,577 [Listener at 127.0.0.1/44435] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-06-25 01:09:35,577 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:35,577 [Listener at 127.0.0.1/44435] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-06-25 01:09:35,577 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:09:35,577 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-06-25 01:09:35,578 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-06-25 01:09:35,591 [Listener at 127.0.0.1/44435] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-06-25 01:09:35,591 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-06-25 01:09:35,591 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-06-25 01:09:35,591 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:35,591 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:35,591 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-3/data/ratis] (custom)
2022-06-25 01:09:35,604 [Listener at 127.0.0.1/44435] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-06-25 01:09:35,615 [Listener at 127.0.0.1/44435] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-06-25 01:09:35,615 [Listener at 127.0.0.1/44435] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-06-25 01:09:35,616 [Listener at 127.0.0.1/44435] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-06-25 01:09:35,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:35,630 [Listener at 127.0.0.1/44435] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-06-25 01:09:35,631 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1029)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-06-25 01:09:35,632 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1005)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-06-25 01:09:35,632 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-06-25 01:09:35,632 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-06-25 01:09:35,632 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1248)) - Jetty bound to port 44599
2022-06-25 01:09:35,632 [Listener at 127.0.0.1/44435] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-06-25 01:09:35,634 [Listener at 127.0.0.1/44435] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-06-25 01:09:35,634 [Listener at 127.0.0.1/44435] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-06-25 01:09:35,634 [Listener at 127.0.0.1/44435] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2022-06-25 01:09:35,635 [Listener at 127.0.0.1/44435] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@7fbecfb0{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-06-25 01:09:35,635 [Listener at 127.0.0.1/44435] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@cd5fbc7{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-06-25 01:09:35,810 [Listener at 0.0.0.0/45907] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-06-25 01:09:35,810 [Listener at 0.0.0.0/45907] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Cluster exits safe mode
2022-06-25 01:09:35,812 [Listener at 0.0.0.0/45907] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:09:35,845 [IPC Server handler 15 on default port 38653] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:recommission(316)) - Queued node be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONED, persistedOpStateExpiryEpochSec: 0} for recommission
2022-06-25 01:09:35,871 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:36,017 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-06-25 01:09:36,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:36,688 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:processCancelledNodes(177)) - Recommissioned node be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONED, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:09:36,688 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONED, persistedOpStateExpiryEpochSec: 0} moved to HEALTHY state.
2022-06-25 01:09:36,689 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(275)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-06-25 01:09:36,689 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=793cb964-1b2d-41b4-96bf-87f9d58b43b0 to datanode:be67eb5e-e62d-4374-a142-8db592db20d7
2022-06-25 01:09:36,689 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 793cb964-1b2d-41b4-96bf-87f9d58b43b0, Nodes: be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONED, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-25T01:09:36.689Z[Etc/UTC]].
2022-06-25 01:09:36,690 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=2b00854c-ae60-4259-8cdb-5f5be5f6e354 to datanode:09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf
2022-06-25 01:09:36,690 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=2b00854c-ae60-4259-8cdb-5f5be5f6e354 to datanode:3c6128f4-7bf2-4a55-83fb-21add5186158
2022-06-25 01:09:36,690 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=2b00854c-ae60-4259-8cdb-5f5be5f6e354 to datanode:be67eb5e-e62d-4374-a142-8db592db20d7
2022-06-25 01:09:36,694 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 2b00854c-ae60-4259-8cdb-5f5be5f6e354, Nodes: 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONED, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-25T01:09:36.690Z[Etc/UTC]].
2022-06-25 01:09:36,767 [Listener at 127.0.0.1/44435] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@50687454{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-44599-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-1647388579460262075/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-25 01:09:36,841 [IPC Server handler 5 on default port 36557] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONED, persistedOpStateExpiryEpochSec: 0} as the reported value does not match the value stored in SCM (IN_SERVICE, 0)
2022-06-25 01:09:36,850 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(309)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-1/data-0/containers/hdds/e228e9f1-8cea-4b31-8b4b-3b149b9026ba/DS-c6412304-c147-467c-a3e4-0829c5263599/container.db for volume DS-c6412304-c147-467c-a3e4-0829c5263599
2022-06-25 01:09:36,851 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(340)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-1/data-0/containers/hdds/e228e9f1-8cea-4b31-8b4b-3b149b9026ba/DS-c6412304-c147-467c-a3e4-0829c5263599/container.db for volume DS-c6412304-c147-467c-a3e4-0829c5263599
2022-06-25 01:09:36,851 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(344)) - Attempting to start container services.
2022-06-25 01:09:36,851 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(279)) - Background container scanner has been disabled.
2022-06-25 01:09:36,852 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 40907
2022-06-25 01:09:36,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:36,911 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis ec2664f4-d768-4745-9abe-ef2a305e3ce9
2022-06-25 01:09:36,911 [Listener at 127.0.0.1/44435] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@670d51b7{HTTP/1.1, (http/1.1)}{0.0.0.0:44599}
2022-06-25 01:09:36,911 [Listener at 127.0.0.1/44435] INFO  server.Server (Server.java:doStart(415)) - Started @410808ms
2022-06-25 01:09:36,911 [Listener at 127.0.0.1/44435] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-06-25 01:09:36,912 [Listener at 127.0.0.1/44435] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:44599
2022-06-25 01:09:36,926 [Listener at 127.0.0.1/44435] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:36,926 [Listener at 127.0.0.1/44435] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:36,926 [Listener at 127.0.0.1/44435] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-06-25 01:09:36,962 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(492)) - Ozone container server started.
2022-06-25 01:09:37,006 [Listener at 127.0.0.1/44435] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net ip:10.1.0.8
2022-06-25 01:09:37,017 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:37,036 [IPC Server handler 0 on default port 44773] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/f368a730-3857-4d18-b0ff-e0c952296109
2022-06-25 01:09:37,037 [IPC Server handler 0 on default port 44773] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : f368a730-3857-4d18-b0ff-e0c952296109{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=36553, RATIS=46119, RATIS_ADMIN=46119, RATIS_SERVER=46119, STANDALONE=36013], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:09:37,063 [Listener at 127.0.0.1/44435] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(82)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2022-06-25 01:09:37,151 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9: start RPC server
2022-06-25 01:09:37,154 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9: GrpcService started, listening on 41903
2022-06-25 01:09:37,157 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2022-06-25 01:09:37,158 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - ContainerSafeModeRule rule is successfully validated
2022-06-25 01:09:37,305 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@e9bcd6a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-06-25 01:09:37,324 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-3/meta/datanode.id
2022-06-25 01:09:37,329 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(275)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-06-25 01:09:37,329 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - AtleastOneDatanodeReportedRule rule is successfully validated
2022-06-25 01:09:37,329 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=8119f22a-7f75-41f6-8378-689fa3209105 to datanode:f368a730-3857-4d18-b0ff-e0c952296109
2022-06-25 01:09:37,331 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis ec2664f4-d768-4745-9abe-ef2a305e3ce9 is started using port 41903 for RATIS
2022-06-25 01:09:37,331 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis ec2664f4-d768-4745-9abe-ef2a305e3ce9 is started using port 41903 for RATIS_ADMIN
2022-06-25 01:09:37,331 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis ec2664f4-d768-4745-9abe-ef2a305e3ce9 is started using port 41903 for RATIS_SERVER
2022-06-25 01:09:37,331 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@5ce72a25] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-ec2664f4-d768-4745-9abe-ef2a305e3ce9: Started
2022-06-25 01:09:37,333 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc ec2664f4-d768-4745-9abe-ef2a305e3ce9 is started using port 45557
2022-06-25 01:09:37,413 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 8119f22a-7f75-41f6-8378-689fa3209105, Nodes: f368a730-3857-4d18-b0ff-e0c952296109{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=36553, RATIS=46119, RATIS_ADMIN=46119, RATIS_SERVER=46119, STANDALONE=36013], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-25T01:09:37.329Z[Etc/UTC]].
2022-06-25 01:09:37,466 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(309)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-2/data-0/containers/hdds/e228e9f1-8cea-4b31-8b4b-3b149b9026ba/DS-34dff939-fb86-4422-b7e1-19ef418e8194/container.db for volume DS-34dff939-fb86-4422-b7e1-19ef418e8194
2022-06-25 01:09:37,466 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(340)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-2/data-0/containers/hdds/e228e9f1-8cea-4b31-8b4b-3b149b9026ba/DS-34dff939-fb86-4422-b7e1-19ef418e8194/container.db for volume DS-34dff939-fb86-4422-b7e1-19ef418e8194
2022-06-25 01:09:37,466 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(344)) - Attempting to start container services.
2022-06-25 01:09:37,467 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(279)) - Background container scanner has been disabled.
2022-06-25 01:09:37,468 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 36173
2022-06-25 01:09:37,478 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis ee118b23-09e5-41f4-9121-1170bcf86bc2
2022-06-25 01:09:37,518 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - ee118b23-09e5-41f4-9121-1170bcf86bc2: start RPC server
2022-06-25 01:09:37,521 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - ee118b23-09e5-41f4-9121-1170bcf86bc2: GrpcService started, listening on 39807
2022-06-25 01:09:37,524 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis ee118b23-09e5-41f4-9121-1170bcf86bc2 is started using port 39807 for RATIS
2022-06-25 01:09:37,524 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis ee118b23-09e5-41f4-9121-1170bcf86bc2 is started using port 39807 for RATIS_ADMIN
2022-06-25 01:09:37,524 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis ee118b23-09e5-41f4-9121-1170bcf86bc2 is started using port 39807 for RATIS_SERVER
2022-06-25 01:09:37,525 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@1eacbbe8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-ee118b23-09e5-41f4-9121-1170bcf86bc2: Started
2022-06-25 01:09:37,582 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc ee118b23-09e5-41f4-9121-1170bcf86bc2 is started using port 36851
2022-06-25 01:09:37,585 [Listener at 127.0.0.1/44435] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 521 ms to scan 7 urls, producing 131 keys and 316 values 
2022-06-25 01:09:37,586 [Listener at 127.0.0.1/44435] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(237)) - Datanode State Machine Task Thread Pool size 2
2022-06-25 01:09:37,609 [Listener at 127.0.0.1/44435] INFO  volume.HddsVolume (HddsVolume.java:<init>(116)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-4/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-06-25 01:09:37,609 [Listener at 127.0.0.1/44435] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-4/data-0/containers/hdds to VolumeSet
2022-06-25 01:09:37,609 [Listener at 127.0.0.1/44435] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-4/data-0/containers/hdds
2022-06-25 01:09:37,614 [Listener at 127.0.0.1/44435] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-4/data-0/containers/hdds
2022-06-25 01:09:37,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:37,716 [Listener at 127.0.0.1/44435] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-4/data/ratis to VolumeSet
2022-06-25 01:09:37,716 [Listener at 127.0.0.1/44435] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-4/data/ratis
2022-06-25 01:09:37,717 [Listener at 127.0.0.1/44435] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-4/data/ratis
2022-06-25 01:09:37,743 [Thread-6570] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-4/data-0/containers/hdds
2022-06-25 01:09:37,743 [Listener at 127.0.0.1/44435] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(266)) - Build ContainerSet costs 0s
2022-06-25 01:09:37,745 [Listener at 127.0.0.1/44435] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-06-25 01:09:37,745 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-06-25 01:09:37,745 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-06-25 01:09:37,745 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-06-25 01:09:37,746 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-06-25 01:09:37,746 [Listener at 127.0.0.1/44435] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-06-25 01:09:37,746 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:37,746 [Listener at 127.0.0.1/44435] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-06-25 01:09:37,746 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:09:37,746 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-06-25 01:09:37,749 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-06-25 01:09:37,750 [Listener at 127.0.0.1/44435] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-06-25 01:09:37,750 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-06-25 01:09:37,750 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-06-25 01:09:37,751 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:37,751 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:37,751 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-4/data/ratis] (custom)
2022-06-25 01:09:37,753 [Listener at 127.0.0.1/44435] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-06-25 01:09:37,779 [Listener at 127.0.0.1/44435] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-06-25 01:09:37,779 [Listener at 127.0.0.1/44435] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-06-25 01:09:37,782 [Listener at 127.0.0.1/44435] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-06-25 01:09:37,787 [Listener at 127.0.0.1/44435] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-06-25 01:09:37,788 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1029)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-06-25 01:09:37,788 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1005)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-06-25 01:09:37,788 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-06-25 01:09:37,788 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-06-25 01:09:37,789 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1248)) - Jetty bound to port 36011
2022-06-25 01:09:37,789 [Listener at 127.0.0.1/44435] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-06-25 01:09:37,791 [Listener at 127.0.0.1/44435] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-06-25 01:09:37,791 [Listener at 127.0.0.1/44435] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-06-25 01:09:37,791 [Listener at 127.0.0.1/44435] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2022-06-25 01:09:37,792 [Listener at 127.0.0.1/44435] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@7e69334{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-06-25 01:09:37,792 [Listener at 127.0.0.1/44435] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@1a2da895{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-06-25 01:09:37,816 [IPC Server handler 4 on default port 36557] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONED, persistedOpStateExpiryEpochSec: 0} as the reported value does not match the value stored in SCM (IN_SERVICE, 0)
2022-06-25 01:09:37,826 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - be67eb5e-e62d-4374-a142-8db592db20d7: addNew group-87F9D58B43B0:[be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:1] returns group-87F9D58B43B0:java.util.concurrent.CompletableFuture@2edcee04[Not completed]
2022-06-25 01:09:37,827 [pool-4611-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - be67eb5e-e62d-4374-a142-8db592db20d7: new RaftServerImpl for group-87F9D58B43B0:[be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:1] with ContainerStateMachine:uninitialized
2022-06-25 01:09:37,827 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:09:37,827 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:09:37,827 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:37,827 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:37,827 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:37,827 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:37,827 [pool-4611-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0: ConfigurationManager, init=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:1], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:37,827 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis] (custom)
2022-06-25 01:09:37,828 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:37,828 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:37,828 [pool-4611-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis/793cb964-1b2d-41b4-96bf-87f9d58b43b0 does not exist. Creating ...
2022-06-25 01:09:37,840 [pool-4611-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis/793cb964-1b2d-41b4-96bf-87f9d58b43b0/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:37,844 [pool-4611-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis/793cb964-1b2d-41b4-96bf-87f9d58b43b0 has been successfully formatted.
2022-06-25 01:09:37,844 [pool-4611-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-87F9D58B43B0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:09:37,851 [IPC Server handler 17 on default port 36557] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONED, persistedOpStateExpiryEpochSec: 0} as the reported value does not match the value stored in SCM (IN_SERVICE, 0)
2022-06-25 01:09:37,852 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(358)) - Pipeline Pipeline[ Id: 793cb964-1b2d-41b4-96bf-87f9d58b43b0, Nodes: be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONED, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:be67eb5e-e62d-4374-a142-8db592db20d7, CreationTimestamp2022-06-25T01:09:36.689Z[Etc/UTC]] moved to OPEN state
2022-06-25 01:09:37,852 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:09:37,853 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:37,853 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:37,853 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:37,853 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:37,853 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:37,864 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:37,864 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:37,864 [pool-4611-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis/793cb964-1b2d-41b4-96bf-87f9d58b43b0
2022-06-25 01:09:37,864 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:09:37,864 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:09:37,864 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:37,865 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:09:37,865 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:37,865 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:37,865 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:37,865 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:37,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:37,875 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:09:37,907 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:37,907 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:09:37,907 [pool-4611-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:37,907 [pool-4611-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:37,912 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: addNew group-5F5BE5F6E354:[be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|priority:0] returns group-5F5BE5F6E354:java.util.concurrent.CompletableFuture@1b47475[Not completed]
2022-06-25 01:09:37,913 [pool-4145-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: new RaftServerImpl for group-5F5BE5F6E354:[be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|priority:0] with ContainerStateMachine:uninitialized
2022-06-25 01:09:37,913 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:09:37,913 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:09:37,913 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:37,913 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:37,913 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:37,913 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:37,913 [pool-4145-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354: ConfigurationManager, init=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|priority:0], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:37,913 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data/ratis] (custom)
2022-06-25 01:09:37,914 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:37,914 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:37,914 [pool-4145-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data/ratis/2b00854c-ae60-4259-8cdb-5f5be5f6e354 does not exist. Creating ...
2022-06-25 01:09:37,917 [pool-4145-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data/ratis/2b00854c-ae60-4259-8cdb-5f5be5f6e354/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:37,920 [pool-4145-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data/ratis/2b00854c-ae60-4259-8cdb-5f5be5f6e354 has been successfully formatted.
2022-06-25 01:09:37,926 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:37,926 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:09:37,926 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:09:37,926 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:09:37,926 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:09:37,926 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:37,931 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:37,931 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:37,931 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:37,932 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:37,932 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:37,932 [pool-4611-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0: start as a follower, conf=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:1], old=null
2022-06-25 01:09:37,932 [pool-4611-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:37,932 [pool-4611-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - be67eb5e-e62d-4374-a142-8db592db20d7: start be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-FollowerState
2022-06-25 01:09:37,951 [pool-4611-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-87F9D58B43B0,id=be67eb5e-e62d-4374-a142-8db592db20d7
2022-06-25 01:09:37,963 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=793cb964-1b2d-41b4-96bf-87f9d58b43b0
2022-06-25 01:09:37,963 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=793cb964-1b2d-41b4-96bf-87f9d58b43b0.
2022-06-25 01:09:37,963 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - be67eb5e-e62d-4374-a142-8db592db20d7: addNew group-5F5BE5F6E354:[be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|priority:0] returns group-5F5BE5F6E354:java.util.concurrent.CompletableFuture@544fff6a[Not completed]
2022-06-25 01:09:37,963 [pool-4145-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-5F5BE5F6E354: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:09:37,963 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:09:37,963 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:37,963 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:37,964 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:37,964 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:37,964 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:37,965 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:37,966 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:37,966 [pool-4145-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data/ratis/2b00854c-ae60-4259-8cdb-5f5be5f6e354
2022-06-25 01:09:37,966 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:09:37,966 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:09:37,966 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:37,966 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:09:37,966 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:37,966 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:37,979 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:37,979 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:37,967 [pool-4611-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - be67eb5e-e62d-4374-a142-8db592db20d7: new RaftServerImpl for group-5F5BE5F6E354:[be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|priority:0] with ContainerStateMachine:uninitialized
2022-06-25 01:09:37,985 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:09:37,985 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:09:37,985 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:37,985 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:37,985 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:37,985 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:37,985 [pool-4611-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354: ConfigurationManager, init=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|priority:0], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:37,986 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis] (custom)
2022-06-25 01:09:37,986 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:37,986 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:37,986 [pool-4611-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis/2b00854c-ae60-4259-8cdb-5f5be5f6e354 does not exist. Creating ...
2022-06-25 01:09:37,992 [pool-4611-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis/2b00854c-ae60-4259-8cdb-5f5be5f6e354/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:37,994 [pool-4611-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis/2b00854c-ae60-4259-8cdb-5f5be5f6e354 has been successfully formatted.
2022-06-25 01:09:37,994 [pool-4611-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-5F5BE5F6E354: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:09:37,995 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:09:37,995 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:37,995 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:37,995 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:37,995 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:37,995 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:38,017 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:38,095 [IPC Server handler 13 on default port 36557] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONED, persistedOpStateExpiryEpochSec: 0} as the reported value does not match the value stored in SCM (IN_SERVICE, 0)
2022-06-25 01:09:38,226 [IPC Server handler 5 on default port 44773] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/ec2664f4-d768-4745-9abe-ef2a305e3ce9
2022-06-25 01:09:38,226 [IPC Server handler 5 on default port 44773] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : ec2664f4-d768-4745-9abe-ef2a305e3ce9{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=40907, RATIS=41903, RATIS_ADMIN=41903, RATIS_SERVER=41903, STANDALONE=45557], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:09:38,230 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2022-06-25 01:09:38,230 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(275)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-06-25 01:09:38,230 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=8bbc5152-3491-4249-8acb-75abb1a65214 to datanode:ec2664f4-d768-4745-9abe-ef2a305e3ce9
2022-06-25 01:09:38,231 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 8bbc5152-3491-4249-8acb-75abb1a65214, Nodes: ec2664f4-d768-4745-9abe-ef2a305e3ce9{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=40907, RATIS=41903, RATIS_ADMIN=41903, RATIS_SERVER=41903, STANDALONE=45557], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-25T01:09:38.230Z[Etc/UTC]].
2022-06-25 01:09:38,307 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:09:38,308 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:38,308 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:09:38,308 [pool-4145-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:38,308 [pool-4145-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:38,309 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:38,309 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:38,309 [pool-4611-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis/2b00854c-ae60-4259-8cdb-5f5be5f6e354
2022-06-25 01:09:38,309 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:09:38,309 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:09:38,309 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:38,309 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:09:38,309 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:38,309 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:38,309 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:38,309 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:38,350 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:38,350 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:09:38,350 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:09:38,350 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:09:38,350 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:09:38,350 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:38,360 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:09:38,361 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:38,361 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:09:38,361 [pool-4611-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:38,361 [pool-4611-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:38,363 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:38,363 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:38,363 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:38,364 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:38,364 [pool-4145-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:38,364 [pool-4145-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354: start as a follower, conf=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|priority:0], old=null
2022-06-25 01:09:38,364 [pool-4145-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:38,377 [pool-4145-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: start 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-FollowerState
2022-06-25 01:09:38,377 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:38,377 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:09:38,377 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:09:38,377 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:09:38,378 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:09:38,378 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:38,382 [pool-4145-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5F5BE5F6E354,id=3c6128f4-7bf2-4a55-83fb-21add5186158
2022-06-25 01:09:38,390 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:38,391 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:38,391 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:38,391 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:38,391 [pool-4611-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:38,391 [pool-4611-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354: start as a follower, conf=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|priority:0], old=null
2022-06-25 01:09:38,391 [pool-4611-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:38,395 [pool-4611-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - be67eb5e-e62d-4374-a142-8db592db20d7: start be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-FollowerState
2022-06-25 01:09:38,395 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=2b00854c-ae60-4259-8cdb-5f5be5f6e354
2022-06-25 01:09:38,407 [grpc-default-executor-9] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: addNew group-5F5BE5F6E354:[be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:0] returns group-5F5BE5F6E354:java.util.concurrent.CompletableFuture@5ac47cae[Not completed]
2022-06-25 01:09:38,408 [pool-4122-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: new RaftServerImpl for group-5F5BE5F6E354:[be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:0] with ContainerStateMachine:uninitialized
2022-06-25 01:09:38,408 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:09:38,408 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:09:38,408 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:38,408 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:38,408 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:38,408 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:38,408 [pool-4122-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354: ConfigurationManager, init=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:38,409 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data/ratis] (custom)
2022-06-25 01:09:38,409 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:38,409 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:38,409 [pool-4122-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data/ratis/2b00854c-ae60-4259-8cdb-5f5be5f6e354 does not exist. Creating ...
2022-06-25 01:09:38,441 [pool-4122-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data/ratis/2b00854c-ae60-4259-8cdb-5f5be5f6e354/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:38,451 [pool-4611-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5F5BE5F6E354,id=be67eb5e-e62d-4374-a142-8db592db20d7
2022-06-25 01:09:38,456 [pool-4122-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data/ratis/2b00854c-ae60-4259-8cdb-5f5be5f6e354 has been successfully formatted.
2022-06-25 01:09:38,475 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=2b00854c-ae60-4259-8cdb-5f5be5f6e354
2022-06-25 01:09:38,527 [pool-4122-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-5F5BE5F6E354: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:09:38,601 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:09:38,601 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:38,601 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:38,601 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:38,601 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:38,602 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:38,617 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:38,617 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:38,617 [pool-4122-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data/ratis/2b00854c-ae60-4259-8cdb-5f5be5f6e354
2022-06-25 01:09:38,617 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:09:38,617 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:09:38,617 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:38,617 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:09:38,617 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:38,617 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:38,617 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:38,617 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:38,621 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:09:38,621 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:38,622 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:09:38,622 [pool-4122-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:38,622 [pool-4122-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:38,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:38,635 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:38,635 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:09:38,635 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:09:38,635 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:09:38,636 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:09:38,636 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:38,652 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:38,652 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:38,652 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:38,652 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:38,652 [pool-4122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:38,652 [pool-4122-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354: start as a follower, conf=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:0], old=null
2022-06-25 01:09:38,652 [pool-4122-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:38,652 [pool-4122-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: start 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354-FollowerState
2022-06-25 01:09:38,668 [pool-4122-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5F5BE5F6E354,id=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf
2022-06-25 01:09:38,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:38,920 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=2b00854c-ae60-4259-8cdb-5f5be5f6e354.
2022-06-25 01:09:39,005 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=2b00854c-ae60-4259-8cdb-5f5be5f6e354.
2022-06-25 01:09:39,018 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:39,213 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(460)) - Shutting down the Mini Ozone Cluster
2022-06-25 01:09:39,213 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(475)) - Stopping the Mini Ozone Cluster
2022-06-25 01:09:39,213 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(557)) - Stopping the OzoneManager
2022-06-25 01:09:39,213 [Mini-Cluster-Provider-Reap] INFO  om.OzoneManager (OzoneManager.java:stop(2020)) - om1[localhost:0]: Stopping Ozone Manager
2022-06-25 01:09:39,216 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3414)) - Stopping server on 35133
2022-06-25 01:09:39,254 [IPC Server handler 4 on default port 44773] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/ee118b23-09e5-41f4-9121-1170bcf86bc2
2022-06-25 01:09:39,254 [IPC Server handler 4 on default port 44773] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : ee118b23-09e5-41f4-9121-1170bcf86bc2{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=36173, RATIS=39807, RATIS_ADMIN=39807, RATIS_SERVER=39807, STANDALONE=36851], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:09:39,255 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(275)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-06-25 01:09:39,261 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=2062d5a7-3c35-4dd5-8ec9-3bb803b7d89d to datanode:ee118b23-09e5-41f4-9121-1170bcf86bc2
2022-06-25 01:09:39,262 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 2062d5a7-3c35-4dd5-8ec9-3bb803b7d89d, Nodes: ee118b23-09e5-41f4-9121-1170bcf86bc2{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=36173, RATIS=39807, RATIS_ADMIN=39807, RATIS_SERVER=39807, STANDALONE=36851], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-25T01:09:39.261Z[Etc/UTC]].
2022-06-25 01:09:39,286 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2022-06-25 01:09:39,286 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - DataNodeSafeModeRule rule is successfully validated
2022-06-25 01:09:39,286 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(233)) - All SCM safe mode pre check rules have passed
2022-06-25 01:09:39,286 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2022-06-25 01:09:39,286 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2022-06-25 01:09:39,286 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(275)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-06-25 01:09:39,302 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1376)) - Stopping IPC Server listener on 0
2022-06-25 01:09:39,317 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - Stopping IPC Server Responder
2022-06-25 01:09:39,360 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=4f5bb74b-936b-4e65-b29c-c104fb0cbee5 to datanode:ec2664f4-d768-4745-9abe-ef2a305e3ce9
2022-06-25 01:09:39,361 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=4f5bb74b-936b-4e65-b29c-c104fb0cbee5 to datanode:ee118b23-09e5-41f4-9121-1170bcf86bc2
2022-06-25 01:09:39,361 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=4f5bb74b-936b-4e65-b29c-c104fb0cbee5 to datanode:f368a730-3857-4d18-b0ff-e0c952296109
2022-06-25 01:09:39,361 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$7(398)) - om1: close
2022-06-25 01:09:39,361 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 4f5bb74b-936b-4e65-b29c-c104fb0cbee5, Nodes: ec2664f4-d768-4745-9abe-ef2a305e3ce9{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=40907, RATIS=41903, RATIS_ADMIN=41903, RATIS_SERVER=41903, STANDALONE=45557], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}ee118b23-09e5-41f4-9121-1170bcf86bc2{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=36173, RATIS=39807, RATIS_ADMIN=39807, RATIS_SERVER=39807, STANDALONE=36851], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f368a730-3857-4d18-b0ff-e0c952296109{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=36553, RATIS=46119, RATIS_ADMIN=46119, RATIS_SERVER=46119, STANDALONE=36013], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-25T01:09:39.360Z[Etc/UTC]].
2022-06-25 01:09:39,455 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - om1@group-C5BA1605619E: shutdown
2022-06-25 01:09:39,455 [Mini-Cluster-Provider-Reap] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2022-06-25 01:09:39,455 [Mini-Cluster-Provider-Reap] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - om1: shutdown om1@group-C5BA1605619E-LeaderStateImpl
2022-06-25 01:09:39,455 [Mini-Cluster-Provider-Reap] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - om1@group-C5BA1605619E-PendingRequests: sendNotLeaderResponses
2022-06-25 01:09:39,473 [Mini-Cluster-Provider-Reap] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - om1@group-C5BA1605619E-StateMachineUpdater: set stopIndex = 84
2022-06-25 01:09:39,489 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(441)) - Current Snapshot Index (t:1, i:84)
2022-06-25 01:09:39,489 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - om1@group-C5BA1605619E-StateMachineUpdater: Took a snapshot at index 84
2022-06-25 01:09:39,489 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - om1@group-C5BA1605619E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 84
2022-06-25 01:09:39,489 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(495)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2022-06-25 01:09:39,489 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(465)) - Stopping OMDoubleBuffer flush thread
2022-06-25 01:09:39,489 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(385)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit.
2022-06-25 01:09:39,510 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (ServerState.java:close(429)) - om1@group-C5BA1605619E: closes. applyIndex: 84
2022-06-25 01:09:39,511 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-25 01:09:39,511 [Mini-Cluster-Provider-Reap] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker close()
2022-06-25 01:09:39,512 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(269)) - om1: shutdown server with port 41635 now
2022-06-25 01:09:39,512 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(278)) - om1: shutdown server with port 41635 successfully
2022-06-25 01:09:39,512 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@59be0973] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-om1: Stopped
2022-06-25 01:09:39,513 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(495)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2022-06-25 01:09:39,513 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(477)) - OMDoubleBuffer flush thread is not running.
2022-06-25 01:09:39,513 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service KeyDeletingService
2022-06-25 01:09:39,534 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service DirectoryDeletingService
2022-06-25 01:09:39,547 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service OpenKeyCleanupService
2022-06-25 01:09:39,603 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@1387d972{ozoneManager,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2022-06-25 01:09:39,603 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@6d997b5a{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-06-25 01:09:39,604 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-06-25 01:09:39,605 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@3ffe6ccd{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2022-06-25 01:09:39,607 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(309)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-3/data-0/containers/hdds/e228e9f1-8cea-4b31-8b4b-3b149b9026ba/DS-a0958fe5-d3e2-4cbc-b800-29006d9fa262/container.db for volume DS-a0958fe5-d3e2-4cbc-b800-29006d9fa262
2022-06-25 01:09:39,608 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(340)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-3/data-0/containers/hdds/e228e9f1-8cea-4b31-8b4b-3b149b9026ba/DS-a0958fe5-d3e2-4cbc-b800-29006d9fa262/container.db for volume DS-a0958fe5-d3e2-4cbc-b800-29006d9fa262
2022-06-25 01:09:39,608 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(344)) - Attempting to start container services.
2022-06-25 01:09:39,608 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(279)) - Background container scanner has been disabled.
2022-06-25 01:09:39,609 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@7e2d6cc7{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-06-25 01:09:39,609 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 38035
2022-06-25 01:09:39,617 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis d233dd63-6533-4977-8487-4fe644b19e51
2022-06-25 01:09:39,620 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - d233dd63-6533-4977-8487-4fe644b19e51: start RPC server
2022-06-25 01:09:39,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:39,627 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - d233dd63-6533-4977-8487-4fe644b19e51: GrpcService started, listening on 43619
2022-06-25 01:09:39,630 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis d233dd63-6533-4977-8487-4fe644b19e51 is started using port 43619 for RATIS
2022-06-25 01:09:39,630 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis d233dd63-6533-4977-8487-4fe644b19e51 is started using port 43619 for RATIS_ADMIN
2022-06-25 01:09:39,630 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis d233dd63-6533-4977-8487-4fe644b19e51 is started using port 43619 for RATIS_SERVER
2022-06-25 01:09:39,632 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc d233dd63-6533-4977-8487-4fe644b19e51 is started using port 45827
2022-06-25 01:09:39,688 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@63de0485] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-d233dd63-6533-4977-8487-4fe644b19e51: Started
2022-06-25 01:09:39,755 [Listener at 127.0.0.1/44435] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@35497be2{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-36011-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-5879620444291960606/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-25 01:09:39,779 [Listener at 127.0.0.1/44435] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@6b8b5819{HTTP/1.1, (http/1.1)}{0.0.0.0:36011}
2022-06-25 01:09:39,780 [Listener at 127.0.0.1/44435] INFO  server.Server (Server.java:doStart(415)) - Started @413676ms
2022-06-25 01:09:39,780 [Listener at 127.0.0.1/44435] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-06-25 01:09:39,782 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(534)) - Stopping the HddsDatanodes
2022-06-25 01:09:39,858 [Listener at 127.0.0.1/44435] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:36011
2022-06-25 01:09:39,867 [Listener at 127.0.0.1/44435] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:39,867 [Listener at 127.0.0.1/44435] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2022-06-25 01:09:39,867 [Listener at 127.0.0.1/44435] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2022-06-25 01:09:39,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:39,875 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(492)) - Ozone container server started.
2022-06-25 01:09:39,879 [Listener at 127.0.0.1/44435] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(236)) - HddsDatanodeService host:fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net ip:10.1.0.8
2022-06-25 01:09:39,939 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4665e9cf] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-06-25 01:09:39,940 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-4/meta/datanode.id
2022-06-25 01:09:40,002 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - f368a730-3857-4d18-b0ff-e0c952296109: addNew group-689FA3209105:[f368a730-3857-4d18-b0ff-e0c952296109|rpc:10.1.0.8:46119|priority:1] returns group-689FA3209105:java.util.concurrent.CompletableFuture@23cc2c9c[Not completed]
2022-06-25 01:09:40,007 [pool-4658-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - f368a730-3857-4d18-b0ff-e0c952296109: new RaftServerImpl for group-689FA3209105:[f368a730-3857-4d18-b0ff-e0c952296109|rpc:10.1.0.8:46119|priority:1] with ContainerStateMachine:uninitialized
2022-06-25 01:09:40,008 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:09:40,008 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:09:40,008 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:40,008 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:40,008 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:40,008 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:40,008 [pool-4658-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105: ConfigurationManager, init=-1: [f368a730-3857-4d18-b0ff-e0c952296109|rpc:10.1.0.8:46119|priority:1], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:40,008 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-0/data/ratis] (custom)
2022-06-25 01:09:40,008 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:40,008 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:40,008 [pool-4658-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-0/data/ratis/8119f22a-7f75-41f6-8378-689fa3209105 does not exist. Creating ...
2022-06-25 01:09:40,009 [Listener at 127.0.0.1/44435] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(82)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2022-06-25 01:09:40,014 [pool-4658-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-0/data/ratis/8119f22a-7f75-41f6-8378-689fa3209105/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:40,019 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleOverReplicatedContainer(1249)) - Container #1 is over replicated. Expected replica count is 3, but found 4.
2022-06-25 01:09:40,019 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendDeleteCommand(1583)) - Sending delete container command for container #1 to datanode 97d08340-a146-41c4-a759-b3b136c7fb6d{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=37711, RATIS=43169, RATIS_ADMIN=43169, RATIS_SERVER=43169, STANDALONE=44433], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:09:40,020 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleOverReplicatedContainer(1249)) - Container #2 is over replicated. Expected replica count is 3, but found 4.
2022-06-25 01:09:40,020 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendDeleteCommand(1583)) - Sending delete container command for container #2 to datanode 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43029, RATIS=44897, RATIS_ADMIN=44897, RATIS_SERVER=44897, STANDALONE=37333], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:09:40,020 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleOverReplicatedContainer(1249)) - Container #3 is over replicated. Expected replica count is 3, but found 4.
2022-06-25 01:09:40,020 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendDeleteCommand(1583)) - Sending delete container command for container #3 to datanode fc692a40-1ae9-40b7-8d63-7e46f51df1ef{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=40691, RATIS=39343, RATIS_ADMIN=39343, RATIS_SERVER=39343, STANDALONE=32859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:09:40,020 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-06-25 01:09:40,135 [pool-4658-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-0/data/ratis/8119f22a-7f75-41f6-8378-689fa3209105 has been successfully formatted.
2022-06-25 01:09:40,136 [pool-4658-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-689FA3209105: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:09:40,136 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:09:40,136 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:40,136 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:40,136 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:40,136 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:40,136 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:40,138 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:40,138 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:40,138 [pool-4658-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-0/data/ratis/8119f22a-7f75-41f6-8378-689fa3209105
2022-06-25 01:09:40,138 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:09:40,138 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:09:40,138 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:40,138 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:09:40,139 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:40,139 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:40,139 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:40,139 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:40,140 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(358)) - Pipeline Pipeline[ Id: 8119f22a-7f75-41f6-8378-689fa3209105, Nodes: f368a730-3857-4d18-b0ff-e0c952296109{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=36553, RATIS=46119, RATIS_ADMIN=46119, RATIS_SERVER=46119, STANDALONE=36013], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:f368a730-3857-4d18-b0ff-e0c952296109, CreationTimestamp2022-06-25T01:09:37.329Z[Etc/UTC]] moved to OPEN state
2022-06-25 01:09:40,190 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:40,205 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:09:40,205 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:40,205 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:09:40,206 [pool-4658-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:40,206 [pool-4658-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:40,211 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:40,211 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:09:40,212 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:09:40,212 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:09:40,212 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:09:40,212 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:40,217 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:40,217 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:40,218 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:40,218 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:40,218 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:40,218 [pool-4658-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105: start as a follower, conf=-1: [f368a730-3857-4d18-b0ff-e0c952296109|rpc:10.1.0.8:46119|priority:1], old=null
2022-06-25 01:09:40,218 [pool-4658-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:40,218 [pool-4658-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - f368a730-3857-4d18-b0ff-e0c952296109: start f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-FollowerState
2022-06-25 01:09:40,218 [pool-4658-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-689FA3209105,id=f368a730-3857-4d18-b0ff-e0c952296109
2022-06-25 01:09:40,245 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=8119f22a-7f75-41f6-8378-689fa3209105
2022-06-25 01:09:40,245 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=8119f22a-7f75-41f6-8378-689fa3209105.
2022-06-25 01:09:40,245 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - f368a730-3857-4d18-b0ff-e0c952296109: addNew group-C104FB0CBEE5:[f368a730-3857-4d18-b0ff-e0c952296109|rpc:10.1.0.8:46119|priority:1, ee118b23-09e5-41f4-9121-1170bcf86bc2|rpc:10.1.0.8:39807|priority:0, ec2664f4-d768-4745-9abe-ef2a305e3ce9|rpc:10.1.0.8:41903|priority:0] returns group-C104FB0CBEE5:java.util.concurrent.CompletableFuture@27f3ac3d[Not completed]
2022-06-25 01:09:40,248 [pool-4658-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - f368a730-3857-4d18-b0ff-e0c952296109: new RaftServerImpl for group-C104FB0CBEE5:[f368a730-3857-4d18-b0ff-e0c952296109|rpc:10.1.0.8:46119|priority:1, ee118b23-09e5-41f4-9121-1170bcf86bc2|rpc:10.1.0.8:39807|priority:0, ec2664f4-d768-4745-9abe-ef2a305e3ce9|rpc:10.1.0.8:41903|priority:0] with ContainerStateMachine:uninitialized
2022-06-25 01:09:40,249 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:09:40,249 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:09:40,249 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:40,249 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:40,249 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:40,249 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:40,249 [pool-4658-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5: ConfigurationManager, init=-1: [f368a730-3857-4d18-b0ff-e0c952296109|rpc:10.1.0.8:46119|priority:1, ee118b23-09e5-41f4-9121-1170bcf86bc2|rpc:10.1.0.8:39807|priority:0, ec2664f4-d768-4745-9abe-ef2a305e3ce9|rpc:10.1.0.8:41903|priority:0], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:40,249 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-0/data/ratis] (custom)
2022-06-25 01:09:40,249 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:40,249 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:40,249 [pool-4658-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-0/data/ratis/4f5bb74b-936b-4e65-b29c-c104fb0cbee5 does not exist. Creating ...
2022-06-25 01:09:40,254 [pool-4658-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-0/data/ratis/4f5bb74b-936b-4e65-b29c-c104fb0cbee5/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:40,260 [pool-4658-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-0/data/ratis/4f5bb74b-936b-4e65-b29c-c104fb0cbee5 has been successfully formatted.
2022-06-25 01:09:40,260 [pool-4658-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-C104FB0CBEE5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:09:40,261 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:09:40,261 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:40,261 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:40,261 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:40,261 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:40,261 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:40,268 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:40,268 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:40,268 [pool-4658-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-0/data/ratis/4f5bb74b-936b-4e65-b29c-c104fb0cbee5
2022-06-25 01:09:40,268 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:09:40,268 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:09:40,268 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:40,268 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:09:40,268 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:40,268 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:40,268 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:40,268 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:40,274 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:40,323 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:09:40,327 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:40,327 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:09:40,327 [pool-4658-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:40,328 [pool-4658-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:40,344 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:40,344 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:09:40,344 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:09:40,344 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:09:40,344 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:09:40,344 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:40,350 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:40,350 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:40,350 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:40,350 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:40,350 [pool-4658-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:40,350 [pool-4658-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5: start as a follower, conf=-1: [f368a730-3857-4d18-b0ff-e0c952296109|rpc:10.1.0.8:46119|priority:1, ee118b23-09e5-41f4-9121-1170bcf86bc2|rpc:10.1.0.8:39807|priority:0, ec2664f4-d768-4745-9abe-ef2a305e3ce9|rpc:10.1.0.8:41903|priority:0], old=null
2022-06-25 01:09:40,350 [pool-4658-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:40,350 [pool-4658-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - f368a730-3857-4d18-b0ff-e0c952296109: start f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-FollowerState
2022-06-25 01:09:40,374 [pool-4658-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C104FB0CBEE5,id=f368a730-3857-4d18-b0ff-e0c952296109
2022-06-25 01:09:40,376 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=4f5bb74b-936b-4e65-b29c-c104fb0cbee5
2022-06-25 01:09:40,409 [grpc-default-executor-9] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9: addNew group-C104FB0CBEE5:[f368a730-3857-4d18-b0ff-e0c952296109|rpc:10.1.0.8:46119|dataStream:|priority:1, ee118b23-09e5-41f4-9121-1170bcf86bc2|rpc:10.1.0.8:39807|dataStream:|priority:0, ec2664f4-d768-4745-9abe-ef2a305e3ce9|rpc:10.1.0.8:41903|dataStream:|priority:0] returns group-C104FB0CBEE5:java.util.concurrent.CompletableFuture@e7a6a62[Not completed]
2022-06-25 01:09:40,410 [pool-4681-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9: new RaftServerImpl for group-C104FB0CBEE5:[f368a730-3857-4d18-b0ff-e0c952296109|rpc:10.1.0.8:46119|dataStream:|priority:1, ee118b23-09e5-41f4-9121-1170bcf86bc2|rpc:10.1.0.8:39807|dataStream:|priority:0, ec2664f4-d768-4745-9abe-ef2a305e3ce9|rpc:10.1.0.8:41903|dataStream:|priority:0] with ContainerStateMachine:uninitialized
2022-06-25 01:09:40,410 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:09:40,410 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:09:40,410 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:40,410 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:40,410 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:40,410 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:40,411 [pool-4681-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5: ConfigurationManager, init=-1: [f368a730-3857-4d18-b0ff-e0c952296109|rpc:10.1.0.8:46119|dataStream:|priority:1, ee118b23-09e5-41f4-9121-1170bcf86bc2|rpc:10.1.0.8:39807|dataStream:|priority:0, ec2664f4-d768-4745-9abe-ef2a305e3ce9|rpc:10.1.0.8:41903|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:40,411 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-1/data/ratis] (custom)
2022-06-25 01:09:40,411 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:40,411 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:40,411 [pool-4681-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-1/data/ratis/4f5bb74b-936b-4e65-b29c-c104fb0cbee5 does not exist. Creating ...
2022-06-25 01:09:40,414 [pool-4681-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-1/data/ratis/4f5bb74b-936b-4e65-b29c-c104fb0cbee5/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:40,426 [pool-4681-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-1/data/ratis/4f5bb74b-936b-4e65-b29c-c104fb0cbee5 has been successfully formatted.
2022-06-25 01:09:40,426 [pool-4681-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-C104FB0CBEE5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:09:40,426 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:09:40,427 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:40,427 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:40,427 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:40,427 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:40,427 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:40,429 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:40,429 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:40,429 [pool-4681-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-1/data/ratis/4f5bb74b-936b-4e65-b29c-c104fb0cbee5
2022-06-25 01:09:40,429 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:09:40,430 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:09:40,430 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:40,430 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:09:40,430 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:40,430 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:40,430 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:40,430 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:40,475 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:09:40,486 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:40,486 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:09:40,486 [pool-4681-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:40,486 [pool-4681-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:40,487 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:40,487 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:09:40,487 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:09:40,487 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:09:40,487 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:09:40,487 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:40,492 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:40,492 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:40,492 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:40,492 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:40,492 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:40,493 [pool-4681-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5: start as a follower, conf=-1: [f368a730-3857-4d18-b0ff-e0c952296109|rpc:10.1.0.8:46119|dataStream:|priority:1, ee118b23-09e5-41f4-9121-1170bcf86bc2|rpc:10.1.0.8:39807|dataStream:|priority:0, ec2664f4-d768-4745-9abe-ef2a305e3ce9|rpc:10.1.0.8:41903|dataStream:|priority:0], old=null
2022-06-25 01:09:40,493 [pool-4681-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:40,493 [pool-4681-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9: start ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5-FollowerState
2022-06-25 01:09:40,508 [pool-4681-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C104FB0CBEE5,id=ec2664f4-d768-4745-9abe-ef2a305e3ce9
2022-06-25 01:09:40,620 [grpc-default-executor-9] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - ee118b23-09e5-41f4-9121-1170bcf86bc2: addNew group-C104FB0CBEE5:[f368a730-3857-4d18-b0ff-e0c952296109|rpc:10.1.0.8:46119|dataStream:|priority:1, ee118b23-09e5-41f4-9121-1170bcf86bc2|rpc:10.1.0.8:39807|dataStream:|priority:0, ec2664f4-d768-4745-9abe-ef2a305e3ce9|rpc:10.1.0.8:41903|dataStream:|priority:0] returns group-C104FB0CBEE5:java.util.concurrent.CompletableFuture@65ed541[Not completed]
2022-06-25 01:09:40,682 [Listener at 127.0.0.1/44435] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 672 ms to scan 7 urls, producing 131 keys and 316 values 
2022-06-25 01:09:40,683 [Listener at 127.0.0.1/44435] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(237)) - Datanode State Machine Task Thread Pool size 2
2022-06-25 01:09:40,695 [Listener at 127.0.0.1/44435] INFO  volume.HddsVolume (HddsVolume.java:<init>(116)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-5/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2022-06-25 01:09:40,696 [Listener at 127.0.0.1/44435] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-5/data-0/containers/hdds to VolumeSet
2022-06-25 01:09:40,696 [Listener at 127.0.0.1/44435] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-5/data-0/containers/hdds
2022-06-25 01:09:40,698 [Listener at 127.0.0.1/44435] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-5/data-0/containers/hdds
2022-06-25 01:09:40,709 [Listener at 127.0.0.1/44435] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-5/data/ratis to VolumeSet
2022-06-25 01:09:40,709 [Listener at 127.0.0.1/44435] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-5/data/ratis
2022-06-25 01:09:40,710 [Listener at 127.0.0.1/44435] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-5/data/ratis
2022-06-25 01:09:40,754 [pool-4704-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - ee118b23-09e5-41f4-9121-1170bcf86bc2: new RaftServerImpl for group-C104FB0CBEE5:[f368a730-3857-4d18-b0ff-e0c952296109|rpc:10.1.0.8:46119|dataStream:|priority:1, ee118b23-09e5-41f4-9121-1170bcf86bc2|rpc:10.1.0.8:39807|dataStream:|priority:0, ec2664f4-d768-4745-9abe-ef2a305e3ce9|rpc:10.1.0.8:41903|dataStream:|priority:0] with ContainerStateMachine:uninitialized
2022-06-25 01:09:40,754 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:09:40,754 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:09:40,754 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:40,754 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:40,754 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:40,754 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:40,754 [pool-4704-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-C104FB0CBEE5: ConfigurationManager, init=-1: [f368a730-3857-4d18-b0ff-e0c952296109|rpc:10.1.0.8:46119|dataStream:|priority:1, ee118b23-09e5-41f4-9121-1170bcf86bc2|rpc:10.1.0.8:39807|dataStream:|priority:0, ec2664f4-d768-4745-9abe-ef2a305e3ce9|rpc:10.1.0.8:41903|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:40,754 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-2/data/ratis] (custom)
2022-06-25 01:09:40,754 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:40,754 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:40,754 [pool-4704-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-2/data/ratis/4f5bb74b-936b-4e65-b29c-c104fb0cbee5 does not exist. Creating ...
2022-06-25 01:09:40,755 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:40,756 [pool-4704-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-2/data/ratis/4f5bb74b-936b-4e65-b29c-c104fb0cbee5/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:40,757 [pool-4704-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-2/data/ratis/4f5bb74b-936b-4e65-b29c-c104fb0cbee5 has been successfully formatted.
2022-06-25 01:09:40,764 [Thread-6618] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(172)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-5/data-0/containers/hdds
2022-06-25 01:09:40,765 [Listener at 127.0.0.1/44435] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(266)) - Build ContainerSet costs 0s
2022-06-25 01:09:40,766 [Listener at 127.0.0.1/44435] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2022-06-25 01:09:40,766 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(48)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2022-06-25 01:09:40,766 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2022-06-25 01:09:40,766 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2022-06-25 01:09:40,766 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2022-06-25 01:09:40,767 [Listener at 127.0.0.1/44435] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2022-06-25 01:09:40,767 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:40,767 [Listener at 127.0.0.1/44435] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2022-06-25 01:09:40,767 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:09:40,767 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2022-06-25 01:09:40,767 [Listener at 127.0.0.1/44435] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2022-06-25 01:09:40,768 [Listener at 127.0.0.1/44435] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2022-06-25 01:09:40,768 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2022-06-25 01:09:40,768 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2022-06-25 01:09:40,768 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:40,769 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:40,769 [Listener at 127.0.0.1/44435] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-5/data/ratis] (custom)
2022-06-25 01:09:40,773 [pool-4704-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-C104FB0CBEE5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:09:40,774 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:09:40,774 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:40,774 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:40,774 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:40,774 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:40,780 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:40,782 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:40,782 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:40,782 [pool-4704-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new ee118b23-09e5-41f4-9121-1170bcf86bc2@group-C104FB0CBEE5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-2/data/ratis/4f5bb74b-936b-4e65-b29c-c104fb0cbee5
2022-06-25 01:09:40,782 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:09:40,782 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:09:40,782 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:40,782 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:09:40,782 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:40,782 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:40,782 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:40,782 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:40,788 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:09:40,788 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:40,788 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:09:40,788 [pool-4704-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-C104FB0CBEE5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:40,788 [pool-4704-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-C104FB0CBEE5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:40,791 [Listener at 127.0.0.1/44435] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2022-06-25 01:09:40,792 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:40,792 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:09:40,792 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:09:40,792 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:09:40,792 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:09:40,792 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:40,797 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:40,797 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:40,797 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:40,797 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:40,797 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:40,798 [pool-4704-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-C104FB0CBEE5: start as a follower, conf=-1: [f368a730-3857-4d18-b0ff-e0c952296109|rpc:10.1.0.8:46119|dataStream:|priority:1, ee118b23-09e5-41f4-9121-1170bcf86bc2|rpc:10.1.0.8:39807|dataStream:|priority:0, ec2664f4-d768-4745-9abe-ef2a305e3ce9|rpc:10.1.0.8:41903|dataStream:|priority:0], old=null
2022-06-25 01:09:40,798 [pool-4704-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-C104FB0CBEE5: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:40,823 [pool-4704-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ee118b23-09e5-41f4-9121-1170bcf86bc2: start ee118b23-09e5-41f4-9121-1170bcf86bc2@group-C104FB0CBEE5-FollowerState
2022-06-25 01:09:40,825 [pool-4704-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C104FB0CBEE5,id=ee118b23-09e5-41f4-9121-1170bcf86bc2
2022-06-25 01:09:40,873 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:40,874 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=4f5bb74b-936b-4e65-b29c-c104fb0cbee5.
2022-06-25 01:09:40,925 [Listener at 127.0.0.1/44435] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(209)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2022-06-25 01:09:40,925 [Listener at 127.0.0.1/44435] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2022-06-25 01:09:40,931 [Listener at 127.0.0.1/44435] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-06-25 01:09:40,950 [Listener at 127.0.0.1/44435] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2022-06-25 01:09:40,951 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1029)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2022-06-25 01:09:40,951 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1005)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2022-06-25 01:09:40,952 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-06-25 01:09:40,952 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1013)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-06-25 01:09:40,952 [Listener at 127.0.0.1/44435] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1248)) - Jetty bound to port 35579
2022-06-25 01:09:40,952 [Listener at 127.0.0.1/44435] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_332-b09
2022-06-25 01:09:40,977 [Listener at 127.0.0.1/44435] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2022-06-25 01:09:40,977 [Listener at 127.0.0.1/44435] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2022-06-25 01:09:40,977 [Listener at 127.0.0.1/44435] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2022-06-25 01:09:40,978 [Listener at 127.0.0.1/44435] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@51461687{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2022-06-25 01:09:40,978 [Listener at 127.0.0.1/44435] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.s.ServletContextHandler@412e9b74{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2022-06-25 01:09:40,986 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(365)) - Attempting to stop container services.
2022-06-25 01:09:40,987 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$7(398)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: close
2022-06-25 01:09:40,987 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C: shutdown
2022-06-25 01:09:40,987 [Mini-Cluster-Provider-Reap] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-23927ECA553C,id=fc692a40-1ae9-40b7-8d63-7e46f51df1ef
2022-06-25 01:09:40,987 [Mini-Cluster-Provider-Reap] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: shutdown fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-LeaderStateImpl
2022-06-25 01:09:40,987 [Mini-Cluster-Provider-Reap] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-PendingRequests: sendNotLeaderResponses
2022-06-25 01:09:40,989 [Mini-Cluster-Provider-Reap] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-StateMachineUpdater: set stopIndex = 0
2022-06-25 01:09:40,990 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-23927ECA553C: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/data/ratis/a58b823e-be03-49ee-a4ae-23927eca553c/sm/snapshot.1_0
2022-06-25 01:09:40,994 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-23927ECA553C: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/data/ratis/a58b823e-be03-49ee-a4ae-23927eca553c/sm/snapshot.1_0 took: 4 ms
2022-06-25 01:09:40,994 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-StateMachineUpdater: Took a snapshot at index 0
2022-06-25 01:09:40,994 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-06-25 01:09:40,994 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (ServerState.java:close(429)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C: closes. applyIndex: 0
2022-06-25 01:09:40,995 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-25 01:09:40,995 [Mini-Cluster-Provider-Reap] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-23927ECA553C-SegmentedRaftLogWorker close()
2022-06-25 01:09:40,998 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: shutdown
2022-06-25 01:09:41,002 [Mini-Cluster-Provider-Reap] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B6B9DF3CEF32,id=fc692a40-1ae9-40b7-8d63-7e46f51df1ef
2022-06-25 01:09:41,002 [Mini-Cluster-Provider-Reap] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: shutdown fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:41,003 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-FollowerState was interrupted
2022-06-25 01:09:41,004 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-B6B9DF3CEF32: Taking a snapshot at:(t:8, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/data/ratis/1a613b2a-b322-4f7f-932c-b6b9df3cef32/sm/snapshot.8_0
2022-06-25 01:09:41,004 [Mini-Cluster-Provider-Reap] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-StateMachineUpdater: set stopIndex = 0
2022-06-25 01:09:41,005 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-B6B9DF3CEF32: Finished taking a snapshot at:(t:8, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-3/data/ratis/1a613b2a-b322-4f7f-932c-b6b9df3cef32/sm/snapshot.8_0 took: 1 ms
2022-06-25 01:09:41,005 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-StateMachineUpdater: Took a snapshot at index 0
2022-06-25 01:09:41,005 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-06-25 01:09:41,020 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:41,027 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (ServerState.java:close(429)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32: closes. applyIndex: 0
2022-06-25 01:09:41,028 [fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-25 01:09:41,038 [Mini-Cluster-Provider-Reap] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef@group-B6B9DF3CEF32-SegmentedRaftLogWorker close()
2022-06-25 01:09:41,039 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(269)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: shutdown server with port 39343 now
2022-06-25 01:09:41,119 [grpc-default-executor-6] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: installSnapshot onError, lastRequest: 97d08340-a146-41c4-a759-b3b136c7fb6d->fc692a40-1ae9-40b7-8d63-7e46f51df1ef#1-t8,previous=(t:0, i:0),leaderCommit=0,initializing? true,entries: size=1, first=(t:8, i:0), CONFIGURATIONENTRY: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2022-06-25 01:09:41,123 [grpc-default-executor-10] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32->fc692a40-1ae9-40b7-8d63-7e46f51df1ef-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2022-06-25 01:09:41,123 [grpc-default-executor-10] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(111)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32->fc692a40-1ae9-40b7-8d63-7e46f51df1ef-GrpcLogAppender: Leader has not got in touch with Follower 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32->fc692a40-1ae9-40b7-8d63-7e46f51df1ef(c0,m0,n1, attendVote=true, lastRpcSendTime=381, lastRpcResponseTime=363) yet, just keep nextIndex unchanged and retry.
2022-06-25 01:09:41,145 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(278)) - fc692a40-1ae9-40b7-8d63-7e46f51df1ef: shutdown server with port 39343 successfully
2022-06-25 01:09:41,145 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@58e06509] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-fc692a40-1ae9-40b7-8d63-7e46f51df1ef: Stopped
2022-06-25 01:09:41,230 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9: addNew group-75ABB1A65214:[ec2664f4-d768-4745-9abe-ef2a305e3ce9|rpc:10.1.0.8:41903|priority:1] returns group-75ABB1A65214:java.util.concurrent.CompletableFuture@614d55d6[Not completed]
2022-06-25 01:09:41,231 [pool-4681-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9: new RaftServerImpl for group-75ABB1A65214:[ec2664f4-d768-4745-9abe-ef2a305e3ce9|rpc:10.1.0.8:41903|priority:1] with ContainerStateMachine:uninitialized
2022-06-25 01:09:41,231 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:09:41,231 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:09:41,231 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:41,231 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:41,231 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:41,231 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:41,231 [pool-4681-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214: ConfigurationManager, init=-1: [ec2664f4-d768-4745-9abe-ef2a305e3ce9|rpc:10.1.0.8:41903|priority:1], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:41,231 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-1/data/ratis] (custom)
2022-06-25 01:09:41,231 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:41,231 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:41,232 [pool-4681-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-1/data/ratis/8bbc5152-3491-4249-8acb-75abb1a65214 does not exist. Creating ...
2022-06-25 01:09:41,246 [pool-4681-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-1/data/ratis/8bbc5152-3491-4249-8acb-75abb1a65214/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:41,251 [pool-4681-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-1/data/ratis/8bbc5152-3491-4249-8acb-75abb1a65214 has been successfully formatted.
2022-06-25 01:09:41,251 [pool-4681-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-75ABB1A65214: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:09:41,251 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:09:41,251 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:41,251 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:41,251 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:41,251 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:41,252 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:41,255 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(358)) - Pipeline Pipeline[ Id: 8bbc5152-3491-4249-8acb-75abb1a65214, Nodes: ec2664f4-d768-4745-9abe-ef2a305e3ce9{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=40907, RATIS=41903, RATIS_ADMIN=41903, RATIS_SERVER=41903, STANDALONE=45557], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:ec2664f4-d768-4745-9abe-ef2a305e3ce9, CreationTimestamp2022-06-25T01:09:38.230Z[Etc/UTC]] moved to OPEN state
2022-06-25 01:09:41,255 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:41,260 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:41,270 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:41,270 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:41,270 [pool-4681-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-1/data/ratis/8bbc5152-3491-4249-8acb-75abb1a65214
2022-06-25 01:09:41,271 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:09:41,271 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:09:41,271 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:41,271 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:09:41,271 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:41,271 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:41,271 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:41,271 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:41,319 [IPC Server handler 1 on default port 44773] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/d233dd63-6533-4977-8487-4fe644b19e51
2022-06-25 01:09:41,319 [IPC Server handler 1 on default port 44773] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : d233dd63-6533-4977-8487-4fe644b19e51{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=38035, RATIS=43619, RATIS_ADMIN=43619, RATIS_SERVER=43619, STANDALONE=45827], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:09:41,319 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(275)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-06-25 01:09:41,320 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=f2ef78ee-d67e-486b-bc60-ad647eb92d8e to datanode:d233dd63-6533-4977-8487-4fe644b19e51
2022-06-25 01:09:41,320 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: f2ef78ee-d67e-486b-bc60-ad647eb92d8e, Nodes: d233dd63-6533-4977-8487-4fe644b19e51{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=38035, RATIS=43619, RATIS_ADMIN=43619, RATIS_SERVER=43619, STANDALONE=45827], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-25T01:09:41.320Z[Etc/UTC]].
2022-06-25 01:09:41,359 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:09:41,360 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:41,361 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:09:41,361 [pool-4681-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:41,361 [pool-4681-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:41,408 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:41,408 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:09:41,408 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:09:41,409 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:09:41,409 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:09:41,409 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:41,422 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:41,422 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:41,422 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:41,422 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:41,422 [pool-4681-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:41,422 [pool-4681-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214: start as a follower, conf=-1: [ec2664f4-d768-4745-9abe-ef2a305e3ce9|rpc:10.1.0.8:41903|priority:1], old=null
2022-06-25 01:09:41,428 [pool-4681-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:41,429 [pool-4681-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9: start ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-FollowerState
2022-06-25 01:09:41,438 [pool-4681-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-75ABB1A65214,id=ec2664f4-d768-4745-9abe-ef2a305e3ce9
2022-06-25 01:09:41,455 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=8bbc5152-3491-4249-8acb-75abb1a65214
2022-06-25 01:09:41,455 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=8bbc5152-3491-4249-8acb-75abb1a65214.
2022-06-25 01:09:41,762 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:41,876 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:42,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:42,202 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode fc692a40-1ae9-40b7-8d63-7e46f51df1ef{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=40691, RATIS=39343, RATIS_ADMIN=39343, RATIS_SERVER=39343, STANDALONE=32859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=a58b823e-be03-49ee-a4ae-23927eca553c, PipelineID=1a613b2a-b322-4f7f-932c-b6b9df3cef32]
2022-06-25 01:09:42,203 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(432)) - Pipeline Pipeline[ Id: a58b823e-be03-49ee-a4ae-23927eca553c, Nodes: fc692a40-1ae9-40b7-8d63-7e46f51df1ef{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=40691, RATIS=39343, RATIS_ADMIN=39343, RATIS_SERVER=39343, STANDALONE=32859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:fc692a40-1ae9-40b7-8d63-7e46f51df1ef, CreationTimestamp2022-06-25T01:08:44.687Z[Etc/UTC]] moved to CLOSED state
2022-06-25 01:09:42,203 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(432)) - Pipeline Pipeline[ Id: 1a613b2a-b322-4f7f-932c-b6b9df3cef32, Nodes: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43029, RATIS=44897, RATIS_ADMIN=44897, RATIS_SERVER=44897, STANDALONE=37333], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}97d08340-a146-41c4-a759-b3b136c7fb6d{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=37711, RATIS=43169, RATIS_ADMIN=43169, RATIS_SERVER=43169, STANDALONE=44433], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}fc692a40-1ae9-40b7-8d63-7e46f51df1ef{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=40691, RATIS=39343, RATIS_ADMIN=39343, RATIS_SERVER=39343, STANDALONE=32859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:97d08340-a146-41c4-a759-b3b136c7fb6d, CreationTimestamp2022-06-25T01:08:47.549Z[Etc/UTC]] moved to CLOSED state
2022-06-25 01:09:42,241 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - ee118b23-09e5-41f4-9121-1170bcf86bc2: addNew group-3BB803B7D89D:[ee118b23-09e5-41f4-9121-1170bcf86bc2|rpc:10.1.0.8:39807|priority:1] returns group-3BB803B7D89D:java.util.concurrent.CompletableFuture@2f791f8[Not completed]
2022-06-25 01:09:42,242 [pool-4704-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - ee118b23-09e5-41f4-9121-1170bcf86bc2: new RaftServerImpl for group-3BB803B7D89D:[ee118b23-09e5-41f4-9121-1170bcf86bc2|rpc:10.1.0.8:39807|priority:1] with ContainerStateMachine:uninitialized
2022-06-25 01:09:42,242 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:09:42,242 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:09:42,242 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:42,242 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:42,242 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:42,242 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:42,242 [pool-4704-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D: ConfigurationManager, init=-1: [ee118b23-09e5-41f4-9121-1170bcf86bc2|rpc:10.1.0.8:39807|priority:1], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:42,242 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-2/data/ratis] (custom)
2022-06-25 01:09:42,242 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:42,242 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:42,242 [pool-4704-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-2/data/ratis/2062d5a7-3c35-4dd5-8ec9-3bb803b7d89d does not exist. Creating ...
2022-06-25 01:09:42,247 [pool-4704-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-2/data/ratis/2062d5a7-3c35-4dd5-8ec9-3bb803b7d89d/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:42,250 [pool-4704-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-2/data/ratis/2062d5a7-3c35-4dd5-8ec9-3bb803b7d89d has been successfully formatted.
2022-06-25 01:09:42,251 [pool-4704-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-3BB803B7D89D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:09:42,252 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:09:42,252 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:42,252 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:42,252 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:42,252 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:42,253 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(358)) - Pipeline Pipeline[ Id: 2062d5a7-3c35-4dd5-8ec9-3bb803b7d89d, Nodes: ee118b23-09e5-41f4-9121-1170bcf86bc2{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=36173, RATIS=39807, RATIS_ADMIN=39807, RATIS_SERVER=39807, STANDALONE=36851], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:ee118b23-09e5-41f4-9121-1170bcf86bc2, CreationTimestamp2022-06-25T01:09:39.261Z[Etc/UTC]] moved to OPEN state
2022-06-25 01:09:42,253 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:42,253 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:42,255 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:42,255 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:42,255 [pool-4704-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-2/data/ratis/2062d5a7-3c35-4dd5-8ec9-3bb803b7d89d
2022-06-25 01:09:42,255 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:09:42,255 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:09:42,255 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:42,255 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:09:42,255 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:42,255 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:42,255 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:42,255 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:42,279 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:09:42,279 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:42,279 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:09:42,279 [pool-4704-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:42,279 [pool-4704-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:42,280 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:42,280 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:09:42,280 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:09:42,280 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:09:42,280 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:09:42,280 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:42,301 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:42,301 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:42,301 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:42,301 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:42,301 [pool-4704-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:42,302 [pool-4704-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D: start as a follower, conf=-1: [ee118b23-09e5-41f4-9121-1170bcf86bc2|rpc:10.1.0.8:39807|priority:1], old=null
2022-06-25 01:09:42,302 [pool-4704-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:42,302 [pool-4704-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ee118b23-09e5-41f4-9121-1170bcf86bc2: start ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-FollowerState
2022-06-25 01:09:42,319 [pool-4704-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3BB803B7D89D,id=ee118b23-09e5-41f4-9121-1170bcf86bc2
2022-06-25 01:09:42,324 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=2062d5a7-3c35-4dd5-8ec9-3bb803b7d89d
2022-06-25 01:09:42,324 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=2062d5a7-3c35-4dd5-8ec9-3bb803b7d89d.
2022-06-25 01:09:42,330 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(309)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-4/data-0/containers/hdds/e228e9f1-8cea-4b31-8b4b-3b149b9026ba/DS-44fc9292-c5e2-42fc-90a9-2990da3dc66c/container.db for volume DS-44fc9292-c5e2-42fc-90a9-2990da3dc66c
2022-06-25 01:09:42,330 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(340)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-4/data-0/containers/hdds/e228e9f1-8cea-4b31-8b4b-3b149b9026ba/DS-44fc9292-c5e2-42fc-90a9-2990da3dc66c/container.db for volume DS-44fc9292-c5e2-42fc-90a9-2990da3dc66c
2022-06-25 01:09:42,331 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(344)) - Attempting to start container services.
2022-06-25 01:09:42,331 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(279)) - Background container scanner has been disabled.
2022-06-25 01:09:42,351 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 43321
2022-06-25 01:09:42,402 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis 0414aa62-2593-4022-a495-25b345e9257d
2022-06-25 01:09:42,506 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - 0414aa62-2593-4022-a495-25b345e9257d: start RPC server
2022-06-25 01:09:42,506 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - 0414aa62-2593-4022-a495-25b345e9257d: GrpcService started, listening on 40303
2022-06-25 01:09:42,506 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 0414aa62-2593-4022-a495-25b345e9257d is started using port 40303 for RATIS
2022-06-25 01:09:42,506 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 0414aa62-2593-4022-a495-25b345e9257d is started using port 40303 for RATIS_ADMIN
2022-06-25 01:09:42,506 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis 0414aa62-2593-4022-a495-25b345e9257d is started using port 40303 for RATIS_SERVER
2022-06-25 01:09:42,507 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@41ccc90b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-0414aa62-2593-4022-a495-25b345e9257d: Started
2022-06-25 01:09:42,507 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 0414aa62-2593-4022-a495-25b345e9257d is started using port 43699
2022-06-25 01:09:42,615 [Listener at 127.0.0.1/44435] INFO  handler.ContextHandler (ContextHandler.java:doStart(915)) - Started o.e.j.w.WebAppContext@1a2d0471{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-35579-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-5988331970671203569/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-25 01:09:42,659 [Listener at 127.0.0.1/44435] INFO  server.AbstractConnector (AbstractConnector.java:doStart(331)) - Started ServerConnector@32d1f2ba{HTTP/1.1, (http/1.1)}{0.0.0.0:35579}
2022-06-25 01:09:42,659 [Listener at 127.0.0.1/44435] INFO  server.Server (Server.java:doStart(415)) - Started @416556ms
2022-06-25 01:09:42,659 [Listener at 127.0.0.1/44435] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2022-06-25 01:09:42,666 [Listener at 127.0.0.1/44435] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(329)) - HTTP server of hddsDatanode listening at http://0.0.0.0:35579
2022-06-25 01:09:42,736 [Listener at 127.0.0.1/44435] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Waiting for nodes to be ready. Got 4 of 6 DN Heartbeats.
2022-06-25 01:09:42,736 [Listener at 127.0.0.1/44435] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Waiting for cluster to exit safe mode
2022-06-25 01:09:42,736 [Listener at 127.0.0.1/44435] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:09:42,762 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=ecaf046a-409f-4687-9322-92e04f1b2936, PipelineID=2b00854c-ae60-4259-8cdb-5f5be5f6e354]
2022-06-25 01:09:42,762 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(432)) - Pipeline Pipeline[ Id: ecaf046a-409f-4687-9322-92e04f1b2936, Nodes: 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, CreationTimestamp2022-06-25T01:08:41.898Z[Etc/UTC]] moved to CLOSED state
2022-06-25 01:09:42,762 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:42,762 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(432)) - Pipeline Pipeline[ Id: 2b00854c-ae60-4259-8cdb-5f5be5f6e354, Nodes: 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONED, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-25T01:09:36.690Z[Etc/UTC]] moved to CLOSED state
2022-06-25 01:09:42,770 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(492)) - Ozone container server started.
2022-06-25 01:09:42,876 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:42,939 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5b6e93ad] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2022-06-25 01:09:42,990 [be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5058539940ns, electionTimeout:5037ms
2022-06-25 01:09:42,991 [be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - be67eb5e-e62d-4374-a142-8db592db20d7: shutdown be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-FollowerState
2022-06-25 01:09:42,991 [be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:09:43,001 [be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:43,001 [be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - be67eb5e-e62d-4374-a142-8db592db20d7: start be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-LeaderElection186
2022-06-25 01:09:43,004 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-5/meta/datanode.id
2022-06-25 01:09:43,022 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleOverReplicatedContainer(1249)) - Container #3 is over replicated. Expected replica count is 3, but found 4.
2022-06-25 01:09:43,022 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendDeleteCommand(1583)) - Sending delete container command for container #3 to datanode fc692a40-1ae9-40b7-8d63-7e46f51df1ef{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=40691, RATIS=39343, RATIS_ADMIN=39343, RATIS_SERVER=39343, STANDALONE=32859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:09:43,022 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-06-25 01:09:43,135 [be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-LeaderElection186] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-LeaderElection186 ELECTION round 0: submit vote requests at term 1 for -1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:1], old=null
2022-06-25 01:09:43,135 [be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-LeaderElection186] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-LeaderElection186 ELECTION round 0: result PASSED (term=1)
2022-06-25 01:09:43,135 [be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-LeaderElection186] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - be67eb5e-e62d-4374-a142-8db592db20d7: shutdown be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-LeaderElection186
2022-06-25 01:09:43,135 [be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-LeaderElection186] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-06-25 01:09:43,135 [be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-LeaderElection186] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-87F9D58B43B0 with new leaderId: be67eb5e-e62d-4374-a142-8db592db20d7
2022-06-25 01:09:43,140 [be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-LeaderElection186] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0: change Leader from null to be67eb5e-e62d-4374-a142-8db592db20d7 at term 1 for becomeLeader, leader elected after 5282ms
2022-06-25 01:09:43,140 [be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-LeaderElection186] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-25 01:09:43,166 [be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-LeaderElection186] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:43,166 [be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-LeaderElection186] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-06-25 01:09:43,167 [be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-LeaderElection186] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-06-25 01:09:43,167 [be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-LeaderElection186] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-25 01:09:43,167 [be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-LeaderElection186] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-25 01:09:43,167 [be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-LeaderElection186] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:43,167 [be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-LeaderElection186] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-25 01:09:43,167 [be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-LeaderElection186] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - be67eb5e-e62d-4374-a142-8db592db20d7: start be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-LeaderStateImpl
2022-06-25 01:09:43,168 [be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-LeaderElection186] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:43,170 [be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis/793cb964-1b2d-41b4-96bf-87f9d58b43b0/current/log_inprogress_0
2022-06-25 01:09:43,253 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:43,254 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:43,261 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:43,303 [be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-LeaderElection186] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0: set configuration 0: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:1], old=null
2022-06-25 01:09:43,467 [grpc-default-executor-10] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32->fc692a40-1ae9-40b7-8d63-7e46f51df1ef-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-06-25 01:09:43,468 [grpc-default-executor-10] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(111)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32->fc692a40-1ae9-40b7-8d63-7e46f51df1ef-GrpcLogAppender: Leader has not got in touch with Follower 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32->fc692a40-1ae9-40b7-8d63-7e46f51df1ef(c0,m0,n1, attendVote=true, lastRpcSendTime=0, lastRpcResponseTime=2707) yet, just keep nextIndex unchanged and retry.
2022-06-25 01:09:43,471 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-06-25 01:09:43,499 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5104194823ns, electionTimeout:5041ms
2022-06-25 01:09:43,500 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - be67eb5e-e62d-4374-a142-8db592db20d7: shutdown be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-FollowerState
2022-06-25 01:09:43,500 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:09:43,500 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:43,500 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - be67eb5e-e62d-4374-a142-8db592db20d7: start be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-LeaderElection187
2022-06-25 01:09:43,573 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5195814687ns, electionTimeout:5179ms
2022-06-25 01:09:43,573 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: shutdown 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-FollowerState
2022-06-25 01:09:43,574 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:09:43,574 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:43,574 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: start 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-LeaderElection188
2022-06-25 01:09:43,602 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-LeaderElection187] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-LeaderElection187 ELECTION round 0: submit vote requests at term 1 for -1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|priority:0], old=null
2022-06-25 01:09:43,614 [grpc-default-executor-10] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354: receive requestVote(ELECTION, be67eb5e-e62d-4374-a142-8db592db20d7, group-5F5BE5F6E354, 1, (t:0, i:0))
2022-06-25 01:09:43,614 [grpc-default-executor-10] INFO  impl.VoteContext (VoteContext.java:log(48)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354-FOLLOWER: reject ELECTION from be67eb5e-e62d-4374-a142-8db592db20d7: our priority 1 > candidate's priority 0
2022-06-25 01:09:43,614 [grpc-default-executor-10] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:be67eb5e-e62d-4374-a142-8db592db20d7
2022-06-25 01:09:43,614 [grpc-default-executor-10] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: shutdown 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354-FollowerState
2022-06-25 01:09:43,626 [grpc-default-executor-10] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: start 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354-FollowerState
2022-06-25 01:09:43,627 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354-FollowerState was interrupted
2022-06-25 01:09:43,630 [grpc-default-executor-9] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354: receive requestVote(ELECTION, be67eb5e-e62d-4374-a142-8db592db20d7, group-5F5BE5F6E354, 1, (t:0, i:0))
2022-06-25 01:09:43,732 [grpc-default-executor-10] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354 replies to ELECTION vote request: be67eb5e-e62d-4374-a142-8db592db20d7<-09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf#0:FAIL-t1. Peer's state: 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354:t1, leader=null, voted=null, raftlog=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354-SegmentedRaftLog:OPENED:c-1, conf=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:0], old=null
2022-06-25 01:09:43,766 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:43,808 [Listener at 127.0.0.1/44435] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Waiting for nodes to be ready. Got 4 of 6 DN Heartbeats.
2022-06-25 01:09:43,808 [Listener at 127.0.0.1/44435] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Waiting for cluster to exit safe mode
2022-06-25 01:09:43,808 [Listener at 127.0.0.1/44435] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:09:43,808 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-LeaderElection188] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-LeaderElection188 ELECTION round 0: submit vote requests at term 1 for -1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|priority:0], old=null
2022-06-25 01:09:43,808 [grpc-default-executor-9] INFO  impl.VoteContext (VoteContext.java:log(48)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-CANDIDATE: reject ELECTION from be67eb5e-e62d-4374-a142-8db592db20d7: already has voted for 3c6128f4-7bf2-4a55-83fb-21add5186158 at current term 1
2022-06-25 01:09:43,808 [grpc-default-executor-9] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354 replies to ELECTION vote request: be67eb5e-e62d-4374-a142-8db592db20d7<-3c6128f4-7bf2-4a55-83fb-21add5186158#0:FAIL-t1. Peer's state: 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354:t1, leader=null, voted=3c6128f4-7bf2-4a55-83fb-21add5186158, raftlog=3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-SegmentedRaftLog:OPENED:c-1, conf=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|priority:0], old=null
2022-06-25 01:09:43,849 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-LeaderElection187] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-LeaderElection187: ELECTION REJECTED received 1 response(s) and 0 exception(s):
2022-06-25 01:09:43,849 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-LeaderElection187] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: be67eb5e-e62d-4374-a142-8db592db20d7<-09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf#0:FAIL-t1
2022-06-25 01:09:43,849 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-LeaderElection187] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-LeaderElection187 ELECTION round 0: result REJECTED
2022-06-25 01:09:43,849 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-LeaderElection187] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
2022-06-25 01:09:43,849 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-LeaderElection187] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - be67eb5e-e62d-4374-a142-8db592db20d7: shutdown be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-LeaderElection187
2022-06-25 01:09:43,849 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-LeaderElection187] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - be67eb5e-e62d-4374-a142-8db592db20d7: start be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-FollowerState
2022-06-25 01:09:43,882 [grpc-default-executor-9] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354: receive requestVote(ELECTION, 3c6128f4-7bf2-4a55-83fb-21add5186158, group-5F5BE5F6E354, 1, (t:0, i:0))
2022-06-25 01:09:43,883 [grpc-default-executor-10] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354: receive requestVote(ELECTION, 3c6128f4-7bf2-4a55-83fb-21add5186158, group-5F5BE5F6E354, 1, (t:0, i:0))
2022-06-25 01:09:43,883 [grpc-default-executor-10] INFO  impl.VoteContext (VoteContext.java:log(48)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-FOLLOWER: reject ELECTION from 3c6128f4-7bf2-4a55-83fb-21add5186158: already has voted for be67eb5e-e62d-4374-a142-8db592db20d7 at current term 1
2022-06-25 01:09:43,883 [grpc-default-executor-10] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354 replies to ELECTION vote request: 3c6128f4-7bf2-4a55-83fb-21add5186158<-be67eb5e-e62d-4374-a142-8db592db20d7#0:FAIL-t1. Peer's state: be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354:t1, leader=null, voted=be67eb5e-e62d-4374-a142-8db592db20d7, raftlog=be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-SegmentedRaftLog:OPENED:c-1, conf=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|priority:0], old=null
2022-06-25 01:09:43,905 [grpc-default-executor-9] INFO  impl.VoteContext (VoteContext.java:log(48)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354-FOLLOWER: reject ELECTION from 3c6128f4-7bf2-4a55-83fb-21add5186158: our priority 1 > candidate's priority 0
2022-06-25 01:09:43,905 [grpc-default-executor-9] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:3c6128f4-7bf2-4a55-83fb-21add5186158
2022-06-25 01:09:43,905 [grpc-default-executor-9] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: shutdown 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354-FollowerState
2022-06-25 01:09:43,905 [grpc-default-executor-9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: start 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354-FollowerState
2022-06-25 01:09:43,910 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354-FollowerState was interrupted
2022-06-25 01:09:43,910 [grpc-default-executor-9] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354 replies to ELECTION vote request: 3c6128f4-7bf2-4a55-83fb-21add5186158<-09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf#0:FAIL-t1. Peer's state: 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354:t1, leader=null, voted=null, raftlog=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354-SegmentedRaftLog:OPENED:c-1, conf=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|dataStream:|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|dataStream:|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|dataStream:|priority:0], old=null
2022-06-25 01:09:43,913 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-LeaderElection188] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-LeaderElection188: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-06-25 01:09:43,913 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-LeaderElection188] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 3c6128f4-7bf2-4a55-83fb-21add5186158<-be67eb5e-e62d-4374-a142-8db592db20d7#0:FAIL-t1
2022-06-25 01:09:43,913 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-LeaderElection188] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 3c6128f4-7bf2-4a55-83fb-21add5186158<-09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf#0:FAIL-t1
2022-06-25 01:09:43,913 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-LeaderElection188] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-LeaderElection188 ELECTION round 0: result REJECTED
2022-06-25 01:09:43,913 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-LeaderElection188] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
2022-06-25 01:09:43,913 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-LeaderElection188] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: shutdown 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-LeaderElection188
2022-06-25 01:09:43,913 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-LeaderElection188] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: start 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-FollowerState
2022-06-25 01:09:43,950 [IPC Server handler 17 on default port 44773] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/0414aa62-2593-4022-a495-25b345e9257d
2022-06-25 01:09:43,951 [IPC Server handler 17 on default port 44773] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 0414aa62-2593-4022-a495-25b345e9257d{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43321, RATIS=40303, RATIS_ADMIN=40303, RATIS_SERVER=40303, STANDALONE=43699], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:09:43,951 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(275)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-06-25 01:09:43,951 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=1cb91e0d-df45-4cda-93da-bee07bcec32e to datanode:0414aa62-2593-4022-a495-25b345e9257d
2022-06-25 01:09:43,952 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 1cb91e0d-df45-4cda-93da-bee07bcec32e, Nodes: 0414aa62-2593-4022-a495-25b345e9257d{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43321, RATIS=40303, RATIS_ADMIN=40303, RATIS_SERVER=40303, STANDALONE=43699], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-25T01:09:43.951Z[Etc/UTC]].
2022-06-25 01:09:43,969 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:43,974 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@451ea648] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-a39a8077-0667-4534-bc11-ae9dd274a08a: Detected pause in JVM or host machine (eg GC): pause of approximately 102367399ns. No GCs detected.
2022-06-25 01:09:43,975 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@1067788d] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: Detected pause in JVM or host machine (eg GC): pause of approximately 102511700ns. No GCs detected.
2022-06-25 01:09:44,025 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleOverReplicatedContainer(1249)) - Container #3 is over replicated. Expected replica count is 3, but found 4.
2022-06-25 01:09:44,025 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendDeleteCommand(1583)) - Sending delete container command for container #3 to datanode fc692a40-1ae9-40b7-8d63-7e46f51df1ef{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=40691, RATIS=39343, RATIS_ADMIN=39343, RATIS_SERVER=39343, STANDALONE=32859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:09:44,025 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:44,253 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:44,259 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:44,263 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:44,320 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - d233dd63-6533-4977-8487-4fe644b19e51: addNew group-AD647EB92D8E:[d233dd63-6533-4977-8487-4fe644b19e51|rpc:10.1.0.8:43619|priority:1] returns group-AD647EB92D8E:java.util.concurrent.CompletableFuture@7a2f81fd[Not completed]
2022-06-25 01:09:44,321 [pool-4731-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - d233dd63-6533-4977-8487-4fe644b19e51: new RaftServerImpl for group-AD647EB92D8E:[d233dd63-6533-4977-8487-4fe644b19e51|rpc:10.1.0.8:43619|priority:1] with ContainerStateMachine:uninitialized
2022-06-25 01:09:44,321 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:09:44,321 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:09:44,321 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:44,321 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:44,322 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:44,322 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:44,322 [pool-4731-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E: ConfigurationManager, init=-1: [d233dd63-6533-4977-8487-4fe644b19e51|rpc:10.1.0.8:43619|priority:1], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:44,322 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-3/data/ratis] (custom)
2022-06-25 01:09:44,323 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:44,323 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:44,323 [pool-4731-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-3/data/ratis/f2ef78ee-d67e-486b-bc60-ad647eb92d8e does not exist. Creating ...
2022-06-25 01:09:44,327 [pool-4731-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-3/data/ratis/f2ef78ee-d67e-486b-bc60-ad647eb92d8e/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:44,329 [pool-4731-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-3/data/ratis/f2ef78ee-d67e-486b-bc60-ad647eb92d8e has been successfully formatted.
2022-06-25 01:09:44,329 [pool-4731-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-AD647EB92D8E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:09:44,330 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:09:44,330 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:44,330 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:44,330 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:44,330 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:44,330 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:44,332 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:44,332 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:44,332 [pool-4731-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-3/data/ratis/f2ef78ee-d67e-486b-bc60-ad647eb92d8e
2022-06-25 01:09:44,332 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:09:44,332 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:09:44,332 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:44,346 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:09:44,346 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:44,346 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:44,346 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:44,346 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:44,358 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(358)) - Pipeline Pipeline[ Id: f2ef78ee-d67e-486b-bc60-ad647eb92d8e, Nodes: d233dd63-6533-4977-8487-4fe644b19e51{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=38035, RATIS=43619, RATIS_ADMIN=43619, RATIS_SERVER=43619, STANDALONE=45827], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:d233dd63-6533-4977-8487-4fe644b19e51, CreationTimestamp2022-06-25T01:09:41.320Z[Etc/UTC]] moved to OPEN state
2022-06-25 01:09:44,359 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:44,418 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:09:44,419 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:44,419 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:09:44,419 [pool-4731-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:44,419 [pool-4731-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:44,450 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:44,450 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:09:44,450 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:09:44,450 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:09:44,450 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:09:44,450 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:44,455 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:44,455 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:44,456 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:44,457 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:44,457 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:44,458 [pool-4731-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E: start as a follower, conf=-1: [d233dd63-6533-4977-8487-4fe644b19e51|rpc:10.1.0.8:43619|priority:1], old=null
2022-06-25 01:09:44,458 [pool-4731-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:44,458 [pool-4731-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d233dd63-6533-4977-8487-4fe644b19e51: start d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-FollowerState
2022-06-25 01:09:44,464 [pool-4731-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AD647EB92D8E,id=d233dd63-6533-4977-8487-4fe644b19e51
2022-06-25 01:09:44,465 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=f2ef78ee-d67e-486b-bc60-ad647eb92d8e
2022-06-25 01:09:44,465 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=f2ef78ee-d67e-486b-bc60-ad647eb92d8e.
2022-06-25 01:09:44,717 [grpc-default-executor-9] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32->fc692a40-1ae9-40b7-8d63-7e46f51df1ef-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-06-25 01:09:44,718 [grpc-default-executor-9] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(111)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32->fc692a40-1ae9-40b7-8d63-7e46f51df1ef-GrpcLogAppender: Leader has not got in touch with Follower 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32->fc692a40-1ae9-40b7-8d63-7e46f51df1ef(c0,m0,n1, attendVote=true, lastRpcSendTime=1250, lastRpcResponseTime=3957) yet, just keep nextIndex unchanged and retry.
2022-06-25 01:09:44,766 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:44,789 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(365)) - Attempting to stop container services.
2022-06-25 01:09:44,809 [Listener at 127.0.0.1/44435] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Waiting for nodes to be ready. Got 5 of 6 DN Heartbeats.
2022-06-25 01:09:44,809 [Listener at 127.0.0.1/44435] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Waiting for cluster to exit safe mode
2022-06-25 01:09:44,809 [Listener at 127.0.0.1/44435] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:09:44,864 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$7(398)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: close
2022-06-25 01:09:44,865 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936: shutdown
2022-06-25 01:09:44,865 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-92E04F1B2936,id=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf
2022-06-25 01:09:44,865 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: shutdown 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-LeaderStateImpl
2022-06-25 01:09:44,865 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-PendingRequests: sendNotLeaderResponses
2022-06-25 01:09:44,867 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-92E04F1B2936: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data/ratis/ecaf046a-409f-4687-9322-92e04f1b2936/sm/snapshot.1_0
2022-06-25 01:09:44,868 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-StateMachineUpdater: set stopIndex = 0
2022-06-25 01:09:44,869 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-92E04F1B2936: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-1/data/ratis/ecaf046a-409f-4687-9322-92e04f1b2936/sm/snapshot.1_0 took: 2 ms
2022-06-25 01:09:44,869 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-StateMachineUpdater: Took a snapshot at index 0
2022-06-25 01:09:44,869 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-06-25 01:09:44,869 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer$Division (ServerState.java:close(429)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936: closes. applyIndex: 0
2022-06-25 01:09:44,869 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-25 01:09:44,870 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-92E04F1B2936-SegmentedRaftLogWorker close()
2022-06-25 01:09:44,870 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354: shutdown
2022-06-25 01:09:44,870 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-5F5BE5F6E354,id=09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf
2022-06-25 01:09:44,870 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: shutdown 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354-FollowerState
2022-06-25 01:09:44,870 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354-FollowerState was interrupted
2022-06-25 01:09:44,871 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354-StateMachineUpdater: set stopIndex = -1
2022-06-25 01:09:44,871 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer$Division (ServerState.java:close(429)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354: closes. applyIndex: -1
2022-06-25 01:09:44,871 [09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-25 01:09:44,871 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf@group-5F5BE5F6E354-SegmentedRaftLogWorker close()
2022-06-25 01:09:44,903 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(269)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: shutdown server with port 39033 now
2022-06-25 01:09:44,952 [grpc-default-executor-10] WARN  server.GrpcClientProtocolService (LogUtils.java:warn(122)) - 1-UnorderedRequestStreamObserver1: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2022-06-25 01:09:44,969 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:44,993 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(278)) - 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: shutdown server with port 39033 successfully
2022-06-25 01:09:44,993 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@3a3a1bd4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf: Stopped
2022-06-25 01:09:45,028 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleOverReplicatedContainer(1249)) - Container #3 is over replicated. Expected replica count is 3, but found 4.
2022-06-25 01:09:45,038 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendDeleteCommand(1583)) - Sending delete container command for container #3 to datanode fc692a40-1ae9-40b7-8d63-7e46f51df1ef{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=40691, RATIS=39343, RATIS_ADMIN=39343, RATIS_SERVER=39343, STANDALONE=32859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:09:45,038 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 10 milliseconds for processing 3 containers.
2022-06-25 01:09:45,170 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. fc692a40-1ae9-40b7-8d63-7e46f51df1ef{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=40691, RATIS=39343, RATIS_ADMIN=39343, RATIS_SERVER=39343, STANDALONE=32859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:09:45,170 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=a58b823e-be03-49ee-a4ae-23927eca553c close command to datanode fc692a40-1ae9-40b7-8d63-7e46f51df1ef
2022-06-25 01:09:45,197 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(309)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-5/data-0/containers/hdds/e228e9f1-8cea-4b31-8b4b-3b149b9026ba/DS-f2566377-4ed1-4760-9179-13037de255d7/container.db for volume DS-f2566377-4ed1-4760-9179-13037de255d7
2022-06-25 01:09:45,197 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(340)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-5/data-0/containers/hdds/e228e9f1-8cea-4b31-8b4b-3b149b9026ba/DS-f2566377-4ed1-4760-9179-13037de255d7/container.db for volume DS-f2566377-4ed1-4760-9179-13037de255d7
2022-06-25 01:09:45,197 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(344)) - Attempting to start container services.
2022-06-25 01:09:45,197 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(279)) - Background container scanner has been disabled.
2022-06-25 01:09:45,198 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(243)) - Pipeline Pipeline[ Id: a58b823e-be03-49ee-a4ae-23927eca553c, Nodes: fc692a40-1ae9-40b7-8d63-7e46f51df1ef{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=40691, RATIS=39343, RATIS_ADMIN=39343, RATIS_SERVER=39343, STANDALONE=32859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:fc692a40-1ae9-40b7-8d63-7e46f51df1ef, CreationTimestamp2022-06-25T01:08:44.687Z[Etc/UTC]] removed.
2022-06-25 01:09:45,198 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=1a613b2a-b322-4f7f-932c-b6b9df3cef32 close command to datanode 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9
2022-06-25 01:09:45,198 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=1a613b2a-b322-4f7f-932c-b6b9df3cef32 close command to datanode 97d08340-a146-41c4-a759-b3b136c7fb6d
2022-06-25 01:09:45,198 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=1a613b2a-b322-4f7f-932c-b6b9df3cef32 close command to datanode fc692a40-1ae9-40b7-8d63-7e46f51df1ef
2022-06-25 01:09:45,199 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(243)) - Pipeline Pipeline[ Id: 1a613b2a-b322-4f7f-932c-b6b9df3cef32, Nodes: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43029, RATIS=44897, RATIS_ADMIN=44897, RATIS_SERVER=44897, STANDALONE=37333], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}97d08340-a146-41c4-a759-b3b136c7fb6d{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=37711, RATIS=43169, RATIS_ADMIN=43169, RATIS_SERVER=43169, STANDALONE=44433], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}fc692a40-1ae9-40b7-8d63-7e46f51df1ef{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=40691, RATIS=39343, RATIS_ADMIN=39343, RATIS_SERVER=39343, STANDALONE=32859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:97d08340-a146-41c4-a759-b3b136c7fb6d, CreationTimestamp2022-06-25T01:08:47.549Z[Etc/UTC]] removed.
2022-06-25 01:09:45,199 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/fc692a40-1ae9-40b7-8d63-7e46f51df1ef
2022-06-25 01:09:45,199 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(111)) - ReplicationServer is started using port 38121
2022-06-25 01:09:45,256 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(481)) - Starting XceiverServerRatis a26e6a85-69e0-4d1b-9fdc-0decb2cb6032
2022-06-25 01:09:45,326 [f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5108261841ns, electionTimeout:5106ms
2022-06-25 01:09:45,327 [f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - f368a730-3857-4d18-b0ff-e0c952296109: shutdown f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-FollowerState
2022-06-25 01:09:45,327 [f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:09:45,328 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=1a613b2a-b322-4f7f-932c-b6b9df3cef32 is not found
2022-06-25 01:09:45,416 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:lambda$start$6(382)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032: start RPC server
2022-06-25 01:09:45,416 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(260)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032: GrpcService started, listening on 45483
2022-06-25 01:09:45,421 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis a26e6a85-69e0-4d1b-9fdc-0decb2cb6032 is started using port 45483 for RATIS
2022-06-25 01:09:45,421 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis a26e6a85-69e0-4d1b-9fdc-0decb2cb6032 is started using port 45483 for RATIS_ADMIN
2022-06-25 01:09:45,421 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(502)) - XceiverServerRatis a26e6a85-69e0-4d1b-9fdc-0decb2cb6032 is started using port 45483 for RATIS_SERVER
2022-06-25 01:09:45,430 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@37a08f49] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-fb218fe0-94a8-44a0-a252-d3cae8685c6f: Detected pause in JVM or host machine (eg GC): pause of approximately 204296105ns. No GCs detected.
2022-06-25 01:09:45,452 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@1f558164] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(103)) - JvmPauseMonitor-a26e6a85-69e0-4d1b-9fdc-0decb2cb6032: Started
2022-06-25 01:09:45,453 [EndpointStateMachine task thread for /0.0.0.0:44773 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc a26e6a85-69e0-4d1b-9fdc-0decb2cb6032 is started using port 41583
2022-06-25 01:09:45,479 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5129005224ns, electionTimeout:5102ms
2022-06-25 01:09:45,479 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - f368a730-3857-4d18-b0ff-e0c952296109: shutdown f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-FollowerState
2022-06-25 01:09:45,480 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:09:45,480 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:45,480 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - f368a730-3857-4d18-b0ff-e0c952296109: start f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190
2022-06-25 01:09:45,518 [f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:45,518 [f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - f368a730-3857-4d18-b0ff-e0c952296109: start f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-LeaderElection189
2022-06-25 01:09:45,595 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190 ELECTION round 0: submit vote requests at term 1 for -1: [f368a730-3857-4d18-b0ff-e0c952296109|rpc:10.1.0.8:46119|priority:1, ee118b23-09e5-41f4-9121-1170bcf86bc2|rpc:10.1.0.8:39807|priority:0, ec2664f4-d768-4745-9abe-ef2a305e3ce9|rpc:10.1.0.8:41903|priority:0], old=null
2022-06-25 01:09:45,596 [f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-LeaderElection189] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-LeaderElection189 ELECTION round 0: submit vote requests at term 1 for -1: [f368a730-3857-4d18-b0ff-e0c952296109|rpc:10.1.0.8:46119|priority:1], old=null
2022-06-25 01:09:45,596 [f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-LeaderElection189] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-LeaderElection189 ELECTION round 0: result PASSED (term=1)
2022-06-25 01:09:45,596 [f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-LeaderElection189] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - f368a730-3857-4d18-b0ff-e0c952296109: shutdown f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-LeaderElection189
2022-06-25 01:09:45,596 [f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-LeaderElection189] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-06-25 01:09:45,596 [f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-LeaderElection189] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-689FA3209105 with new leaderId: f368a730-3857-4d18-b0ff-e0c952296109
2022-06-25 01:09:45,601 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5108342242ns, electionTimeout:5077ms
2022-06-25 01:09:45,602 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9: shutdown ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5-FollowerState
2022-06-25 01:09:45,602 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:09:45,672 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:45,672 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9: start ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5-LeaderElection191
2022-06-25 01:09:45,678 [f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-LeaderElection189] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105: change Leader from null to f368a730-3857-4d18-b0ff-e0c952296109 at term 1 for becomeLeader, leader elected after 5460ms
2022-06-25 01:09:45,678 [f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-LeaderElection189] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-25 01:09:45,679 [f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-LeaderElection189] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:45,679 [f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-LeaderElection189] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-06-25 01:09:45,680 [f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-LeaderElection189] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-06-25 01:09:45,680 [f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-LeaderElection189] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-25 01:09:45,680 [f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-LeaderElection189] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-25 01:09:45,680 [f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-LeaderElection189] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:45,680 [f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-LeaderElection189] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-25 01:09:45,680 [f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-LeaderElection189] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - f368a730-3857-4d18-b0ff-e0c952296109: start f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-LeaderStateImpl
2022-06-25 01:09:45,681 [f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-LeaderElection189] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:45,682 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:45,766 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:45,780 [f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-LeaderElection189] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105: set configuration 0: [f368a730-3857-4d18-b0ff-e0c952296109|rpc:10.1.0.8:46119|dataStream:|priority:1], old=null
2022-06-25 01:09:45,810 [Listener at 127.0.0.1/44435] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Waiting for nodes to be ready. Got 5 of 6 DN Heartbeats.
2022-06-25 01:09:45,810 [Listener at 127.0.0.1/44435] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Waiting for cluster to exit safe mode
2022-06-25 01:09:45,810 [Listener at 127.0.0.1/44435] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:09:45,811 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-C104FB0CBEE5: receive requestVote(ELECTION, f368a730-3857-4d18-b0ff-e0c952296109, group-C104FB0CBEE5, 1, (t:0, i:0))
2022-06-25 01:09:45,811 [grpc-default-executor-8] INFO  impl.VoteContext (VoteContext.java:log(48)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-C104FB0CBEE5-FOLLOWER: accept ELECTION from f368a730-3857-4d18-b0ff-e0c952296109: our priority 0 <= candidate's priority 1
2022-06-25 01:09:45,811 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-C104FB0CBEE5: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:f368a730-3857-4d18-b0ff-e0c952296109
2022-06-25 01:09:45,811 [grpc-default-executor-8] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - ee118b23-09e5-41f4-9121-1170bcf86bc2: shutdown ee118b23-09e5-41f4-9121-1170bcf86bc2@group-C104FB0CBEE5-FollowerState
2022-06-25 01:09:45,811 [grpc-default-executor-8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ee118b23-09e5-41f4-9121-1170bcf86bc2: start ee118b23-09e5-41f4-9121-1170bcf86bc2@group-C104FB0CBEE5-FollowerState
2022-06-25 01:09:45,811 [ee118b23-09e5-41f4-9121-1170bcf86bc2@group-C104FB0CBEE5-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-C104FB0CBEE5-FollowerState was interrupted
2022-06-25 01:09:45,823 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-C104FB0CBEE5 replies to ELECTION vote request: f368a730-3857-4d18-b0ff-e0c952296109<-ee118b23-09e5-41f4-9121-1170bcf86bc2#0:OK-t1. Peer's state: ee118b23-09e5-41f4-9121-1170bcf86bc2@group-C104FB0CBEE5:t1, leader=null, voted=f368a730-3857-4d18-b0ff-e0c952296109, raftlog=ee118b23-09e5-41f4-9121-1170bcf86bc2@group-C104FB0CBEE5-SegmentedRaftLog:OPENED:c-1, conf=-1: [f368a730-3857-4d18-b0ff-e0c952296109|rpc:10.1.0.8:46119|dataStream:|priority:1, ee118b23-09e5-41f4-9121-1170bcf86bc2|rpc:10.1.0.8:39807|dataStream:|priority:0, ec2664f4-d768-4745-9abe-ef2a305e3ce9|rpc:10.1.0.8:41903|dataStream:|priority:0], old=null
2022-06-25 01:09:45,827 [f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - f368a730-3857-4d18-b0ff-e0c952296109@group-689FA3209105-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-0/data/ratis/8119f22a-7f75-41f6-8378-689fa3209105/current/log_inprogress_0
2022-06-25 01:09:45,829 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5: receive requestVote(ELECTION, f368a730-3857-4d18-b0ff-e0c952296109, group-C104FB0CBEE5, 1, (t:0, i:0))
2022-06-25 01:09:45,841 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5-LeaderElection191] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5-LeaderElection191 ELECTION round 0: submit vote requests at term 1 for -1: [f368a730-3857-4d18-b0ff-e0c952296109|rpc:10.1.0.8:46119|dataStream:|priority:1, ee118b23-09e5-41f4-9121-1170bcf86bc2|rpc:10.1.0.8:39807|dataStream:|priority:0, ec2664f4-d768-4745-9abe-ef2a305e3ce9|rpc:10.1.0.8:41903|dataStream:|priority:0], old=null
2022-06-25 01:09:45,841 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5-CANDIDATE: reject ELECTION from f368a730-3857-4d18-b0ff-e0c952296109: already has voted for ec2664f4-d768-4745-9abe-ef2a305e3ce9 at current term 1
2022-06-25 01:09:45,842 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5 replies to ELECTION vote request: f368a730-3857-4d18-b0ff-e0c952296109<-ec2664f4-d768-4745-9abe-ef2a305e3ce9#0:FAIL-t1. Peer's state: ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5:t1, leader=null, voted=ec2664f4-d768-4745-9abe-ef2a305e3ce9, raftlog=ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5-SegmentedRaftLog:OPENED:c-1, conf=-1: [f368a730-3857-4d18-b0ff-e0c952296109|rpc:10.1.0.8:46119|dataStream:|priority:1, ee118b23-09e5-41f4-9121-1170bcf86bc2|rpc:10.1.0.8:39807|dataStream:|priority:0, ec2664f4-d768-4745-9abe-ef2a305e3ce9|rpc:10.1.0.8:41903|dataStream:|priority:0], old=null
2022-06-25 01:09:45,856 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:09:45,856 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=ecaf046a-409f-4687-9322-92e04f1b2936 close command to datanode 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf
2022-06-25 01:09:45,857 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(243)) - Pipeline Pipeline[ Id: ecaf046a-409f-4687-9322-92e04f1b2936, Nodes: 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf, CreationTimestamp2022-06-25T01:08:41.898Z[Etc/UTC]] removed.
2022-06-25 01:09:45,857 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=2b00854c-ae60-4259-8cdb-5f5be5f6e354 close command to datanode 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf
2022-06-25 01:09:45,857 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=2b00854c-ae60-4259-8cdb-5f5be5f6e354 close command to datanode 3c6128f4-7bf2-4a55-83fb-21add5186158
2022-06-25 01:09:45,857 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=2b00854c-ae60-4259-8cdb-5f5be5f6e354 close command to datanode be67eb5e-e62d-4374-a142-8db592db20d7
2022-06-25 01:09:45,857 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(243)) - Pipeline Pipeline[ Id: 2b00854c-ae60-4259-8cdb-5f5be5f6e354, Nodes: 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43059, RATIS=39033, RATIS_ADMIN=39033, RATIS_SERVER=39033, STANDALONE=36009], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONED, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:, CreationTimestamp2022-06-25T01:09:36.690Z[Etc/UTC]] removed.
2022-06-25 01:09:45,857 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf
2022-06-25 01:09:45,859 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190: ELECTION PASSED received 1 response(s) and 0 exception(s):
2022-06-25 01:09:45,859 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: f368a730-3857-4d18-b0ff-e0c952296109<-ee118b23-09e5-41f4-9121-1170bcf86bc2#0:OK-t1
2022-06-25 01:09:45,859 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190 ELECTION round 0: result PASSED
2022-06-25 01:09:45,859 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - f368a730-3857-4d18-b0ff-e0c952296109: shutdown f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190
2022-06-25 01:09:45,859 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-06-25 01:09:45,859 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-C104FB0CBEE5 with new leaderId: f368a730-3857-4d18-b0ff-e0c952296109
2022-06-25 01:09:45,859 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5: change Leader from null to f368a730-3857-4d18-b0ff-e0c952296109 at term 1 for becomeLeader, leader elected after 5598ms
2022-06-25 01:09:45,859 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-25 01:09:45,860 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:45,860 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-06-25 01:09:45,871 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-06-25 01:09:45,871 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-25 01:09:45,871 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-25 01:09:45,871 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:45,872 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-25 01:09:45,922 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(358)) - Pipeline Pipeline[ Id: 4f5bb74b-936b-4e65-b29c-c104fb0cbee5, Nodes: ec2664f4-d768-4745-9abe-ef2a305e3ce9{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=40907, RATIS=41903, RATIS_ADMIN=41903, RATIS_SERVER=41903, STANDALONE=45557], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}ee118b23-09e5-41f4-9121-1170bcf86bc2{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=36173, RATIS=39807, RATIS_ADMIN=39807, RATIS_SERVER=39807, STANDALONE=36851], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f368a730-3857-4d18-b0ff-e0c952296109{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=36553, RATIS=46119, RATIS_ADMIN=46119, RATIS_SERVER=46119, STANDALONE=36013], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:f368a730-3857-4d18-b0ff-e0c952296109, CreationTimestamp2022-06-25T01:09:39.360Z[Etc/UTC]] moved to OPEN state
2022-06-25 01:09:45,922 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2022-06-25 01:09:45,923 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(124)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2022-06-25 01:09:45,923 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(204)) - HealthyPipelineSafeModeRule rule is successfully validated
2022-06-25 01:09:45,923 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(219)) - ScmSafeModeManager, all rules are successfully validated
2022-06-25 01:09:45,923 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(248)) - SCM exiting safe mode.
2022-06-25 01:09:45,923 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2022-06-25 01:09:45,923 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2022-06-25 01:09:45,923 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(253)) - Service BackgroundPipelineCreator transitions to RUNNING.
2022-06-25 01:09:45,923 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2022-06-25 01:09:45,923 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2022-06-25 01:09:45,923 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(372)) - Service ReplicationManager transitions to RUNNING.
2022-06-25 01:09:45,944 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(875)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2022-06-25 01:09:45,970 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:45,975 [grpc-default-executor-10] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32->fc692a40-1ae9-40b7-8d63-7e46f51df1ef-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-06-25 01:09:45,975 [grpc-default-executor-10] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(111)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32->fc692a40-1ae9-40b7-8d63-7e46f51df1ef-GrpcLogAppender: Leader has not got in touch with Follower 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32->fc692a40-1ae9-40b7-8d63-7e46f51df1ef(c0,m0,n1, attendVote=true, lastRpcSendTime=6, lastRpcResponseTime=5215) yet, just keep nextIndex unchanged and retry.
2022-06-25 01:09:45,977 [grpc-default-executor-10] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-C104FB0CBEE5: receive requestVote(ELECTION, ec2664f4-d768-4745-9abe-ef2a305e3ce9, group-C104FB0CBEE5, 1, (t:0, i:0))
2022-06-25 01:09:45,990 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2022-06-25 01:09:45,990 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:45,990 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2022-06-25 01:09:45,990 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5: receive requestVote(ELECTION, ec2664f4-d768-4745-9abe-ef2a305e3ce9, group-C104FB0CBEE5, 1, (t:0, i:0))
2022-06-25 01:09:46,004 [grpc-default-executor-10] INFO  impl.VoteContext (VoteContext.java:log(48)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-C104FB0CBEE5-FOLLOWER: reject ELECTION from ec2664f4-d768-4745-9abe-ef2a305e3ce9: already has voted for f368a730-3857-4d18-b0ff-e0c952296109 at current term 1
2022-06-25 01:09:46,004 [grpc-default-executor-10] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-C104FB0CBEE5 replies to ELECTION vote request: ec2664f4-d768-4745-9abe-ef2a305e3ce9<-ee118b23-09e5-41f4-9121-1170bcf86bc2#0:FAIL-t1. Peer's state: ee118b23-09e5-41f4-9121-1170bcf86bc2@group-C104FB0CBEE5:t1, leader=null, voted=f368a730-3857-4d18-b0ff-e0c952296109, raftlog=ee118b23-09e5-41f4-9121-1170bcf86bc2@group-C104FB0CBEE5-SegmentedRaftLog:OPENED:c-1, conf=-1: [f368a730-3857-4d18-b0ff-e0c952296109|rpc:10.1.0.8:46119|dataStream:|priority:1, ee118b23-09e5-41f4-9121-1170bcf86bc2|rpc:10.1.0.8:39807|dataStream:|priority:0, ec2664f4-d768-4745-9abe-ef2a305e3ce9|rpc:10.1.0.8:41903|dataStream:|priority:0], old=null
2022-06-25 01:09:46,004 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2022-06-25 01:09:46,004 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:09:46,004 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:46,011 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2022-06-25 01:09:46,011 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:46,011 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2022-06-25 01:09:46,011 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2022-06-25 01:09:46,011 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:09:46,011 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:46,012 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - f368a730-3857-4d18-b0ff-e0c952296109: start f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderStateImpl
2022-06-25 01:09:46,013 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:46,015 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-0/data/ratis/4f5bb74b-936b-4e65-b29c-c104fb0cbee5/current/log_inprogress_0
2022-06-25 01:09:46,025 [f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LeaderElection190] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5: set configuration 0: [f368a730-3857-4d18-b0ff-e0c952296109|rpc:10.1.0.8:46119|dataStream:|priority:1, ee118b23-09e5-41f4-9121-1170bcf86bc2|rpc:10.1.0.8:39807|dataStream:|priority:0, ec2664f4-d768-4745-9abe-ef2a305e3ce9|rpc:10.1.0.8:41903|dataStream:|priority:0], old=null
2022-06-25 01:09:46,046 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1192)) - Container #1 is under replicated. Expected replica count is 3, but found 2.
2022-06-25 01:09:46,046 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1555)) - Sending replicate container command for container #1 to datanode 97d08340-a146-41c4-a759-b3b136c7fb6d{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=37711, RATIS=43169, RATIS_ADMIN=43169, RATIS_SERVER=43169, STANDALONE=44433], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-25 01:09:46,046 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1192)) - Container #2 is under replicated. Expected replica count is 3, but found 2.
2022-06-25 01:09:46,046 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1555)) - Sending replicate container command for container #2 to datanode 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43029, RATIS=44897, RATIS_ADMIN=44897, RATIS_SERVER=44897, STANDALONE=37333], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-25 01:09:46,046 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1192)) - Container #3 is under replicated. Expected replica count is 3, but found 2.
2022-06-25 01:09:46,046 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1555)) - Sending replicate container command for container #3 to datanode 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43029, RATIS=44897, RATIS_ADMIN=44897, RATIS_SERVER=44897, STANDALONE=37333], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-25 01:09:46,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-06-25 01:09:46,067 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=2b00854c-ae60-4259-8cdb-5f5be5f6e354 is not found
2022-06-25 01:09:46,143 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=2b00854c-ae60-4259-8cdb-5f5be5f6e354 is not found
2022-06-25 01:09:46,190 [grpc-default-executor-8] INFO  impl.VoteContext (VoteContext.java:log(48)) - f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-LEADER: reject ELECTION from ec2664f4-d768-4745-9abe-ef2a305e3ce9: already has voted for f368a730-3857-4d18-b0ff-e0c952296109 at current term 1
2022-06-25 01:09:46,190 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5 replies to ELECTION vote request: ec2664f4-d768-4745-9abe-ef2a305e3ce9<-f368a730-3857-4d18-b0ff-e0c952296109#0:FAIL-t1. Peer's state: f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5:t1, leader=f368a730-3857-4d18-b0ff-e0c952296109, voted=f368a730-3857-4d18-b0ff-e0c952296109, raftlog=f368a730-3857-4d18-b0ff-e0c952296109@group-C104FB0CBEE5-SegmentedRaftLog:OPENED:c0, conf=0: [f368a730-3857-4d18-b0ff-e0c952296109|rpc:10.1.0.8:46119|dataStream:|priority:1, ee118b23-09e5-41f4-9121-1170bcf86bc2|rpc:10.1.0.8:39807|dataStream:|priority:0, ec2664f4-d768-4745-9abe-ef2a305e3ce9|rpc:10.1.0.8:41903|dataStream:|priority:0], old=null
2022-06-25 01:09:46,270 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5-LeaderElection191] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5-LeaderElection191: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-06-25 01:09:46,270 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5-LeaderElection191] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: ec2664f4-d768-4745-9abe-ef2a305e3ce9<-f368a730-3857-4d18-b0ff-e0c952296109#0:FAIL-t1
2022-06-25 01:09:46,270 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5-LeaderElection191] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: ec2664f4-d768-4745-9abe-ef2a305e3ce9<-ee118b23-09e5-41f4-9121-1170bcf86bc2#0:FAIL-t1
2022-06-25 01:09:46,270 [ee118b23-09e5-41f4-9121-1170bcf86bc2-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-C104FB0CBEE5 with new leaderId: f368a730-3857-4d18-b0ff-e0c952296109
2022-06-25 01:09:46,270 [ee118b23-09e5-41f4-9121-1170bcf86bc2-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-C104FB0CBEE5: change Leader from null to f368a730-3857-4d18-b0ff-e0c952296109 at term 1 for appendEntries, leader elected after 5496ms
2022-06-25 01:09:46,275 [ec2664f4-d768-4745-9abe-ef2a305e3ce9-server-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5: changes role from CANDIDATE to FOLLOWER at term 1 for appendEntries
2022-06-25 01:09:46,275 [ec2664f4-d768-4745-9abe-ef2a305e3ce9-server-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9: shutdown ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5-LeaderElection191
2022-06-25 01:09:46,281 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5-LeaderElection191] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5-LeaderElection191 ELECTION round 0: result REJECTED
2022-06-25 01:09:46,285 [ee118b23-09e5-41f4-9121-1170bcf86bc2-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-C104FB0CBEE5: set configuration 0: [f368a730-3857-4d18-b0ff-e0c952296109|rpc:10.1.0.8:46119|dataStream:|priority:1, ee118b23-09e5-41f4-9121-1170bcf86bc2|rpc:10.1.0.8:39807|dataStream:|priority:0, ec2664f4-d768-4745-9abe-ef2a305e3ce9|rpc:10.1.0.8:41903|dataStream:|priority:0], old=null
2022-06-25 01:09:46,286 [ee118b23-09e5-41f4-9121-1170bcf86bc2-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-C104FB0CBEE5-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:46,287 [ec2664f4-d768-4745-9abe-ef2a305e3ce9-server-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9: start ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5-FollowerState
2022-06-25 01:09:46,287 [ec2664f4-d768-4745-9abe-ef2a305e3ce9-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-C104FB0CBEE5 with new leaderId: f368a730-3857-4d18-b0ff-e0c952296109
2022-06-25 01:09:46,288 [ec2664f4-d768-4745-9abe-ef2a305e3ce9-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5: change Leader from null to f368a730-3857-4d18-b0ff-e0c952296109 at term 1 for appendEntries, leader elected after 5861ms
2022-06-25 01:09:46,289 [ee118b23-09e5-41f4-9121-1170bcf86bc2@group-C104FB0CBEE5-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-C104FB0CBEE5-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-2/data/ratis/4f5bb74b-936b-4e65-b29c-c104fb0cbee5/current/log_inprogress_0
2022-06-25 01:09:46,305 [ec2664f4-d768-4745-9abe-ef2a305e3ce9-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5: set configuration 0: [f368a730-3857-4d18-b0ff-e0c952296109|rpc:10.1.0.8:46119|dataStream:|priority:1, ee118b23-09e5-41f4-9121-1170bcf86bc2|rpc:10.1.0.8:39807|dataStream:|priority:0, ec2664f4-d768-4745-9abe-ef2a305e3ce9|rpc:10.1.0.8:41903|dataStream:|priority:0], old=null
2022-06-25 01:09:46,306 [ec2664f4-d768-4745-9abe-ef2a305e3ce9-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:46,318 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-C104FB0CBEE5-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-1/data/ratis/4f5bb74b-936b-4e65-b29c-c104fb0cbee5/current/log_inprogress_0
2022-06-25 01:09:46,322 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: remove  FOLLOWER 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32:t8, leader=97d08340-a146-41c4-a759-b3b136c7fb6d, voted=97d08340-a146-41c4-a759-b3b136c7fb6d, raftlog=4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c0, conf=0: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null RUNNING
2022-06-25 01:09:46,322 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: shutdown
2022-06-25 01:09:46,322 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B6B9DF3CEF32,id=4943f96b-6a06-411a-b0ee-4ab66ab6f7f9
2022-06-25 01:09:46,322 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: shutdown 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState
2022-06-25 01:09:46,357 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-StateMachineUpdater: set stopIndex = 0
2022-06-25 01:09:46,357 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-FollowerState was interrupted
2022-06-25 01:09:46,358 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-B6B9DF3CEF32: Taking a snapshot at:(t:8, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data/ratis/1a613b2a-b322-4f7f-932c-b6b9df3cef32/sm/snapshot.8_0
2022-06-25 01:09:46,366 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-B6B9DF3CEF32: Finished taking a snapshot at:(t:8, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data/ratis/1a613b2a-b322-4f7f-932c-b6b9df3cef32/sm/snapshot.8_0 took: 8 ms
2022-06-25 01:09:46,366 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-StateMachineUpdater: Took a snapshot at index 0
2022-06-25 01:09:46,366 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-06-25 01:09:46,367 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(429)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: closes. applyIndex: 0
2022-06-25 01:09:46,368 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=1a613b2a-b322-4f7f-932c-b6b9df3cef32 is not found
2022-06-25 01:09:46,382 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-25 01:09:46,385 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32-SegmentedRaftLogWorker close()
2022-06-25 01:09:46,386 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(404)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-B6B9DF3CEF32: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data/ratis/1a613b2a-b322-4f7f-932c-b6b9df3cef32
2022-06-25 01:09:46,386 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=1a613b2a-b322-4f7f-932c-b6b9df3cef32 command on datanode 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9.
2022-06-25 01:09:46,405 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 2 from [3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-25 01:09:46,409 [grpc-default-executor-6] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(52)) - Streaming container data (2) to other datanode
2022-06-25 01:09:46,496 [ContainerReplicationThread-2] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 3 from [3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-25 01:09:46,498 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5069431388ns, electionTimeout:5054ms
2022-06-25 01:09:46,499 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9: shutdown ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-FollowerState
2022-06-25 01:09:46,499 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:09:46,499 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:46,499 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9: start ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-LeaderElection192
2022-06-25 01:09:46,504 [grpc-default-executor-8] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(52)) - Streaming container data (3) to other datanode
2022-06-25 01:09:46,595 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-LeaderElection192] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-LeaderElection192 ELECTION round 0: submit vote requests at term 1 for -1: [ec2664f4-d768-4745-9abe-ef2a305e3ce9|rpc:10.1.0.8:41903|priority:1], old=null
2022-06-25 01:09:46,595 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-LeaderElection192] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-LeaderElection192 ELECTION round 0: result PASSED (term=1)
2022-06-25 01:09:46,595 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-LeaderElection192] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9: shutdown ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-LeaderElection192
2022-06-25 01:09:46,595 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-LeaderElection192] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-06-25 01:09:46,595 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-LeaderElection192] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-75ABB1A65214 with new leaderId: ec2664f4-d768-4745-9abe-ef2a305e3ce9
2022-06-25 01:09:46,595 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-LeaderElection192] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214: change Leader from null to ec2664f4-d768-4745-9abe-ef2a305e3ce9 at term 1 for becomeLeader, leader elected after 5343ms
2022-06-25 01:09:46,595 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-LeaderElection192] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-25 01:09:46,596 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-LeaderElection192] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:46,596 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-LeaderElection192] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-06-25 01:09:46,597 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-LeaderElection192] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-06-25 01:09:46,597 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-LeaderElection192] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-25 01:09:46,597 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-LeaderElection192] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-25 01:09:46,597 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-LeaderElection192] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:46,597 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-LeaderElection192] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-25 01:09:46,597 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-LeaderElection192] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9: start ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-LeaderStateImpl
2022-06-25 01:09:46,598 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-LeaderElection192] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:46,604 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-1/data/ratis/8bbc5152-3491-4249-8acb-75abb1a65214/current/log_inprogress_0
2022-06-25 01:09:46,613 [ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214-LeaderElection192] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - ec2664f4-d768-4745-9abe-ef2a305e3ce9@group-75ABB1A65214: set configuration 0: [ec2664f4-d768-4745-9abe-ef2a305e3ce9|rpc:10.1.0.8:41903|dataStream:|priority:1], old=null
2022-06-25 01:09:46,637 [grpc-default-executor-6] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 20657 bytes for container 2
2022-06-25 01:09:46,676 [grpc-default-executor-8] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 20599 bytes for container 3
2022-06-25 01:09:46,711 [grpc-default-executor-6] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(197)) - Container 3 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data/replication/work/container-3.tar.gz
2022-06-25 01:09:46,740 [ContainerReplicationThread-2] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 3 is downloaded with size 20599, starting to import.
2022-06-25 01:09:46,754 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(580)) - Ozone container server stopped.
2022-06-25 01:09:46,767 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:46,777 [grpc-default-executor-5] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(197)) - Container 2 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data/replication/work/container-2.tar.gz
2022-06-25 01:09:46,802 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 2 is downloaded with size 20657, starting to import.
2022-06-25 01:09:46,810 [Listener at 127.0.0.1/44435] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Waiting for nodes to be ready. Got 5 of 6 DN Heartbeats.
2022-06-25 01:09:46,810 [Listener at 127.0.0.1/44435] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Cluster exits safe mode
2022-06-25 01:09:46,810 [Listener at 127.0.0.1/44435] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:09:46,846 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@612b3831{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-25 01:09:46,847 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@7c6f01e2{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-06-25 01:09:46,847 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-06-25 01:09:46,856 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 2 is replicated successfully
2022-06-25 01:09:46,856 [ContainerReplicationThread-1] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(176)) - Container 2 is replicated.
2022-06-25 01:09:46,864 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@2644ff79{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-06-25 01:09:46,870 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@303ff6b7{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-06-25 01:09:46,972 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:46,977 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 0414aa62-2593-4022-a495-25b345e9257d: addNew group-BEE07BCEC32E:[0414aa62-2593-4022-a495-25b345e9257d|rpc:10.1.0.8:40303|priority:1] returns group-BEE07BCEC32E:java.util.concurrent.CompletableFuture@25779766[Not completed]
2022-06-25 01:09:46,979 [pool-4762-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 0414aa62-2593-4022-a495-25b345e9257d: new RaftServerImpl for group-BEE07BCEC32E:[0414aa62-2593-4022-a495-25b345e9257d|rpc:10.1.0.8:40303|priority:1] with ContainerStateMachine:uninitialized
2022-06-25 01:09:46,980 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:09:46,980 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:09:46,980 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:46,980 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:46,980 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:46,980 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:46,980 [pool-4762-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E: ConfigurationManager, init=-1: [0414aa62-2593-4022-a495-25b345e9257d|rpc:10.1.0.8:40303|priority:1], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:46,980 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-4/data/ratis] (custom)
2022-06-25 01:09:46,980 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:46,982 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:46,982 [pool-4762-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-4/data/ratis/1cb91e0d-df45-4cda-93da-bee07bcec32e does not exist. Creating ...
2022-06-25 01:09:46,984 [pool-4762-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-4/data/ratis/1cb91e0d-df45-4cda-93da-bee07bcec32e/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:46,985 [IPC Server handler 15 on default port 44773] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/a26e6a85-69e0-4d1b-9fdc-0decb2cb6032
2022-06-25 01:09:46,985 [IPC Server handler 15 on default port 44773] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : a26e6a85-69e0-4d1b-9fdc-0decb2cb6032{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=38121, RATIS=45483, RATIS_ADMIN=45483, RATIS_SERVER=45483, STANDALONE=41583], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:09:46,986 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(275)) - trigger a one-shot run on RatisPipelineUtilsThread.
2022-06-25 01:09:46,986 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=07d3f442-d3a5-4cd2-b410-988b5cbffa1c to datanode:a26e6a85-69e0-4d1b-9fdc-0decb2cb6032
2022-06-25 01:09:46,987 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 07d3f442-d3a5-4cd2-b410-988b5cbffa1c, Nodes: a26e6a85-69e0-4d1b-9fdc-0decb2cb6032{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=38121, RATIS=45483, RATIS_ADMIN=45483, RATIS_SERVER=45483, STANDALONE=41583], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-25T01:09:46.986Z[Etc/UTC]].
2022-06-25 01:09:46,987 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=44a487e6-11a7-4ecb-9f21-06e54996bc4d to datanode:0414aa62-2593-4022-a495-25b345e9257d
2022-06-25 01:09:46,987 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=44a487e6-11a7-4ecb-9f21-06e54996bc4d to datanode:a26e6a85-69e0-4d1b-9fdc-0decb2cb6032
2022-06-25 01:09:46,987 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(195)) - Sending CreatePipelineCommand for pipeline:PipelineID=44a487e6-11a7-4ecb-9f21-06e54996bc4d to datanode:d233dd63-6533-4977-8487-4fe644b19e51
2022-06-25 01:09:46,987 [ContainerReplicationThread-2] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 3 is replicated successfully
2022-06-25 01:09:46,987 [ContainerReplicationThread-2] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(176)) - Container 3 is replicated.
2022-06-25 01:09:46,988 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(101)) - Created pipeline Pipeline[ Id: 44a487e6-11a7-4ecb-9f21-06e54996bc4d, Nodes: 0414aa62-2593-4022-a495-25b345e9257d{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43321, RATIS=40303, RATIS_ADMIN=40303, RATIS_SERVER=40303, STANDALONE=43699], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a26e6a85-69e0-4d1b-9fdc-0decb2cb6032{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=38121, RATIS=45483, RATIS_ADMIN=45483, RATIS_SERVER=45483, STANDALONE=41583], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d233dd63-6533-4977-8487-4fe644b19e51{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=38035, RATIS=43619, RATIS_ADMIN=43619, RATIS_SERVER=43619, STANDALONE=45827], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-25T01:09:46.987Z[Etc/UTC]].
2022-06-25 01:09:46,993 [Datanode State Machine Daemon Thread] WARN  statemachine.StateContext (StateContext.java:setState(252)) - Ignore disallowed transition from SHUTDOWN to RUNNING
2022-06-25 01:09:47,007 [pool-4762-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-4/data/ratis/1cb91e0d-df45-4cda-93da-bee07bcec32e has been successfully formatted.
2022-06-25 01:09:47,008 [pool-4762-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-BEE07BCEC32E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:09:47,008 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:09:47,008 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:47,008 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:47,008 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:47,008 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:47,009 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:47,010 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:47,011 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:47,011 [pool-4762-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-4/data/ratis/1cb91e0d-df45-4cda-93da-bee07bcec32e
2022-06-25 01:09:47,011 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:09:47,011 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:09:47,011 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:47,011 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:09:47,011 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:47,011 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:47,011 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:47,011 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:47,015 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:09:47,016 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:47,016 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:09:47,016 [pool-4762-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:47,016 [pool-4762-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:47,017 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:47,017 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:09:47,017 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:09:47,017 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:09:47,017 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:09:47,017 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:47,022 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:47,022 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:47,022 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:47,022 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:47,022 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:47,022 [pool-4762-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E: start as a follower, conf=-1: [0414aa62-2593-4022-a495-25b345e9257d|rpc:10.1.0.8:40303|priority:1], old=null
2022-06-25 01:09:47,022 [pool-4762-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:47,022 [pool-4762-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 0414aa62-2593-4022-a495-25b345e9257d: start 0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-FollowerState
2022-06-25 01:09:47,058 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(358)) - Pipeline Pipeline[ Id: 1cb91e0d-df45-4cda-93da-bee07bcec32e, Nodes: 0414aa62-2593-4022-a495-25b345e9257d{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43321, RATIS=40303, RATIS_ADMIN=40303, RATIS_SERVER=40303, STANDALONE=43699], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:0414aa62-2593-4022-a495-25b345e9257d, CreationTimestamp2022-06-25T01:09:43.951Z[Etc/UTC]] moved to OPEN state
2022-06-25 01:09:47,062 [pool-4762-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BEE07BCEC32E,id=0414aa62-2593-4022-a495-25b345e9257d
2022-06-25 01:09:47,064 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 15 milliseconds for processing 3 containers.
2022-06-25 01:09:47,069 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=1cb91e0d-df45-4cda-93da-bee07bcec32e
2022-06-25 01:09:47,069 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=1cb91e0d-df45-4cda-93da-bee07bcec32e.
2022-06-25 01:09:47,069 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 0414aa62-2593-4022-a495-25b345e9257d: addNew group-06E54996BC4D:[a26e6a85-69e0-4d1b-9fdc-0decb2cb6032|rpc:10.1.0.8:45483|priority:0, 0414aa62-2593-4022-a495-25b345e9257d|rpc:10.1.0.8:40303|priority:1, d233dd63-6533-4977-8487-4fe644b19e51|rpc:10.1.0.8:43619|priority:0] returns group-06E54996BC4D:java.util.concurrent.CompletableFuture@21481710[Not completed]
2022-06-25 01:09:47,070 [pool-4762-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - 0414aa62-2593-4022-a495-25b345e9257d: new RaftServerImpl for group-06E54996BC4D:[a26e6a85-69e0-4d1b-9fdc-0decb2cb6032|rpc:10.1.0.8:45483|priority:0, 0414aa62-2593-4022-a495-25b345e9257d|rpc:10.1.0.8:40303|priority:1, d233dd63-6533-4977-8487-4fe644b19e51|rpc:10.1.0.8:43619|priority:0] with ContainerStateMachine:uninitialized
2022-06-25 01:09:47,070 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:09:47,070 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:09:47,070 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:47,070 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:47,070 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:47,070 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:47,070 [pool-4762-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - 0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D: ConfigurationManager, init=-1: [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032|rpc:10.1.0.8:45483|priority:0, 0414aa62-2593-4022-a495-25b345e9257d|rpc:10.1.0.8:40303|priority:1, d233dd63-6533-4977-8487-4fe644b19e51|rpc:10.1.0.8:43619|priority:0], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:47,071 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-4/data/ratis] (custom)
2022-06-25 01:09:47,071 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:47,071 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:47,071 [pool-4762-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-4/data/ratis/44a487e6-11a7-4ecb-9f21-06e54996bc4d does not exist. Creating ...
2022-06-25 01:09:47,075 [pool-4762-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-4/data/ratis/44a487e6-11a7-4ecb-9f21-06e54996bc4d/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:47,078 [pool-4762-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-4/data/ratis/44a487e6-11a7-4ecb-9f21-06e54996bc4d has been successfully formatted.
2022-06-25 01:09:47,127 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-06-25 01:09:47,139 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - be67eb5e-e62d-4374-a142-8db592db20d7: remove  FOLLOWER be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354:t1, leader=null, voted=be67eb5e-e62d-4374-a142-8db592db20d7, raftlog=be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-SegmentedRaftLog:OPENED:c-1, conf=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|priority:0], old=null RUNNING
2022-06-25 01:09:47,139 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354: shutdown
2022-06-25 01:09:47,139 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-5F5BE5F6E354,id=be67eb5e-e62d-4374-a142-8db592db20d7
2022-06-25 01:09:47,139 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - be67eb5e-e62d-4374-a142-8db592db20d7: shutdown be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-FollowerState
2022-06-25 01:09:47,139 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-StateMachineUpdater: set stopIndex = -1
2022-06-25 01:09:47,140 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(429)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354: closes. applyIndex: -1
2022-06-25 01:09:47,140 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-25 01:09:47,140 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-SegmentedRaftLogWorker close()
2022-06-25 01:09:47,187 [pool-4762-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-06E54996BC4D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:09:47,187 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:09:47,187 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:47,187 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:47,187 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:47,187 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:47,188 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:47,189 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:47,189 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:47,190 [pool-4762-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new 0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-4/data/ratis/44a487e6-11a7-4ecb-9f21-06e54996bc4d
2022-06-25 01:09:47,190 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:09:47,190 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:09:47,190 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:47,190 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:09:47,190 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:47,190 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:47,190 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:47,190 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:47,205 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:09:47,206 [be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354-FollowerState was interrupted
2022-06-25 01:09:47,207 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(404)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-5F5BE5F6E354: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis/2b00854c-ae60-4259-8cdb-5f5be5f6e354
2022-06-25 01:09:47,207 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=2b00854c-ae60-4259-8cdb-5f5be5f6e354 command on datanode be67eb5e-e62d-4374-a142-8db592db20d7.
2022-06-25 01:09:47,250 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32->fc692a40-1ae9-40b7-8d63-7e46f51df1ef-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-06-25 01:09:47,251 [grpc-default-executor-5] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(111)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32->fc692a40-1ae9-40b7-8d63-7e46f51df1ef-GrpcLogAppender: Leader has not got in touch with Follower 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32->fc692a40-1ae9-40b7-8d63-7e46f51df1ef(c0,m0,n1, attendVote=true, lastRpcSendTime=0, lastRpcResponseTime=6491) yet, just keep nextIndex unchanged and retry.
2022-06-25 01:09:47,293 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:47,293 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:09:47,294 [pool-4762-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:47,294 [pool-4762-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:47,295 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:47,295 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:09:47,295 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:09:47,296 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:09:47,296 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:09:47,296 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:47,334 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:47,390 [ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5088503765ns, electionTimeout:5069ms
2022-06-25 01:09:47,377 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=1a613b2a-b322-4f7f-932c-b6b9df3cef32 is not found
2022-06-25 01:09:47,370 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: remove    LEADER 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32:t8, leader=97d08340-a146-41c4-a759-b3b136c7fb6d, voted=97d08340-a146-41c4-a759-b3b136c7fb6d, raftlog=97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-SegmentedRaftLog:OPENED:c0, conf=0: [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9|rpc:10.1.0.8:44897|dataStream:|priority:0, 97d08340-a146-41c4-a759-b3b136c7fb6d|rpc:10.1.0.8:43169|dataStream:|priority:1, fc692a40-1ae9-40b7-8d63-7e46f51df1ef|rpc:10.1.0.8:39343|dataStream:|priority:0], old=null RUNNING
2022-06-25 01:09:47,442 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: shutdown
2022-06-25 01:09:47,443 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B6B9DF3CEF32,id=97d08340-a146-41c4-a759-b3b136c7fb6d
2022-06-25 01:09:47,443 [ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - ee118b23-09e5-41f4-9121-1170bcf86bc2: shutdown ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-FollowerState
2022-06-25 01:09:47,443 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: shutdown 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-LeaderStateImpl
2022-06-25 01:09:47,443 [ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:09:47,443 [ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:47,443 [ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ee118b23-09e5-41f4-9121-1170bcf86bc2: start ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-LeaderElection193
2022-06-25 01:09:47,443 [Command processor thread] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-PendingRequests: sendNotLeaderResponses
2022-06-25 01:09:47,443 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:47,443 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:47,443 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:47,443 [pool-4762-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:47,443 [pool-4762-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - 0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D: start as a follower, conf=-1: [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032|rpc:10.1.0.8:45483|priority:0, 0414aa62-2593-4022-a495-25b345e9257d|rpc:10.1.0.8:40303|priority:1, d233dd63-6533-4977-8487-4fe644b19e51|rpc:10.1.0.8:43619|priority:0], old=null
2022-06-25 01:09:47,443 [pool-4762-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:47,444 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-StateMachineUpdater: set stopIndex = 0
2022-06-25 01:09:47,445 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-B6B9DF3CEF32: Taking a snapshot at:(t:8, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data/ratis/1a613b2a-b322-4f7f-932c-b6b9df3cef32/sm/snapshot.8_0
2022-06-25 01:09:47,446 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-B6B9DF3CEF32: Finished taking a snapshot at:(t:8, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data/ratis/1a613b2a-b322-4f7f-932c-b6b9df3cef32/sm/snapshot.8_0 took: 1 ms
2022-06-25 01:09:47,446 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-StateMachineUpdater: Took a snapshot at index 0
2022-06-25 01:09:47,446 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-06-25 01:09:47,447 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(429)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: closes. applyIndex: 0
2022-06-25 01:09:47,470 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32->4943f96b-6a06-411a-b0ee-4ab66ab6f7f9-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(171)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32->4943f96b-6a06-411a-b0ee-4ab66ab6f7f9-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2022-06-25 01:09:47,471 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(140)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: Completed APPEND_ENTRIES, lastRequest: 97d08340-a146-41c4-a759-b3b136c7fb6d->4943f96b-6a06-411a-b0ee-4ab66ab6f7f9#1-t8,previous=(t:0, i:0),leaderCommit=-1,initializing? true,entries: size=1, first=(t:8, i:0), CONFIGURATIONENTRY
2022-06-25 01:09:47,472 [grpc-default-executor-8] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(339)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32->4943f96b-6a06-411a-b0ee-4ab66ab6f7f9-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2022-06-25 01:09:47,472 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32->4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: nextIndex: updateUnconditionally 1 -> 0
2022-06-25 01:09:47,527 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-25 01:09:47,528 [pool-4762-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 0414aa62-2593-4022-a495-25b345e9257d: start 0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-FollowerState
2022-06-25 01:09:47,528 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32-SegmentedRaftLogWorker close()
2022-06-25 01:09:47,529 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(404)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-B6B9DF3CEF32: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data/ratis/1a613b2a-b322-4f7f-932c-b6b9df3cef32
2022-06-25 01:09:47,529 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=1a613b2a-b322-4f7f-932c-b6b9df3cef32 command on datanode 97d08340-a146-41c4-a759-b3b136c7fb6d.
2022-06-25 01:09:47,539 [ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-LeaderElection193] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-LeaderElection193 ELECTION round 0: submit vote requests at term 1 for -1: [ee118b23-09e5-41f4-9121-1170bcf86bc2|rpc:10.1.0.8:39807|priority:1], old=null
2022-06-25 01:09:47,539 [ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-LeaderElection193] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-LeaderElection193 ELECTION round 0: result PASSED (term=1)
2022-06-25 01:09:47,539 [ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-LeaderElection193] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - ee118b23-09e5-41f4-9121-1170bcf86bc2: shutdown ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-LeaderElection193
2022-06-25 01:09:47,539 [ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-LeaderElection193] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-06-25 01:09:47,539 [ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-LeaderElection193] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-3BB803B7D89D with new leaderId: ee118b23-09e5-41f4-9121-1170bcf86bc2
2022-06-25 01:09:47,568 [pool-4762-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-06E54996BC4D,id=0414aa62-2593-4022-a495-25b345e9257d
2022-06-25 01:09:47,570 [ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-LeaderElection193] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D: change Leader from null to ee118b23-09e5-41f4-9121-1170bcf86bc2 at term 1 for becomeLeader, leader elected after 5287ms
2022-06-25 01:09:47,570 [ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-LeaderElection193] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-25 01:09:47,570 [ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-LeaderElection193] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:47,570 [ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-LeaderElection193] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-06-25 01:09:47,571 [ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-LeaderElection193] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-06-25 01:09:47,572 [ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-LeaderElection193] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-25 01:09:47,572 [ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-LeaderElection193] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-25 01:09:47,572 [ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-LeaderElection193] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:47,572 [ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-LeaderElection193] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-25 01:09:47,572 [ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-LeaderElection193] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ee118b23-09e5-41f4-9121-1170bcf86bc2: start ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-LeaderStateImpl
2022-06-25 01:09:47,572 [ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-LeaderElection193] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:47,573 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=44a487e6-11a7-4ecb-9f21-06e54996bc4d
2022-06-25 01:09:47,578 [ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-2/data/ratis/2062d5a7-3c35-4dd5-8ec9-3bb803b7d89d/current/log_inprogress_0
2022-06-25 01:09:47,584 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 1 from [be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-25 01:09:47,586 [grpc-default-executor-5] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032: addNew group-06E54996BC4D:[a26e6a85-69e0-4d1b-9fdc-0decb2cb6032|rpc:10.1.0.8:45483|dataStream:|priority:0, 0414aa62-2593-4022-a495-25b345e9257d|rpc:10.1.0.8:40303|dataStream:|priority:1, d233dd63-6533-4977-8487-4fe644b19e51|rpc:10.1.0.8:43619|dataStream:|priority:0] returns group-06E54996BC4D:java.util.concurrent.CompletableFuture@4c974c34[Not completed]
2022-06-25 01:09:47,590 [ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D-LeaderElection193] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - ee118b23-09e5-41f4-9121-1170bcf86bc2@group-3BB803B7D89D: set configuration 0: [ee118b23-09e5-41f4-9121-1170bcf86bc2|rpc:10.1.0.8:39807|dataStream:|priority:1], old=null
2022-06-25 01:09:47,691 [pool-4797-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032: new RaftServerImpl for group-06E54996BC4D:[a26e6a85-69e0-4d1b-9fdc-0decb2cb6032|rpc:10.1.0.8:45483|dataStream:|priority:0, 0414aa62-2593-4022-a495-25b345e9257d|rpc:10.1.0.8:40303|dataStream:|priority:1, d233dd63-6533-4977-8487-4fe644b19e51|rpc:10.1.0.8:43619|dataStream:|priority:0] with ContainerStateMachine:uninitialized
2022-06-25 01:09:47,691 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:09:47,691 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:09:47,691 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:47,691 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:47,691 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:47,691 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:47,691 [pool-4797-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-06E54996BC4D: ConfigurationManager, init=-1: [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032|rpc:10.1.0.8:45483|dataStream:|priority:0, 0414aa62-2593-4022-a495-25b345e9257d|rpc:10.1.0.8:40303|dataStream:|priority:1, d233dd63-6533-4977-8487-4fe644b19e51|rpc:10.1.0.8:43619|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:47,691 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-5/data/ratis] (custom)
2022-06-25 01:09:47,691 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:47,691 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:47,692 [pool-4797-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-5/data/ratis/44a487e6-11a7-4ecb-9f21-06e54996bc4d does not exist. Creating ...
2022-06-25 01:09:47,694 [grpc-default-executor-5] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(52)) - Streaming container data (1) to other datanode
2022-06-25 01:09:47,700 [pool-4797-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-5/data/ratis/44a487e6-11a7-4ecb-9f21-06e54996bc4d/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:47,702 [pool-4797-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-5/data/ratis/44a487e6-11a7-4ecb-9f21-06e54996bc4d has been successfully formatted.
2022-06-25 01:09:47,702 [pool-4797-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-06E54996BC4D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:09:47,703 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:09:47,703 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:47,703 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:47,703 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:47,703 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:47,703 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:47,705 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:47,705 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:47,705 [pool-4797-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-06E54996BC4D-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-5/data/ratis/44a487e6-11a7-4ecb-9f21-06e54996bc4d
2022-06-25 01:09:47,705 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:09:47,705 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:09:47,705 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:47,705 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:09:47,705 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:47,705 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:47,705 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:47,705 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:47,714 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:09:47,741 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:47,742 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:09:47,742 [pool-4797-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-06E54996BC4D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:47,742 [pool-4797-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-06E54996BC4D-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:47,764 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:47,764 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:09:47,764 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:09:47,765 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:09:47,765 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:09:47,765 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:47,767 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:47,781 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:47,781 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:47,781 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:47,781 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:47,781 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:47,781 [pool-4797-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-06E54996BC4D: start as a follower, conf=-1: [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032|rpc:10.1.0.8:45483|dataStream:|priority:0, 0414aa62-2593-4022-a495-25b345e9257d|rpc:10.1.0.8:40303|dataStream:|priority:1, d233dd63-6533-4977-8487-4fe644b19e51|rpc:10.1.0.8:43619|dataStream:|priority:0], old=null
2022-06-25 01:09:47,781 [pool-4797-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-06E54996BC4D: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:47,781 [pool-4797-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032: start a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-06E54996BC4D-FollowerState
2022-06-25 01:09:47,804 [pool-4797-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-06E54996BC4D,id=a26e6a85-69e0-4d1b-9fdc-0decb2cb6032
2022-06-25 01:09:47,811 [Listener at 127.0.0.1/44435] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - Nodes are ready. Got 6 of 6 DN Heartbeats.
2022-06-25 01:09:47,811 [Listener at 127.0.0.1/44435] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(226)) - Cluster exits safe mode
2022-06-25 01:09:47,811 [Listener at 127.0.0.1/44435] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(228)) - SCM became leader
2022-06-25 01:09:47,865 [grpc-default-executor-6] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - d233dd63-6533-4977-8487-4fe644b19e51: addNew group-06E54996BC4D:[a26e6a85-69e0-4d1b-9fdc-0decb2cb6032|rpc:10.1.0.8:45483|dataStream:|priority:0, 0414aa62-2593-4022-a495-25b345e9257d|rpc:10.1.0.8:40303|dataStream:|priority:1, d233dd63-6533-4977-8487-4fe644b19e51|rpc:10.1.0.8:43619|dataStream:|priority:0] returns group-06E54996BC4D:java.util.concurrent.CompletableFuture@6b73932[Not completed]
2022-06-25 01:09:47,865 [pool-4731-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - d233dd63-6533-4977-8487-4fe644b19e51: new RaftServerImpl for group-06E54996BC4D:[a26e6a85-69e0-4d1b-9fdc-0decb2cb6032|rpc:10.1.0.8:45483|dataStream:|priority:0, 0414aa62-2593-4022-a495-25b345e9257d|rpc:10.1.0.8:40303|dataStream:|priority:1, d233dd63-6533-4977-8487-4fe644b19e51|rpc:10.1.0.8:43619|dataStream:|priority:0] with ContainerStateMachine:uninitialized
2022-06-25 01:09:47,866 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:09:47,866 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:09:47,866 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:47,866 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:47,866 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:47,866 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:47,866 [pool-4731-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - d233dd63-6533-4977-8487-4fe644b19e51@group-06E54996BC4D: ConfigurationManager, init=-1: [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032|rpc:10.1.0.8:45483|dataStream:|priority:0, 0414aa62-2593-4022-a495-25b345e9257d|rpc:10.1.0.8:40303|dataStream:|priority:1, d233dd63-6533-4977-8487-4fe644b19e51|rpc:10.1.0.8:43619|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:47,866 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-3/data/ratis] (custom)
2022-06-25 01:09:47,866 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:47,866 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:47,866 [pool-4731-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-3/data/ratis/44a487e6-11a7-4ecb-9f21-06e54996bc4d does not exist. Creating ...
2022-06-25 01:09:47,868 [pool-4731-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-3/data/ratis/44a487e6-11a7-4ecb-9f21-06e54996bc4d/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:47,870 [pool-4731-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-3/data/ratis/44a487e6-11a7-4ecb-9f21-06e54996bc4d has been successfully formatted.
2022-06-25 01:09:47,870 [pool-4731-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-06E54996BC4D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:09:47,871 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:09:47,871 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:47,872 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:47,872 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:47,872 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:47,872 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:47,899 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:47,899 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:47,900 [pool-4731-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new d233dd63-6533-4977-8487-4fe644b19e51@group-06E54996BC4D-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-3/data/ratis/44a487e6-11a7-4ecb-9f21-06e54996bc4d
2022-06-25 01:09:47,900 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:09:47,900 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:09:47,900 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:47,900 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:09:47,900 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:47,900 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:47,900 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:47,900 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:47,939 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032: addNew group-988B5CBFFA1C:[a26e6a85-69e0-4d1b-9fdc-0decb2cb6032|rpc:10.1.0.8:45483|priority:1] returns group-988B5CBFFA1C:java.util.concurrent.CompletableFuture@90b02a2[Not completed]
2022-06-25 01:09:47,940 [pool-4797-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(190)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032: new RaftServerImpl for group-988B5CBFFA1C:[a26e6a85-69e0-4d1b-9fdc-0decb2cb6032|rpc:10.1.0.8:45483|priority:1] with ContainerStateMachine:uninitialized
2022-06-25 01:09:47,940 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2022-06-25 01:09:47,940 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2022-06-25 01:09:47,940 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2022-06-25 01:09:47,940 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2022-06-25 01:09:47,940 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2022-06-25 01:09:47,940 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2022-06-25 01:09:47,940 [pool-4797-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(107)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C: ConfigurationManager, init=-1: [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032|rpc:10.1.0.8:45483|priority:1], old=null, confs=<EMPTY_MAP>
2022-06-25 01:09:47,940 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-5/data/ratis] (custom)
2022-06-25 01:09:47,940 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2022-06-25 01:09:47,941 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2022-06-25 01:09:47,941 [pool-4797-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(135)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-5/data/ratis/07d3f442-d3a5-4cd2-b410-988b5cbffa1c does not exist. Creating ...
2022-06-25 01:09:47,943 [pool-4797-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(230)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-5/data/ratis/07d3f442-d3a5-4cd2-b410-988b5cbffa1c/in_use.lock acquired by nodename 7033@fv-az66-546
2022-06-25 01:09:47,945 [pool-4797-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(89)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-5/data/ratis/07d3f442-d3a5-4cd2-b410-988b5cbffa1c has been successfully formatted.
2022-06-25 01:09:47,946 [pool-4797-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(236)) - group-988B5CBFFA1C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2022-06-25 01:09:47,946 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2022-06-25 01:09:47,946 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2022-06-25 01:09:47,946 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2022-06-25 01:09:47,946 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:47,946 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2022-06-25 01:09:47,946 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:47,948 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2022-06-25 01:09:47,948 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2022-06-25 01:09:47,948 [pool-4797-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(187)) - new a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-5/data/ratis/07d3f442-d3a5-4cd2-b410-988b5cbffa1c
2022-06-25 01:09:47,948 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2022-06-25 01:09:47,948 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2022-06-25 01:09:47,948 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2022-06-25 01:09:47,948 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2022-06-25 01:09:47,948 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2022-06-25 01:09:47,948 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2022-06-25 01:09:47,948 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2022-06-25 01:09:47,949 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2022-06-25 01:09:47,949 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(358)) - Pipeline Pipeline[ Id: 07d3f442-d3a5-4cd2-b410-988b5cbffa1c, Nodes: a26e6a85-69e0-4d1b-9fdc-0decb2cb6032{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=38121, RATIS=45483, RATIS_ADMIN=45483, RATIS_SERVER=45483, STANDALONE=41583], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:a26e6a85-69e0-4d1b-9fdc-0decb2cb6032, CreationTimestamp2022-06-25T01:09:46.986Z[Etc/UTC]] moved to OPEN state
2022-06-25 01:09:47,960 [grpc-default-executor-5] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 20576 bytes for container 1
2022-06-25 01:09:47,964 [grpc-default-executor-6] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(197)) - Container 1 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data/replication/work/container-1.tar.gz
2022-06-25 01:09:47,970 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 1 is downloaded with size 20576, starting to import.
2022-06-25 01:09:47,973 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:48,032 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:09:48,032 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2022-06-25 01:09:48,033 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:48,033 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:09:48,033 [pool-4731-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - d233dd63-6533-4977-8487-4fe644b19e51@group-06E54996BC4D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:48,033 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2022-06-25 01:09:48,033 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2022-06-25 01:09:48,034 [pool-4797-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:48,034 [pool-4797-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:48,034 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:48,034 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:09:48,034 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:09:48,034 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:09:48,034 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:09:48,034 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:48,039 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:48,039 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:48,039 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:48,039 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:48,039 [pool-4797-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:48,039 [pool-4797-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C: start as a follower, conf=-1: [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032|rpc:10.1.0.8:45483|priority:1], old=null
2022-06-25 01:09:48,039 [pool-4797-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:48,039 [pool-4797-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032: start a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-FollowerState
2022-06-25 01:09:48,040 [pool-4797-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-988B5CBFFA1C,id=a26e6a85-69e0-4d1b-9fdc-0decb2cb6032
2022-06-25 01:09:48,041 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(765)) - Created group PipelineID=07d3f442-d3a5-4cd2-b410-988b5cbffa1c
2022-06-25 01:09:48,041 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=07d3f442-d3a5-4cd2-b410-988b5cbffa1c.
2022-06-25 01:09:48,033 [pool-4731-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - d233dd63-6533-4977-8487-4fe644b19e51@group-06E54996BC4D-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2022-06-25 01:09:48,062 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=2b00854c-ae60-4259-8cdb-5f5be5f6e354 is not found
2022-06-25 01:09:48,064 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: remove  FOLLOWER 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354:t1, leader=null, voted=3c6128f4-7bf2-4a55-83fb-21add5186158, raftlog=3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-SegmentedRaftLog:OPENED:c-1, conf=-1: [be67eb5e-e62d-4374-a142-8db592db20d7|rpc:10.1.0.8:39697|priority:0, 09e3cf2b-0c88-4e70-981b-9e7ba4aeefaf|rpc:10.1.0.8:39033|priority:1, 3c6128f4-7bf2-4a55-83fb-21add5186158|rpc:10.1.0.8:46801|priority:0], old=null RUNNING
2022-06-25 01:09:48,064 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354: shutdown
2022-06-25 01:09:48,064 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-5F5BE5F6E354,id=3c6128f4-7bf2-4a55-83fb-21add5186158
2022-06-25 01:09:48,064 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: shutdown 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-FollowerState
2022-06-25 01:09:48,065 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:48,082 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-StateMachineUpdater: set stopIndex = -1
2022-06-25 01:09:48,082 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-FollowerState was interrupted
2022-06-25 01:09:48,086 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(429)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354: closes. applyIndex: -1
2022-06-25 01:09:48,090 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2022-06-25 01:09:48,090 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2022-06-25 01:09:48,090 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2022-06-25 01:09:48,090 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2022-06-25 01:09:48,091 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2022-06-25 01:09:48,091 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100Î¼s (default)
2022-06-25 01:09:48,096 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:48,096 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2022-06-25 01:09:48,097 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2022-06-25 01:09:48,097 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2022-06-25 01:09:48,097 [pool-4731-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2022-06-25 01:09:48,097 [pool-4731-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(310)) - d233dd63-6533-4977-8487-4fe644b19e51@group-06E54996BC4D: start as a follower, conf=-1: [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032|rpc:10.1.0.8:45483|dataStream:|priority:0, 0414aa62-2593-4022-a495-25b345e9257d|rpc:10.1.0.8:40303|dataStream:|priority:1, d233dd63-6533-4977-8487-4fe644b19e51|rpc:10.1.0.8:43619|dataStream:|priority:0], old=null
2022-06-25 01:09:48,097 [pool-4731-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - d233dd63-6533-4977-8487-4fe644b19e51@group-06E54996BC4D: changes role from      null to FOLLOWER at term 0 for startAsFollower
2022-06-25 01:09:48,115 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-25 01:09:48,115 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354-SegmentedRaftLogWorker close()
2022-06-25 01:09:48,125 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(404)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-5F5BE5F6E354: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data/ratis/2b00854c-ae60-4259-8cdb-5f5be5f6e354
2022-06-25 01:09:48,125 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=2b00854c-ae60-4259-8cdb-5f5be5f6e354 command on datanode 3c6128f4-7bf2-4a55-83fb-21add5186158.
2022-06-25 01:09:48,206 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 1 is replicated successfully
2022-06-25 01:09:48,206 [ContainerReplicationThread-1] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(176)) - Container 1 is replicated.
2022-06-25 01:09:48,206 [pool-4731-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d233dd63-6533-4977-8487-4fe644b19e51: start d233dd63-6533-4977-8487-4fe644b19e51@group-06E54996BC4D-FollowerState
2022-06-25 01:09:48,230 [pool-4731-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-06E54996BC4D,id=d233dd63-6533-4977-8487-4fe644b19e51
2022-06-25 01:09:48,244 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=44a487e6-11a7-4ecb-9f21-06e54996bc4d.
2022-06-25 01:09:48,768 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(228)) - Replication Manager is not ready to run until 3000ms after safemode exit
2022-06-25 01:09:48,973 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:49,065 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:49,543 [d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5085711357ns, electionTimeout:5078ms
2022-06-25 01:09:49,544 [d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - d233dd63-6533-4977-8487-4fe644b19e51: shutdown d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-FollowerState
2022-06-25 01:09:49,544 [d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:09:49,544 [d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:49,544 [d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d233dd63-6533-4977-8487-4fe644b19e51: start d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-LeaderElection194
2022-06-25 01:09:49,714 [d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-LeaderElection194] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-LeaderElection194 ELECTION round 0: submit vote requests at term 1 for -1: [d233dd63-6533-4977-8487-4fe644b19e51|rpc:10.1.0.8:43619|priority:1], old=null
2022-06-25 01:09:49,714 [d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-LeaderElection194] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-LeaderElection194 ELECTION round 0: result PASSED (term=1)
2022-06-25 01:09:49,714 [d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-LeaderElection194] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - d233dd63-6533-4977-8487-4fe644b19e51: shutdown d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-LeaderElection194
2022-06-25 01:09:49,714 [d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-LeaderElection194] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-06-25 01:09:49,714 [d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-LeaderElection194] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-AD647EB92D8E with new leaderId: d233dd63-6533-4977-8487-4fe644b19e51
2022-06-25 01:09:49,714 [d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-LeaderElection194] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E: change Leader from null to d233dd63-6533-4977-8487-4fe644b19e51 at term 1 for becomeLeader, leader elected after 5384ms
2022-06-25 01:09:49,714 [d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-LeaderElection194] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-25 01:09:49,715 [d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-LeaderElection194] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:49,715 [d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-LeaderElection194] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-06-25 01:09:49,716 [d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-LeaderElection194] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-06-25 01:09:49,716 [d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-LeaderElection194] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-25 01:09:49,716 [d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-LeaderElection194] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-25 01:09:49,716 [d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-LeaderElection194] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:49,716 [d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-LeaderElection194] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-25 01:09:49,716 [d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-LeaderElection194] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d233dd63-6533-4977-8487-4fe644b19e51: start d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-LeaderStateImpl
2022-06-25 01:09:49,720 [d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-LeaderElection194] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:49,728 [d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-3/data/ratis/f2ef78ee-d67e-486b-bc60-ad647eb92d8e/current/log_inprogress_0
2022-06-25 01:09:49,751 [d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E-LeaderElection194] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - d233dd63-6533-4977-8487-4fe644b19e51@group-AD647EB92D8E: set configuration 0: [d233dd63-6533-4977-8487-4fe644b19e51|rpc:10.1.0.8:43619|dataStream:|priority:1], old=null
2022-06-25 01:09:49,768 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:49,974 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:50,065 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:50,073 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43029, RATIS=44897, RATIS_ADMIN=44897, RATIS_SERVER=44897, STANDALONE=37333], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=b31a673a-3cb5-496f-b87f-d427a30f5985]
2022-06-25 01:09:50,073 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(432)) - Pipeline Pipeline[ Id: b31a673a-3cb5-496f-b87f-d427a30f5985, Nodes: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43029, RATIS=44897, RATIS_ADMIN=44897, RATIS_SERVER=44897, STANDALONE=37333], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:4943f96b-6a06-411a-b0ee-4ab66ab6f7f9, CreationTimestamp2022-06-25T01:08:47.549Z[Etc/UTC]] moved to CLOSED state
2022-06-25 01:09:50,289 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(580)) - Ozone container server stopped.
2022-06-25 01:09:50,457 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@19ac7358{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-25 01:09:50,469 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@18e05852{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-06-25 01:09:50,469 [ForkJoinPool.commonPool-worker-0] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-06-25 01:09:50,478 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@5f16a448{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-06-25 01:09:50,478 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@69d956ec{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-06-25 01:09:50,770 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:50,975 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:51,066 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:51,770 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:51,981 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:51,998 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(365)) - Attempting to stop container services.
2022-06-25 01:09:52,008 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$7(398)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: close
2022-06-25 01:09:52,008 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985: shutdown
2022-06-25 01:09:52,008 [Mini-Cluster-Provider-Reap] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D427A30F5985,id=4943f96b-6a06-411a-b0ee-4ab66ab6f7f9
2022-06-25 01:09:52,008 [Mini-Cluster-Provider-Reap] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: shutdown 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-LeaderStateImpl
2022-06-25 01:09:52,009 [Mini-Cluster-Provider-Reap] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-PendingRequests: sendNotLeaderResponses
2022-06-25 01:09:52,012 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-D427A30F5985: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data/ratis/b31a673a-3cb5-496f-b87f-d427a30f5985/sm/snapshot.1_0
2022-06-25 01:09:52,012 [Mini-Cluster-Provider-Reap] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-StateMachineUpdater: set stopIndex = 0
2022-06-25 01:09:52,013 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-D427A30F5985: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-5/data/ratis/b31a673a-3cb5-496f-b87f-d427a30f5985/sm/snapshot.1_0 took: 2 ms
2022-06-25 01:09:52,014 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-StateMachineUpdater: Took a snapshot at index 0
2022-06-25 01:09:52,014 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-06-25 01:09:52,030 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (ServerState.java:close(429)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985: closes. applyIndex: 0
2022-06-25 01:09:52,034 [4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-25 01:09:52,046 [Mini-Cluster-Provider-Reap] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9@group-D427A30F5985-SegmentedRaftLogWorker close()
2022-06-25 01:09:52,052 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(269)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: shutdown server with port 44897 now
2022-06-25 01:09:52,060 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(278)) - 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: shutdown server with port 44897 successfully
2022-06-25 01:09:52,060 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@1067788d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-4943f96b-6a06-411a-b0ee-4ab66ab6f7f9: Stopped
2022-06-25 01:09:52,066 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:52,109 [0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5086943164ns, electionTimeout:5044ms
2022-06-25 01:09:52,110 [0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 0414aa62-2593-4022-a495-25b345e9257d: shutdown 0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-FollowerState
2022-06-25 01:09:52,110 [0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:09:52,110 [0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:52,110 [0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 0414aa62-2593-4022-a495-25b345e9257d: start 0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-LeaderElection195
2022-06-25 01:09:52,144 [0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-LeaderElection195] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-LeaderElection195 ELECTION round 0: submit vote requests at term 1 for -1: [0414aa62-2593-4022-a495-25b345e9257d|rpc:10.1.0.8:40303|priority:1], old=null
2022-06-25 01:09:52,144 [0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-LeaderElection195] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-LeaderElection195 ELECTION round 0: result PASSED (term=1)
2022-06-25 01:09:52,144 [0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-LeaderElection195] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 0414aa62-2593-4022-a495-25b345e9257d: shutdown 0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-LeaderElection195
2022-06-25 01:09:52,144 [0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-LeaderElection195] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-06-25 01:09:52,144 [0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-LeaderElection195] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-BEE07BCEC32E with new leaderId: 0414aa62-2593-4022-a495-25b345e9257d
2022-06-25 01:09:52,145 [0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-LeaderElection195] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E: change Leader from null to 0414aa62-2593-4022-a495-25b345e9257d at term 1 for becomeLeader, leader elected after 5136ms
2022-06-25 01:09:52,145 [0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-LeaderElection195] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-25 01:09:52,145 [0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-LeaderElection195] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:52,145 [0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-LeaderElection195] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-06-25 01:09:52,147 [0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-LeaderElection195] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-06-25 01:09:52,147 [0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-LeaderElection195] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-25 01:09:52,147 [0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-LeaderElection195] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-25 01:09:52,147 [0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-LeaderElection195] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:52,147 [0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-LeaderElection195] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-25 01:09:52,147 [0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-LeaderElection195] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 0414aa62-2593-4022-a495-25b345e9257d: start 0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-LeaderStateImpl
2022-06-25 01:09:52,148 [0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-LeaderElection195] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:52,149 [0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-LeaderElection195] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E: set configuration 0: [0414aa62-2593-4022-a495-25b345e9257d|rpc:10.1.0.8:40303|dataStream:|priority:1], old=null
2022-06-25 01:09:52,150 [0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 0414aa62-2593-4022-a495-25b345e9257d@group-BEE07BCEC32E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-4/data/ratis/1cb91e0d-df45-4cda-93da-bee07bcec32e/current/log_inprogress_0
2022-06-25 01:09:52,575 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5047120107ns, electionTimeout:5005ms
2022-06-25 01:09:52,575 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 0414aa62-2593-4022-a495-25b345e9257d: shutdown 0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-FollowerState
2022-06-25 01:09:52,575 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:09:52,576 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:52,576 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 0414aa62-2593-4022-a495-25b345e9257d: start 0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196
2022-06-25 01:09:52,663 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196 ELECTION round 0: submit vote requests at term 1 for -1: [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032|rpc:10.1.0.8:45483|priority:0, 0414aa62-2593-4022-a495-25b345e9257d|rpc:10.1.0.8:40303|priority:1, d233dd63-6533-4977-8487-4fe644b19e51|rpc:10.1.0.8:43619|priority:0], old=null
2022-06-25 01:09:52,690 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-06E54996BC4D: receive requestVote(ELECTION, 0414aa62-2593-4022-a495-25b345e9257d, group-06E54996BC4D, 1, (t:0, i:0))
2022-06-25 01:09:52,690 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-06E54996BC4D-FOLLOWER: accept ELECTION from 0414aa62-2593-4022-a495-25b345e9257d: our priority 0 <= candidate's priority 1
2022-06-25 01:09:52,690 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-06E54996BC4D: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:0414aa62-2593-4022-a495-25b345e9257d
2022-06-25 01:09:52,690 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032: shutdown a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-06E54996BC4D-FollowerState
2022-06-25 01:09:52,690 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032: start a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-06E54996BC4D-FollowerState
2022-06-25 01:09:52,696 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-06E54996BC4D-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-06E54996BC4D-FollowerState was interrupted
2022-06-25 01:09:52,709 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - d233dd63-6533-4977-8487-4fe644b19e51@group-06E54996BC4D: receive requestVote(ELECTION, 0414aa62-2593-4022-a495-25b345e9257d, group-06E54996BC4D, 1, (t:0, i:0))
2022-06-25 01:09:52,709 [grpc-default-executor-8] INFO  impl.VoteContext (VoteContext.java:log(48)) - d233dd63-6533-4977-8487-4fe644b19e51@group-06E54996BC4D-FOLLOWER: accept ELECTION from 0414aa62-2593-4022-a495-25b345e9257d: our priority 0 <= candidate's priority 1
2022-06-25 01:09:52,709 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - d233dd63-6533-4977-8487-4fe644b19e51@group-06E54996BC4D: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:0414aa62-2593-4022-a495-25b345e9257d
2022-06-25 01:09:52,709 [grpc-default-executor-8] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - d233dd63-6533-4977-8487-4fe644b19e51: shutdown d233dd63-6533-4977-8487-4fe644b19e51@group-06E54996BC4D-FollowerState
2022-06-25 01:09:52,710 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-06E54996BC4D replies to ELECTION vote request: 0414aa62-2593-4022-a495-25b345e9257d<-a26e6a85-69e0-4d1b-9fdc-0decb2cb6032#0:OK-t1. Peer's state: a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-06E54996BC4D:t1, leader=null, voted=0414aa62-2593-4022-a495-25b345e9257d, raftlog=a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-06E54996BC4D-SegmentedRaftLog:OPENED:c-1, conf=-1: [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032|rpc:10.1.0.8:45483|dataStream:|priority:0, 0414aa62-2593-4022-a495-25b345e9257d|rpc:10.1.0.8:40303|dataStream:|priority:1, d233dd63-6533-4977-8487-4fe644b19e51|rpc:10.1.0.8:43619|dataStream:|priority:0], old=null
2022-06-25 01:09:52,719 [grpc-default-executor-8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d233dd63-6533-4977-8487-4fe644b19e51: start d233dd63-6533-4977-8487-4fe644b19e51@group-06E54996BC4D-FollowerState
2022-06-25 01:09:52,719 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196: ELECTION PASSED received 1 response(s) and 0 exception(s):
2022-06-25 01:09:52,719 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 0414aa62-2593-4022-a495-25b345e9257d<-a26e6a85-69e0-4d1b-9fdc-0decb2cb6032#0:OK-t1
2022-06-25 01:09:52,722 [d233dd63-6533-4977-8487-4fe644b19e51@group-06E54996BC4D-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - d233dd63-6533-4977-8487-4fe644b19e51@group-06E54996BC4D-FollowerState was interrupted
2022-06-25 01:09:52,738 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196 ELECTION round 0: result PASSED
2022-06-25 01:09:52,738 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 0414aa62-2593-4022-a495-25b345e9257d: shutdown 0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196
2022-06-25 01:09:52,738 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-06-25 01:09:52,738 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-06E54996BC4D with new leaderId: 0414aa62-2593-4022-a495-25b345e9257d
2022-06-25 01:09:52,738 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D: change Leader from null to 0414aa62-2593-4022-a495-25b345e9257d at term 1 for becomeLeader, leader elected after 5550ms
2022-06-25 01:09:52,738 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-25 01:09:52,738 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:52,738 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-06-25 01:09:52,739 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-06-25 01:09:52,739 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-25 01:09:52,739 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-25 01:09:52,740 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:52,740 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-25 01:09:52,743 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(358)) - Pipeline Pipeline[ Id: 44a487e6-11a7-4ecb-9f21-06e54996bc4d, Nodes: 0414aa62-2593-4022-a495-25b345e9257d{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43321, RATIS=40303, RATIS_ADMIN=40303, RATIS_SERVER=40303, STANDALONE=43699], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}a26e6a85-69e0-4d1b-9fdc-0decb2cb6032{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=38121, RATIS=45483, RATIS_ADMIN=45483, RATIS_SERVER=45483, STANDALONE=41583], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d233dd63-6533-4977-8487-4fe644b19e51{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=38035, RATIS=43619, RATIS_ADMIN=43619, RATIS_SERVER=43619, STANDALONE=45827], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:0414aa62-2593-4022-a495-25b345e9257d, CreationTimestamp2022-06-25T01:09:46.987Z[Etc/UTC]] moved to OPEN state
2022-06-25 01:09:52,746 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - d233dd63-6533-4977-8487-4fe644b19e51@group-06E54996BC4D replies to ELECTION vote request: 0414aa62-2593-4022-a495-25b345e9257d<-d233dd63-6533-4977-8487-4fe644b19e51#0:OK-t1. Peer's state: d233dd63-6533-4977-8487-4fe644b19e51@group-06E54996BC4D:t1, leader=null, voted=0414aa62-2593-4022-a495-25b345e9257d, raftlog=d233dd63-6533-4977-8487-4fe644b19e51@group-06E54996BC4D-SegmentedRaftLog:OPENED:c-1, conf=-1: [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032|rpc:10.1.0.8:45483|dataStream:|priority:0, 0414aa62-2593-4022-a495-25b345e9257d|rpc:10.1.0.8:40303|dataStream:|priority:1, d233dd63-6533-4977-8487-4fe644b19e51|rpc:10.1.0.8:43619|dataStream:|priority:0], old=null
2022-06-25 01:09:52,758 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2022-06-25 01:09:52,758 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:52,758 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2022-06-25 01:09:52,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:52,777 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2022-06-25 01:09:52,777 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:09:52,777 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:52,781 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2022-06-25 01:09:52,781 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-25 01:09:52,781 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2022-06-25 01:09:52,781 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2022-06-25 01:09:52,781 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-25 01:09:52,781 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-25 01:09:52,782 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 0414aa62-2593-4022-a495-25b345e9257d: start 0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderStateImpl
2022-06-25 01:09:52,787 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:52,790 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-4/data/ratis/44a487e6-11a7-4ecb-9f21-06e54996bc4d/current/log_inprogress_0
2022-06-25 01:09:52,805 [0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D-LeaderElection196] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 0414aa62-2593-4022-a495-25b345e9257d@group-06E54996BC4D: set configuration 0: [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032|rpc:10.1.0.8:45483|dataStream:|priority:0, 0414aa62-2593-4022-a495-25b345e9257d|rpc:10.1.0.8:40303|dataStream:|priority:1, d233dd63-6533-4977-8487-4fe644b19e51|rpc:10.1.0.8:43619|dataStream:|priority:0], old=null
2022-06-25 01:09:52,950 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-06E54996BC4D with new leaderId: 0414aa62-2593-4022-a495-25b345e9257d
2022-06-25 01:09:52,950 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-06E54996BC4D: change Leader from null to 0414aa62-2593-4022-a495-25b345e9257d at term 1 for appendEntries, leader elected after 5247ms
2022-06-25 01:09:52,950 [d233dd63-6533-4977-8487-4fe644b19e51-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-06E54996BC4D with new leaderId: 0414aa62-2593-4022-a495-25b345e9257d
2022-06-25 01:09:52,950 [d233dd63-6533-4977-8487-4fe644b19e51-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - d233dd63-6533-4977-8487-4fe644b19e51@group-06E54996BC4D: change Leader from null to 0414aa62-2593-4022-a495-25b345e9257d at term 1 for appendEntries, leader elected after 5079ms
2022-06-25 01:09:52,977 [d233dd63-6533-4977-8487-4fe644b19e51-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - d233dd63-6533-4977-8487-4fe644b19e51@group-06E54996BC4D: set configuration 0: [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032|rpc:10.1.0.8:45483|dataStream:|priority:0, 0414aa62-2593-4022-a495-25b345e9257d|rpc:10.1.0.8:40303|dataStream:|priority:1, d233dd63-6533-4977-8487-4fe644b19e51|rpc:10.1.0.8:43619|dataStream:|priority:0], old=null
2022-06-25 01:09:52,978 [d233dd63-6533-4977-8487-4fe644b19e51-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - d233dd63-6533-4977-8487-4fe644b19e51@group-06E54996BC4D-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:52,980 [d233dd63-6533-4977-8487-4fe644b19e51@group-06E54996BC4D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - d233dd63-6533-4977-8487-4fe644b19e51@group-06E54996BC4D-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-3/data/ratis/44a487e6-11a7-4ecb-9f21-06e54996bc4d/current/log_inprogress_0
2022-06-25 01:09:52,982 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:53,011 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-06E54996BC4D: set configuration 0: [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032|rpc:10.1.0.8:45483|dataStream:|priority:0, 0414aa62-2593-4022-a495-25b345e9257d|rpc:10.1.0.8:40303|dataStream:|priority:1, d233dd63-6533-4977-8487-4fe644b19e51|rpc:10.1.0.8:43619|dataStream:|priority:0], old=null
2022-06-25 01:09:53,012 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-06E54996BC4D-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:53,042 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5002942931ns, electionTimeout:5001ms
2022-06-25 01:09:53,043 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032: shutdown a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-FollowerState
2022-06-25 01:09:53,043 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-25 01:09:53,090 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode 3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=5525c833-6a53-417b-b57e-c2534272b3f4]
2022-06-25 01:09:53,090 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(432)) - Pipeline Pipeline[ Id: 5525c833-6a53-417b-b57e-c2534272b3f4, Nodes: 3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:3c6128f4-7bf2-4a55-83fb-21add5186158, CreationTimestamp2022-06-25T01:08:42.884Z[Etc/UTC]] moved to CLOSED state
2022-06-25 01:09:53,095 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43029, RATIS=44897, RATIS_ADMIN=44897, RATIS_SERVER=44897, STANDALONE=37333], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:09:53,095 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=b31a673a-3cb5-496f-b87f-d427a30f5985 close command to datanode 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9
2022-06-25 01:09:53,095 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(243)) - Pipeline Pipeline[ Id: b31a673a-3cb5-496f-b87f-d427a30f5985, Nodes: 4943f96b-6a06-411a-b0ee-4ab66ab6f7f9{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=43029, RATIS=44897, RATIS_ADMIN=44897, RATIS_SERVER=44897, STANDALONE=37333], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:4943f96b-6a06-411a-b0ee-4ab66ab6f7f9, CreationTimestamp2022-06-25T01:08:47.549Z[Etc/UTC]] removed.
2022-06-25 01:09:53,096 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/4943f96b-6a06-411a-b0ee-4ab66ab6f7f9
2022-06-25 01:09:53,111 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-06E54996BC4D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-06E54996BC4D-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-5/data/ratis/44a487e6-11a7-4ecb-9f21-06e54996bc4d/current/log_inprogress_0
2022-06-25 01:09:53,171 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1192)) - Container #2 is under replicated. Expected replica count is 3, but found 2.
2022-06-25 01:09:53,171 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1555)) - Sending replicate container command for container #2 to datanode 97d08340-a146-41c4-a759-b3b136c7fb6d{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=37711, RATIS=43169, RATIS_ADMIN=43169, RATIS_SERVER=43169, STANDALONE=44433], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-25 01:09:53,171 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1192)) - Container #3 is under replicated. Expected replica count is 3, but found 2.
2022-06-25 01:09:53,171 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1555)) - Sending replicate container command for container #3 to datanode 97d08340-a146-41c4-a759-b3b136c7fb6d{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=37711, RATIS=43169, RATIS_ADMIN=43169, RATIS_SERVER=43169, STANDALONE=44433], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-25 01:09:53,171 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:53,183 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-25 01:09:53,183 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032: start a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-LeaderElection197
2022-06-25 01:09:53,235 [ContainerReplicationThread-2] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 2 from [be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-25 01:09:53,260 [grpc-default-executor-8] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(52)) - Streaming container data (2) to other datanode
2022-06-25 01:09:53,315 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-LeaderElection197] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-LeaderElection197 ELECTION round 0: submit vote requests at term 1 for -1: [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032|rpc:10.1.0.8:45483|priority:1], old=null
2022-06-25 01:09:53,315 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-LeaderElection197] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-LeaderElection197 ELECTION round 0: result PASSED (term=1)
2022-06-25 01:09:53,315 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-LeaderElection197] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032: shutdown a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-LeaderElection197
2022-06-25 01:09:53,315 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-LeaderElection197] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-06-25 01:09:53,315 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-LeaderElection197] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-988B5CBFFA1C with new leaderId: a26e6a85-69e0-4d1b-9fdc-0decb2cb6032
2022-06-25 01:09:53,316 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-LeaderElection197] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C: change Leader from null to a26e6a85-69e0-4d1b-9fdc-0decb2cb6032 at term 1 for becomeLeader, leader elected after 5369ms
2022-06-25 01:09:53,316 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-LeaderElection197] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-25 01:09:53,316 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-LeaderElection197] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:53,316 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-LeaderElection197] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-06-25 01:09:53,317 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-LeaderElection197] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-06-25 01:09:53,317 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-LeaderElection197] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-25 01:09:53,317 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-LeaderElection197] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-25 01:09:53,317 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-LeaderElection197] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-25 01:09:53,317 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-LeaderElection197] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-25 01:09:53,318 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-LeaderElection197] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032: start a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-LeaderStateImpl
2022-06-25 01:09:53,318 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-LeaderElection197] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-25 01:09:53,320 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-e228e9f1-8cea-4b31-8b4b-3b149b9026ba/datanode-5/data/ratis/07d3f442-d3a5-4cd2-b410-988b5cbffa1c/current/log_inprogress_0
2022-06-25 01:09:53,327 [ContainerReplicationThread-3] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 3 from [be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-25 01:09:53,356 [grpc-default-executor-6] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(52)) - Streaming container data (3) to other datanode
2022-06-25 01:09:53,390 [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C-LeaderElection197] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - a26e6a85-69e0-4d1b-9fdc-0decb2cb6032@group-988B5CBFFA1C: set configuration 0: [a26e6a85-69e0-4d1b-9fdc-0decb2cb6032|rpc:10.1.0.8:45483|dataStream:|priority:1], old=null
2022-06-25 01:09:53,460 [grpc-default-executor-8] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 19142 bytes for container 2
2022-06-25 01:09:53,464 [grpc-default-executor-5] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(197)) - Container 2 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data/replication/work/container-2.tar.gz
2022-06-25 01:09:53,468 [ContainerReplicationThread-2] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 2 is downloaded with size 19142, starting to import.
2022-06-25 01:09:53,610 [grpc-default-executor-6] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 27216 bytes for container 3
2022-06-25 01:09:53,610 [grpc-default-executor-5] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(197)) - Container 3 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data/replication/work/container-3.tar.gz
2022-06-25 01:09:53,615 [ContainerReplicationThread-3] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 3 is downloaded with size 27216, starting to import.
2022-06-25 01:09:53,618 [ContainerReplicationThread-2] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 2 is replicated successfully
2022-06-25 01:09:53,618 [ContainerReplicationThread-2] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(176)) - Container 2 is replicated.
2022-06-25 01:09:53,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:53,880 [ContainerReplicationThread-3] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 3 is replicated successfully
2022-06-25 01:09:53,880 [ContainerReplicationThread-3] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(176)) - Container 3 is replicated.
2022-06-25 01:09:53,983 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:54,171 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-06-25 01:09:54,210 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-06-25 01:09:54,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:54,998 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:55,174 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:09:55,534 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(365)) - Attempting to stop container services.
2022-06-25 01:09:55,607 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$7(398)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: close
2022-06-25 01:09:55,607 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4: shutdown
2022-06-25 01:09:55,607 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C2534272B3F4,id=3c6128f4-7bf2-4a55-83fb-21add5186158
2022-06-25 01:09:55,607 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: shutdown 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-LeaderStateImpl
2022-06-25 01:09:55,608 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-PendingRequests: sendNotLeaderResponses
2022-06-25 01:09:55,610 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-C2534272B3F4: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data/ratis/5525c833-6a53-417b-b57e-c2534272b3f4/sm/snapshot.1_0
2022-06-25 01:09:55,610 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-StateMachineUpdater: set stopIndex = 0
2022-06-25 01:09:55,611 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-C2534272B3F4: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-2/data/ratis/5525c833-6a53-417b-b57e-c2534272b3f4/sm/snapshot.1_0 took: 1 ms
2022-06-25 01:09:55,611 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-StateMachineUpdater: Took a snapshot at index 0
2022-06-25 01:09:55,611 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-06-25 01:09:55,612 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer$Division (ServerState.java:close(429)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4: closes. applyIndex: 0
2022-06-25 01:09:55,612 [3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-25 01:09:55,612 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - 3c6128f4-7bf2-4a55-83fb-21add5186158@group-C2534272B3F4-SegmentedRaftLogWorker close()
2022-06-25 01:09:55,614 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(269)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: shutdown server with port 46801 now
2022-06-25 01:09:55,718 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(278)) - 3c6128f4-7bf2-4a55-83fb-21add5186158: shutdown server with port 46801 successfully
2022-06-25 01:09:55,722 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@4240468b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-3c6128f4-7bf2-4a55-83fb-21add5186158: Stopped
2022-06-25 01:09:55,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:56,003 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:09:56,108 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. 3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:09:56,108 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=5525c833-6a53-417b-b57e-c2534272b3f4 close command to datanode 3c6128f4-7bf2-4a55-83fb-21add5186158
2022-06-25 01:09:56,108 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(243)) - Pipeline Pipeline[ Id: 5525c833-6a53-417b-b57e-c2534272b3f4, Nodes: 3c6128f4-7bf2-4a55-83fb-21add5186158{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=42673, RATIS=46801, RATIS_ADMIN=46801, RATIS_SERVER=46801, STANDALONE=39955], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:3c6128f4-7bf2-4a55-83fb-21add5186158, CreationTimestamp2022-06-25T01:08:42.884Z[Etc/UTC]] removed.
2022-06-25 01:09:56,108 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/3c6128f4-7bf2-4a55-83fb-21add5186158
2022-06-25 01:09:56,174 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-25 01:09:56,174 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-25 01:09:56,174 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-25 01:09:56,175 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-25 01:09:56,175 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-25 01:09:56,175 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-25 01:09:56,175 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-06-25 01:09:56,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:57,004 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:57,175 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-25 01:09:57,175 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-25 01:09:57,175 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-25 01:09:57,175 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-25 01:09:57,176 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-25 01:09:57,176 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-25 01:09:57,176 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-06-25 01:09:57,328 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(580)) - Ozone container server stopped.
2022-06-25 01:09:57,489 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@225aebe9{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-25 01:09:57,490 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@3f73a3d2{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-06-25 01:09:57,490 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-06-25 01:09:57,491 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@50a196c4{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-06-25 01:09:57,491 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@6f836b3a{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-06-25 01:09:57,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:57,847 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-06-25 01:09:58,005 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:58,176 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-25 01:09:58,176 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-25 01:09:58,176 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-25 01:09:58,176 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-25 01:09:58,176 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-25 01:09:58,176 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-25 01:09:58,177 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-06-25 01:09:58,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:59,007 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:59,177 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-25 01:09:59,177 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-25 01:09:59,177 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-25 01:09:59,177 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-25 01:09:59,177 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-25 01:09:59,177 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-25 01:09:59,178 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-06-25 01:09:59,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:09:59,936 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode 97d08340-a146-41c4-a759-b3b136c7fb6d{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=37711, RATIS=43169, RATIS_ADMIN=43169, RATIS_SERVER=43169, STANDALONE=44433], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=cdbaaf97-8e9b-4256-80e1-298c63fec351]
2022-06-25 01:09:59,936 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(432)) - Pipeline Pipeline[ Id: cdbaaf97-8e9b-4256-80e1-298c63fec351, Nodes: 97d08340-a146-41c4-a759-b3b136c7fb6d{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=37711, RATIS=43169, RATIS_ADMIN=43169, RATIS_SERVER=43169, STANDALONE=44433], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:97d08340-a146-41c4-a759-b3b136c7fb6d, CreationTimestamp2022-06-25T01:08:45.699Z[Etc/UTC]] moved to CLOSED state
2022-06-25 01:10:00,007 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:00,178 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-25 01:10:00,178 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-25 01:10:00,178 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-25 01:10:00,178 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-25 01:10:00,179 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-25 01:10:00,179 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-25 01:10:00,179 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-06-25 01:10:00,776 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:00,868 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(580)) - Ozone container server stopped.
2022-06-25 01:10:01,015 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:01,061 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@11725f6b{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-25 01:10:01,062 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@2622fda1{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-06-25 01:10:01,062 [ForkJoinPool.commonPool-worker-0] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-06-25 01:10:01,070 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@4fd3e0e9{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-06-25 01:10:01,070 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@3df34d10{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-06-25 01:10:01,180 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-25 01:10:01,180 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-25 01:10:01,182 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-25 01:10:01,183 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-25 01:10:01,183 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-25 01:10:01,183 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-25 01:10:01,183 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 4 milliseconds for processing 3 containers.
2022-06-25 01:10:01,782 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:02,015 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:02,183 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-25 01:10:02,183 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-25 01:10:02,183 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-25 01:10:02,184 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-25 01:10:02,184 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-25 01:10:02,184 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-25 01:10:02,184 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-06-25 01:10:02,497 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(365)) - Attempting to stop container services.
2022-06-25 01:10:02,498 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$7(398)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: close
2022-06-25 01:10:02,498 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351: shutdown
2022-06-25 01:10:02,498 [Mini-Cluster-Provider-Reap] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-298C63FEC351,id=97d08340-a146-41c4-a759-b3b136c7fb6d
2022-06-25 01:10:02,498 [Mini-Cluster-Provider-Reap] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: shutdown 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-LeaderStateImpl
2022-06-25 01:10:02,499 [Mini-Cluster-Provider-Reap] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-PendingRequests: sendNotLeaderResponses
2022-06-25 01:10:02,501 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-298C63FEC351: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data/ratis/cdbaaf97-8e9b-4256-80e1-298c63fec351/sm/snapshot.1_0
2022-06-25 01:10:02,502 [Mini-Cluster-Provider-Reap] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-StateMachineUpdater: set stopIndex = 0
2022-06-25 01:10:02,512 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-298C63FEC351: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-4/data/ratis/cdbaaf97-8e9b-4256-80e1-298c63fec351/sm/snapshot.1_0 took: 11 ms
2022-06-25 01:10:02,512 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-StateMachineUpdater: Took a snapshot at index 0
2022-06-25 01:10:02,512 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-06-25 01:10:02,526 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (ServerState.java:close(429)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351: closes. applyIndex: 0
2022-06-25 01:10:02,526 [97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-25 01:10:02,527 [Mini-Cluster-Provider-Reap] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - 97d08340-a146-41c4-a759-b3b136c7fb6d@group-298C63FEC351-SegmentedRaftLogWorker close()
2022-06-25 01:10:02,527 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(269)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: shutdown server with port 43169 now
2022-06-25 01:10:02,633 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(278)) - 97d08340-a146-41c4-a759-b3b136c7fb6d: shutdown server with port 43169 successfully
2022-06-25 01:10:02,634 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@3534c0d2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-97d08340-a146-41c4-a759-b3b136c7fb6d: Stopped
2022-06-25 01:10:02,783 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:02,887 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. 97d08340-a146-41c4-a759-b3b136c7fb6d{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=37711, RATIS=43169, RATIS_ADMIN=43169, RATIS_SERVER=43169, STANDALONE=44433], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:10:02,887 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=cdbaaf97-8e9b-4256-80e1-298c63fec351 close command to datanode 97d08340-a146-41c4-a759-b3b136c7fb6d
2022-06-25 01:10:02,888 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(243)) - Pipeline Pipeline[ Id: cdbaaf97-8e9b-4256-80e1-298c63fec351, Nodes: 97d08340-a146-41c4-a759-b3b136c7fb6d{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=37711, RATIS=43169, RATIS_ADMIN=43169, RATIS_SERVER=43169, STANDALONE=44433], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:97d08340-a146-41c4-a759-b3b136c7fb6d, CreationTimestamp2022-06-25T01:08:45.699Z[Etc/UTC]] removed.
2022-06-25 01:10:02,888 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/97d08340-a146-41c4-a759-b3b136c7fb6d
2022-06-25 01:10:03,015 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:03,188 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-25 01:10:03,188 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-25 01:10:03,189 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-25 01:10:03,189 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-25 01:10:03,189 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-25 01:10:03,189 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-25 01:10:03,189 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-06-25 01:10:03,298 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=793cb964-1b2d-41b4-96bf-87f9d58b43b0]
2022-06-25 01:10:03,298 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(432)) - Pipeline Pipeline[ Id: 793cb964-1b2d-41b4-96bf-87f9d58b43b0, Nodes: be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONED, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:be67eb5e-e62d-4374-a142-8db592db20d7, CreationTimestamp2022-06-25T01:09:36.689Z[Etc/UTC]] moved to CLOSED state
2022-06-25 01:10:03,784 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:04,016 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:04,189 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #1, no healthy replica found.
2022-06-25 01:10:04,189 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #2, no healthy replica found.
2022-06-25 01:10:04,189 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #3, no healthy replica found.
2022-06-25 01:10:04,189 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:10:04,775 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-06-25 01:10:04,785 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:05,017 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:05,191 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #1, no healthy replica found.
2022-06-25 01:10:05,191 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #2, no healthy replica found.
2022-06-25 01:10:05,191 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #3, no healthy replica found.
2022-06-25 01:10:05,191 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:10:05,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:10:06,017 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:06,086 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(365)) - Attempting to stop container services.
2022-06-25 01:10:06,087 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$7(398)) - be67eb5e-e62d-4374-a142-8db592db20d7: close
2022-06-25 01:10:06,088 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0: shutdown
2022-06-25 01:10:06,088 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-87F9D58B43B0,id=be67eb5e-e62d-4374-a142-8db592db20d7
2022-06-25 01:10:06,088 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - be67eb5e-e62d-4374-a142-8db592db20d7: shutdown be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-LeaderStateImpl
2022-06-25 01:10:06,088 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-PendingRequests: sendNotLeaderResponses
2022-06-25 01:10:06,091 [be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-87F9D58B43B0: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis/793cb964-1b2d-41b4-96bf-87f9d58b43b0/sm/snapshot.1_0
2022-06-25 01:10:06,091 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-StateMachineUpdater: set stopIndex = 0
2022-06-25 01:10:06,093 [be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-87F9D58B43B0: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-84da1e05-86d5-4b42-9168-65f6ed46dc76/datanode-0/data/ratis/793cb964-1b2d-41b4-96bf-87f9d58b43b0/sm/snapshot.1_0 took: 2 ms
2022-06-25 01:10:06,093 [be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-StateMachineUpdater: Took a snapshot at index 0
2022-06-25 01:10:06,093 [be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-06-25 01:10:06,093 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer$Division (ServerState.java:close(429)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0: closes. applyIndex: 0
2022-06-25 01:10:06,093 [be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-25 01:10:06,095 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - be67eb5e-e62d-4374-a142-8db592db20d7@group-87F9D58B43B0-SegmentedRaftLogWorker close()
2022-06-25 01:10:06,191 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(269)) - be67eb5e-e62d-4374-a142-8db592db20d7: shutdown server with port 39697 now
2022-06-25 01:10:06,214 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-06-25 01:10:06,214 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=793cb964-1b2d-41b4-96bf-87f9d58b43b0 close command to datanode be67eb5e-e62d-4374-a142-8db592db20d7
2022-06-25 01:10:06,215 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(243)) - Pipeline Pipeline[ Id: 793cb964-1b2d-41b4-96bf-87f9d58b43b0, Nodes: be67eb5e-e62d-4374-a142-8db592db20d7{ip: 10.1.0.8, host: fv-az66-546.vwcdieab4koerntclszyavmfxa.dx.internal.cloudapp.net, ports: [REPLICATION=41637, RATIS=39697, RATIS_ADMIN=39697, RATIS_SERVER=39697, STANDALONE=37213], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONED, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:be67eb5e-e62d-4374-a142-8db592db20d7, CreationTimestamp2022-06-25T01:09:36.689Z[Etc/UTC]] removed.
2022-06-25 01:10:06,215 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/be67eb5e-e62d-4374-a142-8db592db20d7
2022-06-25 01:10:06,260 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #1, no healthy replica found.
2022-06-25 01:10:06,261 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #2, no healthy replica found.
2022-06-25 01:10:06,261 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #3, no healthy replica found.
2022-06-25 01:10:06,261 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-06-25 01:10:06,264 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(278)) - be67eb5e-e62d-4374-a142-8db592db20d7: shutdown server with port 39697 successfully
2022-06-25 01:10:06,264 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@95dd22] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-be67eb5e-e62d-4374-a142-8db592db20d7: Stopped
2022-06-25 01:10:06,787 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:07,017 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:07,261 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #1, no healthy replica found.
2022-06-25 01:10:07,261 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #2, no healthy replica found.
2022-06-25 01:10:07,261 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #3, no healthy replica found.
2022-06-25 01:10:07,261 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:10:07,787 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:07,882 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(580)) - Ozone container server stopped.
2022-06-25 01:10:08,018 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:08,050 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@d6a6be7{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-25 01:10:08,051 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@e43c54{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-06-25 01:10:08,051 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-06-25 01:10:08,051 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@73b20ca2{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-06-25 01:10:08,051 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@4996659d{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-06-25 01:10:08,264 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #1, no healthy replica found.
2022-06-25 01:10:08,264 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #2, no healthy replica found.
2022-06-25 01:10:08,264 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #3, no healthy replica found.
2022-06-25 01:10:08,264 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:10:08,384 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-06-25 01:10:08,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:09,019 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:09,266 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #1, no healthy replica found.
2022-06-25 01:10:09,266 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #2, no healthy replica found.
2022-06-25 01:10:09,266 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #3, no healthy replica found.
2022-06-25 01:10:09,266 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:10:09,791 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:10,019 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:10,269 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #1, no healthy replica found.
2022-06-25 01:10:10,269 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #2, no healthy replica found.
2022-06-25 01:10:10,269 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #3, no healthy replica found.
2022-06-25 01:10:10,269 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:10:10,791 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:11,020 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:11,269 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #1, no healthy replica found.
2022-06-25 01:10:11,269 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #2, no healthy replica found.
2022-06-25 01:10:11,269 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #3, no healthy replica found.
2022-06-25 01:10:11,269 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-25 01:10:11,409 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(580)) - Ozone container server stopped.
2022-06-25 01:10:11,496 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@2c02cf78{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-25 01:10:11,496 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@68303aad{HTTP/1.1, (http/1.1)}{0.0.0.0:45929}
2022-06-25 01:10:11,496 [ForkJoinPool.commonPool-worker-0] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-06-25 01:10:11,497 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@46067a74{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-06-25 01:10:11,497 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@155767a7{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-06-25 01:10:11,499 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(549)) - Stopping the StorageContainerManager
2022-06-25 01:10:11,499 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1510)) - Container Balancer is not running.
2022-06-25 01:10:11,499 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1517)) - Stopping Replication Manager Service.
2022-06-25 01:10:11,499 [Mini-Cluster-Provider-Reap] INFO  replication.ReplicationManager (ReplicationManager.java:stop(212)) - Stopping Replication Monitor Thread.
2022-06-25 01:10:11,502 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1524)) - Stopping the Datanode Admin Monitor.
2022-06-25 01:10:11,502 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1531)) - Stopping Lease Manager of the command watchers
2022-06-25 01:10:11,502 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1538)) - Stopping datanode service RPC server
2022-06-25 01:10:11,502 [Mini-Cluster-Provider-Reap] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(408)) - Stopping the RPC server for DataNodes
2022-06-25 01:10:11,502 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(270)) - Replication Monitor Thread is stopped
2022-06-25 01:10:11,504 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3414)) - Stopping server on 36557
2022-06-25 01:10:11,513 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - Stopping IPC Server Responder
2022-06-25 01:10:11,513 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1376)) - Stopping IPC Server listener on 0
2022-06-25 01:10:11,536 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(870)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2022-06-25 01:10:11,537 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1546)) - Stopping block service RPC server
2022-06-25 01:10:11,537 [Mini-Cluster-Provider-Reap] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(160)) - Stopping the RPC server for Block Protocol
2022-06-25 01:10:11,561 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3414)) - Stopping server on 44789
2022-06-25 01:10:11,566 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1553)) - Stopping the StorageContainerLocationProtocol RPC server
2022-06-25 01:10:11,566 [Mini-Cluster-Provider-Reap] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(178)) - Stopping the RPC server for Client Protocol
2022-06-25 01:10:11,566 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1376)) - Stopping IPC Server listener on 0
2022-06-25 01:10:11,567 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3414)) - Stopping server on 38653
2022-06-25 01:10:11,576 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1560)) - Stopping Storage Container Manager HTTP server.
2022-06-25 01:10:11,577 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - Stopping IPC Server Responder
2022-06-25 01:10:11,577 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1376)) - Stopping IPC Server listener on 0
2022-06-25 01:10:11,591 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@4ce57534{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2022-06-25 01:10:11,591 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@5828c18f{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-06-25 01:10:11,591 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-06-25 01:10:11,592 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@7e7b9904{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2022-06-25 01:10:11,592 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@20f16681{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-06-25 01:10:11,593 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1571)) - Stopping Block Manager Service.
2022-06-25 01:10:11,593 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service SCMBlockDeletingService
2022-06-25 01:10:11,593 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service SCMBlockDeletingService
2022-06-25 01:10:11,593 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1598)) - Stopping SCM Event Queue.
2022-06-25 01:10:11,608 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1609)) - Stopping SCM HA services.
2022-06-25 01:10:11,608 [Mini-Cluster-Provider-Reap] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(152)) - Stopping RatisPipelineUtilsThread.
2022-06-25 01:10:11,609 [RatisPipelineUtilsThread - 0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(179)) - RatisPipelineUtilsThread is interrupted.
2022-06-25 01:10:11,612 [Mini-Cluster-Provider-Reap] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(126)) - Stopping BackgroundPipelineScrubber Service.
2022-06-25 01:10:11,612 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1619)) - Stopping SCM MetadataStore.
2022-06-25 01:10:11,612 [BackgroundPipelineScrubberThread] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(110)) - BackgroundPipelineScrubber is interrupted, exit
2022-06-25 01:10:11,614 [Mini-Cluster-Provider-Reap] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2022-06-25 01:10:11,631 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2022-06-25 01:10:11,642 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - Stopping IPC Server Responder
2022-06-25 01:10:11,679 [Mini-Cluster-Provider-Reap] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
2022-06-25 01:10:11,791 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:12,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:12,799 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:10:13,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:13,799 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:14,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:14,800 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:15,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:15,801 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:16,022 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:16,801 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:17,022 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:17,801 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:18,023 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:18,801 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:19,023 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:19,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:20,023 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:20,808 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:21,024 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:21,808 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:22,024 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:22,808 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:23,024 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:23,811 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:24,025 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:24,811 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:25,025 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:25,811 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:26,026 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:26,812 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:27,026 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:27,812 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:28,027 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:28,812 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:29,029 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:29,812 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:10:30,034 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:30,813 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:31,038 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:31,814 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:32,042 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:32,814 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:33,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:33,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:34,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:34,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:35,047 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:35,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:36,049 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:36,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:37,049 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:37,818 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:38,050 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:38,820 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:39,050 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:39,822 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:10:40,054 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:40,823 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:41,056 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:41,826 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:42,057 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:42,828 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:43,057 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:43,829 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:44,057 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:44,829 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:45,057 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:10:45,829 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:46,058 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:46,829 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:47,058 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:47,830 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:48,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:48,834 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:49,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:49,834 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:50,061 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:50,834 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:51,061 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:51,837 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:52,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:52,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:53,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:53,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:54,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:54,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:55,063 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:55,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:56,063 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:56,842 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:57,063 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:57,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:58,063 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:58,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:59,064 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:10:59,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:00,064 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:00,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:01,064 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:01,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:02,067 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:02,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:03,067 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:03,847 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:04,067 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:04,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:05,067 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:11:05,852 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:06,068 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:06,853 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:07,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:07,854 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:08,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:08,854 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:09,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:09,854 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:10,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:10,854 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:11,072 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:11,855 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:12,072 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:12,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:11:13,072 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:11:13,858 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:14,073 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:14,858 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:15,074 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:15,859 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:16,081 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:16,859 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:17,081 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:17,859 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:18,082 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:18,861 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:19,082 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:19,865 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:20,083 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:20,865 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:21,083 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:21,865 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:22,083 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:22,865 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:23,084 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:23,866 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:24,086 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:24,870 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:25,086 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:25,871 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:26,090 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:26,871 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:27,091 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:27,871 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:28,093 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:28,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:29,093 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:29,874 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:30,094 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:30,874 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:11:31,096 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:31,878 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:32,097 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:32,878 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:33,098 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:33,882 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:34,098 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:34,886 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:35,098 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:35,886 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:36,104 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:36,889 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:37,104 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:37,891 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:38,106 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:38,891 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:39,106 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:39,891 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:40,110 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:40,894 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:41,114 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:41,894 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:42,114 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:42,895 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:43,118 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:43,895 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:44,119 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:44,895 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:45,119 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:45,897 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:46,121 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:11:46,897 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:47,122 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:47,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:48,122 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:48,903 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:49,123 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:49,904 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:50,123 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:50,904 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:51,124 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:51,904 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:52,124 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:52,905 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:53,124 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:53,905 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:54,126 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:54,905 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:55,126 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:55,906 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:56,127 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:56,906 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:57,127 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:57,906 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:58,130 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:58,909 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:11:59,130 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:11:59,910 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:00,130 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:00,910 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:01,132 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:01,911 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:02,132 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:02,911 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:03,133 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:03,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:04,133 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:04,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:05,134 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:05,914 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:06,134 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:06,914 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:07,137 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:07,915 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:08,137 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:08,915 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:09,138 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:09,915 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:10,138 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:10,916 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:11,141 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:11,916 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:12,146 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:12,917 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:13,147 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:13,918 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:14,148 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:14,919 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:15,148 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:15,920 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:16,148 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:16,922 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:17,148 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:17,926 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:18,149 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:18,928 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:19,149 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:19,928 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:20,149 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:20,928 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:21,151 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:21,929 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:22,154 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:22,930 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:23,154 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:23,930 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:24,155 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:24,931 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:25,155 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:25,935 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:26,156 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:26,936 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:27,157 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:27,937 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:28,158 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:28,937 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:29,158 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:29,937 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:30,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:30,937 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:12:31,162 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:31,938 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:32,162 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:32,943 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:33,162 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:12:33,943 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:34,163 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:34,944 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:35,163 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:35,946 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:36,163 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:36,946 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:37,163 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:12:37,948 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:38,164 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:38,949 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:39,164 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:39,952 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:40,166 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:40,953 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:41,166 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:41,958 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:42,167 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:42,959 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:43,167 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:43,959 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:44,167 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:12:44,960 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:45,168 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:45,962 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:46,168 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:46,963 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:47,169 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:47,964 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:48,169 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:48,965 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:49,169 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:49,965 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:50,169 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:50,965 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:51,170 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:12:51,972 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:52,173 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:52,972 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:53,173 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:53,973 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:54,173 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:54,974 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:55,174 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:55,974 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:56,174 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:56,975 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:57,174 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:57,976 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:58,175 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:58,976 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:59,175 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:12:59,976 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:00,175 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:00,976 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:01,175 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:13:01,977 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:02,182 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:02,977 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:03,182 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:03,977 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:04,184 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:04,977 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:05,184 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:05,978 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:06,184 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:13:06,978 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:07,185 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:07,978 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:13:08,185 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:08,979 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:09,185 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:09,979 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:10,189 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:10,981 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:11,194 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:11,981 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:12,199 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:12,982 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:13,206 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:13,983 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:14,207 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:14,983 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:15,207 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:15,986 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:16,207 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:16,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:17,208 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:17,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:18,208 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:13:18,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:19,209 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:19,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:20,209 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:20,988 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:21,209 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:21,989 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:22,210 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:22,989 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:23,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:23,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:24,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:24,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:25,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:25,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:13:26,213 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:26,993 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:27,215 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:27,998 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:28,216 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:28,999 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:29,216 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:30,002 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:30,217 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:31,002 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:31,217 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:32,002 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:32,219 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:33,002 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:33,220 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:34,003 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:34,223 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:35,003 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:35,223 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:36,003 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:36,224 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:37,006 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:37,225 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:38,010 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:38,225 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:39,012 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:39,225 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:40,012 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:40,225 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:41,014 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:41,226 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:42,018 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:42,226 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:43,020 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:43,227 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:44,020 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:44,227 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:45,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:45,228 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:46,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:46,228 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:47,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:47,228 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:48,022 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:48,230 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:49,024 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:49,230 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:50,024 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:50,230 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:51,025 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:51,231 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:52,025 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:52,231 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:53,026 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:53,234 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:54,026 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:13:54,234 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:55,028 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:55,238 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:56,028 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:56,238 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:13:57,030 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:57,240 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:58,030 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:13:58,242 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:13:59,031 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:13:59,243 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:00,034 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:00,243 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:01,034 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:01,243 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:02,035 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:02,248 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:03,036 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:03,249 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:04,036 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:04,249 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:05,037 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:05,249 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:06,037 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:06,249 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:07,040 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:07,250 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:08,044 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:08,251 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:09,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:09,252 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:10,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:10,252 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:11,047 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:11,252 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:12,050 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:12,253 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:13,050 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:13,253 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:14,051 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:14,253 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:14:15,053 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:15,254 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:16,053 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:16,254 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:17,053 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:17,254 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:18,135 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:18,254 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:19,135 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:19,257 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:20,139 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:20,258 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:21,140 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:21,259 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:22,142 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:22,260 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:23,143 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:23,261 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:24,143 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:24,261 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:25,144 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:25,262 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:26,144 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:26,262 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:27,145 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:27,262 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:28,145 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:28,270 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:29,145 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:29,271 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:30,146 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:30,271 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:31,146 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:31,274 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:32,148 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:32,274 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:33,149 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:33,277 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:34,150 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:34,277 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:14:35,151 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:35,278 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:36,151 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:36,278 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:37,151 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:37,278 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:38,151 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:38,279 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:39,152 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:39,279 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:40,152 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:40,281 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:41,154 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:41,282 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:42,158 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:42,282 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:43,158 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:43,284 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:44,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:44,287 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:45,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:45,287 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:46,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:46,288 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:47,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:47,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:48,160 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:48,291 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:49,160 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:49,292 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:50,160 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:50,292 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:51,162 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:51,294 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:52,166 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:52,294 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:14:53,166 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:53,297 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:54,167 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:54,297 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:55,168 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:55,297 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:56,170 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:56,299 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:57,171 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:57,301 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:58,174 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:58,302 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:59,175 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:14:59,302 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:00,175 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:00,306 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:01,175 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:01,307 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:02,177 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:02,308 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:03,177 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:03,310 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:04,178 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:04,310 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:05,178 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:05,310 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:06,178 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:06,311 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:07,179 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:07,312 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:08,180 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:08,312 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:09,180 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:09,312 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:10,180 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:10,312 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:11,181 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:11,314 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:12,181 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:12,319 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 5 milliseconds for processing 0 containers.
2022-06-25 01:15:13,182 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:13,320 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:14,182 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:14,320 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:15,182 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:15,321 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:16,182 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:16,324 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:17,183 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:17,326 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:18,183 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:18,326 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:19,184 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:19,326 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:20,184 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:20,329 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:21,188 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:21,329 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:22,190 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:22,329 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:23,190 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:23,329 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:24,190 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:24,335 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:25,191 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:25,338 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:26,191 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:26,338 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:27,192 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:27,339 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:28,193 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:28,339 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:29,194 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:29,340 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:30,194 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:30,341 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:31,196 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:31,341 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:32,197 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:32,341 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:33,197 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:33,343 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:34,197 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:34,344 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:15:35,198 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:35,345 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:36,198 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:15:36,349 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:37,199 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:37,349 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:38,199 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:38,349 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:39,199 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:39,350 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:40,199 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:15:40,350 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:41,206 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:41,351 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:42,209 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:42,352 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:43,209 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:43,352 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:44,209 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:44,353 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:45,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:45,354 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:46,216 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:46,354 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:47,217 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:47,355 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:48,218 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:48,355 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:49,219 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:49,355 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:50,219 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:50,355 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:51,219 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:51,358 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:52,219 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:52,358 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:53,221 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:53,360 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:54,221 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:54,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:55,221 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:55,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:56,221 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:15:56,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:57,222 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:57,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:58,226 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:58,366 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:59,227 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:15:59,366 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:00,227 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:00,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:01,228 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:01,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:02,228 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:02,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:03,228 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:03,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:04,229 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:04,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:16:05,229 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:05,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:06,229 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:06,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:07,229 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:16:07,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:08,234 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:08,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:09,236 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:09,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:10,238 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:10,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:11,239 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:11,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:12,240 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:12,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:13,240 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:13,378 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:14,240 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:14,378 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:15,241 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:15,477 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:16,242 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:16,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:17,243 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:17,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:18,246 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:18,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:19,247 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:19,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:20,247 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:20,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:21,248 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:21,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:22,248 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:22,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:23,249 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:23,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:24,249 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:24,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:25,249 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:25,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:16:26,251 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:26,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:27,251 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:16:27,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:28,252 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:28,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:29,252 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:29,490 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:30,254 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:30,494 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:16:31,258 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:31,495 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:32,260 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:32,501 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:33,260 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:33,506 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:34,260 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:34,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:35,261 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:35,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:36,261 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:36,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:37,262 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:37,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:38,262 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:38,513 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:39,262 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:39,513 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:40,263 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:40,513 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:41,264 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:41,513 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:42,264 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:42,519 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:43,264 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:43,522 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:44,266 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:44,522 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:45,266 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:45,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:46,266 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:46,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:47,267 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:47,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:48,274 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:48,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:49,274 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:49,524 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:50,275 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:50,526 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:51,275 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:51,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:52,275 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:52,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:53,278 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:53,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:54,278 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:54,528 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:55,281 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:55,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:56,282 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:56,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:16:57,282 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:57,532 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:58,282 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:58,532 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:59,282 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:16:59,532 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:00,283 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:00,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:01,284 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:01,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:02,285 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:02,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:03,288 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:03,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:04,289 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:04,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:05,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:05,546 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:06,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:06,549 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:07,292 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:07,550 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:08,292 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:08,550 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:09,294 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:09,550 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:10,295 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:10,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:11,296 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:11,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:12,296 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:12,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:13,296 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:17:13,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:14,297 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:14,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:15,297 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:15,556 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:16,297 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:16,556 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:17,297 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:17:17,556 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:18,298 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:18,557 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:19,298 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:19,557 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:20,298 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:20,557 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:17:21,299 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:21,558 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:22,300 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:22,558 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:23,300 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:23,565 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:24,302 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:24,567 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:25,302 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:25,567 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:26,303 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:26,570 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:27,303 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:27,570 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:28,303 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:28,571 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:29,306 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:29,574 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:30,310 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:30,574 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:31,311 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:31,579 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:17:32,311 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:32,579 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:33,311 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:33,579 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:34,313 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:34,580 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:35,313 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:35,580 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:36,313 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:36,580 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:37,314 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:37,581 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:38,314 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:38,581 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:39,315 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:39,581 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:40,321 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:40,581 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:41,321 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:41,582 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:42,322 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:17:42,582 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:43,323 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:43,582 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:44,323 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:44,584 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:45,323 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:45,585 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:46,324 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:46,585 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:47,324 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:47,586 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:17:48,325 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:48,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:49,325 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:49,590 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:50,325 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:50,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:51,325 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:51,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:52,326 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:52,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:53,326 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:53,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:54,327 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:54,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:55,327 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:17:55,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:56,328 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:56,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:57,328 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:57,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:58,328 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:58,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:59,328 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:17:59,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:00,329 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:00,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:01,333 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:01,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:02,333 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:02,604 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:18:03,334 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:03,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:04,335 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:04,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:05,335 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:05,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:06,338 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:06,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:07,339 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:07,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:08,339 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:08,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:09,339 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:09,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:10,340 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:10,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:11,014 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@3babaf97] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-a2e7c5f8-591a-42df-bc70-018e5970ca84: Detected pause in JVM or host machine (eg GC): pause of approximately 110087748ns.
GC pool 'PS Scavenge' had collection(s): count=1 time=8ms
2022-06-25 01:18:11,014 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@37a08f49] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-fb218fe0-94a8-44a0-a252-d3cae8685c6f: Detected pause in JVM or host machine (eg GC): pause of approximately 110321449ns.
GC pool 'PS Scavenge' had collection(s): count=1 time=8ms
2022-06-25 01:18:11,018 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@1f558164] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-a26e6a85-69e0-4d1b-9fdc-0decb2cb6032: Detected pause in JVM or host machine (eg GC): pause of approximately 100393009ns.
GC pool 'PS Scavenge' had collection(s): count=1 time=8ms
2022-06-25 01:18:11,018 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@4db088e8] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-489bfe9a-d541-48f0-84f9-7976b526cd96: Detected pause in JVM or host machine (eg GC): pause of approximately 108692742ns.
GC pool 'PS Scavenge' had collection(s): count=1 time=8ms
2022-06-25 01:18:11,018 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@596aab5f] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-om1: Detected pause in JVM or host machine (eg GC): pause of approximately 108688043ns.
GC pool 'PS Scavenge' had collection(s): count=1 time=8ms
2022-06-25 01:18:11,340 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:18:11,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:12,341 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:12,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:18:13,342 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:13,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:14,346 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:14,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:15,348 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:15,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:16,348 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:16,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:17,349 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:17,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:18,349 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:18,617 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:19,349 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:19,617 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:20,351 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:20,617 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:21,352 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:21,617 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:22,354 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:22,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:23,354 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:23,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:24,356 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:24,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:25,358 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:25,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:26,358 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:26,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:27,359 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:27,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:28,360 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:18:28,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:29,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:29,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:30,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:30,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:31,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:31,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:32,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:32,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:33,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:33,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:34,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:34,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:35,364 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:35,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:36,364 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:36,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:37,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:37,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:18:38,366 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:38,631 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:18:39,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:39,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:40,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:40,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:41,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:41,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:42,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:42,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:43,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:43,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:44,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:18:44,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:45,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:45,636 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:46,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:46,637 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:47,373 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:47,637 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:48,373 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:48,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:49,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:49,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:50,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:50,644 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:51,375 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:51,644 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:52,376 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:52,645 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:53,376 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:53,645 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:54,377 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:54,647 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:55,377 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:55,647 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:56,377 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:56,647 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:57,377 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:18:57,648 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:58,378 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:58,648 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:59,378 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:18:59,649 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:00,378 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:00,649 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:01,378 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:01,650 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:02,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:02,651 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:03,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:03,651 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:04,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:04,652 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:05,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:05,652 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:06,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:06,652 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:07,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:07,653 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:08,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:08,654 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:09,383 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:09,654 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:10,383 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:10,658 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:11,383 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:11,658 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:12,390 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:12,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:13,390 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:13,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:14,393 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:19:14,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:15,394 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:15,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:16,398 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:16,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:19:17,401 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:17,661 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:18,401 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:18,663 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:19,402 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:19,663 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:20,405 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:20,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:21,405 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:21,667 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:22,405 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:22,668 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:23,410 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:23,670 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:24,410 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:24,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:25,412 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:25,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:26,412 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:26,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:27,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:27,673 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:28,417 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:28,674 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:29,418 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:29,674 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:30,418 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:30,678 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:31,418 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:31,678 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:32,421 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:32,679 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:33,422 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:33,679 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:34,422 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:34,679 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:35,425 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:19:35,679 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:36,426 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:36,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:37,426 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:37,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:38,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:38,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:39,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:39,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:40,429 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:40,681 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:41,429 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:41,681 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:42,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:42,684 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:43,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:43,684 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:44,433 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:44,684 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:45,433 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:19:45,684 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:46,434 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:46,684 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:47,434 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:47,685 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:48,434 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:48,685 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:49,438 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:49,690 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:50,442 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:50,690 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:51,442 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:51,693 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:52,443 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:52,693 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:53,444 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:53,696 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:54,444 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:54,696 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:55,446 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:55,696 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:56,447 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:56,697 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:57,447 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:57,699 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:58,447 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:58,702 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:59,447 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:19:59,704 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:00,448 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:00,704 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:20:01,454 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:01,705 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:20:02,455 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:02,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:03,458 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:03,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:04,458 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:04,708 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:05,466 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:05,709 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:06,466 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:06,709 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:07,467 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:07,709 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:08,468 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:08,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:09,469 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:09,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:10,472 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:10,715 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:11,474 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:11,715 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:12,475 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:12,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:13,475 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:13,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:14,475 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:20:14,720 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:15,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:15,720 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:16,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:16,721 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:17,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:17,722 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:18,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:18,722 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:19,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:19,723 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:20,484 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:20:20,723 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:21,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:21,723 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:22,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:22,724 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:23,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:23,725 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:24,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:24,730 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:25,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:25,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:26,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:26,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:27,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:27,732 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:28,490 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:20:28,734 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:29,491 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:29,734 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:30,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:30,735 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:31,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:31,735 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:32,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:32,735 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:33,493 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:33,735 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:34,493 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:34,735 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:35,493 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:35,736 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:36,493 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:36,737 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:37,493 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:37,738 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:38,494 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:38,739 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:39,496 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:20:39,745 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:40,498 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:40,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:41,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:41,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:42,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:42,751 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:43,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:43,752 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:44,500 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:44,752 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:45,500 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:45,752 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:46,502 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:46,752 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:47,502 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:47,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:48,503 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:48,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:49,505 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:49,756 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:50,508 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:50,758 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:20:51,509 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:51,759 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:52,509 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:52,763 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:53,509 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:53,766 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:54,509 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:54,766 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:55,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:55,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:56,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:56,772 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:57,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:57,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:58,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:58,776 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:59,515 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:20:59,776 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:00,516 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:00,777 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:01,518 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:01,778 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:02,520 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:02,778 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:03,522 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:03,782 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:04,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:04,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:05,528 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:05,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:06,528 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:06,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:21:07,528 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:07,787 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:08,528 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:08,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:09,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:09,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:10,530 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:10,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:11,530 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:11,792 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:12,530 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:12,792 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:13,530 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:13,792 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:14,531 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:14,792 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:21:15,531 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:15,793 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:16,531 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:16,793 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:17,531 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:17,793 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:18,532 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:18,793 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:19,534 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:19,794 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:20,534 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:20,794 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:21,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:21,794 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:22,536 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:22,794 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:23,537 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:23,795 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:24,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:24,798 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:25,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:25,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:26,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:26,805 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:27,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:27,805 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:28,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:28,806 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:29,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:29,810 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:30,545 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:30,812 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:31,546 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:31,814 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:32,546 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:32,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:33,548 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:33,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:34,552 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:34,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:35,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:35,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:36,557 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:36,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:37,557 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:37,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:38,557 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:21:38,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:39,558 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:39,822 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:40,558 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:40,823 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:41,558 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:41,823 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:42,558 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:42,823 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:43,559 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:43,829 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:44,560 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:44,829 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:45,561 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:45,829 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:46,561 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:46,829 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:47,561 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:47,830 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:48,562 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:48,830 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:49,562 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:49,830 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:50,562 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:50,832 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:51,565 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:51,833 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:52,566 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:52,833 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:53,570 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:53,833 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:54,570 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:54,834 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:55,570 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:21:55,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:56,571 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:56,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:57,572 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:57,841 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:58,574 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:58,841 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:59,574 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:21:59,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:00,575 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:00,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:01,575 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:01,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:02,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:02,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:03,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:03,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:04,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:04,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:22:05,579 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:05,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:06,580 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:06,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:07,580 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:07,848 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:08,581 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:08,848 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:09,581 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:09,848 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:10,586 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:10,849 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:11,586 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:11,849 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:12,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:12,849 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:13,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:13,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:14,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:14,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:15,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:15,854 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:16,590 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:16,854 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:17,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:17,855 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:18,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:18,858 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:19,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:19,858 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:20,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:20,861 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:21,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:22:21,862 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:22,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:22,862 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:23,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:23,863 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:24,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:24,864 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:25,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:25,865 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:26,604 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:26,866 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:27,604 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:22:27,867 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:28,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:28,867 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:29,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:29,870 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:30,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:30,870 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:31,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:31,871 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:32,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:32,871 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:33,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:33,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:34,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:34,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:35,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:35,873 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:36,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:36,874 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:37,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:37,874 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:38,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:38,878 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:39,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:39,880 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:40,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:40,880 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:41,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:41,881 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:42,613 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:42,882 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:22:43,613 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:43,884 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:44,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:44,885 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:22:45,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:45,886 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:46,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:46,886 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:47,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:47,886 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:48,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:48,887 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:49,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:49,889 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:50,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:50,890 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:51,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:51,893 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:52,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:52,893 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:53,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:53,896 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:54,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:54,896 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:55,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:55,896 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:56,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:56,897 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:57,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:57,897 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:58,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:58,899 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:59,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:22:59,899 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:00,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:00,899 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:01,674 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:01,900 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:02,674 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:02,900 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:03,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:03,900 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:04,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:04,900 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:05,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:05,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:06,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:06,906 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:07,676 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:07,908 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:08,676 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:08,908 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:09,677 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:09,908 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:10,677 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:10,910 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:11,678 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:11,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:12,678 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:12,914 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:13,678 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:13,914 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:14,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:23:14,917 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:15,681 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:15,917 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:16,682 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:16,917 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:23:17,683 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:17,922 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:18,684 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:18,922 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:19,687 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:19,925 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:20,688 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:20,926 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:21,689 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:21,926 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:22,695 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:22,927 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:23,697 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:23,927 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:24,698 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:24,928 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:25,698 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:25,928 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:26,699 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:26,928 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:27,701 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:27,928 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:23:28,701 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:28,929 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:29,705 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:29,929 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:30,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:30,929 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:31,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:31,929 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:32,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:23:32,934 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:33,707 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:33,934 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:34,708 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:34,940 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:35,708 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:35,941 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:36,709 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:36,942 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:37,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:37,942 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:38,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:38,942 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:39,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:39,943 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:40,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:40,943 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:41,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:41,945 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:42,713 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:42,945 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:43,717 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:43,946 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:44,717 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:44,946 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:45,717 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:23:45,946 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:46,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:46,946 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:47,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:47,947 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:48,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:48,949 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:49,720 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:49,949 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:50,720 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:23:50,950 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:51,724 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:51,950 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:52,724 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:23:52,950 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:53,726 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:53,950 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:54,729 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:54,956 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:55,730 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:55,958 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:56,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:56,962 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:57,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:57,966 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:58,732 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:58,967 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:59,732 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:23:59,968 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:00,733 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:00,973 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:01,738 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:01,975 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:02,738 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:02,975 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:03,739 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:03,976 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:04,740 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:04,976 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:05,741 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:05,976 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:24:06,741 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:06,977 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:07,742 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:07,978 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:08,742 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:08,978 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:09,743 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:09,978 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:10,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:10,979 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:11,748 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:24:11,979 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:12,749 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:12,980 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:13,749 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:13,981 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:14,749 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:14,981 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:15,749 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:15,982 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:16,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:16,982 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:17,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:17,984 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:18,751 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:18,984 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:19,752 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:19,986 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:20,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:20,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:21,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:21,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:22,755 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:22,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:23,755 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:23,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:24,756 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:24,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:25,756 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:25,988 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:26,759 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:26,988 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:27,760 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:27,988 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:28,760 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:28,988 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:24:29,762 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:29,989 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:30,763 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:30,989 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:24:31,763 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:31,994 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:32,763 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:32,996 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:33,763 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:33,996 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:34,764 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:34,999 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:35,764 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:35,999 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:36,764 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:36,999 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:37,764 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:37,999 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:38,765 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:39,002 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:39,765 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:40,002 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:40,765 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:41,004 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:41,766 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:42,005 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:42,766 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:24:43,008 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:43,767 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:44,014 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:44,767 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:45,016 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:45,767 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:46,018 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:46,768 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:47,018 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:47,770 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:48,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:48,770 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:49,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:49,773 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:50,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:50,773 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:51,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:51,773 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:52,022 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:52,773 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:53,022 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:53,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:54,022 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:54,776 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:55,022 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:55,776 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:24:56,027 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:56,777 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:57,027 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:57,779 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:58,030 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:58,781 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:24:59,030 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:24:59,782 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:00,030 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:00,782 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:01,030 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:01,784 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:25:02,036 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:02,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:03,038 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:03,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:04,040 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:04,787 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:05,040 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:05,787 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:06,040 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:06,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:07,040 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:25:07,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:08,042 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:08,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:09,042 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:09,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:10,043 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:10,789 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:11,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:11,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:12,049 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:12,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:13,049 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:13,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:14,049 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:14,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:15,050 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:15,791 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:16,050 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:16,791 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:17,050 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:17,794 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:18,051 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:18,795 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:19,051 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:19,795 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:20,051 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:20,796 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:21,052 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:21,796 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:25:22,052 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:22,797 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:23,053 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:23,798 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:24,053 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:24,798 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:25,053 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:25:25,798 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:26,054 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:26,799 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:27,054 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:27,799 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:28,054 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:28,802 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:29,058 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:29,802 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:25:30,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:30,805 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:31,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:31,805 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:32,060 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:32,806 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:33,060 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:33,810 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:34,060 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:34,812 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:35,061 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:35,814 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:36,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:36,814 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:37,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:37,814 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:38,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:38,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:39,065 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:39,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:40,065 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:40,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:41,065 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:25:41,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:42,066 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:42,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:43,066 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:43,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:44,066 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:44,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:45,066 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:25:45,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:46,067 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:46,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:47,067 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:47,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:48,069 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:48,820 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:49,069 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:49,822 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:50,070 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:50,822 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:51,070 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:51,823 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:52,073 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:52,823 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:53,074 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:53,823 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:54,075 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:54,823 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:55,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:55,823 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:56,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:56,824 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:57,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:57,824 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:58,077 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:58,824 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:59,077 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:25:59,824 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:00,077 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:00,825 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:01,077 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:26:01,826 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:02,078 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:02,826 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:03,078 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:03,830 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:04,078 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:04,834 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:05,078 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:26:05,834 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:06,079 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:06,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:07,079 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:07,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:08,079 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:08,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:09,080 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:09,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:10,080 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:10,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:11,081 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:11,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:12,082 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:12,840 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:13,083 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:13,841 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:14,083 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:14,841 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:15,086 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:15,842 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:16,090 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:16,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:17,090 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:17,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:18,091 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:18,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:19,091 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:19,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:20,091 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:20,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:21,094 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:21,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:22,094 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:22,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:23,098 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:23,852 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:24,102 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:24,852 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:25,103 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:25,853 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:26,104 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:26,853 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:27,104 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:27,854 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:28,104 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:28,854 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:29,105 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:29,855 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:26:30,106 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:30,858 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:31,109 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:31,858 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:32,109 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:32,861 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:33,109 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:33,861 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:26:34,109 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:34,862 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:35,110 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:35,862 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:36,110 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:36,865 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:37,110 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:37,865 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:38,114 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:38,865 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:39,118 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:39,866 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:40,118 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:40,866 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:41,118 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:41,870 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:42,119 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:42,871 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:43,121 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:43,871 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:44,121 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:44,871 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:45,121 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:45,871 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:26:46,122 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:46,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:47,123 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:47,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:48,123 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:48,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:49,124 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:49,873 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:50,124 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:50,873 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:51,128 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:51,875 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:52,128 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:52,876 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:53,128 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:53,876 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:54,128 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:54,876 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:55,129 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:55,876 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:56,129 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:56,880 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:57,130 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:57,882 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:58,130 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:58,884 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:59,131 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:26:59,887 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:00,131 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:00,887 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:01,131 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:01,890 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:02,134 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:02,890 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:03,135 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:03,892 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:04,135 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:04,892 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:05,137 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:05,893 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:06,137 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:27:06,893 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:07,138 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:07,893 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:08,141 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:08,893 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:09,141 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:09,894 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:10,142 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:10,894 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:11,142 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:11,895 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:12,142 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:12,895 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:13,142 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:13,895 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:14,144 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:14,897 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:15,144 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:15,897 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:16,144 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:16,897 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:17,144 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:17,898 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:18,145 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:18,898 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:19,147 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:19,899 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:20,150 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:20,899 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:21,150 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:21,899 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:22,150 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:22,900 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:23,150 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:23,903 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:24,153 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:24,904 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:25,153 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:25,904 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:26,153 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:26,904 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:27,154 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:27,904 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:28,158 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:28,904 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:29,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:29,906 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:30,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:30,908 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:31,162 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:31,911 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:32,162 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:27:32,911 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:33,163 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:33,914 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:34,168 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:34,917 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:35,173 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:35,917 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:36,173 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:36,917 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:37,173 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:37,919 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:38,175 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:38,920 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:39,175 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:39,920 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:40,175 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:40,926 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:41,175 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:41,927 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:42,176 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:42,927 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:43,176 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:43,927 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:44,176 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:44,928 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:45,178 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:45,937 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:46,178 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:27:46,937 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:47,179 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:47,937 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:48,179 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:48,938 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:49,182 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:49,938 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:50,182 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:50,939 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:51,183 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:51,947 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:52,183 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:27:52,948 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:53,184 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:53,950 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:54,186 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:55,012 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:55,190 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:56,013 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:56,190 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:57,013 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:57,193 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:58,016 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:58,196 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:59,016 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:27:59,199 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:00,016 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:00,199 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:01,017 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:01,199 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:02,017 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:02,200 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:03,017 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:03,202 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:04,017 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:04,207 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:05,018 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:05,207 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:06,018 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:06,209 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:07,024 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:07,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:08,024 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:08,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:09,025 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:09,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:10,025 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:10,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:11,025 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:11,213 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:12,025 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:12,213 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:13,030 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:13,214 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:14,031 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:14,215 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:15,032 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:15,218 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:16,032 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:16,219 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:17,033 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:17,219 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:18,033 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:18,220 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:19,033 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:19,222 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:20,034 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:20,222 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:21,034 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:21,226 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:22,034 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:22,226 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:23,038 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:23,227 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:24,038 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:24,227 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:25,038 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:25,227 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:26,040 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:26,227 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:28:27,040 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:27,231 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:28,040 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:28,231 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:29,042 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:29,232 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:30,042 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:30,234 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:31,043 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:31,237 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:32,045 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:32,237 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:33,047 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:33,238 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:34,048 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:34,238 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:35,048 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:35,238 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:36,048 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:36,239 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:37,054 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:37,239 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:38,055 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:38,240 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:39,058 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:39,240 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:28:40,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:28:40,242 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:41,060 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:41,242 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:42,060 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:42,243 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:43,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:43,243 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:44,065 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:44,246 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:45,066 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:45,247 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:46,066 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:46,247 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:47,067 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:47,247 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:48,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:48,250 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:49,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:49,250 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:50,073 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:50,250 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:51,074 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:51,252 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:52,074 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:52,254 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:53,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:53,254 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:54,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:28:54,258 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:55,077 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:55,260 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:56,077 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:56,261 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:57,077 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:57,261 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:58,077 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:58,261 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:59,078 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:28:59,262 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:00,078 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:00,266 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:01,080 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:01,270 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:02,080 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:02,271 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:03,082 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:03,271 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:04,085 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:04,271 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:05,085 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:05,272 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:06,086 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:06,272 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:07,086 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:07,274 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:08,086 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:08,274 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:09,086 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:09,275 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:10,087 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:10,276 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:11,087 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:11,276 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:12,087 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:12,276 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:13,090 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:13,276 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:14,092 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:14,284 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:15,092 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:15,285 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:16,092 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:16,286 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:17,093 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:17,288 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:18,094 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:18,288 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:19,094 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:19,288 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:20,096 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:20,289 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:21,096 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:21,289 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:22,097 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:22,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:23,098 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:23,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:24,098 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:24,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:25,098 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:25,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:26,100 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:26,292 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:27,100 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:27,293 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:28,101 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:28,294 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:29,101 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:29,294 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:30,103 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:30,294 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:31,104 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:31,298 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:32,187 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:32,299 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:33,191 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:33,299 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:34,192 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:34,300 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:35,194 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:35,300 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:29:36,198 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:36,301 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:37,199 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:37,303 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:38,199 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:38,303 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:39,199 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:29:39,305 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:40,200 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:40,305 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:41,200 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:41,305 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:42,200 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:42,305 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:43,200 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:29:43,307 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:44,201 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:44,307 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:45,201 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:45,307 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:46,202 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:46,309 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:47,202 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:47,310 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:48,203 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:48,311 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:49,204 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:49,311 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:50,204 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:50,313 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:51,205 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:29:51,313 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:52,207 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:52,314 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:53,207 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:53,314 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:54,210 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:54,314 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:55,211 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:55,314 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:56,216 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:56,317 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:29:57,217 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:57,318 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:58,217 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:58,318 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:59,218 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:29:59,318 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:00,222 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:00,318 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:01,222 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:01,318 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:02,225 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:02,321 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:03,225 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:03,321 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:04,226 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:04,321 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:05,226 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:05,325 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:06,238 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:06,325 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:07,238 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:30:07,325 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:08,239 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:08,325 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:09,239 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:09,326 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:10,240 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:10,327 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:11,241 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:11,328 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:12,242 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:12,330 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:13,242 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:13,330 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:14,242 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:14,331 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:15,243 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:15,332 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:16,243 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:16,333 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:17,246 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:17,334 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:18,247 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:18,338 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:19,250 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:19,338 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:20,252 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:20,338 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:21,253 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:21,339 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:22,253 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:22,341 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:23,253 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:23,342 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:24,253 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:24,344 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:25,254 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:25,344 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:26,254 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:26,344 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:27,254 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:27,344 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:28,255 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:28,344 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:29,255 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:29,345 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:30,261 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:30,348 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:31,261 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:31,349 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:32,261 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:32,349 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:33,262 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:33,350 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:34,262 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:34,350 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:35,264 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:35,350 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:36,264 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:36,354 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:37,264 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:37,357 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:38,266 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:38,358 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:39,272 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:30:39,358 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:40,273 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:40,358 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:41,273 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:41,358 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:42,274 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:42,358 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:43,274 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:43,364 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:30:44,275 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:44,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:45,280 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:45,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:46,280 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:46,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:47,280 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:47,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:48,283 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:48,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:49,283 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:49,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:50,284 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:50,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:51,284 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:51,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:52,289 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:52,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:53,291 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:53,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:54,292 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:54,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:55,292 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:55,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:56,292 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:56,375 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:57,294 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:57,375 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:58,294 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:58,378 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:59,296 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:30:59,378 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:00,296 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:31:00,378 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:01,298 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:01,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:02,298 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:02,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:03,299 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:03,382 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:04,302 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:04,385 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:05,302 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:05,385 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:06,302 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:06,385 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:07,306 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:07,387 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:08,309 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:08,387 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:09,309 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:09,387 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:10,310 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:10,388 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:11,311 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:11,389 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:12,311 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:31:12,389 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:13,312 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:13,389 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:14,312 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:14,390 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:15,313 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:15,390 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:16,313 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:16,390 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:17,314 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:17,391 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:18,314 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:18,391 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:19,314 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:19,391 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:20,314 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:20,391 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:21,315 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:21,392 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:22,315 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:22,393 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:23,316 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:31:23,393 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:24,317 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:24,393 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:25,321 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:25,393 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:26,321 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:26,394 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:27,322 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:27,395 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:28,322 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:28,396 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:29,324 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:29,397 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:30,324 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:30,397 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:31,325 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:31,410 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:32,325 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:32,412 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:33,325 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:33,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:34,325 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:34,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:31:35,327 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:35,416 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:36,328 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:36,416 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:37,328 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:37,419 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:38,328 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:38,419 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:39,337 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:39,419 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:40,338 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:40,420 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:41,338 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:41,422 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:42,343 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:42,422 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:43,344 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:43,423 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:44,344 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:44,423 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:45,344 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:45,424 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:46,344 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:46,424 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:47,345 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:47,427 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:48,346 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:48,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:49,347 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:49,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:50,347 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:50,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:51,349 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:51,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:52,350 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:52,431 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:53,350 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:53,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:54,350 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:54,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:55,354 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:55,434 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:56,354 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:56,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:57,356 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:57,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:58,358 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:58,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:59,358 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:31:59,436 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:00,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:00,436 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:01,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:01,436 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:02,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:02,439 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:03,094 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@1a74e36] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-d5d86ba7-8a8a-4b58-b698-440423a66b5d: Detected pause in JVM or host machine (eg GC): pause of approximately 104808801ns.
GC pool 'PS Scavenge' had collection(s): count=1 time=8ms
2022-06-25 01:32:03,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:03,439 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:04,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:04,439 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:05,364 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:05,440 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:06,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:06,440 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:07,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:07,440 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:08,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:08,440 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:09,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:09,441 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:10,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:10,443 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:11,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:11,444 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:12,371 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:12,446 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:13,377 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:13,446 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:14,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:14,447 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:15,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:15,448 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:16,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:16,451 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:17,381 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:17,451 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:18,381 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:18,452 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:19,381 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:19,452 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:20,381 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:20,452 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:32:21,382 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:21,453 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:22,382 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:22,453 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:23,382 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:23,453 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:24,383 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:24,453 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:25,385 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:25,453 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:26,386 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:26,454 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:27,386 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:27,455 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:28,386 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:28,456 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:29,391 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:29,458 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:30,391 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:30,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:31,391 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:31,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:32,395 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:32,463 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:33,397 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:33,466 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:34,398 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:34,470 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:35,402 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:35,470 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:32:36,402 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:36,472 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:37,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:37,473 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:38,406 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:38,473 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:39,407 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:39,473 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:40,407 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:40,474 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:41,408 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:41,474 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:42,408 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:42,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:43,408 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:32:43,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:44,409 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:44,482 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:45,409 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:45,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:46,410 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:46,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:47,412 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:47,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:48,412 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:48,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:49,412 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:49,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:50,413 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:50,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:51,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:51,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:52,415 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:52,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:53,416 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:53,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:54,417 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:54,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:55,420 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:55,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:56,421 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:56,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:57,421 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:57,490 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:58,423 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:58,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:59,423 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:32:59,494 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:00,425 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:33:00,498 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:01,426 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:01,498 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:02,426 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:02,498 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:03,426 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:03,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:04,426 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:04,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:05,427 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:05,502 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:06,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:06,505 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:07,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:07,505 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:08,429 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:08,505 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:09,429 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:09,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:10,429 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:10,509 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:11,429 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:11,509 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:12,431 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:12,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:13,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:13,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:14,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:14,513 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:15,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:15,513 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:16,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:16,513 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:17,434 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:17,514 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:18,434 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:18,514 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:19,437 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:19,517 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:20,056 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@5ce72a25] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-ec2664f4-d768-4745-9abe-ef2a305e3ce9: Detected pause in JVM or host machine (eg GC): pause of approximately 106122218ns.
GC pool 'PS Scavenge' had collection(s): count=1 time=9ms
2022-06-25 01:33:20,440 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:20,517 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:21,440 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:21,517 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:33:22,440 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:22,518 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:23,442 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:23,521 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:24,442 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:24,522 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:25,442 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:25,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:26,442 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:26,525 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:27,443 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:27,525 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:28,443 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:28,525 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:29,444 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:29,525 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:30,444 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:30,526 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:31,444 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:33:31,526 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:32,445 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:32,526 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:33,449 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:33,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:34,449 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:34,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:35,450 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:35,528 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:36,450 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:36,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:37,450 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:37,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:38,451 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:38,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:39,451 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:39,531 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:33:40,452 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:40,532 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:41,452 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:41,532 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:42,454 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:42,532 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:43,456 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:43,532 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:44,456 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:44,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:45,457 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:45,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:46,457 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:46,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:47,458 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:47,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:48,458 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:48,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:49,459 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:49,542 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:50,459 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:50,542 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:51,460 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:51,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:52,460 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:33:52,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:53,461 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:53,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:54,461 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:54,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:33:55,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:55,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:56,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:56,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:57,463 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:57,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:58,463 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:58,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:59,464 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:33:59,545 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:00,464 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:00,545 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:01,470 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:01,545 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:02,472 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:02,546 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:03,472 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:34:03,546 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:04,473 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:04,548 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:05,474 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:05,550 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:06,477 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:06,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:07,477 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:07,552 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:08,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:08,552 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:09,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:09,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:10,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:10,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:11,484 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:11,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:12,484 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:12,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:13,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:13,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:14,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:14,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:15,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:15,566 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:16,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:16,570 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:17,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:17,570 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:18,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:18,571 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:19,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:19,571 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:20,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:20,574 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:21,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:21,578 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:22,490 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:22,582 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:23,490 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:23,582 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:24,491 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:24,582 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:25,491 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:25,583 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:26,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:26,584 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:27,494 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:27,588 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:28,494 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:28,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:29,494 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:29,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:30,496 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:30,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:31,496 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:31,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:32,496 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:32,596 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:33,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:33,596 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:34,502 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:34,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:34:35,502 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:35,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:36,503 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:36,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:37,503 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:37,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:38,503 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:38,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:39,505 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:39,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:40,505 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:40,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:41,506 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:41,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:42,506 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:42,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:43,506 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:43,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:44,506 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:34:44,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:45,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:45,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:46,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:46,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:47,509 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:47,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:48,509 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:48,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:49,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:49,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:50,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:50,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:51,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:51,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:52,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:52,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:53,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:53,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:54,513 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:54,617 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:55,513 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:55,617 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:56,518 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:56,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:57,518 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:57,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:58,519 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:58,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:59,521 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:34:59,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:00,521 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:00,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:01,522 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:01,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:02,525 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:02,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:03,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:03,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:04,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:04,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:05,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:05,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:06,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:35:06,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:07,528 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:07,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:08,530 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:08,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:09,531 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:09,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:10,531 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:10,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:11,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:11,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:12,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:12,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:13,534 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:13,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:14,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:14,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:15,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:15,629 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:16,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:16,629 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:17,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:17,629 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:18,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:18,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:19,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:19,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:20,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:20,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:21,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:21,631 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:22,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:22,631 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:23,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:23,633 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:35:24,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:24,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:25,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:35:25,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:26,541 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:26,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:27,542 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:27,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:28,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:28,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:29,547 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:29,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:30,548 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:30,637 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:31,550 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:31,639 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:32,550 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:32,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:33,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:33,641 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:34,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:34,642 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:35,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:35,642 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:36,552 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:36,643 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:37,552 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:37,646 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:38,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:38,646 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:39,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:39,649 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:40,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:40,650 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:41,560 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:41,650 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:42,564 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:42,656 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:43,566 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:43,656 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:44,566 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:44,657 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:45,567 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:45,657 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:46,567 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:46,658 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:47,567 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:47,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:48,568 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:48,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:49,570 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:35:49,661 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:50,571 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:50,661 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:51,571 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:51,662 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:52,573 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:52,662 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:53,573 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:53,664 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:54,573 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:54,664 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:55,575 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:55,665 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:56,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:56,666 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:57,578 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:57,668 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:58,578 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:58,670 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:59,579 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:35:59,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:00,580 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:00,672 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:01,582 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:01,677 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:02,583 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:02,678 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:03,584 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:03,678 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:04,584 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:04,679 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:05,586 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:05,686 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:06,586 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:06,689 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:07,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:07,690 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:08,590 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:08,690 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:09,590 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:09,690 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:10,591 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:10,691 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:11,591 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:11,698 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:12,591 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:12,702 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:13,591 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:13,702 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:14,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:14,702 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:15,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:15,702 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:16,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:16,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:17,593 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:17,707 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:18,593 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:36:18,707 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:19,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:19,710 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:20,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:20,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:21,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:21,717 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:22,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:22,719 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:36:23,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:23,721 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:24,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:24,721 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:25,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:36:25,721 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:26,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:26,723 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:27,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:27,728 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:28,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:28,729 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:29,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:29,729 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:30,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:30,729 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:31,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:31,730 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:32,603 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:32,730 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:33,603 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:33,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:34,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:34,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:35,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:35,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:36,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:36,731 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:36:37,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:37,732 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:38,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:38,736 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:39,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:39,738 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:40,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:40,738 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:41,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:41,738 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:42,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:42,739 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:43,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:43,740 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:44,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:44,741 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:45,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:45,741 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:46,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:46,741 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:47,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:47,741 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:36:48,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:48,742 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:49,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:49,743 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:50,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:50,743 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:51,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:51,744 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:52,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:52,744 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:53,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:53,748 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:54,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:54,749 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:55,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:55,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:56,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:56,751 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:57,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:57,752 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:58,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:58,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:59,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:36:59,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:00,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:37:00,755 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:01,629 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:01,758 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:02,629 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:02,759 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:03,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:03,760 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:04,633 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:37:04,760 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:05,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:05,761 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:06,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:06,761 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:07,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:07,762 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:08,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:08,762 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:09,639 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:09,762 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:37:10,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:10,766 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:11,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:11,766 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:37:12,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:12,831 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:13,641 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:13,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:14,641 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:14,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:15,644 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:15,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:16,644 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:16,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:17,644 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:17,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:18,644 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:18,840 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:19,645 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:19,841 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:20,645 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:20,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:21,646 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:21,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:22,646 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:22,844 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:23,647 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:23,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:24,647 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:24,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:25,647 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:25,847 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:26,650 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:26,847 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:27,650 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:27,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:28,651 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:28,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:29,651 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:29,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:30,653 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:30,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:31,657 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:31,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:32,657 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:32,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:33,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:33,852 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:34,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:34,852 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:35,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:35,852 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:36,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:36,854 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:37,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:37,854 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:38,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:38,855 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:39,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:39,855 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:40,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:40,859 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:41,661 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:41,859 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:42,661 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:42,859 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:43,662 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:43,862 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:37:44,662 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:44,863 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:45,662 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:45,863 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:46,665 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:46,865 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:47,665 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:47,865 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:48,668 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:48,866 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:49,668 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:49,866 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:50,668 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:50,866 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:51,668 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:51,867 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:52,672 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:52,868 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:53,672 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:53,868 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:54,672 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:54,869 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:55,672 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:37:55,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:56,673 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:56,873 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:57,673 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:57,873 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:58,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:58,873 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:59,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:37:59,876 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:00,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:00,881 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:01,675 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:01,882 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:38:02,676 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:02,886 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:03,676 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:03,886 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:04,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:04,891 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:05,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:05,893 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:06,681 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:06,893 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:07,681 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:07,895 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:08,684 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:08,895 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:09,684 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:09,895 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:38:10,685 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:10,896 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:11,685 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:11,896 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:12,685 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:12,896 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:13,686 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:13,896 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:14,686 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:38:14,897 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:15,736 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:15,897 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:16,736 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:16,899 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:17,738 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:17,899 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:18,739 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:18,899 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:19,742 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:19,900 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:20,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:20,901 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:21,748 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:21,901 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:22,748 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:22,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:23,748 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:23,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:24,748 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:24,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:25,749 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:25,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:38:26,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:26,903 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:27,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:27,903 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:28,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:28,903 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:29,751 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:29,904 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:30,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:30,904 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:31,759 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:31,904 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:32,759 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:32,904 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:33,760 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:33,905 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:34,760 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:34,905 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:35,760 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:35,906 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:36,763 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:36,906 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:37,766 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:37,906 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:38,770 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:38,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:39,770 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:39,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:40,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:40,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:41,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:41,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:42,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:42,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:43,772 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:43,917 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:44,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:44,921 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:45,782 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:45,928 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:46,782 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:46,929 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:47,783 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:47,929 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:48,783 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:48,929 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:49,784 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:49,930 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:50,785 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:50,936 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:51,787 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:51,937 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:52,787 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:52,937 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:53,787 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:53,938 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:54,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:54,938 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:55,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:55,940 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:56,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:56,940 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:57,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:57,940 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:58,791 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:58,942 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:59,791 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:38:59,942 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:00,791 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:00,946 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:01,792 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:01,950 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:02,794 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:02,950 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:03,795 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:03,951 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:04,798 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:04,951 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:05,346 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@37a08f49] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-fb218fe0-94a8-44a0-a252-d3cae8685c6f: Detected pause in JVM or host machine (eg GC): pause of approximately 112222959ns.
GC pool 'PS Scavenge' had collection(s): count=1 time=11ms
2022-06-25 01:39:05,801 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:05,954 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:06,801 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:39:06,958 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:07,802 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:07,958 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:08,802 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:08,963 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:09,802 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:09,963 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:10,803 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:10,966 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:11,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:11,970 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:12,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:12,970 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:13,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:13,971 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:14,805 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:14,974 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:15,809 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:15,977 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:16,809 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:16,977 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:17,809 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:17,977 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:18,811 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:18,978 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:19,811 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:19,981 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:20,811 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:20,981 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:21,811 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:21,982 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:22,812 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:22,982 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:23,813 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:23,982 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:24,813 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:24,984 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:25,814 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:25,984 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:26,814 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:26,984 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:27,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:27,994 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:28,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:28,994 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:29,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:39:29,995 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:30,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:30,995 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:31,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:31,962 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@41ccc90b] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-0414aa62-2593-4022-a495-25b345e9257d: Detected pause in JVM or host machine (eg GC): pause of approximately 101236560ns.
GC pool 'PS Scavenge' had collection(s): count=1 time=8ms
2022-06-25 01:39:31,995 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:39:32,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:32,997 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:33,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:33,997 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:39:34,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:34,998 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:35,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:35,998 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:36,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:37,000 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:37,818 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:38,001 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:38,820 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:39,001 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:39,820 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:40,002 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:40,820 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:39:41,003 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:41,838 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:42,005 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:39:42,843 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:43,006 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:43,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:44,006 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:44,849 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:45,008 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:45,849 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:46,014 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:46,849 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:47,014 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:47,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:48,015 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:48,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:49,015 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:49,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:50,015 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:50,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:51,016 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:51,851 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:52,019 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:52,854 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:53,019 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:53,855 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:54,020 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:54,855 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:55,020 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:55,855 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:56,020 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:56,855 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:57,020 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:57,856 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:58,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:58,856 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:59,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:39:59,856 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:00,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:00,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:01,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:01,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:02,022 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:02,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:03,025 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:03,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:40:04,026 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:04,860 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:05,026 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:05,861 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:06,027 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:06,861 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:07,027 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:07,866 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:08,027 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:08,866 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:09,027 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:09,867 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:10,029 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:10,867 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:11,030 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:11,867 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:12,030 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:12,868 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:13,031 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:13,870 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:14,032 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:14,870 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:15,032 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:15,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:16,034 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:16,874 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:17,034 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:17,876 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:18,035 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:18,878 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:19,037 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:19,880 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:20,038 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:20,881 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:21,038 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:40:21,881 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:22,039 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:22,881 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:23,040 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:23,881 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:24,040 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:40:24,882 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:25,043 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:25,882 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:26,044 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:26,884 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:27,044 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:27,885 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:28,044 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:28,886 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:29,045 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:29,886 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:30,045 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:30,887 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:31,045 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:31,890 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:32,109 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:32,890 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:33,109 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:33,891 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:34,113 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:34,891 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:35,114 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:35,891 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:40:36,114 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:36,892 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:37,115 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:37,892 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:38,115 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:38,893 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:39,118 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:39,898 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:40,118 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:40:40,899 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:41,122 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:41,900 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:42,122 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:42,900 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:43,123 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:43,901 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:44,124 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:40:44,901 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:45,124 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:45,901 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:46,125 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:40:46,901 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:47,126 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:47,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:48,126 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:48,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:49,130 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:49,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:50,130 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:50,903 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:51,132 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:51,903 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:52,132 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:52,903 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:53,133 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:53,904 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:54,134 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:54,904 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:55,135 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:55,907 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:56,136 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:56,907 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:57,136 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:57,908 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:58,137 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:58,909 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:40:59,137 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:40:59,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:00,137 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:00,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:01,137 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:01,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:41:02,138 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:02,914 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:03,138 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:03,914 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:04,138 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:04,916 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:05,138 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:05,918 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:06,139 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:06,919 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:07,139 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:07,919 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:08,140 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:08,922 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:09,140 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:09,923 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:10,140 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:10,926 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:11,140 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:11,926 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:12,141 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:12,926 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:13,142 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:13,927 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:14,143 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:14,928 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:15,145 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:15,928 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:16,145 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:16,928 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:17,145 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:17,930 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:18,146 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:18,933 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:19,146 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:19,933 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:20,146 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:20,935 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:21,146 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:21,937 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:22,148 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:41:22,937 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:23,149 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:23,942 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:24,150 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:24,942 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:25,155 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:25,943 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:26,156 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:26,943 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:41:27,156 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:27,944 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:28,157 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:28,945 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:29,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:29,945 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:30,160 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:30,946 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:31,164 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:31,947 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:32,165 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:32,951 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:33,165 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:33,951 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:34,165 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:34,952 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:35,165 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:41:35,952 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:36,166 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:36,953 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:37,170 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:37,953 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:38,171 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:38,953 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:39,174 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:39,953 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:41:40,176 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:40,954 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:41,178 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:41,954 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:42,181 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:42,955 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:43,181 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:43,956 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:44,181 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:44,956 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:45,182 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:45,956 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:46,182 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:46,958 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:47,185 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:47,958 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:48,186 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:48,959 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:49,186 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:49,960 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:50,187 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:50,960 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:41:51,187 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:51,962 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:52,187 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:52,962 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:53,188 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:53,962 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:54,188 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:54,962 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:55,188 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:55,964 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:56,189 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:56,964 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:41:57,191 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:57,965 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:58,193 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:58,965 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:59,193 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:41:59,965 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:00,213 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:00,965 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:42:01,213 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:01,966 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:02,213 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:42:02,966 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:03,214 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:03,966 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:04,214 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:04,967 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:05,214 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:05,967 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:06,216 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:06,967 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:07,217 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:07,970 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:08,224 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:08,970 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:09,224 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:42:09,971 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:10,225 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:10,971 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:11,228 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:11,971 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:12,228 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:12,972 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:13,229 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:13,972 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:42:14,231 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:14,973 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:15,231 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:15,973 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:16,234 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:16,974 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:17,235 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:17,974 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:18,236 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:18,974 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:42:19,238 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:19,975 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:20,238 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:20,975 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:21,238 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:21,977 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:22,239 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:22,977 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:23,239 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:23,981 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:24,239 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:24,981 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:25,240 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:25,981 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:26,241 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:26,984 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:27,241 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:27,984 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:28,241 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:28,985 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:29,241 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:29,986 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:30,242 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:30,986 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:31,242 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:31,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:32,244 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:32,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:33,248 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:33,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:34,248 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:34,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:35,250 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:42:35,992 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:36,254 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:36,992 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:37,258 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:37,992 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:38,258 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:38,992 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:39,262 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:39,993 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:40,267 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:40,993 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:41,268 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:41,993 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:42,270 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:42,994 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:43,274 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:43,994 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:44,274 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:44,996 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:45,275 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:45,996 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:46,275 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:42:47,001 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:47,276 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:48,002 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:48,276 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:49,002 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:49,276 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:50,002 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:50,277 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:51,003 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:51,278 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:52,003 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:52,279 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:53,008 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:53,281 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:54,008 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:54,286 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:55,008 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:55,289 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:56,008 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:56,289 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:57,010 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:57,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:58,014 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:58,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:59,014 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:42:59,292 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:00,016 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:00,293 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:01,016 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:01,295 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:02,018 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:02,296 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:03,018 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:03,296 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:04,026 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:04,298 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:05,027 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:05,301 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:06,028 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:43:06,301 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:07,029 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:07,303 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:08,029 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:08,304 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:09,038 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:09,304 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:10,040 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:10,304 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:11,041 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:11,305 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:43:12,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:12,310 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:13,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:13,310 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:14,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:14,312 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:15,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:15,314 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:16,054 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:16,322 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:17,054 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:17,322 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:18,057 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:18,323 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:19,057 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:19,326 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:20,057 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:20,327 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:21,057 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:21,327 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:22,058 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:22,330 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:23,059 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:23,330 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:24,060 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:24,331 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:25,060 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:25,331 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:26,061 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:26,331 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:27,061 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:27,331 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:28,061 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:28,332 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:29,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:29,332 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:30,063 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:30,332 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:31,063 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:31,333 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:32,065 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:32,333 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:33,070 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:33,333 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:34,072 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:34,334 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:35,072 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:35,334 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:36,072 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:36,338 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:37,074 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:37,338 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:38,074 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:38,339 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:39,074 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:39,339 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:40,074 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:40,339 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:41,075 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:41,339 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:42,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:42,340 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:43,077 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:43,340 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:44,078 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:44,340 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:45,080 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:45,341 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:46,081 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:46,341 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:47,082 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:47,341 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:48,083 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:48,342 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:49,087 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:49,342 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:50,088 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:50,342 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:51,092 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:51,344 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:52,092 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:52,345 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:53,092 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:53,345 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:54,093 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:43:54,346 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:55,094 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:55,348 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:56,094 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:56,351 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:57,096 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:57,351 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:58,096 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:58,351 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:59,096 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:43:59,352 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:00,097 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:00,352 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:01,097 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:01,352 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:02,098 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:02,352 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:44:03,098 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:03,353 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:04,098 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:04,354 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:05,098 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:05,354 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:06,099 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:06,360 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:07,101 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:07,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:08,101 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:44:08,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:09,102 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:09,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:10,102 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:10,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:11,102 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:11,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:12,103 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:12,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:13,103 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:13,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:14,103 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:14,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:15,104 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:15,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:16,104 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:16,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:17,106 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:17,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:18,106 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:18,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:19,107 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:19,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:20,107 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:20,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:21,107 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:21,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:22,108 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:22,372 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:23,109 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:23,373 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:24,109 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:24,373 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:25,109 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:25,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:26,110 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:26,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:27,110 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:27,375 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:28,110 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:28,375 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:44:29,112 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:29,378 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:30,114 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:30,378 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:31,114 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:31,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:32,114 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:32,382 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:33,114 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:33,382 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:34,115 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:34,386 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:35,116 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:35,386 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:36,116 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:36,390 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:37,116 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:37,390 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:38,117 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:38,392 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:39,117 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:39,392 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:40,119 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:40,395 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:41,121 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:41,399 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:42,126 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:42,399 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:43,130 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:43,400 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:44,130 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:44:44,400 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:45,131 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:45,401 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:46,131 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:46,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:47,132 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:47,406 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:48,133 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:48,406 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:49,135 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:49,408 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:50,136 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:50,408 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:51,136 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:51,409 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:52,137 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:52,409 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:53,137 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:53,409 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:54,138 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:54,409 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:55,138 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:55,411 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:56,138 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:56,412 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:57,139 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:57,412 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:44:58,139 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:58,413 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:59,141 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:44:59,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:00,141 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:00,418 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:01,150 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:01,418 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:02,152 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:02,419 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:03,152 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:03,419 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:04,153 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:04,420 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:05,154 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:05,421 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:06,156 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:06,422 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:07,156 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:07,425 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:08,157 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:08,425 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:09,158 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:09,427 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:10,158 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:10,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:11,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:11,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:12,161 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:12,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:13,164 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:45:13,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:14,165 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:14,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:15,166 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:15,433 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:16,166 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:45:16,433 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:17,167 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:17,433 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:18,167 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:18,433 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:19,168 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:19,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:20,169 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:20,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:21,169 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:21,435 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:22,170 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:22,436 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:23,172 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:23,436 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:24,172 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:24,436 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:25,172 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:25,438 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:26,173 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:26,439 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:27,173 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:27,439 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:28,173 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:28,439 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:29,173 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:29,440 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:30,178 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:30,440 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:31,178 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:31,444 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:32,180 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:45:32,444 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:33,181 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:33,445 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:34,182 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:34,446 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:35,186 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:35,446 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:36,190 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:36,448 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:37,190 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:37,451 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:38,192 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:38,451 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:39,193 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:39,452 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:40,193 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:40,452 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:41,194 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:41,452 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:42,195 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:42,452 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:43,195 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:43,452 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:44,198 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:44,453 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:45,198 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:45,453 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:46,199 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:46,453 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:47,199 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:47,453 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:48,199 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:48,454 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:49,199 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:49,454 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:50,199 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:50,454 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:51,201 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:51,454 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:52,201 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:52,454 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:53,201 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:53,455 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:54,203 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:54,460 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:55,203 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:55,460 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:56,206 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:56,461 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:57,206 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:57,461 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:58,207 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:58,461 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:59,207 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:45:59,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:00,207 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:00,465 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:01,209 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:01,465 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:02,209 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:46:02,465 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:03,210 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:03,465 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:04,210 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:04,466 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:05,211 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:05,471 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:06,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:06,471 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:07,034 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@27040a78] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-f368a730-3857-4d18-b0ff-e0c952296109: Detected pause in JVM or host machine (eg GC): pause of approximately 101637010ns.
GC pool 'PS Scavenge' had collection(s): count=1 time=9ms
2022-06-25 01:46:07,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:07,472 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:08,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:08,473 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:09,214 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:09,474 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:10,216 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:10,474 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:11,218 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:11,474 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:12,218 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:12,475 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:13,219 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:13,475 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:14,220 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:14,475 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:15,220 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:15,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:16,221 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:16,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:17,221 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:17,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:18,221 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:18,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:19,224 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:19,477 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:20,226 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:20,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:21,226 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:21,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:22,228 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:22,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:23,228 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:46:23,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:24,229 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:24,482 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:25,229 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:25,482 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:26,229 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:26,482 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:27,230 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:27,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:46:28,231 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:28,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:29,231 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:29,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:30,232 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:30,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:31,232 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:31,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:46:32,234 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:32,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:33,234 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:33,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:34,237 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:34,490 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:46:35,237 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:35,491 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:36,237 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:36,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:37,238 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:37,493 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:37,720 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@37a08f49] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-fb218fe0-94a8-44a0-a252-d3cae8685c6f: Detected pause in JVM or host machine (eg GC): pause of approximately 109572122ns.
GC pool 'PS Scavenge' had collection(s): count=1 time=8ms
2022-06-25 01:46:38,238 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:38,494 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:39,238 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:39,494 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:40,242 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:40,494 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:41,244 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:41,494 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:42,250 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:42,498 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:43,250 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:43,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:44,253 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:44,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:45,255 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:45,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:46:46,258 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:46,500 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:47,259 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:47,500 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:48,259 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:48,500 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:49,259 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:49,500 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:50,260 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:50,501 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:51,260 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:51,501 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:52,260 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:52,501 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:53,260 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:53,501 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:54,261 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:54,501 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:55,261 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:55,502 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:56,261 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:56,502 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:57,261 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:57,503 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:58,262 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:58,503 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:59,262 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:46:59,503 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:00,266 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:00,504 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:01,266 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:01,506 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:02,266 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:02,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:03,267 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:03,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:04,267 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:04,508 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:05,268 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:05,508 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:06,268 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:06,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:07,268 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:07,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:08,271 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:08,511 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:09,271 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:09,516 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:10,271 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:10,516 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:11,272 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:11,517 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:12,274 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:12,523 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:47:13,274 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:13,524 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:14,274 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:14,524 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:15,278 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:15,525 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:16,278 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:16,525 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:17,282 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:17,525 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:18,282 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:18,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:19,282 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:19,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:20,284 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:20,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:21,284 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:21,529 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:22,285 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:22,532 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:23,285 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:23,532 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:24,286 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:24,532 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:47:25,286 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:25,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:26,287 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:26,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:27,287 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:27,533 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:28,287 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:28,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:29,288 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:29,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:30,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:30,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:31,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:31,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:32,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:32,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:33,290 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:33,549 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:34,291 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:34,550 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:35,294 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:35,550 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:36,294 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:36,550 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:37,296 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:37,551 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:38,296 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:38,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:39,296 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:39,558 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:40,297 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:40,559 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:47:41,302 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:41,560 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:42,302 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:42,560 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:43,303 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:43,564 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:44,303 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:44,564 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:47:45,304 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:45,565 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:46,304 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:46,566 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:47,304 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:47,568 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:48,304 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:47:48,568 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:49,305 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:49,569 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:50,305 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:50,569 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:51,307 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:51,569 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:52,308 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:52,569 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:53,308 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:53,571 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:54,309 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:54,572 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:55,309 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:55,574 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:56,309 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:56,574 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:57,309 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:57,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:58,310 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:58,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:59,310 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:47:59,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:00,310 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:00,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:01,311 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:01,579 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:02,314 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:02,579 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:03,318 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:03,580 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:04,319 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:04,582 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:05,319 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:48:05,584 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:06,320 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:06,584 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:07,322 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:07,584 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:08,322 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:08,584 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:09,322 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:09,584 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:10,322 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:10,585 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:11,326 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:11,585 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:12,326 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:12,585 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:13,327 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:13,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:14,327 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:14,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:15,329 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:15,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:16,329 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:16,588 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:17,330 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:17,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:18,330 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:18,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:19,334 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:19,589 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:20,334 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:20,590 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:21,336 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:21,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:22,336 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:22,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:23,340 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:23,593 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:24,341 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:24,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:25,341 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:25,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:26,341 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:26,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:27,341 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:27,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:28,342 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:28,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:29,344 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:29,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:30,346 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:30,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:31,346 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:31,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:32,349 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:32,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:33,349 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:33,603 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:34,349 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:34,604 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:35,350 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:35,604 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:36,350 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:36,604 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:37,354 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:37,604 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:38,357 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:38,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:39,357 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:39,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:40,357 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:40,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:41,359 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:41,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:42,359 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:42,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:43,360 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:43,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:44,360 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:44,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:45,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:45,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:46,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:46,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:47,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:47,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:48,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:48,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:49,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:49,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:50,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:50,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:51,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:51,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:52,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:52,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:53,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:53,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:54,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:54,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:55,371 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:55,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:56,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:56,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:57,378 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:57,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:58,378 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:58,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:59,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:48:59,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:00,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:00,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:01,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:01,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:02,381 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:02,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:03,381 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:49:03,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:04,382 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:04,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:05,382 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:05,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:06,382 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:06,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:07,382 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:07,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:08,383 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:08,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:09,384 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:09,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:10,384 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:10,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:11,384 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:11,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:12,384 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:12,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:13,384 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:13,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:14,385 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:14,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:15,385 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:15,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:16,386 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:16,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:17,387 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:17,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:18,387 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:18,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:19,387 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:19,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:20,392 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:20,636 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:21,392 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:21,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:22,392 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:22,639 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:23,392 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:23,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:24,393 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:24,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:25,393 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:25,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:26,393 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:26,642 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:27,393 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:49:27,642 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:28,394 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:28,643 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:29,394 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:29,643 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:30,394 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:30,643 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:31,395 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:31,646 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:32,395 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:32,646 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:33,395 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:33,647 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:34,396 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:34,650 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:35,396 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:35,650 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:36,397 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:36,651 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:37,397 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:37,651 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:38,400 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:38,654 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:39,401 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:39,656 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:40,401 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:40,656 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:49:41,401 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:41,657 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:42,401 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:42,657 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:43,401 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:43,657 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:44,402 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:44,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:45,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:45,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:46,406 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:46,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:47,406 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:47,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:48,410 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:48,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:49,412 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:49,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:50,417 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:50,661 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:51,419 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:51,661 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:52,420 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:52,662 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:53,422 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:53,662 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:54,426 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:54,662 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:55,429 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:55,663 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:56,429 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:56,668 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:57,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:57,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:58,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:58,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:59,431 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:49:59,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:00,431 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:00,671 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:01,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:01,673 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:02,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:02,673 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:03,432 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:03,674 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:04,433 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:04,674 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:05,436 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:05,674 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:06,436 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:06,674 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:07,436 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:07,676 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:08,437 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:08,677 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:09,437 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:09,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:10,437 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:10,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:11,438 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:11,686 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:12,438 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:12,690 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:13,438 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:13,690 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:14,440 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:14,694 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:15,440 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:15,694 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:16,441 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:16,698 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:17,442 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:17,701 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:18,443 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:18,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:19,444 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:19,708 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:20,445 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:20,708 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:21,445 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:21,708 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:22,446 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:22,710 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:23,446 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:23,711 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:24,454 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:24,711 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:25,454 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:25,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:26,454 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:26,715 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:27,455 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:27,715 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:28,455 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:28,715 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:29,456 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:29,715 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:30,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:30,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:31,468 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:31,719 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:32,468 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:32,719 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:33,468 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:33,722 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:34,469 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:34,725 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:35,469 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:35,725 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:36,470 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:36,726 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:37,474 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:37,726 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:38,474 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:38,726 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:50:39,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:39,727 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:40,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:40,727 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:41,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:41,728 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:42,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:42,730 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:43,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:43,732 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:44,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:44,734 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:45,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:45,734 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:46,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:46,734 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:47,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:47,735 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:48,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:48,738 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:49,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:49,739 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:50,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:50,739 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:51,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:51,740 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:52,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:52,740 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:53,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:53,740 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:54,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:54,740 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:55,490 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:55,741 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:56,491 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:56,741 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:57,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:57,741 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:58,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:58,741 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:59,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:50:59,741 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:00,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:00,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:01,492 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:01,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:02,493 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:02,749 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:03,493 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:03,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:04,493 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:04,750 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:05,493 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:51:05,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:06,495 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:06,755 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:07,495 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:07,756 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:08,495 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:08,756 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:09,496 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:09,756 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:10,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:10,756 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:11,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:11,757 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:12,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:12,758 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:13,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:13,762 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:14,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:14,765 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:15,503 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:15,765 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:16,504 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:16,767 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:17,504 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:17,767 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:18,504 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:18,767 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:19,504 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:19,767 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:20,506 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:20,767 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:21,506 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:21,768 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:22,506 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:22,769 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:23,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:23,770 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:24,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:24,770 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:25,507 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:25,770 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:26,510 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:26,770 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:27,511 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:27,770 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:28,511 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:28,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:29,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:29,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:30,512 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:30,772 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:31,513 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:31,772 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:32,513 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:32,772 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:33,513 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:33,772 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:34,513 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:34,772 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:35,514 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:35,773 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:36,518 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:36,773 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:37,521 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:37,773 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:38,522 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:38,773 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:39,524 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:39,773 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:40,526 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:40,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:41,526 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:41,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:42,527 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:42,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:43,528 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:43,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:51:44,530 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:44,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:45,531 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:45,777 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:46,531 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:46,778 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:47,531 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:47,782 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:48,532 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:48,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:49,534 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:49,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:50,534 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:50,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:51,534 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:51,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:52,536 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:52,792 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:53,536 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:53,792 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:54,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:54,794 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:55,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:55,796 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:56,538 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:56,796 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:57,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:57,796 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:58,539 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:58,796 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:59,540 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:51:59,798 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:00,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:00,799 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:01,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:01,799 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:02,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:52:02,803 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:03,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:03,803 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:04,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:04,803 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:05,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:05,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:06,544 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:06,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:07,545 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:07,808 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:08,545 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:08,808 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:09,545 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:09,808 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:10,548 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:10,810 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:11,548 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:11,810 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:12,549 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:12,811 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:13,550 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:13,811 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:14,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:14,812 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:15,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:15,812 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:16,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:16,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:17,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:17,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:18,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:18,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:19,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:19,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:20,556 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:20,815 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:21,557 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:21,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:22,558 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:22,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:23,558 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:23,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:24,559 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:24,818 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:25,560 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:25,821 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:26,562 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:26,821 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:27,562 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:27,821 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:28,562 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:28,822 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:29,563 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:29,822 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:30,563 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:30,823 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:31,564 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:31,831 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:32,570 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:32,833 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:33,570 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:33,833 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:34,570 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:34,834 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:35,574 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:35,834 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:36,576 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:36,835 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:37,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:37,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:38,577 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:38,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:39,578 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:39,839 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:40,578 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:40,846 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:41,580 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:41,847 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:42,582 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:42,847 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:43,582 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:43,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:44,582 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:44,850 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:45,583 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:45,854 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:46,583 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:46,855 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:47,585 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:47,855 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:52:48,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:48,856 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:49,587 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:49,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:50,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:50,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:51,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:51,857 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:52,593 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:52,858 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:53,593 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:53,858 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:54,593 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:54,859 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:55,597 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:55,859 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:56,597 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:56,861 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:57,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:57,861 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:58,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:58,861 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:59,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:52:59,861 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:00,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:00,861 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:01,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:01,862 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:02,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:02,862 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:03,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:03,863 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:04,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:04,863 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:05,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:53:05,864 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:06,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:06,868 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:07,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:07,869 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:08,613 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:08,870 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:09,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:09,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:10,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:10,874 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:11,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:11,874 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:12,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:12,874 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:13,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:13,875 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:14,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:14,875 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:15,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:15,876 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:16,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:16,876 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:17,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:17,879 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:18,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:18,880 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:19,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:19,881 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:20,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:20,885 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:21,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:21,886 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:22,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:22,889 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:23,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:23,889 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:24,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:53:24,890 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:25,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:25,894 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:26,636 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:26,894 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:27,636 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:27,894 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:53:28,636 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:28,895 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:29,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:29,895 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:30,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:30,895 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:31,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:31,895 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:32,639 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:32,895 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:33,641 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:33,896 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:34,641 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:34,896 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:35,642 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:35,896 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:36,643 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:36,896 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:37,643 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:37,896 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:38,647 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:38,897 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:39,647 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:39,898 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:40,649 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:40,898 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:41,654 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:41,899 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:42,654 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:42,899 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:43,655 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:43,899 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:44,655 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:44,899 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:53:45,655 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:45,906 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:46,656 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:46,906 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:47,656 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:47,906 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:48,656 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:48,910 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:49,656 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:49,914 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:50,657 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:50,915 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:51,657 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:51,918 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:52,657 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:52,922 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:53,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:53,924 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:54,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:54,924 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:55,659 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:55,928 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:56,660 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:56,928 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:57,661 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:57,928 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:58,661 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:58,928 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:59,661 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:53:59,957 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:54:00,661 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:00,958 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:01,662 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:01,959 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:02,662 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:02,960 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:03,662 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:03,962 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:04,662 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:04,962 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:05,662 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:05,962 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:06,663 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:06,966 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:07,663 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:07,966 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:08,663 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:08,966 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:09,663 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:09,967 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:10,664 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:10,967 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:11,664 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:11,967 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:12,667 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:12,967 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:13,667 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:13,970 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:14,668 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:14,970 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:15,668 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:15,970 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:16,129 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@aa6ee36] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-d6b643ca-dbb5-4f56-bb4f-5aafb3f408f2: Detected pause in JVM or host machine (eg GC): pause of approximately 102947514ns.
GC pool 'PS Scavenge' had collection(s): count=1 time=8ms
2022-06-25 01:54:16,670 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:16,971 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:17,670 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:17,971 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:18,673 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:18,971 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:19,673 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:19,972 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:20,673 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:54:20,972 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:21,674 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:21,972 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:22,674 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:22,972 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:23,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:23,973 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:24,680 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:54:24,973 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:25,681 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:25,973 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:26,685 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:26,973 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:27,687 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:27,974 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:28,687 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:28,974 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:29,688 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:29,976 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:30,690 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:30,976 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:31,690 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:31,976 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:32,692 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:32,979 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:33,692 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:33,979 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:34,696 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:34,979 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:35,697 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:35,980 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:36,698 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:36,986 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:37,702 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:37,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:38,703 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:38,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:39,703 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:39,991 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:40,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:40,994 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:41,706 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:41,994 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:42,710 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:42,995 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:43,710 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:43,998 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:44,711 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:44,998 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:45,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:45,998 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:46,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:46,998 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:47,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:47,999 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:48,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:48,999 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:49,712 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:50,000 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:50,714 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:51,000 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:51,716 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:52,000 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:52,717 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:53,000 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:53,717 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:54,000 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:54,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:55,001 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:55,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:56,001 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:56,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:57,004 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:57,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:58,008 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:58,718 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:59,013 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:54:59,722 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:00,013 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:00,728 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:01,013 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:01,728 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:02,013 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:02,730 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:03,014 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:03,734 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:04,014 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:04,734 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:05,014 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:05,736 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:06,015 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:06,736 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:07,015 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:07,737 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:08,019 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:08,737 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:09,020 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:09,738 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:10,020 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:10,739 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:11,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:11,742 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:12,021 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:12,742 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:13,023 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:13,743 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:14,023 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:14,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:15,024 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:15,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:16,024 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:16,746 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:17,025 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:17,747 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:18,025 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:18,749 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:19,025 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:19,749 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:20,025 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:20,752 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:21,025 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:21,752 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:22,026 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:22,752 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:23,027 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:23,752 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:24,027 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:24,753 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:25,028 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:25,753 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:26,029 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:26,753 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:27,029 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:27,753 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:28,030 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:28,753 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:55:29,031 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:29,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:30,031 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:30,754 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:31,031 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:31,755 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:55:32,034 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:32,756 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:33,035 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:33,756 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:34,037 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:34,757 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:35,038 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:35,758 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:36,038 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:36,758 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:37,041 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:37,762 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:38,042 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:38,762 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:39,042 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:39,762 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:40,044 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:40,763 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:41,044 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:41,766 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:42,044 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:42,766 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:43,045 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:43,766 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:44,045 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:44,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:45,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:45,771 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:46,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:46,772 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:47,048 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:47,772 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:48,049 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:48,772 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:49,050 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:49,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:50,050 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:50,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:51,051 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:51,774 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:55:52,051 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:52,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:53,051 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:53,775 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:54,051 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:54,780 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:55,052 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:55,781 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:56,053 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:56,781 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:57,053 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:57,781 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:58,055 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:58,781 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:59,056 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:55:59,782 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:00,058 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:00,782 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:01,058 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:01,782 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:02,061 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:02,785 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:03,064 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:03,785 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:04,066 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:04,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:05,066 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:05,788 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:06,066 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:06,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:07,067 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:07,790 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:08,067 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:08,791 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:09,068 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:09,792 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:10,070 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:10,793 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:11,072 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:11,794 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:12,072 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:12,795 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:13,072 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:13,795 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:14,072 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:14,796 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:15,073 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:15,804 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:16,074 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:16,805 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:17,074 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:17,805 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:18,075 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:18,806 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:19,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:19,806 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:20,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:20,807 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:21,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:21,807 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:22,080 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:22,810 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:23,080 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:23,810 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:24,082 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:24,813 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:25,082 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:25,813 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:56:26,082 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:26,814 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:27,083 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:27,814 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:28,083 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:28,814 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:29,087 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:29,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:30,088 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:30,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:31,088 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:31,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:32,088 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:32,816 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:33,088 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:33,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:34,088 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:34,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:35,089 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:35,817 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:36,089 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:36,818 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:37,089 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:37,819 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:38,089 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:38,819 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:39,089 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:39,820 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:40,090 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:40,820 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:41,090 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:41,820 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:42,090 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:42,821 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:43,090 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:56:43,821 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:44,091 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:44,821 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:45,091 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:45,825 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:46,091 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:46,825 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:47,091 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:47,825 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:48,098 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:48,826 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:49,098 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:49,826 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:50,098 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:50,861 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:51,102 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:51,861 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:52,102 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:52,861 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:53,103 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:53,861 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:54,104 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:54,862 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:55,110 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:55,862 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:56,110 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:56,862 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:57,118 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:57,862 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:58,118 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:58,863 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:59,119 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:56:59,866 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:00,119 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:57:00,869 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:01,122 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:01,869 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:02,122 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:02,870 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:03,124 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:03,870 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:04,124 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:04,871 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:05,124 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:05,871 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:06,126 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:06,872 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:07,126 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:07,873 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:08,126 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:08,874 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:09,127 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:09,874 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:10,127 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:10,875 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:11,127 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:11,875 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:12,127 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:12,876 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:13,128 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:13,876 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:14,129 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:14,878 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:15,129 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:15,878 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:16,130 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:16,878 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:17,135 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:17,878 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:18,135 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:18,879 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:19,135 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:19,880 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:20,135 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:20,880 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:21,135 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:21,880 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:57:22,138 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:22,881 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:23,138 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:23,881 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:24,139 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:24,881 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:25,139 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:25,882 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:26,140 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:26,882 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:27,140 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:27,882 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:28,140 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:28,883 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:29,141 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:29,883 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:30,142 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:30,883 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:31,143 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:31,886 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:32,145 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:32,887 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:33,146 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:33,894 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:34,146 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:34,894 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:35,149 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:35,233 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1141522042@451ea648] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(124)) - JvmPauseMonitor-a39a8077-0667-4534-bc11-ae9dd274a08a: Detected pause in JVM or host machine (eg GC): pause of approximately 103845862ns.
GC pool 'PS Scavenge' had collection(s): count=1 time=7ms
2022-06-25 01:57:35,898 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:36,149 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:36,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:37,149 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:57:37,902 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:38,150 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:38,903 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:39,150 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:39,904 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:40,150 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:40,906 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:41,150 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:41,908 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:42,155 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:42,909 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:43,156 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:43,910 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:44,156 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:44,911 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:45,156 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:45,912 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:46,156 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:46,912 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:47,158 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:47,912 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:48,158 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:57:48,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:49,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:57:49,913 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:50,160 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:50,914 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:51,162 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:51,915 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:52,162 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:52,916 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:53,162 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:53,917 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:54,163 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:54,917 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:55,163 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:55,921 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:56,166 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:56,922 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:57,166 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:57,924 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:58,166 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:58,924 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:59,167 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:57:59,925 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:00,168 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:00,925 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:01,168 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:01,925 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:02,168 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:02,925 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:03,169 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:03,925 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:04,170 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:04,926 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:05,170 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:05,926 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:06,170 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:06,930 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:07,171 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:07,934 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:08,171 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:08,938 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:09,171 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:09,942 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:10,171 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:10,944 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:11,171 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:11,945 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:12,173 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:12,945 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:13,174 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:13,945 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:14,174 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:58:14,946 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:15,182 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:15,947 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:16,184 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:16,947 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:17,187 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:17,948 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:18,188 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:58:18,948 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:19,189 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:19,948 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:20,189 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:20,950 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:21,189 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:21,953 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:22,192 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:22,954 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:23,192 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:23,954 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:24,192 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:24,955 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:25,192 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:58:25,955 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:26,193 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:26,955 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:27,193 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:27,960 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:28,193 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:28,961 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:29,194 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:29,962 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:30,194 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:30,964 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:31,194 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:31,964 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:32,195 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:32,965 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:33,195 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:33,965 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:34,196 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:34,965 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:35,203 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:35,965 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:36,204 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:36,965 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:37,204 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:37,966 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:38,205 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:38,969 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:39,205 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:39,970 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:40,207 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:40,970 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:41,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:41,971 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:42,218 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:42,971 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:43,220 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:43,971 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:44,221 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:44,972 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:45,222 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:45,972 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:46,224 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:46,972 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:47,225 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:47,973 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:48,227 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:48,974 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:49,227 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:49,976 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:50,227 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:50,977 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:51,228 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:51,977 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:52,229 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:52,978 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:53,229 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:53,978 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:54,229 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:58:54,980 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:55,230 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:55,981 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:56,230 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:56,981 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:57,233 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:57,983 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:58,233 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:58,986 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:59,233 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:58:59,986 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:00,233 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:00,986 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:59:01,234 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:01,987 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:02,234 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:02,989 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:03,234 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:03,989 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:04,234 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:04,989 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:05,238 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:05,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:06,238 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:06,990 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:07,238 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:07,993 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:08,239 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:08,994 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:09,241 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:09,995 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:10,245 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:10,996 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:11,245 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:11,997 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:12,245 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:12,998 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:13,248 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:14,004 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:14,248 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:59:15,004 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:15,251 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:16,005 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:16,251 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:17,005 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:17,251 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:18,005 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:18,252 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:19,005 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:19,253 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:20,006 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:20,253 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:21,010 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:21,254 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:22,011 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:22,256 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:23,013 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:23,261 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:24,013 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:24,262 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:25,013 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:25,264 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:26,015 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:26,264 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:27,015 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:27,265 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:28,019 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:28,266 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:29,019 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:29,266 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:30,030 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:30,270 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:31,030 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:31,272 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:32,032 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:32,272 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:33,032 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:59:33,272 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:34,033 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:34,272 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:35,033 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:35,272 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:36,033 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:36,274 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:37,033 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:59:37,276 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:38,052 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 18 milliseconds for processing 0 containers.
2022-06-25 01:59:38,277 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:39,052 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 01:59:39,277 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:40,053 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:40,277 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:41,053 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:41,279 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:42,054 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:42,330 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:43,056 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:43,331 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:44,057 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:44,331 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:45,058 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:45,331 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:46,063 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:46,331 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:47,063 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:47,331 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:48,064 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:48,332 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:49,065 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:49,332 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:50,069 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:50,332 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:51,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:51,335 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:52,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:52,340 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:53,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:53,341 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:54,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:54,341 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:55,074 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:55,341 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:56,074 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:56,346 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:57,075 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:57,346 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:58,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:58,346 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:59,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 01:59:59,349 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 02:00:00,076 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:00,350 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:01,079 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:01,351 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:02,079 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:02,351 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 02:00:03,079 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:03,354 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:04,080 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:04,354 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:05,082 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:05,354 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:06,082 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:06,355 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:07,083 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:07,357 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:08,084 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:08,358 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:09,084 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:09,358 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:10,088 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:10,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:11,088 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 02:00:11,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:12,090 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:12,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:13,091 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:13,366 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:14,091 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:14,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:15,091 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 02:00:15,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:16,093 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:16,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:17,093 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:17,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:18,094 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:18,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:19,094 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:19,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:20,096 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:20,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:21,097 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:21,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:22,097 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:22,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:23,098 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:23,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:24,098 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:24,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:25,099 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:25,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:26,106 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:26,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:27,106 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:27,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:28,106 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:28,373 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:29,107 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:29,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:30,108 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:30,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:31,111 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:31,375 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:32,112 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:32,376 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:33,114 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:33,376 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:34,116 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:34,377 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:35,117 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:35,378 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:36,118 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:36,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:37,118 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:37,385 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:38,118 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:38,389 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:39,119 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:39,389 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:40,119 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:40,390 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:41,120 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:41,395 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:42,120 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:42,395 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:43,122 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:43,395 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:44,122 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:44,395 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:45,123 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:45,396 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:46,124 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:46,397 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:47,124 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:47,397 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:48,124 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:48,397 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:49,126 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:49,402 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:50,130 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:50,402 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:51,134 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:51,402 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:52,134 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:52,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:53,135 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:53,404 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:54,135 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:54,405 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:55,136 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:55,405 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:56,136 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:56,405 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:57,136 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:57,405 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:58,136 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:58,406 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:59,137 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:00:59,406 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:00,137 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:00,407 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:01,137 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:01,407 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:02,137 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:02,408 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:03,138 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:03,411 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:04,138 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:04,412 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:05,138 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:05,412 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:06,139 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:06,412 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:07,139 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:07,413 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:08,140 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:08,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:09,140 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:09,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:10,141 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:10,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:11,141 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:11,417 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:12,143 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:12,418 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:13,149 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:13,418 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:14,149 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:14,418 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:15,149 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:15,418 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:16,153 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:16,419 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:17,153 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:17,419 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:18,154 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:18,420 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:19,155 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:19,420 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:20,157 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:20,420 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:21,157 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:21,420 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:22,158 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:22,421 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:23,158 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:23,421 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:24,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:24,422 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:25,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:25,422 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:26,161 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:26,422 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:27,161 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2022-06-25 02:01:27,424 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:28,162 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:28,424 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:29,166 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:29,424 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:30,169 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:30,425 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:31,169 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:31,425 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:32,170 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:32,425 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:33,170 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:33,425 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:34,170 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:34,427 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:35,170 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:35,427 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:36,170 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:36,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:37,171 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:37,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:38,171 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:38,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:39,171 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:39,428 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:40,171 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:40,429 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:41,172 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:41,429 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:42,172 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:42,429 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:43,172 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:43,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:44,174 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:44,430 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:45,182 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:45,431 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:46,182 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:46,440 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:47,182 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:47,441 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:48,183 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:48,441 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:49,183 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:49,441 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:50,184 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:50,443 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:51,186 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:51,443 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:52,194 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:52,444 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:53,198 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:53,444 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:54,198 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:54,444 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:55,201 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:55,446 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:56,201 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:56,446 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:57,201 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:57,450 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:58,202 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:58,454 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:59,202 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:01:59,458 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:00,205 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:00,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:01,206 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:01,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:02,206 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:02,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:03,206 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:03,466 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:04,208 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:04,466 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:05,208 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:05,468 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:06,210 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:06,469 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:07,210 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:07,469 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:08,211 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:08,469 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:09,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:09,470 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:10,213 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:10,470 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:11,213 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:11,470 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:12,213 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:12,470 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:13,213 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:13,470 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:14,213 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:14,473 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:15,214 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:15,473 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:16,214 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:16,473 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:17,217 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:17,473 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:18,217 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:18,474 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:19,217 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:19,475 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:20,217 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:20,475 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:21,218 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:21,482 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:22,221 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:22,482 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:23,222 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:23,484 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:24,222 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:24,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:25,222 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:25,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:26,223 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:26,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:27,223 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:27,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:28,224 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:28,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:29,227 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:29,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:30,228 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:30,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:31,228 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:31,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:32,229 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:32,490 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:33,229 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:33,490 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:34,229 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:34,490 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:35,230 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:35,491 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:36,234 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:36,494 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:37,234 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:37,494 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:38,238 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:38,495 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:39,238 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:39,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:40,238 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:40,497 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2022-06-25 02:02:41,239 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
