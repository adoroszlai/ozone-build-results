<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="675.437" tests="8" errors="6" skipped="0" failures="0">
  <properties>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/classes:/home/runner/.m2/repository/org/apache/ozone/ozone-common/1.3.0-SNAPSHOT/ozone-common-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/grpc/grpc-netty/1.44.0/grpc-netty-1.44.0.jar:/home/runner/.m2/repository/io/grpc/grpc-core/1.44.0/grpc-core-1.44.0.jar:/home/runner/.m2/repository/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar:/home/runner/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.19/animal-sniffer-annotations-1.19.jar:/home/runner/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/runner/.m2/repository/io/perfmark/perfmark-api/0.23.0/perfmark-api-0.23.0.jar:/home/runner/.m2/repository/io/netty/netty-codec-http2/4.1.74.Final/netty-codec-http2-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-common/4.1.74.Final/netty-common-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-buffer/4.1.74.Final/netty-buffer-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.74.Final/netty-codec-http-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler-proxy/4.1.74.Final/netty-handler-proxy-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-socks/4.1.74.Final/netty-codec-socks-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.48.Final/netty-tcnative-boringssl-static-2.0.48.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-classes/2.0.48.Final/netty-tcnative-classes-2.0.48.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative/2.0.48.Final/netty-tcnative-2.0.48.Final.jar:/home/runner/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.3.0-SNAPSHOT/hdds-common-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-client/1.3.0-SNAPSHOT/hdds-client-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-client/1.3.0-SNAPSHOT/ozone-interface-client-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-test-utils/1.3.0-SNAPSHOT/hdds-test-utils-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/guava/guava/31.1-jre/guava-31.1-jre.jar:/home/runner/.m2/repository/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar:/home/runner/.m2/repository/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/runner/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/runner/.m2/repository/org/checkerframework/checker-qual/3.12.0/checker-qual-3.12.0.jar:/home/runner/.m2/repository/com/google/j2objc/j2objc-annotations/1.3/j2objc-annotations-1.3.jar:/home/runner/.m2/repository/commons-io/commons-io/2.11.0/commons-io-2.11.0.jar:/home/runner/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/runner/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/runner/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.3.0-SNAPSHOT/hdds-server-scm-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-server/1.3.0-SNAPSHOT/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.1/hadoop-hdfs-3.3.1.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-framework/1.3.0-SNAPSHOT/hdds-server-framework-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-server/1.3.0-SNAPSHOT/hdds-interface-server-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-core/2.17.1/log4j-core-2.17.1.jar:/home/runner/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-servlet/9.4.43.v20210629/jetty-servlet-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-security/9.4.43.v20210629/jetty-security-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/rocksdb/rocksdbjni/6.29.5/rocksdbjni-6.29.5.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_dropwizard/0.7.0/simpleclient_dropwizard-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient/0.7.0/simpleclient-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_common/0.7.0/simpleclient_common-0.7.0.jar:/home/runner/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.3.1/hadoop-hdfs-client-3.3.1.jar:/home/runner/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.67/bcprov-jdk15on-1.67.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.3.0-SNAPSHOT/ozone-manager-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/aspectj/aspectjrt/1.9.7/aspectjrt-1.9.7.jar:/home/runner/.m2/repository/org/aspectj/aspectjweaver/1.9.7/aspectjweaver-1.9.7.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-client/1.3.0-SNAPSHOT/hdds-interface-client-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-protobuf_3_7/1.1.1/hadoop-shaded-protobuf_3_7-1.1.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-storage/1.3.0-SNAPSHOT/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-intg/3.0.0-SNAPSHOT/ranger-intg-3.0.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-common/3.0.0-SNAPSHOT/ranger-plugins-common-3.0.0-SNAPSHOT.jar:/home/runner/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-cred/3.0.0-SNAPSHOT/ranger-plugins-cred-3.0.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-audit/3.0.0-SNAPSHOT/ranger-plugins-audit-3.0.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/kafka/kafka-clients/2.8.1/kafka-clients-2.8.1.jar:/home/runner/.m2/repository/com/github/luben/zstd-jni/1.4.9-1/zstd-jni-1.4.9-1.jar:/home/runner/.m2/repository/org/apache/solr/solr-solrj/8.6.3/solr-solrj-8.6.3.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-client/9.4.44.v20210927/jetty-client-9.4.44.v20210927.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpmime/4.5.13/httpmime-4.5.13.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore-nio/4.4.14/httpcore-nio-4.4.14.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpasyncclient/4.1.4/httpasyncclient-4.1.4.jar:/home/runner/.m2/repository/com/carrotsearch/hppc/0.8.0/hppc-0.8.0.jar:/home/runner/.m2/repository/org/apache/hive/hive-storage-api/2.7.2/hive-storage-api-2.7.2.jar:/home/runner/.m2/repository/org/apache/orc/orc-core/1.5.8/orc-core-1.5.8.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-bundle/1.12.125/aws-java-sdk-bundle-1.12.125.jar:/home/runner/.m2/repository/net/java/dev/jna/jna/5.2.0/jna-5.2.0.jar:/home/runner/.m2/repository/net/java/dev/jna/jna-platform/5.2.0/jna-platform-5.2.0.jar:/home/runner/.m2/repository/com/kstruct/gethostname4j/0.0.2/gethostname4j-0.0.2.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugin-classloader/3.0.0-SNAPSHOT/ranger-plugin-classloader-3.0.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.3.1/hadoop-minikdc-3.3.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/runner/.m2/repository/org/slf4j/slf4j-log4j12/1.7.30/slf4j-log4j12-1.7.30.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-s3gateway/1.3.0-SNAPSHOT/ozone-s3gateway-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/home/runner/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.33/jersey-container-servlet-core-2.33.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-common/2.33/jersey-common-2.33.jar:/home/runner/.m2/repository/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.33/jersey-cdi1x-2.33.jar:/home/runner/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.33/jersey-hk2-2.33.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.33/jersey-media-jaxb-2.33.jar:/home/runner/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.13.2/jackson-dataformat-xml-2.13.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.13.2/jackson-core-2.13.2.jar:/home/runner/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/runner/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/runner/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.13.2/jackson-module-jaxb-annotations-2.13.2.jar:/home/runner/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.3/jakarta.xml.bind-api-2.3.3.jar:/home/runner/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/runner/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/runner/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/runner/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/runner/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/runner/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-runtime/2.3.0.1/jaxb-runtime-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/txw2/2.3.0.1/txw2-2.3.0.1.jar:/home/runner/.m2/repository/com/sun/istack/istack-commons-runtime/3.0.5/istack-commons-runtime-3.0.5.jar:/home/runner/.m2/repository/org/jvnet/staxex/stax-ex/1.7.8/stax-ex-1.7.8.jar:/home/runner/.m2/repository/com/sun/xml/fastinfoset/FastInfoset/1.2.13/FastInfoset-1.2.13.jar:/home/runner/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf/1.44.0/grpc-protobuf-1.44.0.jar:/home/runner/.m2/repository/io/grpc/grpc-api/1.44.0/grpc-api-1.44.0.jar:/home/runner/.m2/repository/io/grpc/grpc-context/1.44.0/grpc-context-1.44.0.jar:/home/runner/.m2/repository/com/google/api/grpc/proto-google-common-protos/2.0.1/proto-google-common-protos-2.0.1.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf-lite/1.44.0/grpc-protobuf-lite-1.44.0.jar:/home/runner/.m2/repository/io/grpc/grpc-stub/1.44.0/grpc-stub-1.44.0.jar:/home/runner/.m2/repository/io/netty/netty-transport/4.1.74.Final/netty-transport-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver/4.1.74.Final/netty-resolver-4.1.74.Final.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-csi/1.3.0-SNAPSHOT/ozone-csi-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java-util/3.19.2/protobuf-java-util-3.19.2.jar:/home/runner/.m2/repository/com/google/code/gson/gson/2.8.9/gson-2.8.9.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-config/1.3.0-SNAPSHOT/hdds-config-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.74.Final/netty-transport-native-epoll-4.1.74.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-classes-epoll/4.1.74.Final/netty-transport-classes-epoll-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.74.Final/netty-transport-native-unix-common-4.1.74.Final.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-recon/1.3.0-SNAPSHOT/ozone-recon-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-reconcodegen/1.3.0-SNAPSHOT/ozone-reconcodegen-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/runner/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/runner/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.33/jersey-container-servlet-2.33.jar:/home/runner/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-server/2.33/jersey-server-2.33.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-client/2.33/jersey-client-2.33.jar:/home/runner/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.5/jakarta.annotation-api-1.3.5.jar:/home/runner/.m2/repository/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.33/jersey-media-json-jackson-2.33.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.33/jersey-entity-filtering-2.33.jar:/home/runner/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/runner/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/runner/.m2/repository/org/apache/derby/derby/10.14.2.0/derby-10.14.2.0.jar:/home/runner/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/runner/.m2/repository/org/springframework/spring-jdbc/5.2.20.RELEASE/spring-jdbc-5.2.20.RELEASE.jar:/home/runner/.m2/repository/org/springframework/spring-beans/5.2.20.RELEASE/spring-beans-5.2.20.RELEASE.jar:/home/runner/.m2/repository/org/springframework/spring-core/5.2.20.RELEASE/spring-core-5.2.20.RELEASE.jar:/home/runner/.m2/repository/org/springframework/spring-jcl/5.2.20.RELEASE/spring-jcl-5.2.20.RELEASE.jar:/home/runner/.m2/repository/org/springframework/spring-tx/5.2.20.RELEASE/spring-tx-5.2.20.RELEASE.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-client/1.3.0-SNAPSHOT/ozone-client-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-erasurecode/1.3.0-SNAPSHOT/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/github/spotbugs/spotbugs-annotations/3.1.12/spotbugs-annotations-3.1.12.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem/1.3.0-SNAPSHOT/ozone-filesystem-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem-common/1.3.0-SNAPSHOT/ozone-filesystem-common-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-tools/1.3.0-SNAPSHOT/ozone-tools-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-tools/2.3.0/ratis-tools-2.3.0.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-core/1.12.124/aws-java-sdk-core-1.12.124.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/runner/.m2/repository/software/amazon/ion/ion-java/1.0.2/ion-java-1.0.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.13.2/jackson-dataformat-cbor-2.13.2.jar:/home/runner/.m2/repository/joda-time/joda-time/2.8.1/joda-time-2.8.1.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-s3/1.12.124/aws-java-sdk-s3-1.12.124.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-kms/1.12.124/aws-java-sdk-kms-1.12.124.jar:/home/runner/.m2/repository/com/amazonaws/jmespath-java/1.12.124/jmespath-java-1.12.124.jar:/home/runner/.m2/repository/org/kohsuke/metainf-services/metainf-services/1.8/metainf-services-1.8.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-tools/1.3.0-SNAPSHOT/hdds-tools-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/runner/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.3.0-SNAPSHOT/ozone-manager-1.3.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.3.0-SNAPSHOT/hdds-common-1.3.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-client/1.3.0-SNAPSHOT/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/info/picocli/picocli/4.6.1/picocli-4.6.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.13.2/jackson-annotations-2.13.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.13.2/jackson-datatype-jsr310-2.13.2.jar:/home/runner/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server/2.3.0/ratis-server-2.3.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-client/2.3.0/ratis-client-2.3.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server-api/2.3.0/ratis-server-api-2.3.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics/2.3.0/ratis-metrics-2.3.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-netty/2.3.0/ratis-netty-2.3.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-grpc/2.3.0/ratis-grpc-2.3.0.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-api/2.17.1/log4j-api-2.17.1.jar:/home/runner/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/runner/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.67/bcpkix-jdk15on-1.67.jar:/home/runner/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/runner/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/runner/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/runner/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-client/1.6.0/jaeger-client-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-thrift/1.6.0/jaeger-thrift-1.6.0.jar:/home/runner/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/runner/.m2/repository/com/squareup/okhttp3/okhttp/4.9.0/okhttp-4.9.0.jar:/home/runner/.m2/repository/com/squareup/okio/okio/2.8.0/okio-2.8.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-core/1.6.0/jaeger-core-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-tracerresolver/1.6.0/jaeger-tracerresolver-1.6.0.jar:/home/runner/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.8/opentracing-tracerresolver-0.1.8.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib/1.6.21/kotlin-stdlib-1.6.21.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-common/1.6.21/kotlin-stdlib-common-1.6.21.jar:/home/runner/.m2/repository/org/jetbrains/annotations/13.0/annotations-13.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-util/0.33.0/opentracing-util-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-api/0.33.0/opentracing-api-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-noop/0.33.0/opentracing-noop-0.33.0.jar:/home/runner/.m2/repository/org/yaml/snakeyaml/1.26/snakeyaml-1.26.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-admin/1.3.0-SNAPSHOT/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/junit/junit/4.13.1/junit-4.13.1.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.8.2/junit-jupiter-api-5.8.2.jar:/home/runner/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-commons/1.8.2/junit-platform-commons-1.8.2.jar:/home/runner/.m2/repository/org/apiguardian/apiguardian-api/1.1.2/apiguardian-api-1.1.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.8.2/junit-jupiter-params-5.8.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-migrationsupport/5.8.2/junit-jupiter-migrationsupport-5.8.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.8.2/junit-jupiter-engine-5.8.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-engine/1.8.2/junit-platform-engine-1.8.2.jar:/home/runner/.m2/repository/org/junit/vintage/junit-vintage-engine/5.8.2/junit-vintage-engine-5.8.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-launcher/1.8.2/junit-platform-launcher-1.8.2.jar:/home/runner/.m2/repository/org/mockito/mockito-core/2.28.2/mockito-core-2.28.2.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy/1.9.10/byte-buddy-1.9.10.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy-agent/1.9.10/byte-buddy-agent-1.9.10.jar:/home/runner/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.1/hadoop-kms-3.3.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-auth/3.3.1/hadoop-auth-3.3.1.jar:/home/runner/.m2/repository/com/nimbusds/nimbus-jose-jwt/7.9/nimbus-jose-jwt-7.9.jar:/home/runner/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/runner/.m2/repository/net/minidev/json-smart/2.4.7/json-smart-2.4.7.jar:/home/runner/.m2/repository/net/minidev/accessors-smart/2.4.7/accessors-smart-2.4.7.jar:/home/runner/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper/3.5.6/zookeeper-3.5.6.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.6/zookeeper-jute-3.5.6.jar:/home/runner/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-guava/1.1.1/hadoop-shaded-guava-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/runner/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/runner/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-server/9.4.43.v20210629/jetty-server-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-http/9.4.43.v20210629/jetty-http-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-io/9.4.43.v20210629/jetty-io-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-webapp/9.4.43.v20210629/jetty-webapp-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-xml/9.4.43.v20210629/jetty-xml-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.1/hadoop-common-3.3.1.jar:/home/runner/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/runner/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/runner/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/runner/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/runner/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/runner/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/runner/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/runner/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/runner/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/runner/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/runner/.m2/repository/org/xerial/snappy/snappy-java/1.1.8.2/snappy-java-1.1.8.2.jar:/home/runner/.m2/repository/org/slf4j/jul-to-slf4j/1.7.30/jul-to-slf4j-1.7.30.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util/9.4.43.v20210629/jetty-util-9.4.43.v20210629.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.13.2.2/jackson-databind-2.13.2.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.1/hadoop-kms-3.3.1-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.3.0-SNAPSHOT/hdds-server-scm-1.3.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/home/runner/.m2/repository/io/netty/netty-codec/4.1.74.Final/netty-codec-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler/4.1.74.Final/netty-handler-4.1.74.Final.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-test/1.3.0-SNAPSHOT/hdds-hadoop-dependency-test-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.1/hadoop-common-3.3.1-tests.jar:/home/runner/.m2/repository/org/assertj/assertj-core/3.12.2/assertj-core-3.12.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.1/hadoop-hdfs-3.3.1-tests.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.4.43.v20210629/jetty-util-ajax-9.4.43.v20210629.jar:/home/runner/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/runner/.m2/repository/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/home/runner/.m2/repository/io/netty/netty-all/4.1.74.Final/netty-all-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-dns/4.1.74.Final/netty-codec-dns-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-haproxy/4.1.74.Final/netty-codec-haproxy-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-memcache/4.1.74.Final/netty-codec-memcache-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-mqtt/4.1.74.Final/netty-codec-mqtt-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-redis/4.1.74.Final/netty-codec-redis-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-smtp/4.1.74.Final/netty-codec-smtp-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-stomp/4.1.74.Final/netty-codec-stomp-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-xml/4.1.74.Final/netty-codec-xml-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver-dns/4.1.74.Final/netty-resolver-dns-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-rxtx/4.1.74.Final/netty-transport-rxtx-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-sctp/4.1.74.Final/netty-transport-sctp-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-udt/4.1.74.Final/netty-transport-udt-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-classes-kqueue/4.1.74.Final/netty-transport-classes-kqueue-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver-dns-classes-macos/4.1.74.Final/netty-resolver-dns-classes-macos-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.74.Final/netty-transport-native-epoll-4.1.74.Final-linux-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.74.Final/netty-transport-native-kqueue-4.1.74.Final-osx-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.74.Final/netty-transport-native-kqueue-4.1.74.Final-osx-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-resolver-dns-native-macos/4.1.74.Final/netty-resolver-dns-native-macos-4.1.74.Final-osx-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-resolver-dns-native-macos/4.1.74.Final/netty-resolver-dns-native-macos-4.1.74.Final-osx-aarch_64.jar:/home/runner/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/runner/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.1/hadoop-distcp-3.3.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.3.1/hadoop-mapreduce-client-jobclient-3.3.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.3.1/hadoop-mapreduce-client-common-3.3.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.3.1/hadoop-yarn-common-3.3.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.3.1/hadoop-yarn-api-3.3.1.jar:/home/runner/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.13.2/jackson-jaxrs-json-provider-2.13.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.13.2/jackson-jaxrs-base-2.13.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.3.1/hadoop-yarn-client-3.3.1.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.4.40.v20210413/websocket-client-9.4.40.v20210413.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.4.40.v20210413/websocket-common-9.4.40.v20210413.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.4.40.v20210413/websocket-api-9.4.40.v20210413.jar:/home/runner/.m2/repository/org/jline/jline/3.9.0/jline-3.9.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.3.1/hadoop-mapreduce-client-core-3.3.1.jar:/home/runner/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/runner/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-annotations/3.3.1/hadoop-annotations-3.3.1.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/../lib/tools.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.1/hadoop-distcp-3.3.1-tests.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-common/2.3.0/ratis-common-2.3.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/1.0.0/ratis-thirdparty-misc-1.0.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-proto/2.3.0/ratis-proto-2.3.0.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-annotation-processing/1.3.0-SNAPSHOT/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:"/>
    <property name="java.vm.vendor" value="Temurin"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="test.build.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir"/>
    <property name="test.cache.data" value=""/>
    <property name="java.vendor.url" value="https://adoptium.net/"/>
    <property name="user.timezone" value="Etc/UTC"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="os.name" value="Linux"/>
    <property name="test.build.data" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/surefire/surefirebooter6106936567075737622.jar /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/surefire 2022-06-20T00-58-00_242-jvmRun1 surefire8784847015020554952tmp surefire_167724062962191508939tmp"/>
    <property name="surefire.test.class.path" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/classes:/home/runner/.m2/repository/org/apache/ozone/ozone-common/1.3.0-SNAPSHOT/ozone-common-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/grpc/grpc-netty/1.44.0/grpc-netty-1.44.0.jar:/home/runner/.m2/repository/io/grpc/grpc-core/1.44.0/grpc-core-1.44.0.jar:/home/runner/.m2/repository/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar:/home/runner/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.19/animal-sniffer-annotations-1.19.jar:/home/runner/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/runner/.m2/repository/io/perfmark/perfmark-api/0.23.0/perfmark-api-0.23.0.jar:/home/runner/.m2/repository/io/netty/netty-codec-http2/4.1.74.Final/netty-codec-http2-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-common/4.1.74.Final/netty-common-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-buffer/4.1.74.Final/netty-buffer-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.74.Final/netty-codec-http-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler-proxy/4.1.74.Final/netty-handler-proxy-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-socks/4.1.74.Final/netty-codec-socks-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.48.Final/netty-tcnative-boringssl-static-2.0.48.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-classes/2.0.48.Final/netty-tcnative-classes-2.0.48.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative/2.0.48.Final/netty-tcnative-2.0.48.Final.jar:/home/runner/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.3.0-SNAPSHOT/hdds-common-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-client/1.3.0-SNAPSHOT/hdds-client-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-client/1.3.0-SNAPSHOT/ozone-interface-client-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-test-utils/1.3.0-SNAPSHOT/hdds-test-utils-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/guava/guava/31.1-jre/guava-31.1-jre.jar:/home/runner/.m2/repository/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar:/home/runner/.m2/repository/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/runner/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/runner/.m2/repository/org/checkerframework/checker-qual/3.12.0/checker-qual-3.12.0.jar:/home/runner/.m2/repository/com/google/j2objc/j2objc-annotations/1.3/j2objc-annotations-1.3.jar:/home/runner/.m2/repository/commons-io/commons-io/2.11.0/commons-io-2.11.0.jar:/home/runner/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/runner/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/runner/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.3.0-SNAPSHOT/hdds-server-scm-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-server/1.3.0-SNAPSHOT/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.1/hadoop-hdfs-3.3.1.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-framework/1.3.0-SNAPSHOT/hdds-server-framework-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-server/1.3.0-SNAPSHOT/hdds-interface-server-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-core/2.17.1/log4j-core-2.17.1.jar:/home/runner/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-servlet/9.4.43.v20210629/jetty-servlet-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-security/9.4.43.v20210629/jetty-security-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/rocksdb/rocksdbjni/6.29.5/rocksdbjni-6.29.5.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_dropwizard/0.7.0/simpleclient_dropwizard-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient/0.7.0/simpleclient-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_common/0.7.0/simpleclient_common-0.7.0.jar:/home/runner/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.3.1/hadoop-hdfs-client-3.3.1.jar:/home/runner/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.67/bcprov-jdk15on-1.67.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.3.0-SNAPSHOT/ozone-manager-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/aspectj/aspectjrt/1.9.7/aspectjrt-1.9.7.jar:/home/runner/.m2/repository/org/aspectj/aspectjweaver/1.9.7/aspectjweaver-1.9.7.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-client/1.3.0-SNAPSHOT/hdds-interface-client-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-protobuf_3_7/1.1.1/hadoop-shaded-protobuf_3_7-1.1.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-storage/1.3.0-SNAPSHOT/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-intg/3.0.0-SNAPSHOT/ranger-intg-3.0.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-common/3.0.0-SNAPSHOT/ranger-plugins-common-3.0.0-SNAPSHOT.jar:/home/runner/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-cred/3.0.0-SNAPSHOT/ranger-plugins-cred-3.0.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-audit/3.0.0-SNAPSHOT/ranger-plugins-audit-3.0.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/kafka/kafka-clients/2.8.1/kafka-clients-2.8.1.jar:/home/runner/.m2/repository/com/github/luben/zstd-jni/1.4.9-1/zstd-jni-1.4.9-1.jar:/home/runner/.m2/repository/org/apache/solr/solr-solrj/8.6.3/solr-solrj-8.6.3.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-client/9.4.44.v20210927/jetty-client-9.4.44.v20210927.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpmime/4.5.13/httpmime-4.5.13.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore-nio/4.4.14/httpcore-nio-4.4.14.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpasyncclient/4.1.4/httpasyncclient-4.1.4.jar:/home/runner/.m2/repository/com/carrotsearch/hppc/0.8.0/hppc-0.8.0.jar:/home/runner/.m2/repository/org/apache/hive/hive-storage-api/2.7.2/hive-storage-api-2.7.2.jar:/home/runner/.m2/repository/org/apache/orc/orc-core/1.5.8/orc-core-1.5.8.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-bundle/1.12.125/aws-java-sdk-bundle-1.12.125.jar:/home/runner/.m2/repository/net/java/dev/jna/jna/5.2.0/jna-5.2.0.jar:/home/runner/.m2/repository/net/java/dev/jna/jna-platform/5.2.0/jna-platform-5.2.0.jar:/home/runner/.m2/repository/com/kstruct/gethostname4j/0.0.2/gethostname4j-0.0.2.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugin-classloader/3.0.0-SNAPSHOT/ranger-plugin-classloader-3.0.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.3.1/hadoop-minikdc-3.3.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/runner/.m2/repository/org/slf4j/slf4j-log4j12/1.7.30/slf4j-log4j12-1.7.30.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-s3gateway/1.3.0-SNAPSHOT/ozone-s3gateway-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/home/runner/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.33/jersey-container-servlet-core-2.33.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-common/2.33/jersey-common-2.33.jar:/home/runner/.m2/repository/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.33/jersey-cdi1x-2.33.jar:/home/runner/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.33/jersey-hk2-2.33.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.33/jersey-media-jaxb-2.33.jar:/home/runner/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.13.2/jackson-dataformat-xml-2.13.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.13.2/jackson-core-2.13.2.jar:/home/runner/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/runner/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/runner/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.13.2/jackson-module-jaxb-annotations-2.13.2.jar:/home/runner/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.3/jakarta.xml.bind-api-2.3.3.jar:/home/runner/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/runner/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/runner/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/runner/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/runner/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/runner/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-runtime/2.3.0.1/jaxb-runtime-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/txw2/2.3.0.1/txw2-2.3.0.1.jar:/home/runner/.m2/repository/com/sun/istack/istack-commons-runtime/3.0.5/istack-commons-runtime-3.0.5.jar:/home/runner/.m2/repository/org/jvnet/staxex/stax-ex/1.7.8/stax-ex-1.7.8.jar:/home/runner/.m2/repository/com/sun/xml/fastinfoset/FastInfoset/1.2.13/FastInfoset-1.2.13.jar:/home/runner/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf/1.44.0/grpc-protobuf-1.44.0.jar:/home/runner/.m2/repository/io/grpc/grpc-api/1.44.0/grpc-api-1.44.0.jar:/home/runner/.m2/repository/io/grpc/grpc-context/1.44.0/grpc-context-1.44.0.jar:/home/runner/.m2/repository/com/google/api/grpc/proto-google-common-protos/2.0.1/proto-google-common-protos-2.0.1.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf-lite/1.44.0/grpc-protobuf-lite-1.44.0.jar:/home/runner/.m2/repository/io/grpc/grpc-stub/1.44.0/grpc-stub-1.44.0.jar:/home/runner/.m2/repository/io/netty/netty-transport/4.1.74.Final/netty-transport-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver/4.1.74.Final/netty-resolver-4.1.74.Final.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-csi/1.3.0-SNAPSHOT/ozone-csi-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java-util/3.19.2/protobuf-java-util-3.19.2.jar:/home/runner/.m2/repository/com/google/code/gson/gson/2.8.9/gson-2.8.9.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-config/1.3.0-SNAPSHOT/hdds-config-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.74.Final/netty-transport-native-epoll-4.1.74.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-classes-epoll/4.1.74.Final/netty-transport-classes-epoll-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.74.Final/netty-transport-native-unix-common-4.1.74.Final.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-recon/1.3.0-SNAPSHOT/ozone-recon-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-reconcodegen/1.3.0-SNAPSHOT/ozone-reconcodegen-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/runner/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/runner/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.33/jersey-container-servlet-2.33.jar:/home/runner/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-server/2.33/jersey-server-2.33.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-client/2.33/jersey-client-2.33.jar:/home/runner/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.5/jakarta.annotation-api-1.3.5.jar:/home/runner/.m2/repository/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.33/jersey-media-json-jackson-2.33.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.33/jersey-entity-filtering-2.33.jar:/home/runner/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/runner/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/runner/.m2/repository/org/apache/derby/derby/10.14.2.0/derby-10.14.2.0.jar:/home/runner/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/runner/.m2/repository/org/springframework/spring-jdbc/5.2.20.RELEASE/spring-jdbc-5.2.20.RELEASE.jar:/home/runner/.m2/repository/org/springframework/spring-beans/5.2.20.RELEASE/spring-beans-5.2.20.RELEASE.jar:/home/runner/.m2/repository/org/springframework/spring-core/5.2.20.RELEASE/spring-core-5.2.20.RELEASE.jar:/home/runner/.m2/repository/org/springframework/spring-jcl/5.2.20.RELEASE/spring-jcl-5.2.20.RELEASE.jar:/home/runner/.m2/repository/org/springframework/spring-tx/5.2.20.RELEASE/spring-tx-5.2.20.RELEASE.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-client/1.3.0-SNAPSHOT/ozone-client-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-erasurecode/1.3.0-SNAPSHOT/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/github/spotbugs/spotbugs-annotations/3.1.12/spotbugs-annotations-3.1.12.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem/1.3.0-SNAPSHOT/ozone-filesystem-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem-common/1.3.0-SNAPSHOT/ozone-filesystem-common-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-tools/1.3.0-SNAPSHOT/ozone-tools-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-tools/2.3.0/ratis-tools-2.3.0.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-core/1.12.124/aws-java-sdk-core-1.12.124.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/runner/.m2/repository/software/amazon/ion/ion-java/1.0.2/ion-java-1.0.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.13.2/jackson-dataformat-cbor-2.13.2.jar:/home/runner/.m2/repository/joda-time/joda-time/2.8.1/joda-time-2.8.1.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-s3/1.12.124/aws-java-sdk-s3-1.12.124.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-kms/1.12.124/aws-java-sdk-kms-1.12.124.jar:/home/runner/.m2/repository/com/amazonaws/jmespath-java/1.12.124/jmespath-java-1.12.124.jar:/home/runner/.m2/repository/org/kohsuke/metainf-services/metainf-services/1.8/metainf-services-1.8.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-tools/1.3.0-SNAPSHOT/hdds-tools-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/runner/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.3.0-SNAPSHOT/ozone-manager-1.3.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.3.0-SNAPSHOT/hdds-common-1.3.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-client/1.3.0-SNAPSHOT/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/info/picocli/picocli/4.6.1/picocli-4.6.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.13.2/jackson-annotations-2.13.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.13.2/jackson-datatype-jsr310-2.13.2.jar:/home/runner/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server/2.3.0/ratis-server-2.3.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-client/2.3.0/ratis-client-2.3.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server-api/2.3.0/ratis-server-api-2.3.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics/2.3.0/ratis-metrics-2.3.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-netty/2.3.0/ratis-netty-2.3.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-grpc/2.3.0/ratis-grpc-2.3.0.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-api/2.17.1/log4j-api-2.17.1.jar:/home/runner/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/runner/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.67/bcpkix-jdk15on-1.67.jar:/home/runner/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/runner/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/runner/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/runner/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-client/1.6.0/jaeger-client-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-thrift/1.6.0/jaeger-thrift-1.6.0.jar:/home/runner/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/runner/.m2/repository/com/squareup/okhttp3/okhttp/4.9.0/okhttp-4.9.0.jar:/home/runner/.m2/repository/com/squareup/okio/okio/2.8.0/okio-2.8.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-core/1.6.0/jaeger-core-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-tracerresolver/1.6.0/jaeger-tracerresolver-1.6.0.jar:/home/runner/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.8/opentracing-tracerresolver-0.1.8.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib/1.6.21/kotlin-stdlib-1.6.21.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-common/1.6.21/kotlin-stdlib-common-1.6.21.jar:/home/runner/.m2/repository/org/jetbrains/annotations/13.0/annotations-13.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-util/0.33.0/opentracing-util-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-api/0.33.0/opentracing-api-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-noop/0.33.0/opentracing-noop-0.33.0.jar:/home/runner/.m2/repository/org/yaml/snakeyaml/1.26/snakeyaml-1.26.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-admin/1.3.0-SNAPSHOT/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/junit/junit/4.13.1/junit-4.13.1.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.8.2/junit-jupiter-api-5.8.2.jar:/home/runner/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-commons/1.8.2/junit-platform-commons-1.8.2.jar:/home/runner/.m2/repository/org/apiguardian/apiguardian-api/1.1.2/apiguardian-api-1.1.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.8.2/junit-jupiter-params-5.8.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-migrationsupport/5.8.2/junit-jupiter-migrationsupport-5.8.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.8.2/junit-jupiter-engine-5.8.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-engine/1.8.2/junit-platform-engine-1.8.2.jar:/home/runner/.m2/repository/org/junit/vintage/junit-vintage-engine/5.8.2/junit-vintage-engine-5.8.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-launcher/1.8.2/junit-platform-launcher-1.8.2.jar:/home/runner/.m2/repository/org/mockito/mockito-core/2.28.2/mockito-core-2.28.2.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy/1.9.10/byte-buddy-1.9.10.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy-agent/1.9.10/byte-buddy-agent-1.9.10.jar:/home/runner/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.1/hadoop-kms-3.3.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-auth/3.3.1/hadoop-auth-3.3.1.jar:/home/runner/.m2/repository/com/nimbusds/nimbus-jose-jwt/7.9/nimbus-jose-jwt-7.9.jar:/home/runner/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/runner/.m2/repository/net/minidev/json-smart/2.4.7/json-smart-2.4.7.jar:/home/runner/.m2/repository/net/minidev/accessors-smart/2.4.7/accessors-smart-2.4.7.jar:/home/runner/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper/3.5.6/zookeeper-3.5.6.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.6/zookeeper-jute-3.5.6.jar:/home/runner/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-guava/1.1.1/hadoop-shaded-guava-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/runner/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/runner/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-server/9.4.43.v20210629/jetty-server-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-http/9.4.43.v20210629/jetty-http-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-io/9.4.43.v20210629/jetty-io-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-webapp/9.4.43.v20210629/jetty-webapp-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-xml/9.4.43.v20210629/jetty-xml-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.1/hadoop-common-3.3.1.jar:/home/runner/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/runner/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/runner/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/runner/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/runner/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/runner/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/runner/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/runner/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/runner/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/runner/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/runner/.m2/repository/org/xerial/snappy/snappy-java/1.1.8.2/snappy-java-1.1.8.2.jar:/home/runner/.m2/repository/org/slf4j/jul-to-slf4j/1.7.30/jul-to-slf4j-1.7.30.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util/9.4.43.v20210629/jetty-util-9.4.43.v20210629.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.13.2.2/jackson-databind-2.13.2.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.1/hadoop-kms-3.3.1-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.3.0-SNAPSHOT/hdds-server-scm-1.3.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/home/runner/.m2/repository/io/netty/netty-codec/4.1.74.Final/netty-codec-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler/4.1.74.Final/netty-handler-4.1.74.Final.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-test/1.3.0-SNAPSHOT/hdds-hadoop-dependency-test-1.3.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.1/hadoop-common-3.3.1-tests.jar:/home/runner/.m2/repository/org/assertj/assertj-core/3.12.2/assertj-core-3.12.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.1/hadoop-hdfs-3.3.1-tests.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.4.43.v20210629/jetty-util-ajax-9.4.43.v20210629.jar:/home/runner/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/runner/.m2/repository/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/home/runner/.m2/repository/io/netty/netty-all/4.1.74.Final/netty-all-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-dns/4.1.74.Final/netty-codec-dns-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-haproxy/4.1.74.Final/netty-codec-haproxy-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-memcache/4.1.74.Final/netty-codec-memcache-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-mqtt/4.1.74.Final/netty-codec-mqtt-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-redis/4.1.74.Final/netty-codec-redis-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-smtp/4.1.74.Final/netty-codec-smtp-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-stomp/4.1.74.Final/netty-codec-stomp-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-xml/4.1.74.Final/netty-codec-xml-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver-dns/4.1.74.Final/netty-resolver-dns-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-rxtx/4.1.74.Final/netty-transport-rxtx-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-sctp/4.1.74.Final/netty-transport-sctp-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-udt/4.1.74.Final/netty-transport-udt-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-classes-kqueue/4.1.74.Final/netty-transport-classes-kqueue-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver-dns-classes-macos/4.1.74.Final/netty-resolver-dns-classes-macos-4.1.74.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.74.Final/netty-transport-native-epoll-4.1.74.Final-linux-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.74.Final/netty-transport-native-kqueue-4.1.74.Final-osx-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.74.Final/netty-transport-native-kqueue-4.1.74.Final-osx-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-resolver-dns-native-macos/4.1.74.Final/netty-resolver-dns-native-macos-4.1.74.Final-osx-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-resolver-dns-native-macos/4.1.74.Final/netty-resolver-dns-native-macos-4.1.74.Final-osx-aarch_64.jar:/home/runner/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/runner/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.1/hadoop-distcp-3.3.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.3.1/hadoop-mapreduce-client-jobclient-3.3.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.3.1/hadoop-mapreduce-client-common-3.3.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.3.1/hadoop-yarn-common-3.3.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.3.1/hadoop-yarn-api-3.3.1.jar:/home/runner/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.13.2/jackson-jaxrs-json-provider-2.13.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.13.2/jackson-jaxrs-base-2.13.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.3.1/hadoop-yarn-client-3.3.1.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.4.40.v20210413/websocket-client-9.4.40.v20210413.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.4.40.v20210413/websocket-common-9.4.40.v20210413.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.4.40.v20210413/websocket-api-9.4.40.v20210413.jar:/home/runner/.m2/repository/org/jline/jline/3.9.0/jline-3.9.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.3.1/hadoop-mapreduce-client-core-3.3.1.jar:/home/runner/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/runner/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-annotations/3.3.1/hadoop-annotations-3.3.1.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/../lib/tools.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.1/hadoop-distcp-3.3.1-tests.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-common/2.3.0/ratis-common-2.3.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/1.0.0/ratis-thirdparty-misc-1.0.0.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-proto/2.3.0/ratis-proto-2.3.0.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-annotation-processing/1.3.0-SNAPSHOT/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/runner"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre"/>
    <property name="java.security.krb5.conf" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/krb5.conf"/>
    <property name="basedir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test"/>
    <property name="file.separator" value="/"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="skip.installnpx" value="true"/>
    <property name="surefire.fork.timeout" value="3600"/>
    <property name="surefire.real.class.path" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/surefire/surefirebooter6106936567075737622.jar:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.5/org.jacoco.agent-0.8.5-runtime.jar"/>
    <property name="hadoop.log.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/classes"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="skip.npx" value="true"/>
    <property name="java.runtime.version" value="1.8.0_332-b09"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="user.name" value="runner"/>
    <property name="path.separator" value=":"/>
    <property name="java.security.egd" value="file:///dev/urandom"/>
    <property name="os.version" value="5.4.0-1083-azure"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="test.build.webapps" value=""/>
    <property name="localRepository" value="/home/runner/.m2/repository"/>
    <property name="jetty.git.hash" value="526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8"/>
    <property name="java.vendor.url.bug" value="https://github.com/adoptium/adoptium-support/issues"/>
    <property name="java.io.tmpdir" value="/tmp"/>
    <property name="require.test.libhadoop" value=""/>
    <property name="surefire.rerunFailingTestsCount" value="5"/>
    <property name="java.version" value="1.8.0_332"/>
    <property name="user.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test"/>
    <property name="os.arch" value="amd64"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="test.build.classes" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="hadoop.tmp.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/tmp"/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vendor" value="Temurin"/>
    <property name="java.vm.version" value="25.332-b09"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.class.version" value="52.0"/>
  </properties>
  <testcase name="testNodeWithOpenPipelineCanBeDecommissionedAndRecommissioned" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="54.343"/>
  <testcase name="testContainerIsReplicatedWhenAllNodesGotoMaintenance" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="20.442"/>
  <testcase name="testMaintenanceEndsAutomaticallyAtTimeout" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="100.003">
    <error type="java.io.IOException"><![CDATA[java.io.IOException: Failed to obtain available cluster in time
	at org.apache.hadoop.ozone.MiniOzoneClusterProvider.provide(MiniOzoneClusterProvider.java:162)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.setUp(TestDecommissionAndMaintenance.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptLifecycleMethod(TimeoutExtension.java:126)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptBeforeEachMethod(TimeoutExtension.java:76)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeMethodInExtensionContext(ClassBasedTestDescriptor.java:506)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$synthesizeBeforeEachMethodAdapter$21(ClassBasedTestDescriptor.java:491)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeBeforeEachMethods$3(TestMethodTestDescriptor.java:171)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeBeforeMethodsOrCallbacksUntilExceptionOccurs$6(TestMethodTestDescriptor.java:199)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeBeforeMethodsOrCallbacksUntilExceptionOccurs(TestMethodTestDescriptor.java:199)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeBeforeEachMethods(TestMethodTestDescriptor.java:168)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:131)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)
]]></error>
    <system-out><![CDATA[2022-06-20 01:36:18,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-06-20 01:36:18,887 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5029098244ns, electionTimeout:5022ms
2022-06-20 01:36:18,887 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b: shutdown 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-FollowerState
2022-06-20 01:36:18,887 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-20 01:36:18,887 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-20 01:36:18,887 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b: start 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-LeaderElection36
2022-06-20 01:36:18,900 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-LeaderElection36] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-LeaderElection36 ELECTION round 0: submit vote requests at term 1 for -1: [5e432c75-8719-4a7d-ad09-7985e0971b8b|rpc:10.1.0.17:44011|priority:1], old=null
2022-06-20 01:36:18,900 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-LeaderElection36] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-LeaderElection36 ELECTION round 0: result PASSED (term=1)
2022-06-20 01:36:18,900 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-LeaderElection36] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b: shutdown 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-LeaderElection36
2022-06-20 01:36:18,900 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-LeaderElection36] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-06-20 01:36:18,900 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-LeaderElection36] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-CF3E20F3E79F with new leaderId: 5e432c75-8719-4a7d-ad09-7985e0971b8b
2022-06-20 01:36:18,900 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-LeaderElection36] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F: change Leader from null to 5e432c75-8719-4a7d-ad09-7985e0971b8b at term 1 for becomeLeader, leader elected after 5070ms
2022-06-20 01:36:18,901 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-LeaderElection36] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-20 01:36:18,902 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-LeaderElection36] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-20 01:36:18,902 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-LeaderElection36] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-06-20 01:36:18,902 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-LeaderElection36] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-06-20 01:36:18,902 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-LeaderElection36] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-20 01:36:18,902 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-LeaderElection36] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-20 01:36:18,903 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-LeaderElection36] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-20 01:36:18,903 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-LeaderElection36] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-20 01:36:18,903 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-LeaderElection36] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b: start 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-LeaderStateImpl
2022-06-20 01:36:18,903 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-LeaderElection36] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-20 01:36:18,904 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5057269200ns, electionTimeout:5054ms
2022-06-20 01:36:18,904 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d: shutdown fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-FollowerState
2022-06-20 01:36:18,904 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2022-06-20 01:36:18,909 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-1/data/ratis/27442fc4-f4d7-4206-a0cc-cf3e20f3e79f/current/log_inprogress_0
2022-06-20 01:36:18,927 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-20 01:36:18,928 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d: start fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-LeaderElection37
2022-06-20 01:36:18,933 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-LeaderElection36] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F: set configuration 0: [5e432c75-8719-4a7d-ad09-7985e0971b8b|rpc:10.1.0.17:44011|dataStream:|priority:1], old=null
2022-06-20 01:36:18,937 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(150)) - Not enough healthy nodes to allocate container. 2  datanodes required. Found 1
2022-06-20 01:36:18,937 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Not enough healthy nodes to allocate container. 2  datanodes required. Found 1
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:151)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:18,938 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:18,938 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:18,938 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(150)) - Not enough healthy nodes to allocate container. 2  datanodes required. Found 1
2022-06-20 01:36:18,938 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: Not enough healthy nodes to allocate container. 2  datanodes required. Found 1
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:151)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:18,938 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-06-20 01:36:18,952 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-LeaderElection37] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-LeaderElection37 ELECTION round 0: submit vote requests at term 1 for -1: [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d|rpc:10.1.0.17:35727|priority:1], old=null
2022-06-20 01:36:18,952 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-LeaderElection37] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-LeaderElection37 ELECTION round 0: result PASSED (term=1)
2022-06-20 01:36:18,952 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-LeaderElection37] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d: shutdown fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-LeaderElection37
2022-06-20 01:36:18,952 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-LeaderElection37] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2022-06-20 01:36:18,952 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-LeaderElection37] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-35D4BFF3126D with new leaderId: fd1f8b8e-2a75-4423-a446-fc45b4d61a4d
2022-06-20 01:36:18,952 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-LeaderElection37] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D: change Leader from null to fd1f8b8e-2a75-4423-a446-fc45b4d61a4d at term 1 for becomeLeader, leader elected after 5123ms
2022-06-20 01:36:18,952 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-LeaderElection37] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-20 01:36:18,953 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-LeaderElection37] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-20 01:36:18,953 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-LeaderElection37] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-06-20 01:36:18,954 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-LeaderElection37] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-06-20 01:36:18,954 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-LeaderElection37] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-20 01:36:18,954 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-LeaderElection37] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-20 01:36:18,954 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-LeaderElection37] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-20 01:36:18,954 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-LeaderElection37] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-20 01:36:18,954 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-LeaderElection37] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d: start fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-LeaderStateImpl
2022-06-20 01:36:18,954 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-LeaderElection37] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-20 01:36:18,959 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-2/data/ratis/afc4b00a-4ea5-41e3-a374-35d4bff3126d/current/log_inprogress_0
2022-06-20 01:36:18,973 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-LeaderElection37] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D: set configuration 0: [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d|rpc:10.1.0.17:35727|dataStream:|priority:1], old=null
2022-06-20 01:36:19,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-06-20 01:36:19,463 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode 700564b4-0717-4bb0-a12e-83aaa95ec9ba{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=36621, RATIS=41783, RATIS_ADMIN=41783, RATIS_SERVER=41783, STANDALONE=44735], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=afb0e4a9-051a-44b5-9ed5-33f08d971fd4]
2022-06-20 01:36:19,463 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(430)) - Pipeline Pipeline[ Id: afb0e4a9-051a-44b5-9ed5-33f08d971fd4, Nodes: 700564b4-0717-4bb0-a12e-83aaa95ec9ba{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=36621, RATIS=41783, RATIS_ADMIN=41783, RATIS_SERVER=41783, STANDALONE=44735], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:700564b4-0717-4bb0-a12e-83aaa95ec9ba, CreationTimestamp2022-06-20T01:35:15.034Z[Etc/UTC]] moved to CLOSED state
2022-06-20 01:36:19,938 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:19,939 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:19,939 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:19,939 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:19,944 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:19,944 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:19,944 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 6 milliseconds for processing 3 containers.
2022-06-20 01:36:20,415 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-06-20 01:36:20,864 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode 4305c143-0452-4ed8-8c62-6c38c0ad1b23{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=46617, RATIS=35783, RATIS_ADMIN=35783, RATIS_SERVER=35783, STANDALONE=37345], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=b3299a2b-5565-4776-a640-7e01da335d8d]
2022-06-20 01:36:20,865 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(430)) - Pipeline Pipeline[ Id: b3299a2b-5565-4776-a640-7e01da335d8d, Nodes: 4305c143-0452-4ed8-8c62-6c38c0ad1b23{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=46617, RATIS=35783, RATIS_ADMIN=35783, RATIS_SERVER=35783, STANDALONE=37345], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONED, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:4305c143-0452-4ed8-8c62-6c38c0ad1b23, CreationTimestamp2022-06-20T01:35:55.501Z[Etc/UTC]] moved to CLOSED state
2022-06-20 01:36:20,944 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #1, no healthy replica found.
2022-06-20 01:36:20,945 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #2, no healthy replica found.
2022-06-20 01:36:20,945 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #3, no healthy replica found.
2022-06-20 01:36:20,945 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-20 01:36:21,415 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-06-20 01:36:21,945 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #1, no healthy replica found.
2022-06-20 01:36:21,945 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #2, no healthy replica found.
2022-06-20 01:36:21,945 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #3, no healthy replica found.
2022-06-20 01:36:21,945 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-06-20 01:36:22,064 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(365)) - Attempting to stop container services.
2022-06-20 01:36:22,065 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$7(398)) - 700564b4-0717-4bb0-a12e-83aaa95ec9ba: close
2022-06-20 01:36:22,065 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - 700564b4-0717-4bb0-a12e-83aaa95ec9ba@group-33F08D971FD4: shutdown
2022-06-20 01:36:22,065 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-33F08D971FD4,id=700564b4-0717-4bb0-a12e-83aaa95ec9ba
2022-06-20 01:36:22,065 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 700564b4-0717-4bb0-a12e-83aaa95ec9ba: shutdown 700564b4-0717-4bb0-a12e-83aaa95ec9ba@group-33F08D971FD4-LeaderStateImpl
2022-06-20 01:36:22,065 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 700564b4-0717-4bb0-a12e-83aaa95ec9ba@group-33F08D971FD4-PendingRequests: sendNotLeaderResponses
2022-06-20 01:36:22,066 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 700564b4-0717-4bb0-a12e-83aaa95ec9ba@group-33F08D971FD4-StateMachineUpdater: set stopIndex = 0
2022-06-20 01:36:22,066 [700564b4-0717-4bb0-a12e-83aaa95ec9ba@group-33F08D971FD4-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-33F08D971FD4: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b100358f-1f15-45e6-9c02-f3e691616771/datanode-0/data/ratis/afb0e4a9-051a-44b5-9ed5-33f08d971fd4/sm/snapshot.1_0
2022-06-20 01:36:22,067 [700564b4-0717-4bb0-a12e-83aaa95ec9ba@group-33F08D971FD4-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-33F08D971FD4: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b100358f-1f15-45e6-9c02-f3e691616771/datanode-0/data/ratis/afb0e4a9-051a-44b5-9ed5-33f08d971fd4/sm/snapshot.1_0 took: 2 ms
2022-06-20 01:36:22,067 [700564b4-0717-4bb0-a12e-83aaa95ec9ba@group-33F08D971FD4-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 700564b4-0717-4bb0-a12e-83aaa95ec9ba@group-33F08D971FD4-StateMachineUpdater: Took a snapshot at index 0
2022-06-20 01:36:22,067 [700564b4-0717-4bb0-a12e-83aaa95ec9ba@group-33F08D971FD4-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 700564b4-0717-4bb0-a12e-83aaa95ec9ba@group-33F08D971FD4-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-06-20 01:36:22,068 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer$Division (ServerState.java:close(429)) - 700564b4-0717-4bb0-a12e-83aaa95ec9ba@group-33F08D971FD4: closes. applyIndex: 0
2022-06-20 01:36:22,068 [700564b4-0717-4bb0-a12e-83aaa95ec9ba@group-33F08D971FD4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - 700564b4-0717-4bb0-a12e-83aaa95ec9ba@group-33F08D971FD4-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-20 01:36:22,068 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - 700564b4-0717-4bb0-a12e-83aaa95ec9ba@group-33F08D971FD4-SegmentedRaftLogWorker close()
2022-06-20 01:36:22,069 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(269)) - 700564b4-0717-4bb0-a12e-83aaa95ec9ba: shutdown server with port 41783 now
2022-06-20 01:36:22,082 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(278)) - 700564b4-0717-4bb0-a12e-83aaa95ec9ba: shutdown server with port 41783 successfully
2022-06-20 01:36:22,082 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1750956089@74ab8edc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-700564b4-0717-4bb0-a12e-83aaa95ec9ba: Stopped
2022-06-20 01:36:22,416 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-06-20 01:36:22,472 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. 700564b4-0717-4bb0-a12e-83aaa95ec9ba{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=36621, RATIS=41783, RATIS_ADMIN=41783, RATIS_SERVER=41783, STANDALONE=44735], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-06-20 01:36:22,473 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=afb0e4a9-051a-44b5-9ed5-33f08d971fd4 close command to datanode 700564b4-0717-4bb0-a12e-83aaa95ec9ba
2022-06-20 01:36:22,473 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(243)) - Pipeline Pipeline[ Id: afb0e4a9-051a-44b5-9ed5-33f08d971fd4, Nodes: 700564b4-0717-4bb0-a12e-83aaa95ec9ba{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=36621, RATIS=41783, RATIS_ADMIN=41783, RATIS_SERVER=41783, STANDALONE=44735], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:700564b4-0717-4bb0-a12e-83aaa95ec9ba, CreationTimestamp2022-06-20T01:35:15.034Z[Etc/UTC]] removed.
2022-06-20 01:36:22,473 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(137)) - Removed a node: /default-rack/700564b4-0717-4bb0-a12e-83aaa95ec9ba
2022-06-20 01:36:22,946 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #1, no healthy replica found.
2022-06-20 01:36:22,946 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #2, no healthy replica found.
2022-06-20 01:36:22,946 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #3, no healthy replica found.
2022-06-20 01:36:22,946 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-06-20 01:36:23,034 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5033603320ns, electionTimeout:5028ms
2022-06-20 01:36:23,034 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b: shutdown 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-FollowerState
2022-06-20 01:36:23,034 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2022-06-20 01:36:23,034 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-20 01:36:23,034 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b: start 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-LeaderElection38
2022-06-20 01:36:23,045 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-LeaderElection38] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-LeaderElection38 ELECTION round 0: submit vote requests at term 2 for -1: [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d|rpc:10.1.0.17:35727|dataStream:|priority:0, 5e432c75-8719-4a7d-ad09-7985e0971b8b|rpc:10.1.0.17:44011|dataStream:|priority:0, 6c2707a0-87fd-4dba-96bb-b14739c19597|rpc:10.1.0.17:37095|dataStream:|priority:1], old=null
2022-06-20 01:36:23,057 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B: receive requestVote(ELECTION, 5e432c75-8719-4a7d-ad09-7985e0971b8b, group-931A667C2C5B, 2, (t:0, i:0))
2022-06-20 01:36:23,059 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-FOLLOWER: accept ELECTION from 5e432c75-8719-4a7d-ad09-7985e0971b8b: our priority 0 <= candidate's priority 0
2022-06-20 01:36:23,059 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:5e432c75-8719-4a7d-ad09-7985e0971b8b
2022-06-20 01:36:23,059 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d: shutdown fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-FollowerState
2022-06-20 01:36:23,059 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d: start fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-FollowerState
2022-06-20 01:36:23,059 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-FollowerState was interrupted
2022-06-20 01:36:23,061 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B: receive requestVote(ELECTION, 5e432c75-8719-4a7d-ad09-7985e0971b8b, group-931A667C2C5B, 2, (t:0, i:0))
2022-06-20 01:36:23,066 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-FOLLOWER: reject ELECTION from 5e432c75-8719-4a7d-ad09-7985e0971b8b: our priority 1 > candidate's priority 0
2022-06-20 01:36:23,066 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:5e432c75-8719-4a7d-ad09-7985e0971b8b
2022-06-20 01:36:23,066 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 6c2707a0-87fd-4dba-96bb-b14739c19597: shutdown 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-FollowerState
2022-06-20 01:36:23,066 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6c2707a0-87fd-4dba-96bb-b14739c19597: start 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-FollowerState
2022-06-20 01:36:23,066 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-FollowerState was interrupted
2022-06-20 01:36:23,071 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B replies to ELECTION vote request: 5e432c75-8719-4a7d-ad09-7985e0971b8b<-fd1f8b8e-2a75-4423-a446-fc45b4d61a4d#0:OK-t2. Peer's state: fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B:t2, leader=null, voted=5e432c75-8719-4a7d-ad09-7985e0971b8b, raftlog=fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-SegmentedRaftLog:OPENED:c-1, conf=-1: [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d|rpc:10.1.0.17:35727|dataStream:|priority:0, 5e432c75-8719-4a7d-ad09-7985e0971b8b|rpc:10.1.0.17:44011|dataStream:|priority:0, 6c2707a0-87fd-4dba-96bb-b14739c19597|rpc:10.1.0.17:37095|dataStream:|priority:1], old=null
2022-06-20 01:36:23,076 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B replies to ELECTION vote request: 5e432c75-8719-4a7d-ad09-7985e0971b8b<-6c2707a0-87fd-4dba-96bb-b14739c19597#0:FAIL-t2. Peer's state: 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B:t2, leader=null, voted=null, raftlog=6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-SegmentedRaftLog:OPENED:c-1, conf=-1: [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d|rpc:10.1.0.17:35727|priority:0, 5e432c75-8719-4a7d-ad09-7985e0971b8b|rpc:10.1.0.17:44011|priority:0, 6c2707a0-87fd-4dba-96bb-b14739c19597|rpc:10.1.0.17:37095|priority:1], old=null
2022-06-20 01:36:23,087 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-LeaderElection38] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-LeaderElection38: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-06-20 01:36:23,087 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-LeaderElection38] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 5e432c75-8719-4a7d-ad09-7985e0971b8b<-fd1f8b8e-2a75-4423-a446-fc45b4d61a4d#0:OK-t2
2022-06-20 01:36:23,087 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-LeaderElection38] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 5e432c75-8719-4a7d-ad09-7985e0971b8b<-6c2707a0-87fd-4dba-96bb-b14739c19597#0:FAIL-t2
2022-06-20 01:36:23,087 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-LeaderElection38] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-LeaderElection38 ELECTION round 0: result REJECTED
2022-06-20 01:36:23,087 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-LeaderElection38] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
2022-06-20 01:36:23,087 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-LeaderElection38] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b: shutdown 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-LeaderElection38
2022-06-20 01:36:23,087 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-LeaderElection38] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b: start 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-FollowerState
2022-06-20 01:36:23,187 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(365)) - Attempting to stop container services.
2022-06-20 01:36:23,188 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$7(398)) - 4305c143-0452-4ed8-8c62-6c38c0ad1b23: close
2022-06-20 01:36:23,188 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - 4305c143-0452-4ed8-8c62-6c38c0ad1b23@group-7E01DA335D8D: shutdown
2022-06-20 01:36:23,188 [Mini-Cluster-Provider-Reap] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-7E01DA335D8D,id=4305c143-0452-4ed8-8c62-6c38c0ad1b23
2022-06-20 01:36:23,188 [Mini-Cluster-Provider-Reap] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 4305c143-0452-4ed8-8c62-6c38c0ad1b23: shutdown 4305c143-0452-4ed8-8c62-6c38c0ad1b23@group-7E01DA335D8D-LeaderStateImpl
2022-06-20 01:36:23,188 [Mini-Cluster-Provider-Reap] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 4305c143-0452-4ed8-8c62-6c38c0ad1b23@group-7E01DA335D8D-PendingRequests: sendNotLeaderResponses
2022-06-20 01:36:23,189 [Mini-Cluster-Provider-Reap] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 4305c143-0452-4ed8-8c62-6c38c0ad1b23@group-7E01DA335D8D-StateMachineUpdater: set stopIndex = 0
2022-06-20 01:36:23,192 [4305c143-0452-4ed8-8c62-6c38c0ad1b23@group-7E01DA335D8D-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-7E01DA335D8D: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b100358f-1f15-45e6-9c02-f3e691616771/datanode-4/data/ratis/b3299a2b-5565-4776-a640-7e01da335d8d/sm/snapshot.1_0
2022-06-20 01:36:23,193 [4305c143-0452-4ed8-8c62-6c38c0ad1b23@group-7E01DA335D8D-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-7E01DA335D8D: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b100358f-1f15-45e6-9c02-f3e691616771/datanode-4/data/ratis/b3299a2b-5565-4776-a640-7e01da335d8d/sm/snapshot.1_0 took: 2 ms
2022-06-20 01:36:23,197 [4305c143-0452-4ed8-8c62-6c38c0ad1b23@group-7E01DA335D8D-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 4305c143-0452-4ed8-8c62-6c38c0ad1b23@group-7E01DA335D8D-StateMachineUpdater: Took a snapshot at index 0
2022-06-20 01:36:23,197 [4305c143-0452-4ed8-8c62-6c38c0ad1b23@group-7E01DA335D8D-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 4305c143-0452-4ed8-8c62-6c38c0ad1b23@group-7E01DA335D8D-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-06-20 01:36:23,198 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (ServerState.java:close(429)) - 4305c143-0452-4ed8-8c62-6c38c0ad1b23@group-7E01DA335D8D: closes. applyIndex: 0
2022-06-20 01:36:23,198 [4305c143-0452-4ed8-8c62-6c38c0ad1b23@group-7E01DA335D8D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - 4305c143-0452-4ed8-8c62-6c38c0ad1b23@group-7E01DA335D8D-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-20 01:36:23,198 [Mini-Cluster-Provider-Reap] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - 4305c143-0452-4ed8-8c62-6c38c0ad1b23@group-7E01DA335D8D-SegmentedRaftLogWorker close()
2022-06-20 01:36:23,198 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(269)) - 4305c143-0452-4ed8-8c62-6c38c0ad1b23: shutdown server with port 35783 now
2022-06-20 01:36:23,202 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(278)) - 4305c143-0452-4ed8-8c62-6c38c0ad1b23: shutdown server with port 35783 successfully
2022-06-20 01:36:23,202 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1750956089@60719190] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-4305c143-0452-4ed8-8c62-6c38c0ad1b23: Stopped
2022-06-20 01:36:23,416 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-06-20 01:36:23,876 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. 4305c143-0452-4ed8-8c62-6c38c0ad1b23{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=46617, RATIS=35783, RATIS_ADMIN=35783, RATIS_SERVER=35783, STANDALONE=37345], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-06-20 01:36:23,877 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=b3299a2b-5565-4776-a640-7e01da335d8d close command to datanode 4305c143-0452-4ed8-8c62-6c38c0ad1b23
2022-06-20 01:36:23,877 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(243)) - Pipeline Pipeline[ Id: b3299a2b-5565-4776-a640-7e01da335d8d, Nodes: 4305c143-0452-4ed8-8c62-6c38c0ad1b23{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=46617, RATIS=35783, RATIS_ADMIN=35783, RATIS_SERVER=35783, STANDALONE=37345], networkLocation: /default-rack, certSerialId: null, persistedOpState: DECOMMISSIONED, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:4305c143-0452-4ed8-8c62-6c38c0ad1b23, CreationTimestamp2022-06-20T01:35:55.501Z[Etc/UTC]] removed.
2022-06-20 01:36:23,877 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(137)) - Removed a node: /default-rack/4305c143-0452-4ed8-8c62-6c38c0ad1b23
2022-06-20 01:36:23,946 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #1, no healthy replica found.
2022-06-20 01:36:23,946 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #2, no healthy replica found.
2022-06-20 01:36:23,946 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #3, no healthy replica found.
2022-06-20 01:36:23,947 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-20 01:36:24,118 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-06-20 01:36:24,417 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-06-20 01:36:24,947 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #1, no healthy replica found.
2022-06-20 01:36:24,947 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #2, no healthy replica found.
2022-06-20 01:36:24,947 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #3, no healthy replica found.
2022-06-20 01:36:24,947 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-06-20 01:36:25,251 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-06-20 01:36:25,417 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-06-20 01:36:25,947 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #1, no healthy replica found.
2022-06-20 01:36:25,948 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #2, no healthy replica found.
2022-06-20 01:36:25,948 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #3, no healthy replica found.
2022-06-20 01:36:25,948 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 3 containers.
2022-06-20 01:36:26,418 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-06-20 01:36:26,948 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #1, no healthy replica found.
2022-06-20 01:36:26,948 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #2, no healthy replica found.
2022-06-20 01:36:26,948 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #3, no healthy replica found.
2022-06-20 01:36:26,948 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-06-20 01:36:27,152 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(580)) - Ozone container server stopped.
2022-06-20 01:36:27,176 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@11566e34{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-20 01:36:27,176 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@6c83ce27{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-06-20 01:36:27,177 [ForkJoinPool.commonPool-worker-0] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-06-20 01:36:27,202 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@1b146cff{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-06-20 01:36:27,202 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@76239ff3{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-06-20 01:36:27,418 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-06-20 01:36:27,949 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #1, no healthy replica found.
2022-06-20 01:36:27,949 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #2, no healthy replica found.
2022-06-20 01:36:27,949 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #3, no healthy replica found.
2022-06-20 01:36:27,949 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 3 containers.
2022-06-20 01:36:28,092 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5020755725ns, electionTimeout:5005ms
2022-06-20 01:36:28,092 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d: shutdown fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-FollowerState
2022-06-20 01:36:28,092 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2022-06-20 01:36:28,092 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-20 01:36:28,092 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d: start fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-LeaderElection39
2022-06-20 01:36:28,102 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-LeaderElection39] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-LeaderElection39 ELECTION round 0: submit vote requests at term 3 for -1: [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d|rpc:10.1.0.17:35727|dataStream:|priority:0, 5e432c75-8719-4a7d-ad09-7985e0971b8b|rpc:10.1.0.17:44011|dataStream:|priority:0, 6c2707a0-87fd-4dba-96bb-b14739c19597|rpc:10.1.0.17:37095|dataStream:|priority:1], old=null
2022-06-20 01:36:28,124 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B: receive requestVote(ELECTION, fd1f8b8e-2a75-4423-a446-fc45b4d61a4d, group-931A667C2C5B, 3, (t:0, i:0))
2022-06-20 01:36:28,125 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-FOLLOWER: accept ELECTION from fd1f8b8e-2a75-4423-a446-fc45b4d61a4d: our priority 0 <= candidate's priority 0
2022-06-20 01:36:28,125 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:fd1f8b8e-2a75-4423-a446-fc45b4d61a4d
2022-06-20 01:36:28,125 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b: shutdown 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-FollowerState
2022-06-20 01:36:28,125 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5058969170ns, electionTimeout:5034ms
2022-06-20 01:36:28,125 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b: start 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-FollowerState
2022-06-20 01:36:28,125 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 6c2707a0-87fd-4dba-96bb-b14739c19597: shutdown 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-FollowerState
2022-06-20 01:36:28,125 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2022-06-20 01:36:28,125 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-FollowerState was interrupted
2022-06-20 01:36:28,127 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B: receive requestVote(ELECTION, fd1f8b8e-2a75-4423-a446-fc45b4d61a4d, group-931A667C2C5B, 3, (t:0, i:0))
2022-06-20 01:36:28,128 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-20 01:36:28,128 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6c2707a0-87fd-4dba-96bb-b14739c19597: start 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection40
2022-06-20 01:36:28,130 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B replies to ELECTION vote request: fd1f8b8e-2a75-4423-a446-fc45b4d61a4d<-5e432c75-8719-4a7d-ad09-7985e0971b8b#0:OK-t3. Peer's state: 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B:t3, leader=null, voted=fd1f8b8e-2a75-4423-a446-fc45b4d61a4d, raftlog=5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-SegmentedRaftLog:OPENED:c-1, conf=-1: [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d|rpc:10.1.0.17:35727|dataStream:|priority:0, 5e432c75-8719-4a7d-ad09-7985e0971b8b|rpc:10.1.0.17:44011|dataStream:|priority:0, 6c2707a0-87fd-4dba-96bb-b14739c19597|rpc:10.1.0.17:37095|dataStream:|priority:1], old=null
2022-06-20 01:36:28,136 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-CANDIDATE: reject ELECTION from fd1f8b8e-2a75-4423-a446-fc45b4d61a4d: our priority 1 > candidate's priority 0
2022-06-20 01:36:28,136 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B: changes role from CANDIDATE to FOLLOWER at term 3 for candidate:fd1f8b8e-2a75-4423-a446-fc45b4d61a4d
2022-06-20 01:36:28,136 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 6c2707a0-87fd-4dba-96bb-b14739c19597: shutdown 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection40
2022-06-20 01:36:28,136 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6c2707a0-87fd-4dba-96bb-b14739c19597: start 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-FollowerState
2022-06-20 01:36:28,137 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection40] INFO  impl.LeaderElection (LeaderElection.java:run(231)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection40: skip running since this is already CLOSING
2022-06-20 01:36:28,139 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B replies to ELECTION vote request: fd1f8b8e-2a75-4423-a446-fc45b4d61a4d<-6c2707a0-87fd-4dba-96bb-b14739c19597#0:FAIL-t3. Peer's state: 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B:t3, leader=null, voted=null, raftlog=6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-SegmentedRaftLog:OPENED:c-1, conf=-1: [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d|rpc:10.1.0.17:35727|priority:0, 5e432c75-8719-4a7d-ad09-7985e0971b8b|rpc:10.1.0.17:44011|priority:0, 6c2707a0-87fd-4dba-96bb-b14739c19597|rpc:10.1.0.17:37095|priority:1], old=null
2022-06-20 01:36:28,143 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-LeaderElection39] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-LeaderElection39: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2022-06-20 01:36:28,143 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-LeaderElection39] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: fd1f8b8e-2a75-4423-a446-fc45b4d61a4d<-5e432c75-8719-4a7d-ad09-7985e0971b8b#0:OK-t3
2022-06-20 01:36:28,143 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-LeaderElection39] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: fd1f8b8e-2a75-4423-a446-fc45b4d61a4d<-6c2707a0-87fd-4dba-96bb-b14739c19597#0:FAIL-t3
2022-06-20 01:36:28,143 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-LeaderElection39] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-LeaderElection39 ELECTION round 0: result REJECTED
2022-06-20 01:36:28,143 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-LeaderElection39] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
2022-06-20 01:36:28,143 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-LeaderElection39] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d: shutdown fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-LeaderElection39
2022-06-20 01:36:28,143 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-LeaderElection39] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d: start fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-FollowerState
2022-06-20 01:36:28,263 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(580)) - Ozone container server stopped.
2022-06-20 01:36:28,297 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@b788dc2{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-20 01:36:28,302 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@7ecb9e17{HTTP/1.1, (http/1.1)}{0.0.0.0:45487}
2022-06-20 01:36:28,302 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-06-20 01:36:28,303 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@4ac19bc6{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-06-20 01:36:28,303 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@49d543a9{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-06-20 01:36:28,305 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(545)) - Stopping the StorageContainerManager
2022-06-20 01:36:28,305 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1501)) - Container Balancer is not running.
2022-06-20 01:36:28,305 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1508)) - Stopping Replication Manager Service.
2022-06-20 01:36:28,305 [Mini-Cluster-Provider-Reap] INFO  replication.ReplicationManager (ReplicationManager.java:stop(212)) - Stopping Replication Monitor Thread.
2022-06-20 01:36:28,306 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(270)) - Replication Monitor Thread is stopped
2022-06-20 01:36:28,306 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1515)) - Stopping the Datanode Admin Monitor.
2022-06-20 01:36:28,306 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1522)) - Stopping Lease Manager of the command watchers
2022-06-20 01:36:28,307 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1529)) - Stopping datanode service RPC server
2022-06-20 01:36:28,307 [Mini-Cluster-Provider-Reap] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(400)) - Stopping the RPC server for DataNodes
2022-06-20 01:36:28,307 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3414)) - Stopping server on 36329
2022-06-20 01:36:28,310 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1376)) - Stopping IPC Server listener on 0
2022-06-20 01:36:28,311 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - Stopping IPC Server Responder
2022-06-20 01:36:28,403 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(848)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2022-06-20 01:36:28,404 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1537)) - Stopping block service RPC server
2022-06-20 01:36:28,404 [Mini-Cluster-Provider-Reap] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(160)) - Stopping the RPC server for Block Protocol
2022-06-20 01:36:28,404 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3414)) - Stopping server on 45831
2022-06-20 01:36:28,410 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1544)) - Stopping the StorageContainerLocationProtocol RPC server
2022-06-20 01:36:28,410 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - Stopping IPC Server Responder
2022-06-20 01:36:28,410 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1376)) - Stopping IPC Server listener on 0
2022-06-20 01:36:28,410 [Mini-Cluster-Provider-Reap] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(178)) - Stopping the RPC server for Client Protocol
2022-06-20 01:36:28,411 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3414)) - Stopping server on 44655
2022-06-20 01:36:28,412 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1551)) - Stopping Storage Container Manager HTTP server.
2022-06-20 01:36:28,412 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - Stopping IPC Server Responder
2022-06-20 01:36:28,413 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1376)) - Stopping IPC Server listener on 0
2022-06-20 01:36:28,416 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@4d9d2a60{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2022-06-20 01:36:28,416 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@23b3af40{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-06-20 01:36:28,416 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-06-20 01:36:28,417 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@91c0576{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2022-06-20 01:36:28,417 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@41dba13d{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-06-20 01:36:28,418 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1562)) - Stopping Block Manager Service.
2022-06-20 01:36:28,418 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service SCMBlockDeletingService
2022-06-20 01:36:28,418 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service SCMBlockDeletingService
2022-06-20 01:36:28,418 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1589)) - Stopping SCM Event Queue.
2022-06-20 01:36:28,419 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-06-20 01:36:28,453 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1600)) - Stopping SCM HA services.
2022-06-20 01:36:28,453 [Mini-Cluster-Provider-Reap] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(150)) - Stopping RatisPipelineUtilsThread.
2022-06-20 01:36:28,456 [RatisPipelineUtilsThread - 0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(177)) - RatisPipelineUtilsThread is interrupted.
2022-06-20 01:36:28,456 [Mini-Cluster-Provider-Reap] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(126)) - Stopping BackgroundPipelineScrubber Service.
2022-06-20 01:36:28,456 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1610)) - Stopping SCM MetadataStore.
2022-06-20 01:36:28,457 [Mini-Cluster-Provider-Reap] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(205)) - HddsDatanode metrics system stopped (again)
2022-06-20 01:36:28,460 [BackgroundPipelineScrubberThread] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(110)) - BackgroundPipelineScrubber is interrupted, exit
2022-06-20 01:36:28,616 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(456)) - Shutting down the Mini Ozone Cluster
2022-06-20 01:36:28,616 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(471)) - Stopping the Mini Ozone Cluster
2022-06-20 01:36:28,616 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(553)) - Stopping the OzoneManager
2022-06-20 01:36:28,616 [Mini-Cluster-Provider-Reap] INFO  om.OzoneManager (OzoneManager.java:stop(2020)) - om1[localhost:0]: Stopping Ozone Manager
2022-06-20 01:36:28,618 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3414)) - Stopping server on 36243
2022-06-20 01:36:28,618 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1376)) - Stopping IPC Server listener on 0
2022-06-20 01:36:28,637 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - Stopping IPC Server Responder
2022-06-20 01:36:28,639 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$7(398)) - om1: close
2022-06-20 01:36:28,640 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - om1@group-C5BA1605619E: shutdown
2022-06-20 01:36:28,640 [Mini-Cluster-Provider-Reap] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id="om1"
2022-06-20 01:36:28,640 [Mini-Cluster-Provider-Reap] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - om1: shutdown om1@group-C5BA1605619E-LeaderStateImpl
2022-06-20 01:36:28,640 [Mini-Cluster-Provider-Reap] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - om1@group-C5BA1605619E-PendingRequests: sendNotLeaderResponses
2022-06-20 01:36:28,664 [Mini-Cluster-Provider-Reap] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - om1@group-C5BA1605619E-StateMachineUpdater: set stopIndex = 84
2022-06-20 01:36:28,664 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(441)) - Current Snapshot Index (t:1, i:84)
2022-06-20 01:36:28,664 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - om1@group-C5BA1605619E-StateMachineUpdater: Took a snapshot at index 84
2022-06-20 01:36:28,664 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - om1@group-C5BA1605619E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 84
2022-06-20 01:36:28,664 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(495)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2022-06-20 01:36:28,665 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(465)) - Stopping OMDoubleBuffer flush thread
2022-06-20 01:36:28,665 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(385)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit.
2022-06-20 01:36:28,665 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (ServerState.java:close(429)) - om1@group-C5BA1605619E: closes. applyIndex: 84
2022-06-20 01:36:28,665 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-20 01:36:28,666 [Mini-Cluster-Provider-Reap] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker close()
2022-06-20 01:36:28,667 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(269)) - om1: shutdown server with port 44533 now
2022-06-20 01:36:28,672 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(278)) - om1: shutdown server with port 44533 successfully
2022-06-20 01:36:28,672 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1750956089@5a48e41a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-om1: Stopped
2022-06-20 01:36:28,672 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(495)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2022-06-20 01:36:28,672 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(477)) - OMDoubleBuffer flush thread is not running.
2022-06-20 01:36:28,672 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service KeyDeletingService
2022-06-20 01:36:28,673 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service DirectoryDeletingService
2022-06-20 01:36:28,676 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@124136b2{ozoneManager,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2022-06-20 01:36:28,679 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@2a80517{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-06-20 01:36:28,679 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-06-20 01:36:28,679 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@7a3d9873{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2022-06-20 01:36:28,679 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@1ce1ee9e{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-06-20 01:36:28,683 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(530)) - Stopping the HddsDatanodes
2022-06-20 01:36:29,419 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-06-20 01:36:30,424 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-06-20 01:36:30,576 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(365)) - Attempting to stop container services.
2022-06-20 01:36:30,577 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$7(398)) - 9ece5a04-4580-4177-bd03-ef9ae8c86b04: close
2022-06-20 01:36:30,577 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - 9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-0A153277B499: shutdown
2022-06-20 01:36:30,577 [Mini-Cluster-Provider-Reap] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-0A153277B499,id=9ece5a04-4580-4177-bd03-ef9ae8c86b04
2022-06-20 01:36:30,578 [Mini-Cluster-Provider-Reap] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 9ece5a04-4580-4177-bd03-ef9ae8c86b04: shutdown 9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-0A153277B499-LeaderStateImpl
2022-06-20 01:36:30,578 [Mini-Cluster-Provider-Reap] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-0A153277B499-PendingRequests: sendNotLeaderResponses
2022-06-20 01:36:30,578 [Mini-Cluster-Provider-Reap] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-0A153277B499-StateMachineUpdater: set stopIndex = 0
2022-06-20 01:36:30,578 [9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-0A153277B499-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-0A153277B499: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-3/data/ratis/f077a8bb-16d7-4a00-94d3-0a153277b499/sm/snapshot.1_0
2022-06-20 01:36:30,598 [9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-0A153277B499-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-0A153277B499: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-3/data/ratis/f077a8bb-16d7-4a00-94d3-0a153277b499/sm/snapshot.1_0 took: 20 ms
2022-06-20 01:36:30,599 [9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-0A153277B499-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-0A153277B499-StateMachineUpdater: Took a snapshot at index 0
2022-06-20 01:36:30,599 [9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-0A153277B499-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-0A153277B499-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-06-20 01:36:30,599 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (ServerState.java:close(429)) - 9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-0A153277B499: closes. applyIndex: 0
2022-06-20 01:36:30,599 [9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-0A153277B499-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - 9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-0A153277B499-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-20 01:36:30,600 [Mini-Cluster-Provider-Reap] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - 9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-0A153277B499-SegmentedRaftLogWorker close()
2022-06-20 01:36:30,600 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - 9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-C59EB1D378B7: shutdown
2022-06-20 01:36:30,600 [Mini-Cluster-Provider-Reap] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C59EB1D378B7,id=9ece5a04-4580-4177-bd03-ef9ae8c86b04
2022-06-20 01:36:30,600 [Mini-Cluster-Provider-Reap] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9ece5a04-4580-4177-bd03-ef9ae8c86b04: shutdown 9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-C59EB1D378B7-FollowerState
2022-06-20 01:36:30,600 [Mini-Cluster-Provider-Reap] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-C59EB1D378B7-StateMachineUpdater: set stopIndex = 40
2022-06-20 01:36:30,600 [9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-C59EB1D378B7-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-C59EB1D378B7: Taking a snapshot at:(t:4, i:40) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-3/data/ratis/e614cc2c-3ea4-4885-93f5-c59eb1d378b7/sm/snapshot.4_40
2022-06-20 01:36:30,600 [9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-C59EB1D378B7-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-C59EB1D378B7-FollowerState was interrupted
2022-06-20 01:36:30,603 [9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-C59EB1D378B7-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-C59EB1D378B7: Finished taking a snapshot at:(t:4, i:40) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-3/data/ratis/e614cc2c-3ea4-4885-93f5-c59eb1d378b7/sm/snapshot.4_40 took: 3 ms
2022-06-20 01:36:30,603 [9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-C59EB1D378B7-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-C59EB1D378B7-StateMachineUpdater: Took a snapshot at index 40
2022-06-20 01:36:30,604 [9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-C59EB1D378B7-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-C59EB1D378B7-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 40
2022-06-20 01:36:30,604 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (ServerState.java:close(429)) - 9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-C59EB1D378B7: closes. applyIndex: 40
2022-06-20 01:36:30,605 [9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-C59EB1D378B7-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - 9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-C59EB1D378B7-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-20 01:36:30,608 [Mini-Cluster-Provider-Reap] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - 9ece5a04-4580-4177-bd03-ef9ae8c86b04@group-C59EB1D378B7-SegmentedRaftLogWorker close()
2022-06-20 01:36:30,608 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(269)) - 9ece5a04-4580-4177-bd03-ef9ae8c86b04: shutdown server with port 38907 now
2022-06-20 01:36:30,619 [grpc-default-executor-5] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - 9ece5a04-4580-4177-bd03-ef9ae8c86b04: installSnapshot onError, lastRequest: 1c5b3100-0df6-4edf-aaf2-8491709a0a2e->9ece5a04-4580-4177-bd03-ef9ae8c86b04#218-t4,previous=(t:4, i:39),leaderCommit=38,initializing? true,entries: size=1, first=(t:4, i:40), METADATAENTRY(c:38): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2022-06-20 01:36:30,620 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(278)) - 9ece5a04-4580-4177-bd03-ef9ae8c86b04: shutdown server with port 38907 successfully
2022-06-20 01:36:30,623 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1750956089@c3b8806] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-9ece5a04-4580-4177-bd03-ef9ae8c86b04: Stopped
2022-06-20 01:36:30,624 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2022-06-20 01:36:30,624 [grpc-default-executor-0] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04: nextIndex: updateUnconditionally 41 -> 40
2022-06-20 01:36:30,633 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-06-20 01:36:30,633 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04: nextIndex: updateUnconditionally 41 -> 40
2022-06-20 01:36:30,920 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode 5e432c75-8719-4a7d-ad09-7985e0971b8b{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=40283, RATIS=44011, RATIS_ADMIN=44011, RATIS_SERVER=44011, STANDALONE=34313], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=7b40afe4-7a11-46b3-955b-931a667c2c5b, PipelineID=27442fc4-f4d7-4206-a0cc-cf3e20f3e79f]
2022-06-20 01:36:30,921 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(430)) - Pipeline Pipeline[ Id: 7b40afe4-7a11-46b3-955b-931a667c2c5b, Nodes: 5e432c75-8719-4a7d-ad09-7985e0971b8b{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=40283, RATIS=44011, RATIS_ADMIN=44011, RATIS_SERVER=44011, STANDALONE=34313], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}fd1f8b8e-2a75-4423-a446-fc45b4d61a4d{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=46197, RATIS=35727, RATIS_ADMIN=35727, RATIS_SERVER=35727, STANDALONE=33859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}6c2707a0-87fd-4dba-96bb-b14739c19597{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=32853, RATIS=37095, RATIS_ADMIN=37095, RATIS_SERVER=37095, STANDALONE=33553], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-20T01:36:11.376Z[Etc/UTC]] moved to CLOSED state
2022-06-20 01:36:30,921 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(430)) - Pipeline Pipeline[ Id: 27442fc4-f4d7-4206-a0cc-cf3e20f3e79f, Nodes: 5e432c75-8719-4a7d-ad09-7985e0971b8b{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=40283, RATIS=44011, RATIS_ADMIN=44011, RATIS_SERVER=44011, STANDALONE=34313], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:5e432c75-8719-4a7d-ad09-7985e0971b8b, CreationTimestamp2022-06-20T01:36:11.375Z[Etc/UTC]] moved to CLOSED state
2022-06-20 01:36:31,421 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode 9ece5a04-4580-4177-bd03-ef9ae8c86b04{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=38363, RATIS=38907, RATIS_ADMIN=38907, RATIS_SERVER=38907, STANDALONE=40597], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=f077a8bb-16d7-4a00-94d3-0a153277b499, PipelineID=e614cc2c-3ea4-4885-93f5-c59eb1d378b7]
2022-06-20 01:36:31,421 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(430)) - Pipeline Pipeline[ Id: f077a8bb-16d7-4a00-94d3-0a153277b499, Nodes: 9ece5a04-4580-4177-bd03-ef9ae8c86b04{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=38363, RATIS=38907, RATIS_ADMIN=38907, RATIS_SERVER=38907, STANDALONE=40597], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:9ece5a04-4580-4177-bd03-ef9ae8c86b04, CreationTimestamp2022-06-20T01:35:33.420Z[Etc/UTC]] moved to CLOSED state
2022-06-20 01:36:31,422 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(409)) - Container #3 closed for pipeline=PipelineID=e614cc2c-3ea4-4885-93f5-c59eb1d378b7
2022-06-20 01:36:31,422 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(70)) - Close container Event triggered for container : #3
2022-06-20 01:36:31,422 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(409)) - Container #5 closed for pipeline=PipelineID=e614cc2c-3ea4-4885-93f5-c59eb1d378b7
2022-06-20 01:36:31,422 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(70)) - Close container Event triggered for container : #5
2022-06-20 01:36:31,422 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(409)) - Container #6 closed for pipeline=PipelineID=e614cc2c-3ea4-4885-93f5-c59eb1d378b7
2022-06-20 01:36:31,422 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(70)) - Close container Event triggered for container : #6
2022-06-20 01:36:31,422 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(430)) - Pipeline Pipeline[ Id: e614cc2c-3ea4-4885-93f5-c59eb1d378b7, Nodes: 6f92f58e-935c-4e45-b2b1-2d5bfa669174{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=42433, RATIS=34635, RATIS_ADMIN=34635, RATIS_SERVER=34635, STANDALONE=32799], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1c5b3100-0df6-4edf-aaf2-8491709a0a2e{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=33141, RATIS=34593, RATIS_ADMIN=34593, RATIS_SERVER=34593, STANDALONE=43715], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9ece5a04-4580-4177-bd03-ef9ae8c86b04{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=38363, RATIS=38907, RATIS_ADMIN=38907, RATIS_SERVER=38907, STANDALONE=40597], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:1c5b3100-0df6-4edf-aaf2-8491709a0a2e, CreationTimestamp2022-06-20T01:35:34.122Z[Etc/UTC]] moved to CLOSED state
2022-06-20 01:36:31,424 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #3 to datanode 1c5b3100-0df6-4edf-aaf2-8491709a0a2e{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=33141, RATIS=34593, RATIS_ADMIN=34593, RATIS_SERVER=34593, STANDALONE=43715], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-20 01:36:31,424 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #3 to datanode 6f92f58e-935c-4e45-b2b1-2d5bfa669174{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=42433, RATIS=34635, RATIS_ADMIN=34635, RATIS_SERVER=34635, STANDALONE=32799], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-20 01:36:31,424 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #3 to datanode 9ece5a04-4580-4177-bd03-ef9ae8c86b04{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=38363, RATIS=38907, RATIS_ADMIN=38907, RATIS_SERVER=38907, STANDALONE=40597], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-20 01:36:31,424 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #5 to datanode 1c5b3100-0df6-4edf-aaf2-8491709a0a2e{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=33141, RATIS=34593, RATIS_ADMIN=34593, RATIS_SERVER=34593, STANDALONE=43715], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-20 01:36:31,424 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #5 to datanode 6f92f58e-935c-4e45-b2b1-2d5bfa669174{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=42433, RATIS=34635, RATIS_ADMIN=34635, RATIS_SERVER=34635, STANDALONE=32799], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-20 01:36:31,425 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #5 to datanode 9ece5a04-4580-4177-bd03-ef9ae8c86b04{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=38363, RATIS=38907, RATIS_ADMIN=38907, RATIS_SERVER=38907, STANDALONE=40597], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-20 01:36:31,425 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #6 to datanode 6f92f58e-935c-4e45-b2b1-2d5bfa669174{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=42433, RATIS=34635, RATIS_ADMIN=34635, RATIS_SERVER=34635, STANDALONE=32799], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-20 01:36:31,425 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #6 to datanode 1c5b3100-0df6-4edf-aaf2-8491709a0a2e{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=33141, RATIS=34593, RATIS_ADMIN=34593, RATIS_SERVER=34593, STANDALONE=43715], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-20 01:36:31,425 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #6 to datanode 9ece5a04-4580-4177-bd03-ef9ae8c86b04{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=38363, RATIS=38907, RATIS_ADMIN=38907, RATIS_SERVER=38907, STANDALONE=40597], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-20 01:36:31,425 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-06-20 01:36:32,425 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #3 to datanode 1c5b3100-0df6-4edf-aaf2-8491709a0a2e{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=33141, RATIS=34593, RATIS_ADMIN=34593, RATIS_SERVER=34593, STANDALONE=43715], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-20 01:36:32,425 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #3 to datanode 6f92f58e-935c-4e45-b2b1-2d5bfa669174{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=42433, RATIS=34635, RATIS_ADMIN=34635, RATIS_SERVER=34635, STANDALONE=32799], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-20 01:36:32,425 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #3 to datanode 9ece5a04-4580-4177-bd03-ef9ae8c86b04{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=38363, RATIS=38907, RATIS_ADMIN=38907, RATIS_SERVER=38907, STANDALONE=40597], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-20 01:36:32,425 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #5 to datanode 1c5b3100-0df6-4edf-aaf2-8491709a0a2e{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=33141, RATIS=34593, RATIS_ADMIN=34593, RATIS_SERVER=34593, STANDALONE=43715], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-20 01:36:32,426 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #5 to datanode 6f92f58e-935c-4e45-b2b1-2d5bfa669174{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=42433, RATIS=34635, RATIS_ADMIN=34635, RATIS_SERVER=34635, STANDALONE=32799], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-20 01:36:32,426 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #5 to datanode 9ece5a04-4580-4177-bd03-ef9ae8c86b04{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=38363, RATIS=38907, RATIS_ADMIN=38907, RATIS_SERVER=38907, STANDALONE=40597], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-20 01:36:32,426 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #6 to datanode 6f92f58e-935c-4e45-b2b1-2d5bfa669174{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=42433, RATIS=34635, RATIS_ADMIN=34635, RATIS_SERVER=34635, STANDALONE=32799], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-20 01:36:32,426 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #6 to datanode 1c5b3100-0df6-4edf-aaf2-8491709a0a2e{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=33141, RATIS=34593, RATIS_ADMIN=34593, RATIS_SERVER=34593, STANDALONE=43715], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-20 01:36:32,426 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #6 to datanode 9ece5a04-4580-4177-bd03-ef9ae8c86b04{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=38363, RATIS=38907, RATIS_ADMIN=38907, RATIS_SERVER=38907, STANDALONE=40597], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-20 01:36:32,426 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-06-20 01:36:32,649 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-06-20 01:36:32,654 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-06-20 01:36:32,655 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04: nextIndex: updateUnconditionally 41 -> 40
2022-06-20 01:36:33,216 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5080037082ns, electionTimeout:5079ms
2022-06-20 01:36:33,217 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 6c2707a0-87fd-4dba-96bb-b14739c19597: shutdown 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-FollowerState
2022-06-20 01:36:33,217 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
2022-06-20 01:36:33,217 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-20 01:36:33,217 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6c2707a0-87fd-4dba-96bb-b14739c19597: start 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41
2022-06-20 01:36:33,237 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41 ELECTION round 0: submit vote requests at term 4 for -1: [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d|rpc:10.1.0.17:35727|priority:0, 5e432c75-8719-4a7d-ad09-7985e0971b8b|rpc:10.1.0.17:44011|priority:0, 6c2707a0-87fd-4dba-96bb-b14739c19597|rpc:10.1.0.17:37095|priority:1], old=null
2022-06-20 01:36:33,266 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B: receive requestVote(ELECTION, 6c2707a0-87fd-4dba-96bb-b14739c19597, group-931A667C2C5B, 4, (t:0, i:0))
2022-06-20 01:36:33,266 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-FOLLOWER: accept ELECTION from 6c2707a0-87fd-4dba-96bb-b14739c19597: our priority 0 <= candidate's priority 1
2022-06-20 01:36:33,266 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:6c2707a0-87fd-4dba-96bb-b14739c19597
2022-06-20 01:36:33,266 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d: shutdown fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-FollowerState
2022-06-20 01:36:33,266 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d: start fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-FollowerState
2022-06-20 01:36:33,266 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-FollowerState was interrupted
2022-06-20 01:36:33,274 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5144394262ns, electionTimeout:5138ms
2022-06-20 01:36:33,275 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b: shutdown 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-FollowerState
2022-06-20 01:36:33,275 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
2022-06-20 01:36:33,276 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2022-06-20 01:36:33,276 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b: start 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-LeaderElection42
2022-06-20 01:36:33,280 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B replies to ELECTION vote request: 6c2707a0-87fd-4dba-96bb-b14739c19597<-fd1f8b8e-2a75-4423-a446-fc45b4d61a4d#0:OK-t4. Peer's state: fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B:t4, leader=null, voted=6c2707a0-87fd-4dba-96bb-b14739c19597, raftlog=fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-SegmentedRaftLog:OPENED:c-1, conf=-1: [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d|rpc:10.1.0.17:35727|dataStream:|priority:0, 5e432c75-8719-4a7d-ad09-7985e0971b8b|rpc:10.1.0.17:44011|dataStream:|priority:0, 6c2707a0-87fd-4dba-96bb-b14739c19597|rpc:10.1.0.17:37095|dataStream:|priority:1], old=null
2022-06-20 01:36:33,289 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41: ELECTION PASSED received 1 response(s) and 0 exception(s):
2022-06-20 01:36:33,289 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 6c2707a0-87fd-4dba-96bb-b14739c19597<-fd1f8b8e-2a75-4423-a446-fc45b4d61a4d#0:OK-t4
2022-06-20 01:36:33,289 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41 ELECTION round 0: result PASSED
2022-06-20 01:36:33,289 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 6c2707a0-87fd-4dba-96bb-b14739c19597: shutdown 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41
2022-06-20 01:36:33,289 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B: changes role from CANDIDATE to LEADER at term 4 for changeToLeader
2022-06-20 01:36:33,290 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-931A667C2C5B with new leaderId: 6c2707a0-87fd-4dba-96bb-b14739c19597
2022-06-20 01:36:33,290 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B: change Leader from null to 6c2707a0-87fd-4dba-96bb-b14739c19597 at term 4 for becomeLeader, leader elected after 20456ms
2022-06-20 01:36:33,290 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2022-06-20 01:36:33,290 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-20 01:36:33,290 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2022-06-20 01:36:33,290 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2022-06-20 01:36:33,290 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2022-06-20 01:36:33,290 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2022-06-20 01:36:33,291 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2022-06-20 01:36:33,291 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2022-06-20 01:36:33,291 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2022-06-20 01:36:33,291 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-20 01:36:33,291 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2022-06-20 01:36:33,292 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2022-06-20 01:36:33,292 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-20 01:36:33,292 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-20 01:36:33,298 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2022-06-20 01:36:33,298 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2022-06-20 01:36:33,298 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2022-06-20 01:36:33,298 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2022-06-20 01:36:33,298 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2022-06-20 01:36:33,298 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2022-06-20 01:36:33,298 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6c2707a0-87fd-4dba-96bb-b14739c19597: start 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderStateImpl
2022-06-20 01:36:33,299 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-20 01:36:33,309 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-0/data/ratis/7b40afe4-7a11-46b3-955b-931a667c2c5b/current/log_inprogress_0
2022-06-20 01:36:33,326 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-LeaderElection42] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(310)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-LeaderElection42 ELECTION round 0: submit vote requests at term 4 for -1: [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d|rpc:10.1.0.17:35727|dataStream:|priority:0, 5e432c75-8719-4a7d-ad09-7985e0971b8b|rpc:10.1.0.17:44011|dataStream:|priority:0, 6c2707a0-87fd-4dba-96bb-b14739c19597|rpc:10.1.0.17:37095|dataStream:|priority:1], old=null
2022-06-20 01:36:33,327 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B: receive requestVote(ELECTION, 6c2707a0-87fd-4dba-96bb-b14739c19597, group-931A667C2C5B, 4, (t:0, i:0))
2022-06-20 01:36:33,327 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(48)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-CANDIDATE: reject ELECTION from 6c2707a0-87fd-4dba-96bb-b14739c19597: already has voted for 5e432c75-8719-4a7d-ad09-7985e0971b8b at current term 4
2022-06-20 01:36:33,328 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B replies to ELECTION vote request: 6c2707a0-87fd-4dba-96bb-b14739c19597<-5e432c75-8719-4a7d-ad09-7985e0971b8b#0:FAIL-t4. Peer's state: 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B:t4, leader=null, voted=5e432c75-8719-4a7d-ad09-7985e0971b8b, raftlog=5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-SegmentedRaftLog:OPENED:c-1, conf=-1: [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d|rpc:10.1.0.17:35727|dataStream:|priority:0, 5e432c75-8719-4a7d-ad09-7985e0971b8b|rpc:10.1.0.17:44011|dataStream:|priority:0, 6c2707a0-87fd-4dba-96bb-b14739c19597|rpc:10.1.0.17:37095|dataStream:|priority:1], old=null
2022-06-20 01:36:33,380 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B: receive requestVote(ELECTION, 5e432c75-8719-4a7d-ad09-7985e0971b8b, group-931A667C2C5B, 4, (t:0, i:0))
2022-06-20 01:36:33,380 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(48)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-FOLLOWER: reject ELECTION from 5e432c75-8719-4a7d-ad09-7985e0971b8b: already has voted for 6c2707a0-87fd-4dba-96bb-b14739c19597 at current term 4
2022-06-20 01:36:33,381 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B replies to ELECTION vote request: 5e432c75-8719-4a7d-ad09-7985e0971b8b<-fd1f8b8e-2a75-4423-a446-fc45b4d61a4d#0:FAIL-t4. Peer's state: fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B:t4, leader=null, voted=6c2707a0-87fd-4dba-96bb-b14739c19597, raftlog=fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-SegmentedRaftLog:OPENED:c-1, conf=-1: [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d|rpc:10.1.0.17:35727|dataStream:|priority:0, 5e432c75-8719-4a7d-ad09-7985e0971b8b|rpc:10.1.0.17:44011|dataStream:|priority:0, 6c2707a0-87fd-4dba-96bb-b14739c19597|rpc:10.1.0.17:37095|dataStream:|priority:1], old=null
2022-06-20 01:36:33,381 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1152)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B: receive requestVote(ELECTION, 5e432c75-8719-4a7d-ad09-7985e0971b8b, group-931A667C2C5B, 4, (t:0, i:0))
2022-06-20 01:36:33,399 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-931A667C2C5B with new leaderId: 6c2707a0-87fd-4dba-96bb-b14739c19597
2022-06-20 01:36:33,400 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B: change Leader from null to 6c2707a0-87fd-4dba-96bb-b14739c19597 at term 4 for appendEntries, leader elected after 20464ms
2022-06-20 01:36:33,413 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderElection41] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B: set configuration 0: [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d|rpc:10.1.0.17:35727|dataStream:|priority:0, 5e432c75-8719-4a7d-ad09-7985e0971b8b|rpc:10.1.0.17:44011|dataStream:|priority:0, 6c2707a0-87fd-4dba-96bb-b14739c19597|rpc:10.1.0.17:37095|dataStream:|priority:1], old=null
2022-06-20 01:36:33,413 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(48)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LEADER: reject ELECTION from 5e432c75-8719-4a7d-ad09-7985e0971b8b: already has voted for 6c2707a0-87fd-4dba-96bb-b14739c19597 at current term 4
2022-06-20 01:36:33,413 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1184)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B replies to ELECTION vote request: 5e432c75-8719-4a7d-ad09-7985e0971b8b<-6c2707a0-87fd-4dba-96bb-b14739c19597#0:FAIL-t4. Peer's state: 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B:t4, leader=6c2707a0-87fd-4dba-96bb-b14739c19597, voted=6c2707a0-87fd-4dba-96bb-b14739c19597, raftlog=6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-SegmentedRaftLog:OPENED:c-1, conf=0: [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d|rpc:10.1.0.17:35727|dataStream:|priority:0, 5e432c75-8719-4a7d-ad09-7985e0971b8b|rpc:10.1.0.17:44011|dataStream:|priority:0, 6c2707a0-87fd-4dba-96bb-b14739c19597|rpc:10.1.0.17:37095|dataStream:|priority:1], old=null
2022-06-20 01:36:33,416 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-LeaderElection42] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-LeaderElection42: ELECTION REJECTED received 1 response(s) and 0 exception(s):
2022-06-20 01:36:33,418 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-06-20 01:36:33,419 [grpc-default-executor-0] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04: nextIndex: updateUnconditionally 41 -> 40
2022-06-20 01:36:33,426 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #3 to datanode 1c5b3100-0df6-4edf-aaf2-8491709a0a2e{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=33141, RATIS=34593, RATIS_ADMIN=34593, RATIS_SERVER=34593, STANDALONE=43715], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-20 01:36:33,426 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #3 to datanode 6f92f58e-935c-4e45-b2b1-2d5bfa669174{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=42433, RATIS=34635, RATIS_ADMIN=34635, RATIS_SERVER=34635, STANDALONE=32799], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-20 01:36:33,426 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #3 to datanode 9ece5a04-4580-4177-bd03-ef9ae8c86b04{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=38363, RATIS=38907, RATIS_ADMIN=38907, RATIS_SERVER=38907, STANDALONE=40597], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-20 01:36:33,426 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #5 to datanode 1c5b3100-0df6-4edf-aaf2-8491709a0a2e{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=33141, RATIS=34593, RATIS_ADMIN=34593, RATIS_SERVER=34593, STANDALONE=43715], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-20 01:36:33,426 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #5 to datanode 6f92f58e-935c-4e45-b2b1-2d5bfa669174{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=42433, RATIS=34635, RATIS_ADMIN=34635, RATIS_SERVER=34635, STANDALONE=32799], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-20 01:36:33,427 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #5 to datanode 9ece5a04-4580-4177-bd03-ef9ae8c86b04{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=38363, RATIS=38907, RATIS_ADMIN=38907, RATIS_SERVER=38907, STANDALONE=40597], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-20 01:36:33,427 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #6 to datanode 6f92f58e-935c-4e45-b2b1-2d5bfa669174{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=42433, RATIS=34635, RATIS_ADMIN=34635, RATIS_SERVER=34635, STANDALONE=32799], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-20 01:36:33,457 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B: set configuration 0: [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d|rpc:10.1.0.17:35727|dataStream:|priority:0, 5e432c75-8719-4a7d-ad09-7985e0971b8b|rpc:10.1.0.17:44011|dataStream:|priority:0, 6c2707a0-87fd-4dba-96bb-b14739c19597|rpc:10.1.0.17:37095|dataStream:|priority:1], old=null
2022-06-20 01:36:33,457 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-20 01:36:33,462 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-2/data/ratis/7b40afe4-7a11-46b3-955b-931a667c2c5b/current/log_inprogress_0
2022-06-20 01:36:33,476 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #6 to datanode 1c5b3100-0df6-4edf-aaf2-8491709a0a2e{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=33141, RATIS=34593, RATIS_ADMIN=34593, RATIS_SERVER=34593, STANDALONE=43715], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-20 01:36:33,476 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1508)) - Sending close container command for container #6 to datanode 9ece5a04-4580-4177-bd03-ef9ae8c86b04{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=38363, RATIS=38907, RATIS_ADMIN=38907, RATIS_SERVER=38907, STANDALONE=40597], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2022-06-20 01:36:33,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 50 milliseconds for processing 6 containers.
2022-06-20 01:36:33,478 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-LeaderElection42] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 5e432c75-8719-4a7d-ad09-7985e0971b8b<-6c2707a0-87fd-4dba-96bb-b14739c19597#0:FAIL-t4
2022-06-20 01:36:33,478 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-LeaderElection42] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-LeaderElection42 ELECTION round 0: result REJECTED
2022-06-20 01:36:33,478 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-LeaderElection42] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
2022-06-20 01:36:33,478 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-LeaderElection42] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b: shutdown 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-LeaderElection42
2022-06-20 01:36:33,478 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-06-20 01:36:33,479 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04: nextIndex: updateUnconditionally 41 -> 40
2022-06-20 01:36:33,480 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-LeaderElection42] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b: start 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-FollowerState
2022-06-20 01:36:33,482 [5e432c75-8719-4a7d-ad09-7985e0971b8b-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(863)) - Leader change notification received for group: group-931A667C2C5B with new leaderId: 6c2707a0-87fd-4dba-96bb-b14739c19597
2022-06-20 01:36:33,482 [5e432c75-8719-4a7d-ad09-7985e0971b8b-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(287)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B: change Leader from null to 6c2707a0-87fd-4dba-96bb-b14739c19597 at term 4 for appendEntries, leader elected after 20605ms
2022-06-20 01:36:33,524 [5e432c75-8719-4a7d-ad09-7985e0971b8b-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(393)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B: set configuration 0: [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d|rpc:10.1.0.17:35727|dataStream:|priority:0, 5e432c75-8719-4a7d-ad09-7985e0971b8b|rpc:10.1.0.17:44011|dataStream:|priority:0, 6c2707a0-87fd-4dba-96bb-b14739c19597|rpc:10.1.0.17:37095|dataStream:|priority:1], old=null
2022-06-20 01:36:33,525 [5e432c75-8719-4a7d-ad09-7985e0971b8b-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(425)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-SegmentedRaftLogWorker: Starting segment from index:0
2022-06-20 01:36:33,530 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(629)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-1/data/ratis/7b40afe4-7a11-46b3-955b-931a667c2c5b/current/log_inprogress_0
2022-06-20 01:36:33,557 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-06-20 01:36:33,558 [grpc-default-executor-3] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04: nextIndex: updateUnconditionally 41 -> 40
2022-06-20 01:36:33,588 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-06-20 01:36:33,589 [grpc-default-executor-3] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04: nextIndex: updateUnconditionally 41 -> 40
2022-06-20 01:36:33,590 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-06-20 01:36:33,590 [grpc-default-executor-3] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04: nextIndex: updateUnconditionally 41 -> 40
2022-06-20 01:36:33,625 [ContainerOp-e614cc2c-3ea4-4885-93f5-c59eb1d378b7-0] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 3 is synced with bcsId 38.
2022-06-20 01:36:33,636 [ContainerOp-e614cc2c-3ea4-4885-93f5-c59eb1d378b7-0] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 3 is synced with bcsId 38.
2022-06-20 01:36:33,646 [ContainerOp-e614cc2c-3ea4-4885-93f5-c59eb1d378b7-0] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(346)) - Container 3 is closed with bcsId 38.
2022-06-20 01:36:33,648 [FixedThreadPoolWithAffinityExecutor-9-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(288)) - Moving container #3 to CLOSED state, datanode 1c5b3100-0df6-4edf-aaf2-8491709a0a2e{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=33141, RATIS=34593, RATIS_ADMIN=34593, RATIS_SERVER=34593, STANDALONE=43715], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
2022-06-20 01:36:33,650 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-06-20 01:36:33,651 [grpc-default-executor-3] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04: nextIndex: updateUnconditionally 41 -> 40
2022-06-20 01:36:33,670 [ContainerOp-e614cc2c-3ea4-4885-93f5-c59eb1d378b7-0] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 3 is synced with bcsId 38.
2022-06-20 01:36:33,670 [ContainerOp-e614cc2c-3ea4-4885-93f5-c59eb1d378b7-0] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 3 is synced with bcsId 38.
2022-06-20 01:36:33,671 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-06-20 01:36:33,672 [grpc-default-executor-3] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04: nextIndex: updateUnconditionally 41 -> 40
2022-06-20 01:36:33,672 [ContainerOp-e614cc2c-3ea4-4885-93f5-c59eb1d378b7-0] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(346)) - Container 3 is closed with bcsId 38.
2022-06-20 01:36:33,673 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-06-20 01:36:33,673 [grpc-default-executor-3] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04: nextIndex: updateUnconditionally 41 -> 40
2022-06-20 01:36:33,677 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-06-20 01:36:33,678 [grpc-default-executor-3] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04: nextIndex: updateUnconditionally 41 -> 40
2022-06-20 01:36:33,684 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(365)) - Attempting to stop container services.
2022-06-20 01:36:33,685 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$7(398)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b: close
2022-06-20 01:36:33,685 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B: shutdown
2022-06-20 01:36:33,685 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-931A667C2C5B,id=5e432c75-8719-4a7d-ad09-7985e0971b8b
2022-06-20 01:36:33,685 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b: shutdown 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-FollowerState
2022-06-20 01:36:33,685 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-StateMachineUpdater: set stopIndex = 0
2022-06-20 01:36:33,685 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-FollowerState was interrupted
2022-06-20 01:36:33,685 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-931A667C2C5B: Taking a snapshot at:(t:4, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-1/data/ratis/7b40afe4-7a11-46b3-955b-931a667c2c5b/sm/snapshot.4_0
2022-06-20 01:36:33,686 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-931A667C2C5B: Finished taking a snapshot at:(t:4, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-1/data/ratis/7b40afe4-7a11-46b3-955b-931a667c2c5b/sm/snapshot.4_0 took: 1 ms
2022-06-20 01:36:33,686 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-StateMachineUpdater: Took a snapshot at index 0
2022-06-20 01:36:33,686 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-06-20 01:36:33,687 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer$Division (ServerState.java:close(429)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B: closes. applyIndex: 0
2022-06-20 01:36:33,687 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-20 01:36:33,687 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-931A667C2C5B-SegmentedRaftLogWorker close()
2022-06-20 01:36:33,692 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F: shutdown
2022-06-20 01:36:33,692 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-CF3E20F3E79F,id=5e432c75-8719-4a7d-ad09-7985e0971b8b
2022-06-20 01:36:33,692 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b: shutdown 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-LeaderStateImpl
2022-06-20 01:36:33,692 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-PendingRequests: sendNotLeaderResponses
2022-06-20 01:36:33,693 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-StateMachineUpdater: set stopIndex = 0
2022-06-20 01:36:33,696 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-CF3E20F3E79F: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-1/data/ratis/27442fc4-f4d7-4206-a0cc-cf3e20f3e79f/sm/snapshot.1_0
2022-06-20 01:36:33,700 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-CF3E20F3E79F: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-1/data/ratis/27442fc4-f4d7-4206-a0cc-cf3e20f3e79f/sm/snapshot.1_0 took: 5 ms
2022-06-20 01:36:33,700 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-StateMachineUpdater: Took a snapshot at index 0
2022-06-20 01:36:33,700 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-06-20 01:36:33,701 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer$Division (ServerState.java:close(429)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F: closes. applyIndex: 0
2022-06-20 01:36:33,701 [5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-20 01:36:33,701 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b@group-CF3E20F3E79F-SegmentedRaftLogWorker close()
2022-06-20 01:36:33,710 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(269)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b: shutdown server with port 44011 now
2022-06-20 01:36:33,717 [grpc-default-executor-3] WARN  server.GrpcClientProtocolService (LogUtils.java:warn(122)) - 1-UnorderedRequestStreamObserver1: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2022-06-20 01:36:33,720 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B->5e432c75-8719-4a7d-ad09-7985e0971b8b-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2022-06-20 01:36:33,720 [grpc-default-executor-0] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(111)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B->5e432c75-8719-4a7d-ad09-7985e0971b8b-GrpcLogAppender: Leader has not got in touch with Follower 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B->5e432c75-8719-4a7d-ad09-7985e0971b8b(c0,m0,n1, attendVote=true, lastRpcSendTime=282, lastRpcResponseTime=161) yet, just keep nextIndex unchanged and retry.
2022-06-20 01:36:33,724 [grpc-default-executor-5] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b: installSnapshot onError, lastRequest: 6c2707a0-87fd-4dba-96bb-b14739c19597->5e432c75-8719-4a7d-ad09-7985e0971b8b#1-t4,previous=(t:0, i:0),leaderCommit=0,initializing? true,entries: size=1, first=(t:4, i:0), CONFIGURATIONENTRY: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2022-06-20 01:36:33,725 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(278)) - 5e432c75-8719-4a7d-ad09-7985e0971b8b: shutdown server with port 44011 successfully
2022-06-20 01:36:33,727 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1750956089@5864ffd9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-5e432c75-8719-4a7d-ad09-7985e0971b8b: Stopped
2022-06-20 01:36:33,757 [ContainerOp-e614cc2c-3ea4-4885-93f5-c59eb1d378b7-1] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 5 is synced with bcsId 30.
2022-06-20 01:36:33,757 [ContainerOp-e614cc2c-3ea4-4885-93f5-c59eb1d378b7-1] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 5 is synced with bcsId 30.
2022-06-20 01:36:33,758 [ContainerOp-e614cc2c-3ea4-4885-93f5-c59eb1d378b7-1] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 5 is synced with bcsId 30.
2022-06-20 01:36:33,759 [ContainerOp-e614cc2c-3ea4-4885-93f5-c59eb1d378b7-1] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 5 is synced with bcsId 30.
2022-06-20 01:36:33,768 [ContainerOp-e614cc2c-3ea4-4885-93f5-c59eb1d378b7-1] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(346)) - Container 5 is closed with bcsId 30.
2022-06-20 01:36:33,769 [FixedThreadPoolWithAffinityExecutor-1-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(288)) - Moving container #5 to CLOSED state, datanode 1c5b3100-0df6-4edf-aaf2-8491709a0a2e{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=33141, RATIS=34593, RATIS_ADMIN=34593, RATIS_SERVER=34593, STANDALONE=43715], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
2022-06-20 01:36:33,770 [ContainerOp-e614cc2c-3ea4-4885-93f5-c59eb1d378b7-1] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(346)) - Container 5 is closed with bcsId 30.
2022-06-20 01:36:33,772 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-06-20 01:36:33,772 [grpc-default-executor-3] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04: nextIndex: updateUnconditionally 41 -> 40
2022-06-20 01:36:33,791 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-06-20 01:36:33,791 [grpc-default-executor-3] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04: nextIndex: updateUnconditionally 41 -> 40
2022-06-20 01:36:33,806 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-06-20 01:36:33,806 [grpc-default-executor-3] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04: nextIndex: updateUnconditionally 41 -> 40
2022-06-20 01:36:33,810 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-06-20 01:36:33,810 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04: nextIndex: updateUnconditionally 41 -> 40
2022-06-20 01:36:33,833 [ContainerOp-e614cc2c-3ea4-4885-93f5-c59eb1d378b7-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 6 is synced with bcsId 34.
2022-06-20 01:36:33,833 [ContainerOp-e614cc2c-3ea4-4885-93f5-c59eb1d378b7-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 6 is synced with bcsId 34.
2022-06-20 01:36:33,835 [ContainerOp-e614cc2c-3ea4-4885-93f5-c59eb1d378b7-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(346)) - Container 6 is closed with bcsId 34.
2022-06-20 01:36:33,836 [FixedThreadPoolWithAffinityExecutor-1-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(288)) - Moving container #6 to CLOSED state, datanode 1c5b3100-0df6-4edf-aaf2-8491709a0a2e{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=33141, RATIS=34593, RATIS_ADMIN=34593, RATIS_SERVER=34593, STANDALONE=43715], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
2022-06-20 01:36:33,905 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-06-20 01:36:33,906 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04: nextIndex: updateUnconditionally 41 -> 40
2022-06-20 01:36:33,917 [ContainerOp-e614cc2c-3ea4-4885-93f5-c59eb1d378b7-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 6 is synced with bcsId 34.
2022-06-20 01:36:33,917 [ContainerOp-e614cc2c-3ea4-4885-93f5-c59eb1d378b7-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(431)) - Container 6 is synced with bcsId 34.
2022-06-20 01:36:33,919 [ContainerOp-e614cc2c-3ea4-4885-93f5-c59eb1d378b7-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(346)) - Container 6 is closed with bcsId 34.
2022-06-20 01:36:33,932 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. 5e432c75-8719-4a7d-ad09-7985e0971b8b{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=40283, RATIS=44011, RATIS_ADMIN=44011, RATIS_SERVER=44011, STANDALONE=34313], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-06-20 01:36:33,932 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=7b40afe4-7a11-46b3-955b-931a667c2c5b close command to datanode 5e432c75-8719-4a7d-ad09-7985e0971b8b
2022-06-20 01:36:33,932 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=7b40afe4-7a11-46b3-955b-931a667c2c5b close command to datanode fd1f8b8e-2a75-4423-a446-fc45b4d61a4d
2022-06-20 01:36:33,933 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=7b40afe4-7a11-46b3-955b-931a667c2c5b close command to datanode 6c2707a0-87fd-4dba-96bb-b14739c19597
2022-06-20 01:36:33,933 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(243)) - Pipeline Pipeline[ Id: 7b40afe4-7a11-46b3-955b-931a667c2c5b, Nodes: 5e432c75-8719-4a7d-ad09-7985e0971b8b{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=40283, RATIS=44011, RATIS_ADMIN=44011, RATIS_SERVER=44011, STANDALONE=34313], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}fd1f8b8e-2a75-4423-a446-fc45b4d61a4d{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=46197, RATIS=35727, RATIS_ADMIN=35727, RATIS_SERVER=35727, STANDALONE=33859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}6c2707a0-87fd-4dba-96bb-b14739c19597{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=32853, RATIS=37095, RATIS_ADMIN=37095, RATIS_SERVER=37095, STANDALONE=33553], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:6c2707a0-87fd-4dba-96bb-b14739c19597, CreationTimestamp2022-06-20T01:36:11.376Z[Etc/UTC]] removed.
2022-06-20 01:36:33,933 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=27442fc4-f4d7-4206-a0cc-cf3e20f3e79f close command to datanode 5e432c75-8719-4a7d-ad09-7985e0971b8b
2022-06-20 01:36:33,933 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(243)) - Pipeline Pipeline[ Id: 27442fc4-f4d7-4206-a0cc-cf3e20f3e79f, Nodes: 5e432c75-8719-4a7d-ad09-7985e0971b8b{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=40283, RATIS=44011, RATIS_ADMIN=44011, RATIS_SERVER=44011, STANDALONE=34313], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:5e432c75-8719-4a7d-ad09-7985e0971b8b, CreationTimestamp2022-06-20T01:36:11.375Z[Etc/UTC]] removed.
2022-06-20 01:36:33,934 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(137)) - Removed a node: /default-rack/5e432c75-8719-4a7d-ad09-7985e0971b8b
2022-06-20 01:36:34,291 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=7b40afe4-7a11-46b3-955b-931a667c2c5b is not found
2022-06-20 01:36:34,433 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. 9ece5a04-4580-4177-bd03-ef9ae8c86b04{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=38363, RATIS=38907, RATIS_ADMIN=38907, RATIS_SERVER=38907, STANDALONE=40597], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-06-20 01:36:34,433 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=f077a8bb-16d7-4a00-94d3-0a153277b499 close command to datanode 9ece5a04-4580-4177-bd03-ef9ae8c86b04
2022-06-20 01:36:34,433 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(243)) - Pipeline Pipeline[ Id: f077a8bb-16d7-4a00-94d3-0a153277b499, Nodes: 9ece5a04-4580-4177-bd03-ef9ae8c86b04{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=38363, RATIS=38907, RATIS_ADMIN=38907, RATIS_SERVER=38907, STANDALONE=40597], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:9ece5a04-4580-4177-bd03-ef9ae8c86b04, CreationTimestamp2022-06-20T01:35:33.420Z[Etc/UTC]] removed.
2022-06-20 01:36:34,434 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=e614cc2c-3ea4-4885-93f5-c59eb1d378b7 close command to datanode 6f92f58e-935c-4e45-b2b1-2d5bfa669174
2022-06-20 01:36:34,434 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=e614cc2c-3ea4-4885-93f5-c59eb1d378b7 close command to datanode 1c5b3100-0df6-4edf-aaf2-8491709a0a2e
2022-06-20 01:36:34,434 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=e614cc2c-3ea4-4885-93f5-c59eb1d378b7 close command to datanode 9ece5a04-4580-4177-bd03-ef9ae8c86b04
2022-06-20 01:36:34,434 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(243)) - Pipeline Pipeline[ Id: e614cc2c-3ea4-4885-93f5-c59eb1d378b7, Nodes: 6f92f58e-935c-4e45-b2b1-2d5bfa669174{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=42433, RATIS=34635, RATIS_ADMIN=34635, RATIS_SERVER=34635, STANDALONE=32799], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1c5b3100-0df6-4edf-aaf2-8491709a0a2e{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=33141, RATIS=34593, RATIS_ADMIN=34593, RATIS_SERVER=34593, STANDALONE=43715], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9ece5a04-4580-4177-bd03-ef9ae8c86b04{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=38363, RATIS=38907, RATIS_ADMIN=38907, RATIS_SERVER=38907, STANDALONE=40597], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:1c5b3100-0df6-4edf-aaf2-8491709a0a2e, CreationTimestamp2022-06-20T01:35:34.122Z[Etc/UTC]] removed.
2022-06-20 01:36:34,434 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(137)) - Removed a node: /default-rack/9ece5a04-4580-4177-bd03-ef9ae8c86b04
2022-06-20 01:36:34,477 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1192)) - Container #3 is under replicated. Expected replica count is 3, but found 2.
2022-06-20 01:36:34,477 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1555)) - Sending replicate container command for container #3 to datanode 6c2707a0-87fd-4dba-96bb-b14739c19597{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=32853, RATIS=37095, RATIS_ADMIN=37095, RATIS_SERVER=37095, STANDALONE=33553], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [1c5b3100-0df6-4edf-aaf2-8491709a0a2e{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=33141, RATIS=34593, RATIS_ADMIN=34593, RATIS_SERVER=34593, STANDALONE=43715], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 6f92f58e-935c-4e45-b2b1-2d5bfa669174{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=42433, RATIS=34635, RATIS_ADMIN=34635, RATIS_SERVER=34635, STANDALONE=32799], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-20 01:36:34,477 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1192)) - Container #5 is under replicated. Expected replica count is 3, but found 2.
2022-06-20 01:36:34,477 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1555)) - Sending replicate container command for container #5 to datanode fd1f8b8e-2a75-4423-a446-fc45b4d61a4d{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=46197, RATIS=35727, RATIS_ADMIN=35727, RATIS_SERVER=35727, STANDALONE=33859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [1c5b3100-0df6-4edf-aaf2-8491709a0a2e{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=33141, RATIS=34593, RATIS_ADMIN=34593, RATIS_SERVER=34593, STANDALONE=43715], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 6f92f58e-935c-4e45-b2b1-2d5bfa669174{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=42433, RATIS=34635, RATIS_ADMIN=34635, RATIS_SERVER=34635, STANDALONE=32799], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-20 01:36:34,477 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1192)) - Container #6 is under replicated. Expected replica count is 3, but found 2.
2022-06-20 01:36:34,477 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1555)) - Sending replicate container command for container #6 to datanode fd1f8b8e-2a75-4423-a446-fc45b4d61a4d{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=46197, RATIS=35727, RATIS_ADMIN=35727, RATIS_SERVER=35727, STANDALONE=33859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [6f92f58e-935c-4e45-b2b1-2d5bfa669174{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=42433, RATIS=34635, RATIS_ADMIN=34635, RATIS_SERVER=34635, STANDALONE=32799], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 1c5b3100-0df6-4edf-aaf2-8491709a0a2e{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=33141, RATIS=34593, RATIS_ADMIN=34593, RATIS_SERVER=34593, STANDALONE=43715], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-20 01:36:34,477 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-06-20 01:36:34,838 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=e614cc2c-3ea4-4885-93f5-c59eb1d378b7 is not found
2022-06-20 01:36:34,921 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=e614cc2c-3ea4-4885-93f5-c59eb1d378b7 is not found
2022-06-20 01:36:34,961 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d: remove  FOLLOWER fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B:t4, leader=6c2707a0-87fd-4dba-96bb-b14739c19597, voted=6c2707a0-87fd-4dba-96bb-b14739c19597, raftlog=fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-SegmentedRaftLog:OPENED:c-1, conf=0: [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d|rpc:10.1.0.17:35727|dataStream:|priority:0, 5e432c75-8719-4a7d-ad09-7985e0971b8b|rpc:10.1.0.17:44011|dataStream:|priority:0, 6c2707a0-87fd-4dba-96bb-b14739c19597|rpc:10.1.0.17:37095|dataStream:|priority:1], old=null RUNNING
2022-06-20 01:36:34,961 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B: shutdown
2022-06-20 01:36:34,961 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-931A667C2C5B,id=fd1f8b8e-2a75-4423-a446-fc45b4d61a4d
2022-06-20 01:36:34,961 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d: shutdown fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-FollowerState
2022-06-20 01:36:34,961 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-StateMachineUpdater: set stopIndex = -1
2022-06-20 01:36:34,962 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-FollowerState was interrupted
2022-06-20 01:36:34,962 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(429)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B: closes. applyIndex: -1
2022-06-20 01:36:34,963 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-20 01:36:34,963 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B-SegmentedRaftLogWorker close()
2022-06-20 01:36:34,963 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(113)) - Reported pipeline PipelineID=7b40afe4-7a11-46b3-955b-931a667c2c5b is not found
2022-06-20 01:36:34,965 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(404)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-931A667C2C5B: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-2/data/ratis/7b40afe4-7a11-46b3-955b-931a667c2c5b
2022-06-20 01:36:34,965 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=7b40afe4-7a11-46b3-955b-931a667c2c5b command on datanode fd1f8b8e-2a75-4423-a446-fc45b4d61a4d.
2022-06-20 01:36:34,980 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 5 from [1c5b3100-0df6-4edf-aaf2-8491709a0a2e{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=33141, RATIS=34593, RATIS_ADMIN=34593, RATIS_SERVER=34593, STANDALONE=43715], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 6f92f58e-935c-4e45-b2b1-2d5bfa669174{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=42433, RATIS=34635, RATIS_ADMIN=34635, RATIS_SERVER=34635, STANDALONE=32799], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-20 01:36:34,987 [grpc-default-executor-5] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(52)) - Streaming container data (5) to other datanode
2022-06-20 01:36:34,988 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 6 from [6f92f58e-935c-4e45-b2b1-2d5bfa669174{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=42433, RATIS=34635, RATIS_ADMIN=34635, RATIS_SERVER=34635, STANDALONE=32799], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 1c5b3100-0df6-4edf-aaf2-8491709a0a2e{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=33141, RATIS=34593, RATIS_ADMIN=34593, RATIS_SERVER=34593, STANDALONE=43715], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-20 01:36:35,034 [grpc-default-executor-3] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(52)) - Streaming container data (6) to other datanode
2022-06-20 01:36:35,048 [grpc-default-executor-5] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 18654 bytes for container 5
2022-06-20 01:36:35,067 [grpc-default-executor-0] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(197)) - Container 5 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-2/data/replication/work/container-5.tar.gz
2022-06-20 01:36:35,100 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 5 is downloaded with size 18654, starting to import.
2022-06-20 01:36:35,127 [grpc-default-executor-3] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 20832 bytes for container 6
2022-06-20 01:36:35,132 [grpc-default-executor-0] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(197)) - Container 6 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-2/data/replication/work/container-6.tar.gz
2022-06-20 01:36:35,156 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-06-20 01:36:35,161 [grpc-default-executor-3] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04: nextIndex: updateUnconditionally 41 -> 40
2022-06-20 01:36:35,163 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 6 is downloaded with size 20832, starting to import.
2022-06-20 01:36:35,166 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - 6c2707a0-87fd-4dba-96bb-b14739c19597: remove    LEADER 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B:t4, leader=6c2707a0-87fd-4dba-96bb-b14739c19597, voted=6c2707a0-87fd-4dba-96bb-b14739c19597, raftlog=6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-SegmentedRaftLog:OPENED:c0, conf=0: [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d|rpc:10.1.0.17:35727|dataStream:|priority:0, 5e432c75-8719-4a7d-ad09-7985e0971b8b|rpc:10.1.0.17:44011|dataStream:|priority:0, 6c2707a0-87fd-4dba-96bb-b14739c19597|rpc:10.1.0.17:37095|dataStream:|priority:1], old=null RUNNING
2022-06-20 01:36:35,166 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B: shutdown
2022-06-20 01:36:35,166 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-931A667C2C5B,id=6c2707a0-87fd-4dba-96bb-b14739c19597
2022-06-20 01:36:35,166 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 6c2707a0-87fd-4dba-96bb-b14739c19597: shutdown 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-LeaderStateImpl
2022-06-20 01:36:35,166 [Command processor thread] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-PendingRequests: sendNotLeaderResponses
2022-06-20 01:36:35,167 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-StateMachineUpdater: set stopIndex = 0
2022-06-20 01:36:35,167 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-931A667C2C5B: Taking a snapshot at:(t:4, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-0/data/ratis/7b40afe4-7a11-46b3-955b-931a667c2c5b/sm/snapshot.4_0
2022-06-20 01:36:35,167 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B->fd1f8b8e-2a75-4423-a446-fc45b4d61a4d-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(171)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B->fd1f8b8e-2a75-4423-a446-fc45b4d61a4d-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2022-06-20 01:36:35,168 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(140)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d: Completed APPEND_ENTRIES, lastRequest: 6c2707a0-87fd-4dba-96bb-b14739c19597->fd1f8b8e-2a75-4423-a446-fc45b4d61a4d#1-t4,previous=(t:0, i:0),leaderCommit=-1,initializing? true,entries: size=1, first=(t:4, i:0), CONFIGURATIONENTRY
2022-06-20 01:36:35,168 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(339)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B->fd1f8b8e-2a75-4423-a446-fc45b4d61a4d-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2022-06-20 01:36:35,168 [grpc-default-executor-0] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B->fd1f8b8e-2a75-4423-a446-fc45b4d61a4d: nextIndex: updateUnconditionally 1 -> 0
2022-06-20 01:36:35,169 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-931A667C2C5B: Finished taking a snapshot at:(t:4, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-0/data/ratis/7b40afe4-7a11-46b3-955b-931a667c2c5b/sm/snapshot.4_0 took: 1 ms
2022-06-20 01:36:35,169 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-StateMachineUpdater: Took a snapshot at index 0
2022-06-20 01:36:35,169 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-06-20 01:36:35,169 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(429)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B: closes. applyIndex: 0
2022-06-20 01:36:35,169 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-20 01:36:35,170 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-SegmentedRaftLogWorker close()
2022-06-20 01:36:35,174 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(404)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-0/data/ratis/7b40afe4-7a11-46b3-955b-931a667c2c5b
2022-06-20 01:36:35,174 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=7b40afe4-7a11-46b3-955b-931a667c2c5b command on datanode 6c2707a0-87fd-4dba-96bb-b14739c19597.
2022-06-20 01:36:35,176 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 5 is replicated successfully
2022-06-20 01:36:35,176 [ContainerReplicationThread-0] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(176)) - Container 5 is replicated.
2022-06-20 01:36:35,184 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B->5e432c75-8719-4a7d-ad09-7985e0971b8b-GrpcLogAppender-LogAppenderDaemon] ERROR leader.LogAppenderDaemon (LogAppenderDaemon.java:run(86)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B->5e432c75-8719-4a7d-ad09-7985e0971b8b-GrpcLogAppender-LogAppenderDaemon failed
java.lang.IllegalArgumentException: 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-SegmentedRaftLog is expected to be opened but it is CLOSED
	at org.apache.ratis.util.OpenCloseState.assertOpen(OpenCloseState.java:63)
	at org.apache.ratis.server.raftlog.RaftLogBase.checkLogState(RaftLogBase.java:109)
	at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.getLastEntryTermIndex(SegmentedRaftLog.java:340)
	at org.apache.ratis.server.raftlog.RaftLog.getNextIndex(RaftLog.java:83)
	at org.apache.ratis.server.leader.LogAppenderBase.newAppendEntriesRequest(LogAppenderBase.java:146)
	at org.apache.ratis.grpc.server.GrpcLogAppender.appendLog(GrpcLogAppender.java:206)
	at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
	at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:77)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.util.OpenCloseState$CloseTrace: Close 6c2707a0-87fd-4dba-96bb-b14739c19597@group-931A667C2C5B-SegmentedRaftLog
	at org.apache.ratis.util.OpenCloseState.lambda$close$1(OpenCloseState.java:109)
	at java.util.concurrent.atomic.AtomicReference.getAndUpdate(AtomicReference.java:160)
	at org.apache.ratis.util.OpenCloseState.close(OpenCloseState.java:109)
	at org.apache.ratis.server.raftlog.RaftLogBase.close(RaftLogBase.java:358)
	at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLog.close(SegmentedRaftLog.java:506)
	at org.apache.ratis.server.impl.ServerState.close(ServerState.java:431)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$close$4(RaftServerImpl.java:456)
	at org.apache.ratis.util.LifeCycle.lambda$checkStateAndClose$4(LifeCycle.java:299)
	at org.apache.ratis.util.LifeCycle.checkStateAndClose(LifeCycle.java:319)
	at org.apache.ratis.util.LifeCycle.checkStateAndClose(LifeCycle.java:297)
	at org.apache.ratis.server.impl.RaftServerImpl.close(RaftServerImpl.java:433)
	at org.apache.ratis.server.impl.RaftServerImpl.groupRemove(RaftServerImpl.java:398)
	at org.apache.ratis.server.impl.RaftServerProxy.lambda$groupRemoveAsync$13(RaftServerProxy.java:515)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:616)
	at java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:628)
	at java.util.concurrent.CompletableFuture.thenApply(CompletableFuture.java:1996)
	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:514)
	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:468)
	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:448)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:781)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
	... 1 more
2022-06-20 01:36:35,245 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 6 is replicated successfully
2022-06-20 01:36:35,246 [ContainerReplicationThread-1] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(176)) - Container 6 is replicated.
2022-06-20 01:36:35,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-06-20 01:36:35,512 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - 6f92f58e-935c-4e45-b2b1-2d5bfa669174: remove  FOLLOWER 6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-C59EB1D378B7:t4, leader=1c5b3100-0df6-4edf-aaf2-8491709a0a2e, voted=1c5b3100-0df6-4edf-aaf2-8491709a0a2e, raftlog=6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-C59EB1D378B7-SegmentedRaftLog:OPENED:c45, conf=0: [6f92f58e-935c-4e45-b2b1-2d5bfa669174|rpc:10.1.0.17:34635|dataStream:|priority:0, 1c5b3100-0df6-4edf-aaf2-8491709a0a2e|rpc:10.1.0.17:34593|dataStream:|priority:1, 9ece5a04-4580-4177-bd03-ef9ae8c86b04|rpc:10.1.0.17:38907|dataStream:|priority:0], old=null RUNNING
2022-06-20 01:36:35,512 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - 6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-C59EB1D378B7: shutdown
2022-06-20 01:36:35,513 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C59EB1D378B7,id=6f92f58e-935c-4e45-b2b1-2d5bfa669174
2022-06-20 01:36:35,513 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 6f92f58e-935c-4e45-b2b1-2d5bfa669174: shutdown 6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-C59EB1D378B7-FollowerState
2022-06-20 01:36:35,513 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-C59EB1D378B7-StateMachineUpdater: set stopIndex = 45
2022-06-20 01:36:35,513 [6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-C59EB1D378B7-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-C59EB1D378B7-FollowerState was interrupted
2022-06-20 01:36:35,513 [6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-C59EB1D378B7-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-C59EB1D378B7: Taking a snapshot at:(t:4, i:45) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-4/data/ratis/e614cc2c-3ea4-4885-93f5-c59eb1d378b7/sm/snapshot.4_45
2022-06-20 01:36:35,516 [6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-C59EB1D378B7-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-C59EB1D378B7: Finished taking a snapshot at:(t:4, i:45) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-4/data/ratis/e614cc2c-3ea4-4885-93f5-c59eb1d378b7/sm/snapshot.4_45 took: 3 ms
2022-06-20 01:36:35,517 [6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-C59EB1D378B7-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-C59EB1D378B7-StateMachineUpdater: Took a snapshot at index 45
2022-06-20 01:36:35,517 [6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-C59EB1D378B7-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-C59EB1D378B7-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 45
2022-06-20 01:36:35,518 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(429)) - 6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-C59EB1D378B7: closes. applyIndex: 45
2022-06-20 01:36:35,518 [6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-C59EB1D378B7-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - 6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-C59EB1D378B7-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-20 01:36:35,518 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - 6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-C59EB1D378B7-SegmentedRaftLogWorker close()
2022-06-20 01:36:35,520 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(404)) - 6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-C59EB1D378B7: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-4/data/ratis/e614cc2c-3ea4-4885-93f5-c59eb1d378b7
2022-06-20 01:36:35,520 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=e614cc2c-3ea4-4885-93f5-c59eb1d378b7 command on datanode 6f92f58e-935c-4e45-b2b1-2d5bfa669174.
2022-06-20 01:36:35,658 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(580)) - Ozone container server stopped.
2022-06-20 01:36:35,696 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@60fe708{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-20 01:36:35,697 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@3da4456d{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-06-20 01:36:35,697 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-06-20 01:36:35,697 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@3ab709fc{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-06-20 01:36:35,697 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@29a5cd7d{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-06-20 01:36:35,773 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-06-20 01:36:36,308 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 3 from [1c5b3100-0df6-4edf-aaf2-8491709a0a2e{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=33141, RATIS=34593, RATIS_ADMIN=34593, RATIS_SERVER=34593, STANDALONE=43715], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 6f92f58e-935c-4e45-b2b1-2d5bfa669174{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=42433, RATIS=34635, RATIS_ADMIN=34635, RATIS_SERVER=34635, STANDALONE=32799], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-20 01:36:36,328 [grpc-default-executor-0] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(52)) - Streaming container data (3) to other datanode
2022-06-20 01:36:36,407 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-06-20 01:36:36,407 [grpc-default-executor-3] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04: nextIndex: updateUnconditionally 41 -> 40
2022-06-20 01:36:36,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-06-20 01:36:36,479 [grpc-default-executor-0] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 26204 bytes for container 3
2022-06-20 01:36:36,480 [grpc-default-executor-3] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(197)) - Container 3 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-0/data/replication/work/container-3.tar.gz
2022-06-20 01:36:36,482 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 3 is downloaded with size 26204, starting to import.
2022-06-20 01:36:36,582 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 3 is replicated successfully
2022-06-20 01:36:36,582 [ContainerReplicationThread-0] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(176)) - Container 3 is replicated.
2022-06-20 01:36:37,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-06-20 01:36:37,658 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-06-20 01:36:37,658 [grpc-default-executor-3] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04: nextIndex: updateUnconditionally 41 -> 40
2022-06-20 01:36:37,840 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode 1c5b3100-0df6-4edf-aaf2-8491709a0a2e{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=33141, RATIS=34593, RATIS_ADMIN=34593, RATIS_SERVER=34593, STANDALONE=43715], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=aa4d1550-2b47-4c74-8e32-ed656ed968f5]
2022-06-20 01:36:37,841 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(430)) - Pipeline Pipeline[ Id: aa4d1550-2b47-4c74-8e32-ed656ed968f5, Nodes: 1c5b3100-0df6-4edf-aaf2-8491709a0a2e{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=33141, RATIS=34593, RATIS_ADMIN=34593, RATIS_SERVER=34593, STANDALONE=43715], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:1c5b3100-0df6-4edf-aaf2-8491709a0a2e, CreationTimestamp2022-06-20T01:35:34.120Z[Etc/UTC]] moved to CLOSED state
2022-06-20 01:36:38,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-06-20 01:36:38,776 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(580)) - Ozone container server stopped.
2022-06-20 01:36:38,800 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@1c665770{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-20 01:36:38,819 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@2fc32411{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-06-20 01:36:38,820 [ForkJoinPool.commonPool-worker-0] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-06-20 01:36:38,820 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@43aeadc3{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-06-20 01:36:38,820 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@53e56daf{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-06-20 01:36:38,908 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2022-06-20 01:36:38,909 [grpc-default-executor-3] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04: nextIndex: updateUnconditionally 41 -> 40
2022-06-20 01:36:39,008 [1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7-LeaderStateImpl] WARN  server.RaftServer$Division (LeaderStateImpl.java:checkLeadership(1018)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7-LeaderStateImpl: Lost leadership on term: 4. Election timeout: 5200ms. In charge for: 42129ms. Conf: 0: [6f92f58e-935c-4e45-b2b1-2d5bfa669174|rpc:10.1.0.17:34635|dataStream:|priority:0, 1c5b3100-0df6-4edf-aaf2-8491709a0a2e|rpc:10.1.0.17:34593|dataStream:|priority:1, 9ece5a04-4580-4177-bd03-ef9ae8c86b04|rpc:10.1.0.17:38907|dataStream:|priority:0], old=null
2022-06-20 01:36:39,009 [1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7-LeaderStateImpl] WARN  server.RaftServer$Division (LeaderStateImpl.java:lambda$checkLeadership$17(1022)) - Follower 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->6f92f58e-935c-4e45-b2b1-2d5bfa669174(c45,m46,n47, attendVote=true, lastRpcSendTime=199, lastRpcResponseTime=5203)
2022-06-20 01:36:39,009 [1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7-LeaderStateImpl] WARN  server.RaftServer$Division (LeaderStateImpl.java:lambda$checkLeadership$17(1022)) - Follower 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04(c40,m40,n40, attendVote=true, lastRpcSendTime=101, lastRpcResponseTime=8856)
2022-06-20 01:36:39,009 [1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7-LeaderStateImpl] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(299)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7: changes role from    LEADER to FOLLOWER at term 4 for StepDownReason:LOST_MAJORITY_HEARTBEATS
2022-06-20 01:36:39,009 [1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7-LeaderStateImpl] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e: shutdown 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7-LeaderStateImpl
2022-06-20 01:36:39,010 [1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(171)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->9ece5a04-4580-4177-bd03-ef9ae8c86b04-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2022-06-20 01:36:39,010 [1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->6f92f58e-935c-4e45-b2b1-2d5bfa669174-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(171)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->6f92f58e-935c-4e45-b2b1-2d5bfa669174-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2022-06-20 01:36:39,010 [1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7-LeaderStateImpl] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7-PendingRequests: sendNotLeaderResponses
2022-06-20 01:36:39,012 [1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7-LeaderStateImpl] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e: start 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7-FollowerState
2022-06-20 01:36:39,033 [grpc-default-executor-3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(140)) - 6f92f58e-935c-4e45-b2b1-2d5bfa669174: Completed APPEND_ENTRIES, lastRequest: 1c5b3100-0df6-4edf-aaf2-8491709a0a2e->6f92f58e-935c-4e45-b2b1-2d5bfa669174#504-t4,previous=(t:4, i:45),leaderCommit=45,initializing? true,entries: size=1, first=(t:4, i:46), METADATAENTRY(c:45)
2022-06-20 01:36:39,033 [grpc-default-executor-5] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(339)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->6f92f58e-935c-4e45-b2b1-2d5bfa669174-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2022-06-20 01:36:39,033 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7->6f92f58e-935c-4e45-b2b1-2d5bfa669174: nextIndex: updateUnconditionally 47 -> 46
2022-06-20 01:36:39,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-06-20 01:36:40,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-06-20 01:36:40,716 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(365)) - Attempting to stop container services.
2022-06-20 01:36:40,736 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$7(398)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e: close
2022-06-20 01:36:40,737 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-ED656ED968F5: shutdown
2022-06-20 01:36:40,737 [Mini-Cluster-Provider-Reap] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-ED656ED968F5,id=1c5b3100-0df6-4edf-aaf2-8491709a0a2e
2022-06-20 01:36:40,737 [Mini-Cluster-Provider-Reap] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e: shutdown 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-ED656ED968F5-LeaderStateImpl
2022-06-20 01:36:40,737 [Mini-Cluster-Provider-Reap] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-ED656ED968F5-PendingRequests: sendNotLeaderResponses
2022-06-20 01:36:40,738 [Mini-Cluster-Provider-Reap] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-ED656ED968F5-StateMachineUpdater: set stopIndex = 0
2022-06-20 01:36:40,738 [1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-ED656ED968F5-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-ED656ED968F5: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-5/data/ratis/aa4d1550-2b47-4c74-8e32-ed656ed968f5/sm/snapshot.1_0
2022-06-20 01:36:40,741 [1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-ED656ED968F5-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-ED656ED968F5: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-5/data/ratis/aa4d1550-2b47-4c74-8e32-ed656ed968f5/sm/snapshot.1_0 took: 4 ms
2022-06-20 01:36:40,742 [1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-ED656ED968F5-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-ED656ED968F5-StateMachineUpdater: Took a snapshot at index 0
2022-06-20 01:36:40,742 [1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-ED656ED968F5-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-ED656ED968F5-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-06-20 01:36:40,742 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (ServerState.java:close(429)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-ED656ED968F5: closes. applyIndex: 0
2022-06-20 01:36:40,742 [1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-ED656ED968F5-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-ED656ED968F5-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-20 01:36:40,743 [Mini-Cluster-Provider-Reap] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-ED656ED968F5-SegmentedRaftLogWorker close()
2022-06-20 01:36:40,743 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7: shutdown
2022-06-20 01:36:40,743 [Mini-Cluster-Provider-Reap] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C59EB1D378B7,id=1c5b3100-0df6-4edf-aaf2-8491709a0a2e
2022-06-20 01:36:40,743 [Mini-Cluster-Provider-Reap] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e: shutdown 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7-FollowerState
2022-06-20 01:36:40,743 [Mini-Cluster-Provider-Reap] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7-StateMachineUpdater: set stopIndex = 46
2022-06-20 01:36:40,743 [1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7-FollowerState was interrupted
2022-06-20 01:36:40,743 [1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-C59EB1D378B7: Taking a snapshot at:(t:4, i:46) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-5/data/ratis/e614cc2c-3ea4-4885-93f5-c59eb1d378b7/sm/snapshot.4_46
2022-06-20 01:36:40,745 [1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-C59EB1D378B7: Finished taking a snapshot at:(t:4, i:46) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-5/data/ratis/e614cc2c-3ea4-4885-93f5-c59eb1d378b7/sm/snapshot.4_46 took: 2 ms
2022-06-20 01:36:40,745 [1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7-StateMachineUpdater: Took a snapshot at index 46
2022-06-20 01:36:40,745 [1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 46
2022-06-20 01:36:40,746 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (ServerState.java:close(429)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7: closes. applyIndex: 46
2022-06-20 01:36:40,749 [1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-20 01:36:40,749 [Mini-Cluster-Provider-Reap] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e@group-C59EB1D378B7-SegmentedRaftLogWorker close()
2022-06-20 01:36:40,751 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(269)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e: shutdown server with port 34593 now
2022-06-20 01:36:40,764 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(278)) - 1c5b3100-0df6-4edf-aaf2-8491709a0a2e: shutdown server with port 34593 successfully
2022-06-20 01:36:40,780 [grpc-default-executor-3] WARN  server.GrpcClientProtocolService (LogUtils.java:warn(122)) - 1-UnorderedRequestStreamObserver1: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2022-06-20 01:36:40,788 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1750956089@712efce7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-1c5b3100-0df6-4edf-aaf2-8491709a0a2e: Stopped
2022-06-20 01:36:40,849 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. 1c5b3100-0df6-4edf-aaf2-8491709a0a2e{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=33141, RATIS=34593, RATIS_ADMIN=34593, RATIS_SERVER=34593, STANDALONE=43715], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-06-20 01:36:40,850 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=aa4d1550-2b47-4c74-8e32-ed656ed968f5 close command to datanode 1c5b3100-0df6-4edf-aaf2-8491709a0a2e
2022-06-20 01:36:40,850 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(243)) - Pipeline Pipeline[ Id: aa4d1550-2b47-4c74-8e32-ed656ed968f5, Nodes: 1c5b3100-0df6-4edf-aaf2-8491709a0a2e{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=33141, RATIS=34593, RATIS_ADMIN=34593, RATIS_SERVER=34593, STANDALONE=43715], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:1c5b3100-0df6-4edf-aaf2-8491709a0a2e, CreationTimestamp2022-06-20T01:35:34.120Z[Etc/UTC]] removed.
2022-06-20 01:36:40,850 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(137)) - Removed a node: /default-rack/1c5b3100-0df6-4edf-aaf2-8491709a0a2e
2022-06-20 01:36:41,250 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode fd1f8b8e-2a75-4423-a446-fc45b4d61a4d{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=46197, RATIS=35727, RATIS_ADMIN=35727, RATIS_SERVER=35727, STANDALONE=33859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=afc4b00a-4ea5-41e3-a374-35d4bff3126d]
2022-06-20 01:36:41,251 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(430)) - Pipeline Pipeline[ Id: afc4b00a-4ea5-41e3-a374-35d4bff3126d, Nodes: fd1f8b8e-2a75-4423-a446-fc45b4d61a4d{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=46197, RATIS=35727, RATIS_ADMIN=35727, RATIS_SERVER=35727, STANDALONE=33859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:fd1f8b8e-2a75-4423-a446-fc45b4d61a4d, CreationTimestamp2022-06-20T01:36:11.377Z[Etc/UTC]] moved to CLOSED state
2022-06-20 01:36:41,481 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1192)) - Container #1 is under replicated. Expected replica count is 3, but found 2.
2022-06-20 01:36:41,481 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1555)) - Sending replicate container command for container #1 to datanode 6f92f58e-935c-4e45-b2b1-2d5bfa669174{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=42433, RATIS=34635, RATIS_ADMIN=34635, RATIS_SERVER=34635, STANDALONE=32799], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [6c2707a0-87fd-4dba-96bb-b14739c19597{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=32853, RATIS=37095, RATIS_ADMIN=37095, RATIS_SERVER=37095, STANDALONE=33553], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-20 01:36:41,482 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1192)) - Container #2 is under replicated. Expected replica count is 3, but found 2.
2022-06-20 01:36:41,482 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1555)) - Sending replicate container command for container #2 to datanode 6f92f58e-935c-4e45-b2b1-2d5bfa669174{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=42433, RATIS=34635, RATIS_ADMIN=34635, RATIS_SERVER=34635, STANDALONE=32799], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [6c2707a0-87fd-4dba-96bb-b14739c19597{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=32853, RATIS=37095, RATIS_ADMIN=37095, RATIS_SERVER=37095, STANDALONE=33553], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-20 01:36:41,482 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:41,482 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:41,482 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1192)) - Container #4 is under replicated. Expected replica count is 3, but found 2.
2022-06-20 01:36:41,482 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1555)) - Sending replicate container command for container #4 to datanode 6f92f58e-935c-4e45-b2b1-2d5bfa669174{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=42433, RATIS=34635, RATIS_ADMIN=34635, RATIS_SERVER=34635, STANDALONE=32799], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [6c2707a0-87fd-4dba-96bb-b14739c19597{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=32853, RATIS=37095, RATIS_ADMIN=37095, RATIS_SERVER=37095, STANDALONE=33553], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-20 01:36:41,482 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1192)) - Container #5 is under replicated. Expected replica count is 3, but found 2.
2022-06-20 01:36:41,482 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1555)) - Sending replicate container command for container #5 to datanode 6c2707a0-87fd-4dba-96bb-b14739c19597{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=32853, RATIS=37095, RATIS_ADMIN=37095, RATIS_SERVER=37095, STANDALONE=33553], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [6f92f58e-935c-4e45-b2b1-2d5bfa669174{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=42433, RATIS=34635, RATIS_ADMIN=34635, RATIS_SERVER=34635, STANDALONE=32799], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-20 01:36:41,482 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1192)) - Container #6 is under replicated. Expected replica count is 3, but found 2.
2022-06-20 01:36:41,482 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1555)) - Sending replicate container command for container #6 to datanode 6c2707a0-87fd-4dba-96bb-b14739c19597{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=32853, RATIS=37095, RATIS_ADMIN=37095, RATIS_SERVER=37095, STANDALONE=33553], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [6f92f58e-935c-4e45-b2b1-2d5bfa669174{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=42433, RATIS=34635, RATIS_ADMIN=34635, RATIS_SERVER=34635, STANDALONE=32799], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-20 01:36:41,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-06-20 01:36:42,483 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:42,483 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:42,484 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-06-20 01:36:42,828 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-06-20 01:36:43,484 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:43,485 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:43,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-06-20 01:36:43,592 [ContainerReplicationThread-2] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 6 from [6f92f58e-935c-4e45-b2b1-2d5bfa669174{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=42433, RATIS=34635, RATIS_ADMIN=34635, RATIS_SERVER=34635, STANDALONE=32799], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-20 01:36:43,596 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 5 from [6f92f58e-935c-4e45-b2b1-2d5bfa669174{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=42433, RATIS=34635, RATIS_ADMIN=34635, RATIS_SERVER=34635, STANDALONE=32799], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-20 01:36:43,650 [grpc-default-executor-3] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(52)) - Streaming container data (6) to other datanode
2022-06-20 01:36:43,650 [grpc-default-executor-0] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(52)) - Streaming container data (5) to other datanode
2022-06-20 01:36:43,802 [grpc-default-executor-0] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 26058 bytes for container 5
2022-06-20 01:36:43,803 [grpc-default-executor-3] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 26396 bytes for container 6
2022-06-20 01:36:43,829 [grpc-default-executor-5] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(197)) - Container 6 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-0/data/replication/work/container-6.tar.gz
2022-06-20 01:36:43,831 [grpc-default-executor-0] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(197)) - Container 5 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-0/data/replication/work/container-5.tar.gz
2022-06-20 01:36:43,832 [ContainerReplicationThread-2] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 6 is downloaded with size 26396, starting to import.
2022-06-20 01:36:43,834 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 5 is downloaded with size 26058, starting to import.
2022-06-20 01:36:43,848 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(365)) - Attempting to stop container services.
2022-06-20 01:36:43,860 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$7(398)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d: close
2022-06-20 01:36:43,860 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D: shutdown
2022-06-20 01:36:43,860 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-35D4BFF3126D,id=fd1f8b8e-2a75-4423-a446-fc45b4d61a4d
2022-06-20 01:36:43,860 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d: shutdown fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-LeaderStateImpl
2022-06-20 01:36:43,860 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-PendingRequests: sendNotLeaderResponses
2022-06-20 01:36:43,861 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-StateMachineUpdater: set stopIndex = 0
2022-06-20 01:36:43,861 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-35D4BFF3126D: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-2/data/ratis/afc4b00a-4ea5-41e3-a374-35d4bff3126d/sm/snapshot.1_0
2022-06-20 01:36:43,862 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-35D4BFF3126D: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-2/data/ratis/afc4b00a-4ea5-41e3-a374-35d4bff3126d/sm/snapshot.1_0 took: 0 ms
2022-06-20 01:36:43,862 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-StateMachineUpdater: Took a snapshot at index 0
2022-06-20 01:36:43,862 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-06-20 01:36:43,862 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer$Division (ServerState.java:close(429)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D: closes. applyIndex: 0
2022-06-20 01:36:43,863 [fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-20 01:36:43,863 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d@group-35D4BFF3126D-SegmentedRaftLogWorker close()
2022-06-20 01:36:43,864 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(269)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d: shutdown server with port 35727 now
2022-06-20 01:36:43,901 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(278)) - fd1f8b8e-2a75-4423-a446-fc45b4d61a4d: shutdown server with port 35727 successfully
2022-06-20 01:36:43,901 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1750956089@33763956] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-fd1f8b8e-2a75-4423-a446-fc45b4d61a4d: Stopped
2022-06-20 01:36:43,953 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 5 is replicated successfully
2022-06-20 01:36:43,953 [ContainerReplicationThread-1] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(176)) - Container 5 is replicated.
2022-06-20 01:36:43,953 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 1 from [6c2707a0-87fd-4dba-96bb-b14739c19597{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=32853, RATIS=37095, RATIS_ADMIN=37095, RATIS_SERVER=37095, STANDALONE=33553], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-20 01:36:43,967 [ContainerReplicationThread-2] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 2 from [6c2707a0-87fd-4dba-96bb-b14739c19597{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=32853, RATIS=37095, RATIS_ADMIN=37095, RATIS_SERVER=37095, STANDALONE=33553], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-20 01:36:43,973 [grpc-default-executor-0] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(52)) - Streaming container data (2) to other datanode
2022-06-20 01:36:43,977 [grpc-default-executor-5] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(52)) - Streaming container data (1) to other datanode
2022-06-20 01:36:43,988 [ContainerReplicationThread-2] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 6 is replicated successfully
2022-06-20 01:36:43,988 [ContainerReplicationThread-2] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(176)) - Container 6 is replicated.
2022-06-20 01:36:44,004 [ContainerReplicationThread-3] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 4 from [6c2707a0-87fd-4dba-96bb-b14739c19597{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=32853, RATIS=37095, RATIS_ADMIN=37095, RATIS_SERVER=37095, STANDALONE=33553], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2022-06-20 01:36:44,010 [grpc-default-executor-3] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(52)) - Streaming container data (4) to other datanode
2022-06-20 01:36:44,136 [grpc-default-executor-0] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 26088 bytes for container 2
2022-06-20 01:36:44,164 [grpc-default-executor-2] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(197)) - Container 2 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-4/data/replication/work/container-2.tar.gz
2022-06-20 01:36:44,166 [ContainerReplicationThread-2] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 2 is downloaded with size 26088, starting to import.
2022-06-20 01:36:44,241 [grpc-default-executor-3] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 26135 bytes for container 4
2022-06-20 01:36:44,242 [grpc-default-executor-5] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 18465 bytes for container 1
2022-06-20 01:36:44,243 [grpc-default-executor-0] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(197)) - Container 4 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-4/data/replication/work/container-4.tar.gz
2022-06-20 01:36:44,258 [ContainerReplicationThread-2] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 2 is replicated successfully
2022-06-20 01:36:44,258 [ContainerReplicationThread-2] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(176)) - Container 2 is replicated.
2022-06-20 01:36:44,259 [ContainerReplicationThread-3] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 4 is downloaded with size 26135, starting to import.
2022-06-20 01:36:44,264 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. fd1f8b8e-2a75-4423-a446-fc45b4d61a4d{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=46197, RATIS=35727, RATIS_ADMIN=35727, RATIS_SERVER=35727, STANDALONE=33859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-06-20 01:36:44,264 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=afc4b00a-4ea5-41e3-a374-35d4bff3126d close command to datanode fd1f8b8e-2a75-4423-a446-fc45b4d61a4d
2022-06-20 01:36:44,265 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(243)) - Pipeline Pipeline[ Id: afc4b00a-4ea5-41e3-a374-35d4bff3126d, Nodes: fd1f8b8e-2a75-4423-a446-fc45b4d61a4d{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=46197, RATIS=35727, RATIS_ADMIN=35727, RATIS_SERVER=35727, STANDALONE=33859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:fd1f8b8e-2a75-4423-a446-fc45b4d61a4d, CreationTimestamp2022-06-20T01:36:11.377Z[Etc/UTC]] removed.
2022-06-20 01:36:44,265 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(137)) - Removed a node: /default-rack/fd1f8b8e-2a75-4423-a446-fc45b4d61a4d
2022-06-20 01:36:44,280 [grpc-default-executor-2] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(197)) - Container 1 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-4/data/replication/work/container-1.tar.gz
2022-06-20 01:36:44,285 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 1 is downloaded with size 18465, starting to import.
2022-06-20 01:36:44,357 [ContainerReplicationThread-3] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 4 is replicated successfully
2022-06-20 01:36:44,358 [ContainerReplicationThread-3] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(176)) - Container 4 is replicated.
2022-06-20 01:36:44,382 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 1 is replicated successfully
2022-06-20 01:36:44,382 [ContainerReplicationThread-1] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(176)) - Container 1 is replicated.
2022-06-20 01:36:44,485 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:44,485 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:44,486 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:44,486 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:44,486 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:44,486 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:44,486 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:44,486 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 4.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:44,486 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:44,486 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 5.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:44,487 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:44,487 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 6.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:44,487 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-06-20 01:36:45,487 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:45,487 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:45,487 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:45,488 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:45,488 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:45,488 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:45,488 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:45,488 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 4.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:45,488 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:45,488 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 5.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:45,488 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:45,488 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 6.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:45,489 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 2 milliseconds for processing 6 containers.
2022-06-20 01:36:45,836 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(580)) - Ozone container server stopped.
2022-06-20 01:36:45,896 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@ce0f7b9{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-20 01:36:45,908 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@723d1dff{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-06-20 01:36:45,908 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-06-20 01:36:45,909 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@29f2884a{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-06-20 01:36:45,909 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@18a7e592{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-06-20 01:36:45,981 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-06-20 01:36:46,492 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:46,492 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:46,492 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:46,493 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:46,493 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:46,493 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:46,493 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:46,493 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 4.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:46,493 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:46,493 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 5.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:46,493 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:46,493 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 6.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:46,493 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 2 milliseconds for processing 6 containers.
2022-06-20 01:36:47,494 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:47,494 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:47,494 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:47,494 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:47,495 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:47,495 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:47,495 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:47,495 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 4.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:47,495 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:47,495 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 5.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:47,495 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:47,495 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 6.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:47,495 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 2 milliseconds for processing 6 containers.
2022-06-20 01:36:48,425 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode 6f92f58e-935c-4e45-b2b1-2d5bfa669174{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=42433, RATIS=34635, RATIS_ADMIN=34635, RATIS_SERVER=34635, STANDALONE=32799], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=7c273264-1d7a-4723-8715-891141f9887c]
2022-06-20 01:36:48,425 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(430)) - Pipeline Pipeline[ Id: 7c273264-1d7a-4723-8715-891141f9887c, Nodes: 6f92f58e-935c-4e45-b2b1-2d5bfa669174{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=42433, RATIS=34635, RATIS_ADMIN=34635, RATIS_SERVER=34635, STANDALONE=32799], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:6f92f58e-935c-4e45-b2b1-2d5bfa669174, CreationTimestamp2022-06-20T01:35:33.793Z[Etc/UTC]] moved to CLOSED state
2022-06-20 01:36:48,496 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:48,496 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:48,496 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:48,496 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:48,499 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:48,499 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:48,499 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:48,499 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 4.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:48,499 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:48,499 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 5.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:48,499 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:48,499 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 6.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:48,499 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 4 milliseconds for processing 6 containers.
2022-06-20 01:36:49,006 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(580)) - Ozone container server stopped.
2022-06-20 01:36:49,082 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@2ede3a0f{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-20 01:36:49,083 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@50ca21bc{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-06-20 01:36:49,083 [ForkJoinPool.commonPool-worker-0] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-06-20 01:36:49,083 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@4923dca5{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-06-20 01:36:49,083 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@5ed82e6{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-06-20 01:36:49,500 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:49,500 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:49,500 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:49,500 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:49,500 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:49,500 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:49,500 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:49,501 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 4.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:49,501 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:49,501 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 5.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:49,501 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:49,501 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 6.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:49,501 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 2 milliseconds for processing 6 containers.
2022-06-20 01:36:50,501 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:50,502 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:50,502 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:50,502 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:50,502 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:50,502 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:50,502 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:50,502 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 4.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:50,502 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:50,502 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 5.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:50,503 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:50,503 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 6.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:50,503 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-06-20 01:36:50,919 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(365)) - Attempting to stop container services.
2022-06-20 01:36:50,921 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$7(398)) - 6f92f58e-935c-4e45-b2b1-2d5bfa669174: close
2022-06-20 01:36:50,921 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - 6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-891141F9887C: shutdown
2022-06-20 01:36:50,921 [Mini-Cluster-Provider-Reap] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-891141F9887C,id=6f92f58e-935c-4e45-b2b1-2d5bfa669174
2022-06-20 01:36:50,921 [Mini-Cluster-Provider-Reap] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 6f92f58e-935c-4e45-b2b1-2d5bfa669174: shutdown 6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-891141F9887C-LeaderStateImpl
2022-06-20 01:36:50,921 [Mini-Cluster-Provider-Reap] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-891141F9887C-PendingRequests: sendNotLeaderResponses
2022-06-20 01:36:50,922 [Mini-Cluster-Provider-Reap] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-891141F9887C-StateMachineUpdater: set stopIndex = 0
2022-06-20 01:36:50,924 [6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-891141F9887C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-891141F9887C: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-4/data/ratis/7c273264-1d7a-4723-8715-891141f9887c/sm/snapshot.1_0
2022-06-20 01:36:50,936 [6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-891141F9887C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-891141F9887C: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-4/data/ratis/7c273264-1d7a-4723-8715-891141f9887c/sm/snapshot.1_0 took: 12 ms
2022-06-20 01:36:50,936 [6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-891141F9887C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-891141F9887C-StateMachineUpdater: Took a snapshot at index 0
2022-06-20 01:36:50,937 [6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-891141F9887C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-891141F9887C-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-06-20 01:36:50,937 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer$Division (ServerState.java:close(429)) - 6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-891141F9887C: closes. applyIndex: 0
2022-06-20 01:36:50,940 [6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-891141F9887C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - 6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-891141F9887C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-20 01:36:50,940 [Mini-Cluster-Provider-Reap] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - 6f92f58e-935c-4e45-b2b1-2d5bfa669174@group-891141F9887C-SegmentedRaftLogWorker close()
2022-06-20 01:36:50,940 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(269)) - 6f92f58e-935c-4e45-b2b1-2d5bfa669174: shutdown server with port 34635 now
2022-06-20 01:36:50,944 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(278)) - 6f92f58e-935c-4e45-b2b1-2d5bfa669174: shutdown server with port 34635 successfully
2022-06-20 01:36:50,944 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1750956089@31460908] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-6f92f58e-935c-4e45-b2b1-2d5bfa669174: Stopped
2022-06-20 01:36:51,461 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. 6f92f58e-935c-4e45-b2b1-2d5bfa669174{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=42433, RATIS=34635, RATIS_ADMIN=34635, RATIS_SERVER=34635, STANDALONE=32799], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-06-20 01:36:51,462 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=7c273264-1d7a-4723-8715-891141f9887c close command to datanode 6f92f58e-935c-4e45-b2b1-2d5bfa669174
2022-06-20 01:36:51,462 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(243)) - Pipeline Pipeline[ Id: 7c273264-1d7a-4723-8715-891141f9887c, Nodes: 6f92f58e-935c-4e45-b2b1-2d5bfa669174{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=42433, RATIS=34635, RATIS_ADMIN=34635, RATIS_SERVER=34635, STANDALONE=32799], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:6f92f58e-935c-4e45-b2b1-2d5bfa669174, CreationTimestamp2022-06-20T01:35:33.793Z[Etc/UTC]] removed.
2022-06-20 01:36:51,462 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(137)) - Removed a node: /default-rack/6f92f58e-935c-4e45-b2b1-2d5bfa669174
2022-06-20 01:36:51,503 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:51,503 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:51,503 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:51,503 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:51,504 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:51,504 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:51,504 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:51,504 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 4.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:51,506 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:51,506 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 5.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:51,506 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodes(141)) - No healthy node found to allocate container.
2022-06-20 01:36:51,541 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1225)) - Exception while replicating container 6.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:142)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodes(SCMContainerPlacementRandom.java:78)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1189)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:539)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:244)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:265)
	at java.lang.Thread.run(Thread.java:750)
2022-06-20 01:36:51,542 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 39 milliseconds for processing 6 containers.
2022-06-20 01:36:52,075 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode 6c2707a0-87fd-4dba-96bb-b14739c19597{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=32853, RATIS=37095, RATIS_ADMIN=37095, RATIS_SERVER=37095, STANDALONE=33553], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=6a7893e3-a87e-49c7-8994-eaf9c225b5d5]
2022-06-20 01:36:52,076 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(430)) - Pipeline Pipeline[ Id: 6a7893e3-a87e-49c7-8994-eaf9c225b5d5, Nodes: 6c2707a0-87fd-4dba-96bb-b14739c19597{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=32853, RATIS=37095, RATIS_ADMIN=37095, RATIS_SERVER=37095, STANDALONE=33553], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:6c2707a0-87fd-4dba-96bb-b14739c19597, CreationTimestamp2022-06-20T01:36:11.376Z[Etc/UTC]] moved to CLOSED state
2022-06-20 01:36:52,542 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #1, no healthy replica found.
2022-06-20 01:36:52,542 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #2, no healthy replica found.
2022-06-20 01:36:52,542 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #3, no healthy replica found.
2022-06-20 01:36:52,542 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #4, no healthy replica found.
2022-06-20 01:36:52,542 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #5, no healthy replica found.
2022-06-20 01:36:52,542 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #6, no healthy replica found.
2022-06-20 01:36:52,542 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-06-20 01:36:52,984 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-06-20 01:36:53,543 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #1, no healthy replica found.
2022-06-20 01:36:53,543 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #2, no healthy replica found.
2022-06-20 01:36:53,543 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #3, no healthy replica found.
2022-06-20 01:36:53,543 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #4, no healthy replica found.
2022-06-20 01:36:53,543 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #5, no healthy replica found.
2022-06-20 01:36:53,543 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #6, no healthy replica found.
2022-06-20 01:36:53,543 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-06-20 01:36:54,089 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(365)) - Attempting to stop container services.
2022-06-20 01:36:54,092 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$7(398)) - 6c2707a0-87fd-4dba-96bb-b14739c19597: close
2022-06-20 01:36:54,092 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(434)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-EAF9C225B5D5: shutdown
2022-06-20 01:36:54,093 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-EAF9C225B5D5,id=6c2707a0-87fd-4dba-96bb-b14739c19597
2022-06-20 01:36:54,093 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 6c2707a0-87fd-4dba-96bb-b14739c19597: shutdown 6c2707a0-87fd-4dba-96bb-b14739c19597@group-EAF9C225B5D5-LeaderStateImpl
2022-06-20 01:36:54,094 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-EAF9C225B5D5-PendingRequests: sendNotLeaderResponses
2022-06-20 01:36:54,094 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-EAF9C225B5D5-StateMachineUpdater: set stopIndex = 0
2022-06-20 01:36:54,095 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-EAF9C225B5D5-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(304)) - group-EAF9C225B5D5: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-0/data/ratis/6a7893e3-a87e-49c7-8994-eaf9c225b5d5/sm/snapshot.1_0
2022-06-20 01:36:54,097 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-EAF9C225B5D5-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(315)) - group-EAF9C225B5D5: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7155b5b-f786-4084-b2af-ea5b528c53e8/datanode-0/data/ratis/6a7893e3-a87e-49c7-8994-eaf9c225b5d5/sm/snapshot.1_0 took: 1 ms
2022-06-20 01:36:54,097 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-EAF9C225B5D5-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-EAF9C225B5D5-StateMachineUpdater: Took a snapshot at index 0
2022-06-20 01:36:54,097 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-EAF9C225B5D5-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-EAF9C225B5D5-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2022-06-20 01:36:54,100 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer$Division (ServerState.java:close(429)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-EAF9C225B5D5: closes. applyIndex: 0
2022-06-20 01:36:54,101 [6c2707a0-87fd-4dba-96bb-b14739c19597@group-EAF9C225B5D5-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(336)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-EAF9C225B5D5-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2022-06-20 01:36:54,102 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(246)) - 6c2707a0-87fd-4dba-96bb-b14739c19597@group-EAF9C225B5D5-SegmentedRaftLogWorker close()
2022-06-20 01:36:54,137 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(269)) - 6c2707a0-87fd-4dba-96bb-b14739c19597: shutdown server with port 37095 now
2022-06-20 01:36:54,150 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(278)) - 6c2707a0-87fd-4dba-96bb-b14739c19597: shutdown server with port 37095 successfully
2022-06-20 01:36:54,150 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$706/1750956089@2b713971] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(109)) - JvmPauseMonitor-6c2707a0-87fd-4dba-96bb-b14739c19597: Stopped
2022-06-20 01:36:54,552 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #1, no healthy replica found.
2022-06-20 01:36:54,552 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #2, no healthy replica found.
2022-06-20 01:36:54,552 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #3, no healthy replica found.
2022-06-20 01:36:54,552 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #4, no healthy replica found.
2022-06-20 01:36:54,553 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #5, no healthy replica found.
2022-06-20 01:36:54,553 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #6, no healthy replica found.
2022-06-20 01:36:54,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-06-20 01:36:55,089 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(80)) - A dead datanode is detected. 6c2707a0-87fd-4dba-96bb-b14739c19597{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=32853, RATIS=37095, RATIS_ADMIN=37095, RATIS_SERVER=37095, STANDALONE=33553], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2022-06-20 01:36:55,089 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$1(244)) - Send pipeline:PipelineID=6a7893e3-a87e-49c7-8994-eaf9c225b5d5 close command to datanode 6c2707a0-87fd-4dba-96bb-b14739c19597
2022-06-20 01:36:55,089 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(243)) - Pipeline Pipeline[ Id: 6a7893e3-a87e-49c7-8994-eaf9c225b5d5, Nodes: 6c2707a0-87fd-4dba-96bb-b14739c19597{ip: 10.1.0.17, host: fv-az21-158.v4iizcarkezebbfea14bcgzyke.bx.internal.cloudapp.net, ports: [REPLICATION=32853, RATIS=37095, RATIS_ADMIN=37095, RATIS_SERVER=37095, STANDALONE=33553], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:6c2707a0-87fd-4dba-96bb-b14739c19597, CreationTimestamp2022-06-20T01:36:11.376Z[Etc/UTC]] removed.
2022-06-20 01:36:55,090 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(137)) - Removed a node: /default-rack/6c2707a0-87fd-4dba-96bb-b14739c19597
2022-06-20 01:36:55,553 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #1, no healthy replica found.
2022-06-20 01:36:55,553 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #2, no healthy replica found.
2022-06-20 01:36:55,553 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #3, no healthy replica found.
2022-06-20 01:36:55,553 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #4, no healthy replica found.
2022-06-20 01:36:55,553 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #5, no healthy replica found.
2022-06-20 01:36:55,553 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #6, no healthy replica found.
2022-06-20 01:36:55,553 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-06-20 01:36:55,989 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(580)) - Ozone container server stopped.
2022-06-20 01:36:56,052 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@322fb70{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-20 01:36:56,060 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@616a8b97{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-06-20 01:36:56,060 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-06-20 01:36:56,061 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@b7c0f6f{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-06-20 01:36:56,061 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@1108e641{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-06-20 01:36:56,213 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service BlockDeletingService
2022-06-20 01:36:56,554 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #1, no healthy replica found.
2022-06-20 01:36:56,554 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #2, no healthy replica found.
2022-06-20 01:36:56,554 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #3, no healthy replica found.
2022-06-20 01:36:56,554 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #4, no healthy replica found.
2022-06-20 01:36:56,554 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #5, no healthy replica found.
2022-06-20 01:36:56,554 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #6, no healthy replica found.
2022-06-20 01:36:56,554 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2022-06-20 01:36:57,554 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #1, no healthy replica found.
2022-06-20 01:36:57,555 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #2, no healthy replica found.
2022-06-20 01:36:57,555 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #3, no healthy replica found.
2022-06-20 01:36:57,555 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #4, no healthy replica found.
2022-06-20 01:36:57,555 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #5, no healthy replica found.
2022-06-20 01:36:57,555 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #6, no healthy replica found.
2022-06-20 01:36:57,555 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-06-20 01:36:58,555 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #1, no healthy replica found.
2022-06-20 01:36:58,555 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #2, no healthy replica found.
2022-06-20 01:36:58,555 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #3, no healthy replica found.
2022-06-20 01:36:58,555 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #4, no healthy replica found.
2022-06-20 01:36:58,555 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #5, no healthy replica found.
2022-06-20 01:36:58,555 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1221)) - Cannot replicate container #6, no healthy replica found.
2022-06-20 01:36:58,556 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(249)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2022-06-20 01:36:59,221 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(580)) - Ozone container server stopped.
2022-06-20 01:36:59,272 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@27dfdb77{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2022-06-20 01:36:59,278 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@f21fcb7{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-06-20 01:36:59,279 [ForkJoinPool.commonPool-worker-0] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-06-20 01:36:59,279 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@43c867d8{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.3.0-SNAPSHOT/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2022-06-20 01:36:59,279 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@3af27cd7{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-06-20 01:36:59,285 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(545)) - Stopping the StorageContainerManager
2022-06-20 01:36:59,285 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1501)) - Container Balancer is not running.
2022-06-20 01:36:59,285 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1508)) - Stopping Replication Manager Service.
2022-06-20 01:36:59,285 [Mini-Cluster-Provider-Reap] INFO  replication.ReplicationManager (ReplicationManager.java:stop(212)) - Stopping Replication Monitor Thread.
2022-06-20 01:36:59,285 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1515)) - Stopping the Datanode Admin Monitor.
2022-06-20 01:36:59,285 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(270)) - Replication Monitor Thread is stopped
2022-06-20 01:36:59,285 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1522)) - Stopping Lease Manager of the command watchers
2022-06-20 01:36:59,286 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1529)) - Stopping datanode service RPC server
2022-06-20 01:36:59,286 [Mini-Cluster-Provider-Reap] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(400)) - Stopping the RPC server for DataNodes
2022-06-20 01:36:59,286 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3414)) - Stopping server on 44353
2022-06-20 01:36:59,308 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1376)) - Stopping IPC Server listener on 0
2022-06-20 01:36:59,308 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - Stopping IPC Server Responder
2022-06-20 01:36:59,313 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(848)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2022-06-20 01:36:59,313 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1537)) - Stopping block service RPC server
2022-06-20 01:36:59,314 [Mini-Cluster-Provider-Reap] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(160)) - Stopping the RPC server for Block Protocol
2022-06-20 01:36:59,314 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3414)) - Stopping server on 41013
2022-06-20 01:36:59,316 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1544)) - Stopping the StorageContainerLocationProtocol RPC server
2022-06-20 01:36:59,316 [Mini-Cluster-Provider-Reap] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(178)) - Stopping the RPC server for Client Protocol
2022-06-20 01:36:59,316 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1376)) - Stopping IPC Server listener on 0
2022-06-20 01:36:59,317 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3414)) - Stopping server on 37855
2022-06-20 01:36:59,330 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - Stopping IPC Server Responder
2022-06-20 01:36:59,330 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1551)) - Stopping Storage Container Manager HTTP server.
2022-06-20 01:36:59,330 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - Stopping IPC Server Responder
2022-06-20 01:36:59,330 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1376)) - Stopping IPC Server listener on 0
2022-06-20 01:36:59,340 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.w.WebAppContext@34d818e3{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2022-06-20 01:36:59,341 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(381)) - Stopped ServerConnector@3dc7f169{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2022-06-20 01:36:59,341 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2022-06-20 01:36:59,341 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@4a307ed7{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2022-06-20 01:36:59,341 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1153)) - Stopped o.e.j.s.ServletContextHandler@19b52a1d{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2022-06-20 01:36:59,350 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1562)) - Stopping Block Manager Service.
2022-06-20 01:36:59,350 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service SCMBlockDeletingService
2022-06-20 01:36:59,350 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(132)) - Shutting down service SCMBlockDeletingService
2022-06-20 01:36:59,350 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1589)) - Stopping SCM Event Queue.
2022-06-20 01:36:59,352 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1600)) - Stopping SCM HA services.
2022-06-20 01:36:59,353 [Mini-Cluster-Provider-Reap] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(150)) - Stopping RatisPipelineUtilsThread.
2022-06-20 01:36:59,353 [RatisPipelineUtilsThread - 0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(177)) - RatisPipelineUtilsThread is interrupted.
2022-06-20 01:36:59,353 [Mini-Cluster-Provider-Reap] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(126)) - Stopping BackgroundPipelineScrubber Service.
2022-06-20 01:36:59,353 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1610)) - Stopping SCM MetadataStore.
2022-06-20 01:36:59,356 [BackgroundPipelineScrubberThread] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(110)) - BackgroundPipelineScrubber is interrupted, exit
2022-06-20 01:36:59,357 [Mini-Cluster-Provider-Reap] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(205)) - HddsDatanode metrics system stopped (again)
]]></system-out>
  </testcase>
  <testcase name="testSingleNodeWithOpenPipelineCanGotoMaintenance" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="100.012">
    <error type="java.io.IOException"><![CDATA[java.io.IOException: Failed to obtain available cluster in time
	at org.apache.hadoop.ozone.MiniOzoneClusterProvider.provide(MiniOzoneClusterProvider.java:162)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.setUp(TestDecommissionAndMaintenance.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptLifecycleMethod(TimeoutExtension.java:126)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptBeforeEachMethod(TimeoutExtension.java:76)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeMethodInExtensionContext(ClassBasedTestDescriptor.java:506)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$synthesizeBeforeEachMethodAdapter$21(ClassBasedTestDescriptor.java:491)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeBeforeEachMethods$3(TestMethodTestDescriptor.java:171)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeBeforeMethodsOrCallbacksUntilExceptionOccurs$6(TestMethodTestDescriptor.java:199)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeBeforeMethodsOrCallbacksUntilExceptionOccurs(TestMethodTestDescriptor.java:199)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeBeforeEachMethods(TestMethodTestDescriptor.java:168)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:131)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)
]]></error>
  </testcase>
  <testcase name="testSCMHandlesRestartForMaintenanceNode" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="100.016">
    <error type="java.io.IOException"><![CDATA[java.io.IOException: Failed to obtain available cluster in time
	at org.apache.hadoop.ozone.MiniOzoneClusterProvider.provide(MiniOzoneClusterProvider.java:162)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.setUp(TestDecommissionAndMaintenance.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptLifecycleMethod(TimeoutExtension.java:126)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptBeforeEachMethod(TimeoutExtension.java:76)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeMethodInExtensionContext(ClassBasedTestDescriptor.java:506)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$synthesizeBeforeEachMethodAdapter$21(ClassBasedTestDescriptor.java:491)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeBeforeEachMethods$3(TestMethodTestDescriptor.java:171)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeBeforeMethodsOrCallbacksUntilExceptionOccurs$6(TestMethodTestDescriptor.java:199)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeBeforeMethodsOrCallbacksUntilExceptionOccurs(TestMethodTestDescriptor.java:199)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeBeforeEachMethods(TestMethodTestDescriptor.java:168)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:131)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)
]]></error>
  </testcase>
  <testcase name="testStoppedDecommissionedNodeTakesSCMStateOnRestart" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="100.001">
    <error type="java.io.IOException"><![CDATA[java.io.IOException: Failed to obtain available cluster in time
	at org.apache.hadoop.ozone.MiniOzoneClusterProvider.provide(MiniOzoneClusterProvider.java:162)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.setUp(TestDecommissionAndMaintenance.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptLifecycleMethod(TimeoutExtension.java:126)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptBeforeEachMethod(TimeoutExtension.java:76)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeMethodInExtensionContext(ClassBasedTestDescriptor.java:506)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$synthesizeBeforeEachMethodAdapter$21(ClassBasedTestDescriptor.java:491)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeBeforeEachMethods$3(TestMethodTestDescriptor.java:171)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeBeforeMethodsOrCallbacksUntilExceptionOccurs$6(TestMethodTestDescriptor.java:199)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeBeforeMethodsOrCallbacksUntilExceptionOccurs(TestMethodTestDescriptor.java:199)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeBeforeEachMethods(TestMethodTestDescriptor.java:168)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:131)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)
]]></error>
  </testcase>
  <testcase name="testEnteringMaintenanceNodeCompletesAfterSCMRestart" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="100.021">
    <error type="java.io.IOException"><![CDATA[java.io.IOException: Failed to obtain available cluster in time
	at org.apache.hadoop.ozone.MiniOzoneClusterProvider.provide(MiniOzoneClusterProvider.java:162)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.setUp(TestDecommissionAndMaintenance.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptLifecycleMethod(TimeoutExtension.java:126)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptBeforeEachMethod(TimeoutExtension.java:76)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeMethodInExtensionContext(ClassBasedTestDescriptor.java:506)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$synthesizeBeforeEachMethodAdapter$21(ClassBasedTestDescriptor.java:491)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeBeforeEachMethods$3(TestMethodTestDescriptor.java:171)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeBeforeMethodsOrCallbacksUntilExceptionOccurs$6(TestMethodTestDescriptor.java:199)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeBeforeMethodsOrCallbacksUntilExceptionOccurs(TestMethodTestDescriptor.java:199)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeBeforeEachMethods(TestMethodTestDescriptor.java:168)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:131)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)
]]></error>
  </testcase>
  <testcase name="testDecommissioningNodesCompleteDecommissionOnSCMRestart" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="100.005">
    <error type="java.io.IOException"><![CDATA[java.io.IOException: Failed to obtain available cluster in time
	at org.apache.hadoop.ozone.MiniOzoneClusterProvider.provide(MiniOzoneClusterProvider.java:162)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.setUp(TestDecommissionAndMaintenance.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptLifecycleMethod(TimeoutExtension.java:126)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptBeforeEachMethod(TimeoutExtension.java:76)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeMethodInExtensionContext(ClassBasedTestDescriptor.java:506)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$synthesizeBeforeEachMethodAdapter$21(ClassBasedTestDescriptor.java:491)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeBeforeEachMethods$3(TestMethodTestDescriptor.java:171)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeBeforeMethodsOrCallbacksUntilExceptionOccurs$6(TestMethodTestDescriptor.java:199)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeBeforeMethodsOrCallbacksUntilExceptionOccurs(TestMethodTestDescriptor.java:199)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeBeforeEachMethods(TestMethodTestDescriptor.java:168)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:131)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)
]]></error>
  </testcase>
</testsuite>