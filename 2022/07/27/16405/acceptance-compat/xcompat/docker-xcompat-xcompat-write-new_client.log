Attaching to xcompat_recon_1, xcompat_old_client_1_0_0_1, xcompat_datanode_4, xcompat_datanode_5, xcompat_datanode_3, xcompat_datanode_1, xcompat_datanode_2, xcompat_new_client_1, xcompat_old_client_1_2_1_1, xcompat_old_client_1_1_0_1, xcompat_scm_1, xcompat_s3g_1, xcompat_om_1
datanode_1          | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode_1          | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1          | 2022-07-27 17:14:16,214 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1          | /************************************************************
datanode_1          | STARTUP_MSG: Starting HddsDatanodeService
datanode_1          | STARTUP_MSG:   host = 032319ade833/172.23.0.9
datanode_1          | STARTUP_MSG:   args = []
datanode_1          | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode_1          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode_1          | STARTUP_MSG:   build = https://github.com/apache/ozone/9f188e38b2f4663af1a9169fb7f63dfe156555a0 ; compiled by 'runner' on 2022-07-27T16:18Z
datanode_1          | STARTUP_MSG:   java = 11.0.14.1
datanode_1          | ************************************************************/
datanode_1          | 2022-07-27 17:14:16,290 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1          | 2022-07-27 17:14:16,647 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1          | 2022-07-27 17:14:17,385 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1          | 2022-07-27 17:14:18,395 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1          | 2022-07-27 17:14:18,396 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1          | 2022-07-27 17:14:19,250 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:032319ade833 ip:172.23.0.9
datanode_1          | 2022-07-27 17:14:21,396 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode_1          | 2022-07-27 17:14:22,378 [main] INFO reflections.Reflections: Reflections took 771 ms to scan 2 urls, producing 89 keys and 198 values 
datanode_1          | 2022-07-27 17:14:23,186 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
datanode_1          | 2022-07-27 17:14:24,441 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_1          | 2022-07-27 17:14:24,529 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
datanode_1          | 2022-07-27 17:14:24,647 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_1          | 2022-07-27 17:14:24,652 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1          | 2022-07-27 17:14:24,936 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_1          | 2022-07-27 17:14:25,162 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1          | 2022-07-27 17:14:25,179 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode_1          | 2022-07-27 17:14:25,223 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode_1          | 2022-07-27 17:14:25,224 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode_1          | 2022-07-27 17:14:25,224 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode_1          | 2022-07-27 17:14:25,587 [Thread-7] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_1          | 2022-07-27 17:14:25,603 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_1          | 2022-07-27 17:14:34,151 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode_1          | 2022-07-27 17:14:34,732 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1          | 2022-07-27 17:14:35,384 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode_1          | 2022-07-27 17:14:36,379 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode_1          | 2022-07-27 17:14:36,437 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode_1          | 2022-07-27 17:14:36,451 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode_1          | 2022-07-27 17:14:36,452 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1          | 2022-07-27 17:14:36,473 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1          | 2022-07-27 17:14:36,474 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_1          | 2022-07-27 17:14:36,474 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1          | 2022-07-27 17:14:36,721 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode_1          | 2022-07-27 17:14:36,736 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode_1          | 2022-07-27 17:14:39,259 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode_1          | 2022-07-27 17:14:39,262 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode_1          | 2022-07-27 17:14:39,262 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode_1          | 2022-07-27 17:14:39,262 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_1          | 2022-07-27 17:14:39,262 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_1          | 2022-07-27 17:14:39,306 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1          | 2022-07-27 17:14:39,540 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode_1          | 2022-07-27 17:14:40,729 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1          | 2022-07-27 17:14:40,786 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_1          | 2022-07-27 17:14:41,121 [main] INFO util.log: Logging initialized @36414ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1          | 2022-07-27 17:14:41,907 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1          | 2022-07-27 17:14:41,918 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1          | 2022-07-27 17:14:41,996 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1          | 2022-07-27 17:14:42,028 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_1          | 2022-07-27 17:14:42,040 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_1          | 2022-07-27 17:14:42,041 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_1          | 2022-07-27 17:14:42,440 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1          | 2022-07-27 17:14:42,442 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode_1          | 2022-07-27 17:14:42,699 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_1          | 2022-07-27 17:14:42,699 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_1          | 2022-07-27 17:14:42,701 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_1          | 2022-07-27 17:14:42,827 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2af3b054{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1          | 2022-07-27 17:14:42,838 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@41bbdd8a{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1          | 2022-07-27 17:14:43,678 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7d7c05fa{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-4759968929083462220/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_1          | 2022-07-27 17:14:43,785 [main] INFO server.AbstractConnector: Started ServerConnector@1a5a4f8{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode_1          | 2022-07-27 17:14:43,793 [main] INFO server.Server: Started @39105ms
datanode_1          | 2022-07-27 17:14:43,805 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1          | 2022-07-27 17:14:43,805 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1          | 2022-07-27 17:14:43,815 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_1          | 2022-07-27 17:14:43,843 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode_1          | 2022-07-27 17:14:44,124 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@150cdbec] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1          | 2022-07-27 17:14:44,891 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.23.0.11:9891
datanode_1          | 2022-07-27 17:14:45,225 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_1          | 2022-07-27 17:14:47,608 [EndpointStateMachine task thread for recon/172.23.0.11:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.23.0.11:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1          | 2022-07-27 17:14:47,609 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1          | 2022-07-27 17:14:48,609 [EndpointStateMachine task thread for recon/172.23.0.11:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.23.0.11:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1          | 2022-07-27 17:14:48,610 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1          | 2022-07-27 17:14:49,610 [EndpointStateMachine task thread for recon/172.23.0.11:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.23.0.11:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1          | 2022-07-27 17:14:49,610 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1          | 2022-07-27 17:14:50,611 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1          | 2022-07-27 17:14:50,612 [EndpointStateMachine task thread for recon/172.23.0.11:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.23.0.11:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1          | 2022-07-27 17:14:51,614 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1          | 2022-07-27 17:14:52,615 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1          | 2022-07-27 17:14:53,616 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1          | 2022-07-27 17:14:54,618 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1          | 2022-07-27 17:14:55,619 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1          | 2022-07-27 17:14:55,657 [EndpointStateMachine task thread for recon/172.23.0.11:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode_1          | java.net.SocketTimeoutException: Call From 032319ade833/172.23.0.9 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.9:36068 remote=recon/172.23.0.11:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_1          | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_1          | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_1          | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_1          | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_1          | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode_1          | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
datanode_1          | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
datanode_1          | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
datanode_1          | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
datanode_1          | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
datanode_1          | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
datanode_1          | 	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
datanode_1          | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_1          | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_1          | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
datanode_1          | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
datanode_1          | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1          | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1          | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1          | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_1          | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.9:36068 remote=recon/172.23.0.11:9891]
datanode_1          | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_1          | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_1          | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_1          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_1          | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_1          | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_1          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1          | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
datanode_1          | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_1          | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
datanode_1          | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
datanode_1          | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
datanode_1          | 2022-07-27 17:15:00,628 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_1          | java.net.SocketTimeoutException: Call From 032319ade833/172.23.0.9 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.9:57582 remote=scm/172.23.0.4:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_1          | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_1          | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_1          | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_1          | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_1          | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode_1          | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
datanode_1          | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
datanode_1          | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
datanode_1          | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
datanode_1          | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
datanode_1          | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
datanode_1          | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
datanode_1          | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_1          | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_1          | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
datanode_1          | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
datanode_1          | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1          | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1          | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1          | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_1          | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.9:57582 remote=scm/172.23.0.4:9861]
datanode_1          | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_1          | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_1          | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_1          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_1          | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_1          | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_1          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1          | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
datanode_1          | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_1          | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
datanode_1          | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
datanode_1          | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
datanode_1          | 2022-07-27 17:15:01,627 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-7d45909c-9fcd-4dc9-be34-cfa80db7825a/DS-bb851a33-b319-447b-9b77-1644bcaf8c27/container.db for volume DS-bb851a33-b319-447b-9b77-1644bcaf8c27
datanode_1          | 2022-07-27 17:15:01,665 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-7d45909c-9fcd-4dc9-be34-cfa80db7825a/DS-bb851a33-b319-447b-9b77-1644bcaf8c27/container.db for volume DS-bb851a33-b319-447b-9b77-1644bcaf8c27
datanode_1          | 2022-07-27 17:15:01,671 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_1          | 2022-07-27 17:15:01,688 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_1          | 2022-07-27 17:15:02,003 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 5a16948f-0635-4af6-ad47-d40ff1547cf8
datanode_1          | 2022-07-27 17:15:02,101 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO server.RaftServer: 5a16948f-0635-4af6-ad47-d40ff1547cf8: start RPC server
datanode_1          | 2022-07-27 17:15:02,105 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO server.GrpcService: 5a16948f-0635-4af6-ad47-d40ff1547cf8: GrpcService started, listening on 9856
datanode_1          | 2022-07-27 17:15:02,116 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO server.GrpcService: 5a16948f-0635-4af6-ad47-d40ff1547cf8: GrpcService started, listening on 9857
datanode_1          | 2022-07-27 17:15:02,119 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO server.GrpcService: 5a16948f-0635-4af6-ad47-d40ff1547cf8: GrpcService started, listening on 9858
datanode_1          | 2022-07-27 17:15:02,133 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 5a16948f-0635-4af6-ad47-d40ff1547cf8 is started using port 9858 for RATIS
datanode_1          | 2022-07-27 17:15:02,134 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 5a16948f-0635-4af6-ad47-d40ff1547cf8 is started using port 9857 for RATIS_ADMIN
datanode_1          | 2022-07-27 17:15:02,134 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$343/0x0000000840501440@2fe6e35e] INFO util.JvmPauseMonitor: JvmPauseMonitor-5a16948f-0635-4af6-ad47-d40ff1547cf8: Started
datanode_1          | 2022-07-27 17:15:02,135 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 5a16948f-0635-4af6-ad47-d40ff1547cf8 is started using port 9856 for RATIS_SERVER
datanode_1          | 2022-07-27 17:15:02,207 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode_1          | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode_1          | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode_1          | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode_1          | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
datanode_1          | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
datanode_1          | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode_1          | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:660)
datanode_1          | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:298)
datanode_1          | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:493)
datanode_1          | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_1          | Caused by: java.util.concurrent.TimeoutException
datanode_1          | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode_1          | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
datanode_1          | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1          | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1          | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1          | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1          | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1          | 	... 1 more
datanode_1          | 2022-07-27 17:15:12,171 [grpc-default-executor-1] INFO server.RaftServer: 5a16948f-0635-4af6-ad47-d40ff1547cf8: addNew group-29EFD5711FCF:[b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|dataStream:|priority:0, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|dataStream:|priority:1, 5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|dataStream:|priority:0] returns group-29EFD5711FCF:java.util.concurrent.CompletableFuture@70787ae4[Not completed]
datanode_1          | 2022-07-27 17:15:12,186 [grpc-default-executor-0] INFO server.RaftServer: 5a16948f-0635-4af6-ad47-d40ff1547cf8: addNew group-747C147E1F30:[5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|dataStream:|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|dataStream:|priority:0, fb410344-fcfe-4f99-b41b-29dd0a68d978|rpc:172.23.0.13:9856|admin:172.23.0.13:9857|client:172.23.0.13:9858|dataStream:|priority:1] returns group-747C147E1F30:java.util.concurrent.CompletableFuture@1cbb3c07[Not completed]
datanode_1          | 2022-07-27 17:15:12,382 [pool-22-thread-1] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8: new RaftServerImpl for group-29EFD5711FCF:[b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|dataStream:|priority:0, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|dataStream:|priority:1, 5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
datanode_1          | 2022-07-27 17:15:12,419 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1          | 2022-07-27 17:15:12,436 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1          | 2022-07-27 17:15:12,439 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1          | 2022-07-27 17:15:12,450 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_1          | 2022-07-27 17:15:12,450 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_1          | 2022-07-27 17:15:12,452 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_1          | 2022-07-27 17:15:12,514 [pool-22-thread-1] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF: ConfigurationManager, init=-1: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|dataStream:|priority:0, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|dataStream:|priority:1, 5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
datanode_1          | 2022-07-27 17:15:12,533 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1          | 2022-07-27 17:15:12,571 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1          | 2022-07-27 17:15:12,573 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_1          | 2022-07-27 17:15:12,576 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/de666cc0-d9ea-4d5d-8684-29efd5711fcf does not exist. Creating ...
datanode_1          | 2022-07-27 17:15:12,612 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/de666cc0-d9ea-4d5d-8684-29efd5711fcf/in_use.lock acquired by nodename 8@032319ade833
datanode_1          | 2022-07-27 17:15:12,638 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/de666cc0-d9ea-4d5d-8684-29efd5711fcf has been successfully formatted.
datanode_1          | 2022-07-27 17:15:12,713 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-29EFD5711FCF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1          | 2022-07-27 17:15:12,723 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_1          | 2022-07-27 17:15:12,725 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1          | 2022-07-27 17:15:12,766 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1          | 2022-07-27 17:15:12,766 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1          | 2022-07-27 17:15:12,767 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_1          | 2022-07-27 17:15:12,818 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1          | 2022-07-27 17:15:12,840 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1          | 2022-07-27 17:15:12,843 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_1          | 2022-07-27 17:15:12,870 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/de666cc0-d9ea-4d5d-8684-29efd5711fcf
datanode_1          | 2022-07-27 17:15:12,870 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_1          | 2022-07-27 17:15:12,871 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1          | 2022-07-27 17:15:12,874 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1          | 2022-07-27 17:15:12,874 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1          | 2022-07-27 17:15:12,876 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1          | 2022-07-27 17:15:12,879 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1          | 2022-07-27 17:15:12,884 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1          | 2022-07-27 17:15:12,885 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1          | 2022-07-27 17:15:12,911 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1          | 2022-07-27 17:15:12,917 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_1          | 2022-07-27 17:15:12,917 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1          | 2022-07-27 17:15:12,941 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1          | 2022-07-27 17:15:12,944 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1          | 2022-07-27 17:15:12,968 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1          | 2022-07-27 17:15:12,969 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1          | 2022-07-27 17:15:12,969 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1          | 2022-07-27 17:15:12,972 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1          | 2022-07-27 17:15:12,977 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1          | 2022-07-27 17:15:12,977 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_1          | 2022-07-27 17:15:13,072 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1          | 2022-07-27 17:15:13,075 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_1          | 2022-07-27 17:15:13,076 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_1          | 2022-07-27 17:15:13,077 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_1          | 2022-07-27 17:15:13,078 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_1          | 2022-07-27 17:15:13,080 [pool-22-thread-1] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8: new RaftServerImpl for group-747C147E1F30:[5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|dataStream:|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|dataStream:|priority:0, fb410344-fcfe-4f99-b41b-29dd0a68d978|rpc:172.23.0.13:9856|admin:172.23.0.13:9857|client:172.23.0.13:9858|dataStream:|priority:1] with ContainerStateMachine:uninitialized
datanode_1          | 2022-07-27 17:15:13,086 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1          | 2022-07-27 17:15:13,087 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1          | 2022-07-27 17:15:13,087 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1          | 2022-07-27 17:15:13,087 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_1          | 2022-07-27 17:15:13,087 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_1          | 2022-07-27 17:15:13,087 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_1          | 2022-07-27 17:15:13,087 [pool-22-thread-1] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-747C147E1F30: ConfigurationManager, init=-1: [5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|dataStream:|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|dataStream:|priority:0, fb410344-fcfe-4f99-b41b-29dd0a68d978|rpc:172.23.0.13:9856|admin:172.23.0.13:9857|client:172.23.0.13:9858|dataStream:|priority:1], old=null, confs=<EMPTY_MAP>
datanode_1          | 2022-07-27 17:15:13,088 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1          | 2022-07-27 17:15:13,089 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1          | 2022-07-27 17:15:13,089 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_1          | 2022-07-27 17:15:13,089 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/02ad9aa3-8955-4f68-a76b-747c147e1f30 does not exist. Creating ...
datanode_1          | 2022-07-27 17:15:13,094 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/02ad9aa3-8955-4f68-a76b-747c147e1f30/in_use.lock acquired by nodename 8@032319ade833
datanode_1          | 2022-07-27 17:15:13,098 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/02ad9aa3-8955-4f68-a76b-747c147e1f30 has been successfully formatted.
datanode_1          | 2022-07-27 17:15:13,099 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-747C147E1F30: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1          | 2022-07-27 17:15:13,099 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_1          | 2022-07-27 17:15:13,099 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1          | 2022-07-27 17:15:13,100 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1          | 2022-07-27 17:15:13,100 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1          | 2022-07-27 17:15:13,100 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_1          | 2022-07-27 17:15:13,100 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1          | 2022-07-27 17:15:13,116 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1          | 2022-07-27 17:15:13,116 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_1          | 2022-07-27 17:15:13,116 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-747C147E1F30-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/02ad9aa3-8955-4f68-a76b-747c147e1f30
datanode_1          | 2022-07-27 17:15:13,116 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_1          | 2022-07-27 17:15:13,116 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1          | 2022-07-27 17:15:13,116 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1          | 2022-07-27 17:15:13,118 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1          | 2022-07-27 17:15:13,118 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1          | 2022-07-27 17:15:13,118 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1          | 2022-07-27 17:15:13,119 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1          | 2022-07-27 17:15:13,121 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1          | 2022-07-27 17:15:13,123 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1          | 2022-07-27 17:15:13,124 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_1          | 2022-07-27 17:15:13,124 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1          | 2022-07-27 17:15:13,124 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-747C147E1F30-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1          | 2022-07-27 17:15:13,126 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-747C147E1F30-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1          | 2022-07-27 17:15:13,129 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1          | 2022-07-27 17:15:13,129 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1          | 2022-07-27 17:15:13,130 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1          | 2022-07-27 17:15:13,130 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1          | 2022-07-27 17:15:13,130 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1          | 2022-07-27 17:15:13,130 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_1          | 2022-07-27 17:15:13,131 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1          | 2022-07-27 17:15:13,132 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_1          | 2022-07-27 17:15:13,132 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_1          | 2022-07-27 17:15:13,132 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_1          | 2022-07-27 17:15:13,132 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_1          | 2022-07-27 17:15:13,133 [pool-22-thread-1] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF: start as a follower, conf=-1: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|dataStream:|priority:0, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|dataStream:|priority:1, 5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|dataStream:|priority:0], old=null
datanode_1          | 2022-07-27 17:15:13,136 [pool-22-thread-1] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1          | 2022-07-27 17:15:13,138 [pool-22-thread-1] INFO impl.RoleInfo: 5a16948f-0635-4af6-ad47-d40ff1547cf8: start 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF-FollowerState
datanode_1          | 2022-07-27 17:15:13,166 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-29EFD5711FCF,id=5a16948f-0635-4af6-ad47-d40ff1547cf8
datanode_1          | 2022-07-27 17:15:13,214 [pool-22-thread-1] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-747C147E1F30: start as a follower, conf=-1: [5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|dataStream:|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|dataStream:|priority:0, fb410344-fcfe-4f99-b41b-29dd0a68d978|rpc:172.23.0.13:9856|admin:172.23.0.13:9857|client:172.23.0.13:9858|dataStream:|priority:1], old=null
datanode_1          | 2022-07-27 17:15:13,215 [pool-22-thread-1] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-747C147E1F30: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1          | 2022-07-27 17:15:13,215 [pool-22-thread-1] INFO impl.RoleInfo: 5a16948f-0635-4af6-ad47-d40ff1547cf8: start 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-747C147E1F30-FollowerState
datanode_1          | 2022-07-27 17:15:13,215 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-747C147E1F30,id=5a16948f-0635-4af6-ad47-d40ff1547cf8
datanode_1          | 2022-07-27 17:15:14,404 [grpc-default-executor-1] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-747C147E1F30: receive requestVote(ELECTION, fb410344-fcfe-4f99-b41b-29dd0a68d978, group-747C147E1F30, 1, (t:0, i:0))
datanode_1          | 2022-07-27 17:15:14,406 [grpc-default-executor-1] INFO impl.VoteContext: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-747C147E1F30-FOLLOWER: accept ELECTION from fb410344-fcfe-4f99-b41b-29dd0a68d978: our priority 0 <= candidate's priority 1
datanode_1          | 2022-07-27 17:15:14,407 [grpc-default-executor-1] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-747C147E1F30: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:fb410344-fcfe-4f99-b41b-29dd0a68d978
datanode_1          | 2022-07-27 17:15:14,407 [grpc-default-executor-1] INFO impl.RoleInfo: 5a16948f-0635-4af6-ad47-d40ff1547cf8: shutdown 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-747C147E1F30-FollowerState
datanode_1          | 2022-07-27 17:15:14,411 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-747C147E1F30-FollowerState] INFO impl.FollowerState: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-747C147E1F30-FollowerState was interrupted
datanode_2          | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode_2          | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2          | 2022-07-27 17:14:17,307 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2          | /************************************************************
datanode_2          | STARTUP_MSG: Starting HddsDatanodeService
datanode_2          | STARTUP_MSG:   host = a8e8226775b7/172.23.0.6
datanode_2          | STARTUP_MSG:   args = []
datanode_2          | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode_2          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode_2          | STARTUP_MSG:   build = https://github.com/apache/ozone/9f188e38b2f4663af1a9169fb7f63dfe156555a0 ; compiled by 'runner' on 2022-07-27T16:18Z
datanode_2          | STARTUP_MSG:   java = 11.0.14.1
datanode_2          | ************************************************************/
datanode_2          | 2022-07-27 17:14:17,363 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2          | 2022-07-27 17:14:17,571 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2          | 2022-07-27 17:14:18,404 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2          | 2022-07-27 17:14:19,459 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2          | 2022-07-27 17:14:19,464 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2          | 2022-07-27 17:14:20,374 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:a8e8226775b7 ip:172.23.0.6
datanode_2          | 2022-07-27 17:14:22,866 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode_2          | 2022-07-27 17:14:23,861 [main] INFO reflections.Reflections: Reflections took 734 ms to scan 2 urls, producing 89 keys and 198 values 
datanode_2          | 2022-07-27 17:14:24,803 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
datanode_2          | 2022-07-27 17:14:26,141 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_2          | 2022-07-27 17:14:26,310 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
datanode_2          | 2022-07-27 17:14:26,314 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2          | 2022-07-27 17:14:26,348 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2          | 2022-07-27 17:14:26,609 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2          | 2022-07-27 17:14:26,910 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2          | 2022-07-27 17:14:26,915 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode_2          | 2022-07-27 17:14:26,943 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode_2          | 2022-07-27 17:14:26,948 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode_2          | 2022-07-27 17:14:26,951 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode_2          | 2022-07-27 17:14:27,193 [Thread-7] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_2          | 2022-07-27 17:14:27,199 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_2          | 2022-07-27 17:14:36,156 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode_2          | 2022-07-27 17:14:36,840 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2          | 2022-07-27 17:14:37,539 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode_2          | 2022-07-27 17:14:38,510 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode_2          | 2022-07-27 17:14:38,510 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode_2          | 2022-07-27 17:14:38,511 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode_2          | 2022-07-27 17:14:38,528 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_2          | 2022-07-27 17:14:38,529 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2          | 2022-07-27 17:14:38,550 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_2          | 2022-07-27 17:14:38,555 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2          | 2022-07-27 17:14:38,684 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode_2          | 2022-07-27 17:14:38,685 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode_2          | 2022-07-27 17:14:41,136 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode_2          | 2022-07-27 17:14:41,160 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode_2          | 2022-07-27 17:14:41,161 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode_2          | 2022-07-27 17:14:41,161 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_2          | 2022-07-27 17:14:41,167 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_2          | 2022-07-27 17:14:41,192 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2          | 2022-07-27 17:14:41,372 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode_2          | 2022-07-27 17:14:42,500 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2          | 2022-07-27 17:14:42,574 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_2          | 2022-07-27 17:14:42,787 [main] INFO util.log: Logging initialized @36845ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2          | 2022-07-27 17:14:43,378 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2          | 2022-07-27 17:14:43,421 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2          | 2022-07-27 17:14:43,482 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2          | 2022-07-27 17:14:43,493 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_2          | 2022-07-27 17:14:43,498 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_2          | 2022-07-27 17:14:43,498 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_2          | 2022-07-27 17:14:43,752 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1          | 2022-07-27 17:15:14,412 [grpc-default-executor-1] INFO impl.RoleInfo: 5a16948f-0635-4af6-ad47-d40ff1547cf8: start 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-747C147E1F30-FollowerState
datanode_1          | 2022-07-27 17:15:14,439 [grpc-default-executor-1] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-747C147E1F30 replies to ELECTION vote request: fb410344-fcfe-4f99-b41b-29dd0a68d978<-5a16948f-0635-4af6-ad47-d40ff1547cf8#0:OK-t1. Peer's state: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-747C147E1F30:t1, leader=null, voted=fb410344-fcfe-4f99-b41b-29dd0a68d978, raftlog=5a16948f-0635-4af6-ad47-d40ff1547cf8@group-747C147E1F30-SegmentedRaftLog:OPENED:c-1, conf=-1: [5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|dataStream:|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|dataStream:|priority:0, fb410344-fcfe-4f99-b41b-29dd0a68d978|rpc:172.23.0.13:9856|admin:172.23.0.13:9857|client:172.23.0.13:9858|dataStream:|priority:1], old=null
datanode_1          | 2022-07-27 17:15:14,695 [5a16948f-0635-4af6-ad47-d40ff1547cf8-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-747C147E1F30 with new leaderId: fb410344-fcfe-4f99-b41b-29dd0a68d978
datanode_1          | 2022-07-27 17:15:14,703 [5a16948f-0635-4af6-ad47-d40ff1547cf8-server-thread1] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-747C147E1F30: change Leader from null to fb410344-fcfe-4f99-b41b-29dd0a68d978 at term 1 for appendEntries, leader elected after 1596ms
datanode_1          | 2022-07-27 17:15:14,836 [5a16948f-0635-4af6-ad47-d40ff1547cf8-server-thread1] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-747C147E1F30: set configuration 0: [5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|dataStream:|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|dataStream:|priority:0, fb410344-fcfe-4f99-b41b-29dd0a68d978|rpc:172.23.0.13:9856|admin:172.23.0.13:9857|client:172.23.0.13:9858|dataStream:|priority:1], old=null
datanode_1          | 2022-07-27 17:15:14,842 [5a16948f-0635-4af6-ad47-d40ff1547cf8-server-thread1] INFO segmented.SegmentedRaftLogWorker: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-747C147E1F30-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1          | 2022-07-27 17:15:15,069 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-747C147E1F30-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-747C147E1F30-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/02ad9aa3-8955-4f68-a76b-747c147e1f30/current/log_inprogress_0
datanode_1          | 2022-07-27 17:15:16,937 [grpc-default-executor-1] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF: receive requestVote(ELECTION, b50d7a6b-da1f-4bca-b673-015544dce0bd, group-29EFD5711FCF, 1, (t:0, i:0))
datanode_1          | 2022-07-27 17:15:16,937 [grpc-default-executor-1] INFO impl.VoteContext: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF-FOLLOWER: accept ELECTION from b50d7a6b-da1f-4bca-b673-015544dce0bd: our priority 0 <= candidate's priority 0
datanode_1          | 2022-07-27 17:15:16,937 [grpc-default-executor-1] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:b50d7a6b-da1f-4bca-b673-015544dce0bd
datanode_1          | 2022-07-27 17:15:16,937 [grpc-default-executor-1] INFO impl.RoleInfo: 5a16948f-0635-4af6-ad47-d40ff1547cf8: shutdown 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF-FollowerState
datanode_1          | 2022-07-27 17:15:16,938 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF-FollowerState] INFO impl.FollowerState: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF-FollowerState was interrupted
datanode_1          | 2022-07-27 17:15:16,939 [grpc-default-executor-1] INFO impl.RoleInfo: 5a16948f-0635-4af6-ad47-d40ff1547cf8: start 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF-FollowerState
datanode_1          | 2022-07-27 17:15:16,941 [grpc-default-executor-1] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF replies to ELECTION vote request: b50d7a6b-da1f-4bca-b673-015544dce0bd<-5a16948f-0635-4af6-ad47-d40ff1547cf8#0:OK-t1. Peer's state: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF:t1, leader=null, voted=b50d7a6b-da1f-4bca-b673-015544dce0bd, raftlog=5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF-SegmentedRaftLog:OPENED:c-1, conf=-1: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|dataStream:|priority:0, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|dataStream:|priority:1, 5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|dataStream:|priority:0], old=null
datanode_1          | 2022-07-27 17:15:22,131 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF-FollowerState] INFO impl.FollowerState: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5191053625ns, electionTimeout:5188ms
datanode_1          | 2022-07-27 17:15:22,132 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF-FollowerState] INFO impl.RoleInfo: 5a16948f-0635-4af6-ad47-d40ff1547cf8: shutdown 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF-FollowerState
datanode_1          | 2022-07-27 17:15:22,132 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF-FollowerState] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode_1          | 2022-07-27 17:15:22,134 [grpc-default-executor-1] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF: receive requestVote(ELECTION, 0047ef4e-8059-4dda-a40b-cf26d888a843, group-29EFD5711FCF, 2, (t:0, i:0))
datanode_1          | 2022-07-27 17:15:22,181 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_1          | 2022-07-27 17:15:22,196 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF-FollowerState] INFO impl.RoleInfo: 5a16948f-0635-4af6-ad47-d40ff1547cf8: start 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF-LeaderElection1
datanode_1          | 2022-07-27 17:15:22,206 [grpc-default-executor-1] INFO impl.VoteContext: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF-CANDIDATE: accept ELECTION from 0047ef4e-8059-4dda-a40b-cf26d888a843: our priority 0 <= candidate's priority 1
datanode_1          | 2022-07-27 17:15:22,206 [grpc-default-executor-1] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF: changes role from CANDIDATE to FOLLOWER at term 2 for candidate:0047ef4e-8059-4dda-a40b-cf26d888a843
datanode_1          | 2022-07-27 17:15:22,206 [grpc-default-executor-1] INFO impl.RoleInfo: 5a16948f-0635-4af6-ad47-d40ff1547cf8: shutdown 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF-LeaderElection1
datanode_1          | 2022-07-27 17:15:22,207 [grpc-default-executor-1] INFO impl.RoleInfo: 5a16948f-0635-4af6-ad47-d40ff1547cf8: start 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF-FollowerState
datanode_1          | 2022-07-27 17:15:22,208 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF-LeaderElection1] INFO impl.LeaderElection: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF-LeaderElection1: skip running since this is already CLOSING
datanode_1          | 2022-07-27 17:15:22,233 [grpc-default-executor-1] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF replies to ELECTION vote request: 0047ef4e-8059-4dda-a40b-cf26d888a843<-5a16948f-0635-4af6-ad47-d40ff1547cf8#0:OK-t2. Peer's state: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF:t2, leader=null, voted=0047ef4e-8059-4dda-a40b-cf26d888a843, raftlog=5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF-SegmentedRaftLog:OPENED:c-1, conf=-1: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|dataStream:|priority:0, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|dataStream:|priority:1, 5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|dataStream:|priority:0], old=null
datanode_1          | 2022-07-27 17:15:22,433 [5a16948f-0635-4af6-ad47-d40ff1547cf8-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-29EFD5711FCF with new leaderId: 0047ef4e-8059-4dda-a40b-cf26d888a843
datanode_1          | 2022-07-27 17:15:22,433 [5a16948f-0635-4af6-ad47-d40ff1547cf8-server-thread1] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF: change Leader from null to 0047ef4e-8059-4dda-a40b-cf26d888a843 at term 2 for appendEntries, leader elected after 9718ms
datanode_1          | 2022-07-27 17:15:22,490 [5a16948f-0635-4af6-ad47-d40ff1547cf8-server-thread1] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF: set configuration 0: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|dataStream:|priority:0, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|dataStream:|priority:1, 5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|dataStream:|priority:0], old=null
datanode_1          | 2022-07-27 17:15:22,490 [5a16948f-0635-4af6-ad47-d40ff1547cf8-server-thread1] INFO segmented.SegmentedRaftLogWorker: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1          | 2022-07-27 17:15:22,496 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-29EFD5711FCF-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/de666cc0-d9ea-4d5d-8684-29efd5711fcf/current/log_inprogress_0
datanode_1          | 2022-07-27 17:15:35,290 [Command processor thread] INFO server.RaftServer: 5a16948f-0635-4af6-ad47-d40ff1547cf8: addNew group-FD3704A7A93F:[5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|priority:1] returns group-FD3704A7A93F:java.util.concurrent.CompletableFuture@3bdb1148[Not completed]
datanode_1          | 2022-07-27 17:15:35,292 [pool-22-thread-1] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8: new RaftServerImpl for group-FD3704A7A93F:[5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|priority:1] with ContainerStateMachine:uninitialized
datanode_1          | 2022-07-27 17:15:35,299 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1          | 2022-07-27 17:15:35,299 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1          | 2022-07-27 17:15:35,299 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1          | 2022-07-27 17:15:35,299 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_1          | 2022-07-27 17:15:35,299 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_1          | 2022-07-27 17:15:35,299 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_1          | 2022-07-27 17:15:35,299 [pool-22-thread-1] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F: ConfigurationManager, init=-1: [5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode_1          | 2022-07-27 17:15:35,300 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1          | 2022-07-27 17:15:35,300 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1          | 2022-07-27 17:15:35,300 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_1          | 2022-07-27 17:15:35,300 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/063cabaa-8e18-48aa-a5b0-fd3704a7a93f does not exist. Creating ...
datanode_1          | 2022-07-27 17:15:35,303 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/063cabaa-8e18-48aa-a5b0-fd3704a7a93f/in_use.lock acquired by nodename 8@032319ade833
datanode_1          | 2022-07-27 17:15:35,305 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/063cabaa-8e18-48aa-a5b0-fd3704a7a93f has been successfully formatted.
datanode_1          | 2022-07-27 17:15:35,306 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-FD3704A7A93F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1          | 2022-07-27 17:15:35,306 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_1          | 2022-07-27 17:15:35,306 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1          | 2022-07-27 17:15:35,306 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1          | 2022-07-27 17:15:35,306 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1          | 2022-07-27 17:15:35,306 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_1          | 2022-07-27 17:15:35,306 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1          | 2022-07-27 17:15:35,307 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1          | 2022-07-27 17:15:35,307 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_1          | 2022-07-27 17:15:35,307 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/063cabaa-8e18-48aa-a5b0-fd3704a7a93f
datanode_1          | 2022-07-27 17:15:35,307 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_1          | 2022-07-27 17:15:35,307 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1          | 2022-07-27 17:15:35,307 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1          | 2022-07-27 17:15:35,307 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1          | 2022-07-27 17:15:35,307 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1          | 2022-07-27 17:15:35,307 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1          | 2022-07-27 17:15:35,308 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1          | 2022-07-27 17:15:35,308 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1          | 2022-07-27 17:15:35,308 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1          | 2022-07-27 17:15:35,309 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_2          | 2022-07-27 17:14:43,759 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode_2          | 2022-07-27 17:14:43,987 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2          | 2022-07-27 17:14:44,032 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2          | 2022-07-27 17:14:44,034 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_2          | 2022-07-27 17:14:44,125 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@552fffc8{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2          | 2022-07-27 17:14:44,130 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@30adae45{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2          | 2022-07-27 17:14:44,949 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7c4a5ef2{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-12145051860340190170/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_2          | 2022-07-27 17:14:45,067 [main] INFO server.AbstractConnector: Started ServerConnector@174f0d06{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode_2          | 2022-07-27 17:14:45,083 [main] INFO server.Server: Started @39141ms
datanode_2          | 2022-07-27 17:14:45,102 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2          | 2022-07-27 17:14:45,103 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2          | 2022-07-27 17:14:45,134 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2          | 2022-07-27 17:14:45,147 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode_2          | 2022-07-27 17:14:45,492 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1786e47f] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2          | 2022-07-27 17:14:45,951 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.23.0.11:9891
datanode_2          | 2022-07-27 17:14:46,325 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_2          | 2022-07-27 17:14:48,758 [EndpointStateMachine task thread for recon/172.23.0.11:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.23.0.11:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2          | 2022-07-27 17:14:48,762 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2          | 2022-07-27 17:14:49,759 [EndpointStateMachine task thread for recon/172.23.0.11:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.23.0.11:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2          | 2022-07-27 17:14:49,763 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2          | 2022-07-27 17:14:50,760 [EndpointStateMachine task thread for recon/172.23.0.11:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.23.0.11:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2          | 2022-07-27 17:14:50,765 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2          | 2022-07-27 17:14:51,766 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2          | 2022-07-27 17:14:52,767 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2          | 2022-07-27 17:14:53,768 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2          | 2022-07-27 17:14:54,769 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2          | 2022-07-27 17:14:55,770 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2          | 2022-07-27 17:14:55,785 [EndpointStateMachine task thread for recon/172.23.0.11:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode_2          | java.net.SocketTimeoutException: Call From a8e8226775b7/172.23.0.6 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.6:34796 remote=recon/172.23.0.11:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_2          | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_2          | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_2          | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_2          | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_2          | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode_2          | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
datanode_2          | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
datanode_2          | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
datanode_2          | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
datanode_2          | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
datanode_2          | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
datanode_2          | 	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
datanode_2          | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_2          | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_2          | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
datanode_2          | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
datanode_2          | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2          | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1          | 2022-07-27 17:15:35,309 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1          | 2022-07-27 17:15:35,309 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1          | 2022-07-27 17:15:35,309 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1          | 2022-07-27 17:15:35,309 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1          | 2022-07-27 17:15:35,309 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1          | 2022-07-27 17:15:35,309 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1          | 2022-07-27 17:15:35,309 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1          | 2022-07-27 17:15:35,309 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1          | 2022-07-27 17:15:35,309 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_1          | 2022-07-27 17:15:35,311 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1          | 2022-07-27 17:15:35,311 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_1          | 2022-07-27 17:15:35,311 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_1          | 2022-07-27 17:15:35,311 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_1          | 2022-07-27 17:15:35,311 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_1          | 2022-07-27 17:15:35,311 [pool-22-thread-1] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F: start as a follower, conf=-1: [5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|priority:1], old=null
datanode_1          | 2022-07-27 17:15:35,311 [pool-22-thread-1] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1          | 2022-07-27 17:15:35,311 [pool-22-thread-1] INFO impl.RoleInfo: 5a16948f-0635-4af6-ad47-d40ff1547cf8: start 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-FollowerState
datanode_1          | 2022-07-27 17:15:35,323 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FD3704A7A93F,id=5a16948f-0635-4af6-ad47-d40ff1547cf8
datanode_1          | 2022-07-27 17:15:35,341 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=063cabaa-8e18-48aa-a5b0-fd3704a7a93f
datanode_1          | 2022-07-27 17:15:35,342 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=063cabaa-8e18-48aa-a5b0-fd3704a7a93f.
datanode_1          | 2022-07-27 17:15:40,326 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-FollowerState] INFO impl.FollowerState: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5014611052ns, electionTimeout:5002ms
datanode_1          | 2022-07-27 17:15:40,326 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-FollowerState] INFO impl.RoleInfo: 5a16948f-0635-4af6-ad47-d40ff1547cf8: shutdown 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-FollowerState
datanode_1          | 2022-07-27 17:15:40,327 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-FollowerState] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1          | 2022-07-27 17:15:40,327 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_1          | 2022-07-27 17:15:40,327 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-FollowerState] INFO impl.RoleInfo: 5a16948f-0635-4af6-ad47-d40ff1547cf8: start 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-LeaderElection2
datanode_1          | 2022-07-27 17:15:40,330 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-LeaderElection2] INFO impl.LeaderElection: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|priority:1], old=null
datanode_1          | 2022-07-27 17:15:40,331 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-LeaderElection2] INFO impl.LeaderElection: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-LeaderElection2 ELECTION round 0: result PASSED (term=1)
datanode_1          | 2022-07-27 17:15:40,332 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-LeaderElection2] INFO impl.RoleInfo: 5a16948f-0635-4af6-ad47-d40ff1547cf8: shutdown 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-LeaderElection2
datanode_1          | 2022-07-27 17:15:40,332 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-LeaderElection2] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1          | 2022-07-27 17:15:40,332 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-FD3704A7A93F with new leaderId: 5a16948f-0635-4af6-ad47-d40ff1547cf8
datanode_1          | 2022-07-27 17:15:40,341 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-LeaderElection2] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F: change Leader from null to 5a16948f-0635-4af6-ad47-d40ff1547cf8 at term 1 for becomeLeader, leader elected after 5026ms
datanode_1          | 2022-07-27 17:15:40,343 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1          | 2022-07-27 17:15:40,347 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1          | 2022-07-27 17:15:40,356 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode_1          | 2022-07-27 17:15:40,365 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1          | 2022-07-27 17:15:40,365 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1          | 2022-07-27 17:15:40,367 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1          | 2022-07-27 17:15:40,374 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1          | 2022-07-27 17:15:40,378 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode_2          | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2          | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_2          | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.6:34796 remote=recon/172.23.0.11:9891]
datanode_2          | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_2          | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_2          | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_2          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_2          | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_2          | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_2          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2          | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
datanode_2          | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_2          | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
datanode_2          | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
datanode_2          | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
datanode_2          | 2022-07-27 17:15:00,783 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_2          | java.net.SocketTimeoutException: Call From a8e8226775b7/172.23.0.6 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.6:45300 remote=scm/172.23.0.4:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_2          | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_2          | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_2          | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_2          | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_2          | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode_2          | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
datanode_2          | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
datanode_2          | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
datanode_2          | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
datanode_2          | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
datanode_2          | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
datanode_2          | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
datanode_2          | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_2          | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_2          | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
datanode_2          | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
datanode_2          | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2          | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2          | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2          | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_2          | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.6:45300 remote=scm/172.23.0.4:9861]
datanode_2          | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_2          | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_2          | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_2          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_2          | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_2          | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_2          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2          | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
datanode_2          | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_2          | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
datanode_2          | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
datanode_2          | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
datanode_2          | 2022-07-27 17:15:01,563 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode_2          | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode_2          | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode_2          | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode_2          | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
datanode_2          | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
datanode_2          | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode_2          | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:660)
datanode_2          | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:298)
datanode_2          | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:493)
datanode_2          | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_2          | Caused by: java.util.concurrent.TimeoutException
datanode_2          | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode_2          | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
datanode_2          | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2          | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_2          | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2          | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2          | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2          | 	... 1 more
datanode_2          | 2022-07-27 17:15:01,762 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-7d45909c-9fcd-4dc9-be34-cfa80db7825a/DS-c5a15076-0a2c-4bef-ab90-7723a2b3c64b/container.db for volume DS-c5a15076-0a2c-4bef-ab90-7723a2b3c64b
datanode_3          | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode_3          | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3          | 2022-07-27 17:14:14,192 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3          | /************************************************************
datanode_3          | STARTUP_MSG: Starting HddsDatanodeService
datanode_3          | STARTUP_MSG:   host = be9667654851/172.23.0.10
datanode_3          | STARTUP_MSG:   args = []
datanode_3          | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode_2          | 2022-07-27 17:15:01,794 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-7d45909c-9fcd-4dc9-be34-cfa80db7825a/DS-c5a15076-0a2c-4bef-ab90-7723a2b3c64b/container.db for volume DS-c5a15076-0a2c-4bef-ab90-7723a2b3c64b
datanode_2          | 2022-07-27 17:15:01,808 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2          | 2022-07-27 17:15:01,823 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_2          | 2022-07-27 17:15:02,240 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 0047ef4e-8059-4dda-a40b-cf26d888a843
datanode_2          | 2022-07-27 17:15:02,359 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO server.RaftServer: 0047ef4e-8059-4dda-a40b-cf26d888a843: start RPC server
datanode_2          | 2022-07-27 17:15:02,365 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO server.GrpcService: 0047ef4e-8059-4dda-a40b-cf26d888a843: GrpcService started, listening on 9856
datanode_2          | 2022-07-27 17:15:02,368 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO server.GrpcService: 0047ef4e-8059-4dda-a40b-cf26d888a843: GrpcService started, listening on 9857
datanode_2          | 2022-07-27 17:15:02,374 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO server.GrpcService: 0047ef4e-8059-4dda-a40b-cf26d888a843: GrpcService started, listening on 9858
datanode_2          | 2022-07-27 17:15:02,385 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$344/0x00000008404f6840@609872ca] INFO util.JvmPauseMonitor: JvmPauseMonitor-0047ef4e-8059-4dda-a40b-cf26d888a843: Started
datanode_2          | 2022-07-27 17:15:02,393 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 0047ef4e-8059-4dda-a40b-cf26d888a843 is started using port 9858 for RATIS
datanode_2          | 2022-07-27 17:15:02,396 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 0047ef4e-8059-4dda-a40b-cf26d888a843 is started using port 9857 for RATIS_ADMIN
datanode_2          | 2022-07-27 17:15:02,396 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 0047ef4e-8059-4dda-a40b-cf26d888a843 is started using port 9856 for RATIS_SERVER
datanode_2          | 2022-07-27 17:15:06,752 [Command processor thread] INFO server.RaftServer: 0047ef4e-8059-4dda-a40b-cf26d888a843: addNew group-78C2755A5DDC:[b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:1, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:0] returns group-78C2755A5DDC:java.util.concurrent.CompletableFuture@658fba87[Not completed]
datanode_2          | 2022-07-27 17:15:06,862 [pool-22-thread-1] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843: new RaftServerImpl for group-78C2755A5DDC:[b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:1, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:0] with ContainerStateMachine:uninitialized
datanode_2          | 2022-07-27 17:15:06,884 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2          | 2022-07-27 17:15:06,898 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2          | 2022-07-27 17:15:06,898 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2          | 2022-07-27 17:15:06,898 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_2          | 2022-07-27 17:15:06,898 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_2          | 2022-07-27 17:15:06,899 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_2          | 2022-07-27 17:15:06,939 [pool-22-thread-1] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC: ConfigurationManager, init=-1: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:1, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode_2          | 2022-07-27 17:15:06,939 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2          | 2022-07-27 17:15:07,008 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2          | 2022-07-27 17:15:07,009 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_2          | 2022-07-27 17:15:07,018 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/ee453f3e-2788-418a-bfda-78c2755a5ddc does not exist. Creating ...
datanode_2          | 2022-07-27 17:15:07,054 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/ee453f3e-2788-418a-bfda-78c2755a5ddc/in_use.lock acquired by nodename 7@a8e8226775b7
datanode_2          | 2022-07-27 17:15:07,094 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/ee453f3e-2788-418a-bfda-78c2755a5ddc has been successfully formatted.
datanode_2          | 2022-07-27 17:15:07,304 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-78C2755A5DDC: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2          | 2022-07-27 17:15:07,323 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_2          | 2022-07-27 17:15:07,354 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2          | 2022-07-27 17:15:07,470 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2          | 2022-07-27 17:15:07,471 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2          | 2022-07-27 17:15:07,472 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_2          | 2022-07-27 17:15:07,535 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2          | 2022-07-27 17:15:07,606 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2          | 2022-07-27 17:15:07,608 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_2          | 2022-07-27 17:15:07,633 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/ee453f3e-2788-418a-bfda-78c2755a5ddc
datanode_2          | 2022-07-27 17:15:07,652 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_2          | 2022-07-27 17:15:07,679 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2          | 2022-07-27 17:15:07,682 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode_3          | STARTUP_MSG:   build = https://github.com/apache/ozone/9f188e38b2f4663af1a9169fb7f63dfe156555a0 ; compiled by 'runner' on 2022-07-27T16:18Z
datanode_3          | STARTUP_MSG:   java = 11.0.14.1
datanode_3          | ************************************************************/
datanode_3          | 2022-07-27 17:14:14,243 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3          | 2022-07-27 17:14:14,550 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3          | 2022-07-27 17:14:15,304 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3          | 2022-07-27 17:14:16,356 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3          | 2022-07-27 17:14:16,363 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3          | 2022-07-27 17:14:17,183 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:be9667654851 ip:172.23.0.10
datanode_3          | 2022-07-27 17:14:19,406 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode_3          | 2022-07-27 17:14:20,483 [main] INFO reflections.Reflections: Reflections took 877 ms to scan 2 urls, producing 89 keys and 198 values 
datanode_3          | 2022-07-27 17:14:21,523 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
datanode_3          | 2022-07-27 17:14:22,973 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_3          | 2022-07-27 17:14:23,115 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
datanode_3          | 2022-07-27 17:14:23,122 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3          | 2022-07-27 17:14:23,144 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3          | 2022-07-27 17:14:23,394 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3          | 2022-07-27 17:14:23,869 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3          | 2022-07-27 17:14:23,898 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode_3          | 2022-07-27 17:14:23,943 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode_3          | 2022-07-27 17:14:23,947 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode_3          | 2022-07-27 17:14:23,951 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode_3          | 2022-07-27 17:14:24,213 [Thread-7] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_3          | 2022-07-27 17:14:24,279 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_3          | 2022-07-27 17:14:33,292 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode_3          | 2022-07-27 17:14:34,188 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3          | 2022-07-27 17:14:34,621 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode_3          | 2022-07-27 17:14:35,915 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode_3          | 2022-07-27 17:14:35,992 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode_3          | 2022-07-27 17:14:35,992 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode_3          | 2022-07-27 17:14:35,992 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_3          | 2022-07-27 17:14:35,993 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3          | 2022-07-27 17:14:35,993 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_3          | 2022-07-27 17:14:36,036 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3          | 2022-07-27 17:14:36,109 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode_3          | 2022-07-27 17:14:36,109 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode_3          | 2022-07-27 17:14:38,420 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode_3          | 2022-07-27 17:14:38,445 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode_3          | 2022-07-27 17:14:38,459 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode_3          | 2022-07-27 17:14:38,464 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_3          | 2022-07-27 17:14:38,467 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_3          | 2022-07-27 17:14:38,491 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3          | 2022-07-27 17:14:38,721 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode_3          | 2022-07-27 17:14:39,844 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3          | 2022-07-27 17:14:39,968 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_3          | 2022-07-27 17:14:40,189 [main] INFO util.log: Logging initialized @36605ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3          | 2022-07-27 17:14:41,092 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3          | 2022-07-27 17:14:41,099 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3          | 2022-07-27 17:14:41,196 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3          | 2022-07-27 17:14:41,209 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_3          | 2022-07-27 17:14:41,225 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_3          | 2022-07-27 17:14:41,230 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_3          | 2022-07-27 17:14:41,571 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3          | 2022-07-27 17:14:41,573 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode_3          | 2022-07-27 17:14:41,868 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3          | 2022-07-27 17:14:41,875 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_3          | 2022-07-27 17:14:41,892 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_3          | 2022-07-27 17:14:42,025 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@552fffc8{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3          | 2022-07-27 17:14:42,040 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@30adae45{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3          | 2022-07-27 17:14:42,888 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7c4a5ef2{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-9594104194302557368/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_3          | 2022-07-27 17:14:42,966 [main] INFO server.AbstractConnector: Started ServerConnector@174f0d06{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode_3          | 2022-07-27 17:14:42,966 [main] INFO server.Server: Started @39382ms
datanode_3          | 2022-07-27 17:14:42,990 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3          | 2022-07-27 17:14:42,990 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3          | 2022-07-27 17:14:42,995 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_3          | 2022-07-27 17:14:43,012 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode_3          | 2022-07-27 17:14:43,184 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@319eb667] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3          | 2022-07-27 17:14:44,035 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.23.0.11:9891
datanode_3          | 2022-07-27 17:14:44,427 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_3          | 2022-07-27 17:14:46,644 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3          | 2022-07-27 17:14:46,645 [EndpointStateMachine task thread for recon/172.23.0.11:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.23.0.11:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3          | 2022-07-27 17:14:47,645 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3          | 2022-07-27 17:14:47,646 [EndpointStateMachine task thread for recon/172.23.0.11:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.23.0.11:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3          | 2022-07-27 17:14:48,647 [EndpointStateMachine task thread for recon/172.23.0.11:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.23.0.11:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3          | 2022-07-27 17:14:48,647 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3          | 2022-07-27 17:14:49,648 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3          | 2022-07-27 17:14:49,648 [EndpointStateMachine task thread for recon/172.23.0.11:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.23.0.11:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3          | 2022-07-27 17:14:50,649 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3          | 2022-07-27 17:14:50,650 [EndpointStateMachine task thread for recon/172.23.0.11:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.23.0.11:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3          | 2022-07-27 17:14:51,650 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3          | 2022-07-27 17:14:52,651 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3          | 2022-07-27 17:14:53,652 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3          | 2022-07-27 17:14:54,653 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3          | 2022-07-27 17:14:55,654 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3          | 2022-07-27 17:14:55,669 [EndpointStateMachine task thread for recon/172.23.0.11:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode_3          | java.net.SocketTimeoutException: Call From be9667654851/172.23.0.10 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.10:43112 remote=recon/172.23.0.11:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_3          | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_3          | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_3          | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3          | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_3          | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode_3          | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
datanode_3          | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
datanode_3          | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
datanode_1          | 2022-07-27 17:15:40,382 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-LeaderElection2] INFO impl.RoleInfo: 5a16948f-0635-4af6-ad47-d40ff1547cf8: start 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-LeaderStateImpl
datanode_1          | 2022-07-27 17:15:40,393 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1          | 2022-07-27 17:15:40,397 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/063cabaa-8e18-48aa-a5b0-fd3704a7a93f/current/log_inprogress_0
datanode_1          | 2022-07-27 17:15:40,404 [5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F-LeaderElection2] INFO server.RaftServer$Division: 5a16948f-0635-4af6-ad47-d40ff1547cf8@group-FD3704A7A93F: set configuration 0: [5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|dataStream:|priority:1], old=null
datanode_3          | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
datanode_3          | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
datanode_3          | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
datanode_3          | 	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
datanode_3          | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_3          | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_3          | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
datanode_3          | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
datanode_3          | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3          | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3          | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3          | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_3          | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.10:43112 remote=recon/172.23.0.11:9891]
datanode_3          | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_3          | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_3          | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_3          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_3          | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_3          | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_3          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3          | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
datanode_3          | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_3          | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
datanode_3          | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
datanode_3          | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
datanode_3          | 2022-07-27 17:15:00,664 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_3          | java.net.SocketTimeoutException: Call From be9667654851/172.23.0.10 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.10:34542 remote=scm/172.23.0.4:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_3          | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_3          | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_3          | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3          | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_3          | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode_3          | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
datanode_3          | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
datanode_3          | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
datanode_3          | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
datanode_3          | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
datanode_3          | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
datanode_3          | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
datanode_3          | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_3          | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_3          | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
datanode_3          | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
datanode_3          | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3          | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3          | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3          | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_3          | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.10:34542 remote=scm/172.23.0.4:9861]
datanode_3          | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_3          | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_3          | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_3          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_3          | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_3          | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_3          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3          | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
datanode_3          | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_3          | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
datanode_3          | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
datanode_3          | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
datanode_3          | 2022-07-27 17:15:01,715 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-7d45909c-9fcd-4dc9-be34-cfa80db7825a/DS-73882b85-0c8d-4a2a-9a9f-33770f758f46/container.db for volume DS-73882b85-0c8d-4a2a-9a9f-33770f758f46
datanode_3          | 2022-07-27 17:15:01,751 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-7d45909c-9fcd-4dc9-be34-cfa80db7825a/DS-73882b85-0c8d-4a2a-9a9f-33770f758f46/container.db for volume DS-73882b85-0c8d-4a2a-9a9f-33770f758f46
datanode_3          | 2022-07-27 17:15:01,759 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_3          | 2022-07-27 17:15:01,761 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_3          | 2022-07-27 17:15:02,145 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis b50d7a6b-da1f-4bca-b673-015544dce0bd
datanode_3          | 2022-07-27 17:15:02,315 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO server.RaftServer: b50d7a6b-da1f-4bca-b673-015544dce0bd: start RPC server
datanode_2          | 2022-07-27 17:15:07,688 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2          | 2022-07-27 17:15:07,693 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2          | 2022-07-27 17:15:07,695 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2          | 2022-07-27 17:15:07,703 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2          | 2022-07-27 17:15:07,704 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2          | 2022-07-27 17:15:07,768 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2          | 2022-07-27 17:15:07,782 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_2          | 2022-07-27 17:15:07,788 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2          | 2022-07-27 17:15:07,839 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2          | 2022-07-27 17:15:07,840 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2          | 2022-07-27 17:15:07,853 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2          | 2022-07-27 17:15:07,860 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2          | 2022-07-27 17:15:07,860 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2          | 2022-07-27 17:15:07,861 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2          | 2022-07-27 17:15:07,863 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2          | 2022-07-27 17:15:07,865 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_2          | 2022-07-27 17:15:08,030 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2          | 2022-07-27 17:15:08,055 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_2          | 2022-07-27 17:15:08,057 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_2          | 2022-07-27 17:15:08,062 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_2          | 2022-07-27 17:15:08,065 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_2          | 2022-07-27 17:15:08,076 [pool-22-thread-1] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC: start as a follower, conf=-1: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:1, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:0], old=null
datanode_2          | 2022-07-27 17:15:08,092 [pool-22-thread-1] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2          | 2022-07-27 17:15:08,093 [pool-22-thread-1] INFO impl.RoleInfo: 0047ef4e-8059-4dda-a40b-cf26d888a843: start 0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC-FollowerState
datanode_2          | 2022-07-27 17:15:08,146 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-78C2755A5DDC,id=0047ef4e-8059-4dda-a40b-cf26d888a843
datanode_2          | 2022-07-27 17:15:08,362 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=ee453f3e-2788-418a-bfda-78c2755a5ddc
datanode_2          | 2022-07-27 17:15:11,901 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=ee453f3e-2788-418a-bfda-78c2755a5ddc.
datanode_2          | 2022-07-27 17:15:11,910 [Command processor thread] INFO server.RaftServer: 0047ef4e-8059-4dda-a40b-cf26d888a843: addNew group-29EFD5711FCF:[b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:0, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:1, 5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|priority:0] returns group-29EFD5711FCF:java.util.concurrent.CompletableFuture@40136b2c[Not completed]
datanode_2          | 2022-07-27 17:15:11,935 [pool-22-thread-1] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843: new RaftServerImpl for group-29EFD5711FCF:[b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:0, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:1, 5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|priority:0] with ContainerStateMachine:uninitialized
datanode_2          | 2022-07-27 17:15:11,939 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2          | 2022-07-27 17:15:11,939 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2          | 2022-07-27 17:15:11,940 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2          | 2022-07-27 17:15:11,940 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_2          | 2022-07-27 17:15:11,940 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_2          | 2022-07-27 17:15:11,940 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_2          | 2022-07-27 17:15:11,941 [pool-22-thread-1] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF: ConfigurationManager, init=-1: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:0, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:1, 5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode_2          | 2022-07-27 17:15:11,941 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2          | 2022-07-27 17:15:11,941 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2          | 2022-07-27 17:15:11,942 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_2          | 2022-07-27 17:15:11,942 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/de666cc0-d9ea-4d5d-8684-29efd5711fcf does not exist. Creating ...
datanode_2          | 2022-07-27 17:15:11,946 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/de666cc0-d9ea-4d5d-8684-29efd5711fcf/in_use.lock acquired by nodename 7@a8e8226775b7
datanode_2          | 2022-07-27 17:15:11,951 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/de666cc0-d9ea-4d5d-8684-29efd5711fcf has been successfully formatted.
datanode_2          | 2022-07-27 17:15:11,952 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-29EFD5711FCF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2          | 2022-07-27 17:15:11,953 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_2          | 2022-07-27 17:15:11,953 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2          | 2022-07-27 17:15:11,953 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2          | 2022-07-27 17:15:11,953 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2          | 2022-07-27 17:15:11,954 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_2          | 2022-07-27 17:15:11,954 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2          | 2022-07-27 17:15:11,954 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2          | 2022-07-27 17:15:11,954 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_2          | 2022-07-27 17:15:11,955 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/de666cc0-d9ea-4d5d-8684-29efd5711fcf
datanode_2          | 2022-07-27 17:15:11,955 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_2          | 2022-07-27 17:15:11,956 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2          | 2022-07-27 17:15:11,959 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2          | 2022-07-27 17:15:11,959 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2          | 2022-07-27 17:15:11,959 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2          | 2022-07-27 17:15:11,959 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2          | 2022-07-27 17:15:11,959 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2          | 2022-07-27 17:15:11,959 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2          | 2022-07-27 17:15:11,987 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2          | 2022-07-27 17:15:11,988 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_2          | 2022-07-27 17:15:11,989 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2          | 2022-07-27 17:15:11,991 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2          | 2022-07-27 17:15:11,994 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2          | 2022-07-27 17:15:11,996 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2          | 2022-07-27 17:15:12,001 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2          | 2022-07-27 17:15:12,007 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2          | 2022-07-27 17:15:12,007 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2          | 2022-07-27 17:15:12,007 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2          | 2022-07-27 17:15:12,007 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_2          | 2022-07-27 17:15:12,008 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2          | 2022-07-27 17:15:12,026 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_2          | 2022-07-27 17:15:12,026 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_2          | 2022-07-27 17:15:12,026 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_2          | 2022-07-27 17:15:12,026 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_2          | 2022-07-27 17:15:12,026 [pool-22-thread-1] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF: start as a follower, conf=-1: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:0, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:1, 5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|priority:0], old=null
datanode_2          | 2022-07-27 17:15:12,026 [pool-22-thread-1] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2          | 2022-07-27 17:15:12,026 [pool-22-thread-1] INFO impl.RoleInfo: 0047ef4e-8059-4dda-a40b-cf26d888a843: start 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-FollowerState
datanode_2          | 2022-07-27 17:15:12,027 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-29EFD5711FCF,id=0047ef4e-8059-4dda-a40b-cf26d888a843
datanode_2          | 2022-07-27 17:15:12,033 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=de666cc0-d9ea-4d5d-8684-29efd5711fcf
datanode_2          | 2022-07-27 17:15:12,319 [grpc-default-executor-1] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC: receive requestVote(ELECTION, 2750dc88-6529-455f-a3a5-c6a6089a5bfe, group-78C2755A5DDC, 1, (t:0, i:0))
datanode_2          | 2022-07-27 17:15:12,335 [grpc-default-executor-1] INFO impl.VoteContext: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC-FOLLOWER: accept ELECTION from 2750dc88-6529-455f-a3a5-c6a6089a5bfe: our priority 0 <= candidate's priority 0
datanode_2          | 2022-07-27 17:15:12,336 [grpc-default-executor-1] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:2750dc88-6529-455f-a3a5-c6a6089a5bfe
datanode_2          | 2022-07-27 17:15:12,337 [grpc-default-executor-1] INFO impl.RoleInfo: 0047ef4e-8059-4dda-a40b-cf26d888a843: shutdown 0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC-FollowerState
datanode_2          | 2022-07-27 17:15:12,339 [grpc-default-executor-1] INFO impl.RoleInfo: 0047ef4e-8059-4dda-a40b-cf26d888a843: start 0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC-FollowerState
datanode_2          | 2022-07-27 17:15:12,339 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC-FollowerState] INFO impl.FollowerState: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC-FollowerState was interrupted
datanode_2          | 2022-07-27 17:15:12,385 [grpc-default-executor-1] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC replies to ELECTION vote request: 2750dc88-6529-455f-a3a5-c6a6089a5bfe<-0047ef4e-8059-4dda-a40b-cf26d888a843#0:OK-t1. Peer's state: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC:t1, leader=null, voted=2750dc88-6529-455f-a3a5-c6a6089a5bfe, raftlog=0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC-SegmentedRaftLog:OPENED:c-1, conf=-1: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:1, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:0], old=null
datanode_2          | 2022-07-27 17:15:12,480 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=de666cc0-d9ea-4d5d-8684-29efd5711fcf.
datanode_2          | 2022-07-27 17:15:12,481 [Command processor thread] INFO server.RaftServer: 0047ef4e-8059-4dda-a40b-cf26d888a843: addNew group-03BDABE80F24:[0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:1] returns group-03BDABE80F24:java.util.concurrent.CompletableFuture@3f1ba4c8[Not completed]
datanode_2          | 2022-07-27 17:15:12,483 [pool-22-thread-1] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843: new RaftServerImpl for group-03BDABE80F24:[0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:1] with ContainerStateMachine:uninitialized
datanode_2          | 2022-07-27 17:15:12,484 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2          | 2022-07-27 17:15:12,484 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2          | 2022-07-27 17:15:12,484 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2          | 2022-07-27 17:15:12,485 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_2          | 2022-07-27 17:15:12,487 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_2          | 2022-07-27 17:15:12,491 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_2          | 2022-07-27 17:15:12,492 [pool-22-thread-1] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24: ConfigurationManager, init=-1: [0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode_2          | 2022-07-27 17:15:12,492 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2          | 2022-07-27 17:15:12,492 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2          | 2022-07-27 17:15:12,493 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_2          | 2022-07-27 17:15:12,493 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/e1b362da-60c0-4653-994d-03bdabe80f24 does not exist. Creating ...
datanode_2          | 2022-07-27 17:15:12,495 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/e1b362da-60c0-4653-994d-03bdabe80f24/in_use.lock acquired by nodename 7@a8e8226775b7
datanode_2          | 2022-07-27 17:15:12,497 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/e1b362da-60c0-4653-994d-03bdabe80f24 has been successfully formatted.
datanode_2          | 2022-07-27 17:15:12,502 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-03BDABE80F24: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2          | 2022-07-27 17:15:12,502 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_2          | 2022-07-27 17:15:12,502 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2          | 2022-07-27 17:15:12,502 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2          | 2022-07-27 17:15:12,502 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2          | 2022-07-27 17:15:12,502 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_2          | 2022-07-27 17:15:12,507 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2          | 2022-07-27 17:15:12,508 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2          | 2022-07-27 17:15:12,509 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_2          | 2022-07-27 17:15:12,509 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/e1b362da-60c0-4653-994d-03bdabe80f24
datanode_2          | 2022-07-27 17:15:12,510 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_2          | 2022-07-27 17:15:12,510 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2          | 2022-07-27 17:15:12,513 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2          | 2022-07-27 17:15:12,514 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2          | 2022-07-27 17:15:12,515 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2          | 2022-07-27 17:15:12,515 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2          | 2022-07-27 17:15:12,515 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2          | 2022-07-27 17:15:12,517 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2          | 2022-07-27 17:15:12,518 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2          | 2022-07-27 17:15:12,522 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_2          | 2022-07-27 17:15:12,523 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2          | 2022-07-27 17:15:12,523 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2          | 2022-07-27 17:15:12,535 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2          | 2022-07-27 17:15:12,535 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2          | 2022-07-27 17:15:12,536 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2          | 2022-07-27 17:15:12,537 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2          | 2022-07-27 17:15:12,537 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3          | 2022-07-27 17:15:02,330 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO server.GrpcService: b50d7a6b-da1f-4bca-b673-015544dce0bd: GrpcService started, listening on 9856
datanode_3          | 2022-07-27 17:15:02,335 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO server.GrpcService: b50d7a6b-da1f-4bca-b673-015544dce0bd: GrpcService started, listening on 9857
datanode_3          | 2022-07-27 17:15:02,336 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO server.GrpcService: b50d7a6b-da1f-4bca-b673-015544dce0bd: GrpcService started, listening on 9858
datanode_3          | 2022-07-27 17:15:02,346 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis b50d7a6b-da1f-4bca-b673-015544dce0bd is started using port 9858 for RATIS
datanode_3          | 2022-07-27 17:15:02,346 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis b50d7a6b-da1f-4bca-b673-015544dce0bd is started using port 9857 for RATIS_ADMIN
datanode_3          | 2022-07-27 17:15:02,346 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis b50d7a6b-da1f-4bca-b673-015544dce0bd is started using port 9856 for RATIS_SERVER
datanode_3          | 2022-07-27 17:15:02,361 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$343/0x0000000840501440@24d44fe3] INFO util.JvmPauseMonitor: JvmPauseMonitor-b50d7a6b-da1f-4bca-b673-015544dce0bd: Started
datanode_3          | 2022-07-27 17:15:06,460 [Command processor thread] INFO server.RaftServer: b50d7a6b-da1f-4bca-b673-015544dce0bd: addNew group-78C2755A5DDC:[b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:1, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:0] returns group-78C2755A5DDC:java.util.concurrent.CompletableFuture@604f3c6f[Not completed]
datanode_3          | 2022-07-27 17:15:06,547 [pool-22-thread-1] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd: new RaftServerImpl for group-78C2755A5DDC:[b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:1, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:0] with ContainerStateMachine:uninitialized
datanode_3          | 2022-07-27 17:15:06,549 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3          | 2022-07-27 17:15:06,549 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3          | 2022-07-27 17:15:06,549 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3          | 2022-07-27 17:15:06,550 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_3          | 2022-07-27 17:15:06,550 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_3          | 2022-07-27 17:15:06,553 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_3          | 2022-07-27 17:15:06,599 [pool-22-thread-1] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC: ConfigurationManager, init=-1: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:1, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode_3          | 2022-07-27 17:15:06,599 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3          | 2022-07-27 17:15:06,627 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3          | 2022-07-27 17:15:06,651 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_3          | 2022-07-27 17:15:06,653 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/ee453f3e-2788-418a-bfda-78c2755a5ddc does not exist. Creating ...
datanode_3          | 2022-07-27 17:15:06,688 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/ee453f3e-2788-418a-bfda-78c2755a5ddc/in_use.lock acquired by nodename 7@be9667654851
datanode_3          | 2022-07-27 17:15:06,720 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/ee453f3e-2788-418a-bfda-78c2755a5ddc has been successfully formatted.
datanode_3          | 2022-07-27 17:15:06,880 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-78C2755A5DDC: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3          | 2022-07-27 17:15:06,882 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_3          | 2022-07-27 17:15:06,906 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3          | 2022-07-27 17:15:06,973 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3          | 2022-07-27 17:15:06,991 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3          | 2022-07-27 17:15:06,992 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_3          | 2022-07-27 17:15:07,067 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3          | 2022-07-27 17:15:07,116 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3          | 2022-07-27 17:15:07,117 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_3          | 2022-07-27 17:15:07,143 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/ee453f3e-2788-418a-bfda-78c2755a5ddc
datanode_3          | 2022-07-27 17:15:07,144 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_3          | 2022-07-27 17:15:07,155 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3          | 2022-07-27 17:15:07,169 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3          | 2022-07-27 17:15:07,176 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3          | 2022-07-27 17:15:07,179 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3          | 2022-07-27 17:15:07,182 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3          | 2022-07-27 17:15:07,187 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3          | 2022-07-27 17:15:07,188 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3          | 2022-07-27 17:15:07,257 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3          | 2022-07-27 17:15:07,258 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_4          | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode_4          | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_4          | 2022-07-27 17:14:16,053 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_4          | /************************************************************
datanode_4          | STARTUP_MSG: Starting HddsDatanodeService
datanode_4          | STARTUP_MSG:   host = caa94ab9ee1a/172.23.0.13
datanode_4          | STARTUP_MSG:   args = []
datanode_4          | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode_3          | 2022-07-27 17:15:07,259 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3          | 2022-07-27 17:15:07,282 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3          | 2022-07-27 17:15:07,291 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3          | 2022-07-27 17:15:07,302 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3          | 2022-07-27 17:15:07,315 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3          | 2022-07-27 17:15:07,317 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3          | 2022-07-27 17:15:07,318 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3          | 2022-07-27 17:15:07,331 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3          | 2022-07-27 17:15:07,338 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_3          | 2022-07-27 17:15:07,562 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3          | 2022-07-27 17:15:07,585 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_3          | 2022-07-27 17:15:07,586 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_3          | 2022-07-27 17:15:07,588 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_3          | 2022-07-27 17:15:07,588 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_3          | 2022-07-27 17:15:07,589 [pool-22-thread-1] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC: start as a follower, conf=-1: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:1, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:0], old=null
datanode_3          | 2022-07-27 17:15:07,592 [pool-22-thread-1] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3          | 2022-07-27 17:15:07,593 [pool-22-thread-1] INFO impl.RoleInfo: b50d7a6b-da1f-4bca-b673-015544dce0bd: start b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-FollowerState
datanode_3          | 2022-07-27 17:15:07,619 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-78C2755A5DDC,id=b50d7a6b-da1f-4bca-b673-015544dce0bd
datanode_3          | 2022-07-27 17:15:07,715 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=ee453f3e-2788-418a-bfda-78c2755a5ddc
datanode_3          | 2022-07-27 17:15:11,131 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=ee453f3e-2788-418a-bfda-78c2755a5ddc.
datanode_3          | 2022-07-27 17:15:11,132 [Command processor thread] INFO server.RaftServer: b50d7a6b-da1f-4bca-b673-015544dce0bd: addNew group-152FBED2C6FC:[b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:1] returns group-152FBED2C6FC:java.util.concurrent.CompletableFuture@161f5f4c[Not completed]
datanode_3          | 2022-07-27 17:15:11,137 [pool-22-thread-1] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd: new RaftServerImpl for group-152FBED2C6FC:[b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:1] with ContainerStateMachine:uninitialized
datanode_3          | 2022-07-27 17:15:11,149 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3          | 2022-07-27 17:15:11,152 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3          | 2022-07-27 17:15:11,153 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3          | 2022-07-27 17:15:11,153 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_3          | 2022-07-27 17:15:11,153 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_3          | 2022-07-27 17:15:11,153 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_3          | 2022-07-27 17:15:11,154 [pool-22-thread-1] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC: ConfigurationManager, init=-1: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode_3          | 2022-07-27 17:15:11,154 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3          | 2022-07-27 17:15:11,159 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3          | 2022-07-27 17:15:11,160 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_3          | 2022-07-27 17:15:11,160 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/ba79c91e-c001-4819-a859-152fbed2c6fc does not exist. Creating ...
datanode_3          | 2022-07-27 17:15:11,167 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/ba79c91e-c001-4819-a859-152fbed2c6fc/in_use.lock acquired by nodename 7@be9667654851
datanode_3          | 2022-07-27 17:15:11,203 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/ba79c91e-c001-4819-a859-152fbed2c6fc has been successfully formatted.
datanode_3          | 2022-07-27 17:15:11,207 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-152FBED2C6FC: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3          | 2022-07-27 17:15:11,216 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_3          | 2022-07-27 17:15:11,224 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3          | 2022-07-27 17:15:11,224 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3          | 2022-07-27 17:15:11,224 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3          | 2022-07-27 17:15:11,225 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_3          | 2022-07-27 17:15:11,226 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3          | 2022-07-27 17:15:11,244 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3          | 2022-07-27 17:15:11,249 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_5          | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode_5          | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_5          | 2022-07-27 17:14:15,755 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_5          | /************************************************************
datanode_5          | STARTUP_MSG: Starting HddsDatanodeService
datanode_5          | STARTUP_MSG:   host = 48d5efc1923c/172.23.0.12
datanode_5          | STARTUP_MSG:   args = []
datanode_5          | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode_3          | 2022-07-27 17:15:11,251 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/ba79c91e-c001-4819-a859-152fbed2c6fc
datanode_3          | 2022-07-27 17:15:11,253 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_3          | 2022-07-27 17:15:11,259 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3          | 2022-07-27 17:15:11,259 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3          | 2022-07-27 17:15:11,259 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3          | 2022-07-27 17:15:11,259 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3          | 2022-07-27 17:15:11,260 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3          | 2022-07-27 17:15:11,260 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3          | 2022-07-27 17:15:11,261 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3          | 2022-07-27 17:15:11,274 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3          | 2022-07-27 17:15:11,289 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_3          | 2022-07-27 17:15:11,290 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3          | 2022-07-27 17:15:11,290 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3          | 2022-07-27 17:15:11,291 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3          | 2022-07-27 17:15:11,362 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3          | 2022-07-27 17:15:11,362 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3          | 2022-07-27 17:15:11,363 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3          | 2022-07-27 17:15:11,363 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3          | 2022-07-27 17:15:11,363 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3          | 2022-07-27 17:15:11,364 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_3          | 2022-07-27 17:15:11,382 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3          | 2022-07-27 17:15:11,382 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_3          | 2022-07-27 17:15:11,385 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_3          | 2022-07-27 17:15:11,385 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_3          | 2022-07-27 17:15:11,386 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_3          | 2022-07-27 17:15:11,387 [pool-22-thread-1] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC: start as a follower, conf=-1: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:1], old=null
datanode_3          | 2022-07-27 17:15:11,395 [pool-22-thread-1] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3          | 2022-07-27 17:15:11,397 [pool-22-thread-1] INFO impl.RoleInfo: b50d7a6b-da1f-4bca-b673-015544dce0bd: start b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-FollowerState
datanode_3          | 2022-07-27 17:15:11,397 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-152FBED2C6FC,id=b50d7a6b-da1f-4bca-b673-015544dce0bd
datanode_3          | 2022-07-27 17:15:11,420 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=ba79c91e-c001-4819-a859-152fbed2c6fc
datanode_3          | 2022-07-27 17:15:11,443 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=ba79c91e-c001-4819-a859-152fbed2c6fc.
datanode_3          | 2022-07-27 17:15:11,444 [Command processor thread] INFO server.RaftServer: b50d7a6b-da1f-4bca-b673-015544dce0bd: addNew group-29EFD5711FCF:[b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:0, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:1, 5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|priority:0] returns group-29EFD5711FCF:java.util.concurrent.CompletableFuture@1046d131[Not completed]
datanode_3          | 2022-07-27 17:15:11,460 [pool-22-thread-1] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd: new RaftServerImpl for group-29EFD5711FCF:[b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:0, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:1, 5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|priority:0] with ContainerStateMachine:uninitialized
datanode_3          | 2022-07-27 17:15:11,464 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3          | 2022-07-27 17:15:11,464 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3          | 2022-07-27 17:15:11,466 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3          | 2022-07-27 17:15:11,471 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_3          | 2022-07-27 17:15:11,474 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_3          | 2022-07-27 17:15:11,474 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_3          | 2022-07-27 17:15:11,474 [pool-22-thread-1] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF: ConfigurationManager, init=-1: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:0, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:1, 5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode_3          | 2022-07-27 17:15:11,474 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3          | 2022-07-27 17:15:11,475 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3          | 2022-07-27 17:15:11,475 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_5          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode_5          | STARTUP_MSG:   build = https://github.com/apache/ozone/9f188e38b2f4663af1a9169fb7f63dfe156555a0 ; compiled by 'runner' on 2022-07-27T16:18Z
datanode_5          | STARTUP_MSG:   java = 11.0.14.1
datanode_5          | ************************************************************/
datanode_5          | 2022-07-27 17:14:15,828 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_5          | 2022-07-27 17:14:16,138 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_5          | 2022-07-27 17:14:16,804 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_5          | 2022-07-27 17:14:17,883 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_5          | 2022-07-27 17:14:17,884 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_5          | 2022-07-27 17:14:18,641 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:48d5efc1923c ip:172.23.0.12
datanode_5          | 2022-07-27 17:14:20,940 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode_5          | 2022-07-27 17:14:22,012 [main] INFO reflections.Reflections: Reflections took 802 ms to scan 2 urls, producing 89 keys and 198 values 
datanode_5          | 2022-07-27 17:14:22,855 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
datanode_5          | 2022-07-27 17:14:24,301 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_5          | 2022-07-27 17:14:24,430 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
datanode_5          | 2022-07-27 17:14:24,488 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_5          | 2022-07-27 17:14:24,504 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_5          | 2022-07-27 17:14:24,792 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_5          | 2022-07-27 17:14:24,982 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_5          | 2022-07-27 17:14:25,018 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode_5          | 2022-07-27 17:14:25,052 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode_5          | 2022-07-27 17:14:25,053 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode_5          | 2022-07-27 17:14:25,053 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode_5          | 2022-07-27 17:14:25,341 [Thread-7] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_5          | 2022-07-27 17:14:25,355 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_5          | 2022-07-27 17:14:34,465 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode_5          | 2022-07-27 17:14:35,083 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_5          | 2022-07-27 17:14:36,069 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode_5          | 2022-07-27 17:14:36,921 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode_5          | 2022-07-27 17:14:36,939 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode_5          | 2022-07-27 17:14:36,940 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode_5          | 2022-07-27 17:14:36,940 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_5          | 2022-07-27 17:14:36,959 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5          | 2022-07-27 17:14:36,960 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_5          | 2022-07-27 17:14:36,960 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_5          | 2022-07-27 17:14:37,134 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode_5          | 2022-07-27 17:14:37,138 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode_5          | 2022-07-27 17:14:39,007 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode_5          | 2022-07-27 17:14:39,032 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode_5          | 2022-07-27 17:14:39,047 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode_5          | 2022-07-27 17:14:39,051 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_5          | 2022-07-27 17:14:39,057 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_5          | 2022-07-27 17:14:39,087 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5          | 2022-07-27 17:14:39,573 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode_5          | 2022-07-27 17:14:40,944 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_5          | 2022-07-27 17:14:41,054 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_5          | 2022-07-27 17:14:41,255 [main] INFO util.log: Logging initialized @36432ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_5          | 2022-07-27 17:14:42,052 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_5          | 2022-07-27 17:14:42,089 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_5          | 2022-07-27 17:14:42,161 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_5          | 2022-07-27 17:14:42,179 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_5          | 2022-07-27 17:14:42,192 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_5          | 2022-07-27 17:14:42,192 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_5          | 2022-07-27 17:14:42,546 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_4          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode_4          | STARTUP_MSG:   build = https://github.com/apache/ozone/9f188e38b2f4663af1a9169fb7f63dfe156555a0 ; compiled by 'runner' on 2022-07-27T16:18Z
datanode_4          | STARTUP_MSG:   java = 11.0.14.1
datanode_4          | ************************************************************/
datanode_4          | 2022-07-27 17:14:16,124 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_4          | 2022-07-27 17:14:16,475 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_4          | 2022-07-27 17:14:17,164 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_4          | 2022-07-27 17:14:18,323 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_4          | 2022-07-27 17:14:18,327 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_4          | 2022-07-27 17:14:19,188 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:caa94ab9ee1a ip:172.23.0.13
datanode_4          | 2022-07-27 17:14:21,313 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode_4          | 2022-07-27 17:14:22,374 [main] INFO reflections.Reflections: Reflections took 851 ms to scan 2 urls, producing 89 keys and 198 values 
datanode_4          | 2022-07-27 17:14:23,283 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
datanode_4          | 2022-07-27 17:14:24,865 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_4          | 2022-07-27 17:14:24,971 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
datanode_4          | 2022-07-27 17:14:24,984 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_4          | 2022-07-27 17:14:25,000 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_4          | 2022-07-27 17:14:25,317 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_4          | 2022-07-27 17:14:25,541 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_4          | 2022-07-27 17:14:25,550 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode_4          | 2022-07-27 17:14:25,560 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode_4          | 2022-07-27 17:14:25,564 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode_4          | 2022-07-27 17:14:25,564 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode_4          | 2022-07-27 17:14:25,967 [Thread-7] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_4          | 2022-07-27 17:14:26,016 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_4          | 2022-07-27 17:14:34,670 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode_4          | 2022-07-27 17:14:35,254 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_4          | 2022-07-27 17:14:36,225 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode_4          | 2022-07-27 17:14:36,995 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode_4          | 2022-07-27 17:14:36,999 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode_4          | 2022-07-27 17:14:37,057 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode_4          | 2022-07-27 17:14:37,068 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_4          | 2022-07-27 17:14:37,086 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4          | 2022-07-27 17:14:37,100 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_4          | 2022-07-27 17:14:37,105 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_4          | 2022-07-27 17:14:37,274 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode_4          | 2022-07-27 17:14:37,283 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode_4          | 2022-07-27 17:14:39,537 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode_4          | 2022-07-27 17:14:39,548 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode_4          | 2022-07-27 17:14:39,563 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode_4          | 2022-07-27 17:14:39,567 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_4          | 2022-07-27 17:14:39,567 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_4          | 2022-07-27 17:14:39,570 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4          | 2022-07-27 17:14:39,806 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode_4          | 2022-07-27 17:14:40,864 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_4          | 2022-07-27 17:14:40,972 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_4          | 2022-07-27 17:14:41,184 [main] INFO util.log: Logging initialized @36540ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_4          | 2022-07-27 17:14:42,023 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_4          | 2022-07-27 17:14:42,087 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_4          | 2022-07-27 17:14:42,161 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_4          | 2022-07-27 17:14:42,170 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_4          | 2022-07-27 17:14:42,181 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_4          | 2022-07-27 17:14:42,181 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_4          | 2022-07-27 17:14:42,476 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3          | 2022-07-27 17:15:11,475 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/de666cc0-d9ea-4d5d-8684-29efd5711fcf does not exist. Creating ...
datanode_3          | 2022-07-27 17:15:11,487 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/de666cc0-d9ea-4d5d-8684-29efd5711fcf/in_use.lock acquired by nodename 7@be9667654851
datanode_3          | 2022-07-27 17:15:11,507 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/de666cc0-d9ea-4d5d-8684-29efd5711fcf has been successfully formatted.
datanode_3          | 2022-07-27 17:15:11,563 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-29EFD5711FCF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3          | 2022-07-27 17:15:11,566 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_3          | 2022-07-27 17:15:11,567 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3          | 2022-07-27 17:15:11,567 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3          | 2022-07-27 17:15:11,568 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3          | 2022-07-27 17:15:11,568 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_3          | 2022-07-27 17:15:11,569 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3          | 2022-07-27 17:15:11,569 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3          | 2022-07-27 17:15:11,574 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_3          | 2022-07-27 17:15:11,575 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/de666cc0-d9ea-4d5d-8684-29efd5711fcf
datanode_3          | 2022-07-27 17:15:11,579 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_3          | 2022-07-27 17:15:11,581 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3          | 2022-07-27 17:15:11,582 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3          | 2022-07-27 17:15:11,582 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3          | 2022-07-27 17:15:11,603 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3          | 2022-07-27 17:15:11,603 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3          | 2022-07-27 17:15:11,604 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3          | 2022-07-27 17:15:11,604 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3          | 2022-07-27 17:15:11,604 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3          | 2022-07-27 17:15:11,614 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_3          | 2022-07-27 17:15:11,614 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3          | 2022-07-27 17:15:11,615 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3          | 2022-07-27 17:15:11,619 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3          | 2022-07-27 17:15:11,688 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3          | 2022-07-27 17:15:11,699 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3          | 2022-07-27 17:15:11,713 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3          | 2022-07-27 17:15:11,713 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3          | 2022-07-27 17:15:11,715 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3          | 2022-07-27 17:15:11,719 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_3          | 2022-07-27 17:15:11,720 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3          | 2022-07-27 17:15:11,723 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_3          | 2022-07-27 17:15:11,723 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_3          | 2022-07-27 17:15:11,723 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_3          | 2022-07-27 17:15:11,723 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_3          | 2022-07-27 17:15:11,724 [pool-22-thread-1] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF: start as a follower, conf=-1: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:0, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:1, 5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|priority:0], old=null
datanode_3          | 2022-07-27 17:15:11,724 [pool-22-thread-1] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3          | 2022-07-27 17:15:11,724 [pool-22-thread-1] INFO impl.RoleInfo: b50d7a6b-da1f-4bca-b673-015544dce0bd: start b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-FollowerState
datanode_3          | 2022-07-27 17:15:11,747 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-29EFD5711FCF,id=b50d7a6b-da1f-4bca-b673-015544dce0bd
datanode_3          | 2022-07-27 17:15:11,750 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=de666cc0-d9ea-4d5d-8684-29efd5711fcf
datanode_3          | 2022-07-27 17:15:12,288 [grpc-default-executor-0] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC: receive requestVote(ELECTION, 2750dc88-6529-455f-a3a5-c6a6089a5bfe, group-78C2755A5DDC, 1, (t:0, i:0))
datanode_3          | 2022-07-27 17:15:12,290 [grpc-default-executor-0] INFO impl.VoteContext: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-FOLLOWER: reject ELECTION from 2750dc88-6529-455f-a3a5-c6a6089a5bfe: our priority 1 > candidate's priority 0
datanode_3          | 2022-07-27 17:15:12,291 [grpc-default-executor-0] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:2750dc88-6529-455f-a3a5-c6a6089a5bfe
datanode_3          | 2022-07-27 17:15:12,291 [grpc-default-executor-0] INFO impl.RoleInfo: b50d7a6b-da1f-4bca-b673-015544dce0bd: shutdown b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-FollowerState
datanode_2          | 2022-07-27 17:15:12,537 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2          | 2022-07-27 17:15:12,537 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_2          | 2022-07-27 17:15:12,540 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2          | 2022-07-27 17:15:12,542 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_2          | 2022-07-27 17:15:12,544 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_2          | 2022-07-27 17:15:12,545 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_2          | 2022-07-27 17:15:12,545 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_2          | 2022-07-27 17:15:12,545 [pool-22-thread-1] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24: start as a follower, conf=-1: [0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:1], old=null
datanode_2          | 2022-07-27 17:15:12,547 [pool-22-thread-1] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2          | 2022-07-27 17:15:12,548 [pool-22-thread-1] INFO impl.RoleInfo: 0047ef4e-8059-4dda-a40b-cf26d888a843: start 0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-FollowerState
datanode_2          | 2022-07-27 17:15:12,549 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-03BDABE80F24,id=0047ef4e-8059-4dda-a40b-cf26d888a843
datanode_2          | 2022-07-27 17:15:12,555 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=e1b362da-60c0-4653-994d-03bdabe80f24
datanode_2          | 2022-07-27 17:15:12,555 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=e1b362da-60c0-4653-994d-03bdabe80f24.
datanode_2          | 2022-07-27 17:15:16,952 [grpc-default-executor-1] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF: receive requestVote(ELECTION, b50d7a6b-da1f-4bca-b673-015544dce0bd, group-29EFD5711FCF, 1, (t:0, i:0))
datanode_2          | 2022-07-27 17:15:16,953 [grpc-default-executor-1] INFO impl.VoteContext: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-FOLLOWER: reject ELECTION from b50d7a6b-da1f-4bca-b673-015544dce0bd: our priority 1 > candidate's priority 0
datanode_2          | 2022-07-27 17:15:16,953 [grpc-default-executor-1] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:b50d7a6b-da1f-4bca-b673-015544dce0bd
datanode_2          | 2022-07-27 17:15:16,953 [grpc-default-executor-1] INFO impl.RoleInfo: 0047ef4e-8059-4dda-a40b-cf26d888a843: shutdown 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-FollowerState
datanode_2          | 2022-07-27 17:15:16,953 [grpc-default-executor-1] INFO impl.RoleInfo: 0047ef4e-8059-4dda-a40b-cf26d888a843: start 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-FollowerState
datanode_2          | 2022-07-27 17:15:16,953 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-FollowerState] INFO impl.FollowerState: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-FollowerState was interrupted
datanode_2          | 2022-07-27 17:15:16,956 [grpc-default-executor-1] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF replies to ELECTION vote request: b50d7a6b-da1f-4bca-b673-015544dce0bd<-0047ef4e-8059-4dda-a40b-cf26d888a843#0:FAIL-t1. Peer's state: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF:t1, leader=null, voted=null, raftlog=0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-SegmentedRaftLog:OPENED:c-1, conf=-1: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:0, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:1, 5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|priority:0], old=null
datanode_2          | 2022-07-27 17:15:17,383 [grpc-default-executor-1] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC: receive requestVote(ELECTION, b50d7a6b-da1f-4bca-b673-015544dce0bd, group-78C2755A5DDC, 2, (t:0, i:0))
datanode_2          | 2022-07-27 17:15:17,383 [grpc-default-executor-1] INFO impl.VoteContext: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC-FOLLOWER: accept ELECTION from b50d7a6b-da1f-4bca-b673-015544dce0bd: our priority 0 <= candidate's priority 1
datanode_2          | 2022-07-27 17:15:17,383 [grpc-default-executor-1] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:b50d7a6b-da1f-4bca-b673-015544dce0bd
datanode_2          | 2022-07-27 17:15:17,384 [grpc-default-executor-1] INFO impl.RoleInfo: 0047ef4e-8059-4dda-a40b-cf26d888a843: shutdown 0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC-FollowerState
datanode_2          | 2022-07-27 17:15:17,384 [grpc-default-executor-1] INFO impl.RoleInfo: 0047ef4e-8059-4dda-a40b-cf26d888a843: start 0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC-FollowerState
datanode_2          | 2022-07-27 17:15:17,384 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC-FollowerState] INFO impl.FollowerState: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC-FollowerState was interrupted
datanode_2          | 2022-07-27 17:15:17,400 [grpc-default-executor-1] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC replies to ELECTION vote request: b50d7a6b-da1f-4bca-b673-015544dce0bd<-0047ef4e-8059-4dda-a40b-cf26d888a843#0:OK-t2. Peer's state: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC:t2, leader=null, voted=b50d7a6b-da1f-4bca-b673-015544dce0bd, raftlog=0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC-SegmentedRaftLog:OPENED:c-1, conf=-1: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:1, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:0], old=null
datanode_2          | 2022-07-27 17:15:17,676 [0047ef4e-8059-4dda-a40b-cf26d888a843-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-78C2755A5DDC with new leaderId: b50d7a6b-da1f-4bca-b673-015544dce0bd
datanode_2          | 2022-07-27 17:15:17,676 [0047ef4e-8059-4dda-a40b-cf26d888a843-server-thread1] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC: change Leader from null to b50d7a6b-da1f-4bca-b673-015544dce0bd at term 2 for appendEntries, leader elected after 10353ms
datanode_2          | 2022-07-27 17:15:17,701 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-FollowerState] INFO impl.FollowerState: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5153001946ns, electionTimeout:5148ms
datanode_2          | 2022-07-27 17:15:17,716 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-FollowerState] INFO impl.RoleInfo: 0047ef4e-8059-4dda-a40b-cf26d888a843: shutdown 0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-FollowerState
datanode_2          | 2022-07-27 17:15:17,716 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-FollowerState] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3          | 2022-07-27 17:15:12,291 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-FollowerState] INFO impl.FollowerState: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-FollowerState was interrupted
datanode_3          | 2022-07-27 17:15:12,292 [grpc-default-executor-0] INFO impl.RoleInfo: b50d7a6b-da1f-4bca-b673-015544dce0bd: start b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-FollowerState
datanode_3          | 2022-07-27 17:15:12,314 [grpc-default-executor-0] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC replies to ELECTION vote request: 2750dc88-6529-455f-a3a5-c6a6089a5bfe<-b50d7a6b-da1f-4bca-b673-015544dce0bd#0:FAIL-t1. Peer's state: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC:t1, leader=null, voted=null, raftlog=b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-SegmentedRaftLog:OPENED:c-1, conf=-1: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:1, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:0], old=null
datanode_3          | 2022-07-27 17:15:13,385 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=de666cc0-d9ea-4d5d-8684-29efd5711fcf.
datanode_3          | 2022-07-27 17:15:16,569 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-FollowerState] INFO impl.FollowerState: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5172217608ns, electionTimeout:5156ms
datanode_3          | 2022-07-27 17:15:16,569 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-FollowerState] INFO impl.RoleInfo: b50d7a6b-da1f-4bca-b673-015544dce0bd: shutdown b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-FollowerState
datanode_3          | 2022-07-27 17:15:16,570 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-FollowerState] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3          | 2022-07-27 17:15:16,572 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_3          | 2022-07-27 17:15:16,572 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-FollowerState] INFO impl.RoleInfo: b50d7a6b-da1f-4bca-b673-015544dce0bd: start b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-LeaderElection1
datanode_3          | 2022-07-27 17:15:16,580 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-LeaderElection1] INFO impl.LeaderElection: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:1], old=null
datanode_3          | 2022-07-27 17:15:16,581 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-LeaderElection1] INFO impl.LeaderElection: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode_3          | 2022-07-27 17:15:16,581 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-LeaderElection1] INFO impl.RoleInfo: b50d7a6b-da1f-4bca-b673-015544dce0bd: shutdown b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-LeaderElection1
datanode_3          | 2022-07-27 17:15:16,585 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-LeaderElection1] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3          | 2022-07-27 17:15:16,585 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-152FBED2C6FC with new leaderId: b50d7a6b-da1f-4bca-b673-015544dce0bd
datanode_3          | 2022-07-27 17:15:16,586 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-LeaderElection1] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC: change Leader from null to b50d7a6b-da1f-4bca-b673-015544dce0bd at term 1 for becomeLeader, leader elected after 5369ms
datanode_3          | 2022-07-27 17:15:16,613 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3          | 2022-07-27 17:15:16,648 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3          | 2022-07-27 17:15:16,651 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode_3          | 2022-07-27 17:15:16,666 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3          | 2022-07-27 17:15:16,668 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3          | 2022-07-27 17:15:16,669 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3          | 2022-07-27 17:15:16,685 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3          | 2022-07-27 17:15:16,699 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode_3          | 2022-07-27 17:15:16,708 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-LeaderElection1] INFO impl.RoleInfo: b50d7a6b-da1f-4bca-b673-015544dce0bd: start b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-LeaderStateImpl
datanode_3          | 2022-07-27 17:15:16,755 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-FollowerState] INFO impl.FollowerState: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5030984166ns, electionTimeout:5005ms
datanode_3          | 2022-07-27 17:15:16,756 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-FollowerState] INFO impl.RoleInfo: b50d7a6b-da1f-4bca-b673-015544dce0bd: shutdown b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-FollowerState
datanode_3          | 2022-07-27 17:15:16,756 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-FollowerState] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3          | 2022-07-27 17:15:16,756 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_3          | 2022-07-27 17:15:16,756 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-FollowerState] INFO impl.RoleInfo: b50d7a6b-da1f-4bca-b673-015544dce0bd: start b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-LeaderElection2
datanode_3          | 2022-07-27 17:15:16,773 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2          | 2022-07-27 17:15:17,719 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_2          | 2022-07-27 17:15:17,719 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-FollowerState] INFO impl.RoleInfo: 0047ef4e-8059-4dda-a40b-cf26d888a843: start 0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-LeaderElection1
datanode_2          | 2022-07-27 17:15:17,728 [0047ef4e-8059-4dda-a40b-cf26d888a843-server-thread1] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC: set configuration 0: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|dataStream:|priority:1, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|dataStream:|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|dataStream:|priority:0], old=null
datanode_2          | 2022-07-27 17:15:17,757 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-LeaderElection1] INFO impl.LeaderElection: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:1], old=null
datanode_2          | 2022-07-27 17:15:17,767 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-LeaderElection1] INFO impl.LeaderElection: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode_2          | 2022-07-27 17:15:17,769 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-LeaderElection1] INFO impl.RoleInfo: 0047ef4e-8059-4dda-a40b-cf26d888a843: shutdown 0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-LeaderElection1
datanode_2          | 2022-07-27 17:15:17,770 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-LeaderElection1] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2          | 2022-07-27 17:15:17,771 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-03BDABE80F24 with new leaderId: 0047ef4e-8059-4dda-a40b-cf26d888a843
datanode_2          | 2022-07-27 17:15:17,780 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-LeaderElection1] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24: change Leader from null to 0047ef4e-8059-4dda-a40b-cf26d888a843 at term 1 for becomeLeader, leader elected after 5268ms
datanode_2          | 2022-07-27 17:15:17,769 [0047ef4e-8059-4dda-a40b-cf26d888a843-server-thread1] INFO segmented.SegmentedRaftLogWorker: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2          | 2022-07-27 17:15:17,824 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2          | 2022-07-27 17:15:17,853 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2          | 2022-07-27 17:15:17,906 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode_2          | 2022-07-27 17:15:17,959 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2          | 2022-07-27 17:15:17,963 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2          | 2022-07-27 17:15:17,972 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2          | 2022-07-27 17:15:18,019 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2          | 2022-07-27 17:15:18,021 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode_2          | 2022-07-27 17:15:18,040 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-LeaderElection1] INFO impl.RoleInfo: 0047ef4e-8059-4dda-a40b-cf26d888a843: start 0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-LeaderStateImpl
datanode_2          | 2022-07-27 17:15:18,074 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2          | 2022-07-27 17:15:18,097 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-LeaderElection1] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24: set configuration 0: [0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|dataStream:|priority:1], old=null
datanode_2          | 2022-07-27 17:15:18,232 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-03BDABE80F24-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/e1b362da-60c0-4653-994d-03bdabe80f24/current/log_inprogress_0
datanode_2          | 2022-07-27 17:15:18,251 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-78C2755A5DDC-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/ee453f3e-2788-418a-bfda-78c2755a5ddc/current/log_inprogress_0
datanode_2          | 2022-07-27 17:15:22,045 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-FollowerState] INFO impl.FollowerState: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5092066828ns, electionTimeout:5089ms
datanode_2          | 2022-07-27 17:15:22,048 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-FollowerState] INFO impl.RoleInfo: 0047ef4e-8059-4dda-a40b-cf26d888a843: shutdown 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-FollowerState
datanode_2          | 2022-07-27 17:15:22,048 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-FollowerState] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode_2          | 2022-07-27 17:15:22,048 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_2          | 2022-07-27 17:15:22,048 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-FollowerState] INFO impl.RoleInfo: 0047ef4e-8059-4dda-a40b-cf26d888a843: start 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2
datanode_2          | 2022-07-27 17:15:22,056 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO impl.LeaderElection: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2 ELECTION round 0: submit vote requests at term 2 for -1: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:0, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:1, 5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|priority:0], old=null
datanode_3          | 2022-07-27 17:15:16,780 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-LeaderElection2] INFO impl.LeaderElection: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:0, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:1, 5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|priority:0], old=null
datanode_3          | 2022-07-27 17:15:16,923 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-LeaderElection1] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC: set configuration 0: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|dataStream:|priority:1], old=null
datanode_3          | 2022-07-27 17:15:16,961 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-LeaderElection2] INFO impl.LeaderElection: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-LeaderElection2: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode_3          | 2022-07-27 17:15:16,966 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-LeaderElection2] INFO impl.LeaderElection:   Response 0: b50d7a6b-da1f-4bca-b673-015544dce0bd<-0047ef4e-8059-4dda-a40b-cf26d888a843#0:FAIL-t1
datanode_3          | 2022-07-27 17:15:16,966 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-LeaderElection2] INFO impl.LeaderElection:   Response 1: b50d7a6b-da1f-4bca-b673-015544dce0bd<-5a16948f-0635-4af6-ad47-d40ff1547cf8#0:OK-t1
datanode_3          | 2022-07-27 17:15:16,967 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-LeaderElection2] INFO impl.LeaderElection: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-LeaderElection2 ELECTION round 0: result REJECTED
datanode_3          | 2022-07-27 17:15:16,969 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-LeaderElection2] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
datanode_3          | 2022-07-27 17:15:16,970 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-LeaderElection2] INFO impl.RoleInfo: b50d7a6b-da1f-4bca-b673-015544dce0bd: shutdown b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-LeaderElection2
datanode_3          | 2022-07-27 17:15:16,970 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-LeaderElection2] INFO impl.RoleInfo: b50d7a6b-da1f-4bca-b673-015544dce0bd: start b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-FollowerState
datanode_3          | 2022-07-27 17:15:17,066 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-152FBED2C6FC-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/ba79c91e-c001-4819-a859-152fbed2c6fc/current/log_inprogress_0
datanode_3          | 2022-07-27 17:15:17,351 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-FollowerState] INFO impl.FollowerState: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5059109761ns, electionTimeout:5052ms
datanode_3          | 2022-07-27 17:15:17,351 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-FollowerState] INFO impl.RoleInfo: b50d7a6b-da1f-4bca-b673-015544dce0bd: shutdown b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-FollowerState
datanode_3          | 2022-07-27 17:15:17,352 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-FollowerState] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode_3          | 2022-07-27 17:15:17,352 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_3          | 2022-07-27 17:15:17,352 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-FollowerState] INFO impl.RoleInfo: b50d7a6b-da1f-4bca-b673-015544dce0bd: start b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3
datanode_3          | 2022-07-27 17:15:17,355 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO impl.LeaderElection: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3 ELECTION round 0: submit vote requests at term 2 for -1: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:1, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:0], old=null
datanode_3          | 2022-07-27 17:15:17,403 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO impl.LeaderElection: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode_3          | 2022-07-27 17:15:17,403 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO impl.LeaderElection:   Response 0: b50d7a6b-da1f-4bca-b673-015544dce0bd<-0047ef4e-8059-4dda-a40b-cf26d888a843#0:OK-t2
datanode_3          | 2022-07-27 17:15:17,403 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO impl.LeaderElection: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3 ELECTION round 0: result PASSED
datanode_3          | 2022-07-27 17:15:17,403 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO impl.RoleInfo: b50d7a6b-da1f-4bca-b673-015544dce0bd: shutdown b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3
datanode_3          | 2022-07-27 17:15:17,436 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
datanode_3          | 2022-07-27 17:15:17,436 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-78C2755A5DDC with new leaderId: b50d7a6b-da1f-4bca-b673-015544dce0bd
datanode_3          | 2022-07-27 17:15:17,436 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC: change Leader from null to b50d7a6b-da1f-4bca-b673-015544dce0bd at term 2 for becomeLeader, leader elected after 10554ms
datanode_3          | 2022-07-27 17:15:17,436 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3          | 2022-07-27 17:15:17,437 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3          | 2022-07-27 17:15:17,437 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode_3          | 2022-07-27 17:15:17,438 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3          | 2022-07-27 17:15:17,438 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3          | 2022-07-27 17:15:17,438 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3          | 2022-07-27 17:15:17,438 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3          | 2022-07-27 17:15:17,438 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode_3          | 2022-07-27 17:15:17,473 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3          | 2022-07-27 17:15:17,473 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3          | 2022-07-27 17:15:17,475 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3          | 2022-07-27 17:15:17,489 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3          | 2022-07-27 17:15:17,490 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3          | 2022-07-27 17:15:17,490 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3          | 2022-07-27 17:15:17,493 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3          | 2022-07-27 17:15:17,494 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3          | 2022-07-27 17:15:17,494 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3          | 2022-07-27 17:15:17,509 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3          | 2022-07-27 17:15:17,509 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3          | 2022-07-27 17:15:17,510 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3          | 2022-07-27 17:15:17,511 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO impl.RoleInfo: b50d7a6b-da1f-4bca-b673-015544dce0bd: start b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderStateImpl
datanode_3          | 2022-07-27 17:15:17,516 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3          | 2022-07-27 17:15:17,523 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/ee453f3e-2788-418a-bfda-78c2755a5ddc/current/log_inprogress_0
datanode_3          | 2022-07-27 17:15:17,541 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC-LeaderElection3] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-78C2755A5DDC: set configuration 0: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|dataStream:|priority:1, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|dataStream:|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|dataStream:|priority:0], old=null
datanode_3          | 2022-07-27 17:15:22,169 [grpc-default-executor-0] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF: receive requestVote(ELECTION, 0047ef4e-8059-4dda-a40b-cf26d888a843, group-29EFD5711FCF, 2, (t:0, i:0))
datanode_3          | 2022-07-27 17:15:22,170 [grpc-default-executor-0] INFO impl.VoteContext: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-FOLLOWER: accept ELECTION from 0047ef4e-8059-4dda-a40b-cf26d888a843: our priority 0 <= candidate's priority 1
datanode_3          | 2022-07-27 17:15:22,170 [grpc-default-executor-0] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:0047ef4e-8059-4dda-a40b-cf26d888a843
datanode_3          | 2022-07-27 17:15:22,170 [grpc-default-executor-0] INFO impl.RoleInfo: b50d7a6b-da1f-4bca-b673-015544dce0bd: shutdown b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-FollowerState
datanode_3          | 2022-07-27 17:15:22,170 [grpc-default-executor-0] INFO impl.RoleInfo: b50d7a6b-da1f-4bca-b673-015544dce0bd: start b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-FollowerState
datanode_3          | 2022-07-27 17:15:22,172 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-FollowerState] INFO impl.FollowerState: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-FollowerState was interrupted
datanode_3          | 2022-07-27 17:15:22,179 [grpc-default-executor-0] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF replies to ELECTION vote request: 0047ef4e-8059-4dda-a40b-cf26d888a843<-b50d7a6b-da1f-4bca-b673-015544dce0bd#0:OK-t2. Peer's state: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF:t2, leader=null, voted=0047ef4e-8059-4dda-a40b-cf26d888a843, raftlog=b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-SegmentedRaftLog:OPENED:c-1, conf=-1: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:0, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:1, 5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|priority:0], old=null
datanode_3          | 2022-07-27 17:15:22,443 [b50d7a6b-da1f-4bca-b673-015544dce0bd-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-29EFD5711FCF with new leaderId: 0047ef4e-8059-4dda-a40b-cf26d888a843
datanode_3          | 2022-07-27 17:15:22,443 [b50d7a6b-da1f-4bca-b673-015544dce0bd-server-thread1] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF: change Leader from null to 0047ef4e-8059-4dda-a40b-cf26d888a843 at term 2 for appendEntries, leader elected after 10877ms
datanode_3          | 2022-07-27 17:15:22,509 [b50d7a6b-da1f-4bca-b673-015544dce0bd-server-thread1] INFO server.RaftServer$Division: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF: set configuration 0: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|dataStream:|priority:0, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|dataStream:|priority:1, 5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|dataStream:|priority:0], old=null
datanode_3          | 2022-07-27 17:15:22,524 [b50d7a6b-da1f-4bca-b673-015544dce0bd-server-thread1] INFO segmented.SegmentedRaftLogWorker: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3          | 2022-07-27 17:15:22,525 [b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: b50d7a6b-da1f-4bca-b673-015544dce0bd@group-29EFD5711FCF-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/de666cc0-d9ea-4d5d-8684-29efd5711fcf/current/log_inprogress_0
datanode_4          | 2022-07-27 17:14:42,478 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode_4          | 2022-07-27 17:14:42,707 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_4          | 2022-07-27 17:14:42,709 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_4          | 2022-07-27 17:14:42,711 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_4          | 2022-07-27 17:14:42,798 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@21046afa{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_4          | 2022-07-27 17:14:42,811 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3bf4644c{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_4          | 2022-07-27 17:14:43,622 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7dbbf730{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-7363049170003607045/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_4          | 2022-07-27 17:14:43,712 [main] INFO server.AbstractConnector: Started ServerConnector@5392aa2b{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode_4          | 2022-07-27 17:14:43,720 [main] INFO server.Server: Started @39076ms
datanode_4          | 2022-07-27 17:14:43,733 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_4          | 2022-07-27 17:14:43,734 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_4          | 2022-07-27 17:14:43,743 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_4          | 2022-07-27 17:14:43,770 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode_4          | 2022-07-27 17:14:44,002 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3f483c9f] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_4          | 2022-07-27 17:14:44,609 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.23.0.11:9891
datanode_4          | 2022-07-27 17:14:44,974 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_4          | 2022-07-27 17:14:47,668 [EndpointStateMachine task thread for recon/172.23.0.11:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.23.0.11:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4          | 2022-07-27 17:14:47,669 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4          | 2022-07-27 17:14:48,670 [EndpointStateMachine task thread for recon/172.23.0.11:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.23.0.11:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4          | 2022-07-27 17:14:48,671 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4          | 2022-07-27 17:14:49,671 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4          | 2022-07-27 17:14:49,671 [EndpointStateMachine task thread for recon/172.23.0.11:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.23.0.11:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4          | 2022-07-27 17:14:50,672 [EndpointStateMachine task thread for recon/172.23.0.11:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.23.0.11:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4          | 2022-07-27 17:14:50,675 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4          | 2022-07-27 17:14:51,676 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4          | 2022-07-27 17:14:52,677 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4          | 2022-07-27 17:14:53,678 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4          | 2022-07-27 17:14:54,679 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4          | 2022-07-27 17:14:55,680 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_4          | 2022-07-27 17:14:55,722 [EndpointStateMachine task thread for recon/172.23.0.11:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode_4          | java.net.SocketTimeoutException: Call From caa94ab9ee1a/172.23.0.13 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.13:57276 remote=recon/172.23.0.11:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_4          | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_4          | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_4          | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_4          | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_4          | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode_4          | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
datanode_4          | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
datanode_4          | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
datanode_4          | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
datanode_4          | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
datanode_4          | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
datanode_4          | 	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
datanode_4          | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_2          | 2022-07-27 17:15:22,186 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO impl.LeaderElection: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode_2          | 2022-07-27 17:15:22,187 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO impl.LeaderElection:   Response 0: 0047ef4e-8059-4dda-a40b-cf26d888a843<-b50d7a6b-da1f-4bca-b673-015544dce0bd#0:OK-t2
datanode_2          | 2022-07-27 17:15:22,187 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO impl.LeaderElection: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2 ELECTION round 0: result PASSED
datanode_2          | 2022-07-27 17:15:22,198 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO impl.RoleInfo: 0047ef4e-8059-4dda-a40b-cf26d888a843: shutdown 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2
datanode_2          | 2022-07-27 17:15:22,198 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
datanode_2          | 2022-07-27 17:15:22,198 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-29EFD5711FCF with new leaderId: 0047ef4e-8059-4dda-a40b-cf26d888a843
datanode_2          | 2022-07-27 17:15:22,200 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF: change Leader from null to 0047ef4e-8059-4dda-a40b-cf26d888a843 at term 2 for becomeLeader, leader elected after 10245ms
datanode_2          | 2022-07-27 17:15:22,200 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2          | 2022-07-27 17:15:22,200 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2          | 2022-07-27 17:15:22,200 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode_2          | 2022-07-27 17:15:22,200 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2          | 2022-07-27 17:15:22,200 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2          | 2022-07-27 17:15:22,200 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2          | 2022-07-27 17:15:22,200 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2          | 2022-07-27 17:15:22,200 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode_2          | 2022-07-27 17:15:22,263 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_2          | 2022-07-27 17:15:22,277 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2          | 2022-07-27 17:15:22,294 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_2          | 2022-07-27 17:15:22,308 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_2          | 2022-07-27 17:15:22,309 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2          | 2022-07-27 17:15:22,309 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2          | 2022-07-27 17:15:22,323 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_2          | 2022-07-27 17:15:22,324 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2          | 2022-07-27 17:15:22,324 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_2          | 2022-07-27 17:15:22,324 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_2          | 2022-07-27 17:15:22,325 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2          | 2022-07-27 17:15:22,325 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2          | 2022-07-27 17:15:22,344 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO impl.RoleInfo: 0047ef4e-8059-4dda-a40b-cf26d888a843: start 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderStateImpl
datanode_2          | 2022-07-27 17:15:22,354 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2          | 2022-07-27 17:15:22,360 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/de666cc0-d9ea-4d5d-8684-29efd5711fcf/current/log_inprogress_0
datanode_2          | 2022-07-27 17:15:22,390 [0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF-LeaderElection2] INFO server.RaftServer$Division: 0047ef4e-8059-4dda-a40b-cf26d888a843@group-29EFD5711FCF: set configuration 0: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|dataStream:|priority:0, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|dataStream:|priority:1, 5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|dataStream:|priority:0], old=null
datanode_5          | 2022-07-27 17:14:42,575 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode_5          | 2022-07-27 17:14:42,817 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_5          | 2022-07-27 17:14:42,817 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_5          | 2022-07-27 17:14:42,822 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_5          | 2022-07-27 17:14:42,921 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@21046afa{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_5          | 2022-07-27 17:14:42,936 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3bf4644c{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_5          | 2022-07-27 17:14:43,950 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7dbbf730{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-14837040521073489157/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_5          | 2022-07-27 17:14:44,083 [main] INFO server.AbstractConnector: Started ServerConnector@5392aa2b{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode_5          | 2022-07-27 17:14:44,084 [main] INFO server.Server: Started @39281ms
datanode_5          | 2022-07-27 17:14:44,099 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_5          | 2022-07-27 17:14:44,100 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_5          | 2022-07-27 17:14:44,105 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_5          | 2022-07-27 17:14:44,134 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode_5          | 2022-07-27 17:14:44,481 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2e3946a] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_5          | 2022-07-27 17:14:45,112 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.23.0.11:9891
datanode_5          | 2022-07-27 17:14:45,455 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_5          | 2022-07-27 17:14:47,956 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5          | 2022-07-27 17:14:47,973 [EndpointStateMachine task thread for recon/172.23.0.11:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.23.0.11:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5          | 2022-07-27 17:14:48,957 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5          | 2022-07-27 17:14:48,974 [EndpointStateMachine task thread for recon/172.23.0.11:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.23.0.11:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5          | 2022-07-27 17:14:49,958 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5          | 2022-07-27 17:14:49,975 [EndpointStateMachine task thread for recon/172.23.0.11:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.23.0.11:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5          | 2022-07-27 17:14:50,959 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5          | 2022-07-27 17:14:50,975 [EndpointStateMachine task thread for recon/172.23.0.11:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.23.0.11:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5          | 2022-07-27 17:14:51,960 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5          | 2022-07-27 17:14:52,961 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5          | 2022-07-27 17:14:53,964 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5          | 2022-07-27 17:14:54,965 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5          | 2022-07-27 17:14:55,965 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.4:9861. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_5          | 2022-07-27 17:14:55,998 [EndpointStateMachine task thread for recon/172.23.0.11:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode_5          | java.net.SocketTimeoutException: Call From 48d5efc1923c/172.23.0.12 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.12:58090 remote=recon/172.23.0.11:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_5          | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_5          | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_5          | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_5          | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_5          | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode_5          | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
datanode_5          | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
datanode_5          | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
datanode_5          | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
datanode_5          | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
datanode_5          | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
datanode_5          | 	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
datanode_5          | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_4          | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_4          | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
datanode_4          | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
datanode_4          | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4          | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4          | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4          | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_4          | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.13:57276 remote=recon/172.23.0.11:9891]
datanode_4          | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_4          | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_4          | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_4          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_4          | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_4          | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_4          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4          | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
datanode_4          | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_4          | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
datanode_4          | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
datanode_4          | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
datanode_4          | 2022-07-27 17:15:00,692 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_4          | java.net.SocketTimeoutException: Call From caa94ab9ee1a/172.23.0.13 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.13:60950 remote=scm/172.23.0.4:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_4          | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_4          | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_4          | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_4          | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_4          | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode_4          | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
datanode_4          | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
datanode_4          | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
datanode_4          | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
datanode_4          | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
datanode_4          | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
datanode_4          | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
datanode_4          | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_4          | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_4          | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
datanode_4          | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
datanode_4          | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4          | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4          | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4          | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_4          | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.13:60950 remote=scm/172.23.0.4:9861]
datanode_4          | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_4          | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_4          | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_4          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_4          | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_4          | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_4          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4          | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
datanode_4          | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_4          | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
datanode_4          | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
datanode_4          | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
datanode_4          | 2022-07-27 17:15:01,684 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-7d45909c-9fcd-4dc9-be34-cfa80db7825a/DS-e4864c73-6634-487d-b7cf-0595f0ec0790/container.db for volume DS-e4864c73-6634-487d-b7cf-0595f0ec0790
datanode_4          | 2022-07-27 17:15:01,721 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-7d45909c-9fcd-4dc9-be34-cfa80db7825a/DS-e4864c73-6634-487d-b7cf-0595f0ec0790/container.db for volume DS-e4864c73-6634-487d-b7cf-0595f0ec0790
datanode_4          | 2022-07-27 17:15:01,723 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_4          | 2022-07-27 17:15:01,731 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_4          | 2022-07-27 17:15:02,162 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis fb410344-fcfe-4f99-b41b-29dd0a68d978
datanode_4          | 2022-07-27 17:15:02,230 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO server.RaftServer: fb410344-fcfe-4f99-b41b-29dd0a68d978: start RPC server
datanode_4          | 2022-07-27 17:15:02,253 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO server.GrpcService: fb410344-fcfe-4f99-b41b-29dd0a68d978: GrpcService started, listening on 9856
datanode_4          | 2022-07-27 17:15:02,264 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO server.GrpcService: fb410344-fcfe-4f99-b41b-29dd0a68d978: GrpcService started, listening on 9857
datanode_4          | 2022-07-27 17:15:02,274 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO server.GrpcService: fb410344-fcfe-4f99-b41b-29dd0a68d978: GrpcService started, listening on 9858
datanode_5          | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_5          | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
datanode_5          | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
datanode_5          | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5          | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5          | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5          | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_5          | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.12:58090 remote=recon/172.23.0.11:9891]
datanode_5          | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_5          | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_5          | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_5          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_5          | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_5          | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_5          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_5          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_5          | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
datanode_5          | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_5          | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
datanode_5          | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
datanode_5          | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
datanode_5          | 2022-07-27 17:15:00,972 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_5          | java.net.SocketTimeoutException: Call From 48d5efc1923c/172.23.0.12 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.12:56576 remote=scm/172.23.0.4:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_5          | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_5          | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_5          | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_5          | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_5          | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode_5          | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
datanode_5          | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
datanode_5          | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
datanode_5          | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
datanode_5          | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
datanode_5          | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
datanode_5          | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
datanode_5          | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_5          | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_5          | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
datanode_5          | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
datanode_5          | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5          | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5          | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5          | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_5          | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.12:56576 remote=scm/172.23.0.4:9861]
datanode_5          | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_5          | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_5          | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_5          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_5          | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_5          | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_5          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_5          | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_5          | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
datanode_5          | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_5          | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
datanode_5          | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
datanode_5          | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
datanode_5          | 2022-07-27 17:15:01,716 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-7d45909c-9fcd-4dc9-be34-cfa80db7825a/DS-67069b75-6fc3-42ed-a51e-f80681b0e0ae/container.db for volume DS-67069b75-6fc3-42ed-a51e-f80681b0e0ae
datanode_5          | 2022-07-27 17:15:01,749 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-7d45909c-9fcd-4dc9-be34-cfa80db7825a/DS-67069b75-6fc3-42ed-a51e-f80681b0e0ae/container.db for volume DS-67069b75-6fc3-42ed-a51e-f80681b0e0ae
datanode_5          | 2022-07-27 17:15:01,755 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_5          | 2022-07-27 17:15:01,780 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_5          | 2022-07-27 17:15:02,073 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 2750dc88-6529-455f-a3a5-c6a6089a5bfe
datanode_5          | 2022-07-27 17:15:02,255 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO server.RaftServer: 2750dc88-6529-455f-a3a5-c6a6089a5bfe: start RPC server
datanode_5          | 2022-07-27 17:15:02,266 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO server.GrpcService: 2750dc88-6529-455f-a3a5-c6a6089a5bfe: GrpcService started, listening on 9856
datanode_5          | 2022-07-27 17:15:02,278 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO server.GrpcService: 2750dc88-6529-455f-a3a5-c6a6089a5bfe: GrpcService started, listening on 9857
datanode_5          | 2022-07-27 17:15:02,279 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO server.GrpcService: 2750dc88-6529-455f-a3a5-c6a6089a5bfe: GrpcService started, listening on 9858
datanode_4          | 2022-07-27 17:15:02,277 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis fb410344-fcfe-4f99-b41b-29dd0a68d978 is started using port 9858 for RATIS
datanode_4          | 2022-07-27 17:15:02,277 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis fb410344-fcfe-4f99-b41b-29dd0a68d978 is started using port 9857 for RATIS_ADMIN
datanode_4          | 2022-07-27 17:15:02,278 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis fb410344-fcfe-4f99-b41b-29dd0a68d978 is started using port 9856 for RATIS_SERVER
datanode_4          | 2022-07-27 17:15:02,278 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$344/0x00000008404f6840@28f9b91b] INFO util.JvmPauseMonitor: JvmPauseMonitor-fb410344-fcfe-4f99-b41b-29dd0a68d978: Started
datanode_4          | 2022-07-27 17:15:07,353 [Command processor thread] INFO server.RaftServer: fb410344-fcfe-4f99-b41b-29dd0a68d978: addNew group-13FCC6BFCCB5:[fb410344-fcfe-4f99-b41b-29dd0a68d978|rpc:172.23.0.13:9856|admin:172.23.0.13:9857|client:172.23.0.13:9858|priority:1] returns group-13FCC6BFCCB5:java.util.concurrent.CompletableFuture@2c57c74a[Not completed]
datanode_4          | 2022-07-27 17:15:07,611 [pool-22-thread-1] INFO server.RaftServer$Division: fb410344-fcfe-4f99-b41b-29dd0a68d978: new RaftServerImpl for group-13FCC6BFCCB5:[fb410344-fcfe-4f99-b41b-29dd0a68d978|rpc:172.23.0.13:9856|admin:172.23.0.13:9857|client:172.23.0.13:9858|priority:1] with ContainerStateMachine:uninitialized
datanode_4          | 2022-07-27 17:15:07,641 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_4          | 2022-07-27 17:15:07,643 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_4          | 2022-07-27 17:15:07,643 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_4          | 2022-07-27 17:15:07,644 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_4          | 2022-07-27 17:15:07,644 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_4          | 2022-07-27 17:15:07,644 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_4          | 2022-07-27 17:15:07,692 [pool-22-thread-1] INFO server.RaftServer$Division: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5: ConfigurationManager, init=-1: [fb410344-fcfe-4f99-b41b-29dd0a68d978|rpc:172.23.0.13:9856|admin:172.23.0.13:9857|client:172.23.0.13:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode_4          | 2022-07-27 17:15:07,693 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4          | 2022-07-27 17:15:07,730 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4          | 2022-07-27 17:15:07,768 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_4          | 2022-07-27 17:15:07,773 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/d09c0e06-9ec9-4ed1-9cd9-13fcc6bfccb5 does not exist. Creating ...
datanode_4          | 2022-07-27 17:15:07,809 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/d09c0e06-9ec9-4ed1-9cd9-13fcc6bfccb5/in_use.lock acquired by nodename 7@caa94ab9ee1a
datanode_4          | 2022-07-27 17:15:07,842 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/d09c0e06-9ec9-4ed1-9cd9-13fcc6bfccb5 has been successfully formatted.
datanode_4          | 2022-07-27 17:15:07,930 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-13FCC6BFCCB5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_4          | 2022-07-27 17:15:07,942 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_4          | 2022-07-27 17:15:07,949 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4          | 2022-07-27 17:15:08,023 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_4          | 2022-07-27 17:15:08,023 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4          | 2022-07-27 17:15:08,088 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_4          | 2022-07-27 17:15:08,220 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4          | 2022-07-27 17:15:08,416 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_4          | 2022-07-27 17:15:08,424 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_4          | 2022-07-27 17:15:08,500 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/d09c0e06-9ec9-4ed1-9cd9-13fcc6bfccb5
datanode_4          | 2022-07-27 17:15:08,501 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_4          | 2022-07-27 17:15:08,509 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_4          | 2022-07-27 17:15:08,552 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4          | 2022-07-27 17:15:08,557 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_4          | 2022-07-27 17:15:08,559 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_4          | 2022-07-27 17:15:08,562 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_4          | 2022-07-27 17:15:08,567 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_4          | 2022-07-27 17:15:08,570 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_4          | 2022-07-27 17:15:08,672 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_4          | 2022-07-27 17:15:08,673 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_4          | 2022-07-27 17:15:08,673 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_4          | 2022-07-27 17:15:08,720 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_4          | 2022-07-27 17:15:08,720 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_4          | 2022-07-27 17:15:08,738 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_4          | 2022-07-27 17:15:08,756 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_4          | 2022-07-27 17:15:08,765 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_4          | 2022-07-27 17:15:08,769 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_5          | 2022-07-27 17:15:02,301 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 2750dc88-6529-455f-a3a5-c6a6089a5bfe is started using port 9858 for RATIS
datanode_5          | 2022-07-27 17:15:02,301 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 2750dc88-6529-455f-a3a5-c6a6089a5bfe is started using port 9857 for RATIS_ADMIN
datanode_5          | 2022-07-27 17:15:02,301 [EndpointStateMachine task thread for scm/172.23.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 2750dc88-6529-455f-a3a5-c6a6089a5bfe is started using port 9856 for RATIS_SERVER
datanode_5          | 2022-07-27 17:15:02,302 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$343/0x0000000840501440@2d566ff3] INFO util.JvmPauseMonitor: JvmPauseMonitor-2750dc88-6529-455f-a3a5-c6a6089a5bfe: Started
datanode_5          | 2022-07-27 17:15:05,777 [Command processor thread] INFO server.RaftServer: 2750dc88-6529-455f-a3a5-c6a6089a5bfe: addNew group-78C2755A5DDC:[b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:1, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:0] returns group-78C2755A5DDC:java.util.concurrent.CompletableFuture@2c57c74a[Not completed]
datanode_5          | 2022-07-27 17:15:06,013 [pool-22-thread-1] INFO server.RaftServer$Division: 2750dc88-6529-455f-a3a5-c6a6089a5bfe: new RaftServerImpl for group-78C2755A5DDC:[b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:1, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:0] with ContainerStateMachine:uninitialized
datanode_5          | 2022-07-27 17:15:06,015 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_5          | 2022-07-27 17:15:06,015 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_5          | 2022-07-27 17:15:06,016 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_5          | 2022-07-27 17:15:06,023 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_5          | 2022-07-27 17:15:06,023 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_5          | 2022-07-27 17:15:06,024 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_5          | 2022-07-27 17:15:06,041 [pool-22-thread-1] INFO server.RaftServer$Division: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC: ConfigurationManager, init=-1: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:1, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode_5          | 2022-07-27 17:15:06,046 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5          | 2022-07-27 17:15:06,079 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5          | 2022-07-27 17:15:06,096 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_5          | 2022-07-27 17:15:06,098 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/ee453f3e-2788-418a-bfda-78c2755a5ddc does not exist. Creating ...
datanode_5          | 2022-07-27 17:15:06,116 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/ee453f3e-2788-418a-bfda-78c2755a5ddc/in_use.lock acquired by nodename 6@48d5efc1923c
datanode_5          | 2022-07-27 17:15:06,131 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/ee453f3e-2788-418a-bfda-78c2755a5ddc has been successfully formatted.
datanode_5          | 2022-07-27 17:15:06,203 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-78C2755A5DDC: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_5          | 2022-07-27 17:15:06,225 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_5          | 2022-07-27 17:15:06,260 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_5          | 2022-07-27 17:15:06,333 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_5          | 2022-07-27 17:15:06,346 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5          | 2022-07-27 17:15:06,355 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_5          | 2022-07-27 17:15:06,406 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5          | 2022-07-27 17:15:06,438 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_5          | 2022-07-27 17:15:06,447 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_5          | 2022-07-27 17:15:06,459 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/ee453f3e-2788-418a-bfda-78c2755a5ddc
datanode_5          | 2022-07-27 17:15:06,480 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_5          | 2022-07-27 17:15:06,483 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_5          | 2022-07-27 17:15:06,488 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5          | 2022-07-27 17:15:06,493 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_5          | 2022-07-27 17:15:06,493 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_5          | 2022-07-27 17:15:06,513 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_5          | 2022-07-27 17:15:06,513 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_5          | 2022-07-27 17:15:06,514 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_5          | 2022-07-27 17:15:06,542 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_5          | 2022-07-27 17:15:06,557 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_5          | 2022-07-27 17:15:06,560 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_5          | 2022-07-27 17:15:06,588 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_4          | 2022-07-27 17:15:08,783 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_4          | 2022-07-27 17:15:08,784 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_4          | 2022-07-27 17:15:08,903 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4          | 2022-07-27 17:15:08,915 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_4          | 2022-07-27 17:15:08,916 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_4          | 2022-07-27 17:15:08,916 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_4          | 2022-07-27 17:15:08,917 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_4          | 2022-07-27 17:15:08,918 [pool-22-thread-1] INFO server.RaftServer$Division: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5: start as a follower, conf=-1: [fb410344-fcfe-4f99-b41b-29dd0a68d978|rpc:172.23.0.13:9856|admin:172.23.0.13:9857|client:172.23.0.13:9858|priority:1], old=null
datanode_4          | 2022-07-27 17:15:08,919 [pool-22-thread-1] INFO server.RaftServer$Division: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_4          | 2022-07-27 17:15:08,920 [pool-22-thread-1] INFO impl.RoleInfo: fb410344-fcfe-4f99-b41b-29dd0a68d978: start fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-FollowerState
datanode_4          | 2022-07-27 17:15:08,941 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-13FCC6BFCCB5,id=fb410344-fcfe-4f99-b41b-29dd0a68d978
datanode_4          | 2022-07-27 17:15:09,042 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=d09c0e06-9ec9-4ed1-9cd9-13fcc6bfccb5
datanode_4          | 2022-07-27 17:15:09,043 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=d09c0e06-9ec9-4ed1-9cd9-13fcc6bfccb5.
datanode_4          | 2022-07-27 17:15:09,044 [Command processor thread] INFO server.RaftServer: fb410344-fcfe-4f99-b41b-29dd0a68d978: addNew group-747C147E1F30:[5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:0, fb410344-fcfe-4f99-b41b-29dd0a68d978|rpc:172.23.0.13:9856|admin:172.23.0.13:9857|client:172.23.0.13:9858|priority:1] returns group-747C147E1F30:java.util.concurrent.CompletableFuture@5cceb11a[Not completed]
datanode_4          | 2022-07-27 17:15:09,051 [pool-22-thread-1] INFO server.RaftServer$Division: fb410344-fcfe-4f99-b41b-29dd0a68d978: new RaftServerImpl for group-747C147E1F30:[5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:0, fb410344-fcfe-4f99-b41b-29dd0a68d978|rpc:172.23.0.13:9856|admin:172.23.0.13:9857|client:172.23.0.13:9858|priority:1] with ContainerStateMachine:uninitialized
datanode_4          | 2022-07-27 17:15:09,078 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_4          | 2022-07-27 17:15:09,081 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_4          | 2022-07-27 17:15:09,082 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_4          | 2022-07-27 17:15:09,082 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_4          | 2022-07-27 17:15:09,082 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_4          | 2022-07-27 17:15:09,082 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_4          | 2022-07-27 17:15:09,084 [pool-22-thread-1] INFO server.RaftServer$Division: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30: ConfigurationManager, init=-1: [5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:0, fb410344-fcfe-4f99-b41b-29dd0a68d978|rpc:172.23.0.13:9856|admin:172.23.0.13:9857|client:172.23.0.13:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode_4          | 2022-07-27 17:15:09,084 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4          | 2022-07-27 17:15:09,084 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4          | 2022-07-27 17:15:09,084 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_4          | 2022-07-27 17:15:09,084 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/02ad9aa3-8955-4f68-a76b-747c147e1f30 does not exist. Creating ...
datanode_4          | 2022-07-27 17:15:09,100 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/02ad9aa3-8955-4f68-a76b-747c147e1f30/in_use.lock acquired by nodename 7@caa94ab9ee1a
datanode_4          | 2022-07-27 17:15:09,110 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/02ad9aa3-8955-4f68-a76b-747c147e1f30 has been successfully formatted.
datanode_4          | 2022-07-27 17:15:09,115 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-747C147E1F30: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_4          | 2022-07-27 17:15:09,122 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_4          | 2022-07-27 17:15:09,122 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4          | 2022-07-27 17:15:09,122 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_4          | 2022-07-27 17:15:09,122 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4          | 2022-07-27 17:15:09,122 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_4          | 2022-07-27 17:15:09,123 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4          | 2022-07-27 17:15:09,127 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_4          | 2022-07-27 17:15:09,127 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_4          | 2022-07-27 17:15:09,127 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/02ad9aa3-8955-4f68-a76b-747c147e1f30
datanode_4          | 2022-07-27 17:15:09,127 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_4          | 2022-07-27 17:15:09,128 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_4          | 2022-07-27 17:15:09,128 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4          | 2022-07-27 17:15:09,128 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_4          | 2022-07-27 17:15:09,128 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_5          | 2022-07-27 17:15:06,591 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_5          | 2022-07-27 17:15:06,597 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_5          | 2022-07-27 17:15:06,608 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_5          | 2022-07-27 17:15:06,608 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_5          | 2022-07-27 17:15:06,611 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_5          | 2022-07-27 17:15:06,614 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_5          | 2022-07-27 17:15:06,619 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_5          | 2022-07-27 17:15:06,789 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5          | 2022-07-27 17:15:06,795 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_5          | 2022-07-27 17:15:06,799 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_5          | 2022-07-27 17:15:06,801 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_5          | 2022-07-27 17:15:06,801 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_5          | 2022-07-27 17:15:06,802 [pool-22-thread-1] INFO server.RaftServer$Division: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC: start as a follower, conf=-1: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:1, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:0], old=null
datanode_5          | 2022-07-27 17:15:06,816 [pool-22-thread-1] INFO server.RaftServer$Division: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_5          | 2022-07-27 17:15:06,831 [pool-22-thread-1] INFO impl.RoleInfo: 2750dc88-6529-455f-a3a5-c6a6089a5bfe: start 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-FollowerState
datanode_5          | 2022-07-27 17:15:06,850 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-78C2755A5DDC,id=2750dc88-6529-455f-a3a5-c6a6089a5bfe
datanode_5          | 2022-07-27 17:15:06,918 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=ee453f3e-2788-418a-bfda-78c2755a5ddc
datanode_5          | 2022-07-27 17:15:11,902 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=ee453f3e-2788-418a-bfda-78c2755a5ddc.
datanode_5          | 2022-07-27 17:15:11,902 [Command processor thread] INFO server.RaftServer: 2750dc88-6529-455f-a3a5-c6a6089a5bfe: addNew group-DEF6498BD1FD:[2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:1] returns group-DEF6498BD1FD:java.util.concurrent.CompletableFuture@75be8af4[Not completed]
datanode_5          | 2022-07-27 17:15:11,904 [pool-22-thread-1] INFO server.RaftServer$Division: 2750dc88-6529-455f-a3a5-c6a6089a5bfe: new RaftServerImpl for group-DEF6498BD1FD:[2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:1] with ContainerStateMachine:uninitialized
datanode_5          | 2022-07-27 17:15:11,904 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_5          | 2022-07-27 17:15:11,905 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_5          | 2022-07-27 17:15:11,905 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_5          | 2022-07-27 17:15:11,905 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_5          | 2022-07-27 17:15:11,905 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_5          | 2022-07-27 17:15:11,905 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_5          | 2022-07-27 17:15:11,905 [pool-22-thread-1] INFO server.RaftServer$Division: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD: ConfigurationManager, init=-1: [2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode_5          | 2022-07-27 17:15:11,906 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5          | 2022-07-27 17:15:11,906 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5          | 2022-07-27 17:15:11,906 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_5          | 2022-07-27 17:15:11,906 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/8d4254b1-f279-4915-b6c2-def6498bd1fd does not exist. Creating ...
datanode_5          | 2022-07-27 17:15:11,908 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/8d4254b1-f279-4915-b6c2-def6498bd1fd/in_use.lock acquired by nodename 6@48d5efc1923c
datanode_5          | 2022-07-27 17:15:11,911 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/8d4254b1-f279-4915-b6c2-def6498bd1fd has been successfully formatted.
datanode_5          | 2022-07-27 17:15:11,911 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-DEF6498BD1FD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_5          | 2022-07-27 17:15:11,920 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_5          | 2022-07-27 17:15:11,926 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_5          | 2022-07-27 17:15:11,930 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_5          | 2022-07-27 17:15:11,930 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5          | 2022-07-27 17:15:11,930 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_5          | 2022-07-27 17:15:11,930 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5          | 2022-07-27 17:15:11,931 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_5          | 2022-07-27 17:15:11,939 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_5          | 2022-07-27 17:15:11,940 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/8d4254b1-f279-4915-b6c2-def6498bd1fd
datanode_5          | 2022-07-27 17:15:11,941 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_5          | 2022-07-27 17:15:11,942 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_5          | 2022-07-27 17:15:11,945 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4          | 2022-07-27 17:15:09,128 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_4          | 2022-07-27 17:15:09,128 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_4          | 2022-07-27 17:15:09,128 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_4          | 2022-07-27 17:15:09,129 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_4          | 2022-07-27 17:15:09,143 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_4          | 2022-07-27 17:15:09,143 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_4          | 2022-07-27 17:15:09,143 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_4          | 2022-07-27 17:15:09,159 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_4          | 2022-07-27 17:15:09,164 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_4          | 2022-07-27 17:15:09,165 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_4          | 2022-07-27 17:15:09,166 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_4          | 2022-07-27 17:15:09,166 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_4          | 2022-07-27 17:15:09,170 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_4          | 2022-07-27 17:15:09,171 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_4          | 2022-07-27 17:15:09,176 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4          | 2022-07-27 17:15:09,178 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_4          | 2022-07-27 17:15:09,178 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_4          | 2022-07-27 17:15:09,179 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_4          | 2022-07-27 17:15:09,179 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_4          | 2022-07-27 17:15:09,179 [pool-22-thread-1] INFO server.RaftServer$Division: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30: start as a follower, conf=-1: [5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:0, fb410344-fcfe-4f99-b41b-29dd0a68d978|rpc:172.23.0.13:9856|admin:172.23.0.13:9857|client:172.23.0.13:9858|priority:1], old=null
datanode_4          | 2022-07-27 17:15:09,180 [pool-22-thread-1] INFO server.RaftServer$Division: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_4          | 2022-07-27 17:15:09,180 [pool-22-thread-1] INFO impl.RoleInfo: fb410344-fcfe-4f99-b41b-29dd0a68d978: start fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-FollowerState
datanode_4          | 2022-07-27 17:15:09,192 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-747C147E1F30,id=fb410344-fcfe-4f99-b41b-29dd0a68d978
datanode_4          | 2022-07-27 17:15:09,193 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=02ad9aa3-8955-4f68-a76b-747c147e1f30
datanode_4          | 2022-07-27 17:15:13,494 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=02ad9aa3-8955-4f68-a76b-747c147e1f30.
datanode_4          | 2022-07-27 17:15:14,101 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-FollowerState] INFO impl.FollowerState: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5181525187ns, electionTimeout:5169ms
datanode_4          | 2022-07-27 17:15:14,102 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-FollowerState] INFO impl.RoleInfo: fb410344-fcfe-4f99-b41b-29dd0a68d978: shutdown fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-FollowerState
datanode_4          | 2022-07-27 17:15:14,103 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-FollowerState] INFO server.RaftServer$Division: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_4          | 2022-07-27 17:15:14,106 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_4          | 2022-07-27 17:15:14,106 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-FollowerState] INFO impl.RoleInfo: fb410344-fcfe-4f99-b41b-29dd0a68d978: start fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-LeaderElection1
datanode_4          | 2022-07-27 17:15:14,120 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-LeaderElection1] INFO impl.LeaderElection: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [fb410344-fcfe-4f99-b41b-29dd0a68d978|rpc:172.23.0.13:9856|admin:172.23.0.13:9857|client:172.23.0.13:9858|priority:1], old=null
datanode_4          | 2022-07-27 17:15:14,121 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-LeaderElection1] INFO impl.LeaderElection: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode_4          | 2022-07-27 17:15:14,121 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-LeaderElection1] INFO impl.RoleInfo: fb410344-fcfe-4f99-b41b-29dd0a68d978: shutdown fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-LeaderElection1
datanode_4          | 2022-07-27 17:15:14,123 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-LeaderElection1] INFO server.RaftServer$Division: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_4          | 2022-07-27 17:15:14,123 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-13FCC6BFCCB5 with new leaderId: fb410344-fcfe-4f99-b41b-29dd0a68d978
datanode_4          | 2022-07-27 17:15:14,124 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-LeaderElection1] INFO server.RaftServer$Division: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5: change Leader from null to fb410344-fcfe-4f99-b41b-29dd0a68d978 at term 1 for becomeLeader, leader elected after 6180ms
datanode_4          | 2022-07-27 17:15:14,145 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_4          | 2022-07-27 17:15:14,158 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_4          | 2022-07-27 17:15:14,162 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode_5          | 2022-07-27 17:15:11,946 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_5          | 2022-07-27 17:15:11,946 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_5          | 2022-07-27 17:15:11,946 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_5          | 2022-07-27 17:15:11,952 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_5          | 2022-07-27 17:15:11,952 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_5          | 2022-07-27 17:15:11,957 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_5          | 2022-07-27 17:15:11,960 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_5          | 2022-07-27 17:15:11,964 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_5          | 2022-07-27 17:15:11,965 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_5          | 2022-07-27 17:15:11,965 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_5          | 2022-07-27 17:15:11,971 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_5          | 2022-07-27 17:15:11,971 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_5          | 2022-07-27 17:15:11,972 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_5          | 2022-07-27 17:15:11,975 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_5          | 2022-07-27 17:15:11,975 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_5          | 2022-07-27 17:15:11,975 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_5          | 2022-07-27 17:15:11,986 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5          | 2022-07-27 17:15:11,988 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_5          | 2022-07-27 17:15:11,990 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_5          | 2022-07-27 17:15:11,990 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_5          | 2022-07-27 17:15:11,991 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-FollowerState] INFO impl.FollowerState: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5174253419ns, electionTimeout:5140ms
datanode_5          | 2022-07-27 17:15:11,992 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-FollowerState] INFO impl.RoleInfo: 2750dc88-6529-455f-a3a5-c6a6089a5bfe: shutdown 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-FollowerState
datanode_5          | 2022-07-27 17:15:11,992 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_5          | 2022-07-27 17:15:11,992 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-FollowerState] INFO server.RaftServer$Division: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_5          | 2022-07-27 17:15:11,996 [pool-22-thread-1] INFO server.RaftServer$Division: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD: start as a follower, conf=-1: [2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:1], old=null
datanode_5          | 2022-07-27 17:15:11,996 [pool-22-thread-1] INFO server.RaftServer$Division: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_5          | 2022-07-27 17:15:11,996 [pool-22-thread-1] INFO impl.RoleInfo: 2750dc88-6529-455f-a3a5-c6a6089a5bfe: start 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-FollowerState
datanode_5          | 2022-07-27 17:15:12,044 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_5          | 2022-07-27 17:15:12,044 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-FollowerState] INFO impl.RoleInfo: 2750dc88-6529-455f-a3a5-c6a6089a5bfe: start 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-LeaderElection1
datanode_5          | 2022-07-27 17:15:12,046 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DEF6498BD1FD,id=2750dc88-6529-455f-a3a5-c6a6089a5bfe
datanode_5          | 2022-07-27 17:15:12,056 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=8d4254b1-f279-4915-b6c2-def6498bd1fd
datanode_5          | 2022-07-27 17:15:12,056 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=8d4254b1-f279-4915-b6c2-def6498bd1fd.
datanode_5          | 2022-07-27 17:15:12,057 [Command processor thread] INFO server.RaftServer: 2750dc88-6529-455f-a3a5-c6a6089a5bfe: addNew group-747C147E1F30:[5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:0, fb410344-fcfe-4f99-b41b-29dd0a68d978|rpc:172.23.0.13:9856|admin:172.23.0.13:9857|client:172.23.0.13:9858|priority:1] returns group-747C147E1F30:java.util.concurrent.CompletableFuture@53c1dd1f[Not completed]
datanode_5          | 2022-07-27 17:15:12,061 [pool-22-thread-1] INFO server.RaftServer$Division: 2750dc88-6529-455f-a3a5-c6a6089a5bfe: new RaftServerImpl for group-747C147E1F30:[5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:0, fb410344-fcfe-4f99-b41b-29dd0a68d978|rpc:172.23.0.13:9856|admin:172.23.0.13:9857|client:172.23.0.13:9858|priority:1] with ContainerStateMachine:uninitialized
datanode_5          | 2022-07-27 17:15:12,062 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_5          | 2022-07-27 17:15:12,062 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_5          | 2022-07-27 17:15:12,062 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_5          | 2022-07-27 17:15:12,062 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_5          | 2022-07-27 17:15:12,062 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_5          | 2022-07-27 17:15:12,062 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_4          | 2022-07-27 17:15:14,182 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_4          | 2022-07-27 17:15:14,184 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_4          | 2022-07-27 17:15:14,188 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_4          | 2022-07-27 17:15:14,208 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_4          | 2022-07-27 17:15:14,221 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode_4          | 2022-07-27 17:15:14,226 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-LeaderElection1] INFO impl.RoleInfo: fb410344-fcfe-4f99-b41b-29dd0a68d978: start fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-LeaderStateImpl
datanode_4          | 2022-07-27 17:15:14,249 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-SegmentedRaftLogWorker: Starting segment from index:0
datanode_4          | 2022-07-27 17:15:14,300 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-LeaderElection1] INFO server.RaftServer$Division: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5: set configuration 0: [fb410344-fcfe-4f99-b41b-29dd0a68d978|rpc:172.23.0.13:9856|admin:172.23.0.13:9857|client:172.23.0.13:9858|dataStream:|priority:1], old=null
datanode_4          | 2022-07-27 17:15:14,300 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-FollowerState] INFO impl.FollowerState: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5119691974ns, electionTimeout:5088ms
datanode_4          | 2022-07-27 17:15:14,303 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-FollowerState] INFO impl.RoleInfo: fb410344-fcfe-4f99-b41b-29dd0a68d978: shutdown fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-FollowerState
datanode_4          | 2022-07-27 17:15:14,304 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-FollowerState] INFO server.RaftServer$Division: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_4          | 2022-07-27 17:15:14,304 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_4          | 2022-07-27 17:15:14,304 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-FollowerState] INFO impl.RoleInfo: fb410344-fcfe-4f99-b41b-29dd0a68d978: start fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2
datanode_4          | 2022-07-27 17:15:14,328 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO impl.LeaderElection: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:0, fb410344-fcfe-4f99-b41b-29dd0a68d978|rpc:172.23.0.13:9856|admin:172.23.0.13:9857|client:172.23.0.13:9858|priority:1], old=null
datanode_4          | 2022-07-27 17:15:14,469 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO impl.LeaderElection: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode_4          | 2022-07-27 17:15:14,470 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO impl.LeaderElection:   Response 0: fb410344-fcfe-4f99-b41b-29dd0a68d978<-5a16948f-0635-4af6-ad47-d40ff1547cf8#0:OK-t1
datanode_4          | 2022-07-27 17:15:14,470 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO impl.LeaderElection: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2 ELECTION round 0: result PASSED
datanode_4          | 2022-07-27 17:15:14,470 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO impl.RoleInfo: fb410344-fcfe-4f99-b41b-29dd0a68d978: shutdown fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2
datanode_4          | 2022-07-27 17:15:14,471 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO server.RaftServer$Division: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_4          | 2022-07-27 17:15:14,471 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-747C147E1F30 with new leaderId: fb410344-fcfe-4f99-b41b-29dd0a68d978
datanode_4          | 2022-07-27 17:15:14,471 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO server.RaftServer$Division: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30: change Leader from null to fb410344-fcfe-4f99-b41b-29dd0a68d978 at term 1 for becomeLeader, leader elected after 5349ms
datanode_4          | 2022-07-27 17:15:14,474 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_4          | 2022-07-27 17:15:14,474 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_4          | 2022-07-27 17:15:14,474 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode_4          | 2022-07-27 17:15:14,475 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_4          | 2022-07-27 17:15:14,475 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_4          | 2022-07-27 17:15:14,475 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_4          | 2022-07-27 17:15:14,475 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_4          | 2022-07-27 17:15:14,476 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode_4          | 2022-07-27 17:15:14,521 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_4          | 2022-07-27 17:15:14,523 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4          | 2022-07-27 17:15:14,526 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_4          | 2022-07-27 17:15:14,534 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_4          | 2022-07-27 17:15:14,538 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_5          | 2022-07-27 17:15:12,062 [pool-22-thread-1] INFO server.RaftServer$Division: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-747C147E1F30: ConfigurationManager, init=-1: [5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:0, fb410344-fcfe-4f99-b41b-29dd0a68d978|rpc:172.23.0.13:9856|admin:172.23.0.13:9857|client:172.23.0.13:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode_5          | 2022-07-27 17:15:12,063 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5          | 2022-07-27 17:15:12,063 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5          | 2022-07-27 17:15:12,063 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_5          | 2022-07-27 17:15:12,064 [pool-22-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/02ad9aa3-8955-4f68-a76b-747c147e1f30 does not exist. Creating ...
datanode_5          | 2022-07-27 17:15:12,065 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/02ad9aa3-8955-4f68-a76b-747c147e1f30/in_use.lock acquired by nodename 6@48d5efc1923c
datanode_5          | 2022-07-27 17:15:12,066 [pool-22-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/02ad9aa3-8955-4f68-a76b-747c147e1f30 has been successfully formatted.
datanode_5          | 2022-07-27 17:15:12,067 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-747C147E1F30: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_5          | 2022-07-27 17:15:12,067 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_5          | 2022-07-27 17:15:12,068 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_5          | 2022-07-27 17:15:12,068 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_5          | 2022-07-27 17:15:12,072 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5          | 2022-07-27 17:15:12,074 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_5          | 2022-07-27 17:15:12,074 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5          | 2022-07-27 17:15:12,075 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_5          | 2022-07-27 17:15:12,101 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_5          | 2022-07-27 17:15:12,101 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-747C147E1F30-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/02ad9aa3-8955-4f68-a76b-747c147e1f30
datanode_5          | 2022-07-27 17:15:12,101 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_5          | 2022-07-27 17:15:12,074 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-LeaderElection1] INFO impl.LeaderElection: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:1, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:0], old=null
datanode_5          | 2022-07-27 17:15:12,102 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_5          | 2022-07-27 17:15:12,119 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5          | 2022-07-27 17:15:12,119 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_5          | 2022-07-27 17:15:12,123 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_5          | 2022-07-27 17:15:12,123 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_5          | 2022-07-27 17:15:12,123 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_5          | 2022-07-27 17:15:12,124 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_5          | 2022-07-27 17:15:12,124 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_5          | 2022-07-27 17:15:12,127 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_5          | 2022-07-27 17:15:12,143 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_5          | 2022-07-27 17:15:12,146 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-747C147E1F30-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_5          | 2022-07-27 17:15:12,151 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-747C147E1F30-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_5          | 2022-07-27 17:15:12,158 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_5          | 2022-07-27 17:15:12,159 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_5          | 2022-07-27 17:15:12,159 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_5          | 2022-07-27 17:15:12,159 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_5          | 2022-07-27 17:15:12,159 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_5          | 2022-07-27 17:15:12,159 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_5          | 2022-07-27 17:15:12,168 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5          | 2022-07-27 17:15:12,168 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_5          | 2022-07-27 17:15:12,168 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_5          | 2022-07-27 17:15:12,168 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_5          | 2022-07-27 17:15:12,168 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_5          | 2022-07-27 17:15:12,169 [pool-22-thread-1] INFO server.RaftServer$Division: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-747C147E1F30: start as a follower, conf=-1: [5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:0, fb410344-fcfe-4f99-b41b-29dd0a68d978|rpc:172.23.0.13:9856|admin:172.23.0.13:9857|client:172.23.0.13:9858|priority:1], old=null
datanode_5          | 2022-07-27 17:15:12,169 [pool-22-thread-1] INFO server.RaftServer$Division: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-747C147E1F30: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_5          | 2022-07-27 17:15:12,169 [pool-22-thread-1] INFO impl.RoleInfo: 2750dc88-6529-455f-a3a5-c6a6089a5bfe: start 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-747C147E1F30-FollowerState
datanode_4          | 2022-07-27 17:15:14,540 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4          | 2022-07-27 17:15:14,544 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_4          | 2022-07-27 17:15:14,557 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4          | 2022-07-27 17:15:14,571 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_4          | 2022-07-27 17:15:14,571 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_4          | 2022-07-27 17:15:14,572 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_4          | 2022-07-27 17:15:14,572 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4          | 2022-07-27 17:15:14,574 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO impl.RoleInfo: fb410344-fcfe-4f99-b41b-29dd0a68d978: start fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderStateImpl
datanode_4          | 2022-07-27 17:15:14,575 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-SegmentedRaftLogWorker: Starting segment from index:0
datanode_4          | 2022-07-27 17:15:14,605 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-LeaderElection2] INFO server.RaftServer$Division: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30: set configuration 0: [5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|dataStream:|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|dataStream:|priority:0, fb410344-fcfe-4f99-b41b-29dd0a68d978|rpc:172.23.0.13:9856|admin:172.23.0.13:9857|client:172.23.0.13:9858|dataStream:|priority:1], old=null
datanode_4          | 2022-07-27 17:15:14,789 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-747C147E1F30-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/02ad9aa3-8955-4f68-a76b-747c147e1f30/current/log_inprogress_0
datanode_4          | 2022-07-27 17:15:14,826 [fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: fb410344-fcfe-4f99-b41b-29dd0a68d978@group-13FCC6BFCCB5-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/d09c0e06-9ec9-4ed1-9cd9-13fcc6bfccb5/current/log_inprogress_0
datanode_5          | 2022-07-27 17:15:12,202 [pool-22-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-747C147E1F30,id=2750dc88-6529-455f-a3a5-c6a6089a5bfe
datanode_5          | 2022-07-27 17:15:12,227 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=02ad9aa3-8955-4f68-a76b-747c147e1f30
datanode_5          | 2022-07-27 17:15:12,333 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-LeaderElection1] INFO impl.LeaderElection: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-LeaderElection1: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode_5          | 2022-07-27 17:15:12,334 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-LeaderElection1] INFO impl.LeaderElection:   Response 0: 2750dc88-6529-455f-a3a5-c6a6089a5bfe<-b50d7a6b-da1f-4bca-b673-015544dce0bd#0:FAIL-t1
datanode_5          | 2022-07-27 17:15:12,339 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-LeaderElection1] INFO impl.LeaderElection: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-LeaderElection1 ELECTION round 0: result REJECTED
datanode_5          | 2022-07-27 17:15:12,340 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-LeaderElection1] INFO server.RaftServer$Division: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
datanode_5          | 2022-07-27 17:15:12,347 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-LeaderElection1] INFO impl.RoleInfo: 2750dc88-6529-455f-a3a5-c6a6089a5bfe: shutdown 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-LeaderElection1
datanode_5          | 2022-07-27 17:15:12,349 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-LeaderElection1] INFO impl.RoleInfo: 2750dc88-6529-455f-a3a5-c6a6089a5bfe: start 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-FollowerState
datanode_5          | 2022-07-27 17:15:12,691 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=02ad9aa3-8955-4f68-a76b-747c147e1f30.
datanode_5          | 2022-07-27 17:15:14,456 [grpc-default-executor-0] INFO server.RaftServer$Division: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-747C147E1F30: receive requestVote(ELECTION, fb410344-fcfe-4f99-b41b-29dd0a68d978, group-747C147E1F30, 1, (t:0, i:0))
datanode_5          | 2022-07-27 17:15:14,457 [grpc-default-executor-0] INFO impl.VoteContext: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-747C147E1F30-FOLLOWER: accept ELECTION from fb410344-fcfe-4f99-b41b-29dd0a68d978: our priority 0 <= candidate's priority 1
datanode_5          | 2022-07-27 17:15:14,458 [grpc-default-executor-0] INFO server.RaftServer$Division: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-747C147E1F30: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:fb410344-fcfe-4f99-b41b-29dd0a68d978
datanode_5          | 2022-07-27 17:15:14,458 [grpc-default-executor-0] INFO impl.RoleInfo: 2750dc88-6529-455f-a3a5-c6a6089a5bfe: shutdown 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-747C147E1F30-FollowerState
datanode_5          | 2022-07-27 17:15:14,458 [grpc-default-executor-0] INFO impl.RoleInfo: 2750dc88-6529-455f-a3a5-c6a6089a5bfe: start 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-747C147E1F30-FollowerState
datanode_5          | 2022-07-27 17:15:14,458 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-747C147E1F30-FollowerState] INFO impl.FollowerState: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-747C147E1F30-FollowerState was interrupted
datanode_5          | 2022-07-27 17:15:14,464 [grpc-default-executor-0] INFO server.RaftServer$Division: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-747C147E1F30 replies to ELECTION vote request: fb410344-fcfe-4f99-b41b-29dd0a68d978<-2750dc88-6529-455f-a3a5-c6a6089a5bfe#0:OK-t1. Peer's state: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-747C147E1F30:t1, leader=null, voted=fb410344-fcfe-4f99-b41b-29dd0a68d978, raftlog=2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-747C147E1F30-SegmentedRaftLog:OPENED:c-1, conf=-1: [5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:0, fb410344-fcfe-4f99-b41b-29dd0a68d978|rpc:172.23.0.13:9856|admin:172.23.0.13:9857|client:172.23.0.13:9858|priority:1], old=null
datanode_5          | 2022-07-27 17:15:14,650 [2750dc88-6529-455f-a3a5-c6a6089a5bfe-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-747C147E1F30 with new leaderId: fb410344-fcfe-4f99-b41b-29dd0a68d978
datanode_5          | 2022-07-27 17:15:14,650 [2750dc88-6529-455f-a3a5-c6a6089a5bfe-server-thread1] INFO server.RaftServer$Division: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-747C147E1F30: change Leader from null to fb410344-fcfe-4f99-b41b-29dd0a68d978 at term 1 for appendEntries, leader elected after 2582ms
datanode_5          | 2022-07-27 17:15:14,786 [2750dc88-6529-455f-a3a5-c6a6089a5bfe-server-thread1] INFO server.RaftServer$Division: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-747C147E1F30: set configuration 0: [5a16948f-0635-4af6-ad47-d40ff1547cf8|rpc:172.23.0.9:9856|admin:172.23.0.9:9857|client:172.23.0.9:9858|dataStream:|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|dataStream:|priority:0, fb410344-fcfe-4f99-b41b-29dd0a68d978|rpc:172.23.0.13:9856|admin:172.23.0.13:9857|client:172.23.0.13:9858|dataStream:|priority:1], old=null
datanode_5          | 2022-07-27 17:15:14,813 [2750dc88-6529-455f-a3a5-c6a6089a5bfe-server-thread1] INFO segmented.SegmentedRaftLogWorker: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-747C147E1F30-SegmentedRaftLogWorker: Starting segment from index:0
datanode_5          | 2022-07-27 17:15:15,014 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-747C147E1F30-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-747C147E1F30-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/02ad9aa3-8955-4f68-a76b-747c147e1f30/current/log_inprogress_0
datanode_5          | 2022-07-27 17:15:17,240 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-FollowerState] INFO impl.FollowerState: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5244187342ns, electionTimeout:5193ms
datanode_5          | 2022-07-27 17:15:17,240 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-FollowerState] INFO impl.RoleInfo: 2750dc88-6529-455f-a3a5-c6a6089a5bfe: shutdown 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-FollowerState
datanode_5          | 2022-07-27 17:15:17,241 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-FollowerState] INFO server.RaftServer$Division: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_5          | 2022-07-27 17:15:17,241 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_5          | 2022-07-27 17:15:17,241 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-FollowerState] INFO impl.RoleInfo: 2750dc88-6529-455f-a3a5-c6a6089a5bfe: start 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-LeaderElection2
datanode_5          | 2022-07-27 17:15:17,244 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-LeaderElection2] INFO impl.LeaderElection: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:1], old=null
datanode_5          | 2022-07-27 17:15:17,247 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-LeaderElection2] INFO impl.LeaderElection: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-LeaderElection2 ELECTION round 0: result PASSED (term=1)
datanode_5          | 2022-07-27 17:15:17,247 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-LeaderElection2] INFO impl.RoleInfo: 2750dc88-6529-455f-a3a5-c6a6089a5bfe: shutdown 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-LeaderElection2
datanode_5          | 2022-07-27 17:15:17,247 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-LeaderElection2] INFO server.RaftServer$Division: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_5          | 2022-07-27 17:15:17,247 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-DEF6498BD1FD with new leaderId: 2750dc88-6529-455f-a3a5-c6a6089a5bfe
datanode_5          | 2022-07-27 17:15:17,259 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-LeaderElection2] INFO server.RaftServer$Division: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD: change Leader from null to 2750dc88-6529-455f-a3a5-c6a6089a5bfe at term 1 for becomeLeader, leader elected after 5327ms
datanode_5          | 2022-07-27 17:15:17,275 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_5          | 2022-07-27 17:15:17,280 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_5          | 2022-07-27 17:15:17,281 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode_5          | 2022-07-27 17:15:17,292 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_5          | 2022-07-27 17:15:17,294 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_5          | 2022-07-27 17:15:17,295 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_5          | 2022-07-27 17:15:17,311 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_5          | 2022-07-27 17:15:17,316 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode_5          | 2022-07-27 17:15:17,321 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-LeaderElection2] INFO impl.RoleInfo: 2750dc88-6529-455f-a3a5-c6a6089a5bfe: start 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-LeaderStateImpl
datanode_5          | 2022-07-27 17:15:17,340 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-SegmentedRaftLogWorker: Starting segment from index:0
datanode_5          | 2022-07-27 17:15:17,349 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/8d4254b1-f279-4915-b6c2-def6498bd1fd/current/log_inprogress_0
datanode_5          | 2022-07-27 17:15:17,354 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD-LeaderElection2] INFO server.RaftServer$Division: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-DEF6498BD1FD: set configuration 0: [2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|dataStream:|priority:1], old=null
datanode_5          | 2022-07-27 17:15:17,404 [grpc-default-executor-0] INFO server.RaftServer$Division: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC: receive requestVote(ELECTION, b50d7a6b-da1f-4bca-b673-015544dce0bd, group-78C2755A5DDC, 2, (t:0, i:0))
datanode_5          | 2022-07-27 17:15:17,404 [grpc-default-executor-0] INFO impl.VoteContext: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-FOLLOWER: accept ELECTION from b50d7a6b-da1f-4bca-b673-015544dce0bd: our priority 0 <= candidate's priority 1
datanode_5          | 2022-07-27 17:15:17,404 [grpc-default-executor-0] INFO server.RaftServer$Division: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:b50d7a6b-da1f-4bca-b673-015544dce0bd
datanode_5          | 2022-07-27 17:15:17,404 [grpc-default-executor-0] INFO impl.RoleInfo: 2750dc88-6529-455f-a3a5-c6a6089a5bfe: shutdown 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-FollowerState
datanode_5          | 2022-07-27 17:15:17,407 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-FollowerState] INFO impl.FollowerState: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-FollowerState was interrupted
datanode_5          | 2022-07-27 17:15:17,413 [grpc-default-executor-0] INFO impl.RoleInfo: 2750dc88-6529-455f-a3a5-c6a6089a5bfe: start 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-FollowerState
datanode_5          | 2022-07-27 17:15:17,422 [grpc-default-executor-0] INFO server.RaftServer$Division: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC replies to ELECTION vote request: b50d7a6b-da1f-4bca-b673-015544dce0bd<-2750dc88-6529-455f-a3a5-c6a6089a5bfe#0:OK-t2. Peer's state: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC:t2, leader=null, voted=b50d7a6b-da1f-4bca-b673-015544dce0bd, raftlog=2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-SegmentedRaftLog:OPENED:c-1, conf=-1: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|priority:1, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|priority:0], old=null
datanode_5          | 2022-07-27 17:15:17,596 [2750dc88-6529-455f-a3a5-c6a6089a5bfe-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-78C2755A5DDC with new leaderId: b50d7a6b-da1f-4bca-b673-015544dce0bd
datanode_5          | 2022-07-27 17:15:17,597 [2750dc88-6529-455f-a3a5-c6a6089a5bfe-server-thread1] INFO server.RaftServer$Division: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC: change Leader from null to b50d7a6b-da1f-4bca-b673-015544dce0bd at term 2 for appendEntries, leader elected after 11378ms
datanode_5          | 2022-07-27 17:15:17,675 [2750dc88-6529-455f-a3a5-c6a6089a5bfe-server-thread1] INFO server.RaftServer$Division: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC: set configuration 0: [b50d7a6b-da1f-4bca-b673-015544dce0bd|rpc:172.23.0.10:9856|admin:172.23.0.10:9857|client:172.23.0.10:9858|dataStream:|priority:1, 0047ef4e-8059-4dda-a40b-cf26d888a843|rpc:172.23.0.6:9856|admin:172.23.0.6:9857|client:172.23.0.6:9858|dataStream:|priority:0, 2750dc88-6529-455f-a3a5-c6a6089a5bfe|rpc:172.23.0.12:9856|admin:172.23.0.12:9857|client:172.23.0.12:9858|dataStream:|priority:0], old=null
datanode_5          | 2022-07-27 17:15:17,676 [2750dc88-6529-455f-a3a5-c6a6089a5bfe-server-thread1] INFO segmented.SegmentedRaftLogWorker: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-SegmentedRaftLogWorker: Starting segment from index:0
datanode_5          | 2022-07-27 17:15:17,683 [2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 2750dc88-6529-455f-a3a5-c6a6089a5bfe@group-78C2755A5DDC-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/ee453f3e-2788-418a-bfda-78c2755a5ddc/current/log_inprogress_0
om_1                | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om_1                | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1                | 2022-07-27 17:14:15,436 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1                | /************************************************************
om_1                | STARTUP_MSG: Starting OzoneManager
om_1                | STARTUP_MSG:   host = 0dd774f2a837/172.23.0.3
om_1                | STARTUP_MSG:   args = [--init]
om_1                | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om_1                | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.6.3.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jcl-over-slf4j-1.7.24.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om_1                | STARTUP_MSG:   build = https://github.com/apache/ozone/9f188e38b2f4663af1a9169fb7f63dfe156555a0 ; compiled by 'runner' on 2022-07-27T16:19Z
om_1                | STARTUP_MSG:   java = 11.0.14.1
om_1                | ************************************************************/
om_1                | 2022-07-27 17:14:15,493 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1                | 2022-07-27 17:14:22,899 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om_1                | 2022-07-27 17:14:25,545 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1                | 2022-07-27 17:14:26,003 [main] INFO ha.OMHANodeDetails: Configuration does not have ozone.om.address set. Falling back to the default OM address om/172.23.0.3:9862
om_1                | 2022-07-27 17:14:26,011 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1                | 2022-07-27 17:14:26,011 [main] INFO ha.OMHANodeDetails: OM Node ID is not set. Setting it to the default ID: om1
om_1                | 2022-07-27 17:14:26,218 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1                | 2022-07-27 17:14:27,692 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/172.23.0.4:9863]
om_1                | 2022-07-27 17:14:31,435 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 0dd774f2a837/172.23.0.3 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.23.0.4:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
om_1                | 2022-07-27 17:14:33,437 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 0dd774f2a837/172.23.0.3 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.23.0.4:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
om_1                | 2022-07-27 17:14:35,439 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 0dd774f2a837/172.23.0.3 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.23.0.4:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
om_1                | 2022-07-27 17:14:37,440 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 0dd774f2a837/172.23.0.3 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.23.0.4:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
om_1                | 2022-07-27 17:14:39,441 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 0dd774f2a837/172.23.0.3 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.23.0.4:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
om_1                | 2022-07-27 17:14:41,443 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 0dd774f2a837/172.23.0.3 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.23.0.4:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
om_1                | 2022-07-27 17:14:43,444 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 0dd774f2a837/172.23.0.3 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.23.0.4:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
om_1                | 2022-07-27 17:14:45,446 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 0dd774f2a837/172.23.0.3 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.23.0.4:9863 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
om_1                | 2022-07-27 17:14:47,448 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 0dd774f2a837/172.23.0.3 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.23.0.4:9863 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
om_1                | 2022-07-27 17:14:49,450 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 0dd774f2a837/172.23.0.3 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.23.0.4:9863 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
om_1                | 2022-07-27 17:14:51,451 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 0dd774f2a837/172.23.0.3 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.23.0.4:9863 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
om_1                | 2022-07-27 17:14:53,453 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 0dd774f2a837/172.23.0.3 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.23.0.4:9863 after 12 failover attempts. Trying to failover after sleeping for 2000ms.
om_1                | 2022-07-27 17:14:55,455 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 0dd774f2a837/172.23.0.3 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.23.0.4:9863 after 13 failover attempts. Trying to failover after sleeping for 2000ms.
om_1                | 2022-07-27 17:14:57,529 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:0282b415-9225-47ae-b725-ee6b70b40488 is not the leader. Could not determine the leader node.
om_1                | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
om_1                | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
om_1                | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:109)
om_1                | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:14202)
om_1                | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
om_1                | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
om_1                | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
om_1                | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
om_1                | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
om_1                | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
om_1                | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1                | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1                | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om_1                | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
om_1                | , while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.23.0.4:9863 after 14 failover attempts. Trying to failover after sleeping for 2000ms.
om_1                | 2022-07-27 17:14:59,534 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:0282b415-9225-47ae-b725-ee6b70b40488 is not the leader. Could not determine the leader node.
om_1                | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
om_1                | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
om_1                | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:109)
om_1                | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:14202)
om_1                | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
om_1                | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
om_1                | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
om_1                | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
om_1                | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
om_1                | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
om_1                | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1                | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1                | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om_1                | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
om_1                | , while invoking $Proxy32.send over nodeId=scmNodeId,nodeAddress=scm/172.23.0.4:9863 after 15 failover attempts. Trying to failover after sleeping for 2000ms.
om_1                | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-7d45909c-9fcd-4dc9-be34-cfa80db7825a;layoutVersion=3
om_1                | 2022-07-27 17:15:02,158 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om_1                | /************************************************************
om_1                | SHUTDOWN_MSG: Shutting down OzoneManager at 0dd774f2a837/172.23.0.3
om_1                | ************************************************************/
om_1                | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om_1                | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1                | 2022-07-27 17:15:09,381 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1                | /************************************************************
om_1                | STARTUP_MSG: Starting OzoneManager
om_1                | STARTUP_MSG:   host = 0dd774f2a837/172.23.0.3
om_1                | STARTUP_MSG:   args = []
om_1                | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om_1                | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.6.3.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jcl-over-slf4j-1.7.24.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om_1                | STARTUP_MSG:   build = https://github.com/apache/ozone/9f188e38b2f4663af1a9169fb7f63dfe156555a0 ; compiled by 'runner' on 2022-07-27T16:19Z
om_1                | STARTUP_MSG:   java = 11.0.14.1
om_1                | ************************************************************/
om_1                | 2022-07-27 17:15:09,421 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1                | 2022-07-27 17:15:13,329 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om_1                | 2022-07-27 17:15:14,118 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1                | 2022-07-27 17:15:14,211 [main] INFO ha.OMHANodeDetails: Configuration does not have ozone.om.address set. Falling back to the default OM address om/172.23.0.3:9862
om_1                | 2022-07-27 17:15:14,219 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1                | 2022-07-27 17:15:14,219 [main] INFO ha.OMHANodeDetails: OM Node ID is not set. Setting it to the default ID: om1
om_1                | 2022-07-27 17:15:14,299 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1                | 2022-07-27 17:15:14,424 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
om_1                | 2022-07-27 17:15:15,216 [main] INFO reflections.Reflections: Reflections took 542 ms to scan 1 urls, producing 112 keys and 332 values [using 2 cores]
om_1                | 2022-07-27 17:15:15,248 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1                | 2022-07-27 17:15:16,006 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/172.23.0.4:9863]
om_1                | 2022-07-27 17:15:16,066 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/172.23.0.4:9863]
om_1                | 2022-07-27 17:15:18,111 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1                | 2022-07-27 17:15:18,572 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om_1                | 2022-07-27 17:15:18,573 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om_1                | 2022-07-27 17:15:19,119 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om_1                | 2022-07-27 17:15:19,333 [main] INFO om.OzoneManager: Created Volume s3v With Owner hadoop required for S3Gateway operations.
om_1                | 2022-07-27 17:15:19,558 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om_1                | 2022-07-27 17:15:19,558 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om_1                | 2022-07-27 17:15:19,580 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om_1                | 2022-07-27 17:15:19,588 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om_1                | 2022-07-27 17:15:19,639 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: omServiceIdDefault and peers: om:9872
om_1                | 2022-07-27 17:15:19,658 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om_1                | 2022-07-27 17:15:19,738 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om_1                | 2022-07-27 17:15:19,856 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om_1                | 2022-07-27 17:15:19,857 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om_1                | 2022-07-27 17:15:19,858 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om_1                | 2022-07-27 17:15:19,859 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om_1                | 2022-07-27 17:15:19,859 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om_1                | 2022-07-27 17:15:19,860 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om_1                | 2022-07-27 17:15:19,862 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1                | 2022-07-27 17:15:19,868 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om_1                | 2022-07-27 17:15:19,870 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om_1                | 2022-07-27 17:15:19,901 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om_1                | 2022-07-27 17:15:19,904 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om_1                | 2022-07-27 17:15:20,382 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om_1                | 2022-07-27 17:15:20,384 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om_1                | 2022-07-27 17:15:20,385 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om_1                | 2022-07-27 17:15:20,385 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om_1                | 2022-07-27 17:15:20,385 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om_1                | 2022-07-27 17:15:20,401 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om_1                | 2022-07-27 17:15:20,411 [main] INFO server.RaftServer: om1: addNew group-C5BA1605619E:[om1|rpc:om:9872|priority:0] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@7f088b5c[Not completed]
om_1                | 2022-07-27 17:15:20,411 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om_1                | 2022-07-27 17:15:20,450 [main] INFO om.OzoneManager: Creating RPC Server
om_1                | 2022-07-27 17:15:20,456 [pool-26-thread-1] INFO server.RaftServer$Division: om1: new RaftServerImpl for group-C5BA1605619E:[om1|rpc:om:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om_1                | 2022-07-27 17:15:20,464 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om_1                | 2022-07-27 17:15:20,466 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om_1                | 2022-07-27 17:15:20,467 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om_1                | 2022-07-27 17:15:20,468 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om_1                | 2022-07-27 17:15:20,468 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om_1                | 2022-07-27 17:15:20,468 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om_1                | 2022-07-27 17:15:20,483 [pool-26-thread-1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: ConfigurationManager, init=-1: [om1|rpc:om:9872|priority:0], old=null, confs=<EMPTY_MAP>
om_1                | 2022-07-27 17:15:20,483 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om_1                | 2022-07-27 17:15:20,490 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om_1                | 2022-07-27 17:15:20,490 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om_1                | 2022-07-27 17:15:20,502 [pool-26-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
om_1                | 2022-07-27 17:15:20,612 [pool-26-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 8@0dd774f2a837
om_1                | 2022-07-27 17:15:20,708 [pool-26-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
om_1                | 2022-07-27 17:15:20,724 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om_1                | 2022-07-27 17:15:20,732 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om_1                | 2022-07-27 17:15:20,772 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om_1                | 2022-07-27 17:15:20,775 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1                | 2022-07-27 17:15:20,779 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om_1                | 2022-07-27 17:15:21,056 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om_1                | 2022-07-27 17:15:21,103 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om_1                | 2022-07-27 17:15:21,104 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om_1                | 2022-07-27 17:15:21,126 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e
om_1                | 2022-07-27 17:15:21,132 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om_1                | 2022-07-27 17:15:21,132 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om_1                | 2022-07-27 17:15:21,135 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om_1                | 2022-07-27 17:15:21,137 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om_1                | 2022-07-27 17:15:21,139 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om_1                | 2022-07-27 17:15:21,140 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om_1                | 2022-07-27 17:15:21,143 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om_1                | 2022-07-27 17:15:21,143 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om_1                | 2022-07-27 17:15:21,290 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om_1                | 2022-07-27 17:15:21,291 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om_1                | 2022-07-27 17:15:21,306 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om_1                | 2022-07-27 17:15:21,332 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om_1                | 2022-07-27 17:15:21,332 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om_1                | 2022-07-27 17:15:21,389 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om_1                | 2022-07-27 17:15:21,392 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om_1                | 2022-07-27 17:15:21,392 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om_1                | 2022-07-27 17:15:21,395 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om_1                | 2022-07-27 17:15:21,401 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om_1                | 2022-07-27 17:15:21,407 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om_1                | 2022-07-27 17:15:21,683 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om_1                | 2022-07-27 17:15:21,684 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om_1                | 2022-07-27 17:15:21,685 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om_1                | 2022-07-27 17:15:21,689 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om_1                | 2022-07-27 17:15:21,694 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om_1                | 2022-07-27 17:15:22,072 [main] INFO reflections.Reflections: Reflections took 1310 ms to scan 8 urls, producing 23 keys and 512 values [using 2 cores]
om_1                | 2022-07-27 17:15:22,884 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1                | 2022-07-27 17:15:22,913 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om_1                | 2022-07-27 17:15:23,170 [Listener at om/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1                | 2022-07-27 17:15:23,204 [Listener at om/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1                | 2022-07-27 17:15:23,204 [Listener at om/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om_1                | 2022-07-27 17:15:23,315 [Listener at om/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om/172.23.0.3:9862
om_1                | 2022-07-27 17:15:23,319 [Listener at om/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
om_1                | 2022-07-27 17:15:23,321 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: start as a follower, conf=-1: [om1|rpc:om:9872|priority:0], old=null
om_1                | 2022-07-27 17:15:23,325 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
om_1                | 2022-07-27 17:15:23,327 [om1-impl-thread1] INFO impl.RoleInfo: om1: start om1@group-C5BA1605619E-FollowerState
om_1                | 2022-07-27 17:15:23,332 [om1-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
om_1                | 2022-07-27 17:15:23,338 [Listener at om/9862] INFO server.RaftServer: om1: start RPC server
om_1                | 2022-07-27 17:15:23,432 [Listener at om/9862] INFO server.GrpcService: om1: GrpcService started, listening on 9872
om_1                | 2022-07-27 17:15:23,434 [Listener at om/9862] INFO om.OzoneManager: Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om_1                | 2022-07-27 17:15:23,439 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$405/0x0000000840537040@75c858e6] INFO util.JvmPauseMonitor: JvmPauseMonitor-om1: Started
om_1                | 2022-07-27 17:15:23,517 [Listener at om/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om_1                | 2022-07-27 17:15:23,518 [Listener at om/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om_1                | 2022-07-27 17:15:23,557 [Listener at om/9862] INFO util.log: Logging initialized @20651ms to org.eclipse.jetty.util.log.Slf4jLog
om_1                | 2022-07-27 17:15:23,744 [Listener at om/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1                | 2022-07-27 17:15:23,764 [Listener at om/9862] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
om_1                | 2022-07-27 17:15:23,780 [Listener at om/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1                | 2022-07-27 17:15:23,783 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om_1                | 2022-07-27 17:15:23,786 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om_1                | 2022-07-27 17:15:23,786 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om_1                | 2022-07-27 17:15:23,888 [Listener at om/9862] INFO http.HttpServer2: Jetty bound to port 9874
om_1                | 2022-07-27 17:15:23,889 [Listener at om/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om_1                | 2022-07-27 17:15:23,967 [Listener at om/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om_1                | 2022-07-27 17:15:23,969 [Listener at om/9862] INFO server.session: No SessionScavenger set, using defaults
om_1                | 2022-07-27 17:15:23,973 [Listener at om/9862] INFO server.session: node0 Scavenging every 660000ms
om_1                | 2022-07-27 17:15:23,999 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@11c94cf7{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1                | 2022-07-27 17:15:24,001 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@515a3572{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1                | 2022-07-27 17:15:24,216 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@c940eab{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-5856058610956904961/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om_1                | 2022-07-27 17:15:24,237 [Listener at om/9862] INFO server.AbstractConnector: Started ServerConnector@2e706bc6{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om_1                | 2022-07-27 17:15:24,238 [Listener at om/9862] INFO server.Server: Started @21331ms
om_1                | 2022-07-27 17:15:24,247 [Listener at om/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1                | 2022-07-27 17:15:24,248 [Listener at om/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1                | 2022-07-27 17:15:24,251 [Listener at om/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om_1                | 2022-07-27 17:15:24,257 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om_1                | 2022-07-27 17:15:24,294 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om_1                | 2022-07-27 17:15:24,394 [Listener at om/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted won't move to trash
om_1                | 2022-07-27 17:15:24,420 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@689cc29a] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om_1                | 2022-07-27 17:15:28,376 [om1@group-C5BA1605619E-FollowerState] INFO impl.FollowerState: om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5049901427ns, electionTimeout:5033ms
om_1                | 2022-07-27 17:15:28,378 [om1@group-C5BA1605619E-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-C5BA1605619E-FollowerState
om_1                | 2022-07-27 17:15:28,379 [om1@group-C5BA1605619E-FollowerState] INFO server.RaftServer$Division: om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om_1                | 2022-07-27 17:15:28,381 [om1@group-C5BA1605619E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om_1                | 2022-07-27 17:15:28,382 [om1@group-C5BA1605619E-FollowerState] INFO impl.RoleInfo: om1: start om1@group-C5BA1605619E-LeaderElection1
om_1                | 2022-07-27 17:15:28,405 [om1@group-C5BA1605619E-LeaderElection1] INFO impl.LeaderElection: om1@group-C5BA1605619E-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om:9872|priority:0], old=null
om_1                | 2022-07-27 17:15:28,408 [om1@group-C5BA1605619E-LeaderElection1] INFO impl.LeaderElection: om1@group-C5BA1605619E-LeaderElection1 ELECTION round 0: result PASSED (term=1)
om_1                | 2022-07-27 17:15:28,409 [om1@group-C5BA1605619E-LeaderElection1] INFO impl.RoleInfo: om1: shutdown om1@group-C5BA1605619E-LeaderElection1
om_1                | 2022-07-27 17:15:28,412 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
om_1                | 2022-07-27 17:15:28,412 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 7690ms
om_1                | 2022-07-27 17:15:28,435 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om_1                | 2022-07-27 17:15:28,443 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om_1                | 2022-07-27 17:15:28,445 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
om_1                | 2022-07-27 17:15:28,504 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om_1                | 2022-07-27 17:15:28,505 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om_1                | 2022-07-27 17:15:28,511 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om_1                | 2022-07-27 17:15:28,525 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om_1                | 2022-07-27 17:15:28,528 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
om_1                | 2022-07-27 17:15:28,534 [om1@group-C5BA1605619E-LeaderElection1] INFO impl.RoleInfo: om1: start om1@group-C5BA1605619E-LeaderStateImpl
om_1                | 2022-07-27 17:15:28,598 [om1@group-C5BA1605619E-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
om_1                | 2022-07-27 17:15:28,655 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: set configuration 0: [om1|rpc:om:9872|admin:|client:|dataStream:|priority:0], old=null
om_1                | 2022-07-27 17:15:28,789 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
om_1                | 2022-07-27 17:15:28,941 [om1@group-C5BA1605619E-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om_1                | [id: "om1"
om_1                | address: "om:9872"
om_1                | ]
om_1                | 2022-07-27 17:15:31,446 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:asntpvol1 for user:hadoop
om_1                | 2022-07-27 17:15:35,042 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: asntpdefault of layout LEGACY in volume: asntpvol1
om_1                | 2022-07-27 17:15:38,669 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: asntpratis of layout LEGACY in volume: asntpvol1
om_1                | 2022-07-27 17:15:42,465 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: asntpec of layout LEGACY in volume: asntpvol1
om_1                | 2022-07-27 17:15:55,384 [qtp668845267-49] INFO utils.DBCheckpointServlet: Received request to obtain DB checkpoint snapshot
om_1                | 2022-07-27 17:15:55,407 [qtp668845267-49] INFO db.RDBCheckpointManager: Created checkpoint at /data/metadata/db.checkpoints/om.db_checkpoint_1658942155389 in 17 milliseconds
om_1                | 2022-07-27 17:15:55,504 [qtp668845267-49] INFO utils.DBCheckpointServlet: Time taken to write the checkpoint to response output stream: 95 milliseconds
om_1                | 2022-07-27 17:15:55,504 [qtp668845267-49] INFO db.RocksDBCheckpoint: Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/om.db_checkpoint_1658942155389
scm_1               | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm_1               | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1               | 2022-07-27 17:14:12,741 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1               | /************************************************************
scm_1               | STARTUP_MSG: Starting StorageContainerManager
scm_1               | STARTUP_MSG:   host = 785df6c4750b/172.23.0.4
scm_1               | STARTUP_MSG:   args = [--init]
scm_1               | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm_1               | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm_1               | STARTUP_MSG:   build = https://github.com/apache/ozone/9f188e38b2f4663af1a9169fb7f63dfe156555a0 ; compiled by 'runner' on 2022-07-27T16:18Z
scm_1               | STARTUP_MSG:   java = 11.0.14.1
scm_1               | ************************************************************/
scm_1               | 2022-07-27 17:14:12,916 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1               | 2022-07-27 17:14:14,045 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1               | 2022-07-27 17:14:14,509 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm_1               | 2022-07-27 17:14:14,764 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm_1               | 2022-07-27 17:14:17,537 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm_1               | 2022-07-27 17:14:19,144 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm_1               | 2022-07-27 17:14:19,149 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm_1               | 2022-07-27 17:14:19,150 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm_1               | 2022-07-27 17:14:19,155 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm_1               | 2022-07-27 17:14:19,159 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm_1               | 2022-07-27 17:14:19,211 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm_1               | 2022-07-27 17:14:19,288 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1               | 2022-07-27 17:14:19,307 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm_1               | 2022-07-27 17:14:19,392 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm_1               | 2022-07-27 17:14:19,658 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm_1               | 2022-07-27 17:14:19,662 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm_1               | 2022-07-27 17:14:23,102 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm_1               | 2022-07-27 17:14:23,128 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm_1               | 2022-07-27 17:14:23,155 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm_1               | 2022-07-27 17:14:23,159 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm_1               | 2022-07-27 17:14:23,182 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm_1               | 2022-07-27 17:14:23,186 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm_1               | 2022-07-27 17:14:23,312 [main] INFO server.RaftServer: 0282b415-9225-47ae-b725-ee6b70b40488: addNew group-CFA80DB7825A:[0282b415-9225-47ae-b725-ee6b70b40488|rpc:785df6c4750b:9894|priority:0] returns group-CFA80DB7825A:java.util.concurrent.CompletableFuture@588cd519[Not completed]
scm_1               | 2022-07-27 17:14:23,560 [pool-2-thread-1] INFO server.RaftServer$Division: 0282b415-9225-47ae-b725-ee6b70b40488: new RaftServerImpl for group-CFA80DB7825A:[0282b415-9225-47ae-b725-ee6b70b40488|rpc:785df6c4750b:9894|priority:0] with SCMStateMachine:uninitialized
scm_1               | 2022-07-27 17:14:23,573 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm_1               | 2022-07-27 17:14:23,593 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm_1               | 2022-07-27 17:14:23,596 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm_1               | 2022-07-27 17:14:23,596 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm_1               | 2022-07-27 17:14:23,596 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm_1               | 2022-07-27 17:14:23,596 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm_1               | 2022-07-27 17:14:23,642 [pool-2-thread-1] INFO server.RaftServer$Division: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A: ConfigurationManager, init=-1: [0282b415-9225-47ae-b725-ee6b70b40488|rpc:785df6c4750b:9894|priority:0], old=null, confs=<EMPTY_MAP>
scm_1               | 2022-07-27 17:14:23,665 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm_1               | 2022-07-27 17:14:23,671 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm_1               | 2022-07-27 17:14:23,711 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm_1               | 2022-07-27 17:14:23,716 [pool-2-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/7d45909c-9fcd-4dc9-be34-cfa80db7825a does not exist. Creating ...
scm_1               | 2022-07-27 17:14:24,018 [pool-2-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/7d45909c-9fcd-4dc9-be34-cfa80db7825a/in_use.lock acquired by nodename 13@785df6c4750b
scm_1               | 2022-07-27 17:14:24,095 [pool-2-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/7d45909c-9fcd-4dc9-be34-cfa80db7825a has been successfully formatted.
scm_1               | 2022-07-27 17:14:24,141 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm_1               | 2022-07-27 17:14:24,177 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm_1               | 2022-07-27 17:14:24,304 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm_1               | 2022-07-27 17:14:24,327 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1               | 2022-07-27 17:14:24,339 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm_1               | 2022-07-27 17:14:24,397 [pool-2-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm_1               | 2022-07-27 17:14:26,126 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm_1               | 2022-07-27 17:14:26,247 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm_1               | 2022-07-27 17:14:26,271 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm_1               | 2022-07-27 17:14:26,335 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: new 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/7d45909c-9fcd-4dc9-be34-cfa80db7825a
scm_1               | 2022-07-27 17:14:26,423 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm_1               | 2022-07-27 17:14:26,429 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm_1               | 2022-07-27 17:14:26,436 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm_1               | 2022-07-27 17:14:26,536 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm_1               | 2022-07-27 17:14:26,537 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm_1               | 2022-07-27 17:14:26,538 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm_1               | 2022-07-27 17:14:26,598 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm_1               | 2022-07-27 17:14:26,603 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm_1               | 2022-07-27 17:14:26,804 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm_1               | 2022-07-27 17:14:26,864 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm_1               | 2022-07-27 17:14:26,879 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm_1               | 2022-07-27 17:14:26,934 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm_1               | 2022-07-27 17:14:26,969 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm_1               | 2022-07-27 17:14:27,022 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm_1               | 2022-07-27 17:14:27,024 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm_1               | 2022-07-27 17:14:27,035 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm_1               | 2022-07-27 17:14:27,048 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm_1               | 2022-07-27 17:14:27,059 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm_1               | 2022-07-27 17:14:27,061 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm_1               | 2022-07-27 17:14:27,835 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1               | 2022-07-27 17:14:27,839 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm_1               | 2022-07-27 17:14:27,871 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm_1               | 2022-07-27 17:14:27,877 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm_1               | 2022-07-27 17:14:27,878 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm_1               | 2022-07-27 17:14:27,951 [0282b415-9225-47ae-b725-ee6b70b40488-impl-thread1] INFO server.RaftServer$Division: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A: start as a follower, conf=-1: [0282b415-9225-47ae-b725-ee6b70b40488|rpc:785df6c4750b:9894|priority:0], old=null
scm_1               | 2022-07-27 17:14:27,967 [0282b415-9225-47ae-b725-ee6b70b40488-impl-thread1] INFO server.RaftServer$Division: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm_1               | 2022-07-27 17:14:27,988 [0282b415-9225-47ae-b725-ee6b70b40488-impl-thread1] INFO impl.RoleInfo: 0282b415-9225-47ae-b725-ee6b70b40488: start 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-FollowerState
scm_1               | 2022-07-27 17:14:28,064 [0282b415-9225-47ae-b725-ee6b70b40488-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CFA80DB7825A,id=0282b415-9225-47ae-b725-ee6b70b40488
scm_1               | 2022-07-27 17:14:28,161 [main] INFO server.RaftServer: 0282b415-9225-47ae-b725-ee6b70b40488: start RPC server
scm_1               | 2022-07-27 17:14:28,837 [main] INFO server.GrpcService: 0282b415-9225-47ae-b725-ee6b70b40488: GrpcService started, listening on 9894
scm_1               | 2022-07-27 17:14:28,894 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$327/0x0000000840287c40@5bb7643d] INFO util.JvmPauseMonitor: JvmPauseMonitor-0282b415-9225-47ae-b725-ee6b70b40488: Started
scm_1               | 2022-07-27 17:14:33,266 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-FollowerState] INFO impl.FollowerState: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5278585775ns, electionTimeout:5179ms
scm_1               | 2022-07-27 17:14:33,314 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-FollowerState] INFO impl.RoleInfo: 0282b415-9225-47ae-b725-ee6b70b40488: shutdown 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-FollowerState
scm_1               | 2022-07-27 17:14:33,329 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-FollowerState] INFO server.RaftServer$Division: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
scm_1               | 2022-07-27 17:14:33,342 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm_1               | 2022-07-27 17:14:33,347 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-FollowerState] INFO impl.RoleInfo: 0282b415-9225-47ae-b725-ee6b70b40488: start 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1
scm_1               | 2022-07-27 17:14:33,403 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO impl.LeaderElection: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [0282b415-9225-47ae-b725-ee6b70b40488|rpc:785df6c4750b:9894|priority:0], old=null
scm_1               | 2022-07-27 17:14:33,408 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO impl.LeaderElection: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1 ELECTION round 0: result PASSED (term=1)
scm_1               | 2022-07-27 17:14:33,413 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO impl.RoleInfo: 0282b415-9225-47ae-b725-ee6b70b40488: shutdown 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1
scm_1               | 2022-07-27 17:14:33,426 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO server.RaftServer$Division: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
scm_1               | 2022-07-27 17:14:33,457 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO server.RaftServer$Division: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A: change Leader from null to 0282b415-9225-47ae-b725-ee6b70b40488 at term 1 for becomeLeader, leader elected after 9316ms
recon_1             | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
recon_1             | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1             | 2022-07-27 17:14:17,251 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1             | /************************************************************
recon_1             | STARTUP_MSG: Starting ReconServer
recon_1             | STARTUP_MSG:   host = 0841fc0de2be/172.23.0.11
recon_1             | STARTUP_MSG:   args = []
recon_1             | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm_1               | 2022-07-27 17:14:33,600 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm_1               | 2022-07-27 17:14:33,711 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm_1               | 2022-07-27 17:14:33,731 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm_1               | 2022-07-27 17:14:33,865 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm_1               | 2022-07-27 17:14:33,907 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm_1               | 2022-07-27 17:14:33,928 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm_1               | 2022-07-27 17:14:34,077 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm_1               | 2022-07-27 17:14:34,121 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm_1               | 2022-07-27 17:14:34,163 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO impl.RoleInfo: 0282b415-9225-47ae-b725-ee6b70b40488: start 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderStateImpl
scm_1               | 2022-07-27 17:14:34,701 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-SegmentedRaftLogWorker: Starting segment from index:0
scm_1               | 2022-07-27 17:14:35,268 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO server.RaftServer$Division: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A: set configuration 0: [0282b415-9225-47ae-b725-ee6b70b40488|rpc:785df6c4750b:9894|admin:|client:|dataStream:|priority:0], old=null
scm_1               | 2022-07-27 17:14:35,939 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/7d45909c-9fcd-4dc9-be34-cfa80db7825a/current/log_inprogress_0
scm_1               | 2022-07-27 17:14:36,934 [main] INFO server.RaftServer: 0282b415-9225-47ae-b725-ee6b70b40488: close
scm_1               | 2022-07-27 17:14:36,963 [main] INFO server.RaftServer$Division: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A: shutdown
scm_1               | 2022-07-27 17:14:36,969 [main] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-CFA80DB7825A,id=0282b415-9225-47ae-b725-ee6b70b40488
scm_1               | 2022-07-27 17:14:36,983 [main] INFO impl.RoleInfo: 0282b415-9225-47ae-b725-ee6b70b40488: shutdown 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderStateImpl
scm_1               | 2022-07-27 17:14:37,101 [main] INFO impl.PendingRequests: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-PendingRequests: sendNotLeaderResponses
scm_1               | 2022-07-27 17:14:37,189 [main] INFO impl.StateMachineUpdater: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater: set stopIndex = 0
scm_1               | 2022-07-27 17:14:37,204 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO impl.StateMachineUpdater: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater: Took a snapshot at index 0
scm_1               | 2022-07-27 17:14:37,220 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO impl.StateMachineUpdater: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
scm_1               | 2022-07-27 17:14:37,320 [main] INFO server.RaftServer$Division: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A: closes. applyIndex: 0
scm_1               | 2022-07-27 17:14:37,331 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
scm_1               | 2022-07-27 17:14:37,339 [main] INFO segmented.SegmentedRaftLogWorker: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-SegmentedRaftLogWorker close()
scm_1               | 2022-07-27 17:14:37,352 [main] INFO server.GrpcService: 0282b415-9225-47ae-b725-ee6b70b40488: shutdown server with port 9894 now
scm_1               | 2022-07-27 17:14:37,485 [main] INFO server.GrpcService: 0282b415-9225-47ae-b725-ee6b70b40488: shutdown server with port 9894 successfully
scm_1               | 2022-07-27 17:14:37,493 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$327/0x0000000840287c40@5bb7643d] INFO util.JvmPauseMonitor: JvmPauseMonitor-0282b415-9225-47ae-b725-ee6b70b40488: Stopped
scm_1               | 2022-07-27 17:14:37,515 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1               | 2022-07-27 17:14:37,535 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-7d45909c-9fcd-4dc9-be34-cfa80db7825a; layoutVersion=4; scmId=0282b415-9225-47ae-b725-ee6b70b40488
scm_1               | 2022-07-27 17:14:37,819 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm_1               | /************************************************************
scm_1               | SHUTDOWN_MSG: Shutting down StorageContainerManager at 785df6c4750b/172.23.0.4
scm_1               | ************************************************************/
scm_1               | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm_1               | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1               | 2022-07-27 17:14:49,341 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1               | /************************************************************
scm_1               | STARTUP_MSG: Starting StorageContainerManager
scm_1               | STARTUP_MSG:   host = 785df6c4750b/172.23.0.4
scm_1               | STARTUP_MSG:   args = []
scm_1               | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
s3g_1               | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
s3g_1               | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1               | 2022-07-27 17:14:09,918 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1               | 2022-07-27 17:14:09,935 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
s3g_1               | 2022-07-27 17:14:10,171 [main] INFO util.log: Logging initialized @8214ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1               | 2022-07-27 17:14:11,280 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g_1               | 2022-07-27 17:14:11,500 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1               | 2022-07-27 17:14:11,595 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1               | 2022-07-27 17:14:11,624 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context s3gateway
s3g_1               | 2022-07-27 17:14:11,624 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
s3g_1               | 2022-07-27 17:14:11,624 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
s3g_1               | 2022-07-27 17:14:12,418 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1               | /************************************************************
s3g_1               | STARTUP_MSG: Starting Gateway
s3g_1               | STARTUP_MSG:   host = 2bbae0e76451/172.23.0.2
s3g_1               | STARTUP_MSG:   args = []
s3g_1               | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
recon_1             | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.33.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-tools-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.33.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.6.3.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.33.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jcl-over-slf4j-1.7.24.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/ozone-reconcodegen-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar
recon_1             | STARTUP_MSG:   build = https://github.com/apache/ozone/9f188e38b2f4663af1a9169fb7f63dfe156555a0 ; compiled by 'runner' on 2022-07-27T16:19Z
recon_1             | STARTUP_MSG:   java = 11.0.14.1
recon_1             | ************************************************************/
recon_1             | 2022-07-27 17:14:17,485 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1             | 2022-07-27 17:14:21,365 [main] INFO reflections.Reflections: Reflections took 269 ms to scan 1 urls, producing 13 keys and 35 values 
recon_1             | 2022-07-27 17:14:26,690 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1             | 2022-07-27 17:14:28,901 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1             | 2022-07-27 17:14:35,651 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1             | WARNING: An illegal reflective access operation has occurred
recon_1             | WARNING: Illegal reflective access by org.jooq.tools.reflect.Reflect (file:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class)
recon_1             | WARNING: Please consider reporting this to the maintainers of org.jooq.tools.reflect.Reflect
recon_1             | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1             | WARNING: All illegal access operations will be denied in a future release
recon_1             | 2022-07-27 17:14:37,779 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1             | 2022-07-27 17:14:37,985 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1             | 2022-07-27 17:14:37,996 [main] INFO recon.ReconServer: Creating Recon Schema.
scm_1               | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm_1               | STARTUP_MSG:   build = https://github.com/apache/ozone/9f188e38b2f4663af1a9169fb7f63dfe156555a0 ; compiled by 'runner' on 2022-07-27T16:18Z
scm_1               | STARTUP_MSG:   java = 11.0.14.1
scm_1               | ************************************************************/
scm_1               | 2022-07-27 17:14:49,359 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1               | 2022-07-27 17:14:49,489 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1               | 2022-07-27 17:14:49,564 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm_1               | 2022-07-27 17:14:49,586 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm_1               | 2022-07-27 17:14:50,805 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1               | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.13.2.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.33.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar
s3g_1               | STARTUP_MSG:   build = https://github.com/apache/ozone/9f188e38b2f4663af1a9169fb7f63dfe156555a0 ; compiled by 'runner' on 2022-07-27T16:19Z
s3g_1               | STARTUP_MSG:   java = 11.0.14.1
s3g_1               | ************************************************************/
s3g_1               | 2022-07-27 17:14:12,476 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1               | 2022-07-27 17:14:12,640 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1               | 2022-07-27 17:14:13,194 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1               | 2022-07-27 17:14:14,284 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1               | 2022-07-27 17:14:14,284 [main] INFO impl.MetricsSystemImpl: S3Gateway metrics system started
s3g_1               | 2022-07-27 17:14:14,636 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1               | 2022-07-27 17:14:14,640 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
s3g_1               | 2022-07-27 17:14:14,854 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1               | 2022-07-27 17:14:14,854 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1               | 2022-07-27 17:14:14,874 [main] INFO server.session: node0 Scavenging every 660000ms
s3g_1               | 2022-07-27 17:14:15,036 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@62fad19{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1               | 2022-07-27 17:14:15,038 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@878452d{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1               | WARNING: An illegal reflective access operation has occurred
s3g_1               | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1               | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1               | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1               | WARNING: All illegal access operations will be denied in a future release
s3g_1               | Jul 27, 2022 5:14:40 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1               | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1               | 
recon_1             | 2022-07-27 17:14:42,844 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1             | 2022-07-27 17:14:42,944 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
recon_1             | 2022-07-27 17:14:43,033 [main] INFO util.log: Logging initialized @35364ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1             | 2022-07-27 17:14:43,757 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
recon_1             | 2022-07-27 17:14:43,784 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1             | 2022-07-27 17:14:43,847 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1             | 2022-07-27 17:14:43,861 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context recon
recon_1             | 2022-07-27 17:14:43,878 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
recon_1             | 2022-07-27 17:14:43,879 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
recon_1             | 2022-07-27 17:14:44,882 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1             | 2022-07-27 17:14:45,875 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1             | 2022-07-27 17:14:45,887 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
recon_1             | 2022-07-27 17:14:45,904 [main] INFO tasks.ReconTaskControllerImpl: Registered task NSSummaryTask with controller.
recon_1             | 2022-07-27 17:14:45,958 [main] INFO ozone.OmUtils: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
recon_1             | 2022-07-27 17:14:45,974 [main] INFO ozone.OmUtils: No OzoneManager ServiceID configured.
recon_1             | 2022-07-27 17:14:48,206 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1             | 2022-07-27 17:14:48,657 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1             | 2022-07-27 17:14:48,752 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
recon_1             | 2022-07-27 17:14:48,756 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1             | 2022-07-27 17:14:48,899 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1             | 2022-07-27 17:14:49,110 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
recon_1             | 2022-07-27 17:14:49,195 [main] INFO reflections.Reflections: Reflections took 81 ms to scan 3 urls, producing 109 keys and 246 values 
recon_1             | 2022-07-27 17:14:49,312 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
recon_1             | 2022-07-27 17:14:49,373 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1             | 2022-07-27 17:14:49,407 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
recon_1             | 2022-07-27 17:14:49,421 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1             | 2022-07-27 17:14:50,114 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
recon_1             | 2022-07-27 17:14:50,174 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1             | 2022-07-27 17:14:50,277 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1             | 2022-07-27 17:14:50,333 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
recon_1             | 2022-07-27 17:14:50,477 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
recon_1             | 2022-07-27 17:14:50,477 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
recon_1             | 2022-07-27 17:14:50,574 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1             | 2022-07-27 17:14:50,599 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1             | 2022-07-27 17:14:50,602 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1             | 2022-07-27 17:14:51,020 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1             | 2022-07-27 17:14:51,021 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
recon_1             | 2022-07-27 17:14:51,092 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1             | 2022-07-27 17:14:51,092 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1             | 2022-07-27 17:14:51,099 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 600000ms
recon_1             | 2022-07-27 17:14:51,123 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2e0163cb{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1             | 2022-07-27 17:14:51,124 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2d172c7{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1             | 2022-07-27 17:14:54,568 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@412d379c{recon,/,file:///tmp/jetty-0_0_0_0-9888-ozone-recon-1_3_0-SNAPSHOT_jar-_-any-15034289754239976954/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/recon}
recon_1             | 2022-07-27 17:14:54,598 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@54b2d002{HTTP/1.1, (http/1.1)}{0.0.0.0:9888}
recon_1             | 2022-07-27 17:14:54,598 [Listener at 0.0.0.0/9891] INFO server.Server: Started @46929ms
recon_1             | 2022-07-27 17:14:54,601 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1             | 2022-07-27 17:14:54,601 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1             | 2022-07-27 17:14:54,606 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1             | 2022-07-27 17:14:54,606 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1             | 2022-07-27 17:14:54,630 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
recon_1             | 2022-07-27 17:14:54,634 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
recon_1             | 2022-07-27 17:14:54,634 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
scm_1               | 2022-07-27 17:14:51,192 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1               | 2022-07-27 17:14:51,641 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm_1               | 2022-07-27 17:14:51,642 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1               | 2022-07-27 17:14:51,792 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm_1               | 2022-07-27 17:14:51,831 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:0282b415-9225-47ae-b725-ee6b70b40488
scm_1               | 2022-07-27 17:14:51,983 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm_1               | 2022-07-27 17:14:52,218 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm_1               | 2022-07-27 17:14:52,219 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm_1               | 2022-07-27 17:14:52,223 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm_1               | 2022-07-27 17:14:52,223 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm_1               | 2022-07-27 17:14:52,224 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm_1               | 2022-07-27 17:14:52,227 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm_1               | 2022-07-27 17:14:52,228 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1               | 2022-07-27 17:14:52,229 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm_1               | 2022-07-27 17:14:52,230 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm_1               | 2022-07-27 17:14:52,257 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm_1               | 2022-07-27 17:14:52,257 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm_1               | 2022-07-27 17:14:52,723 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm_1               | 2022-07-27 17:14:52,726 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm_1               | 2022-07-27 17:14:52,727 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm_1               | 2022-07-27 17:14:52,727 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm_1               | 2022-07-27 17:14:52,728 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm_1               | 2022-07-27 17:14:52,740 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm_1               | 2022-07-27 17:14:52,768 [0282b415-9225-47ae-b725-ee6b70b40488-impl-thread1] INFO server.RaftServer: 0282b415-9225-47ae-b725-ee6b70b40488: found a subdirectory /data/metadata/scm-ha/7d45909c-9fcd-4dc9-be34-cfa80db7825a
scm_1               | 2022-07-27 17:14:52,779 [main] INFO server.RaftServer: 0282b415-9225-47ae-b725-ee6b70b40488: addNew group-CFA80DB7825A:[] returns group-CFA80DB7825A:java.util.concurrent.CompletableFuture@259b85d6[Not completed]
scm_1               | 2022-07-27 17:14:52,863 [pool-16-thread-1] INFO server.RaftServer$Division: 0282b415-9225-47ae-b725-ee6b70b40488: new RaftServerImpl for group-CFA80DB7825A:[] with SCMStateMachine:uninitialized
scm_1               | 2022-07-27 17:14:52,867 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm_1               | 2022-07-27 17:14:52,870 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm_1               | 2022-07-27 17:14:52,870 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm_1               | 2022-07-27 17:14:52,871 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm_1               | 2022-07-27 17:14:52,871 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm_1               | 2022-07-27 17:14:52,871 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm_1               | 2022-07-27 17:14:52,883 [pool-16-thread-1] INFO server.RaftServer$Division: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm_1               | 2022-07-27 17:14:52,883 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm_1               | 2022-07-27 17:14:52,887 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm_1               | 2022-07-27 17:14:52,887 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm_1               | 2022-07-27 17:14:52,912 [pool-16-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/7d45909c-9fcd-4dc9-be34-cfa80db7825a/in_use.lock acquired by nodename 7@785df6c4750b
scm_1               | 2022-07-27 17:14:52,921 [pool-16-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=0282b415-9225-47ae-b725-ee6b70b40488} from /data/metadata/scm-ha/7d45909c-9fcd-4dc9-be34-cfa80db7825a/current/raft-meta
scm_1               | 2022-07-27 17:14:52,979 [pool-16-thread-1] INFO server.RaftServer$Division: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A: set configuration 0: [0282b415-9225-47ae-b725-ee6b70b40488|rpc:785df6c4750b:9894|admin:|client:|dataStream:|priority:0], old=null
scm_1               | 2022-07-27 17:14:52,980 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm_1               | 2022-07-27 17:14:52,981 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm_1               | 2022-07-27 17:14:52,994 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm_1               | 2022-07-27 17:14:52,995 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1               | 2022-07-27 17:14:52,997 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm_1               | 2022-07-27 17:14:53,204 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm_1               | 2022-07-27 17:14:53,235 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm_1               | 2022-07-27 17:14:53,237 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm_1               | 2022-07-27 17:14:53,242 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: new 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/7d45909c-9fcd-4dc9-be34-cfa80db7825a
scm_1               | 2022-07-27 17:14:53,248 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm_1               | 2022-07-27 17:14:53,248 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm_1               | 2022-07-27 17:14:53,249 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm_1               | 2022-07-27 17:14:53,250 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm_1               | 2022-07-27 17:14:53,250 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
recon_1             | 2022-07-27 17:14:54,634 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1             | 2022-07-27 17:14:54,635 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1             | 2022-07-27 17:14:54,646 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1             | 2022-07-27 17:14:56,923 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:0282b415-9225-47ae-b725-ee6b70b40488 is not the leader. Could not determine the leader node.
recon_1             | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
recon_1             | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
recon_1             | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:191)
recon_1             | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:61195)
recon_1             | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1             | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1             | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1             | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1             | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1             | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1             | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1             | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1             | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1             | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1             | , while invoking $Proxy41.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.23.0.4:9860 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1             | 2022-07-27 17:14:58,928 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:0282b415-9225-47ae-b725-ee6b70b40488 is not the leader. Could not determine the leader node.
recon_1             | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
recon_1             | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
recon_1             | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:191)
recon_1             | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:61195)
recon_1             | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1             | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1             | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1             | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1             | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1             | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1             | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1             | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1             | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1             | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1             | , while invoking $Proxy41.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.23.0.4:9860 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1             | 2022-07-27 17:15:00,940 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:0282b415-9225-47ae-b725-ee6b70b40488 is not the leader. Could not determine the leader node.
recon_1             | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
recon_1             | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
recon_1             | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:191)
recon_1             | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:61195)
recon_1             | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1             | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1             | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1             | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1             | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1             | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1             | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1             | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1             | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1             | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1             | , while invoking $Proxy41.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.23.0.4:9860 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1             | 2022-07-27 17:15:04,097 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 0 pipelines from SCM.
recon_1             | 2022-07-27 17:15:04,100 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1             | 2022-07-27 17:15:04,104 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1             | 2022-07-27 17:15:04,120 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1             | 2022-07-27 17:15:04,160 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1             | 2022-07-27 17:15:04,341 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered ContainerHealthTask task 
recon_1             | 2022-07-27 17:15:04,341 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting ContainerHealthTask Thread.
recon_1             | 2022-07-27 17:15:04,379 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
recon_1             | 2022-07-27 17:15:04,379 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1             | 2022-07-27 17:15:04,438 [IPC Server handler 4 on default port 9891] INFO ipc.Server: IPC Server handler 4 on default port 9891: skipped Call#1 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.23.0.6:34796
recon_1             | 2022-07-27 17:15:04,442 [IPC Server handler 6 on default port 9891] INFO ipc.Server: IPC Server handler 6 on default port 9891: skipped Call#2 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.23.0.10:43192
s3g_1               | 2022-07-27 17:14:40,241 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7d90644f{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-ozone-s3gateway-1_3_0-SNAPSHOT_jar-_-any-9534744361772271682/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1               | 2022-07-27 17:14:40,328 [main] INFO server.AbstractConnector: Started ServerConnector@25ddbbbb{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1               | 2022-07-27 17:14:40,328 [main] INFO server.Server: Started @38403ms
s3g_1               | 2022-07-27 17:14:40,347 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
s3g_1               | 2022-07-27 17:14:40,351 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
s3g_1               | 2022-07-27 17:14:40,364 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
scm_1               | 2022-07-27 17:14:53,251 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm_1               | 2022-07-27 17:14:53,251 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm_1               | 2022-07-27 17:14:53,252 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm_1               | 2022-07-27 17:14:53,271 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm_1               | 2022-07-27 17:14:53,272 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm_1               | 2022-07-27 17:14:53,273 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm_1               | 2022-07-27 17:14:53,318 [pool-16-thread-1] INFO server.RaftServer$Division: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A: set configuration 0: [0282b415-9225-47ae-b725-ee6b70b40488|rpc:785df6c4750b:9894|admin:|client:|dataStream:|priority:0], old=null
scm_1               | 2022-07-27 17:14:53,320 [pool-16-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/7d45909c-9fcd-4dc9-be34-cfa80db7825a/current/log_inprogress_0
scm_1               | 2022-07-27 17:14:53,325 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
scm_1               | 2022-07-27 17:14:53,325 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm_1               | 2022-07-27 17:14:53,457 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm_1               | 2022-07-27 17:14:53,462 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm_1               | 2022-07-27 17:14:53,462 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm_1               | 2022-07-27 17:14:53,463 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm_1               | 2022-07-27 17:14:53,470 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm_1               | 2022-07-27 17:14:53,471 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm_1               | 2022-07-27 17:14:53,589 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1               | 2022-07-27 17:14:53,589 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm_1               | 2022-07-27 17:14:53,590 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm_1               | 2022-07-27 17:14:53,590 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm_1               | 2022-07-27 17:14:53,591 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm_1               | 2022-07-27 17:14:53,593 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm_1               | 2022-07-27 17:14:53,593 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm_1               | 2022-07-27 17:14:53,594 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm_1               | 2022-07-27 17:14:53,654 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
scm_1               | 2022-07-27 17:14:53,926 [main] INFO reflections.Reflections: Reflections took 212 ms to scan 3 urls, producing 109 keys and 246 values 
scm_1               | 2022-07-27 17:14:54,128 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm_1               | 2022-07-27 17:14:54,129 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm_1               | 2022-07-27 17:14:54,139 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm_1               | 2022-07-27 17:14:54,151 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm_1               | 2022-07-27 17:14:54,268 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1               | 2022-07-27 17:14:54,314 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm_1               | 2022-07-27 17:14:54,359 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm_1               | 2022-07-27 17:14:54,428 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm_1               | 2022-07-27 17:14:54,430 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm_1               | 2022-07-27 17:14:54,440 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm_1               | 2022-07-27 17:14:54,442 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm_1               | 2022-07-27 17:14:54,447 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm_1               | 2022-07-27 17:14:54,447 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
scm_1               | 2022-07-27 17:14:54,483 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
scm_1               | 2022-07-27 17:14:54,484 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
scm_1               | 2022-07-27 17:14:54,552 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm_1               | 2022-07-27 17:14:54,588 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm_1               | 2022-07-27 17:14:54,645 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm_1               | 2022-07-27 17:14:54,678 [main] INFO UnderReplicatedQueueThread: Starting UnderReplicatedQueueThread Service.
scm_1               | 2022-07-27 17:14:54,695 [main] INFO ha.SCMServiceManager: Registering service UnderReplicatedQueueThread.
scm_1               | 2022-07-27 17:14:54,702 [main] INFO OverReplicatedQueueThread: Starting OverReplicatedQueueThread Service.
scm_1               | 2022-07-27 17:14:54,708 [main] INFO ha.SCMServiceManager: Registering service OverReplicatedQueueThread.
scm_1               | 2022-07-27 17:14:54,708 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm_1               | 2022-07-27 17:14:54,702 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1               | 2022-07-27 17:14:54,731 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm_1               | 2022-07-27 17:14:54,736 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm_1               | 2022-07-27 17:14:54,741 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1               | 2022-07-27 17:14:55,452 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
recon_1             | 2022-07-27 17:15:04,450 [IPC Server handler 6 on default port 9891] INFO ipc.Server: IPC Server handler 6 on default port 9891: skipped Call#2 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.23.0.6:34888
recon_1             | 2022-07-27 17:15:04,454 [IPC Server handler 6 on default port 9891] INFO ipc.Server: IPC Server handler 6 on default port 9891: skipped Call#1 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.23.0.13:57276
recon_1             | 2022-07-27 17:15:04,454 [IPC Server handler 6 on default port 9891] INFO ipc.Server: IPC Server handler 6 on default port 9891: skipped Call#0 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.23.0.12:58090
recon_1             | 2022-07-27 17:15:04,454 [IPC Server handler 6 on default port 9891] INFO ipc.Server: IPC Server handler 6 on default port 9891: skipped Call#0 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.23.0.10:43112
recon_1             | 2022-07-27 17:15:04,454 [IPC Server handler 6 on default port 9891] INFO ipc.Server: IPC Server handler 6 on default port 9891: skipped Call#2 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.23.0.9:36150
recon_1             | 2022-07-27 17:15:04,606 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1             | 2022-07-27 17:15:04,628 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=de666cc0-d9ea-4d5d-8684-29efd5711fcf from SCM.
recon_1             | 2022-07-27 17:15:04,896 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: de666cc0-d9ea-4d5d-8684-29efd5711fcf, Nodes: b50d7a6b-da1f-4bca-b673-015544dce0bd{ip: 172.23.0.10, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}5a16948f-0635-4af6-ad47-d40ff1547cf8{ip: 172.23.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0047ef4e-8059-4dda-a40b-cf26d888a843{ip: 172.23.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-27T17:15:04.120Z[UTC]].
recon_1             | 2022-07-27 17:15:04,937 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=e1b362da-60c0-4653-994d-03bdabe80f24 from SCM.
recon_1             | 2022-07-27 17:15:04,947 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: e1b362da-60c0-4653-994d-03bdabe80f24, Nodes: 0047ef4e-8059-4dda-a40b-cf26d888a843{ip: 172.23.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-27T17:15:04.221Z[UTC]].
recon_1             | 2022-07-27 17:15:04,948 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=ee453f3e-2788-418a-bfda-78c2755a5ddc from SCM.
recon_1             | 2022-07-27 17:15:04,950 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: ee453f3e-2788-418a-bfda-78c2755a5ddc, Nodes: 0047ef4e-8059-4dda-a40b-cf26d888a843{ip: 172.23.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2750dc88-6529-455f-a3a5-c6a6089a5bfe{ip: 172.23.0.12, host: xcompat_datanode_5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}b50d7a6b-da1f-4bca-b673-015544dce0bd{ip: 172.23.0.10, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-27T17:15:04.030Z[UTC]].
recon_1             | 2022-07-27 17:15:04,951 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=ba79c91e-c001-4819-a859-152fbed2c6fc from SCM.
recon_1             | 2022-07-27 17:15:04,953 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: ba79c91e-c001-4819-a859-152fbed2c6fc, Nodes: b50d7a6b-da1f-4bca-b673-015544dce0bd{ip: 172.23.0.10, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-27T17:15:04.077Z[UTC]].
recon_1             | 2022-07-27 17:15:04,954 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=063cabaa-8e18-48aa-a5b0-fd3704a7a93f from SCM.
recon_1             | 2022-07-27 17:15:04,956 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 063cabaa-8e18-48aa-a5b0-fd3704a7a93f, Nodes: 5a16948f-0635-4af6-ad47-d40ff1547cf8{ip: 172.23.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-27T17:15:02.930Z[UTC]].
recon_1             | 2022-07-27 17:15:04,960 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=8d4254b1-f279-4915-b6c2-def6498bd1fd from SCM.
recon_1             | 2022-07-27 17:15:04,961 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 8d4254b1-f279-4915-b6c2-def6498bd1fd, Nodes: 2750dc88-6529-455f-a3a5-c6a6089a5bfe{ip: 172.23.0.12, host: xcompat_datanode_5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-27T17:15:04.166Z[UTC]].
recon_1             | 2022-07-27 17:15:04,987 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 543 milliseconds.
recon_1             | 2022-07-27 17:15:05,445 [IPC Server handler 1 on default port 9891] WARN ipc.Server: IPC Server handler 1 on default port 9891, call Call#2 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.23.0.13:57368: output error
recon_1             | 2022-07-27 17:15:05,449 [IPC Server handler 1 on default port 9891] INFO ipc.Server: IPC Server handler 1 on default port 9891 caught an exception
recon_1             | java.nio.channels.ClosedChannelException
recon_1             | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1             | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1             | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3605)
recon_1             | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:141)
recon_1             | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1667)
scm_1               | 2022-07-27 17:14:55,491 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1               | 2022-07-27 17:14:55,543 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1               | 2022-07-27 17:14:55,705 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm_1               | 2022-07-27 17:14:55,713 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1               | 2022-07-27 17:14:55,714 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1               | 2022-07-27 17:14:55,761 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm_1               | 2022-07-27 17:14:55,771 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1               | 2022-07-27 17:14:55,772 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1               | 2022-07-27 17:14:55,853 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
scm_1               | 2022-07-27 17:14:55,854 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm_1               | Container Balancer status:
scm_1               | Key                            Value
scm_1               | Running                        false
scm_1               | Container Balancer Configuration values:
scm_1               | Key                                                Value
scm_1               | Threshold                                          10
scm_1               | Max Datanodes to Involve per Iteration(percent)    20
scm_1               | Max Size to Move per Iteration                     500GB
scm_1               | Max Size Entering Target per Iteration             26GB
scm_1               | Max Size Leaving Source per Iteration              26GB
scm_1               | 
scm_1               | 2022-07-27 17:14:55,854 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm_1               | 2022-07-27 17:14:55,854 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm_1               | 2022-07-27 17:14:55,884 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1               | 2022-07-27 17:14:55,885 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm_1               | 2022-07-27 17:14:55,886 [0282b415-9225-47ae-b725-ee6b70b40488-impl-thread1] INFO server.RaftServer$Division: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A: start as a follower, conf=0: [0282b415-9225-47ae-b725-ee6b70b40488|rpc:785df6c4750b:9894|admin:|client:|dataStream:|priority:0], old=null
scm_1               | 2022-07-27 17:14:55,886 [0282b415-9225-47ae-b725-ee6b70b40488-impl-thread1] INFO server.RaftServer$Division: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A: changes role from      null to FOLLOWER at term 1 for startAsFollower
scm_1               | 2022-07-27 17:14:55,888 [0282b415-9225-47ae-b725-ee6b70b40488-impl-thread1] INFO impl.RoleInfo: 0282b415-9225-47ae-b725-ee6b70b40488: start 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-FollowerState
scm_1               | 2022-07-27 17:14:55,895 [0282b415-9225-47ae-b725-ee6b70b40488-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CFA80DB7825A,id=0282b415-9225-47ae-b725-ee6b70b40488
scm_1               | 2022-07-27 17:14:55,903 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 0282b415-9225-47ae-b725-ee6b70b40488: start RPC server
scm_1               | 2022-07-27 17:14:55,952 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 0282b415-9225-47ae-b725-ee6b70b40488: GrpcService started, listening on 9894
scm_1               | 2022-07-27 17:14:55,954 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [0282b415-9225-47ae-b725-ee6b70b40488|rpc:785df6c4750b:9894|admin:|client:|dataStream:|priority:0]
scm_1               | 2022-07-27 17:14:55,954 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm_1               | 2022-07-27 17:14:55,965 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$429/0x00000008404b7c40@126e2710] INFO util.JvmPauseMonitor: JvmPauseMonitor-0282b415-9225-47ae-b725-ee6b70b40488: Started
scm_1               | 2022-07-27 17:14:56,102 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1               | 2022-07-27 17:14:56,118 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1               | 2022-07-27 17:14:56,118 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1               | 2022-07-27 17:14:56,341 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1               | 2022-07-27 17:14:56,343 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1               | 2022-07-27 17:14:56,348 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1               | 2022-07-27 17:14:56,399 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1               | 2022-07-27 17:14:56,400 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1               | 2022-07-27 17:14:56,400 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1               | 2022-07-27 17:14:56,402 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1               | 2022-07-27 17:14:56,450 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@225890bc] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1               | 2022-07-27 17:14:56,461 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm_1               | 2022-07-27 17:14:56,461 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
scm_1               | 2022-07-27 17:14:56,493 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @15952ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1               | 2022-07-27 17:14:56,680 [Listener at 0.0.0.0/9860] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1               | 2022-07-27 17:14:56,691 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1               | 2022-07-27 17:14:56,706 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1               | 2022-07-27 17:14:56,707 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
scm_1               | 2022-07-27 17:14:56,708 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
scm_1               | 2022-07-27 17:14:56,708 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
scm_1               | 2022-07-27 17:14:56,800 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
recon_1             | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1737)
recon_1             | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2837)
recon_1             | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1809)
recon_1             | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1117)
recon_1             | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:909)
recon_1             | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:895)
recon_1             | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1052)
recon_1             | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1             | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1             | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1             | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1             | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1             | 2022-07-27 17:15:05,451 [IPC Server handler 2 on default port 9891] WARN ipc.Server: IPC Server handler 2 on default port 9891, call Call#2 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.23.0.12:58180: output error
recon_1             | 2022-07-27 17:15:05,451 [IPC Server handler 2 on default port 9891] INFO ipc.Server: IPC Server handler 2 on default port 9891 caught an exception
recon_1             | java.nio.channels.ClosedChannelException
recon_1             | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1             | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1             | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3605)
recon_1             | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:141)
recon_1             | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1667)
recon_1             | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1737)
recon_1             | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2837)
recon_1             | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1809)
recon_1             | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1117)
recon_1             | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:909)
recon_1             | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:895)
recon_1             | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1052)
recon_1             | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1             | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1             | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1             | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1             | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1             | 2022-07-27 17:15:05,452 [IPC Server handler 0 on default port 9891] WARN ipc.Server: IPC Server handler 0 on default port 9891, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.23.0.9:36068: output error
recon_1             | 2022-07-27 17:15:05,452 [IPC Server handler 0 on default port 9891] INFO ipc.Server: IPC Server handler 0 on default port 9891 caught an exception
recon_1             | java.nio.channels.ClosedChannelException
recon_1             | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1             | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1             | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3605)
recon_1             | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:141)
recon_1             | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1667)
recon_1             | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1737)
recon_1             | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2837)
recon_1             | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1809)
recon_1             | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1117)
recon_1             | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:909)
recon_1             | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:895)
recon_1             | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1052)
recon_1             | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1             | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1             | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1             | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1             | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1             | 2022-07-27 17:15:05,649 [IPC Server handler 11 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/0047ef4e-8059-4dda-a40b-cf26d888a843
recon_1             | 2022-07-27 17:15:05,669 [IPC Server handler 11 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 0047ef4e-8059-4dda-a40b-cf26d888a843{ip: 172.23.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:05,716 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 0047ef4e-8059-4dda-a40b-cf26d888a843 to Node DB.
recon_1             | 2022-07-27 17:15:06,118 [IPC Server handler 12 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/fb410344-fcfe-4f99-b41b-29dd0a68d978
recon_1             | 2022-07-27 17:15:06,120 [IPC Server handler 12 on default port 9891] INFO node.SCMNodeManager: Registered Data node : fb410344-fcfe-4f99-b41b-29dd0a68d978{ip: 172.23.0.13, host: xcompat_datanode_4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:06,120 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node fb410344-fcfe-4f99-b41b-29dd0a68d978 to Node DB.
recon_1             | 2022-07-27 17:15:06,229 [IPC Server handler 56 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/2750dc88-6529-455f-a3a5-c6a6089a5bfe
recon_1             | 2022-07-27 17:15:06,231 [IPC Server handler 56 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 2750dc88-6529-455f-a3a5-c6a6089a5bfe{ip: 172.23.0.12, host: xcompat_datanode_5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:06,237 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 2750dc88-6529-455f-a3a5-c6a6089a5bfe to Node DB.
recon_1             | 2022-07-27 17:15:06,251 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=ee453f3e-2788-418a-bfda-78c2755a5ddc reported by 2750dc88-6529-455f-a3a5-c6a6089a5bfe{ip: 172.23.0.12, host: xcompat_datanode_5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:06,848 [IPC Server handler 12 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/b50d7a6b-da1f-4bca-b673-015544dce0bd
scm_1               | 2022-07-27 17:14:56,808 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm_1               | 2022-07-27 17:14:56,900 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1               | 2022-07-27 17:14:56,901 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm_1               | 2022-07-27 17:14:56,903 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm_1               | 2022-07-27 17:14:56,950 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2ab1c7a9{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1               | 2022-07-27 17:14:56,951 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6e2e11ee{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1               | 2022-07-27 17:14:57,034 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@456beb8b{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-15391783618727271407/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm_1               | 2022-07-27 17:14:57,042 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@c8d20bb{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm_1               | 2022-07-27 17:14:57,042 [Listener at 0.0.0.0/9860] INFO server.Server: Started @16501ms
scm_1               | 2022-07-27 17:14:57,044 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1               | 2022-07-27 17:14:57,044 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1               | 2022-07-27 17:14:57,046 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm_1               | 2022-07-27 17:15:00,915 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-FollowerState] INFO impl.FollowerState: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5027456256ns, electionTimeout:5019ms
scm_1               | 2022-07-27 17:15:00,916 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-FollowerState] INFO impl.RoleInfo: 0282b415-9225-47ae-b725-ee6b70b40488: shutdown 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-FollowerState
scm_1               | 2022-07-27 17:15:00,917 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-FollowerState] INFO server.RaftServer$Division: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
scm_1               | 2022-07-27 17:15:00,921 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm_1               | 2022-07-27 17:15:00,921 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-FollowerState] INFO impl.RoleInfo: 0282b415-9225-47ae-b725-ee6b70b40488: start 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1
scm_1               | 2022-07-27 17:15:00,963 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO impl.LeaderElection: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: [0282b415-9225-47ae-b725-ee6b70b40488|rpc:785df6c4750b:9894|admin:|client:|dataStream:|priority:0], old=null
scm_1               | 2022-07-27 17:15:00,964 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO impl.LeaderElection: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1 ELECTION round 0: result PASSED (term=2)
scm_1               | 2022-07-27 17:15:00,965 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO impl.RoleInfo: 0282b415-9225-47ae-b725-ee6b70b40488: shutdown 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1
scm_1               | 2022-07-27 17:15:00,965 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO server.RaftServer$Division: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
scm_1               | 2022-07-27 17:15:00,965 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
scm_1               | 2022-07-27 17:15:00,965 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
scm_1               | 2022-07-27 17:15:00,967 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO server.RaftServer$Division: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A: change Leader from null to 0282b415-9225-47ae-b725-ee6b70b40488 at term 2 for becomeLeader, leader elected after 7986ms
scm_1               | 2022-07-27 17:15:00,973 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm_1               | 2022-07-27 17:15:00,977 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm_1               | 2022-07-27 17:15:00,977 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm_1               | 2022-07-27 17:15:00,983 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm_1               | 2022-07-27 17:15:00,983 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm_1               | 2022-07-27 17:15:00,983 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm_1               | 2022-07-27 17:15:00,989 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm_1               | 2022-07-27 17:15:00,991 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm_1               | 2022-07-27 17:15:00,993 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO impl.RoleInfo: 0282b415-9225-47ae-b725-ee6b70b40488: start 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderStateImpl
scm_1               | 2022-07-27 17:15:00,999 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm_1               | 2022-07-27 17:15:01,005 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/7d45909c-9fcd-4dc9-be34-cfa80db7825a/current/log_inprogress_0 to /data/metadata/scm-ha/7d45909c-9fcd-4dc9-be34-cfa80db7825a/current/log_0-0
scm_1               | 2022-07-27 17:15:01,023 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-LeaderElection1] INFO server.RaftServer$Division: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A: set configuration 1: [0282b415-9225-47ae-b725-ee6b70b40488|rpc:785df6c4750b:9894|admin:|client:|dataStream:|priority:0], old=null
scm_1               | 2022-07-27 17:15:01,030 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/7d45909c-9fcd-4dc9-be34-cfa80db7825a/current/log_inprogress_1
recon_1             | 2022-07-27 17:15:06,848 [IPC Server handler 12 on default port 9891] INFO node.SCMNodeManager: Registered Data node : b50d7a6b-da1f-4bca-b673-015544dce0bd{ip: 172.23.0.10, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:06,848 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node b50d7a6b-da1f-4bca-b673-015544dce0bd to Node DB.
recon_1             | 2022-07-27 17:15:06,849 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=ee453f3e-2788-418a-bfda-78c2755a5ddc reported by b50d7a6b-da1f-4bca-b673-015544dce0bd{ip: 172.23.0.10, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:07,451 [IPC Server handler 1 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for xcompat_datanode_2.xcompat_default
recon_1             | 2022-07-27 17:15:07,451 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=ee453f3e-2788-418a-bfda-78c2755a5ddc reported by 0047ef4e-8059-4dda-a40b-cf26d888a843{ip: 172.23.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:08,126 [IPC Server handler 8 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for xcompat_datanode_4.xcompat_default
recon_1             | 2022-07-27 17:15:08,127 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=d09c0e06-9ec9-4ed1-9cd9-13fcc6bfccb5. Trying to get from SCM.
recon_1             | 2022-07-27 17:15:08,288 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: d09c0e06-9ec9-4ed1-9cd9-13fcc6bfccb5, Nodes: fb410344-fcfe-4f99-b41b-29dd0a68d978{ip: 172.23.0.13, host: xcompat_datanode_4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:fb410344-fcfe-4f99-b41b-29dd0a68d978, CreationTimestamp2022-07-27T17:15:04.446Z[UTC]] to Recon pipeline metadata.
recon_1             | 2022-07-27 17:15:08,303 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d09c0e06-9ec9-4ed1-9cd9-13fcc6bfccb5, Nodes: fb410344-fcfe-4f99-b41b-29dd0a68d978{ip: 172.23.0.13, host: xcompat_datanode_4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:fb410344-fcfe-4f99-b41b-29dd0a68d978, CreationTimestamp2022-07-27T17:15:04.446Z[UTC]].
recon_1             | 2022-07-27 17:15:09,118 [IPC Server handler 8 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for xcompat_datanode_4.xcompat_default
recon_1             | 2022-07-27 17:15:09,119 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=02ad9aa3-8955-4f68-a76b-747c147e1f30. Trying to get from SCM.
recon_1             | 2022-07-27 17:15:09,137 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 02ad9aa3-8955-4f68-a76b-747c147e1f30, Nodes: 5a16948f-0635-4af6-ad47-d40ff1547cf8{ip: 172.23.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2750dc88-6529-455f-a3a5-c6a6089a5bfe{ip: 172.23.0.12, host: xcompat_datanode_5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}fb410344-fcfe-4f99-b41b-29dd0a68d978{ip: 172.23.0.13, host: xcompat_datanode_4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-27T17:15:04.515Z[UTC]] to Recon pipeline metadata.
recon_1             | 2022-07-27 17:15:09,138 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 02ad9aa3-8955-4f68-a76b-747c147e1f30, Nodes: 5a16948f-0635-4af6-ad47-d40ff1547cf8{ip: 172.23.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2750dc88-6529-455f-a3a5-c6a6089a5bfe{ip: 172.23.0.12, host: xcompat_datanode_5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}fb410344-fcfe-4f99-b41b-29dd0a68d978{ip: 172.23.0.13, host: xcompat_datanode_4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-27T17:15:04.515Z[UTC]].
recon_1             | 2022-07-27 17:15:09,140 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=02ad9aa3-8955-4f68-a76b-747c147e1f30 reported by fb410344-fcfe-4f99-b41b-29dd0a68d978{ip: 172.23.0.13, host: xcompat_datanode_4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:11,235 [IPC Server handler 51 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for xcompat_datanode_3.xcompat_default
recon_1             | 2022-07-27 17:15:11,236 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=ee453f3e-2788-418a-bfda-78c2755a5ddc reported by b50d7a6b-da1f-4bca-b673-015544dce0bd{ip: 172.23.0.10, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:11,237 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=ba79c91e-c001-4819-a859-152fbed2c6fc reported by b50d7a6b-da1f-4bca-b673-015544dce0bd{ip: 172.23.0.10, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1               | 2022-07-27 17:15:01,035 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
scm_1               | 2022-07-27 17:15:01,036 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
scm_1               | 2022-07-27 17:15:01,040 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1               | 2022-07-27 17:15:01,040 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm_1               | 2022-07-27 17:15:01,041 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1               | 2022-07-27 17:15:01,042 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1               | 2022-07-27 17:15:01,056 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm_1               | 2022-07-27 17:15:01,057 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1               | 2022-07-27 17:15:01,221 [IPC Server handler 9 on default port 9861] WARN ipc.Server: IPC Server handler 9 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.23.0.13:60950: output error
scm_1               | 2022-07-27 17:15:01,222 [IPC Server handler 9 on default port 9861] INFO ipc.Server: IPC Server handler 9 on default port 9861 caught an exception
scm_1               | java.nio.channels.ClosedChannelException
scm_1               | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
scm_1               | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
scm_1               | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3605)
scm_1               | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:141)
scm_1               | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1667)
scm_1               | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1737)
scm_1               | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2837)
scm_1               | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1809)
scm_1               | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1117)
scm_1               | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:909)
scm_1               | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:895)
scm_1               | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1052)
scm_1               | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm_1               | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1               | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1               | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm_1               | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm_1               | 2022-07-27 17:15:01,225 [IPC Server handler 6 on default port 9861] WARN ipc.Server: IPC Server handler 6 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.23.0.9:57582: output error
scm_1               | 2022-07-27 17:15:01,236 [IPC Server handler 6 on default port 9861] INFO ipc.Server: IPC Server handler 6 on default port 9861 caught an exception
scm_1               | java.nio.channels.ClosedChannelException
scm_1               | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
scm_1               | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
scm_1               | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3605)
scm_1               | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:141)
scm_1               | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1667)
scm_1               | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1737)
scm_1               | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2837)
scm_1               | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1809)
scm_1               | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1117)
scm_1               | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:909)
scm_1               | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:895)
scm_1               | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1052)
scm_1               | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm_1               | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1               | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1               | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm_1               | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm_1               | 2022-07-27 17:15:01,232 [IPC Server handler 0 on default port 9861] WARN ipc.Server: IPC Server handler 0 on default port 9861, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.23.0.12:56576: output error
scm_1               | 2022-07-27 17:15:01,226 [IPC Server handler 7 on default port 9861] WARN ipc.Server: IPC Server handler 7 on default port 9861, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.23.0.10:34542: output error
scm_1               | 2022-07-27 17:15:01,256 [IPC Server handler 7 on default port 9861] INFO ipc.Server: IPC Server handler 7 on default port 9861 caught an exception
scm_1               | java.nio.channels.ClosedChannelException
scm_1               | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
scm_1               | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
scm_1               | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3605)
scm_1               | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:141)
scm_1               | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1667)
scm_1               | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1737)
scm_1               | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2837)
scm_1               | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1809)
scm_1               | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1117)
scm_1               | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:909)
scm_1               | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:895)
scm_1               | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1052)
scm_1               | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm_1               | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1               | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1               | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm_1               | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm_1               | 2022-07-27 17:15:01,261 [IPC Server handler 0 on default port 9861] INFO ipc.Server: IPC Server handler 0 on default port 9861 caught an exception
scm_1               | java.nio.channels.ClosedChannelException
scm_1               | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
scm_1               | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
scm_1               | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3605)
scm_1               | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:141)
recon_1             | 2022-07-27 17:15:11,237 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: ba79c91e-c001-4819-a859-152fbed2c6fc, Nodes: b50d7a6b-da1f-4bca-b673-015544dce0bd{ip: 172.23.0.10, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:b50d7a6b-da1f-4bca-b673-015544dce0bd, CreationTimestamp2022-07-27T17:15:04.077Z[UTC]] moved to OPEN state
recon_1             | 2022-07-27 17:15:11,605 [IPC Server handler 11 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for xcompat_datanode_3.xcompat_default
recon_1             | 2022-07-27 17:15:11,607 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=de666cc0-d9ea-4d5d-8684-29efd5711fcf reported by b50d7a6b-da1f-4bca-b673-015544dce0bd{ip: 172.23.0.10, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:11,608 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=ee453f3e-2788-418a-bfda-78c2755a5ddc reported by b50d7a6b-da1f-4bca-b673-015544dce0bd{ip: 172.23.0.10, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:11,916 [IPC Server handler 8 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for xcompat_datanode_5.xcompat_default
recon_1             | 2022-07-27 17:15:11,917 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=ee453f3e-2788-418a-bfda-78c2755a5ddc reported by 2750dc88-6529-455f-a3a5-c6a6089a5bfe{ip: 172.23.0.12, host: xcompat_datanode_5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:11,917 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=8d4254b1-f279-4915-b6c2-def6498bd1fd reported by 2750dc88-6529-455f-a3a5-c6a6089a5bfe{ip: 172.23.0.12, host: xcompat_datanode_5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:11,917 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 8d4254b1-f279-4915-b6c2-def6498bd1fd, Nodes: 2750dc88-6529-455f-a3a5-c6a6089a5bfe{ip: 172.23.0.12, host: xcompat_datanode_5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:2750dc88-6529-455f-a3a5-c6a6089a5bfe, CreationTimestamp2022-07-27T17:15:04.166Z[UTC]] moved to OPEN state
recon_1             | 2022-07-27 17:15:11,965 [IPC Server handler 42 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for xcompat_datanode_2.xcompat_default
recon_1             | 2022-07-27 17:15:11,966 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=de666cc0-d9ea-4d5d-8684-29efd5711fcf reported by 0047ef4e-8059-4dda-a40b-cf26d888a843{ip: 172.23.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:11,966 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=ee453f3e-2788-418a-bfda-78c2755a5ddc reported by 0047ef4e-8059-4dda-a40b-cf26d888a843{ip: 172.23.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:12,097 [IPC Server handler 43 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for xcompat_datanode_5.xcompat_default
recon_1             | 2022-07-27 17:15:12,098 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=ee453f3e-2788-418a-bfda-78c2755a5ddc reported by 2750dc88-6529-455f-a3a5-c6a6089a5bfe{ip: 172.23.0.12, host: xcompat_datanode_5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:12,098 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=02ad9aa3-8955-4f68-a76b-747c147e1f30 reported by 2750dc88-6529-455f-a3a5-c6a6089a5bfe{ip: 172.23.0.12, host: xcompat_datanode_5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:12,538 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=de666cc0-d9ea-4d5d-8684-29efd5711fcf reported by 0047ef4e-8059-4dda-a40b-cf26d888a843{ip: 172.23.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:12,539 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=e1b362da-60c0-4653-994d-03bdabe80f24 reported by 0047ef4e-8059-4dda-a40b-cf26d888a843{ip: 172.23.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:12,539 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: e1b362da-60c0-4653-994d-03bdabe80f24, Nodes: 0047ef4e-8059-4dda-a40b-cf26d888a843{ip: 172.23.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:0047ef4e-8059-4dda-a40b-cf26d888a843, CreationTimestamp2022-07-27T17:15:04.221Z[UTC]] moved to OPEN state
recon_1             | 2022-07-27 17:15:12,539 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=ee453f3e-2788-418a-bfda-78c2755a5ddc reported by 0047ef4e-8059-4dda-a40b-cf26d888a843{ip: 172.23.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1               | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1667)
scm_1               | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1737)
scm_1               | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2837)
scm_1               | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1809)
scm_1               | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1117)
scm_1               | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:909)
scm_1               | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:895)
scm_1               | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1052)
scm_1               | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm_1               | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1               | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1               | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm_1               | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm_1               | 2022-07-27 17:15:01,271 [IPC Server handler 8 on default port 9861] WARN ipc.Server: IPC Server handler 8 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.23.0.6:45300: output error
scm_1               | 2022-07-27 17:15:01,271 [IPC Server handler 8 on default port 9861] INFO ipc.Server: IPC Server handler 8 on default port 9861 caught an exception
scm_1               | java.nio.channels.ClosedChannelException
scm_1               | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
scm_1               | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
scm_1               | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3605)
scm_1               | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:141)
scm_1               | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1667)
scm_1               | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1737)
scm_1               | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2837)
scm_1               | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1809)
scm_1               | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1117)
scm_1               | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:909)
scm_1               | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:895)
scm_1               | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1052)
scm_1               | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm_1               | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1               | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1               | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm_1               | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm_1               | 2022-07-27 17:15:02,748 [IPC Server handler 11 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/5a16948f-0635-4af6-ad47-d40ff1547cf8
scm_1               | 2022-07-27 17:15:02,771 [IPC Server handler 11 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 5a16948f-0635-4af6-ad47-d40ff1547cf8{ip: 172.23.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1               | 2022-07-27 17:15:02,816 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1               | 2022-07-27 17:15:02,883 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm_1               | 2022-07-27 17:15:02,900 [IPC Server handler 12 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/2750dc88-6529-455f-a3a5-c6a6089a5bfe
scm_1               | 2022-07-27 17:15:02,931 [IPC Server handler 12 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 2750dc88-6529-455f-a3a5-c6a6089a5bfe{ip: 172.23.0.12, host: xcompat_datanode_5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1               | 2022-07-27 17:15:02,931 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1               | 2022-07-27 17:15:02,925 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1               | 2022-07-27 17:15:02,945 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1               | 2022-07-27 17:15:02,980 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm_1               | 2022-07-27 17:15:02,993 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=063cabaa-8e18-48aa-a5b0-fd3704a7a93f to datanode:5a16948f-0635-4af6-ad47-d40ff1547cf8
scm_1               | 2022-07-27 17:15:03,528 [IPC Server handler 11 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/b50d7a6b-da1f-4bca-b673-015544dce0bd
scm_1               | 2022-07-27 17:15:03,529 [IPC Server handler 11 on default port 9861] INFO node.SCMNodeManager: Registered Data node : b50d7a6b-da1f-4bca-b673-015544dce0bd{ip: 172.23.0.10, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1               | 2022-07-27 17:15:03,529 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1               | 2022-07-27 17:15:03,531 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm_1               | 2022-07-27 17:15:03,553 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1               | 2022-07-27 17:15:03,553 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm_1               | 2022-07-27 17:15:03,553 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm_1               | 2022-07-27 17:15:03,554 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm_1               | 2022-07-27 17:15:03,554 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1               | 2022-07-27 17:15:03,800 [IPC Server handler 12 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/0047ef4e-8059-4dda-a40b-cf26d888a843
recon_1             | 2022-07-27 17:15:12,799 [IPC Server handler 12 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/5a16948f-0635-4af6-ad47-d40ff1547cf8
recon_1             | 2022-07-27 17:15:12,800 [IPC Server handler 12 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 5a16948f-0635-4af6-ad47-d40ff1547cf8{ip: 172.23.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:12,800 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 5a16948f-0635-4af6-ad47-d40ff1547cf8 to Node DB.
recon_1             | 2022-07-27 17:15:12,801 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=de666cc0-d9ea-4d5d-8684-29efd5711fcf reported by 5a16948f-0635-4af6-ad47-d40ff1547cf8{ip: 172.23.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:12,801 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=02ad9aa3-8955-4f68-a76b-747c147e1f30 reported by 5a16948f-0635-4af6-ad47-d40ff1547cf8{ip: 172.23.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:13,120 [IPC Server handler 44 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for xcompat_datanode_1.xcompat_default
recon_1             | 2022-07-27 17:15:13,120 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=de666cc0-d9ea-4d5d-8684-29efd5711fcf reported by 5a16948f-0635-4af6-ad47-d40ff1547cf8{ip: 172.23.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:13,120 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=02ad9aa3-8955-4f68-a76b-747c147e1f30 reported by 5a16948f-0635-4af6-ad47-d40ff1547cf8{ip: 172.23.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:14,135 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=02ad9aa3-8955-4f68-a76b-747c147e1f30 reported by fb410344-fcfe-4f99-b41b-29dd0a68d978{ip: 172.23.0.13, host: xcompat_datanode_4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:14,500 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=02ad9aa3-8955-4f68-a76b-747c147e1f30 reported by fb410344-fcfe-4f99-b41b-29dd0a68d978{ip: 172.23.0.13, host: xcompat_datanode_4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:14,501 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 02ad9aa3-8955-4f68-a76b-747c147e1f30, Nodes: 5a16948f-0635-4af6-ad47-d40ff1547cf8{ip: 172.23.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2750dc88-6529-455f-a3a5-c6a6089a5bfe{ip: 172.23.0.12, host: xcompat_datanode_5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}fb410344-fcfe-4f99-b41b-29dd0a68d978{ip: 172.23.0.13, host: xcompat_datanode_4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:fb410344-fcfe-4f99-b41b-29dd0a68d978, CreationTimestamp2022-07-27T17:15:04.515Z[UTC]] moved to OPEN state
recon_1             | 2022-07-27 17:15:16,590 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=de666cc0-d9ea-4d5d-8684-29efd5711fcf reported by b50d7a6b-da1f-4bca-b673-015544dce0bd{ip: 172.23.0.10, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:16,590 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=ee453f3e-2788-418a-bfda-78c2755a5ddc reported by b50d7a6b-da1f-4bca-b673-015544dce0bd{ip: 172.23.0.10, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:17,251 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=ee453f3e-2788-418a-bfda-78c2755a5ddc reported by 2750dc88-6529-455f-a3a5-c6a6089a5bfe{ip: 172.23.0.12, host: xcompat_datanode_5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:17,455 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=de666cc0-d9ea-4d5d-8684-29efd5711fcf reported by b50d7a6b-da1f-4bca-b673-015544dce0bd{ip: 172.23.0.10, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:17,455 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=ee453f3e-2788-418a-bfda-78c2755a5ddc reported by b50d7a6b-da1f-4bca-b673-015544dce0bd{ip: 172.23.0.10, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1               | 2022-07-27 17:15:03,802 [IPC Server handler 12 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 0047ef4e-8059-4dda-a40b-cf26d888a843{ip: 172.23.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1               | 2022-07-27 17:15:03,955 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 063cabaa-8e18-48aa-a5b0-fd3704a7a93f, Nodes: 5a16948f-0635-4af6-ad47-d40ff1547cf8{ip: 172.23.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-27T17:15:02.930Z[UTC]].
scm_1               | 2022-07-27 17:15:03,962 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1               | 2022-07-27 17:15:03,968 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1               | 2022-07-27 17:15:04,035 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=ee453f3e-2788-418a-bfda-78c2755a5ddc to datanode:0047ef4e-8059-4dda-a40b-cf26d888a843
scm_1               | 2022-07-27 17:15:04,043 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=ee453f3e-2788-418a-bfda-78c2755a5ddc to datanode:2750dc88-6529-455f-a3a5-c6a6089a5bfe
scm_1               | 2022-07-27 17:15:04,043 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=ee453f3e-2788-418a-bfda-78c2755a5ddc to datanode:b50d7a6b-da1f-4bca-b673-015544dce0bd
scm_1               | 2022-07-27 17:15:04,067 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: ee453f3e-2788-418a-bfda-78c2755a5ddc, Nodes: 0047ef4e-8059-4dda-a40b-cf26d888a843{ip: 172.23.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2750dc88-6529-455f-a3a5-c6a6089a5bfe{ip: 172.23.0.12, host: xcompat_datanode_5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}b50d7a6b-da1f-4bca-b673-015544dce0bd{ip: 172.23.0.10, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-27T17:15:04.030Z[UTC]].
scm_1               | 2022-07-27 17:15:04,068 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1               | 2022-07-27 17:15:04,077 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=ba79c91e-c001-4819-a859-152fbed2c6fc to datanode:b50d7a6b-da1f-4bca-b673-015544dce0bd
scm_1               | 2022-07-27 17:15:04,104 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: ba79c91e-c001-4819-a859-152fbed2c6fc, Nodes: b50d7a6b-da1f-4bca-b673-015544dce0bd{ip: 172.23.0.10, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-27T17:15:04.077Z[UTC]].
scm_1               | 2022-07-27 17:15:04,110 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1               | 2022-07-27 17:15:04,120 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=de666cc0-d9ea-4d5d-8684-29efd5711fcf to datanode:b50d7a6b-da1f-4bca-b673-015544dce0bd
scm_1               | 2022-07-27 17:15:04,130 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=de666cc0-d9ea-4d5d-8684-29efd5711fcf to datanode:5a16948f-0635-4af6-ad47-d40ff1547cf8
scm_1               | 2022-07-27 17:15:04,131 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=de666cc0-d9ea-4d5d-8684-29efd5711fcf to datanode:0047ef4e-8059-4dda-a40b-cf26d888a843
scm_1               | 2022-07-27 17:15:04,152 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: de666cc0-d9ea-4d5d-8684-29efd5711fcf, Nodes: b50d7a6b-da1f-4bca-b673-015544dce0bd{ip: 172.23.0.10, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}5a16948f-0635-4af6-ad47-d40ff1547cf8{ip: 172.23.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0047ef4e-8059-4dda-a40b-cf26d888a843{ip: 172.23.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-27T17:15:04.120Z[UTC]].
scm_1               | 2022-07-27 17:15:04,158 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1               | 2022-07-27 17:15:04,166 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=8d4254b1-f279-4915-b6c2-def6498bd1fd to datanode:2750dc88-6529-455f-a3a5-c6a6089a5bfe
scm_1               | 2022-07-27 17:15:04,208 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 8d4254b1-f279-4915-b6c2-def6498bd1fd, Nodes: 2750dc88-6529-455f-a3a5-c6a6089a5bfe{ip: 172.23.0.12, host: xcompat_datanode_5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-27T17:15:04.166Z[UTC]].
scm_1               | 2022-07-27 17:15:04,212 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1               | 2022-07-27 17:15:04,226 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=e1b362da-60c0-4653-994d-03bdabe80f24 to datanode:0047ef4e-8059-4dda-a40b-cf26d888a843
recon_1             | 2022-07-27 17:15:17,456 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: ee453f3e-2788-418a-bfda-78c2755a5ddc, Nodes: 0047ef4e-8059-4dda-a40b-cf26d888a843{ip: 172.23.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2750dc88-6529-455f-a3a5-c6a6089a5bfe{ip: 172.23.0.12, host: xcompat_datanode_5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}b50d7a6b-da1f-4bca-b673-015544dce0bd{ip: 172.23.0.10, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:b50d7a6b-da1f-4bca-b673-015544dce0bd, CreationTimestamp2022-07-27T17:15:04.030Z[UTC]] moved to OPEN state
recon_1             | 2022-07-27 17:15:17,785 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=de666cc0-d9ea-4d5d-8684-29efd5711fcf reported by 0047ef4e-8059-4dda-a40b-cf26d888a843{ip: 172.23.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:22,218 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=de666cc0-d9ea-4d5d-8684-29efd5711fcf reported by 0047ef4e-8059-4dda-a40b-cf26d888a843{ip: 172.23.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:22,218 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: de666cc0-d9ea-4d5d-8684-29efd5711fcf, Nodes: b50d7a6b-da1f-4bca-b673-015544dce0bd{ip: 172.23.0.10, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}5a16948f-0635-4af6-ad47-d40ff1547cf8{ip: 172.23.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0047ef4e-8059-4dda-a40b-cf26d888a843{ip: 172.23.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:0047ef4e-8059-4dda-a40b-cf26d888a843, CreationTimestamp2022-07-27T17:15:04.120Z[UTC]] moved to OPEN state
recon_1             | 2022-07-27 17:15:35,352 [IPC Server handler 6 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for xcompat_datanode_1.xcompat_default
recon_1             | 2022-07-27 17:15:35,356 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=063cabaa-8e18-48aa-a5b0-fd3704a7a93f reported by 5a16948f-0635-4af6-ad47-d40ff1547cf8{ip: 172.23.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1             | 2022-07-27 17:15:35,358 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 063cabaa-8e18-48aa-a5b0-fd3704a7a93f, Nodes: 5a16948f-0635-4af6-ad47-d40ff1547cf8{ip: 172.23.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:5a16948f-0635-4af6-ad47-d40ff1547cf8, CreationTimestamp2022-07-27T17:15:02.930Z[UTC]] moved to OPEN state
recon_1             | 2022-07-27 17:15:49,257 [FixedThreadPoolWithAffinityExecutor-8-0] INFO scm.ReconContainerManager: New container #1 got from xcompat_datanode_4.xcompat_default.
recon_1             | 2022-07-27 17:15:49,394 [FixedThreadPoolWithAffinityExecutor-8-0] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
recon_1             | 2022-07-27 17:15:54,639 [pool-26-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1             | 2022-07-27 17:15:54,640 [pool-26-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1             | 2022-07-27 17:15:55,581 [pool-26-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Got new checkpoint from OM : /data/metadata/om.snapshot.db_1658942154640
recon_1             | 2022-07-27 17:15:55,622 [pool-26-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1             | 2022-07-27 17:15:55,623 [pool-26-thread-1] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
recon_1             | 2022-07-27 17:15:55,717 [pool-26-thread-1] INFO recovery.ReconOmMetadataManagerImpl: Created OM DB handle from snapshot at /data/metadata/om.snapshot.db_1658942154640.
recon_1             | 2022-07-27 17:15:55,818 [pool-26-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Calling reprocess on Recon tasks.
recon_1             | 2022-07-27 17:15:55,822 [pool-27-thread-1] INFO tasks.NSSummaryTask: Completed a reprocess run of NSSummaryTask
recon_1             | 2022-07-27 17:15:56,195 [pool-27-thread-1] INFO tasks.TableCountTask: Completed a 'reprocess' run of TableCountTask.
recon_1             | 2022-07-27 17:15:56,196 [pool-27-thread-1] INFO tasks.ContainerKeyMapperTask: Starting a 'reprocess' run of ContainerKeyMapperTask.
recon_1             | 2022-07-27 17:15:56,302 [pool-27-thread-1] INFO tasks.ContainerKeyMapperTask: Completed 'reprocess' of ContainerKeyMapperTask.
recon_1             | 2022-07-27 17:15:56,303 [pool-27-thread-1] INFO tasks.ContainerKeyMapperTask: It took me 0.106 seconds to process 1 keys.
recon_1             | 2022-07-27 17:15:56,338 [pool-27-thread-1] INFO tasks.FileSizeCountTask: Deleted 0 records from "FILE_COUNT_BY_SIZE"
recon_1             | 2022-07-27 17:15:56,354 [pool-27-thread-1] INFO tasks.FileSizeCountTask: Completed a 'reprocess' run of FileSizeCountTask.
recon_1             | 2022-07-27 17:15:57,442 [FixedThreadPoolWithAffinityExecutor-8-0] INFO scm.ReconContainerManager: New container #2 got from xcompat_datanode_1.xcompat_default.
recon_1             | 2022-07-27 17:15:57,448 [FixedThreadPoolWithAffinityExecutor-8-0] INFO scm.ReconContainerManager: Successfully added container #2 to Recon.
recon_1             | 2022-07-27 17:16:04,510 [FixedThreadPoolWithAffinityExecutor-8-0] INFO scm.ReconContainerManager: New container #3 got from xcompat_datanode_2.xcompat_default.
recon_1             | 2022-07-27 17:16:04,519 [FixedThreadPoolWithAffinityExecutor-8-0] WARN scm.ReconContainerManager: Pipeline PipelineID=fcbb54ef-5c01-49d3-aef2-b9be4ffa420f not found. Cannot add container #3
recon_1             | 2022-07-27 17:16:04,521 [FixedThreadPoolWithAffinityExecutor-8-0] WARN scm.ReconIncrementalContainerReportHandler: Container 3 not found!
recon_1             | 2022-07-27 17:16:04,566 [FixedThreadPoolWithAffinityExecutor-9-0] INFO scm.ReconContainerManager: New container #3 got from xcompat_datanode_5.xcompat_default.
recon_1             | 2022-07-27 17:16:04,576 [FixedThreadPoolWithAffinityExecutor-9-0] WARN scm.ReconContainerManager: Pipeline PipelineID=fcbb54ef-5c01-49d3-aef2-b9be4ffa420f not found. Cannot add container #3
recon_1             | 2022-07-27 17:16:04,577 [FixedThreadPoolWithAffinityExecutor-9-0] WARN scm.ReconIncrementalContainerReportHandler: Container 3 not found!
scm_1               | 2022-07-27 17:15:04,244 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: e1b362da-60c0-4653-994d-03bdabe80f24, Nodes: 0047ef4e-8059-4dda-a40b-cf26d888a843{ip: 172.23.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-27T17:15:04.221Z[UTC]].
scm_1               | 2022-07-27 17:15:04,249 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1               | 2022-07-27 17:15:04,413 [IPC Server handler 11 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/fb410344-fcfe-4f99-b41b-29dd0a68d978
scm_1               | 2022-07-27 17:15:04,445 [IPC Server handler 11 on default port 9861] INFO node.SCMNodeManager: Registered Data node : fb410344-fcfe-4f99-b41b-29dd0a68d978{ip: 172.23.0.13, host: xcompat_datanode_4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1               | 2022-07-27 17:15:04,445 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1               | 2022-07-27 17:15:04,446 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=d09c0e06-9ec9-4ed1-9cd9-13fcc6bfccb5 to datanode:fb410344-fcfe-4f99-b41b-29dd0a68d978
scm_1               | 2022-07-27 17:15:04,502 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d09c0e06-9ec9-4ed1-9cd9-13fcc6bfccb5, Nodes: fb410344-fcfe-4f99-b41b-29dd0a68d978{ip: 172.23.0.13, host: xcompat_datanode_4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-27T17:15:04.446Z[UTC]].
scm_1               | 2022-07-27 17:15:04,511 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1               | 2022-07-27 17:15:04,521 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=02ad9aa3-8955-4f68-a76b-747c147e1f30 to datanode:5a16948f-0635-4af6-ad47-d40ff1547cf8
scm_1               | 2022-07-27 17:15:04,545 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=02ad9aa3-8955-4f68-a76b-747c147e1f30 to datanode:2750dc88-6529-455f-a3a5-c6a6089a5bfe
scm_1               | 2022-07-27 17:15:04,546 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=02ad9aa3-8955-4f68-a76b-747c147e1f30 to datanode:fb410344-fcfe-4f99-b41b-29dd0a68d978
scm_1               | 2022-07-27 17:15:04,561 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 02ad9aa3-8955-4f68-a76b-747c147e1f30, Nodes: 5a16948f-0635-4af6-ad47-d40ff1547cf8{ip: 172.23.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2750dc88-6529-455f-a3a5-c6a6089a5bfe{ip: 172.23.0.12, host: xcompat_datanode_5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}fb410344-fcfe-4f99-b41b-29dd0a68d978{ip: 172.23.0.13, host: xcompat_datanode_4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-27T17:15:04.515Z[UTC]].
scm_1               | 2022-07-27 17:15:04,572 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1               | 2022-07-27 17:15:08,148 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d09c0e06-9ec9-4ed1-9cd9-13fcc6bfccb5, Nodes: fb410344-fcfe-4f99-b41b-29dd0a68d978{ip: 172.23.0.13, host: xcompat_datanode_4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:fb410344-fcfe-4f99-b41b-29dd0a68d978, CreationTimestamp2022-07-27T17:15:04.446Z[UTC]] moved to OPEN state
scm_1               | 2022-07-27 17:15:08,160 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1               | 2022-07-27 17:15:08,162 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1               | 2022-07-27 17:15:09,145 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1               | 2022-07-27 17:15:11,226 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: ba79c91e-c001-4819-a859-152fbed2c6fc, Nodes: b50d7a6b-da1f-4bca-b673-015544dce0bd{ip: 172.23.0.10, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:b50d7a6b-da1f-4bca-b673-015544dce0bd, CreationTimestamp2022-07-27T17:15:04.077Z[UTC]] moved to OPEN state
scm_1               | 2022-07-27 17:15:11,234 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1               | 2022-07-27 17:15:11,237 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1               | 2022-07-27 17:15:11,700 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
recon_1             | 2022-07-27 17:16:04,687 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: New container #3 got from xcompat_datanode_4.xcompat_default.
recon_1             | 2022-07-27 17:16:04,692 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=fcbb54ef-5c01-49d3-aef2-b9be4ffa420f not found. Cannot add container #3
recon_1             | 2022-07-27 17:16:04,693 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconIncrementalContainerReportHandler: Container 3 not found!
recon_1             | 2022-07-27 17:16:04,711 [FixedThreadPoolWithAffinityExecutor-8-0] INFO scm.ReconContainerManager: New container #3 got from xcompat_datanode_1.xcompat_default.
recon_1             | 2022-07-27 17:16:04,719 [FixedThreadPoolWithAffinityExecutor-8-0] WARN scm.ReconContainerManager: Pipeline PipelineID=fcbb54ef-5c01-49d3-aef2-b9be4ffa420f not found. Cannot add container #3
recon_1             | 2022-07-27 17:16:04,720 [FixedThreadPoolWithAffinityExecutor-8-0] WARN scm.ReconIncrementalContainerReportHandler: Container 3 not found!
recon_1             | 2022-07-27 17:16:04,729 [FixedThreadPoolWithAffinityExecutor-9-0] INFO scm.ReconContainerManager: New container #3 got from xcompat_datanode_3.xcompat_default.
recon_1             | 2022-07-27 17:16:04,733 [FixedThreadPoolWithAffinityExecutor-9-0] WARN scm.ReconContainerManager: Pipeline PipelineID=fcbb54ef-5c01-49d3-aef2-b9be4ffa420f not found. Cannot add container #3
recon_1             | 2022-07-27 17:16:04,733 [FixedThreadPoolWithAffinityExecutor-9-0] WARN scm.ReconIncrementalContainerReportHandler: Container 3 not found!
recon_1             | 2022-07-27 17:16:53,986 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: New container #4 got from xcompat_datanode_2.xcompat_default.
recon_1             | 2022-07-27 17:16:53,993 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: Successfully added container #4 to Recon.
recon_1             | 2022-07-27 17:20:04,398 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 35 milliseconds to process 0 existing database records.
recon_1             | 2022-07-27 17:20:04,423 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 23 milliseconds for processing 3 containers.
recon_1             | 2022-07-27 17:20:05,235 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 8 pipelines in house.
recon_1             | 2022-07-27 17:20:05,242 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=fcbb54ef-5c01-49d3-aef2-b9be4ffa420f from SCM.
recon_1             | 2022-07-27 17:20:05,248 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: fcbb54ef-5c01-49d3-aef2-b9be4ffa420f, Nodes: b50d7a6b-da1f-4bca-b673-015544dce0bd{ip: 172.23.0.10, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}2750dc88-6529-455f-a3a5-c6a6089a5bfe{ip: 172.23.0.12, host: xcompat_datanode_5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}fb410344-fcfe-4f99-b41b-29dd0a68d978{ip: 172.23.0.13, host: xcompat_datanode_4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}5a16948f-0635-4af6-ad47-d40ff1547cf8{ip: 172.23.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}0047ef4e-8059-4dda-a40b-cf26d888a843{ip: 172.23.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:OPEN, leaderId:, CreationTimestamp2022-07-27T17:16:02.409Z[UTC]].
recon_1             | 2022-07-27 17:20:05,251 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 24 milliseconds.
scm_1               | 2022-07-27 17:15:11,968 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 8d4254b1-f279-4915-b6c2-def6498bd1fd, Nodes: 2750dc88-6529-455f-a3a5-c6a6089a5bfe{ip: 172.23.0.12, host: xcompat_datanode_5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:2750dc88-6529-455f-a3a5-c6a6089a5bfe, CreationTimestamp2022-07-27T17:15:04.166Z[UTC]] moved to OPEN state
scm_1               | 2022-07-27 17:15:11,983 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1               | 2022-07-27 17:15:11,993 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1               | 2022-07-27 17:15:12,108 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1               | 2022-07-27 17:15:12,550 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: e1b362da-60c0-4653-994d-03bdabe80f24, Nodes: 0047ef4e-8059-4dda-a40b-cf26d888a843{ip: 172.23.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:0047ef4e-8059-4dda-a40b-cf26d888a843, CreationTimestamp2022-07-27T17:15:04.221Z[UTC]] moved to OPEN state
scm_1               | 2022-07-27 17:15:12,572 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1               | 2022-07-27 17:15:12,583 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1               | 2022-07-27 17:15:14,154 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1               | 2022-07-27 17:15:14,541 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 02ad9aa3-8955-4f68-a76b-747c147e1f30, Nodes: 5a16948f-0635-4af6-ad47-d40ff1547cf8{ip: 172.23.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2750dc88-6529-455f-a3a5-c6a6089a5bfe{ip: 172.23.0.12, host: xcompat_datanode_5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}fb410344-fcfe-4f99-b41b-29dd0a68d978{ip: 172.23.0.13, host: xcompat_datanode_4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:fb410344-fcfe-4f99-b41b-29dd0a68d978, CreationTimestamp2022-07-27T17:15:04.515Z[UTC]] moved to OPEN state
scm_1               | 2022-07-27 17:15:14,547 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm_1               | 2022-07-27 17:15:14,557 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm_1               | 2022-07-27 17:15:14,558 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1               | 2022-07-27 17:15:14,560 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1               | 2022-07-27 17:15:14,560 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm_1               | 2022-07-27 17:15:14,560 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm_1               | 2022-07-27 17:15:14,560 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm_1               | 2022-07-27 17:15:14,560 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO BackgroundPipelineScrubber: Service BackgroundPipelineScrubber transitions to RUNNING.
scm_1               | 2022-07-27 17:15:14,563 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ExpiredContainerReplicaOpScrubber: Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
scm_1               | 2022-07-27 17:15:14,564 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO UnderReplicatedQueueThread: Service UnderReplicatedQueueThread transitions to RUNNING.
scm_1               | 2022-07-27 17:15:14,579 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO OverReplicatedQueueThread: Service OverReplicatedQueueThread transitions to RUNNING.
scm_1               | 2022-07-27 17:15:14,579 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO replication.ReplicationManager: Service ReplicationManager transitions to RUNNING.
scm_1               | 2022-07-27 17:15:14,584 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
scm_1               | 2022-07-27 17:15:17,466 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: ee453f3e-2788-418a-bfda-78c2755a5ddc, Nodes: 0047ef4e-8059-4dda-a40b-cf26d888a843{ip: 172.23.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2750dc88-6529-455f-a3a5-c6a6089a5bfe{ip: 172.23.0.12, host: xcompat_datanode_5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}b50d7a6b-da1f-4bca-b673-015544dce0bd{ip: 172.23.0.10, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:b50d7a6b-da1f-4bca-b673-015544dce0bd, CreationTimestamp2022-07-27T17:15:04.030Z[UTC]] moved to OPEN state
scm_1               | 2022-07-27 17:15:22,237 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: de666cc0-d9ea-4d5d-8684-29efd5711fcf, Nodes: b50d7a6b-da1f-4bca-b673-015544dce0bd{ip: 172.23.0.10, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}5a16948f-0635-4af6-ad47-d40ff1547cf8{ip: 172.23.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}0047ef4e-8059-4dda-a40b-cf26d888a843{ip: 172.23.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:0047ef4e-8059-4dda-a40b-cf26d888a843, CreationTimestamp2022-07-27T17:15:04.120Z[UTC]] moved to OPEN state
scm_1               | 2022-07-27 17:15:35,354 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 063cabaa-8e18-48aa-a5b0-fd3704a7a93f, Nodes: 5a16948f-0635-4af6-ad47-d40ff1547cf8{ip: 172.23.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:5a16948f-0635-4af6-ad47-d40ff1547cf8, CreationTimestamp2022-07-27T17:15:02.930Z[UTC]] moved to OPEN state
scm_1               | 2022-07-27 17:15:46,484 [IPC Server handler 99 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
scm_1               | 2022-07-27 17:15:46,522 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm_1               | 2022-07-27 17:15:46,534 [IPC Server handler 99 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 109611004723200000 to 109611004723201000.
scm_1               | 2022-07-27 17:16:02,418 [0282b415-9225-47ae-b725-ee6b70b40488@group-CFA80DB7825A-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: fcbb54ef-5c01-49d3-aef2-b9be4ffa420f, Nodes: b50d7a6b-da1f-4bca-b673-015544dce0bd{ip: 172.23.0.10, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}2750dc88-6529-455f-a3a5-c6a6089a5bfe{ip: 172.23.0.12, host: xcompat_datanode_5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}fb410344-fcfe-4f99-b41b-29dd0a68d978{ip: 172.23.0.13, host: xcompat_datanode_4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}5a16948f-0635-4af6-ad47-d40ff1547cf8{ip: 172.23.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}0047ef4e-8059-4dda-a40b-cf26d888a843{ip: 172.23.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-27T17:16:02.409Z[UTC]].
scm_1               | 2022-07-27 17:16:02,427 [IPC Server handler 25 on default port 9863] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: fcbb54ef-5c01-49d3-aef2-b9be4ffa420f, Nodes: b50d7a6b-da1f-4bca-b673-015544dce0bd{ip: 172.23.0.10, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}2750dc88-6529-455f-a3a5-c6a6089a5bfe{ip: 172.23.0.12, host: xcompat_datanode_5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}fb410344-fcfe-4f99-b41b-29dd0a68d978{ip: 172.23.0.13, host: xcompat_datanode_4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}5a16948f-0635-4af6-ad47-d40ff1547cf8{ip: 172.23.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}0047ef4e-8059-4dda-a40b-cf26d888a843{ip: 172.23.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-27T17:16:02.409Z[UTC]] moved to OPEN state
scm_1               | 2022-07-27 17:17:23,517 [IPC Server handler 78 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for delTxnId, change lastId from 0 to 1000.
scm_1               | 2022-07-27 17:19:54,708 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1               | 2022-07-27 17:20:24,702 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1               | 2022-07-27 17:20:24,712 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1               | 2022-07-27 17:20:54,702 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1               | 2022-07-27 17:20:54,712 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
