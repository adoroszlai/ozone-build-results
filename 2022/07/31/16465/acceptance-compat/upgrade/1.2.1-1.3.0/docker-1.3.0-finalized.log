Attaching to ha_om2_1, ha_scm_1, ha_om1_1, ha_dn2_1, ha_om3_1, ha_recon_1, ha_dn4_1, ha_dn3_1, ha_s3g_1, ha_dn1_1, ha_dn5_1
dn1_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
dn1_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
dn1_1    | 2022-07-31 01:17:23,480 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
dn1_1    | /************************************************************
dn1_1    | STARTUP_MSG: Starting HddsDatanodeService
dn1_1    | STARTUP_MSG:   host = b5a69c4cb320/10.9.0.15
dn1_1    | STARTUP_MSG:   args = []
dn1_1    | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
dn1_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
dn1_1    | STARTUP_MSG:   build = https://github.com/apache/ozone/57d620dbd4cb5dfec746cc16039d3843e64c181c ; compiled by 'runner' on 2022-07-31T00:51Z
dn1_1    | STARTUP_MSG:   java = 11.0.14.1
dn1_1    | ************************************************************/
dn1_1    | 2022-07-31 01:17:23,574 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
dn1_1    | 2022-07-31 01:17:24,078 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
dn1_1    | 2022-07-31 01:17:24,911 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
dn1_1    | 2022-07-31 01:17:26,598 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
dn1_1    | 2022-07-31 01:17:26,598 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
dn1_1    | 2022-07-31 01:17:27,987 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:b5a69c4cb320 ip:10.9.0.15
dn1_1    | 2022-07-31 01:17:30,066 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = DATANODE_SCHEMA_V3 (version = 4)
dn1_1    | 2022-07-31 01:17:31,542 [main] INFO reflections.Reflections: Reflections took 1218 ms to scan 2 urls, producing 89 keys and 198 values 
dn1_1    | 2022-07-31 01:17:31,975 [main] INFO upgrade.HDDSLayoutVersionManager: Registering Upgrade Action : DatanodeSchemaV3FinalizeAction
dn1_1    | 2022-07-31 01:17:32,248 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
dn1_1    | 2022-07-31 01:17:33,452 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/hdds/scmUsed: 8414 at 2022-07-31T01:17:01.401Z
dn1_1    | 2022-07-31 01:17:33,631 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
dn1_1    | 2022-07-31 01:17:33,645 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
dn1_1    | 2022-07-31 01:17:33,654 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
dn1_1    | 2022-07-31 01:17:33,875 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
dn1_1    | 2022-07-31 01:17:34,091 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn1_1    | 2022-07-31 01:17:34,095 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/metadata/ratis/scmUsed: 4096 at 2022-07-31T01:17:01.403Z
dn1_1    | 2022-07-31 01:17:34,172 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
dn1_1    | 2022-07-31 01:17:34,172 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
dn1_1    | 2022-07-31 01:17:34,173 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
dn1_1    | 2022-07-31 01:17:34,390 [Thread-3] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
dn1_1    | 2022-07-31 01:17:35,508 [Thread-3] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
dn1_1    | 2022-07-31 01:17:35,509 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 1s
dn1_1    | 2022-07-31 01:17:47,388 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
dn1_1    | 2022-07-31 01:17:48,454 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn1_1    | 2022-07-31 01:17:49,330 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
dn1_1    | 2022-07-31 01:17:51,020 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
dn1_1    | 2022-07-31 01:17:51,021 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
dn1_1    | 2022-07-31 01:17:51,039 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
dn1_1    | 2022-07-31 01:17:51,047 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
dn1_1    | 2022-07-31 01:17:51,053 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2022-07-31 01:17:51,056 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
dn1_1    | 2022-07-31 01:17:51,060 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn1_1    | 2022-07-31 01:17:51,216 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
dn1_1    | 2022-07-31 01:17:51,233 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
dn1_1    | 2022-07-31 01:17:53,604 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
dn1_1    | 2022-07-31 01:17:53,652 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
dn1_1    | 2022-07-31 01:17:53,697 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
dn1_1    | 2022-07-31 01:17:53,699 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn1_1    | 2022-07-31 01:17:53,700 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn1_1    | 2022-07-31 01:17:53,707 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn1_1    | 2022-07-31 01:17:53,746 [609e7f2d-9474-472f-937f-8fa0a0bbb327-impl-thread1] INFO server.RaftServer: 609e7f2d-9474-472f-937f-8fa0a0bbb327: found a subdirectory /data/metadata/ratis/c57ff3c1-98cc-4640-a639-ffc093016e58
dn1_1    | 2022-07-31 01:17:53,883 [609e7f2d-9474-472f-937f-8fa0a0bbb327-impl-thread1] INFO server.RaftServer: 609e7f2d-9474-472f-937f-8fa0a0bbb327: addNew group-FFC093016E58:[] returns group-FFC093016E58:java.util.concurrent.CompletableFuture@2be5a88c[Not completed]
dn1_1    | 2022-07-31 01:17:53,885 [609e7f2d-9474-472f-937f-8fa0a0bbb327-impl-thread1] INFO server.RaftServer: 609e7f2d-9474-472f-937f-8fa0a0bbb327: found a subdirectory /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246
dn1_1    | 2022-07-31 01:17:53,885 [609e7f2d-9474-472f-937f-8fa0a0bbb327-impl-thread1] INFO server.RaftServer: 609e7f2d-9474-472f-937f-8fa0a0bbb327: addNew group-75041C4AA246:[] returns group-75041C4AA246:java.util.concurrent.CompletableFuture@24e697a[Not completed]
dn1_1    | 2022-07-31 01:17:53,885 [609e7f2d-9474-472f-937f-8fa0a0bbb327-impl-thread1] INFO server.RaftServer: 609e7f2d-9474-472f-937f-8fa0a0bbb327: found a subdirectory /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1
dn1_1    | 2022-07-31 01:17:53,885 [609e7f2d-9474-472f-937f-8fa0a0bbb327-impl-thread1] INFO server.RaftServer: 609e7f2d-9474-472f-937f-8fa0a0bbb327: addNew group-65A101075AF1:[] returns group-65A101075AF1:java.util.concurrent.CompletableFuture@65f66d51[Not completed]
dn1_1    | 2022-07-31 01:17:54,021 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
dn1_1    | 2022-07-31 01:17:54,284 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327: new RaftServerImpl for group-FFC093016E58:[] with ContainerStateMachine:uninitialized
dn1_1    | 2022-07-31 01:17:54,301 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn1_1    | 2022-07-31 01:17:54,334 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn1_1    | 2022-07-31 01:17:54,339 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn1_1    | 2022-07-31 01:17:54,339 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn1_1    | 2022-07-31 01:17:54,357 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn1_1    | 2022-07-31 01:17:54,357 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn1_1    | 2022-07-31 01:17:54,440 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn1_1    | 2022-07-31 01:17:54,441 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn1_1    | 2022-07-31 01:17:54,505 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn1_1    | 2022-07-31 01:17:54,521 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn1_1    | 2022-07-31 01:17:54,682 [pool-42-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/c57ff3c1-98cc-4640-a639-ffc093016e58/in_use.lock acquired by nodename 8@b5a69c4cb320
dn1_1    | 2022-07-31 01:17:54,783 [pool-42-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=3, votedFor=609e7f2d-9474-472f-937f-8fa0a0bbb327} from /data/metadata/ratis/c57ff3c1-98cc-4640-a639-ffc093016e58/current/raft-meta
dn1_1    | 2022-07-31 01:17:54,983 [pool-42-thread-1] INFO ratis.ContainerStateMachine: group-FFC093016E58: Setting the last applied index to (t:3, i:4)
dn1_1    | 2022-07-31 01:17:55,457 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
dn1_1    | 2022-07-31 01:17:55,663 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
dn1_1    | 2022-07-31 01:17:56,049 [main] INFO util.log: Logging initialized @44278ms to org.eclipse.jetty.util.log.Slf4jLog
dn1_1    | 2022-07-31 01:17:56,784 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58: set configuration 3: [609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-07-31 01:17:56,804 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn1_1    | 2022-07-31 01:17:56,811 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn1_1    | 2022-07-31 01:17:57,071 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn1_1    | 2022-07-31 01:17:57,071 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2022-07-31 01:17:57,082 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn1_1    | 2022-07-31 01:17:57,315 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2022-07-31 01:17:57,527 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn1_1    | 2022-07-31 01:17:57,536 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn1_1    | 2022-07-31 01:17:57,638 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: new 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/c57ff3c1-98cc-4640-a639-ffc093016e58
dn1_1    | 2022-07-31 01:17:57,653 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn1_1    | 2022-07-31 01:17:57,655 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn1_1    | 2022-07-31 01:17:57,662 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2022-07-31 01:17:57,698 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn1_1    | 2022-07-31 01:17:57,722 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn1_1    | 2022-07-31 01:17:57,734 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn1_1    | 2022-07-31 01:17:57,741 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn1_1    | 2022-07-31 01:17:57,780 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn1_1    | 2022-07-31 01:17:57,863 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn1_1    | 2022-07-31 01:17:57,906 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn1_1    | 2022-07-31 01:17:57,882 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
dn1_1    | 2022-07-31 01:17:57,932 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn1_1    | 2022-07-31 01:17:58,353 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
dn1_1    | 2022-07-31 01:17:58,380 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
dn1_1    | 2022-07-31 01:17:58,499 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
dn1_1    | 2022-07-31 01:17:58,506 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
dn1_1    | 2022-07-31 01:17:58,507 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
dn1_1    | 2022-07-31 01:17:58,625 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58: set configuration 0: [609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-07-31 01:17:58,637 [pool-42-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/c57ff3c1-98cc-4640-a639-ffc093016e58/current/log_0-0
dn1_1    | 2022-07-31 01:17:58,691 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58: set configuration 1: [609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-07-31 01:17:58,696 [pool-42-thread-1] INFO segmented.LogSegment: Successfully read 2 entries from segment file /data/metadata/ratis/c57ff3c1-98cc-4640-a639-ffc093016e58/current/log_1-2
dn2_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
dn2_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
dn2_1    | 2022-07-31 01:17:28,413 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
dn2_1    | /************************************************************
dn2_1    | STARTUP_MSG: Starting HddsDatanodeService
dn2_1    | STARTUP_MSG:   host = c5b89a034b5d/10.9.0.16
dn2_1    | STARTUP_MSG:   args = []
dn2_1    | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
dn1_1    | 2022-07-31 01:17:58,743 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58: set configuration 3: [609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-07-31 01:17:58,743 [pool-42-thread-1] INFO segmented.LogSegment: Successfully read 2 entries from segment file /data/metadata/ratis/c57ff3c1-98cc-4640-a639-ffc093016e58/current/log_inprogress_3
dn1_1    | 2022-07-31 01:17:58,748 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 4
dn1_1    | 2022-07-31 01:17:58,761 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 2
dn1_1    | 2022-07-31 01:17:59,168 [main] INFO http.HttpServer2: Jetty bound to port 9882
dn1_1    | 2022-07-31 01:17:59,176 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
dn1_1    | 2022-07-31 01:17:59,425 [pool-42-thread-1] INFO raftlog.RaftLog: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-SegmentedRaftLog: commitIndex: updateToMax old=4, new=3, updated? false
dn1_1    | 2022-07-31 01:17:59,452 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn1_1    | 2022-07-31 01:17:59,477 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn1_1    | 2022-07-31 01:17:59,482 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn1_1    | 2022-07-31 01:17:59,483 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn1_1    | 2022-07-31 01:17:59,495 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn1_1    | 2022-07-31 01:17:59,497 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn1_1    | 2022-07-31 01:17:59,465 [main] INFO server.session: DefaultSessionIdManager workerName=node0
dn1_1    | 2022-07-31 01:17:59,501 [main] INFO server.session: No SessionScavenger set, using defaults
dn1_1    | 2022-07-31 01:17:59,503 [main] INFO server.session: node0 Scavenging every 660000ms
dn1_1    | 2022-07-31 01:17:59,648 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1d6a8386{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
dn1_1    | 2022-07-31 01:17:59,656 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4fa86cb8{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
dn1_1    | 2022-07-31 01:18:00,170 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn1_1    | 2022-07-31 01:18:00,192 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn1_1    | 2022-07-31 01:18:00,237 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn1_1    | 2022-07-31 01:18:00,256 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn1_1    | 2022-07-31 01:18:00,258 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn1_1    | 2022-07-31 01:18:00,304 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327: new RaftServerImpl for group-75041C4AA246:[] with ContainerStateMachine:uninitialized
dn1_1    | 2022-07-31 01:18:00,310 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn1_1    | 2022-07-31 01:18:00,315 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn1_1    | 2022-07-31 01:18:00,316 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn1_1    | 2022-07-31 01:18:00,345 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn1_1    | 2022-07-31 01:18:00,349 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn1_1    | 2022-07-31 01:18:00,352 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn1_1    | 2022-07-31 01:18:00,353 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn1_1    | 2022-07-31 01:18:00,357 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn1_1    | 2022-07-31 01:18:00,357 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn1_1    | 2022-07-31 01:18:00,357 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn1_1    | 2022-07-31 01:18:00,401 [pool-42-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/in_use.lock acquired by nodename 8@b5a69c4cb320
dn1_1    | 2022-07-31 01:18:00,402 [pool-42-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=9, votedFor=3fc9f139-dd93-41e7-b235-52ce94d6fe3c} from /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/current/raft-meta
dn1_1    | 2022-07-31 01:18:00,407 [pool-42-thread-1] INFO ratis.ContainerStateMachine: group-75041C4AA246: Setting the last applied index to (t:9, i:23)
dn1_1    | 2022-07-31 01:18:00,454 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246: set configuration 10: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-07-31 01:18:00,464 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn1_1    | 2022-07-31 01:18:00,465 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn1_1    | 2022-07-31 01:18:00,478 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn1_1    | 2022-07-31 01:18:00,484 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2022-07-31 01:18:00,485 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn1_1    | 2022-07-31 01:18:00,485 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2022-07-31 01:18:00,488 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn1_1    | 2022-07-31 01:18:00,488 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn1_1    | 2022-07-31 01:18:00,496 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: new 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246
dn3_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
dn3_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
dn3_1    | 2022-07-31 01:17:24,412 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
dn3_1    | /************************************************************
dn3_1    | STARTUP_MSG: Starting HddsDatanodeService
dn3_1    | STARTUP_MSG:   host = 6dca380edee9/10.9.0.17
dn3_1    | STARTUP_MSG:   args = []
dn3_1    | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
dn2_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
dn2_1    | STARTUP_MSG:   build = https://github.com/apache/ozone/57d620dbd4cb5dfec746cc16039d3843e64c181c ; compiled by 'runner' on 2022-07-31T00:51Z
dn2_1    | STARTUP_MSG:   java = 11.0.14.1
dn2_1    | ************************************************************/
dn2_1    | 2022-07-31 01:17:28,495 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
dn2_1    | 2022-07-31 01:17:28,900 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
dn2_1    | 2022-07-31 01:17:29,881 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
dn2_1    | 2022-07-31 01:17:31,222 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
dn2_1    | 2022-07-31 01:17:31,222 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
dn2_1    | 2022-07-31 01:17:33,018 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:c5b89a034b5d ip:10.9.0.16
dn2_1    | 2022-07-31 01:17:34,825 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = DATANODE_SCHEMA_V3 (version = 4)
dn2_1    | 2022-07-31 01:17:36,593 [main] INFO reflections.Reflections: Reflections took 1491 ms to scan 2 urls, producing 89 keys and 198 values 
dn2_1    | 2022-07-31 01:17:37,014 [main] INFO upgrade.HDDSLayoutVersionManager: Registering Upgrade Action : DatanodeSchemaV3FinalizeAction
dn2_1    | 2022-07-31 01:17:37,257 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
dn2_1    | 2022-07-31 01:17:38,544 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/hdds/scmUsed: 8414 at 2022-07-31T01:17:01.345Z
dn2_1    | 2022-07-31 01:17:38,665 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
dn2_1    | 2022-07-31 01:17:38,690 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
dn2_1    | 2022-07-31 01:17:38,698 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
dn2_1    | 2022-07-31 01:17:38,913 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
dn2_1    | 2022-07-31 01:17:39,099 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn2_1    | 2022-07-31 01:17:39,131 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/metadata/ratis/scmUsed: 4096 at 2022-07-31T01:17:01.352Z
dn2_1    | 2022-07-31 01:17:39,210 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
dn2_1    | 2022-07-31 01:17:39,210 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
dn2_1    | 2022-07-31 01:17:39,211 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
dn2_1    | 2022-07-31 01:17:39,356 [Thread-3] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
dn2_1    | 2022-07-31 01:17:40,764 [Thread-3] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
dn2_1    | 2022-07-31 01:17:40,781 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 1s
dn2_1    | 2022-07-31 01:17:53,001 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
dn2_1    | 2022-07-31 01:17:53,750 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn2_1    | 2022-07-31 01:17:54,308 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
dn2_1    | 2022-07-31 01:17:55,680 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
dn2_1    | 2022-07-31 01:17:55,741 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
dn2_1    | 2022-07-31 01:17:55,750 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
dn2_1    | 2022-07-31 01:17:55,770 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
dn2_1    | 2022-07-31 01:17:55,776 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2022-07-31 01:17:55,777 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
dn2_1    | 2022-07-31 01:17:55,777 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn2_1    | 2022-07-31 01:17:55,955 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
dn2_1    | 2022-07-31 01:17:55,965 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
dn2_1    | 2022-07-31 01:17:58,711 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
dn2_1    | 2022-07-31 01:17:58,715 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
dn2_1    | 2022-07-31 01:17:58,732 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
dn2_1    | 2022-07-31 01:17:58,738 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn2_1    | 2022-07-31 01:17:58,740 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn2_1    | 2022-07-31 01:17:58,817 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn2_1    | 2022-07-31 01:17:58,850 [11cba143-91f8-47cb-8422-c32a1e2d51df-impl-thread1] INFO server.RaftServer: 11cba143-91f8-47cb-8422-c32a1e2d51df: found a subdirectory /data/metadata/ratis/8145371a-b336-4e64-a95d-6999419922eb
dn2_1    | 2022-07-31 01:17:58,957 [11cba143-91f8-47cb-8422-c32a1e2d51df-impl-thread1] INFO server.RaftServer: 11cba143-91f8-47cb-8422-c32a1e2d51df: addNew group-6999419922EB:[] returns group-6999419922EB:java.util.concurrent.CompletableFuture@345a40a1[Not completed]
dn2_1    | 2022-07-31 01:17:58,963 [11cba143-91f8-47cb-8422-c32a1e2d51df-impl-thread1] INFO server.RaftServer: 11cba143-91f8-47cb-8422-c32a1e2d51df: found a subdirectory /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246
dn2_1    | 2022-07-31 01:17:58,965 [11cba143-91f8-47cb-8422-c32a1e2d51df-impl-thread1] INFO server.RaftServer: 11cba143-91f8-47cb-8422-c32a1e2d51df: addNew group-75041C4AA246:[] returns group-75041C4AA246:java.util.concurrent.CompletableFuture@49d111aa[Not completed]
dn2_1    | 2022-07-31 01:17:58,973 [11cba143-91f8-47cb-8422-c32a1e2d51df-impl-thread1] INFO server.RaftServer: 11cba143-91f8-47cb-8422-c32a1e2d51df: found a subdirectory /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1
dn3_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
dn3_1    | STARTUP_MSG:   build = https://github.com/apache/ozone/57d620dbd4cb5dfec746cc16039d3843e64c181c ; compiled by 'runner' on 2022-07-31T00:51Z
dn3_1    | STARTUP_MSG:   java = 11.0.14.1
dn3_1    | ************************************************************/
dn3_1    | 2022-07-31 01:17:24,459 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
dn3_1    | 2022-07-31 01:17:25,019 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
dn3_1    | 2022-07-31 01:17:25,947 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
dn3_1    | 2022-07-31 01:17:27,405 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
dn3_1    | 2022-07-31 01:17:27,405 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
dn3_1    | 2022-07-31 01:17:29,284 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:6dca380edee9 ip:10.9.0.17
dn3_1    | 2022-07-31 01:17:31,250 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = DATANODE_SCHEMA_V3 (version = 4)
dn3_1    | 2022-07-31 01:17:32,740 [main] INFO reflections.Reflections: Reflections took 1237 ms to scan 2 urls, producing 89 keys and 198 values 
dn3_1    | 2022-07-31 01:17:33,236 [main] INFO upgrade.HDDSLayoutVersionManager: Registering Upgrade Action : DatanodeSchemaV3FinalizeAction
dn3_1    | 2022-07-31 01:17:33,505 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
dn3_1    | 2022-07-31 01:17:34,797 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/hdds/scmUsed: 4168 at 2022-07-31T01:17:01.427Z
dn3_1    | 2022-07-31 01:17:34,864 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
dn3_1    | 2022-07-31 01:17:34,883 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
dn3_1    | 2022-07-31 01:17:34,946 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
dn3_1    | 2022-07-31 01:17:35,190 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
dn3_1    | 2022-07-31 01:17:35,429 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn3_1    | 2022-07-31 01:17:35,464 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/metadata/ratis/scmUsed: 4096 at 2022-07-31T01:17:01.438Z
dn3_1    | 2022-07-31 01:17:35,478 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
dn3_1    | 2022-07-31 01:17:35,480 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
dn3_1    | 2022-07-31 01:17:35,481 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
dn3_1    | 2022-07-31 01:17:35,729 [Thread-3] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
dn3_1    | 2022-07-31 01:17:36,835 [Thread-3] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
dn3_1    | 2022-07-31 01:17:36,853 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 1s
dn3_1    | 2022-07-31 01:17:49,486 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
dn3_1    | 2022-07-31 01:17:50,004 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn3_1    | 2022-07-31 01:17:50,453 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
dn3_1    | 2022-07-31 01:17:51,909 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
dn3_1    | 2022-07-31 01:17:51,919 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
dn3_1    | 2022-07-31 01:17:51,929 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
dn3_1    | 2022-07-31 01:17:51,930 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
dn3_1    | 2022-07-31 01:17:51,942 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2022-07-31 01:17:51,945 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
dn3_1    | 2022-07-31 01:17:51,958 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn3_1    | 2022-07-31 01:17:52,123 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
dn3_1    | 2022-07-31 01:17:52,127 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
dn3_1    | 2022-07-31 01:17:54,647 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
dn3_1    | 2022-07-31 01:17:54,655 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
dn3_1    | 2022-07-31 01:17:54,682 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
dn3_1    | 2022-07-31 01:17:54,687 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn3_1    | 2022-07-31 01:17:54,708 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn3_1    | 2022-07-31 01:17:54,794 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn3_1    | 2022-07-31 01:17:54,803 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c-impl-thread1] INFO server.RaftServer: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: found a subdirectory /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610
dn3_1    | 2022-07-31 01:17:54,934 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c-impl-thread1] INFO server.RaftServer: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: addNew group-7BB2A1276610:[] returns group-7BB2A1276610:java.util.concurrent.CompletableFuture@4bb0deed[Not completed]
dn3_1    | 2022-07-31 01:17:54,941 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c-impl-thread1] INFO server.RaftServer: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: found a subdirectory /data/metadata/ratis/69ee0657-77f1-4021-b38b-039bb00381b6
dn3_1    | 2022-07-31 01:17:54,942 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c-impl-thread1] INFO server.RaftServer: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: addNew group-039BB00381B6:[] returns group-039BB00381B6:java.util.concurrent.CompletableFuture@1a9b6dad[Not completed]
dn3_1    | 2022-07-31 01:17:54,942 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c-impl-thread1] INFO server.RaftServer: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: found a subdirectory /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246
dn2_1    | 2022-07-31 01:17:58,977 [11cba143-91f8-47cb-8422-c32a1e2d51df-impl-thread1] INFO server.RaftServer: 11cba143-91f8-47cb-8422-c32a1e2d51df: addNew group-65A101075AF1:[] returns group-65A101075AF1:java.util.concurrent.CompletableFuture@2edde097[Not completed]
dn2_1    | 2022-07-31 01:17:59,173 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
dn2_1    | 2022-07-31 01:17:59,407 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df: new RaftServerImpl for group-6999419922EB:[] with ContainerStateMachine:uninitialized
dn2_1    | 2022-07-31 01:17:59,460 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn2_1    | 2022-07-31 01:17:59,492 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn2_1    | 2022-07-31 01:17:59,501 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn2_1    | 2022-07-31 01:17:59,505 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn2_1    | 2022-07-31 01:17:59,512 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn2_1    | 2022-07-31 01:17:59,515 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn2_1    | 2022-07-31 01:17:59,625 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn2_1    | 2022-07-31 01:17:59,637 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn2_1    | 2022-07-31 01:17:59,659 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn2_1    | 2022-07-31 01:17:59,663 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn2_1    | 2022-07-31 01:17:59,849 [pool-42-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/8145371a-b336-4e64-a95d-6999419922eb/in_use.lock acquired by nodename 8@c5b89a034b5d
dn2_1    | 2022-07-31 01:17:59,921 [pool-42-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=3, votedFor=11cba143-91f8-47cb-8422-c32a1e2d51df} from /data/metadata/ratis/8145371a-b336-4e64-a95d-6999419922eb/current/raft-meta
dn2_1    | 2022-07-31 01:18:00,161 [pool-42-thread-1] INFO ratis.ContainerStateMachine: group-6999419922EB: Setting the last applied index to (t:3, i:4)
dn2_1    | 2022-07-31 01:18:00,590 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
dn2_1    | 2022-07-31 01:18:00,802 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
dn2_1    | 2022-07-31 01:18:01,261 [main] INFO util.log: Logging initialized @44287ms to org.eclipse.jetty.util.log.Slf4jLog
dn2_1    | 2022-07-31 01:18:02,094 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB: set configuration 3: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-07-31 01:18:02,095 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn2_1    | 2022-07-31 01:18:02,128 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn2_1    | 2022-07-31 01:18:02,234 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn2_1    | 2022-07-31 01:18:02,238 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2022-07-31 01:18:02,252 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn2_1    | 2022-07-31 01:18:02,370 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2022-07-31 01:18:02,503 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn2_1    | 2022-07-31 01:18:02,504 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn2_1    | 2022-07-31 01:18:02,521 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: new 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/8145371a-b336-4e64-a95d-6999419922eb
dn2_1    | 2022-07-31 01:18:02,536 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn2_1    | 2022-07-31 01:18:02,537 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn2_1    | 2022-07-31 01:18:02,540 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2022-07-31 01:18:02,543 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn2_1    | 2022-07-31 01:18:02,548 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn2_1    | 2022-07-31 01:18:02,562 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn2_1    | 2022-07-31 01:18:02,563 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn2_1    | 2022-07-31 01:18:02,563 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn2_1    | 2022-07-31 01:18:02,642 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn2_1    | 2022-07-31 01:18:02,658 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn2_1    | 2022-07-31 01:18:02,667 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn2_1    | 2022-07-31 01:18:02,873 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
dn2_1    | 2022-07-31 01:18:02,939 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
dn2_1    | 2022-07-31 01:18:02,987 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
dn2_1    | 2022-07-31 01:18:02,998 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
dn2_1    | 2022-07-31 01:18:02,999 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
dn2_1    | 2022-07-31 01:18:02,999 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
dn2_1    | 2022-07-31 01:18:03,114 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB: set configuration 0: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-07-31 01:18:03,147 [pool-42-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/8145371a-b336-4e64-a95d-6999419922eb/current/log_0-0
dn2_1    | 2022-07-31 01:18:03,155 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB: set configuration 1: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-07-31 01:18:03,169 [pool-42-thread-1] INFO segmented.LogSegment: Successfully read 2 entries from segment file /data/metadata/ratis/8145371a-b336-4e64-a95d-6999419922eb/current/log_1-2
dn2_1    | 2022-07-31 01:18:03,170 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB: set configuration 3: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-07-31 01:18:03,171 [pool-42-thread-1] INFO segmented.LogSegment: Successfully read 2 entries from segment file /data/metadata/ratis/8145371a-b336-4e64-a95d-6999419922eb/current/log_inprogress_3
dn2_1    | 2022-07-31 01:18:03,172 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 4
dn2_1    | 2022-07-31 01:18:03,172 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 2
dn2_1    | 2022-07-31 01:18:03,475 [main] INFO http.HttpServer2: Jetty bound to port 9882
dn2_1    | 2022-07-31 01:18:03,485 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
dn2_1    | 2022-07-31 01:18:03,718 [pool-42-thread-1] INFO raftlog.RaftLog: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-SegmentedRaftLog: commitIndex: updateToMax old=4, new=3, updated? false
dn2_1    | 2022-07-31 01:18:03,740 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn2_1    | 2022-07-31 01:18:03,741 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn2_1    | 2022-07-31 01:18:03,741 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn2_1    | 2022-07-31 01:18:03,742 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn2_1    | 2022-07-31 01:18:03,753 [main] INFO server.session: DefaultSessionIdManager workerName=node0
dn2_1    | 2022-07-31 01:18:03,753 [main] INFO server.session: No SessionScavenger set, using defaults
dn2_1    | 2022-07-31 01:18:03,754 [main] INFO server.session: node0 Scavenging every 600000ms
dn2_1    | 2022-07-31 01:18:03,755 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn2_1    | 2022-07-31 01:18:03,755 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn2_1    | 2022-07-31 01:18:03,834 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@22a260ff{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
dn2_1    | 2022-07-31 01:18:03,841 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@ab4aa5e{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
dn2_1    | 2022-07-31 01:18:04,183 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn2_1    | 2022-07-31 01:18:04,220 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn2_1    | 2022-07-31 01:18:04,234 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn2_1    | 2022-07-31 01:18:04,248 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn2_1    | 2022-07-31 01:18:04,249 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn2_1    | 2022-07-31 01:18:04,270 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df: new RaftServerImpl for group-75041C4AA246:[] with ContainerStateMachine:uninitialized
dn2_1    | 2022-07-31 01:18:04,276 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn2_1    | 2022-07-31 01:18:04,278 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn2_1    | 2022-07-31 01:18:04,279 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn2_1    | 2022-07-31 01:18:04,279 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn2_1    | 2022-07-31 01:18:04,280 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn2_1    | 2022-07-31 01:18:04,280 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn2_1    | 2022-07-31 01:18:04,285 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn2_1    | 2022-07-31 01:18:04,286 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn2_1    | 2022-07-31 01:18:04,301 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn2_1    | 2022-07-31 01:18:04,301 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn2_1    | 2022-07-31 01:18:04,314 [pool-42-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/in_use.lock acquired by nodename 8@c5b89a034b5d
dn2_1    | 2022-07-31 01:18:04,317 [pool-42-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=9, votedFor=3fc9f139-dd93-41e7-b235-52ce94d6fe3c} from /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/current/raft-meta
dn2_1    | 2022-07-31 01:18:04,319 [pool-42-thread-1] INFO ratis.ContainerStateMachine: group-75041C4AA246: Setting the last applied index to (t:9, i:23)
dn2_1    | 2022-07-31 01:18:04,386 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246: set configuration 10: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-07-31 01:18:04,389 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn2_1    | 2022-07-31 01:18:04,389 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn2_1    | 2022-07-31 01:18:04,389 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn2_1    | 2022-07-31 01:18:04,390 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2022-07-31 01:18:04,390 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn2_1    | 2022-07-31 01:18:04,390 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2022-07-31 01:18:04,393 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn2_1    | 2022-07-31 01:18:04,393 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn1_1    | 2022-07-31 01:18:00,496 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn1_1    | 2022-07-31 01:18:00,509 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn1_1    | 2022-07-31 01:18:00,509 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2022-07-31 01:18:00,509 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn1_1    | 2022-07-31 01:18:00,510 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn1_1    | 2022-07-31 01:18:00,510 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn1_1    | 2022-07-31 01:18:00,513 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn1_1    | 2022-07-31 01:18:00,513 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn1_1    | 2022-07-31 01:18:00,516 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn1_1    | 2022-07-31 01:18:00,527 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn1_1    | 2022-07-31 01:18:00,573 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn1_1    | 2022-07-31 01:18:00,585 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246: set configuration 0: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-07-31 01:18:00,586 [pool-42-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/current/log_0-0
dn1_1    | 2022-07-31 01:18:00,588 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246: set configuration 1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-07-31 01:18:00,603 [pool-42-thread-1] INFO segmented.LogSegment: Successfully read 9 entries from segment file /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/current/log_1-9
dn1_1    | 2022-07-31 01:18:00,630 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246: set configuration 10: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-07-31 01:18:00,654 [pool-42-thread-1] INFO segmented.LogSegment: Successfully read 14 entries from segment file /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/current/log_inprogress_10
dn1_1    | 2022-07-31 01:18:00,655 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 23
dn1_1    | 2022-07-31 01:18:00,664 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 9
dn1_1    | 2022-07-31 01:18:00,720 [pool-42-thread-1] INFO raftlog.RaftLog: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-SegmentedRaftLog: commitIndex: updateToMax old=23, new=21, updated? false
dn1_1    | 2022-07-31 01:18:00,720 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn1_1    | 2022-07-31 01:18:00,726 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn1_1    | 2022-07-31 01:18:00,730 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn1_1    | 2022-07-31 01:18:00,730 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn1_1    | 2022-07-31 01:18:00,730 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn1_1    | 2022-07-31 01:18:00,731 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn1_1    | 2022-07-31 01:18:00,732 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn1_1    | 2022-07-31 01:18:00,736 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn1_1    | 2022-07-31 01:18:00,737 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn1_1    | 2022-07-31 01:18:00,737 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn1_1    | 2022-07-31 01:18:00,741 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn1_1    | 2022-07-31 01:18:00,747 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327: new RaftServerImpl for group-65A101075AF1:[] with ContainerStateMachine:uninitialized
dn1_1    | 2022-07-31 01:18:00,780 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn1_1    | 2022-07-31 01:18:00,781 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn1_1    | 2022-07-31 01:18:00,785 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn1_1    | 2022-07-31 01:18:00,789 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn1_1    | 2022-07-31 01:18:00,793 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn1_1    | 2022-07-31 01:18:00,794 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn1_1    | 2022-07-31 01:18:00,799 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn1_1    | 2022-07-31 01:18:00,801 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn1_1    | 2022-07-31 01:18:00,801 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn1_1    | 2022-07-31 01:18:00,809 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn1_1    | 2022-07-31 01:18:00,821 [pool-42-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/in_use.lock acquired by nodename 8@b5a69c4cb320
dn3_1    | 2022-07-31 01:17:54,942 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c-impl-thread1] INFO server.RaftServer: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: addNew group-75041C4AA246:[] returns group-75041C4AA246:java.util.concurrent.CompletableFuture@ab414df[Not completed]
dn3_1    | 2022-07-31 01:17:55,116 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
dn3_1    | 2022-07-31 01:17:55,323 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: new RaftServerImpl for group-7BB2A1276610:[] with ContainerStateMachine:uninitialized
dn3_1    | 2022-07-31 01:17:55,364 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn3_1    | 2022-07-31 01:17:55,411 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn3_1    | 2022-07-31 01:17:55,427 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn3_1    | 2022-07-31 01:17:55,430 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn3_1    | 2022-07-31 01:17:55,436 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn3_1    | 2022-07-31 01:17:55,438 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn3_1    | 2022-07-31 01:17:55,589 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn3_1    | 2022-07-31 01:17:55,631 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn3_1    | 2022-07-31 01:17:55,667 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn3_1    | 2022-07-31 01:17:55,673 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn3_1    | 2022-07-31 01:17:55,873 [pool-34-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/in_use.lock acquired by nodename 6@6dca380edee9
dn3_1    | 2022-07-31 01:17:55,950 [pool-34-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=11, votedFor=52aca038-7576-46a0-9ccd-b8aed29078e2} from /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/current/raft-meta
dn3_1    | 2022-07-31 01:17:56,283 [pool-34-thread-1] INFO ratis.ContainerStateMachine: group-7BB2A1276610: Setting the last applied index to (t:11, i:12)
dn3_1    | 2022-07-31 01:17:56,726 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
dn3_1    | 2022-07-31 01:17:56,966 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
dn3_1    | 2022-07-31 01:17:57,330 [main] INFO util.log: Logging initialized @44854ms to org.eclipse.jetty.util.log.Slf4jLog
dn3_1    | 2022-07-31 01:17:58,194 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610: set configuration 3: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-07-31 01:17:58,197 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn3_1    | 2022-07-31 01:17:58,201 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn3_1    | 2022-07-31 01:17:58,316 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn3_1    | 2022-07-31 01:17:58,317 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2022-07-31 01:17:58,350 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn3_1    | 2022-07-31 01:17:58,507 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2022-07-31 01:17:58,631 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn3_1    | 2022-07-31 01:17:58,639 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn3_1    | 2022-07-31 01:17:58,732 [pool-34-thread-1] INFO segmented.SegmentedRaftLogWorker: new 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610
dn3_1    | 2022-07-31 01:17:58,737 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn3_1    | 2022-07-31 01:17:58,741 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn3_1    | 2022-07-31 01:17:58,746 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2022-07-31 01:17:58,761 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn3_1    | 2022-07-31 01:17:58,762 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn3_1    | 2022-07-31 01:17:58,805 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn3_1    | 2022-07-31 01:17:58,806 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn3_1    | 2022-07-31 01:17:58,809 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn3_1    | 2022-07-31 01:17:58,926 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn3_1    | 2022-07-31 01:17:58,944 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn3_1    | 2022-07-31 01:17:58,955 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn3_1    | 2022-07-31 01:17:58,943 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
dn3_1    | 2022-07-31 01:17:59,045 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
dn3_1    | 2022-07-31 01:17:59,131 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
dn3_1    | 2022-07-31 01:17:59,202 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
dn3_1    | 2022-07-31 01:17:59,204 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
dn3_1    | 2022-07-31 01:17:59,204 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
dn3_1    | 2022-07-31 01:17:59,386 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610: set configuration 0: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-07-31 01:17:59,413 [pool-34-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/current/log_0-0
dn3_1    | 2022-07-31 01:17:59,447 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610: set configuration 1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-07-31 01:17:59,448 [pool-34-thread-1] INFO segmented.LogSegment: Successfully read 2 entries from segment file /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/current/log_1-2
dn3_1    | 2022-07-31 01:17:59,486 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610: set configuration 3: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-07-31 01:17:59,513 [pool-34-thread-1] INFO segmented.LogSegment: Successfully read 10 entries from segment file /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/current/log_inprogress_3
dn3_1    | 2022-07-31 01:17:59,519 [pool-34-thread-1] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 12
dn3_1    | 2022-07-31 01:17:59,541 [pool-34-thread-1] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 2
dn3_1    | 2022-07-31 01:17:59,729 [main] INFO http.HttpServer2: Jetty bound to port 9882
dn3_1    | 2022-07-31 01:17:59,750 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
dn3_1    | 2022-07-31 01:17:59,998 [main] INFO server.session: DefaultSessionIdManager workerName=node0
dn3_1    | 2022-07-31 01:18:00,007 [main] INFO server.session: No SessionScavenger set, using defaults
dn3_1    | 2022-07-31 01:18:00,012 [main] INFO server.session: node0 Scavenging every 600000ms
dn3_1    | 2022-07-31 01:18:00,082 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@35cec305{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
dn3_1    | 2022-07-31 01:18:00,090 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7889b4b9{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
dn3_1    | 2022-07-31 01:18:01,018 [pool-34-thread-1] INFO raftlog.RaftLog: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-SegmentedRaftLog: commitIndex: updateToMax old=12, new=11, updated? false
dn3_1    | 2022-07-31 01:18:01,094 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn3_1    | 2022-07-31 01:18:01,102 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn3_1    | 2022-07-31 01:18:01,110 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn3_1    | 2022-07-31 01:18:01,116 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn3_1    | 2022-07-31 01:18:01,142 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn3_1    | 2022-07-31 01:18:01,241 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn3_1    | 2022-07-31 01:18:01,232 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@640d604{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-10278494064042169006/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
dn3_1    | 2022-07-31 01:18:01,537 [main] INFO server.AbstractConnector: Started ServerConnector@486e9d1d{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
dn3_1    | 2022-07-31 01:18:01,542 [main] INFO server.Server: Started @49066ms
dn3_1    | 2022-07-31 01:18:01,575 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
dn3_1    | 2022-07-31 01:18:01,583 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
dn3_1    | 2022-07-31 01:18:01,591 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
dn3_1    | 2022-07-31 01:18:01,594 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
dn3_1    | 2022-07-31 01:18:01,768 [Datanode State Machine Daemon Thread] INFO upgrade.UpgradeFinalizer: Running pre-finalized state validations for unfinalized layout features.
dn3_1    | 2022-07-31 01:18:01,782 [Datanode State Machine Daemon Thread] INFO upgrade.UpgradeFinalizer: Running first upgrade commands for unfinalized layout features.
dn3_1    | 2022-07-31 01:18:01,841 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2032517b] INFO util.JvmPauseMonitor: Starting JVM pause monitor
dn3_1    | 2022-07-31 01:18:02,074 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn3_1    | 2022-07-31 01:18:02,075 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn3_1    | 2022-07-31 01:18:02,084 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn3_1    | 2022-07-31 01:18:02,092 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn3_1    | 2022-07-31 01:18:02,105 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn3_1    | 2022-07-31 01:18:02,174 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: new RaftServerImpl for group-039BB00381B6:[] with ContainerStateMachine:uninitialized
dn3_1    | 2022-07-31 01:18:02,179 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn3_1    | 2022-07-31 01:18:02,179 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn3_1    | 2022-07-31 01:18:02,184 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn3_1    | 2022-07-31 01:18:02,187 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn3_1    | 2022-07-31 01:18:02,188 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn3_1    | 2022-07-31 01:18:02,188 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn3_1    | 2022-07-31 01:18:02,189 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn3_1    | 2022-07-31 01:18:02,194 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn3_1    | 2022-07-31 01:18:02,197 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn1_1    | 2022-07-31 01:18:00,822 [pool-42-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=8, votedFor=609e7f2d-9474-472f-937f-8fa0a0bbb327} from /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/current/raft-meta
dn1_1    | 2022-07-31 01:18:00,824 [pool-42-thread-1] INFO ratis.ContainerStateMachine: group-65A101075AF1: Setting the last applied index to (t:8, i:35)
dn1_1    | 2022-07-31 01:18:00,832 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1: set configuration 31: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-07-31 01:18:00,843 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn1_1    | 2022-07-31 01:18:00,844 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn1_1    | 2022-07-31 01:18:00,844 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn1_1    | 2022-07-31 01:18:00,845 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2022-07-31 01:18:00,852 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn1_1    | 2022-07-31 01:18:00,860 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2022-07-31 01:18:00,869 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn1_1    | 2022-07-31 01:18:00,885 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn1_1    | 2022-07-31 01:18:00,886 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: new 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1
dn1_1    | 2022-07-31 01:18:00,889 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn1_1    | 2022-07-31 01:18:00,890 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn1_1    | 2022-07-31 01:18:00,891 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2022-07-31 01:18:00,891 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn1_1    | 2022-07-31 01:18:00,891 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn1_1    | 2022-07-31 01:18:00,892 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn1_1    | 2022-07-31 01:18:00,911 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn1_1    | 2022-07-31 01:18:00,913 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn1_1    | 2022-07-31 01:18:00,915 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn1_1    | 2022-07-31 01:18:00,924 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn1_1    | 2022-07-31 01:18:00,941 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn1_1    | 2022-07-31 01:18:00,952 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1: set configuration 0: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-07-31 01:18:00,959 [pool-42-thread-1] INFO segmented.LogSegment: Successfully read 13 entries from segment file /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/current/log_0-12
dn1_1    | 2022-07-31 01:18:00,927 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5c3d4f05{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-15617152162793119128/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
dn1_1    | 2022-07-31 01:18:01,057 [main] INFO server.AbstractConnector: Started ServerConnector@3b41e1bf{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
dn1_1    | 2022-07-31 01:18:01,066 [main] INFO server.Server: Started @49294ms
dn1_1    | 2022-07-31 01:18:01,058 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1: set configuration 13: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-07-31 01:18:01,071 [pool-42-thread-1] INFO segmented.LogSegment: Successfully read 18 entries from segment file /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/current/log_13-30
dn1_1    | 2022-07-31 01:18:01,096 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1: set configuration 31: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-07-31 01:18:01,111 [pool-42-thread-1] INFO segmented.LogSegment: Successfully read 5 entries from segment file /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/current/log_inprogress_31
dn1_1    | 2022-07-31 01:18:01,112 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 35
dn1_1    | 2022-07-31 01:18:01,112 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 30
dn1_1    | 2022-07-31 01:18:01,111 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
dn1_1    | 2022-07-31 01:18:01,113 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
dn1_1    | 2022-07-31 01:18:01,121 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
dn1_1    | 2022-07-31 01:18:01,126 [pool-42-thread-1] INFO raftlog.RaftLog: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-SegmentedRaftLog: commitIndex: updateToMax old=35, new=34, updated? false
dn1_1    | 2022-07-31 01:18:01,126 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn1_1    | 2022-07-31 01:18:01,127 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn1_1    | 2022-07-31 01:18:01,128 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn1_1    | 2022-07-31 01:18:01,133 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn1_1    | 2022-07-31 01:18:01,134 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn1_1    | 2022-07-31 01:18:01,138 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn1_1    | 2022-07-31 01:18:01,161 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
dn1_1    | 2022-07-31 01:18:01,211 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn1_1    | 2022-07-31 01:18:01,212 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn1_1    | 2022-07-31 01:18:01,213 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn1_1    | 2022-07-31 01:18:01,214 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn1_1    | 2022-07-31 01:18:01,214 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn1_1    | 2022-07-31 01:18:01,411 [Datanode State Machine Daemon Thread] INFO upgrade.UpgradeFinalizer: Running pre-finalized state validations for unfinalized layout features.
dn1_1    | 2022-07-31 01:18:01,417 [Datanode State Machine Daemon Thread] INFO upgrade.UpgradeFinalizer: Running first upgrade commands for unfinalized layout features.
dn1_1    | 2022-07-31 01:18:01,474 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7b5a638] INFO util.JvmPauseMonitor: Starting JVM pause monitor
dn1_1    | 2022-07-31 01:18:01,869 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/10.9.0.20:9891
dn1_1    | 2022-07-31 01:18:01,935 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
dn1_1    | 2022-07-31 01:18:04,918 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn1_1    | 2022-07-31 01:18:04,922 [EndpointStateMachine task thread for recon/10.9.0.20:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/10.9.0.20:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn1_1    | 2022-07-31 01:18:05,919 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn1_1    | 2022-07-31 01:18:06,920 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn1_1    | 2022-07-31 01:18:07,921 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn1_1    | 2022-07-31 01:18:09,723 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
dn1_1    | 2022-07-31 01:18:09,729 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
dn1_1    | 2022-07-31 01:18:09,968 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 609e7f2d-9474-472f-937f-8fa0a0bbb327
dn1_1    | 2022-07-31 01:18:09,979 [EndpointStateMachine task thread for recon/10.9.0.20:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
dn1_1    | java.net.SocketTimeoutException: Call From b5a69c4cb320/10.9.0.15 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.15:47394 remote=recon/10.9.0.20:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
dn1_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
dn1_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
dn1_1    | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
dn1_1    | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
dn1_1    | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
dn1_1    | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
dn1_1    | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
dn1_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
dn1_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
dn1_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
dn1_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
dn1_1    | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
dn1_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
dn1_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
dn3_1    | 2022-07-31 01:18:02,197 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn3_1    | 2022-07-31 01:18:02,206 [pool-34-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/69ee0657-77f1-4021-b38b-039bb00381b6/in_use.lock acquired by nodename 6@6dca380edee9
dn3_1    | 2022-07-31 01:18:02,207 [pool-34-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=3, votedFor=3fc9f139-dd93-41e7-b235-52ce94d6fe3c} from /data/metadata/ratis/69ee0657-77f1-4021-b38b-039bb00381b6/current/raft-meta
dn3_1    | 2022-07-31 01:18:02,224 [pool-34-thread-1] INFO ratis.ContainerStateMachine: group-039BB00381B6: Setting the last applied index to (t:3, i:4)
dn3_1    | 2022-07-31 01:18:02,225 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6: set configuration 3: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-07-31 01:18:02,227 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn3_1    | 2022-07-31 01:18:02,228 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn3_1    | 2022-07-31 01:18:02,228 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn3_1    | 2022-07-31 01:18:02,228 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2022-07-31 01:18:02,231 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn3_1    | 2022-07-31 01:18:02,239 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2022-07-31 01:18:02,243 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn3_1    | 2022-07-31 01:18:02,243 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn3_1    | 2022-07-31 01:18:02,247 [pool-34-thread-1] INFO segmented.SegmentedRaftLogWorker: new 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/69ee0657-77f1-4021-b38b-039bb00381b6
dn3_1    | 2022-07-31 01:18:02,252 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn3_1    | 2022-07-31 01:18:02,252 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn3_1    | 2022-07-31 01:18:02,252 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2022-07-31 01:18:02,254 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn3_1    | 2022-07-31 01:18:02,254 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn3_1    | 2022-07-31 01:18:02,256 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn3_1    | 2022-07-31 01:18:02,256 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn3_1    | 2022-07-31 01:18:02,256 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn3_1    | 2022-07-31 01:18:02,257 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn3_1    | 2022-07-31 01:18:02,264 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn3_1    | 2022-07-31 01:18:02,267 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn3_1    | 2022-07-31 01:18:02,285 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6: set configuration 0: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-07-31 01:18:02,292 [pool-34-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/69ee0657-77f1-4021-b38b-039bb00381b6/current/log_0-0
dn3_1    | 2022-07-31 01:18:02,293 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6: set configuration 1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-07-31 01:18:02,303 [pool-34-thread-1] INFO segmented.LogSegment: Successfully read 2 entries from segment file /data/metadata/ratis/69ee0657-77f1-4021-b38b-039bb00381b6/current/log_1-2
dn3_1    | 2022-07-31 01:18:02,313 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6: set configuration 3: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-07-31 01:18:02,318 [pool-34-thread-1] INFO segmented.LogSegment: Successfully read 2 entries from segment file /data/metadata/ratis/69ee0657-77f1-4021-b38b-039bb00381b6/current/log_inprogress_3
dn3_1    | 2022-07-31 01:18:02,320 [pool-34-thread-1] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 4
dn3_1    | 2022-07-31 01:18:02,320 [pool-34-thread-1] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 2
dn3_1    | 2022-07-31 01:18:02,322 [pool-34-thread-1] INFO raftlog.RaftLog: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-SegmentedRaftLog: commitIndex: updateToMax old=4, new=3, updated? false
dn3_1    | 2022-07-31 01:18:02,323 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn3_1    | 2022-07-31 01:18:02,346 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn3_1    | 2022-07-31 01:18:02,346 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn3_1    | 2022-07-31 01:18:02,347 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn3_1    | 2022-07-31 01:18:02,349 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn3_1    | 2022-07-31 01:18:02,360 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn3_1    | 2022-07-31 01:18:02,373 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn3_1    | 2022-07-31 01:18:02,381 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn3_1    | 2022-07-31 01:18:02,381 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn3_1    | 2022-07-31 01:18:02,381 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn3_1    | 2022-07-31 01:18:02,381 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn3_1    | 2022-07-31 01:18:02,402 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: new RaftServerImpl for group-75041C4AA246:[] with ContainerStateMachine:uninitialized
dn3_1    | 2022-07-31 01:18:02,405 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn3_1    | 2022-07-31 01:18:02,405 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn3_1    | 2022-07-31 01:18:02,407 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn3_1    | 2022-07-31 01:18:02,407 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn3_1    | 2022-07-31 01:18:02,407 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn3_1    | 2022-07-31 01:18:02,408 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn3_1    | 2022-07-31 01:18:02,408 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn3_1    | 2022-07-31 01:18:02,408 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn3_1    | 2022-07-31 01:18:02,411 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn3_1    | 2022-07-31 01:18:02,412 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn3_1    | 2022-07-31 01:18:02,420 [pool-34-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/in_use.lock acquired by nodename 6@6dca380edee9
dn3_1    | 2022-07-31 01:18:02,423 [pool-34-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=9, votedFor=3fc9f139-dd93-41e7-b235-52ce94d6fe3c} from /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/current/raft-meta
dn3_1    | 2022-07-31 01:18:02,425 [pool-34-thread-1] INFO ratis.ContainerStateMachine: group-75041C4AA246: Setting the last applied index to (t:9, i:23)
dn3_1    | 2022-07-31 01:18:02,453 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246: set configuration 10: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn3_1    | 2022-07-31 01:18:02,454 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn3_1    | 2022-07-31 01:18:02,455 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn3_1    | 2022-07-31 01:18:02,455 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn3_1    | 2022-07-31 01:18:02,455 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2022-07-31 01:18:02,455 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn3_1    | 2022-07-31 01:18:02,460 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2022-07-31 01:18:02,466 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn3_1    | 2022-07-31 01:18:02,466 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn3_1    | 2022-07-31 01:18:02,466 [pool-34-thread-1] INFO segmented.SegmentedRaftLogWorker: new 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246
dn3_1    | 2022-07-31 01:18:02,467 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn3_1    | 2022-07-31 01:18:02,467 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn3_1    | 2022-07-31 01:18:02,467 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2022-07-31 01:18:02,467 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn3_1    | 2022-07-31 01:18:02,468 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn3_1    | 2022-07-31 01:18:02,472 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn3_1    | 2022-07-31 01:18:02,472 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn3_1    | 2022-07-31 01:18:02,472 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn3_1    | 2022-07-31 01:18:02,484 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn3_1    | 2022-07-31 01:18:02,487 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn3_1    | 2022-07-31 01:18:02,489 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn3_1    | 2022-07-31 01:18:02,490 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246: set configuration 0: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn3_1    | 2022-07-31 01:18:02,493 [pool-34-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/current/log_0-0
dn3_1    | 2022-07-31 01:18:02,494 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246: set configuration 1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn3_1    | 2022-07-31 01:18:02,505 [pool-34-thread-1] INFO segmented.LogSegment: Successfully read 9 entries from segment file /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/current/log_1-9
dn3_1    | 2022-07-31 01:18:02,515 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246: set configuration 10: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn3_1    | 2022-07-31 01:18:02,539 [pool-34-thread-1] INFO segmented.LogSegment: Successfully read 14 entries from segment file /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/current/log_inprogress_10
dn3_1    | 2022-07-31 01:18:02,543 [pool-34-thread-1] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 23
dn1_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
dn1_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn1_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn1_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn1_1    | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.15:47394 remote=recon/10.9.0.20:9891]
dn1_1    | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
dn1_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
dn1_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
dn1_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
dn1_1    | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
dn1_1    | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
dn1_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn1_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn1_1    | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
dn1_1    | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
dn1_1    | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
dn1_1    | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
dn1_1    | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
dn1_1    | 2022-07-31 01:18:10,113 [609e7f2d-9474-472f-937f-8fa0a0bbb327-impl-thread1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58: start as a follower, conf=3: [609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-07-31 01:18:10,156 [609e7f2d-9474-472f-937f-8fa0a0bbb327-impl-thread1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58: changes role from      null to FOLLOWER at term 3 for startAsFollower
dn1_1    | 2022-07-31 01:18:10,386 [609e7f2d-9474-472f-937f-8fa0a0bbb327-impl-thread3] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1: start as a follower, conf=31: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-07-31 01:18:10,397 [609e7f2d-9474-472f-937f-8fa0a0bbb327-impl-thread3] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1: changes role from      null to FOLLOWER at term 8 for startAsFollower
dn1_1    | 2022-07-31 01:18:10,402 [609e7f2d-9474-472f-937f-8fa0a0bbb327-impl-thread1] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-FollowerState
dn1_1    | 2022-07-31 01:18:10,419 [609e7f2d-9474-472f-937f-8fa0a0bbb327-impl-thread2] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246: start as a follower, conf=10: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-07-31 01:18:10,440 [609e7f2d-9474-472f-937f-8fa0a0bbb327-impl-thread2] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246: changes role from      null to FOLLOWER at term 9 for startAsFollower
dn1_1    | 2022-07-31 01:18:10,440 [609e7f2d-9474-472f-937f-8fa0a0bbb327-impl-thread2] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-FollowerState
dn1_1    | 2022-07-31 01:18:10,441 [609e7f2d-9474-472f-937f-8fa0a0bbb327-impl-thread3] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-FollowerState
dn1_1    | 2022-07-31 01:18:10,470 [609e7f2d-9474-472f-937f-8fa0a0bbb327-impl-thread2] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-75041C4AA246,id=609e7f2d-9474-472f-937f-8fa0a0bbb327
dn1_1    | 2022-07-31 01:18:10,470 [609e7f2d-9474-472f-937f-8fa0a0bbb327-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FFC093016E58,id=609e7f2d-9474-472f-937f-8fa0a0bbb327
dn1_1    | 2022-07-31 01:18:10,488 [609e7f2d-9474-472f-937f-8fa0a0bbb327-impl-thread3] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-65A101075AF1,id=609e7f2d-9474-472f-937f-8fa0a0bbb327
dn1_1    | 2022-07-31 01:18:10,536 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.RaftServer: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start RPC server
dn1_1    | 2022-07-31 01:18:10,558 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 609e7f2d-9474-472f-937f-8fa0a0bbb327: GrpcService started, listening on 9856
dn1_1    | 2022-07-31 01:18:10,562 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 609e7f2d-9474-472f-937f-8fa0a0bbb327: GrpcService started, listening on 9857
dn1_1    | 2022-07-31 01:18:10,567 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 609e7f2d-9474-472f-937f-8fa0a0bbb327: GrpcService started, listening on 9858
dn1_1    | 2022-07-31 01:18:10,601 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 609e7f2d-9474-472f-937f-8fa0a0bbb327 is started using port 9858 for RATIS
dn1_1    | 2022-07-31 01:18:10,601 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 609e7f2d-9474-472f-937f-8fa0a0bbb327 is started using port 9857 for RATIS_ADMIN
dn1_1    | 2022-07-31 01:18:10,601 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 609e7f2d-9474-472f-937f-8fa0a0bbb327 is started using port 9856 for RATIS_SERVER
dn1_1    | 2022-07-31 01:18:10,647 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$487/0x0000000840571840@6193ed50] INFO util.JvmPauseMonitor: JvmPauseMonitor-609e7f2d-9474-472f-937f-8fa0a0bbb327: Started
dn1_1    | 2022-07-31 01:18:15,462 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-FollowerState] INFO impl.FollowerState: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5060675093ns, electionTimeout:5000ms
dn1_1    | 2022-07-31 01:18:15,464 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-FollowerState] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-FollowerState
dn1_1    | 2022-07-31 01:18:15,464 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-FollowerState] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
dn1_1    | 2022-07-31 01:18:15,467 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn1_1    | 2022-07-31 01:18:15,467 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-FollowerState] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-LeaderElection1
dn1_1    | 2022-07-31 01:18:15,574 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-LeaderElection1] INFO impl.LeaderElection: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-LeaderElection1 ELECTION round 0: submit vote requests at term 4 for 3: [609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-07-31 01:18:15,583 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-FollowerState] INFO impl.FollowerState: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5142481569ns, electionTimeout:5121ms
dn1_1    | 2022-07-31 01:18:15,626 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-FollowerState] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-FollowerState
dn1_1    | 2022-07-31 01:18:15,627 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-FollowerState] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246: changes role from  FOLLOWER to CANDIDATE at term 9 for changeToCandidate
dn1_1    | 2022-07-31 01:18:15,627 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn1_1    | 2022-07-31 01:18:15,627 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-FollowerState] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection2
dn1_1    | 2022-07-31 01:18:15,658 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-LeaderElection1] INFO impl.LeaderElection: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-LeaderElection1 ELECTION round 0: result PASSED (term=4)
dn1_1    | 2022-07-31 01:18:15,659 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-LeaderElection1] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-LeaderElection1
dn1_1    | 2022-07-31 01:18:15,667 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-LeaderElection1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58: changes role from CANDIDATE to LEADER at term 4 for changeToLeader
dn1_1    | 2022-07-31 01:18:15,664 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection2] INFO impl.LeaderElection: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection2 ELECTION round 0: submit vote requests at term 10 for 10: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-07-31 01:18:15,701 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-FollowerState] INFO impl.FollowerState: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5259362362ns, electionTimeout:5173ms
dn1_1    | 2022-07-31 01:18:15,701 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-FollowerState] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-FollowerState
dn1_1    | 2022-07-31 01:18:15,701 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-FollowerState] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1: changes role from  FOLLOWER to CANDIDATE at term 8 for changeToCandidate
dn1_1    | 2022-07-31 01:18:15,702 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn1_1    | 2022-07-31 01:18:15,702 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-FollowerState] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection3
dn1_1    | 2022-07-31 01:18:15,701 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-FFC093016E58 with new leaderId: 609e7f2d-9474-472f-937f-8fa0a0bbb327
dn1_1    | 2022-07-31 01:18:15,743 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-LeaderElection1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58: change Leader from null to 609e7f2d-9474-472f-937f-8fa0a0bbb327 at term 4 for becomeLeader, leader elected after 18916ms
dn1_1    | 2022-07-31 01:18:15,885 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection3] INFO impl.LeaderElection: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection3 ELECTION round 0: submit vote requests at term 9 for 31: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-07-31 01:18:15,888 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn1_1    | 2022-07-31 01:18:16,027 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn1_1    | 2022-07-31 01:18:16,032 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn1_1    | 2022-07-31 01:18:16,134 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn1_1    | 2022-07-31 01:18:16,134 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn1_1    | 2022-07-31 01:18:16,177 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn1_1    | 2022-07-31 01:18:16,262 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn1_1    | 2022-07-31 01:18:16,263 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn1_1    | 2022-07-31 01:18:16,323 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-LeaderElection1] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-LeaderStateImpl
dn1_1    | 2022-07-31 01:18:16,436 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-SegmentedRaftLogWorker: Rolling segment log-3_4 to index:4
dn1_1    | 2022-07-31 01:18:16,787 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-LeaderElection1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58: set configuration 5: [609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-07-31 01:18:16,810 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/c57ff3c1-98cc-4640-a639-ffc093016e58/current/log_inprogress_3 to /data/metadata/ratis/c57ff3c1-98cc-4640-a639-ffc093016e58/current/log_3-4
dn1_1    | 2022-07-31 01:18:16,854 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/c57ff3c1-98cc-4640-a639-ffc093016e58/current/log_inprogress_5
dn1_1    | 2022-07-31 01:18:19,869 [grpc-default-executor-2] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1: receive requestVote(ELECTION, 11cba143-91f8-47cb-8422-c32a1e2d51df, group-65A101075AF1, 9, (t:8, i:35))
dn1_1    | 2022-07-31 01:18:19,870 [grpc-default-executor-2] INFO impl.VoteContext: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-CANDIDATE: reject ELECTION from 11cba143-91f8-47cb-8422-c32a1e2d51df: already has voted for 609e7f2d-9474-472f-937f-8fa0a0bbb327 at current term 9
dn1_1    | 2022-07-31 01:18:19,903 [grpc-default-executor-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246: receive requestVote(ELECTION, 11cba143-91f8-47cb-8422-c32a1e2d51df, group-75041C4AA246, 10, (t:9, i:23))
dn3_1    | 2022-07-31 01:18:02,546 [pool-34-thread-1] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 9
dn3_1    | 2022-07-31 01:18:02,547 [pool-34-thread-1] INFO raftlog.RaftLog: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-SegmentedRaftLog: commitIndex: updateToMax old=23, new=21, updated? false
dn3_1    | 2022-07-31 01:18:02,548 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn3_1    | 2022-07-31 01:18:02,548 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn3_1    | 2022-07-31 01:18:02,549 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn3_1    | 2022-07-31 01:18:02,549 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn3_1    | 2022-07-31 01:18:02,549 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn3_1    | 2022-07-31 01:18:02,552 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn3_1    | 2022-07-31 01:18:02,566 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn3_1    | 2022-07-31 01:18:02,573 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn3_1    | 2022-07-31 01:18:02,573 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn3_1    | 2022-07-31 01:18:02,573 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn3_1    | 2022-07-31 01:18:02,573 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn3_1    | 2022-07-31 01:18:02,621 [Datanode State Machine Task Thread - 1] WARN statemachine.SCMConnectionManager: Trying to add an existing SCM Machine to Machines group. Ignoring the request.
dn3_1    | 2022-07-31 01:18:02,644 [Datanode State Machine Task Thread - 1] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/10.9.0.20:9891
dn3_1    | 2022-07-31 01:18:02,654 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/10.9.0.20:9891
dn3_1    | 2022-07-31 01:18:02,668 [Datanode State Machine Task Thread - 0] WARN statemachine.SCMConnectionManager: Trying to add an existing SCM Machine to Machines group. Ignoring the request.
dn3_1    | 2022-07-31 01:18:02,683 [Datanode State Machine Task Thread - 1] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
dn3_1    | 2022-07-31 01:18:02,701 [Datanode State Machine Task Thread - 1] WARN statemachine.SCMConnectionManager: Trying to add an existing SCM Machine to Machines group. Ignoring the request.
dn3_1    | 2022-07-31 01:18:02,701 [Datanode State Machine Task Thread - 1] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/10.9.0.20:9891
dn3_1    | 2022-07-31 01:18:02,701 [Datanode State Machine Task Thread - 1] WARN statemachine.SCMConnectionManager: Trying to add an existing SCM Machine to Machines group. Ignoring the request.
dn3_1    | 2022-07-31 01:18:02,704 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
dn3_1    | 2022-07-31 01:18:02,726 [Datanode State Machine Task Thread - 1] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
dn3_1    | 2022-07-31 01:18:05,866 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn3_1    | 2022-07-31 01:18:06,867 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn3_1    | 2022-07-31 01:18:07,868 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn3_1    | 2022-07-31 01:18:08,458 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
dn3_1    | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:660)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:298)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:493)
dn3_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn3_1    | Caused by: java.util.concurrent.TimeoutException
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn3_1    | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn3_1    | 	... 1 more
dn3_1    | 2022-07-31 01:18:09,716 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
dn3_1    | 2022-07-31 01:18:09,720 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
dn3_1    | 2022-07-31 01:18:09,932 [EndpointStateMachine task thread for recon/10.9.0.20:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
dn3_1    | java.net.SocketTimeoutException: Call From 6dca380edee9/10.9.0.17 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.17:59242 remote=recon/10.9.0.20:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
dn3_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
dn3_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
dn3_1    | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
dn3_1    | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
dn3_1    | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
dn3_1    | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
dn3_1    | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
dn3_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
dn3_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
dn3_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
dn3_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
dn3_1    | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
dn3_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
dn3_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn3_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn3_1    | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.17:59242 remote=recon/10.9.0.20:9891]
dn3_1    | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
dn3_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
dn3_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
dn3_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
dn3_1    | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
dn3_1    | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
dn3_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn3_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn3_1    | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
dn3_1    | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
dn3_1    | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
dn3_1    | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
dn3_1    | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
dn3_1    | 2022-07-31 01:18:10,136 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 3fc9f139-dd93-41e7-b235-52ce94d6fe3c
dn3_1    | 2022-07-31 01:18:10,459 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c-impl-thread2] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610: start as a follower, conf=3: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-07-31 01:18:10,476 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c-impl-thread2] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610: changes role from      null to FOLLOWER at term 11 for startAsFollower
dn3_1    | 2022-07-31 01:18:10,482 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c-impl-thread2] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-FollowerState
dn3_1    | 2022-07-31 01:18:10,459 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c-impl-thread3] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6: start as a follower, conf=3: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-07-31 01:18:10,466 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c-impl-thread1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246: start as a follower, conf=10: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn3_1    | 2022-07-31 01:18:10,570 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c-impl-thread1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246: changes role from      null to FOLLOWER at term 9 for startAsFollower
dn3_1    | 2022-07-31 01:18:10,571 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c-impl-thread1] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-FollowerState
dn3_1    | 2022-07-31 01:18:10,574 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-75041C4AA246,id=3fc9f139-dd93-41e7-b235-52ce94d6fe3c
dn3_1    | 2022-07-31 01:18:10,603 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c-impl-thread3] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6: changes role from      null to FOLLOWER at term 3 for startAsFollower
dn3_1    | 2022-07-31 01:18:10,653 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c-impl-thread3] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-FollowerState
dn3_1    | 2022-07-31 01:18:10,652 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c-impl-thread2] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7BB2A1276610,id=3fc9f139-dd93-41e7-b235-52ce94d6fe3c
dn3_1    | 2022-07-31 01:18:10,653 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c-impl-thread3] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-039BB00381B6,id=3fc9f139-dd93-41e7-b235-52ce94d6fe3c
dn3_1    | 2022-07-31 01:18:10,678 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.RaftServer: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start RPC server
dn3_1    | 2022-07-31 01:18:10,706 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: GrpcService started, listening on 9856
dn3_1    | 2022-07-31 01:18:10,708 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: GrpcService started, listening on 9857
dn3_1    | 2022-07-31 01:18:10,722 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: GrpcService started, listening on 9858
dn3_1    | 2022-07-31 01:18:10,745 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 3fc9f139-dd93-41e7-b235-52ce94d6fe3c is started using port 9858 for RATIS
dn3_1    | 2022-07-31 01:18:10,746 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 3fc9f139-dd93-41e7-b235-52ce94d6fe3c is started using port 9857 for RATIS_ADMIN
dn2_1    | 2022-07-31 01:18:04,398 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: new 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246
dn2_1    | 2022-07-31 01:18:04,398 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn2_1    | 2022-07-31 01:18:04,398 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn2_1    | 2022-07-31 01:18:04,399 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2022-07-31 01:18:04,399 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn2_1    | 2022-07-31 01:18:04,403 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn2_1    | 2022-07-31 01:18:04,405 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn2_1    | 2022-07-31 01:18:04,406 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn2_1    | 2022-07-31 01:18:04,406 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn2_1    | 2022-07-31 01:18:04,408 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn2_1    | 2022-07-31 01:18:04,418 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn2_1    | 2022-07-31 01:18:04,425 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn2_1    | 2022-07-31 01:18:04,436 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246: set configuration 0: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-07-31 01:18:04,436 [pool-42-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/current/log_0-0
dn2_1    | 2022-07-31 01:18:04,437 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246: set configuration 1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-07-31 01:18:04,471 [pool-42-thread-1] INFO segmented.LogSegment: Successfully read 9 entries from segment file /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/current/log_1-9
dn2_1    | 2022-07-31 01:18:04,496 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246: set configuration 10: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-07-31 01:18:04,499 [pool-42-thread-1] INFO segmented.LogSegment: Successfully read 14 entries from segment file /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/current/log_inprogress_10
dn2_1    | 2022-07-31 01:18:04,501 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 23
dn2_1    | 2022-07-31 01:18:04,502 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 9
dn2_1    | 2022-07-31 01:18:04,533 [pool-42-thread-1] INFO raftlog.RaftLog: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-SegmentedRaftLog: commitIndex: updateToMax old=23, new=21, updated? false
dn2_1    | 2022-07-31 01:18:04,533 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn2_1    | 2022-07-31 01:18:04,534 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn2_1    | 2022-07-31 01:18:04,534 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn2_1    | 2022-07-31 01:18:04,534 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn2_1    | 2022-07-31 01:18:04,534 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn2_1    | 2022-07-31 01:18:04,534 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn2_1    | 2022-07-31 01:18:04,556 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn2_1    | 2022-07-31 01:18:04,557 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn2_1    | 2022-07-31 01:18:04,557 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn2_1    | 2022-07-31 01:18:04,558 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn2_1    | 2022-07-31 01:18:04,564 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn2_1    | 2022-07-31 01:18:04,578 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df: new RaftServerImpl for group-65A101075AF1:[] with ContainerStateMachine:uninitialized
dn2_1    | 2022-07-31 01:18:04,588 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn2_1    | 2022-07-31 01:18:04,592 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn2_1    | 2022-07-31 01:18:04,602 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn2_1    | 2022-07-31 01:18:04,608 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn2_1    | 2022-07-31 01:18:04,609 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn2_1    | 2022-07-31 01:18:04,609 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn2_1    | 2022-07-31 01:18:04,609 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn2_1    | 2022-07-31 01:18:04,611 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn2_1    | 2022-07-31 01:18:04,613 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn2_1    | 2022-07-31 01:18:04,613 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn2_1    | 2022-07-31 01:18:04,615 [pool-42-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/in_use.lock acquired by nodename 8@c5b89a034b5d
dn1_1    | 2022-07-31 01:18:19,904 [grpc-default-executor-1] INFO impl.VoteContext: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-CANDIDATE: reject ELECTION from 11cba143-91f8-47cb-8422-c32a1e2d51df: already has voted for 609e7f2d-9474-472f-937f-8fa0a0bbb327 at current term 10
dn1_1    | 2022-07-31 01:18:19,907 [grpc-default-executor-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246 replies to ELECTION vote request: 11cba143-91f8-47cb-8422-c32a1e2d51df<-609e7f2d-9474-472f-937f-8fa0a0bbb327#0:FAIL-t10. Peer's state: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246:t10, leader=null, voted=609e7f2d-9474-472f-937f-8fa0a0bbb327, raftlog=609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-SegmentedRaftLog:OPENED:c23, conf=10: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-07-31 01:18:19,914 [grpc-default-executor-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246: receive requestVote(ELECTION, 3fc9f139-dd93-41e7-b235-52ce94d6fe3c, group-75041C4AA246, 10, (t:9, i:23))
dn1_1    | 2022-07-31 01:18:19,919 [grpc-default-executor-1] INFO impl.VoteContext: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-CANDIDATE: reject ELECTION from 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: already has voted for 609e7f2d-9474-472f-937f-8fa0a0bbb327 at current term 10
dn1_1    | 2022-07-31 01:18:19,921 [grpc-default-executor-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246 replies to ELECTION vote request: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c<-609e7f2d-9474-472f-937f-8fa0a0bbb327#0:FAIL-t10. Peer's state: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246:t10, leader=null, voted=609e7f2d-9474-472f-937f-8fa0a0bbb327, raftlog=609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-SegmentedRaftLog:OPENED:c23, conf=10: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-07-31 01:18:19,975 [grpc-default-executor-2] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1 replies to ELECTION vote request: 11cba143-91f8-47cb-8422-c32a1e2d51df<-609e7f2d-9474-472f-937f-8fa0a0bbb327#0:FAIL-t9. Peer's state: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1:t9, leader=null, voted=609e7f2d-9474-472f-937f-8fa0a0bbb327, raftlog=609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-SegmentedRaftLog:OPENED:c35, conf=31: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-07-31 01:18:20,033 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection2] INFO impl.LeaderElection: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection2: ELECTION REJECTED received 1 response(s) and 0 exception(s):
dn1_1    | 2022-07-31 01:18:20,037 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection2] INFO impl.LeaderElection:   Response 0: 609e7f2d-9474-472f-937f-8fa0a0bbb327<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:FAIL-t10
dn1_1    | 2022-07-31 01:18:20,037 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection2] INFO impl.LeaderElection: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection2 ELECTION round 0: result REJECTED
dn1_1    | 2022-07-31 01:18:20,042 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection2] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246: changes role from CANDIDATE to FOLLOWER at term 10 for REJECTED
dn1_1    | 2022-07-31 01:18:20,046 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection2] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection2
dn1_1    | 2022-07-31 01:18:20,046 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection2] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-FollowerState
dn1_1    | 2022-07-31 01:18:20,160 [grpc-default-executor-2] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1: receive requestVote(ELECTION, 52aca038-7576-46a0-9ccd-b8aed29078e2, group-65A101075AF1, 9, (t:8, i:35))
dn1_1    | 2022-07-31 01:18:20,169 [grpc-default-executor-2] INFO impl.VoteContext: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-CANDIDATE: reject ELECTION from 52aca038-7576-46a0-9ccd-b8aed29078e2: already has voted for 609e7f2d-9474-472f-937f-8fa0a0bbb327 at current term 9
dn1_1    | 2022-07-31 01:18:20,169 [grpc-default-executor-2] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1 replies to ELECTION vote request: 52aca038-7576-46a0-9ccd-b8aed29078e2<-609e7f2d-9474-472f-937f-8fa0a0bbb327#0:FAIL-t9. Peer's state: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1:t9, leader=null, voted=609e7f2d-9474-472f-937f-8fa0a0bbb327, raftlog=609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-SegmentedRaftLog:OPENED:c35, conf=31: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-07-31 01:18:20,422 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection3] INFO impl.LeaderElection: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection3: ELECTION REJECTED received 2 response(s) and 0 exception(s):
dn1_1    | 2022-07-31 01:18:20,423 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection3] INFO impl.LeaderElection:   Response 0: 609e7f2d-9474-472f-937f-8fa0a0bbb327<-11cba143-91f8-47cb-8422-c32a1e2d51df#0:FAIL-t9
dn1_1    | 2022-07-31 01:18:20,423 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection3] INFO impl.LeaderElection:   Response 1: 609e7f2d-9474-472f-937f-8fa0a0bbb327<-52aca038-7576-46a0-9ccd-b8aed29078e2#0:FAIL-t9
dn1_1    | 2022-07-31 01:18:20,423 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection3] INFO impl.LeaderElection: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection3 ELECTION round 0: result REJECTED
dn1_1    | 2022-07-31 01:18:20,424 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection3] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1: changes role from CANDIDATE to FOLLOWER at term 9 for REJECTED
dn1_1    | 2022-07-31 01:18:20,424 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection3] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection3
dn1_1    | 2022-07-31 01:18:20,424 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection3] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-FollowerState
dn2_1    | 2022-07-31 01:18:04,628 [pool-42-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=8, votedFor=609e7f2d-9474-472f-937f-8fa0a0bbb327} from /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/current/raft-meta
dn2_1    | 2022-07-31 01:18:04,629 [pool-42-thread-1] INFO ratis.ContainerStateMachine: group-65A101075AF1: Setting the last applied index to (t:8, i:35)
dn2_1    | 2022-07-31 01:18:04,638 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1: set configuration 31: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-07-31 01:18:04,641 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn2_1    | 2022-07-31 01:18:04,641 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn2_1    | 2022-07-31 01:18:04,645 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn2_1    | 2022-07-31 01:18:04,645 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2022-07-31 01:18:04,646 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn2_1    | 2022-07-31 01:18:04,648 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2022-07-31 01:18:04,667 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn2_1    | 2022-07-31 01:18:04,668 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn2_1    | 2022-07-31 01:18:04,668 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: new 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1
dn2_1    | 2022-07-31 01:18:04,669 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn2_1    | 2022-07-31 01:18:04,669 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn2_1    | 2022-07-31 01:18:04,669 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2022-07-31 01:18:04,670 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn2_1    | 2022-07-31 01:18:04,670 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn2_1    | 2022-07-31 01:18:04,671 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn2_1    | 2022-07-31 01:18:04,680 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn2_1    | 2022-07-31 01:18:04,680 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn2_1    | 2022-07-31 01:18:04,682 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn2_1    | 2022-07-31 01:18:04,686 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn2_1    | 2022-07-31 01:18:04,703 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn2_1    | 2022-07-31 01:18:04,723 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1: set configuration 0: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-07-31 01:18:04,745 [pool-42-thread-1] INFO segmented.LogSegment: Successfully read 13 entries from segment file /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/current/log_0-12
dn2_1    | 2022-07-31 01:18:04,751 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1: set configuration 13: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-07-31 01:18:04,774 [pool-42-thread-1] INFO segmented.LogSegment: Successfully read 18 entries from segment file /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/current/log_13-30
dn2_1    | 2022-07-31 01:18:04,793 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1: set configuration 31: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-07-31 01:18:04,797 [pool-42-thread-1] INFO segmented.LogSegment: Successfully read 5 entries from segment file /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/current/log_inprogress_31
dn2_1    | 2022-07-31 01:18:04,797 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 35
dn2_1    | 2022-07-31 01:18:04,798 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 30
dn2_1    | 2022-07-31 01:18:04,803 [pool-42-thread-1] INFO raftlog.RaftLog: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-SegmentedRaftLog: commitIndex: updateToMax old=35, new=34, updated? false
dn2_1    | 2022-07-31 01:18:04,804 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn2_1    | 2022-07-31 01:18:04,805 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn2_1    | 2022-07-31 01:18:04,805 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn2_1    | 2022-07-31 01:18:04,805 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn2_1    | 2022-07-31 01:18:04,805 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn2_1    | 2022-07-31 01:18:04,809 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn2_1    | 2022-07-31 01:18:04,810 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn2_1    | 2022-07-31 01:18:04,817 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn1_1    | 2022-07-31 01:18:25,081 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-FollowerState] INFO impl.FollowerState: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5034488181ns, electionTimeout:5013ms
dn1_1    | 2022-07-31 01:18:25,081 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-FollowerState] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-FollowerState
dn1_1    | 2022-07-31 01:18:25,082 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-FollowerState] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246: changes role from  FOLLOWER to CANDIDATE at term 10 for changeToCandidate
dn1_1    | 2022-07-31 01:18:25,082 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn1_1    | 2022-07-31 01:18:25,082 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-FollowerState] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection4
dn1_1    | 2022-07-31 01:18:25,093 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection4] INFO impl.LeaderElection: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection4 ELECTION round 0: submit vote requests at term 11 for 10: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-07-31 01:18:25,128 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection4] INFO impl.LeaderElection: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection4: ELECTION REJECTED received 1 response(s) and 0 exception(s):
dn1_1    | 2022-07-31 01:18:25,129 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection4] INFO impl.LeaderElection:   Response 0: 609e7f2d-9474-472f-937f-8fa0a0bbb327<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:FAIL-t11
dn1_1    | 2022-07-31 01:18:25,131 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection4] INFO impl.LeaderElection: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection4 ELECTION round 0: result REJECTED
dn1_1    | 2022-07-31 01:18:25,133 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection4] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246: changes role from CANDIDATE to FOLLOWER at term 11 for REJECTED
dn1_1    | 2022-07-31 01:18:25,137 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection4] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection4
dn1_1    | 2022-07-31 01:18:25,137 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection4] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-FollowerState
dn1_1    | 2022-07-31 01:18:25,307 [grpc-default-executor-2] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1: receive requestVote(ELECTION, 11cba143-91f8-47cb-8422-c32a1e2d51df, group-65A101075AF1, 10, (t:8, i:35))
dn1_1    | 2022-07-31 01:18:25,308 [grpc-default-executor-2] INFO impl.VoteContext: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-FOLLOWER: reject ELECTION from 11cba143-91f8-47cb-8422-c32a1e2d51df: our priority 1 > candidate's priority 0
dn1_1    | 2022-07-31 01:18:25,309 [grpc-default-executor-2] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1: changes role from  FOLLOWER to FOLLOWER at term 10 for candidate:11cba143-91f8-47cb-8422-c32a1e2d51df
dn1_1    | 2022-07-31 01:18:25,309 [grpc-default-executor-2] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-FollowerState
dn1_1    | 2022-07-31 01:18:25,310 [grpc-default-executor-2] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-FollowerState
dn1_1    | 2022-07-31 01:18:25,310 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-FollowerState] INFO impl.FollowerState: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-FollowerState was interrupted
dn1_1    | 2022-07-31 01:18:25,322 [grpc-default-executor-2] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1 replies to ELECTION vote request: 11cba143-91f8-47cb-8422-c32a1e2d51df<-609e7f2d-9474-472f-937f-8fa0a0bbb327#0:FAIL-t10. Peer's state: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1:t10, leader=null, voted=null, raftlog=609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-SegmentedRaftLog:OPENED:c35, conf=31: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-07-31 01:18:30,219 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-FollowerState] INFO impl.FollowerState: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5082072185ns, electionTimeout:5064ms
dn1_1    | 2022-07-31 01:18:30,219 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-FollowerState] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-FollowerState
dn1_1    | 2022-07-31 01:18:30,219 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-FollowerState] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246: changes role from  FOLLOWER to CANDIDATE at term 11 for changeToCandidate
dn1_1    | 2022-07-31 01:18:30,220 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn1_1    | 2022-07-31 01:18:30,220 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-FollowerState] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection5
dn1_1    | 2022-07-31 01:18:30,223 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection5] INFO impl.LeaderElection: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection5 ELECTION round 0: submit vote requests at term 12 for 10: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-07-31 01:18:30,249 [grpc-default-executor-2] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246: receive requestVote(ELECTION, 3fc9f139-dd93-41e7-b235-52ce94d6fe3c, group-75041C4AA246, 12, (t:9, i:23))
dn1_1    | 2022-07-31 01:18:30,250 [grpc-default-executor-2] INFO impl.VoteContext: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-CANDIDATE: reject ELECTION from 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: already has voted for 609e7f2d-9474-472f-937f-8fa0a0bbb327 at current term 12
dn3_1    | 2022-07-31 01:18:10,746 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 3fc9f139-dd93-41e7-b235-52ce94d6fe3c is started using port 9856 for RATIS_SERVER
dn3_1    | 2022-07-31 01:18:10,760 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$487/0x0000000840571440@7ae28060] INFO util.JvmPauseMonitor: JvmPauseMonitor-3fc9f139-dd93-41e7-b235-52ce94d6fe3c: Started
dn3_1    | 2022-07-31 01:18:15,635 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-FollowerState] INFO impl.FollowerState: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5064464776ns, electionTimeout:5042ms
dn3_1    | 2022-07-31 01:18:15,637 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-FollowerState] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: shutdown 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-FollowerState
dn3_1    | 2022-07-31 01:18:15,637 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-FollowerState] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246: changes role from  FOLLOWER to CANDIDATE at term 9 for changeToCandidate
dn3_1    | 2022-07-31 01:18:15,639 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn3_1    | 2022-07-31 01:18:15,640 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-FollowerState] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection1
dn3_1    | 2022-07-31 01:18:15,679 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-FollowerState] INFO impl.FollowerState: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5197336802ns, electionTimeout:5087ms
dn3_1    | 2022-07-31 01:18:15,734 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-FollowerState] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: shutdown 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-FollowerState
dn3_1    | 2022-07-31 01:18:15,734 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-FollowerState] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610: changes role from  FOLLOWER to CANDIDATE at term 11 for changeToCandidate
dn3_1    | 2022-07-31 01:18:15,734 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn3_1    | 2022-07-31 01:18:15,737 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-FollowerState] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-LeaderElection2
dn3_1    | 2022-07-31 01:18:15,830 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection1] INFO impl.LeaderElection: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection1 ELECTION round 0: submit vote requests at term 10 for 10: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn3_1    | 2022-07-31 01:18:15,832 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-LeaderElection2] INFO impl.LeaderElection: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-LeaderElection2 ELECTION round 0: submit vote requests at term 12 for 3: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-07-31 01:18:15,837 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-FollowerState] INFO impl.FollowerState: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5184179915ns, electionTimeout:5180ms
dn3_1    | 2022-07-31 01:18:15,865 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-FollowerState] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: shutdown 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-FollowerState
dn3_1    | 2022-07-31 01:18:15,865 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-FollowerState] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
dn3_1    | 2022-07-31 01:18:15,865 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn3_1    | 2022-07-31 01:18:15,865 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-FollowerState] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-LeaderElection3
dn3_1    | 2022-07-31 01:18:15,908 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-LeaderElection3] INFO impl.LeaderElection: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-LeaderElection3 ELECTION round 0: submit vote requests at term 4 for 3: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-07-31 01:18:15,914 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-LeaderElection3] INFO impl.LeaderElection: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-LeaderElection3 ELECTION round 0: result PASSED (term=4)
dn3_1    | 2022-07-31 01:18:15,916 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-LeaderElection3] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: shutdown 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-LeaderElection3
dn3_1    | 2022-07-31 01:18:15,917 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-LeaderElection3] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6: changes role from CANDIDATE to LEADER at term 4 for changeToLeader
dn3_1    | 2022-07-31 01:18:15,918 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-039BB00381B6 with new leaderId: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c
dn3_1    | 2022-07-31 01:18:15,921 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-LeaderElection3] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6: change Leader from null to 3fc9f139-dd93-41e7-b235-52ce94d6fe3c at term 4 for becomeLeader, leader elected after 13691ms
dn3_1    | 2022-07-31 01:18:16,045 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn3_1    | 2022-07-31 01:18:16,282 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn3_1    | 2022-07-31 01:18:16,283 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn3_1    | 2022-07-31 01:18:16,299 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn3_1    | 2022-07-31 01:18:16,376 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn3_1    | 2022-07-31 01:18:16,381 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn3_1    | 2022-07-31 01:18:16,531 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn3_1    | 2022-07-31 01:18:16,677 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn3_1    | 2022-07-31 01:18:16,739 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-LeaderElection3] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-LeaderStateImpl
dn3_1    | 2022-07-31 01:18:16,832 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-SegmentedRaftLogWorker: Rolling segment log-3_4 to index:4
dn3_1    | 2022-07-31 01:18:17,004 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/69ee0657-77f1-4021-b38b-039bb00381b6/current/log_inprogress_3 to /data/metadata/ratis/69ee0657-77f1-4021-b38b-039bb00381b6/current/log_3-4
dn3_1    | 2022-07-31 01:18:17,040 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-LeaderElection3] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6: set configuration 5: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-07-31 01:18:17,125 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/69ee0657-77f1-4021-b38b-039bb00381b6/current/log_inprogress_5
dn3_1    | 2022-07-31 01:18:17,998 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$487/0x0000000840571440@7ae28060] WARN util.JvmPauseMonitor: JvmPauseMonitor-3fc9f139-dd93-41e7-b235-52ce94d6fe3c: Detected pause in JVM or host machine (eg GC): pause of approximately 190925509ns.
dn3_1    | GC pool 'ParNew' had collection(s): count=1 time=168ms
dn3_1    | 2022-07-31 01:18:19,634 [grpc-default-executor-2] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246: receive requestVote(ELECTION, 11cba143-91f8-47cb-8422-c32a1e2d51df, group-75041C4AA246, 10, (t:9, i:23))
dn3_1    | 2022-07-31 01:18:19,637 [grpc-default-executor-2] INFO impl.VoteContext: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-CANDIDATE: reject ELECTION from 11cba143-91f8-47cb-8422-c32a1e2d51df: already has voted for 3fc9f139-dd93-41e7-b235-52ce94d6fe3c at current term 10
dn3_1    | 2022-07-31 01:18:19,732 [grpc-default-executor-2] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246 replies to ELECTION vote request: 11cba143-91f8-47cb-8422-c32a1e2d51df<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:FAIL-t10. Peer's state: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246:t10, leader=null, voted=3fc9f139-dd93-41e7-b235-52ce94d6fe3c, raftlog=3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-SegmentedRaftLog:OPENED:c23, conf=10: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn3_1    | 2022-07-31 01:18:19,748 [grpc-default-executor-3] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246: receive requestVote(ELECTION, 609e7f2d-9474-472f-937f-8fa0a0bbb327, group-75041C4AA246, 10, (t:9, i:23))
dn3_1    | 2022-07-31 01:18:19,761 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610: receive requestVote(ELECTION, 310a080d-f635-46ff-a53d-49cc9a09fa5c, group-7BB2A1276610, 12, (t:11, i:12))
dn3_1    | 2022-07-31 01:18:19,755 [grpc-default-executor-3] INFO impl.VoteContext: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-CANDIDATE: reject ELECTION from 609e7f2d-9474-472f-937f-8fa0a0bbb327: already has voted for 3fc9f139-dd93-41e7-b235-52ce94d6fe3c at current term 10
dn3_1    | 2022-07-31 01:18:19,781 [grpc-default-executor-3] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246 replies to ELECTION vote request: 609e7f2d-9474-472f-937f-8fa0a0bbb327<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:FAIL-t10. Peer's state: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246:t10, leader=null, voted=3fc9f139-dd93-41e7-b235-52ce94d6fe3c, raftlog=3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-SegmentedRaftLog:OPENED:c23, conf=10: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn3_1    | 2022-07-31 01:18:19,781 [grpc-default-executor-0] INFO impl.VoteContext: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-CANDIDATE: reject ELECTION from 310a080d-f635-46ff-a53d-49cc9a09fa5c: already has voted for 3fc9f139-dd93-41e7-b235-52ce94d6fe3c at current term 12
dn3_1    | 2022-07-31 01:18:19,965 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610 replies to ELECTION vote request: 310a080d-f635-46ff-a53d-49cc9a09fa5c<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:FAIL-t12. Peer's state: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610:t12, leader=null, voted=3fc9f139-dd93-41e7-b235-52ce94d6fe3c, raftlog=3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-SegmentedRaftLog:OPENED:c12, conf=3: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-07-31 01:18:20,122 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection1] INFO impl.LeaderElection: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
dn3_1    | 2022-07-31 01:18:20,123 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection1] INFO impl.LeaderElection:   Response 0: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c<-11cba143-91f8-47cb-8422-c32a1e2d51df#0:FAIL-t10
dn3_1    | 2022-07-31 01:18:20,123 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection1] INFO impl.LeaderElection:   Response 1: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c<-609e7f2d-9474-472f-937f-8fa0a0bbb327#0:FAIL-t10
dn3_1    | 2022-07-31 01:18:20,123 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection1] INFO impl.LeaderElection: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection1 ELECTION round 0: result REJECTED
dn3_1    | 2022-07-31 01:18:20,125 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246: changes role from CANDIDATE to FOLLOWER at term 10 for REJECTED
dn2_1    | 2022-07-31 01:18:04,817 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn2_1    | 2022-07-31 01:18:04,817 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn2_1    | 2022-07-31 01:18:04,817 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn2_1    | 2022-07-31 01:18:04,908 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@543fe698{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-11880747702807328089/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
dn2_1    | 2022-07-31 01:18:04,981 [main] INFO server.AbstractConnector: Started ServerConnector@5bc63e20{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
dn2_1    | 2022-07-31 01:18:04,982 [main] INFO server.Server: Started @48008ms
dn2_1    | 2022-07-31 01:18:04,990 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
dn2_1    | 2022-07-31 01:18:04,990 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
dn2_1    | 2022-07-31 01:18:05,010 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
dn2_1    | 2022-07-31 01:18:05,019 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
dn2_1    | 2022-07-31 01:18:05,107 [Datanode State Machine Daemon Thread] INFO upgrade.UpgradeFinalizer: Running pre-finalized state validations for unfinalized layout features.
dn2_1    | 2022-07-31 01:18:05,113 [Datanode State Machine Daemon Thread] INFO upgrade.UpgradeFinalizer: Running first upgrade commands for unfinalized layout features.
dn2_1    | 2022-07-31 01:18:05,152 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@63aaeda0] INFO util.JvmPauseMonitor: Starting JVM pause monitor
dn2_1    | 2022-07-31 01:18:05,406 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/10.9.0.20:9891
dn2_1    | 2022-07-31 01:18:05,442 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
dn2_1    | 2022-07-31 01:18:08,460 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn2_1    | 2022-07-31 01:18:09,724 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
dn2_1    | 2022-07-31 01:18:09,728 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
dn2_1    | 2022-07-31 01:18:10,218 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 11cba143-91f8-47cb-8422-c32a1e2d51df
dn2_1    | 2022-07-31 01:18:10,278 [11cba143-91f8-47cb-8422-c32a1e2d51df-impl-thread1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246: start as a follower, conf=10: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-07-31 01:18:10,304 [11cba143-91f8-47cb-8422-c32a1e2d51df-impl-thread1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246: changes role from      null to FOLLOWER at term 9 for startAsFollower
dn2_1    | 2022-07-31 01:18:10,306 [11cba143-91f8-47cb-8422-c32a1e2d51df-impl-thread1] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: start 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-FollowerState
dn2_1    | 2022-07-31 01:18:10,279 [11cba143-91f8-47cb-8422-c32a1e2d51df-impl-thread2] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1: start as a follower, conf=31: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-07-31 01:18:10,351 [11cba143-91f8-47cb-8422-c32a1e2d51df-impl-thread2] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1: changes role from      null to FOLLOWER at term 8 for startAsFollower
dn2_1    | 2022-07-31 01:18:10,353 [11cba143-91f8-47cb-8422-c32a1e2d51df-impl-thread2] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: start 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-FollowerState
dn2_1    | 2022-07-31 01:18:10,342 [11cba143-91f8-47cb-8422-c32a1e2d51df-impl-thread3] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB: start as a follower, conf=3: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-07-31 01:18:10,368 [11cba143-91f8-47cb-8422-c32a1e2d51df-impl-thread3] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB: changes role from      null to FOLLOWER at term 3 for startAsFollower
dn2_1    | 2022-07-31 01:18:10,369 [11cba143-91f8-47cb-8422-c32a1e2d51df-impl-thread3] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: start 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-FollowerState
dn2_1    | 2022-07-31 01:18:10,342 [11cba143-91f8-47cb-8422-c32a1e2d51df-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-75041C4AA246,id=11cba143-91f8-47cb-8422-c32a1e2d51df
dn2_1    | 2022-07-31 01:18:10,363 [11cba143-91f8-47cb-8422-c32a1e2d51df-impl-thread2] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-65A101075AF1,id=11cba143-91f8-47cb-8422-c32a1e2d51df
dn2_1    | 2022-07-31 01:18:10,416 [11cba143-91f8-47cb-8422-c32a1e2d51df-impl-thread3] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6999419922EB,id=11cba143-91f8-47cb-8422-c32a1e2d51df
dn2_1    | 2022-07-31 01:18:10,700 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.RaftServer: 11cba143-91f8-47cb-8422-c32a1e2d51df: start RPC server
dn2_1    | 2022-07-31 01:18:10,757 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 11cba143-91f8-47cb-8422-c32a1e2d51df: GrpcService started, listening on 9856
dn2_1    | 2022-07-31 01:18:10,765 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 11cba143-91f8-47cb-8422-c32a1e2d51df: GrpcService started, listening on 9857
dn2_1    | 2022-07-31 01:18:10,771 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 11cba143-91f8-47cb-8422-c32a1e2d51df: GrpcService started, listening on 9858
dn2_1    | 2022-07-31 01:18:10,800 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 11cba143-91f8-47cb-8422-c32a1e2d51df is started using port 9858 for RATIS
dn2_1    | 2022-07-31 01:18:10,800 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 11cba143-91f8-47cb-8422-c32a1e2d51df is started using port 9857 for RATIS_ADMIN
dn2_1    | 2022-07-31 01:18:10,800 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 11cba143-91f8-47cb-8422-c32a1e2d51df is started using port 9856 for RATIS_SERVER
dn2_1    | 2022-07-31 01:18:10,807 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$488/0x0000000840572040@7a30bdf] INFO util.JvmPauseMonitor: JvmPauseMonitor-11cba143-91f8-47cb-8422-c32a1e2d51df: Started
dn2_1    | 2022-07-31 01:18:12,523 [EndpointStateMachine task thread for recon/10.9.0.20:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
dn2_1    | java.net.SocketTimeoutException: Call From c5b89a034b5d/10.9.0.16 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.16:37832 remote=recon/10.9.0.20:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
dn2_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
dn2_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
dn2_1    | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
dn2_1    | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
dn2_1    | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
dn2_1    | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
dn2_1    | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
dn2_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
dn2_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
dn2_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
dn2_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
dn2_1    | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
dn2_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
dn2_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
dn2_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.16:37832 remote=recon/10.9.0.20:9891]
dn2_1    | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
dn2_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
dn2_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
dn2_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
dn2_1    | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
dn2_1    | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
dn2_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn2_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn2_1    | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
dn2_1    | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
dn2_1    | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
dn2_1    | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
dn2_1    | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
dn2_1    | 2022-07-31 01:18:13,174 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
dn2_1    | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
dn2_1    | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
dn2_1    | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:660)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:298)
dn3_1    | 2022-07-31 01:18:20,129 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection1] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: shutdown 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection1
dn3_1    | 2022-07-31 01:18:20,129 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection1] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-FollowerState
dn3_1    | 2022-07-31 01:18:20,382 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610: receive requestVote(ELECTION, 52aca038-7576-46a0-9ccd-b8aed29078e2, group-7BB2A1276610, 12, (t:11, i:12))
dn3_1    | 2022-07-31 01:18:20,382 [grpc-default-executor-0] INFO impl.VoteContext: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-CANDIDATE: reject ELECTION from 52aca038-7576-46a0-9ccd-b8aed29078e2: already has voted for 3fc9f139-dd93-41e7-b235-52ce94d6fe3c at current term 12
dn3_1    | 2022-07-31 01:18:20,382 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610 replies to ELECTION vote request: 52aca038-7576-46a0-9ccd-b8aed29078e2<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:FAIL-t12. Peer's state: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610:t12, leader=null, voted=3fc9f139-dd93-41e7-b235-52ce94d6fe3c, raftlog=3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-SegmentedRaftLog:OPENED:c12, conf=3: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-07-31 01:18:20,431 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-LeaderElection2] INFO impl.LeaderElection: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-LeaderElection2: ELECTION REJECTED received 2 response(s) and 0 exception(s):
dn3_1    | 2022-07-31 01:18:20,432 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-LeaderElection2] INFO impl.LeaderElection:   Response 0: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c<-310a080d-f635-46ff-a53d-49cc9a09fa5c#0:FAIL-t12
dn3_1    | 2022-07-31 01:18:20,432 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-LeaderElection2] INFO impl.LeaderElection:   Response 1: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c<-52aca038-7576-46a0-9ccd-b8aed29078e2#0:FAIL-t12
dn3_1    | 2022-07-31 01:18:20,432 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-LeaderElection2] INFO impl.LeaderElection: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-LeaderElection2 ELECTION round 0: result REJECTED
dn3_1    | 2022-07-31 01:18:20,434 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-LeaderElection2] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610: changes role from CANDIDATE to FOLLOWER at term 12 for REJECTED
dn3_1    | 2022-07-31 01:18:20,434 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-LeaderElection2] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: shutdown 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-LeaderElection2
dn3_1    | 2022-07-31 01:18:20,434 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-LeaderElection2] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-FollowerState
dn3_1    | 2022-07-31 01:18:25,102 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246: receive requestVote(ELECTION, 609e7f2d-9474-472f-937f-8fa0a0bbb327, group-75041C4AA246, 11, (t:9, i:23))
dn3_1    | 2022-07-31 01:18:25,103 [grpc-default-executor-0] INFO impl.VoteContext: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-FOLLOWER: reject ELECTION from 609e7f2d-9474-472f-937f-8fa0a0bbb327: our priority 1 > candidate's priority 0
dn3_1    | 2022-07-31 01:18:25,103 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246: changes role from  FOLLOWER to FOLLOWER at term 11 for candidate:609e7f2d-9474-472f-937f-8fa0a0bbb327
dn3_1    | 2022-07-31 01:18:25,103 [grpc-default-executor-0] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: shutdown 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-FollowerState
dn3_1    | 2022-07-31 01:18:25,103 [grpc-default-executor-0] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-FollowerState
dn3_1    | 2022-07-31 01:18:25,103 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-FollowerState] INFO impl.FollowerState: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-FollowerState was interrupted
dn3_1    | 2022-07-31 01:18:25,106 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246 replies to ELECTION vote request: 609e7f2d-9474-472f-937f-8fa0a0bbb327<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:FAIL-t11. Peer's state: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246:t11, leader=null, voted=null, raftlog=3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-SegmentedRaftLog:OPENED:c23, conf=10: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn3_1    | 2022-07-31 01:18:25,511 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610: receive requestVote(ELECTION, 310a080d-f635-46ff-a53d-49cc9a09fa5c, group-7BB2A1276610, 13, (t:11, i:12))
dn3_1    | 2022-07-31 01:18:25,511 [grpc-default-executor-0] INFO impl.VoteContext: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-FOLLOWER: accept ELECTION from 310a080d-f635-46ff-a53d-49cc9a09fa5c: our priority 0 <= candidate's priority 0
dn3_1    | 2022-07-31 01:18:25,511 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610: changes role from  FOLLOWER to FOLLOWER at term 13 for candidate:310a080d-f635-46ff-a53d-49cc9a09fa5c
dn3_1    | 2022-07-31 01:18:25,511 [grpc-default-executor-0] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: shutdown 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-FollowerState
dn3_1    | 2022-07-31 01:18:25,511 [grpc-default-executor-0] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-FollowerState
dn3_1    | 2022-07-31 01:18:25,512 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-FollowerState] INFO impl.FollowerState: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-FollowerState was interrupted
dn3_1    | 2022-07-31 01:18:25,521 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610 replies to ELECTION vote request: 310a080d-f635-46ff-a53d-49cc9a09fa5c<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:OK-t13. Peer's state: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610:t13, leader=null, voted=310a080d-f635-46ff-a53d-49cc9a09fa5c, raftlog=3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-SegmentedRaftLog:OPENED:c12, conf=3: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-07-31 01:18:30,173 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-FollowerState] INFO impl.FollowerState: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5070215518ns, electionTimeout:5068ms
dn3_1    | 2022-07-31 01:18:30,174 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-FollowerState] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: shutdown 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-FollowerState
dn3_1    | 2022-07-31 01:18:30,174 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-FollowerState] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246: changes role from  FOLLOWER to CANDIDATE at term 11 for changeToCandidate
dn3_1    | 2022-07-31 01:18:30,174 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn3_1    | 2022-07-31 01:18:30,175 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-FollowerState] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4
dn3_1    | 2022-07-31 01:18:30,181 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO impl.LeaderElection: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4 ELECTION round 0: submit vote requests at term 12 for 10: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn3_1    | 2022-07-31 01:18:30,204 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO impl.LeaderElection: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4: ELECTION PASSED received 1 response(s) and 0 exception(s):
dn3_1    | 2022-07-31 01:18:30,204 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO impl.LeaderElection:   Response 0: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c<-11cba143-91f8-47cb-8422-c32a1e2d51df#0:OK-t12
dn3_1    | 2022-07-31 01:18:30,204 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO impl.LeaderElection: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4 ELECTION round 0: result PASSED
dn3_1    | 2022-07-31 01:18:30,205 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: shutdown 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4
dn3_1    | 2022-07-31 01:18:30,205 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246: changes role from CANDIDATE to LEADER at term 12 for changeToLeader
dn3_1    | 2022-07-31 01:18:30,205 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-75041C4AA246 with new leaderId: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c
dn3_1    | 2022-07-31 01:18:30,206 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246: change Leader from null to 3fc9f139-dd93-41e7-b235-52ce94d6fe3c at term 12 for becomeLeader, leader elected after 27751ms
dn3_1    | 2022-07-31 01:18:30,206 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn3_1    | 2022-07-31 01:18:30,206 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn3_1    | 2022-07-31 01:18:30,206 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn3_1    | 2022-07-31 01:18:30,207 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn3_1    | 2022-07-31 01:18:30,208 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn3_1    | 2022-07-31 01:18:30,208 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn3_1    | 2022-07-31 01:18:30,208 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn3_1    | 2022-07-31 01:18:30,208 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn3_1    | 2022-07-31 01:18:30,267 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246: receive requestVote(ELECTION, 609e7f2d-9474-472f-937f-8fa0a0bbb327, group-75041C4AA246, 12, (t:9, i:23))
dn3_1    | 2022-07-31 01:18:30,324 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn3_1    | 2022-07-31 01:18:30,324 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2022-07-31 01:18:30,325 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
dn3_1    | 2022-07-31 01:18:30,339 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn3_1    | 2022-07-31 01:18:30,343 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn3_1    | 2022-07-31 01:18:30,345 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn3_1    | 2022-07-31 01:18:30,357 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn3_1    | 2022-07-31 01:18:30,364 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2022-07-31 01:18:30,364 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
dn3_1    | 2022-07-31 01:18:30,368 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn3_1    | 2022-07-31 01:18:30,370 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn3_1    | 2022-07-31 01:18:30,370 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn4_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
dn4_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
dn4_1    | 2022-07-31 01:17:27,453 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
dn4_1    | /************************************************************
dn4_1    | STARTUP_MSG: Starting HddsDatanodeService
dn4_1    | STARTUP_MSG:   host = 6d05c26d6799/10.9.0.18
dn4_1    | STARTUP_MSG:   args = []
dn4_1    | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:493)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | Caused by: java.util.concurrent.TimeoutException
dn2_1    | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
dn2_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn2_1    | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
dn2_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn2_1    | 	... 1 more
dn2_1    | 2022-07-31 01:18:15,376 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-FollowerState] INFO impl.FollowerState: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5070593879ns, electionTimeout:5033ms
dn2_1    | 2022-07-31 01:18:15,380 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-FollowerState] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: shutdown 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-FollowerState
dn2_1    | 2022-07-31 01:18:15,380 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-FollowerState] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246: changes role from  FOLLOWER to CANDIDATE at term 9 for changeToCandidate
dn2_1    | 2022-07-31 01:18:15,383 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn2_1    | 2022-07-31 01:18:15,383 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-FollowerState] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: start 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-LeaderElection1
dn1_1    | 2022-07-31 01:18:30,251 [grpc-default-executor-2] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246 replies to ELECTION vote request: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c<-609e7f2d-9474-472f-937f-8fa0a0bbb327#0:FAIL-t12. Peer's state: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246:t12, leader=null, voted=609e7f2d-9474-472f-937f-8fa0a0bbb327, raftlog=609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-SegmentedRaftLog:OPENED:c23, conf=10: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-07-31 01:18:30,413 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection5] INFO impl.LeaderElection: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection5: ELECTION REJECTED received 2 response(s) and 0 exception(s):
dn1_1    | 2022-07-31 01:18:30,413 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection5] INFO impl.LeaderElection:   Response 0: 609e7f2d-9474-472f-937f-8fa0a0bbb327<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:FAIL-t12
dn1_1    | 2022-07-31 01:18:30,413 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection5] INFO impl.LeaderElection:   Response 1: 609e7f2d-9474-472f-937f-8fa0a0bbb327<-11cba143-91f8-47cb-8422-c32a1e2d51df#0:FAIL-t12
dn1_1    | 2022-07-31 01:18:30,414 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection5] INFO impl.LeaderElection: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection5 ELECTION round 0: result REJECTED
dn1_1    | 2022-07-31 01:18:30,415 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection5] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246: changes role from CANDIDATE to FOLLOWER at term 12 for REJECTED
dn1_1    | 2022-07-31 01:18:30,415 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection5] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection5
dn1_1    | 2022-07-31 01:18:30,415 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-LeaderElection5] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-FollowerState
dn1_1    | 2022-07-31 01:18:30,484 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-FollowerState] INFO impl.FollowerState: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5174475788ns, electionTimeout:5152ms
dn1_1    | 2022-07-31 01:18:30,485 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-FollowerState] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-FollowerState
dn1_1    | 2022-07-31 01:18:30,485 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-FollowerState] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1: changes role from  FOLLOWER to CANDIDATE at term 10 for changeToCandidate
dn1_1    | 2022-07-31 01:18:30,485 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn1_1    | 2022-07-31 01:18:30,485 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-FollowerState] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6
dn1_1    | 2022-07-31 01:18:30,487 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO impl.LeaderElection: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6 ELECTION round 0: submit vote requests at term 11 for 31: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-07-31 01:18:30,524 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO impl.LeaderElection: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6: ELECTION PASSED received 1 response(s) and 0 exception(s):
dn1_1    | 2022-07-31 01:18:30,525 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO impl.LeaderElection:   Response 0: 609e7f2d-9474-472f-937f-8fa0a0bbb327<-11cba143-91f8-47cb-8422-c32a1e2d51df#0:OK-t11
dn1_1    | 2022-07-31 01:18:30,525 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO impl.LeaderElection: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6 ELECTION round 0: result PASSED
dn1_1    | 2022-07-31 01:18:30,525 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6
dn1_1    | 2022-07-31 01:18:30,525 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1: changes role from CANDIDATE to LEADER at term 11 for changeToLeader
dn1_1    | 2022-07-31 01:18:30,526 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-65A101075AF1 with new leaderId: 609e7f2d-9474-472f-937f-8fa0a0bbb327
dn1_1    | 2022-07-31 01:18:30,526 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1: change Leader from null to 609e7f2d-9474-472f-937f-8fa0a0bbb327 at term 11 for becomeLeader, leader elected after 29682ms
dn1_1    | 2022-07-31 01:18:30,527 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn1_1    | 2022-07-31 01:18:30,527 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn1_1    | 2022-07-31 01:18:30,527 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn1_1    | 2022-07-31 01:18:30,528 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn1_1    | 2022-07-31 01:18:30,529 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn1_1    | 2022-07-31 01:18:30,529 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn1_1    | 2022-07-31 01:18:30,529 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn1_1    | 2022-07-31 01:18:30,533 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn1_1    | 2022-07-31 01:18:30,540 [609e7f2d-9474-472f-937f-8fa0a0bbb327-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-75041C4AA246 with new leaderId: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c
dn2_1    | 2022-07-31 01:18:15,573 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-LeaderElection1] INFO impl.LeaderElection: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-LeaderElection1 ELECTION round 0: submit vote requests at term 10 for 10: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-07-31 01:18:15,767 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-FollowerState] INFO impl.FollowerState: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5397420381ns, electionTimeout:5077ms
dn2_1    | 2022-07-31 01:18:15,767 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-FollowerState] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: shutdown 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-FollowerState
dn2_1    | 2022-07-31 01:18:15,767 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-FollowerState] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
dn2_1    | 2022-07-31 01:18:15,768 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn2_1    | 2022-07-31 01:18:15,768 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-FollowerState] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: start 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-LeaderElection2
dn2_1    | 2022-07-31 01:18:15,803 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-FollowerState] INFO impl.FollowerState: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5450686135ns, electionTimeout:5129ms
dn2_1    | 2022-07-31 01:18:15,808 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-FollowerState] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: shutdown 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-FollowerState
dn2_1    | 2022-07-31 01:18:15,808 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-FollowerState] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1: changes role from  FOLLOWER to CANDIDATE at term 8 for changeToCandidate
dn2_1    | 2022-07-31 01:18:15,808 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn2_1    | 2022-07-31 01:18:15,817 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-FollowerState] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: start 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-LeaderElection3
dn2_1    | 2022-07-31 01:18:15,809 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-LeaderElection2] INFO impl.LeaderElection: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-LeaderElection2 ELECTION round 0: submit vote requests at term 4 for 3: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-07-31 01:18:15,913 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-LeaderElection2] INFO impl.LeaderElection: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-LeaderElection2 ELECTION round 0: result PASSED (term=4)
dn2_1    | 2022-07-31 01:18:15,923 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-LeaderElection2] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: shutdown 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-LeaderElection2
dn2_1    | 2022-07-31 01:18:15,929 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-LeaderElection2] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB: changes role from CANDIDATE to LEADER at term 4 for changeToLeader
dn2_1    | 2022-07-31 01:18:15,935 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-6999419922EB with new leaderId: 11cba143-91f8-47cb-8422-c32a1e2d51df
dn2_1    | 2022-07-31 01:18:15,975 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-LeaderElection2] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB: change Leader from null to 11cba143-91f8-47cb-8422-c32a1e2d51df at term 4 for becomeLeader, leader elected after 13840ms
dn2_1    | 2022-07-31 01:18:16,002 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-LeaderElection3] INFO impl.LeaderElection: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-LeaderElection3 ELECTION round 0: submit vote requests at term 9 for 31: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-07-31 01:18:16,211 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn2_1    | 2022-07-31 01:18:16,232 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn2_1    | 2022-07-31 01:18:16,306 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn2_1    | 2022-07-31 01:18:16,336 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn2_1    | 2022-07-31 01:18:16,357 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn2_1    | 2022-07-31 01:18:16,358 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn2_1    | 2022-07-31 01:18:16,416 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn2_1    | 2022-07-31 01:18:16,563 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn2_1    | 2022-07-31 01:18:16,571 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-LeaderElection2] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: start 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-LeaderStateImpl
dn2_1    | 2022-07-31 01:18:16,873 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-SegmentedRaftLogWorker: Rolling segment log-3_4 to index:4
dn2_1    | 2022-07-31 01:18:17,109 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-LeaderElection2] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB: set configuration 5: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-07-31 01:18:17,140 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/8145371a-b336-4e64-a95d-6999419922eb/current/log_inprogress_3 to /data/metadata/ratis/8145371a-b336-4e64-a95d-6999419922eb/current/log_3-4
dn1_1    | 2022-07-31 01:18:30,602 [609e7f2d-9474-472f-937f-8fa0a0bbb327-server-thread1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246: change Leader from null to 3fc9f139-dd93-41e7-b235-52ce94d6fe3c at term 12 for appendEntries, leader elected after 30075ms
dn1_1    | 2022-07-31 01:18:30,695 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn1_1    | 2022-07-31 01:18:30,696 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2022-07-31 01:18:30,696 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
dn1_1    | 2022-07-31 01:18:30,824 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn1_1    | 2022-07-31 01:18:30,834 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn1_1    | 2022-07-31 01:18:30,837 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn1_1    | 2022-07-31 01:18:30,846 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn1_1    | 2022-07-31 01:18:30,847 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2022-07-31 01:18:30,847 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
dn1_1    | 2022-07-31 01:18:30,847 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn1_1    | 2022-07-31 01:18:30,878 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn1_1    | 2022-07-31 01:18:30,879 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn1_1    | 2022-07-31 01:18:30,920 [609e7f2d-9474-472f-937f-8fa0a0bbb327-server-thread1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246: set configuration 24: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-07-31 01:18:30,921 [609e7f2d-9474-472f-937f-8fa0a0bbb327-server-thread1] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-SegmentedRaftLogWorker: Rolling segment log-10_23 to index:23
dn1_1    | 2022-07-31 01:18:30,983 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderStateImpl
dn1_1    | 2022-07-31 01:18:31,027 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-SegmentedRaftLogWorker: Rolling segment log-31_35 to index:35
dn1_1    | 2022-07-31 01:18:31,005 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/current/log_inprogress_10 to /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/current/log_10-23
dn1_1    | 2022-07-31 01:18:31,090 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/current/log_inprogress_24
dn1_1    | 2022-07-31 01:18:31,156 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/current/log_inprogress_31 to /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/current/log_31-35
dn1_1    | 2022-07-31 01:18:31,162 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderElection6] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1: set configuration 36: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-07-31 01:18:31,167 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/current/log_inprogress_36
dn1_1    | 2022-07-31 01:19:01,753 [ContainerOp-369e0910-4276-41cc-941b-75041c4aa246-0] INFO keyvalue.KeyValueContainer: Container 1001 is synced with bcsId 8.
dn1_1    | 2022-07-31 01:19:01,766 [ContainerOp-369e0910-4276-41cc-941b-75041c4aa246-0] INFO keyvalue.KeyValueContainer: Container 1001 is synced with bcsId 8.
dn1_1    | 2022-07-31 01:19:01,807 [ContainerOp-369e0910-4276-41cc-941b-75041c4aa246-0] INFO keyvalue.KeyValueContainer: Container 1001 is closed with bcsId 8.
dn1_1    | 2022-07-31 01:19:01,845 [ContainerOp-369e0910-4276-41cc-941b-75041c4aa246-1] INFO keyvalue.KeyValueContainer: Container 2002 is synced with bcsId 21.
dn1_1    | 2022-07-31 01:19:01,850 [ContainerOp-369e0910-4276-41cc-941b-75041c4aa246-1] INFO keyvalue.KeyValueContainer: Container 2002 is synced with bcsId 21.
dn1_1    | 2022-07-31 01:19:01,888 [ContainerOp-369e0910-4276-41cc-941b-75041c4aa246-1] INFO keyvalue.KeyValueContainer: Container 2002 is closed with bcsId 21.
dn1_1    | 2022-07-31 01:19:02,141 [ContainerOp-67b1342c-3bb3-4b48-a218-65a101075af1-0] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 10.
dn1_1    | 2022-07-31 01:19:02,142 [ContainerOp-67b1342c-3bb3-4b48-a218-65a101075af1-0] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 10.
dn1_1    | 2022-07-31 01:19:02,154 [ContainerOp-67b1342c-3bb3-4b48-a218-65a101075af1-0] INFO keyvalue.KeyValueContainer: Container 1 is closed with bcsId 10.
dn1_1    | 2022-07-31 01:19:02,333 [ContainerOp-67b1342c-3bb3-4b48-a218-65a101075af1-1] INFO keyvalue.KeyValueContainer: Container 1002 is synced with bcsId 29.
dn1_1    | 2022-07-31 01:19:02,334 [ContainerOp-67b1342c-3bb3-4b48-a218-65a101075af1-1] INFO keyvalue.KeyValueContainer: Container 1002 is synced with bcsId 29.
dn1_1    | 2022-07-31 01:19:02,354 [ContainerOp-67b1342c-3bb3-4b48-a218-65a101075af1-1] INFO keyvalue.KeyValueContainer: Container 1002 is closed with bcsId 29.
dn4_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
dn4_1    | STARTUP_MSG:   build = https://github.com/apache/ozone/57d620dbd4cb5dfec746cc16039d3843e64c181c ; compiled by 'runner' on 2022-07-31T00:51Z
dn4_1    | STARTUP_MSG:   java = 11.0.14.1
dn4_1    | ************************************************************/
dn4_1    | 2022-07-31 01:17:27,500 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
dn4_1    | 2022-07-31 01:17:28,019 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
dn4_1    | 2022-07-31 01:17:28,979 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
dn4_1    | 2022-07-31 01:17:30,257 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
dn4_1    | 2022-07-31 01:17:30,257 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
dn4_1    | 2022-07-31 01:17:32,099 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:6d05c26d6799 ip:10.9.0.18
dn4_1    | 2022-07-31 01:17:34,310 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = DATANODE_SCHEMA_V3 (version = 4)
dn4_1    | 2022-07-31 01:17:35,971 [main] INFO reflections.Reflections: Reflections took 1463 ms to scan 2 urls, producing 89 keys and 198 values 
dn4_1    | 2022-07-31 01:17:36,458 [main] INFO upgrade.HDDSLayoutVersionManager: Registering Upgrade Action : DatanodeSchemaV3FinalizeAction
dn4_1    | 2022-07-31 01:17:36,700 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
dn4_1    | 2022-07-31 01:17:38,110 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/hdds/scmUsed: 4096 at 2022-07-31T01:17:01.542Z
dn4_1    | 2022-07-31 01:17:38,224 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
dn4_1    | 2022-07-31 01:17:38,237 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
dn4_1    | 2022-07-31 01:17:38,261 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
dn4_1    | 2022-07-31 01:17:38,475 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
dn4_1    | 2022-07-31 01:17:38,657 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn4_1    | 2022-07-31 01:17:38,686 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/metadata/ratis/scmUsed: 4096 at 2022-07-31T01:17:01.543Z
dn4_1    | 2022-07-31 01:17:38,695 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
dn4_1    | 2022-07-31 01:17:38,700 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
dn4_1    | 2022-07-31 01:17:38,705 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
dn4_1    | 2022-07-31 01:17:38,943 [Thread-3] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
dn4_1    | 2022-07-31 01:17:39,783 [Thread-3] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
dn4_1    | 2022-07-31 01:17:39,801 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
dn4_1    | 2022-07-31 01:17:52,443 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
dn4_1    | 2022-07-31 01:17:52,978 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn4_1    | 2022-07-31 01:17:53,584 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
dn4_1    | 2022-07-31 01:17:54,823 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
dn4_1    | 2022-07-31 01:17:54,834 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
dn4_1    | 2022-07-31 01:17:54,838 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
dn4_1    | 2022-07-31 01:17:54,853 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
dn4_1    | 2022-07-31 01:17:54,873 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn4_1    | 2022-07-31 01:17:54,874 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
dn4_1    | 2022-07-31 01:17:54,886 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn4_1    | 2022-07-31 01:17:55,075 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
dn4_1    | 2022-07-31 01:17:55,093 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
dn4_1    | 2022-07-31 01:17:57,571 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
dn4_1    | 2022-07-31 01:17:57,654 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
dn4_1    | 2022-07-31 01:17:57,675 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
dn4_1    | 2022-07-31 01:17:57,676 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn4_1    | 2022-07-31 01:17:57,677 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn4_1    | 2022-07-31 01:17:57,719 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn4_1    | 2022-07-31 01:17:57,750 [310a080d-f635-46ff-a53d-49cc9a09fa5c-impl-thread1] INFO server.RaftServer: 310a080d-f635-46ff-a53d-49cc9a09fa5c: found a subdirectory /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610
dn4_1    | 2022-07-31 01:17:57,886 [310a080d-f635-46ff-a53d-49cc9a09fa5c-impl-thread1] INFO server.RaftServer: 310a080d-f635-46ff-a53d-49cc9a09fa5c: addNew group-7BB2A1276610:[] returns group-7BB2A1276610:java.util.concurrent.CompletableFuture@ac6de39[Not completed]
dn4_1    | 2022-07-31 01:17:57,889 [310a080d-f635-46ff-a53d-49cc9a09fa5c-impl-thread1] INFO server.RaftServer: 310a080d-f635-46ff-a53d-49cc9a09fa5c: found a subdirectory /data/metadata/ratis/c06adbe4-99b1-4236-a662-b3503d3184bf
dn4_1    | 2022-07-31 01:17:57,896 [310a080d-f635-46ff-a53d-49cc9a09fa5c-impl-thread1] INFO server.RaftServer: 310a080d-f635-46ff-a53d-49cc9a09fa5c: addNew group-B3503D3184BF:[] returns group-B3503D3184BF:java.util.concurrent.CompletableFuture@439d37f6[Not completed]
dn4_1    | 2022-07-31 01:17:58,056 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
dn4_1    | 2022-07-31 01:17:58,471 [pool-26-thread-1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c: new RaftServerImpl for group-7BB2A1276610:[] with ContainerStateMachine:uninitialized
dn4_1    | 2022-07-31 01:17:58,529 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn4_1    | 2022-07-31 01:17:58,565 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn4_1    | 2022-07-31 01:17:58,571 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn4_1    | 2022-07-31 01:17:58,580 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn4_1    | 2022-07-31 01:17:58,582 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn4_1    | 2022-07-31 01:17:58,586 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn4_1    | 2022-07-31 01:17:58,760 [pool-26-thread-1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn4_1    | 2022-07-31 01:17:58,767 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn4_1    | 2022-07-31 01:17:58,817 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn4_1    | 2022-07-31 01:17:58,837 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn4_1    | 2022-07-31 01:17:58,967 [pool-26-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/in_use.lock acquired by nodename 6@6d05c26d6799
dn4_1    | 2022-07-31 01:17:59,081 [pool-26-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=11, votedFor=52aca038-7576-46a0-9ccd-b8aed29078e2} from /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/current/raft-meta
dn4_1    | 2022-07-31 01:17:59,382 [pool-26-thread-1] INFO ratis.ContainerStateMachine: group-7BB2A1276610: Setting the last applied index to (t:11, i:12)
dn4_1    | 2022-07-31 01:17:59,454 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
dn4_1    | 2022-07-31 01:17:59,646 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
dn4_1    | 2022-07-31 01:17:59,967 [main] INFO util.log: Logging initialized @44674ms to org.eclipse.jetty.util.log.Slf4jLog
dn4_1    | 2022-07-31 01:18:01,148 [pool-26-thread-1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610: set configuration 3: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn4_1    | 2022-07-31 01:18:01,180 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn4_1    | 2022-07-31 01:18:01,209 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn4_1    | 2022-07-31 01:18:01,317 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn4_1    | 2022-07-31 01:18:01,324 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn4_1    | 2022-07-31 01:18:01,358 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn4_1    | 2022-07-31 01:18:01,561 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn4_1    | 2022-07-31 01:18:01,578 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
dn4_1    | 2022-07-31 01:18:01,684 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
dn4_1    | 2022-07-31 01:18:01,714 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn4_1    | 2022-07-31 01:18:01,749 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn4_1    | 2022-07-31 01:18:01,826 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
dn4_1    | 2022-07-31 01:18:01,858 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
dn4_1    | 2022-07-31 01:18:01,868 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: new 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610
dn3_1    | 2022-07-31 01:18:30,372 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderStateImpl
dn3_1    | 2022-07-31 01:18:30,374 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-SegmentedRaftLogWorker: Rolling segment log-10_23 to index:23
dn3_1    | 2022-07-31 01:18:30,400 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderElection4] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246: set configuration 24: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn3_1    | 2022-07-31 01:18:30,400 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/current/log_inprogress_10 to /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/current/log_10-23
dn3_1    | 2022-07-31 01:18:30,400 [grpc-default-executor-0] INFO impl.VoteContext: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LEADER: reject ELECTION from 609e7f2d-9474-472f-937f-8fa0a0bbb327: already has voted for 3fc9f139-dd93-41e7-b235-52ce94d6fe3c at current term 12
dn3_1    | 2022-07-31 01:18:30,403 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246 replies to ELECTION vote request: 609e7f2d-9474-472f-937f-8fa0a0bbb327<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:FAIL-t12. Peer's state: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246:t12, leader=3fc9f139-dd93-41e7-b235-52ce94d6fe3c, voted=3fc9f139-dd93-41e7-b235-52ce94d6fe3c, raftlog=3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-SegmentedRaftLog:OPENED:c23, conf=24: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn3_1    | 2022-07-31 01:18:30,412 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/current/log_inprogress_24
dn3_1    | 2022-07-31 01:18:30,584 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610: receive requestVote(ELECTION, 52aca038-7576-46a0-9ccd-b8aed29078e2, group-7BB2A1276610, 14, (t:11, i:12))
dn3_1    | 2022-07-31 01:18:30,597 [grpc-default-executor-0] INFO impl.VoteContext: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-FOLLOWER: accept ELECTION from 52aca038-7576-46a0-9ccd-b8aed29078e2: our priority 0 <= candidate's priority 1
dn3_1    | 2022-07-31 01:18:30,598 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610: changes role from  FOLLOWER to FOLLOWER at term 14 for candidate:52aca038-7576-46a0-9ccd-b8aed29078e2
dn3_1    | 2022-07-31 01:18:30,598 [grpc-default-executor-0] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: shutdown 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-FollowerState
dn3_1    | 2022-07-31 01:18:30,598 [grpc-default-executor-0] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-FollowerState
dn3_1    | 2022-07-31 01:18:30,599 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-FollowerState] INFO impl.FollowerState: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-FollowerState was interrupted
dn3_1    | 2022-07-31 01:18:30,614 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610 replies to ELECTION vote request: 52aca038-7576-46a0-9ccd-b8aed29078e2<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:OK-t14. Peer's state: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610:t14, leader=null, voted=52aca038-7576-46a0-9ccd-b8aed29078e2, raftlog=3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-SegmentedRaftLog:OPENED:c12, conf=3: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-07-31 01:18:30,952 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-7BB2A1276610 with new leaderId: 52aca038-7576-46a0-9ccd-b8aed29078e2
dn3_1    | 2022-07-31 01:18:30,952 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c-server-thread1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610: change Leader from null to 52aca038-7576-46a0-9ccd-b8aed29078e2 at term 14 for appendEntries, leader elected after 32758ms
dn3_1    | 2022-07-31 01:18:31,074 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c-server-thread1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610: set configuration 13: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-07-31 01:18:31,077 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c-server-thread1] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-SegmentedRaftLogWorker: Rolling segment log-3_12 to index:12
dn3_1    | 2022-07-31 01:18:31,082 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/current/log_inprogress_3 to /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/current/log_3-12
dn3_1    | 2022-07-31 01:18:31,087 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/current/log_inprogress_13
dn3_1    | 2022-07-31 01:19:01,465 [ContainerOp-369e0910-4276-41cc-941b-75041c4aa246-0] INFO keyvalue.KeyValueContainer: Container 1001 is synced with bcsId 8.
dn3_1    | 2022-07-31 01:19:01,472 [ContainerOp-369e0910-4276-41cc-941b-75041c4aa246-0] INFO keyvalue.KeyValueContainer: Container 1001 is synced with bcsId 8.
dn3_1    | 2022-07-31 01:19:01,497 [ContainerOp-369e0910-4276-41cc-941b-75041c4aa246-0] INFO keyvalue.KeyValueContainer: Container 1001 is closed with bcsId 8.
dn3_1    | 2022-07-31 01:19:01,756 [ContainerOp-369e0910-4276-41cc-941b-75041c4aa246-1] INFO keyvalue.KeyValueContainer: Container 2002 is synced with bcsId 21.
dn3_1    | 2022-07-31 01:19:01,762 [ContainerOp-369e0910-4276-41cc-941b-75041c4aa246-1] INFO keyvalue.KeyValueContainer: Container 2002 is synced with bcsId 21.
dn4_1    | 2022-07-31 01:18:01,873 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
dn4_1    | 2022-07-31 01:18:01,880 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
dn4_1    | 2022-07-31 01:18:01,881 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn4_1    | 2022-07-31 01:18:01,911 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn4_1    | 2022-07-31 01:18:01,914 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn4_1    | 2022-07-31 01:18:01,918 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn4_1    | 2022-07-31 01:18:01,942 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn4_1    | 2022-07-31 01:18:01,954 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn4_1    | 2022-07-31 01:18:01,961 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn4_1    | 2022-07-31 01:18:01,963 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn4_1    | 2022-07-31 01:18:02,209 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn4_1    | 2022-07-31 01:18:02,242 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn4_1    | 2022-07-31 01:18:02,258 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn4_1    | 2022-07-31 01:18:02,621 [main] INFO http.HttpServer2: Jetty bound to port 9882
dn4_1    | 2022-07-31 01:18:02,654 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
dn4_1    | 2022-07-31 01:18:02,685 [pool-26-thread-1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610: set configuration 0: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn4_1    | 2022-07-31 01:18:02,709 [pool-26-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/current/log_0-0
om3_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1    | 2022-07-31 01:17:27,911 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1    | /************************************************************
om3_1    | STARTUP_MSG: Starting OzoneManager
om3_1    | STARTUP_MSG:   host = eb852635f668/10.9.0.13
om3_1    | STARTUP_MSG:   args = [--upgrade]
om3_1    | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
dn1_1    | 2022-07-31 01:19:02,524 [ContainerOp-67b1342c-3bb3-4b48-a218-65a101075af1-2] INFO keyvalue.KeyValueContainer: Container 2003 is synced with bcsId 34.
dn1_1    | 2022-07-31 01:19:02,525 [ContainerOp-67b1342c-3bb3-4b48-a218-65a101075af1-2] INFO keyvalue.KeyValueContainer: Container 2003 is synced with bcsId 34.
dn1_1    | 2022-07-31 01:19:02,539 [ContainerOp-67b1342c-3bb3-4b48-a218-65a101075af1-2] INFO keyvalue.KeyValueContainer: Container 2003 is closed with bcsId 34.
dn1_1    | 2022-07-31 01:19:02,550 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn1_1    | 2022-07-31 01:19:02,551 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn1_1    | 2022-07-31 01:19:02,552 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn1_1    | 2022-07-31 01:19:02,553 [Command processor thread] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: ERASURE_CODED_STORAGE_SUPPORT.
dn1_1    | 2022-07-31 01:19:02,557 [Command processor thread] INFO upgrade.AbstractLayoutVersionManager: Layout feature ERASURE_CODED_STORAGE_SUPPORT has been finalized.
dn1_1    | 2022-07-31 01:19:02,558 [Command processor thread] INFO upgrade.UpgradeFinalizer: Running finalization actions for layout feature: DATANODE_SCHEMA_V3
dn1_1    | 2022-07-31 01:19:02,558 [Command processor thread] INFO upgrade.DatanodeSchemaV3FinalizeAction: Upgrading Datanode volume layout for Schema V3 support.
dn1_1    | 2022-07-31 01:19:02,664 [Command processor thread] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-2b5f2d05-a9c0-4b31-b820-5fa0b5f933e6/DS-48ea89b0-f610-47ad-a079-f1d9e2939dd6/container.db for volume DS-48ea89b0-f610-47ad-a079-f1d9e2939dd6
dn1_1    | 2022-07-31 01:19:02,668 [Command processor thread] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-2b5f2d05-a9c0-4b31-b820-5fa0b5f933e6/DS-48ea89b0-f610-47ad-a079-f1d9e2939dd6/container.db for volume DS-48ea89b0-f610-47ad-a079-f1d9e2939dd6
dn1_1    | 2022-07-31 01:19:02,669 [Command processor thread] INFO upgrade.DatanodeSchemaV3FinalizeAction: Schema V3 is disabled. Won't load RocksDB in upgrade.
dn1_1    | 2022-07-31 01:19:02,672 [Command processor thread] INFO upgrade.AbstractLayoutVersionManager: Layout feature DATANODE_SCHEMA_V3 has been finalized.
dn1_1    | 2022-07-31 01:19:02,672 [Command processor thread] INFO upgrade.AbstractLayoutVersionManager: Finalization is complete.
dn1_1    | 2022-07-31 01:19:02,673 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization is done.
dn1_1    | 2022-07-31 01:19:02,674 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn1_1    | 2022-07-31 01:19:02,674 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn1_1    | 2022-07-31 01:19:02,674 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn1_1    | 2022-07-31 01:19:02,674 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn1_1    | 2022-07-31 01:19:02,674 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn1_1    | 2022-07-31 01:19:02,674 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn1_1    | 2022-07-31 01:19:02,675 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn1_1    | 2022-07-31 01:19:02,675 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn1_1    | 2022-07-31 01:19:02,675 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn1_1    | 2022-07-31 01:19:32,876 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: 609e7f2d-9474-472f-937f-8fa0a0bbb327: Completed APPEND_ENTRIES, lastRequest: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c->609e7f2d-9474-472f-937f-8fa0a0bbb327#81-t12,previous=(t:12, i:28),leaderCommit=28,initializing? true,entries: size=1, first=(t:12, i:29), METADATAENTRY(c:28)
dn1_1    | 2022-07-31 01:19:33,541 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn1_1    | 2022-07-31 01:19:33,543 [Command processor thread] INFO server.RaftServer: 609e7f2d-9474-472f-937f-8fa0a0bbb327: remove    LEADER 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58:t4, leader=609e7f2d-9474-472f-937f-8fa0a0bbb327, voted=609e7f2d-9474-472f-937f-8fa0a0bbb327, raftlog=609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-SegmentedRaftLog:OPENED:c6, conf=5: [609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1], old=null RUNNING
dn1_1    | 2022-07-31 01:19:33,544 [Command processor thread] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58: shutdown
dn1_1    | 2022-07-31 01:19:33,545 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-FFC093016E58,id=609e7f2d-9474-472f-937f-8fa0a0bbb327
dn1_1    | 2022-07-31 01:19:33,545 [Command processor thread] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-LeaderStateImpl
dn1_1    | 2022-07-31 01:19:33,545 [Command processor thread] INFO impl.PendingRequests: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-PendingRequests: sendNotLeaderResponses
dn1_1    | 2022-07-31 01:19:33,550 [Command processor thread] INFO impl.StateMachineUpdater: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-StateMachineUpdater: set stopIndex = 6
dn1_1    | 2022-07-31 01:19:33,550 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-FFC093016E58: Taking a snapshot at:(t:4, i:6) file /data/metadata/ratis/c57ff3c1-98cc-4640-a639-ffc093016e58/sm/snapshot.4_6
dn1_1    | 2022-07-31 01:19:33,553 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-FFC093016E58: Finished taking a snapshot at:(t:4, i:6) file:/data/metadata/ratis/c57ff3c1-98cc-4640-a639-ffc093016e58/sm/snapshot.4_6 took: 3 ms
dn1_1    | 2022-07-31 01:19:33,556 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-StateMachineUpdater] INFO impl.StateMachineUpdater: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-StateMachineUpdater: Took a snapshot at index 6
dn1_1    | 2022-07-31 01:19:33,557 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-StateMachineUpdater] INFO impl.StateMachineUpdater: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-StateMachineUpdater: snapshotIndex: updateIncreasingly 4 -> 6
dn1_1    | 2022-07-31 01:19:33,559 [Command processor thread] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58: closes. applyIndex: 6
dn1_1    | 2022-07-31 01:19:33,560 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
dn1_1    | 2022-07-31 01:19:33,572 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58-SegmentedRaftLogWorker close()
dn4_1    | 2022-07-31 01:18:02,775 [pool-26-thread-1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610: set configuration 1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn4_1    | 2022-07-31 01:18:02,802 [pool-26-thread-1] INFO segmented.LogSegment: Successfully read 2 entries from segment file /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/current/log_1-2
dn4_1    | 2022-07-31 01:18:02,815 [pool-26-thread-1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610: set configuration 3: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn4_1    | 2022-07-31 01:18:02,821 [pool-26-thread-1] INFO segmented.LogSegment: Successfully read 10 entries from segment file /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/current/log_inprogress_3
dn4_1    | 2022-07-31 01:18:02,858 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 12
dn4_1    | 2022-07-31 01:18:02,870 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 2
dn4_1    | 2022-07-31 01:18:03,008 [main] INFO server.session: DefaultSessionIdManager workerName=node0
dn4_1    | 2022-07-31 01:18:03,024 [main] INFO server.session: No SessionScavenger set, using defaults
dn4_1    | 2022-07-31 01:18:03,046 [main] INFO server.session: node0 Scavenging every 600000ms
dn4_1    | 2022-07-31 01:18:03,117 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2744dcae{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
dn4_1    | 2022-07-31 01:18:03,119 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1c297897{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
dn4_1    | 2022-07-31 01:18:03,531 [pool-26-thread-1] INFO raftlog.RaftLog: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-SegmentedRaftLog: commitIndex: updateToMax old=12, new=11, updated? false
dn4_1    | 2022-07-31 01:18:03,538 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn4_1    | 2022-07-31 01:18:03,546 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn4_1    | 2022-07-31 01:18:03,556 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn4_1    | 2022-07-31 01:18:03,563 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn4_1    | 2022-07-31 01:18:03,566 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn4_1    | 2022-07-31 01:18:03,574 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn4_1    | 2022-07-31 01:18:04,033 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn4_1    | 2022-07-31 01:18:04,034 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn4_1    | 2022-07-31 01:18:04,036 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn4_1    | 2022-07-31 01:18:04,037 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn4_1    | 2022-07-31 01:18:04,049 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn4_1    | 2022-07-31 01:18:04,051 [pool-26-thread-1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c: new RaftServerImpl for group-B3503D3184BF:[] with ContainerStateMachine:uninitialized
dn4_1    | 2022-07-31 01:18:04,064 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn4_1    | 2022-07-31 01:18:04,064 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn4_1    | 2022-07-31 01:18:04,075 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn4_1    | 2022-07-31 01:18:04,078 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn4_1    | 2022-07-31 01:18:04,086 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn4_1    | 2022-07-31 01:18:04,086 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn4_1    | 2022-07-31 01:18:04,086 [pool-26-thread-1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn4_1    | 2022-07-31 01:18:04,087 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn4_1    | 2022-07-31 01:18:04,087 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn4_1    | 2022-07-31 01:18:04,087 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn4_1    | 2022-07-31 01:18:04,099 [pool-26-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/c06adbe4-99b1-4236-a662-b3503d3184bf/in_use.lock acquired by nodename 6@6d05c26d6799
dn4_1    | 2022-07-31 01:18:04,100 [pool-26-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=3, votedFor=310a080d-f635-46ff-a53d-49cc9a09fa5c} from /data/metadata/ratis/c06adbe4-99b1-4236-a662-b3503d3184bf/current/raft-meta
dn4_1    | 2022-07-31 01:18:04,101 [pool-26-thread-1] INFO ratis.ContainerStateMachine: group-B3503D3184BF: Setting the last applied index to (t:3, i:4)
dn4_1    | 2022-07-31 01:18:04,105 [pool-26-thread-1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF: set configuration 3: [310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1], old=null
dn4_1    | 2022-07-31 01:18:04,113 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn4_1    | 2022-07-31 01:18:04,113 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn4_1    | 2022-07-31 01:18:04,117 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn4_1    | 2022-07-31 01:18:04,117 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn4_1    | 2022-07-31 01:18:04,117 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn4_1    | 2022-07-31 01:18:04,118 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn4_1    | 2022-07-31 01:18:04,124 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn1_1    | 2022-07-31 01:19:33,577 [Command processor thread] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-FFC093016E58: Succeed to remove RaftStorageDirectory Storage Directory /data/metadata/ratis/c57ff3c1-98cc-4640-a639-ffc093016e58
dn1_1    | 2022-07-31 01:19:33,582 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline PipelineID=c57ff3c1-98cc-4640-a639-ffc093016e58 command on datanode 609e7f2d-9474-472f-937f-8fa0a0bbb327.
dn1_1    | 2022-07-31 01:19:33,583 [Command processor thread] INFO server.RaftServer: 609e7f2d-9474-472f-937f-8fa0a0bbb327: remove  FOLLOWER 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246:t12, leader=3fc9f139-dd93-41e7-b235-52ce94d6fe3c, voted=609e7f2d-9474-472f-937f-8fa0a0bbb327, raftlog=609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-SegmentedRaftLog:OPENED:c29, conf=24: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null RUNNING
dn1_1    | 2022-07-31 01:19:33,583 [Command processor thread] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246: shutdown
dn1_1    | 2022-07-31 01:19:33,583 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-75041C4AA246,id=609e7f2d-9474-472f-937f-8fa0a0bbb327
dn1_1    | 2022-07-31 01:19:33,587 [Command processor thread] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-FollowerState
dn1_1    | 2022-07-31 01:19:33,587 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-FollowerState] INFO impl.FollowerState: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-FollowerState was interrupted
dn1_1    | 2022-07-31 01:19:33,588 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-75041C4AA246: Taking a snapshot at:(t:12, i:29) file /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/sm/snapshot.12_29
dn1_1    | 2022-07-31 01:19:33,588 [Command processor thread] INFO impl.StateMachineUpdater: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-StateMachineUpdater: set stopIndex = 29
dn1_1    | 2022-07-31 01:19:33,595 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-75041C4AA246: Finished taking a snapshot at:(t:12, i:29) file:/data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/sm/snapshot.12_29 took: 8 ms
dn1_1    | 2022-07-31 01:19:33,595 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-StateMachineUpdater] INFO impl.StateMachineUpdater: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-StateMachineUpdater: Took a snapshot at index 29
dn1_1    | 2022-07-31 01:19:33,595 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-StateMachineUpdater] INFO impl.StateMachineUpdater: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-StateMachineUpdater: snapshotIndex: updateIncreasingly 23 -> 29
dn1_1    | 2022-07-31 01:19:33,597 [Command processor thread] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246: closes. applyIndex: 29
dn1_1    | 2022-07-31 01:19:33,597 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
dn1_1    | 2022-07-31 01:19:33,598 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246-SegmentedRaftLogWorker close()
dn1_1    | 2022-07-31 01:19:33,604 [Command processor thread] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-75041C4AA246: Succeed to remove RaftStorageDirectory Storage Directory /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246
dn1_1    | 2022-07-31 01:19:33,604 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline PipelineID=369e0910-4276-41cc-941b-75041c4aa246 command on datanode 609e7f2d-9474-472f-937f-8fa0a0bbb327.
dn1_1    | 2022-07-31 01:19:33,605 [Command processor thread] INFO server.RaftServer: 609e7f2d-9474-472f-937f-8fa0a0bbb327: remove    LEADER 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1:t11, leader=609e7f2d-9474-472f-937f-8fa0a0bbb327, voted=609e7f2d-9474-472f-937f-8fa0a0bbb327, raftlog=609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-SegmentedRaftLog:OPENED:c43, conf=36: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null RUNNING
dn1_1    | 2022-07-31 01:19:33,605 [Command processor thread] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1: shutdown
dn1_1    | 2022-07-31 01:19:33,605 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-65A101075AF1,id=609e7f2d-9474-472f-937f-8fa0a0bbb327
dn1_1    | 2022-07-31 01:19:33,605 [Command processor thread] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-LeaderStateImpl
dn1_1    | 2022-07-31 01:19:33,606 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1->52aca038-7576-46a0-9ccd-b8aed29078e2-GrpcLogAppender-LogAppenderDaemon] WARN server.GrpcLogAppender: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1->52aca038-7576-46a0-9ccd-b8aed29078e2-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
dn1_1    | 2022-07-31 01:19:33,606 [Command processor thread] INFO impl.PendingRequests: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-PendingRequests: sendNotLeaderResponses
dn1_1    | 2022-07-31 01:19:33,614 [grpc-default-executor-1] INFO server.GrpcLogAppender: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1->52aca038-7576-46a0-9ccd-b8aed29078e2-AppendLogResponseHandler: follower responses appendEntries COMPLETED
dn1_1    | 2022-07-31 01:19:33,629 [grpc-default-executor-1] INFO leader.FollowerInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1->52aca038-7576-46a0-9ccd-b8aed29078e2: nextIndex: updateUnconditionally 44 -> 43
dn1_1    | 2022-07-31 01:19:33,607 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1->11cba143-91f8-47cb-8422-c32a1e2d51df-GrpcLogAppender-LogAppenderDaemon] WARN server.GrpcLogAppender: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1->11cba143-91f8-47cb-8422-c32a1e2d51df-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
dn1_1    | 2022-07-31 01:19:33,635 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-65A101075AF1: Taking a snapshot at:(t:11, i:43) file /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/sm/snapshot.11_43
dn1_1    | 2022-07-31 01:19:33,636 [Command processor thread] INFO impl.StateMachineUpdater: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-StateMachineUpdater: set stopIndex = 43
dn1_1    | 2022-07-31 01:19:33,636 [grpc-default-executor-1] INFO server.GrpcLogAppender: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1->11cba143-91f8-47cb-8422-c32a1e2d51df-AppendLogResponseHandler: follower responses appendEntries COMPLETED
dn2_1    | 2022-07-31 01:18:17,218 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/8145371a-b336-4e64-a95d-6999419922eb/current/log_inprogress_5
dn2_1    | 2022-07-31 01:18:19,773 [grpc-default-executor-0] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246: receive requestVote(ELECTION, 3fc9f139-dd93-41e7-b235-52ce94d6fe3c, group-75041C4AA246, 10, (t:9, i:23))
dn2_1    | 2022-07-31 01:18:19,787 [grpc-default-executor-0] INFO impl.VoteContext: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-CANDIDATE: reject ELECTION from 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: already has voted for 11cba143-91f8-47cb-8422-c32a1e2d51df at current term 10
dn2_1    | 2022-07-31 01:18:19,807 [grpc-default-executor-2] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246: receive requestVote(ELECTION, 609e7f2d-9474-472f-937f-8fa0a0bbb327, group-75041C4AA246, 10, (t:9, i:23))
dn2_1    | 2022-07-31 01:18:19,809 [grpc-default-executor-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1: receive requestVote(ELECTION, 609e7f2d-9474-472f-937f-8fa0a0bbb327, group-65A101075AF1, 9, (t:8, i:35))
dn2_1    | 2022-07-31 01:18:19,813 [grpc-default-executor-1] INFO impl.VoteContext: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-CANDIDATE: reject ELECTION from 609e7f2d-9474-472f-937f-8fa0a0bbb327: already has voted for 11cba143-91f8-47cb-8422-c32a1e2d51df at current term 9
dn2_1    | 2022-07-31 01:18:19,845 [grpc-default-executor-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1 replies to ELECTION vote request: 609e7f2d-9474-472f-937f-8fa0a0bbb327<-11cba143-91f8-47cb-8422-c32a1e2d51df#0:FAIL-t9. Peer's state: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1:t9, leader=null, voted=11cba143-91f8-47cb-8422-c32a1e2d51df, raftlog=11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-SegmentedRaftLog:OPENED:c35, conf=31: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-07-31 01:18:19,871 [grpc-default-executor-0] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246 replies to ELECTION vote request: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c<-11cba143-91f8-47cb-8422-c32a1e2d51df#0:FAIL-t10. Peer's state: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246:t10, leader=null, voted=11cba143-91f8-47cb-8422-c32a1e2d51df, raftlog=11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-SegmentedRaftLog:OPENED:c23, conf=10: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-07-31 01:18:19,885 [grpc-default-executor-2] INFO impl.VoteContext: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-CANDIDATE: reject ELECTION from 609e7f2d-9474-472f-937f-8fa0a0bbb327: already has voted for 11cba143-91f8-47cb-8422-c32a1e2d51df at current term 10
dn2_1    | 2022-07-31 01:18:19,959 [grpc-default-executor-2] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246 replies to ELECTION vote request: 609e7f2d-9474-472f-937f-8fa0a0bbb327<-11cba143-91f8-47cb-8422-c32a1e2d51df#0:FAIL-t10. Peer's state: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246:t10, leader=null, voted=11cba143-91f8-47cb-8422-c32a1e2d51df, raftlog=11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-SegmentedRaftLog:OPENED:c23, conf=10: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-07-31 01:18:20,108 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-LeaderElection1] INFO impl.LeaderElection: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-LeaderElection1: ELECTION REJECTED received 1 response(s) and 0 exception(s):
dn2_1    | 2022-07-31 01:18:20,135 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-LeaderElection1] INFO impl.LeaderElection:   Response 0: 11cba143-91f8-47cb-8422-c32a1e2d51df<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:FAIL-t10
dn2_1    | 2022-07-31 01:18:20,135 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-LeaderElection1] INFO impl.LeaderElection: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-LeaderElection1 ELECTION round 0: result REJECTED
dn2_1    | 2022-07-31 01:18:20,136 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-LeaderElection1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246: changes role from CANDIDATE to FOLLOWER at term 10 for REJECTED
dn2_1    | 2022-07-31 01:18:20,136 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-LeaderElection1] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: shutdown 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-LeaderElection1
dn2_1    | 2022-07-31 01:18:20,136 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-LeaderElection1] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: start 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-FollowerState
dn2_1    | 2022-07-31 01:18:20,147 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-LeaderElection3] INFO impl.LeaderElection: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-LeaderElection3: ELECTION REJECTED received 1 response(s) and 0 exception(s):
dn2_1    | 2022-07-31 01:18:20,155 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-LeaderElection3] INFO impl.LeaderElection:   Response 0: 11cba143-91f8-47cb-8422-c32a1e2d51df<-609e7f2d-9474-472f-937f-8fa0a0bbb327#0:FAIL-t9
dn2_1    | 2022-07-31 01:18:20,155 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-LeaderElection3] INFO impl.LeaderElection: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-LeaderElection3 ELECTION round 0: result REJECTED
dn2_1    | 2022-07-31 01:18:20,156 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-LeaderElection3] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1: changes role from CANDIDATE to FOLLOWER at term 9 for REJECTED
dn2_1    | 2022-07-31 01:18:20,156 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-LeaderElection3] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: shutdown 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-LeaderElection3
dn2_1    | 2022-07-31 01:18:20,156 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-LeaderElection3] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: start 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-FollowerState
dn2_1    | 2022-07-31 01:18:20,278 [grpc-default-executor-0] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1: receive requestVote(ELECTION, 52aca038-7576-46a0-9ccd-b8aed29078e2, group-65A101075AF1, 9, (t:8, i:35))
dn2_1    | 2022-07-31 01:18:20,278 [grpc-default-executor-0] INFO impl.VoteContext: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-FOLLOWER: reject ELECTION from 52aca038-7576-46a0-9ccd-b8aed29078e2: already has voted for 11cba143-91f8-47cb-8422-c32a1e2d51df at current term 9
om3_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.6.3.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jcl-over-slf4j-1.7.24.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om3_1    | STARTUP_MSG:   build = https://github.com/apache/ozone/57d620dbd4cb5dfec746cc16039d3843e64c181c ; compiled by 'runner' on 2022-07-31T00:52Z
om3_1    | STARTUP_MSG:   java = 11.0.14.1
om3_1    | ************************************************************/
om3_1    | 2022-07-31 01:17:27,986 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1    | 2022-07-31 01:17:37,674 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om3_1    | 2022-07-31 01:17:41,460 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om3_1    | 2022-07-31 01:17:41,930 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: omservice, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1    | 2022-07-31 01:17:41,947 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.omservice.om3: om3
om3_1    | 2022-07-31 01:17:41,957 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1    | 2022-07-31 01:17:42,102 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = MULTITENANCY_SCHEMA (version = 3)
om3_1    | 2022-07-31 01:17:44,989 [main] INFO reflections.Reflections: Reflections took 2529 ms to scan 1 urls, producing 112 keys and 332 values [using 2 cores]
om3_1    | 2022-07-31 01:17:45,165 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1    | 2022-07-31 01:17:47,741 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863]
om3_1    | 2022-07-31 01:17:47,936 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863]
om3_1    | 2022-07-31 01:17:50,890 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From eb852635f668/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2022-07-31 01:17:52,892 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From eb852635f668/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2022-07-31 01:17:54,895 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From eb852635f668/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2022-07-31 01:17:56,898 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From eb852635f668/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
dn4_1    | 2022-07-31 01:18:04,124 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn4_1    | 2022-07-31 01:18:04,125 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: new 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/c06adbe4-99b1-4236-a662-b3503d3184bf
dn4_1    | 2022-07-31 01:18:04,125 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn4_1    | 2022-07-31 01:18:04,127 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn4_1    | 2022-07-31 01:18:04,127 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn4_1    | 2022-07-31 01:18:04,138 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn4_1    | 2022-07-31 01:18:04,138 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn4_1    | 2022-07-31 01:18:04,139 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn4_1    | 2022-07-31 01:18:04,141 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn4_1    | 2022-07-31 01:18:04,142 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn4_1    | 2022-07-31 01:18:04,147 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn4_1    | 2022-07-31 01:18:04,149 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn4_1    | 2022-07-31 01:18:04,158 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn4_1    | 2022-07-31 01:18:04,142 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5d194314{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-831877007984081133/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
dn4_1    | 2022-07-31 01:18:04,171 [pool-26-thread-1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF: set configuration 0: [310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1], old=null
dn4_1    | 2022-07-31 01:18:04,179 [pool-26-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/c06adbe4-99b1-4236-a662-b3503d3184bf/current/log_0-0
dn4_1    | 2022-07-31 01:18:04,191 [pool-26-thread-1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF: set configuration 1: [310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1], old=null
dn4_1    | 2022-07-31 01:18:04,197 [pool-26-thread-1] INFO segmented.LogSegment: Successfully read 2 entries from segment file /data/metadata/ratis/c06adbe4-99b1-4236-a662-b3503d3184bf/current/log_1-2
dn4_1    | 2022-07-31 01:18:04,216 [pool-26-thread-1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF: set configuration 3: [310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1], old=null
dn4_1    | 2022-07-31 01:18:04,222 [pool-26-thread-1] INFO segmented.LogSegment: Successfully read 2 entries from segment file /data/metadata/ratis/c06adbe4-99b1-4236-a662-b3503d3184bf/current/log_inprogress_3
dn4_1    | 2022-07-31 01:18:04,223 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 4
dn4_1    | 2022-07-31 01:18:04,237 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 2
dn4_1    | 2022-07-31 01:18:04,242 [pool-26-thread-1] INFO raftlog.RaftLog: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-SegmentedRaftLog: commitIndex: updateToMax old=4, new=3, updated? false
dn4_1    | 2022-07-31 01:18:04,272 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn4_1    | 2022-07-31 01:18:04,273 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn4_1    | 2022-07-31 01:18:04,273 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn4_1    | 2022-07-31 01:18:04,273 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn4_1    | 2022-07-31 01:18:04,273 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn4_1    | 2022-07-31 01:18:04,274 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn4_1    | 2022-07-31 01:18:04,275 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn4_1    | 2022-07-31 01:18:04,275 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn4_1    | 2022-07-31 01:18:04,275 [main] INFO server.AbstractConnector: Started ServerConnector@670342a2{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
dn4_1    | 2022-07-31 01:18:04,275 [main] INFO server.Server: Started @48983ms
dn4_1    | 2022-07-31 01:18:04,276 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn4_1    | 2022-07-31 01:18:04,279 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn4_1    | 2022-07-31 01:18:04,280 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn4_1    | 2022-07-31 01:18:04,297 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
dn4_1    | 2022-07-31 01:18:04,301 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
dn4_1    | 2022-07-31 01:18:04,305 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
dn4_1    | 2022-07-31 01:18:04,319 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
dn4_1    | 2022-07-31 01:18:04,385 [Datanode State Machine Daemon Thread] INFO upgrade.UpgradeFinalizer: Running pre-finalized state validations for unfinalized layout features.
dn4_1    | 2022-07-31 01:18:04,416 [Datanode State Machine Daemon Thread] INFO upgrade.UpgradeFinalizer: Running first upgrade commands for unfinalized layout features.
dn4_1    | 2022-07-31 01:18:04,450 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@670d64ab] INFO util.JvmPauseMonitor: Starting JVM pause monitor
dn4_1    | 2022-07-31 01:18:04,998 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/10.9.0.20:9891
dn4_1    | 2022-07-31 01:18:05,016 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
dn4_1    | 2022-07-31 01:18:07,726 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn4_1    | 2022-07-31 01:18:09,719 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
dn2_1    | 2022-07-31 01:18:20,279 [grpc-default-executor-0] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1 replies to ELECTION vote request: 52aca038-7576-46a0-9ccd-b8aed29078e2<-11cba143-91f8-47cb-8422-c32a1e2d51df#0:FAIL-t9. Peer's state: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1:t9, leader=null, voted=11cba143-91f8-47cb-8422-c32a1e2d51df, raftlog=11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-SegmentedRaftLog:OPENED:c35, conf=31: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-07-31 01:18:25,109 [grpc-default-executor-0] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246: receive requestVote(ELECTION, 609e7f2d-9474-472f-937f-8fa0a0bbb327, group-75041C4AA246, 11, (t:9, i:23))
dn2_1    | 2022-07-31 01:18:25,110 [grpc-default-executor-0] INFO impl.VoteContext: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-FOLLOWER: accept ELECTION from 609e7f2d-9474-472f-937f-8fa0a0bbb327: our priority 0 <= candidate's priority 0
dn2_1    | 2022-07-31 01:18:25,110 [grpc-default-executor-0] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246: changes role from  FOLLOWER to FOLLOWER at term 11 for candidate:609e7f2d-9474-472f-937f-8fa0a0bbb327
dn2_1    | 2022-07-31 01:18:25,110 [grpc-default-executor-0] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: shutdown 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-FollowerState
dn2_1    | 2022-07-31 01:18:25,110 [grpc-default-executor-0] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: start 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-FollowerState
dn2_1    | 2022-07-31 01:18:25,110 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-FollowerState] INFO impl.FollowerState: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-FollowerState was interrupted
dn2_1    | 2022-07-31 01:18:25,117 [grpc-default-executor-0] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246 replies to ELECTION vote request: 609e7f2d-9474-472f-937f-8fa0a0bbb327<-11cba143-91f8-47cb-8422-c32a1e2d51df#0:OK-t11. Peer's state: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246:t11, leader=null, voted=609e7f2d-9474-472f-937f-8fa0a0bbb327, raftlog=11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-SegmentedRaftLog:OPENED:c23, conf=10: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-07-31 01:18:25,288 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-FollowerState] INFO impl.FollowerState: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5131471975ns, electionTimeout:5109ms
dn2_1    | 2022-07-31 01:18:25,288 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-FollowerState] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: shutdown 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-FollowerState
dn2_1    | 2022-07-31 01:18:25,288 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-FollowerState] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1: changes role from  FOLLOWER to CANDIDATE at term 9 for changeToCandidate
dn2_1    | 2022-07-31 01:18:25,289 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn2_1    | 2022-07-31 01:18:25,289 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-FollowerState] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: start 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-LeaderElection4
dn2_1    | 2022-07-31 01:18:25,297 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-LeaderElection4] INFO impl.LeaderElection: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-LeaderElection4 ELECTION round 0: submit vote requests at term 10 for 31: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-07-31 01:18:25,326 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-LeaderElection4] INFO impl.LeaderElection: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-LeaderElection4: ELECTION REJECTED received 1 response(s) and 0 exception(s):
dn2_1    | 2022-07-31 01:18:25,326 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-LeaderElection4] INFO impl.LeaderElection:   Response 0: 11cba143-91f8-47cb-8422-c32a1e2d51df<-609e7f2d-9474-472f-937f-8fa0a0bbb327#0:FAIL-t10
dn2_1    | 2022-07-31 01:18:25,326 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-LeaderElection4] INFO impl.LeaderElection: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-LeaderElection4 ELECTION round 0: result REJECTED
dn2_1    | 2022-07-31 01:18:25,326 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-LeaderElection4] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1: changes role from CANDIDATE to FOLLOWER at term 10 for REJECTED
dn2_1    | 2022-07-31 01:18:25,326 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-LeaderElection4] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: shutdown 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-LeaderElection4
dn2_1    | 2022-07-31 01:18:25,326 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-LeaderElection4] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: start 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-FollowerState
dn2_1    | 2022-07-31 01:18:30,186 [grpc-default-executor-0] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246: receive requestVote(ELECTION, 3fc9f139-dd93-41e7-b235-52ce94d6fe3c, group-75041C4AA246, 12, (t:9, i:23))
dn2_1    | 2022-07-31 01:18:30,187 [grpc-default-executor-0] INFO impl.VoteContext: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-FOLLOWER: accept ELECTION from 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: our priority 0 <= candidate's priority 1
dn2_1    | 2022-07-31 01:18:30,187 [grpc-default-executor-0] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246: changes role from  FOLLOWER to FOLLOWER at term 12 for candidate:3fc9f139-dd93-41e7-b235-52ce94d6fe3c
dn2_1    | 2022-07-31 01:18:30,187 [grpc-default-executor-0] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: shutdown 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-FollowerState
dn2_1    | 2022-07-31 01:18:30,187 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-FollowerState] INFO impl.FollowerState: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-FollowerState was interrupted
dn2_1    | 2022-07-31 01:18:30,187 [grpc-default-executor-0] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: start 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-FollowerState
dn2_1    | 2022-07-31 01:18:30,190 [grpc-default-executor-0] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246 replies to ELECTION vote request: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c<-11cba143-91f8-47cb-8422-c32a1e2d51df#0:OK-t12. Peer's state: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246:t12, leader=null, voted=3fc9f139-dd93-41e7-b235-52ce94d6fe3c, raftlog=11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-SegmentedRaftLog:OPENED:c23, conf=10: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-07-31 01:18:30,228 [grpc-default-executor-0] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246: receive requestVote(ELECTION, 609e7f2d-9474-472f-937f-8fa0a0bbb327, group-75041C4AA246, 12, (t:9, i:23))
dn2_1    | 2022-07-31 01:18:30,229 [grpc-default-executor-0] INFO impl.VoteContext: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-FOLLOWER: reject ELECTION from 609e7f2d-9474-472f-937f-8fa0a0bbb327: already has voted for 3fc9f139-dd93-41e7-b235-52ce94d6fe3c at current term 12
dn2_1    | 2022-07-31 01:18:30,229 [grpc-default-executor-0] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246 replies to ELECTION vote request: 609e7f2d-9474-472f-937f-8fa0a0bbb327<-11cba143-91f8-47cb-8422-c32a1e2d51df#0:FAIL-t12. Peer's state: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246:t12, leader=null, voted=3fc9f139-dd93-41e7-b235-52ce94d6fe3c, raftlog=11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-SegmentedRaftLog:OPENED:c23, conf=10: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-07-31 01:18:30,495 [grpc-default-executor-2] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1: receive requestVote(ELECTION, 609e7f2d-9474-472f-937f-8fa0a0bbb327, group-65A101075AF1, 11, (t:8, i:35))
dn2_1    | 2022-07-31 01:18:30,495 [grpc-default-executor-2] INFO impl.VoteContext: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-FOLLOWER: accept ELECTION from 609e7f2d-9474-472f-937f-8fa0a0bbb327: our priority 0 <= candidate's priority 1
dn2_1    | 2022-07-31 01:18:30,495 [grpc-default-executor-2] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1: changes role from  FOLLOWER to FOLLOWER at term 11 for candidate:609e7f2d-9474-472f-937f-8fa0a0bbb327
dn2_1    | 2022-07-31 01:18:30,496 [grpc-default-executor-2] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: shutdown 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-FollowerState
dn2_1    | 2022-07-31 01:18:30,496 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-FollowerState] INFO impl.FollowerState: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-FollowerState was interrupted
dn2_1    | 2022-07-31 01:18:30,497 [grpc-default-executor-2] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: start 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-FollowerState
dn2_1    | 2022-07-31 01:18:30,500 [11cba143-91f8-47cb-8422-c32a1e2d51df-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-75041C4AA246 with new leaderId: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c
dn2_1    | 2022-07-31 01:18:30,500 [11cba143-91f8-47cb-8422-c32a1e2d51df-server-thread1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246: change Leader from null to 3fc9f139-dd93-41e7-b235-52ce94d6fe3c at term 12 for appendEntries, leader elected after 26114ms
dn2_1    | 2022-07-31 01:18:30,502 [grpc-default-executor-2] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1 replies to ELECTION vote request: 609e7f2d-9474-472f-937f-8fa0a0bbb327<-11cba143-91f8-47cb-8422-c32a1e2d51df#0:OK-t11. Peer's state: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1:t11, leader=null, voted=609e7f2d-9474-472f-937f-8fa0a0bbb327, raftlog=11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-SegmentedRaftLog:OPENED:c35, conf=31: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-07-31 01:18:30,679 [11cba143-91f8-47cb-8422-c32a1e2d51df-server-thread1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246: set configuration 24: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-07-31 01:18:30,679 [11cba143-91f8-47cb-8422-c32a1e2d51df-server-thread1] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-SegmentedRaftLogWorker: Rolling segment log-10_23 to index:23
dn2_1    | 2022-07-31 01:18:30,682 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/current/log_inprogress_10 to /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/current/log_10-23
dn2_1    | 2022-07-31 01:18:30,694 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/current/log_inprogress_24
dn2_1    | 2022-07-31 01:18:31,308 [11cba143-91f8-47cb-8422-c32a1e2d51df-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-65A101075AF1 with new leaderId: 609e7f2d-9474-472f-937f-8fa0a0bbb327
dn2_1    | 2022-07-31 01:18:31,308 [11cba143-91f8-47cb-8422-c32a1e2d51df-server-thread1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1: change Leader from null to 609e7f2d-9474-472f-937f-8fa0a0bbb327 at term 11 for appendEntries, leader elected after 26667ms
dn2_1    | 2022-07-31 01:18:31,378 [11cba143-91f8-47cb-8422-c32a1e2d51df-server-thread1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1: set configuration 36: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-07-31 01:18:31,378 [11cba143-91f8-47cb-8422-c32a1e2d51df-server-thread1] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-SegmentedRaftLogWorker: Rolling segment log-31_35 to index:35
dn4_1    | 2022-07-31 01:18:09,729 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
dn4_1    | 2022-07-31 01:18:10,086 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 310a080d-f635-46ff-a53d-49cc9a09fa5c
dn4_1    | 2022-07-31 01:18:10,137 [310a080d-f635-46ff-a53d-49cc9a09fa5c-impl-thread1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF: start as a follower, conf=3: [310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1], old=null
dn4_1    | 2022-07-31 01:18:10,206 [310a080d-f635-46ff-a53d-49cc9a09fa5c-impl-thread1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF: changes role from      null to FOLLOWER at term 3 for startAsFollower
dn4_1    | 2022-07-31 01:18:10,207 [310a080d-f635-46ff-a53d-49cc9a09fa5c-impl-thread1] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: start 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-FollowerState
dn4_1    | 2022-07-31 01:18:10,219 [310a080d-f635-46ff-a53d-49cc9a09fa5c-impl-thread2] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610: start as a follower, conf=3: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn4_1    | 2022-07-31 01:18:10,257 [310a080d-f635-46ff-a53d-49cc9a09fa5c-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B3503D3184BF,id=310a080d-f635-46ff-a53d-49cc9a09fa5c
dn4_1    | 2022-07-31 01:18:10,286 [310a080d-f635-46ff-a53d-49cc9a09fa5c-impl-thread2] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610: changes role from      null to FOLLOWER at term 11 for startAsFollower
dn4_1    | 2022-07-31 01:18:10,291 [310a080d-f635-46ff-a53d-49cc9a09fa5c-impl-thread2] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: start 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-FollowerState
dn4_1    | 2022-07-31 01:18:10,299 [310a080d-f635-46ff-a53d-49cc9a09fa5c-impl-thread2] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7BB2A1276610,id=310a080d-f635-46ff-a53d-49cc9a09fa5c
dn4_1    | 2022-07-31 01:18:10,332 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.RaftServer: 310a080d-f635-46ff-a53d-49cc9a09fa5c: start RPC server
dn4_1    | 2022-07-31 01:18:10,343 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 310a080d-f635-46ff-a53d-49cc9a09fa5c: GrpcService started, listening on 9856
dn4_1    | 2022-07-31 01:18:10,357 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 310a080d-f635-46ff-a53d-49cc9a09fa5c: GrpcService started, listening on 9857
dn4_1    | 2022-07-31 01:18:10,366 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 310a080d-f635-46ff-a53d-49cc9a09fa5c: GrpcService started, listening on 9858
dn4_1    | 2022-07-31 01:18:10,382 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 310a080d-f635-46ff-a53d-49cc9a09fa5c is started using port 9858 for RATIS
dn4_1    | 2022-07-31 01:18:10,383 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 310a080d-f635-46ff-a53d-49cc9a09fa5c is started using port 9857 for RATIS_ADMIN
dn4_1    | 2022-07-31 01:18:10,383 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 310a080d-f635-46ff-a53d-49cc9a09fa5c is started using port 9856 for RATIS_SERVER
dn4_1    | 2022-07-31 01:18:10,472 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
dn4_1    | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
dn4_1    | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
dn4_1    | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:660)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:298)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:493)
dn4_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn4_1    | Caused by: java.util.concurrent.TimeoutException
dn4_1    | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
dn4_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn4_1    | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
dn4_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn4_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn4_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn4_1    | 	... 1 more
dn4_1    | 2022-07-31 01:18:10,538 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$487/0x0000000840571440@553feac] INFO util.JvmPauseMonitor: JvmPauseMonitor-310a080d-f635-46ff-a53d-49cc9a09fa5c: Started
dn4_1    | 2022-07-31 01:18:11,767 [EndpointStateMachine task thread for recon/10.9.0.20:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
dn4_1    | java.net.SocketTimeoutException: Call From 6d05c26d6799/10.9.0.18 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.18:48198 remote=recon/10.9.0.20:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
dn4_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
dn4_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
dn4_1    | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
dn4_1    | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
dn4_1    | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
dn4_1    | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
dn4_1    | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
dn4_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
dn4_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
dn4_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
dn4_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
om2_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1    | 2022-07-31 01:17:29,657 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1    | /************************************************************
om2_1    | STARTUP_MSG: Starting OzoneManager
om2_1    | STARTUP_MSG:   host = 14febe149d7f/10.9.0.12
om2_1    | STARTUP_MSG:   args = [--upgrade]
om2_1    | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
dn2_1    | 2022-07-31 01:18:31,379 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/current/log_inprogress_31 to /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/current/log_31-35
dn2_1    | 2022-07-31 01:18:31,382 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/current/log_inprogress_36
dn2_1    | 2022-07-31 01:18:47,044 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn2_1    | 2022-07-31 01:18:47,046 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn2_1    | 2022-07-31 01:18:47,046 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn2_1    | 2022-07-31 01:18:47,051 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn2_1    | 2022-07-31 01:18:47,051 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn2_1    | 2022-07-31 01:18:47,052 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-07-31 01:18:47,053 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-07-31 01:18:47,059 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn2_1    | 2022-07-31 01:18:47,059 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn2_1    | 2022-07-31 01:18:47,060 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn2_1    | 2022-07-31 01:18:47,060 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn2_1    | 2022-07-31 01:18:47,060 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn2_1    | 2022-07-31 01:18:47,060 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-07-31 01:18:47,061 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-07-31 01:18:47,061 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
dn5_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
dn5_1    | 2022-07-31 01:17:24,142 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
dn5_1    | /************************************************************
dn5_1    | STARTUP_MSG: Starting HddsDatanodeService
dn5_1    | STARTUP_MSG:   host = 6c1f77753501/10.9.0.19
dn5_1    | STARTUP_MSG:   args = []
dn5_1    | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
dn2_1    | 2022-07-31 01:18:47,061 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn2_1    | 2022-07-31 01:18:47,061 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn2_1    | 2022-07-31 01:18:47,061 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn2_1    | 2022-07-31 01:18:47,061 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn2_1    | 2022-07-31 01:18:47,061 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-07-31 01:18:47,062 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-07-31 01:18:47,062 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn2_1    | 2022-07-31 01:18:47,062 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn2_1    | 2022-07-31 01:18:47,062 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn2_1    | 2022-07-31 01:18:47,062 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 1 to close, current state is: CLOSING
dn2_1    | 2022-07-31 01:18:47,062 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn2_1    | 2022-07-31 01:18:47,062 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-07-31 01:18:47,062 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn2_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn2_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn2_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn2_1    | 2022-07-31 01:19:01,484 [ContainerOp-369e0910-4276-41cc-941b-75041c4aa246-0] INFO keyvalue.KeyValueContainer: Container 1001 is synced with bcsId 8.
dn2_1    | 2022-07-31 01:19:01,493 [ContainerOp-369e0910-4276-41cc-941b-75041c4aa246-0] INFO keyvalue.KeyValueContainer: Container 1001 is synced with bcsId 8.
dn2_1    | 2022-07-31 01:19:01,531 [ContainerOp-369e0910-4276-41cc-941b-75041c4aa246-0] INFO keyvalue.KeyValueContainer: Container 1001 is closed with bcsId 8.
dn2_1    | 2022-07-31 01:19:01,746 [ContainerOp-369e0910-4276-41cc-941b-75041c4aa246-1] INFO keyvalue.KeyValueContainer: Container 2002 is synced with bcsId 21.
dn2_1    | 2022-07-31 01:19:01,748 [ContainerOp-369e0910-4276-41cc-941b-75041c4aa246-1] INFO keyvalue.KeyValueContainer: Container 2002 is synced with bcsId 21.
dn1_1    | 2022-07-31 01:19:33,636 [grpc-default-executor-1] INFO leader.FollowerInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1->11cba143-91f8-47cb-8422-c32a1e2d51df: nextIndex: updateUnconditionally 44 -> 43
dn1_1    | 2022-07-31 01:19:33,639 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-65A101075AF1: Finished taking a snapshot at:(t:11, i:43) file:/data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/sm/snapshot.11_43 took: 4 ms
dn1_1    | 2022-07-31 01:19:33,642 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-StateMachineUpdater] INFO impl.StateMachineUpdater: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-StateMachineUpdater: Took a snapshot at index 43
dn1_1    | 2022-07-31 01:19:33,642 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-StateMachineUpdater] INFO impl.StateMachineUpdater: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-StateMachineUpdater: snapshotIndex: updateIncreasingly 35 -> 43
dn1_1    | 2022-07-31 01:19:33,643 [Command processor thread] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1: closes. applyIndex: 43
dn1_1    | 2022-07-31 01:19:33,644 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
dn1_1    | 2022-07-31 01:19:33,645 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1-SegmentedRaftLogWorker close()
dn1_1    | 2022-07-31 01:19:33,649 [Command processor thread] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-65A101075AF1: Succeed to remove RaftStorageDirectory Storage Directory /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1
dn1_1    | 2022-07-31 01:19:33,649 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline PipelineID=67b1342c-3bb3-4b48-a218-65a101075af1 command on datanode 609e7f2d-9474-472f-937f-8fa0a0bbb327.
dn1_1    | 2022-07-31 01:19:34,907 [org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@1c34365c] INFO commandhandler.DeleteBlocksCommandHandler: Start to delete container blocks, TXIDs=[1(0)], numOfContainers=1, numOfBlocks=3
dn1_1    | 2022-07-31 01:20:03,589 [Command processor thread] INFO server.RaftServer: 609e7f2d-9474-472f-937f-8fa0a0bbb327: addNew group-B37BD276617A:[609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1] returns group-B37BD276617A:java.util.concurrent.CompletableFuture@5450fd43[Not completed]
dn1_1    | 2022-07-31 01:20:03,597 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327: new RaftServerImpl for group-B37BD276617A:[609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1] with ContainerStateMachine:uninitialized
dn1_1    | 2022-07-31 01:20:03,597 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn1_1    | 2022-07-31 01:20:03,597 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn1_1    | 2022-07-31 01:20:03,598 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn1_1    | 2022-07-31 01:20:03,598 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn1_1    | 2022-07-31 01:20:03,598 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn1_1    | 2022-07-31 01:20:03,598 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn1_1    | 2022-07-31 01:20:03,598 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A: ConfigurationManager, init=-1: [609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1], old=null, confs=<EMPTY_MAP>
dn1_1    | 2022-07-31 01:20:03,598 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn1_1    | 2022-07-31 01:20:03,607 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn1_1    | 2022-07-31 01:20:03,607 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn1_1    | 2022-07-31 01:20:03,607 [pool-42-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/f058582a-59a2-4a37-8200-b37bd276617a does not exist. Creating ...
dn1_1    | 2022-07-31 01:20:03,611 [pool-42-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/f058582a-59a2-4a37-8200-b37bd276617a/in_use.lock acquired by nodename 8@b5a69c4cb320
dn1_1    | 2022-07-31 01:20:03,613 [pool-42-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/f058582a-59a2-4a37-8200-b37bd276617a has been successfully formatted.
dn1_1    | 2022-07-31 01:20:03,614 [pool-42-thread-1] INFO ratis.ContainerStateMachine: group-B37BD276617A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn1_1    | 2022-07-31 01:20:03,626 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn1_1    | 2022-07-31 01:20:03,627 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn1_1    | 2022-07-31 01:20:03,627 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn1_1    | 2022-07-31 01:20:03,627 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2022-07-31 01:20:03,627 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn1_1    | 2022-07-31 01:20:03,628 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2022-07-31 01:20:03,630 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn1_1    | 2022-07-31 01:20:03,630 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn1_1    | 2022-07-31 01:20:03,630 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: new 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/f058582a-59a2-4a37-8200-b37bd276617a
dn1_1    | 2022-07-31 01:20:03,631 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn1_1    | 2022-07-31 01:20:03,631 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn1_1    | 2022-07-31 01:20:03,631 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2022-07-31 01:20:03,633 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn1_1    | 2022-07-31 01:20:03,636 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn1_1    | 2022-07-31 01:20:03,636 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn1_1    | 2022-07-31 01:20:03,639 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn1_1    | 2022-07-31 01:20:03,639 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn3_1    | 2022-07-31 01:19:01,774 [ContainerOp-369e0910-4276-41cc-941b-75041c4aa246-1] INFO keyvalue.KeyValueContainer: Container 2002 is closed with bcsId 21.
dn3_1    | 2022-07-31 01:19:01,863 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn3_1    | 2022-07-31 01:19:01,864 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn3_1    | 2022-07-31 01:19:01,865 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn3_1    | 2022-07-31 01:19:01,865 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 2001 to close, current state is: CLOSING
dn3_1    | 2022-07-31 01:19:01,865 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn3_1    | 2022-07-31 01:19:01,866 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn3_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn3_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn3_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn3_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn3_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn3_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn3_1    | 2022-07-31 01:19:01,876 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn3_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn3_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn3_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn3_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn3_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn3_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn3_1    | 2022-07-31 01:19:01,877 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn3_1    | 2022-07-31 01:19:01,889 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn3_1    | 2022-07-31 01:19:01,889 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn3_1    | 2022-07-31 01:19:01,889 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 2001 to close, current state is: CLOSING
dn3_1    | 2022-07-31 01:19:01,889 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn3_1    | 2022-07-31 01:19:01,889 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn3_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn3_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn3_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn3_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn3_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn3_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn3_1    | 2022-07-31 01:19:01,889 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn3_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn3_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn3_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn3_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn3_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn3_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn3_1    | 2022-07-31 01:19:01,889 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn3_1    | 2022-07-31 01:19:01,889 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn1_1    | 2022-07-31 01:20:03,645 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn1_1    | 2022-07-31 01:20:03,646 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn1_1    | 2022-07-31 01:20:03,646 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn1_1    | 2022-07-31 01:20:03,646 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn1_1    | 2022-07-31 01:20:03,647 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn1_1    | 2022-07-31 01:20:03,665 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn1_1    | 2022-07-31 01:20:03,665 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn1_1    | 2022-07-31 01:20:03,665 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn1_1    | 2022-07-31 01:20:03,665 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn1_1    | 2022-07-31 01:20:03,665 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn1_1    | 2022-07-31 01:20:03,666 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn1_1    | 2022-07-31 01:20:03,666 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn1_1    | 2022-07-31 01:20:03,667 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn1_1    | 2022-07-31 01:20:03,667 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn1_1    | 2022-07-31 01:20:03,667 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn1_1    | 2022-07-31 01:20:03,667 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn1_1    | 2022-07-31 01:20:03,668 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A: start as a follower, conf=-1: [609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1], old=null
dn1_1    | 2022-07-31 01:20:03,668 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn1_1    | 2022-07-31 01:20:03,668 [pool-42-thread-1] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-FollowerState
dn1_1    | 2022-07-31 01:20:03,673 [pool-42-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B37BD276617A,id=609e7f2d-9474-472f-937f-8fa0a0bbb327
dn1_1    | 2022-07-31 01:20:03,681 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=f058582a-59a2-4a37-8200-b37bd276617a
dn1_1    | 2022-07-31 01:20:03,682 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=f058582a-59a2-4a37-8200-b37bd276617a.
dn1_1    | 2022-07-31 01:20:03,682 [Command processor thread] INFO server.RaftServer: 609e7f2d-9474-472f-937f-8fa0a0bbb327: addNew group-7781FFA9F9E7:[310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0] returns group-7781FFA9F9E7:java.util.concurrent.CompletableFuture@14d42b93[Not completed]
dn1_1    | 2022-07-31 01:20:03,684 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327: new RaftServerImpl for group-7781FFA9F9E7:[310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0] with ContainerStateMachine:uninitialized
dn1_1    | 2022-07-31 01:20:03,684 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn1_1    | 2022-07-31 01:20:03,684 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn1_1    | 2022-07-31 01:20:03,684 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn1_1    | 2022-07-31 01:20:03,684 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn1_1    | 2022-07-31 01:20:03,685 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn1_1    | 2022-07-31 01:20:03,685 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn1_1    | 2022-07-31 01:20:03,685 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7: ConfigurationManager, init=-1: [310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0], old=null, confs=<EMPTY_MAP>
dn1_1    | 2022-07-31 01:20:03,685 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn1_1    | 2022-07-31 01:20:03,685 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn1_1    | 2022-07-31 01:20:03,686 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn1_1    | 2022-07-31 01:20:03,686 [pool-42-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/ae7040c6-f723-491f-8b9e-7781ffa9f9e7 does not exist. Creating ...
dn1_1    | 2022-07-31 01:20:03,688 [pool-42-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/ae7040c6-f723-491f-8b9e-7781ffa9f9e7/in_use.lock acquired by nodename 8@b5a69c4cb320
dn1_1    | 2022-07-31 01:20:03,692 [pool-42-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/ae7040c6-f723-491f-8b9e-7781ffa9f9e7 has been successfully formatted.
dn1_1    | 2022-07-31 01:20:03,695 [pool-42-thread-1] INFO ratis.ContainerStateMachine: group-7781FFA9F9E7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn1_1    | 2022-07-31 01:20:03,697 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn1_1    | 2022-07-31 01:20:03,697 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn1_1    | 2022-07-31 01:20:03,698 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn1_1    | 2022-07-31 01:20:03,698 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2022-07-31 01:20:03,698 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om2_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.6.3.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jcl-over-slf4j-1.7.24.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om2_1    | STARTUP_MSG:   build = https://github.com/apache/ozone/57d620dbd4cb5dfec746cc16039d3843e64c181c ; compiled by 'runner' on 2022-07-31T00:52Z
om2_1    | STARTUP_MSG:   java = 11.0.14.1
om2_1    | ************************************************************/
om2_1    | 2022-07-31 01:17:29,736 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1    | 2022-07-31 01:17:39,453 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om2_1    | 2022-07-31 01:17:42,869 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om2_1    | 2022-07-31 01:17:43,779 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: omservice, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1    | 2022-07-31 01:17:43,780 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.omservice.om2: om2
om2_1    | 2022-07-31 01:17:43,792 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1    | 2022-07-31 01:17:44,146 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = MULTITENANCY_SCHEMA (version = 3)
om2_1    | 2022-07-31 01:17:47,021 [main] INFO reflections.Reflections: Reflections took 2227 ms to scan 1 urls, producing 112 keys and 332 values [using 2 cores]
om2_1    | 2022-07-31 01:17:47,437 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1    | 2022-07-31 01:17:49,642 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863]
om2_1    | 2022-07-31 01:17:49,796 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863]
om2_1    | 2022-07-31 01:17:52,517 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 14febe149d7f/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1    | 2022-07-31 01:17:54,518 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 14febe149d7f/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1    | 2022-07-31 01:17:56,520 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 14febe149d7f/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1    | 2022-07-31 01:17:58,522 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 14febe149d7f/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
dn4_1    | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
dn4_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
dn4_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
dn4_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn4_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn4_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn4_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn4_1    | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.18:48198 remote=recon/10.9.0.20:9891]
dn4_1    | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
dn4_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
dn4_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
dn4_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
dn4_1    | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
dn4_1    | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
dn4_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn4_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn4_1    | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
dn4_1    | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
dn4_1    | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
dn4_1    | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
dn4_1    | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
dn4_1    | 2022-07-31 01:18:15,294 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-FollowerState] INFO impl.FollowerState: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5087206851ns, electionTimeout:5002ms
dn4_1    | 2022-07-31 01:18:15,301 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-FollowerState] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: shutdown 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-FollowerState
dn4_1    | 2022-07-31 01:18:15,301 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-FollowerState] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
dn4_1    | 2022-07-31 01:18:15,304 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn4_1    | 2022-07-31 01:18:15,304 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-FollowerState] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: start 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-LeaderElection1
dn4_1    | 2022-07-31 01:18:15,353 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-FollowerState] INFO impl.FollowerState: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5058197673ns, electionTimeout:5039ms
dn4_1    | 2022-07-31 01:18:15,365 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-FollowerState] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: shutdown 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-FollowerState
dn4_1    | 2022-07-31 01:18:15,366 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-FollowerState] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610: changes role from  FOLLOWER to CANDIDATE at term 11 for changeToCandidate
dn4_1    | 2022-07-31 01:18:15,368 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn4_1    | 2022-07-31 01:18:15,369 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-FollowerState] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: start 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-LeaderElection2
dn4_1    | 2022-07-31 01:18:15,488 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-LeaderElection1] INFO impl.LeaderElection: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-LeaderElection1 ELECTION round 0: submit vote requests at term 4 for 3: [310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1], old=null
dn4_1    | 2022-07-31 01:18:15,500 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-LeaderElection1] INFO impl.LeaderElection: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-LeaderElection1 ELECTION round 0: result PASSED (term=4)
dn4_1    | 2022-07-31 01:18:15,511 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-LeaderElection2] INFO impl.LeaderElection: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-LeaderElection2 ELECTION round 0: submit vote requests at term 12 for 3: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn4_1    | 2022-07-31 01:18:15,517 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-LeaderElection1] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: shutdown 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-LeaderElection1
dn4_1    | 2022-07-31 01:18:15,527 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-LeaderElection1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF: changes role from CANDIDATE to LEADER at term 4 for changeToLeader
dn4_1    | 2022-07-31 01:18:15,527 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-B3503D3184BF with new leaderId: 310a080d-f635-46ff-a53d-49cc9a09fa5c
dn4_1    | 2022-07-31 01:18:15,644 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-LeaderElection1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF: change Leader from null to 310a080d-f635-46ff-a53d-49cc9a09fa5c at term 4 for becomeLeader, leader elected after 11414ms
dn4_1    | 2022-07-31 01:18:15,798 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn4_1    | 2022-07-31 01:18:15,856 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn4_1    | 2022-07-31 01:18:15,898 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn4_1    | 2022-07-31 01:18:15,972 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn4_1    | 2022-07-31 01:18:15,980 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn4_1    | 2022-07-31 01:18:16,035 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn4_1    | 2022-07-31 01:18:16,075 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn4_1    | 2022-07-31 01:18:16,199 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn4_1    | 2022-07-31 01:18:16,228 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-LeaderElection1] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: start 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-LeaderStateImpl
dn4_1    | 2022-07-31 01:18:16,419 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-SegmentedRaftLogWorker: Rolling segment log-3_4 to index:4
dn4_1    | 2022-07-31 01:18:16,475 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/c06adbe4-99b1-4236-a662-b3503d3184bf/current/log_inprogress_3 to /data/metadata/ratis/c06adbe4-99b1-4236-a662-b3503d3184bf/current/log_3-4
dn4_1    | 2022-07-31 01:18:16,559 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/c06adbe4-99b1-4236-a662-b3503d3184bf/current/log_inprogress_5
dn4_1    | 2022-07-31 01:18:16,600 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-LeaderElection1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF: set configuration 5: [310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1], old=null
dn4_1    | 2022-07-31 01:18:17,942 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$487/0x0000000840571440@553feac] WARN util.JvmPauseMonitor: JvmPauseMonitor-310a080d-f635-46ff-a53d-49cc9a09fa5c: Detected pause in JVM or host machine (eg GC): pause of approximately 285109593ns.
dn4_1    | GC pool 'ParNew' had collection(s): count=1 time=306ms
dn4_1    | 2022-07-31 01:18:19,837 [grpc-default-executor-0] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610: receive requestVote(ELECTION, 3fc9f139-dd93-41e7-b235-52ce94d6fe3c, group-7BB2A1276610, 12, (t:11, i:12))
dn4_1    | 2022-07-31 01:18:19,839 [grpc-default-executor-0] INFO impl.VoteContext: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-CANDIDATE: reject ELECTION from 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: already has voted for 310a080d-f635-46ff-a53d-49cc9a09fa5c at current term 12
dn4_1    | 2022-07-31 01:18:19,876 [grpc-default-executor-0] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610 replies to ELECTION vote request: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c<-310a080d-f635-46ff-a53d-49cc9a09fa5c#0:FAIL-t12. Peer's state: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610:t12, leader=null, voted=310a080d-f635-46ff-a53d-49cc9a09fa5c, raftlog=310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-SegmentedRaftLog:OPENED:c12, conf=3: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn4_1    | 2022-07-31 01:18:20,198 [grpc-default-executor-0] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610: receive requestVote(ELECTION, 52aca038-7576-46a0-9ccd-b8aed29078e2, group-7BB2A1276610, 12, (t:11, i:12))
dn4_1    | 2022-07-31 01:18:20,199 [grpc-default-executor-0] INFO impl.VoteContext: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-CANDIDATE: reject ELECTION from 52aca038-7576-46a0-9ccd-b8aed29078e2: already has voted for 310a080d-f635-46ff-a53d-49cc9a09fa5c at current term 12
dn4_1    | 2022-07-31 01:18:20,199 [grpc-default-executor-0] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610 replies to ELECTION vote request: 52aca038-7576-46a0-9ccd-b8aed29078e2<-310a080d-f635-46ff-a53d-49cc9a09fa5c#0:FAIL-t12. Peer's state: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610:t12, leader=null, voted=310a080d-f635-46ff-a53d-49cc9a09fa5c, raftlog=310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-SegmentedRaftLog:OPENED:c12, conf=3: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn4_1    | 2022-07-31 01:18:20,305 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-LeaderElection2] INFO impl.LeaderElection: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-LeaderElection2: ELECTION REJECTED received 2 response(s) and 0 exception(s):
dn4_1    | 2022-07-31 01:18:20,313 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-LeaderElection2] INFO impl.LeaderElection:   Response 0: 310a080d-f635-46ff-a53d-49cc9a09fa5c<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:FAIL-t12
dn4_1    | 2022-07-31 01:18:20,313 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-LeaderElection2] INFO impl.LeaderElection:   Response 1: 310a080d-f635-46ff-a53d-49cc9a09fa5c<-52aca038-7576-46a0-9ccd-b8aed29078e2#0:FAIL-t12
dn4_1    | 2022-07-31 01:18:20,314 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-LeaderElection2] INFO impl.LeaderElection: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-LeaderElection2 ELECTION round 0: result REJECTED
dn4_1    | 2022-07-31 01:18:20,315 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-LeaderElection2] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610: changes role from CANDIDATE to FOLLOWER at term 12 for REJECTED
dn4_1    | 2022-07-31 01:18:20,321 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-LeaderElection2] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: shutdown 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-LeaderElection2
dn4_1    | 2022-07-31 01:18:20,321 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-LeaderElection2] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: start 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-FollowerState
dn4_1    | 2022-07-31 01:18:25,472 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-FollowerState] INFO impl.FollowerState: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5151092859ns, electionTimeout:5114ms
dn4_1    | 2022-07-31 01:18:25,473 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-FollowerState] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: shutdown 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-FollowerState
dn4_1    | 2022-07-31 01:18:25,473 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-FollowerState] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610: changes role from  FOLLOWER to CANDIDATE at term 12 for changeToCandidate
om2_1    | 2022-07-31 01:18:00,523 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 14febe149d7f/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1    | 2022-07-31 01:18:02,525 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 14febe149d7f/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1    | 2022-07-31 01:18:04,527 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 14febe149d7f/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1    | 2022-07-31 01:18:06,528 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 14febe149d7f/10.9.0.12 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1    | 2022-07-31 01:18:12,374 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1    | 2022-07-31 01:18:13,441 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om2_1    | 2022-07-31 01:18:13,444 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om2_1    | 2022-07-31 01:18:13,762 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om2_1    | 2022-07-31 01:18:13,949 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1    | 2022-07-31 01:18:13,951 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om2_1    | 2022-07-31 01:18:13,978 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om2_1    | 2022-07-31 01:18:14,558 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om2_1    | 2022-07-31 01:18:14,597 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1    | 2022-07-31 01:18:14,770 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: omservice and peers: om2:9872, om1:9872, om3:9872
om2_1    | 2022-07-31 01:18:14,841 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:6, i:98)
om2_1    | 2022-07-31 01:18:15,056 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om2_1    | 2022-07-31 01:18:15,915 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om2_1    | 2022-07-31 01:18:15,918 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1    | 2022-07-31 01:18:15,923 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om2_1    | 2022-07-31 01:18:15,924 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1    | 2022-07-31 01:18:15,924 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1    | 2022-07-31 01:18:15,927 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om2_1    | 2022-07-31 01:18:15,935 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1    | 2022-07-31 01:18:15,978 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om2_1    | 2022-07-31 01:18:15,981 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1    | 2022-07-31 01:18:16,247 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om2_1    | 2022-07-31 01:18:16,281 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om2_1    | 2022-07-31 01:18:18,657 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om2_1    | 2022-07-31 01:18:18,684 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om2_1    | 2022-07-31 01:18:18,694 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om2_1    | 2022-07-31 01:18:18,697 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1    | 2022-07-31 01:18:18,701 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1    | 2022-07-31 01:18:18,704 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1    | 2022-07-31 01:18:18,750 [om2-impl-thread1] INFO server.RaftServer: om2: found a subdirectory /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c
om2_1    | 2022-07-31 01:18:18,810 [main] INFO server.RaftServer: om2: addNew group-D66704EFC61C:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-D66704EFC61C:java.util.concurrent.CompletableFuture@4ef4f627[Not completed]
om2_1    | 2022-07-31 01:18:18,845 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om2_1    | 2022-07-31 01:18:19,143 [main] INFO om.OzoneManager: Creating RPC Server
om2_1    | 2022-07-31 01:18:19,197 [pool-26-thread-1] INFO server.RaftServer$Division: om2: new RaftServerImpl for group-D66704EFC61C:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om2_1    | 2022-07-31 01:18:19,281 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om2_1    | 2022-07-31 01:18:19,325 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om2_1    | 2022-07-31 01:18:19,327 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om2_1    | 2022-07-31 01:18:19,329 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1    | 2022-07-31 01:18:19,337 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1    | 2022-07-31 01:18:19,341 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om2_1    | 2022-07-31 01:18:19,547 [pool-26-thread-1] INFO server.RaftServer$Division: om2@group-D66704EFC61C: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om2_1    | 2022-07-31 01:18:19,550 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1    | 2022-07-31 01:18:19,599 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om2_1    | 2022-07-31 01:18:19,611 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn5_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
dn5_1    | STARTUP_MSG:   build = https://github.com/apache/ozone/57d620dbd4cb5dfec746cc16039d3843e64c181c ; compiled by 'runner' on 2022-07-31T00:51Z
dn5_1    | STARTUP_MSG:   java = 11.0.14.1
dn5_1    | ************************************************************/
dn5_1    | 2022-07-31 01:17:24,171 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
dn5_1    | 2022-07-31 01:17:24,683 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
dn5_1    | 2022-07-31 01:17:25,498 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
dn5_1    | 2022-07-31 01:17:26,853 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
dn5_1    | 2022-07-31 01:17:26,869 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
dn5_1    | 2022-07-31 01:17:28,492 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:6c1f77753501 ip:10.9.0.19
dn5_1    | 2022-07-31 01:17:30,322 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = DATANODE_SCHEMA_V3 (version = 4)
dn5_1    | 2022-07-31 01:17:32,072 [main] INFO reflections.Reflections: Reflections took 1468 ms to scan 2 urls, producing 89 keys and 198 values 
dn5_1    | 2022-07-31 01:17:32,578 [main] INFO upgrade.HDDSLayoutVersionManager: Registering Upgrade Action : DatanodeSchemaV3FinalizeAction
dn5_1    | 2022-07-31 01:17:32,813 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
dn5_1    | 2022-07-31 01:17:34,304 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/hdds/scmUsed: 8342 at 2022-07-31T01:17:01.335Z
dn5_1    | 2022-07-31 01:17:34,399 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
dn5_1    | 2022-07-31 01:17:34,423 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
dn5_1    | 2022-07-31 01:17:34,442 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
dn5_1    | 2022-07-31 01:17:34,622 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
dn5_1    | 2022-07-31 01:17:34,743 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn5_1    | 2022-07-31 01:17:34,778 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/metadata/ratis/scmUsed: 4096 at 2022-07-31T01:17:01.346Z
dn5_1    | 2022-07-31 01:17:34,792 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
dn5_1    | 2022-07-31 01:17:34,793 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
dn5_1    | 2022-07-31 01:17:34,831 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
dn5_1    | 2022-07-31 01:17:34,957 [Thread-3] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
dn5_1    | 2022-07-31 01:17:36,493 [Thread-3] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
dn5_1    | 2022-07-31 01:17:36,516 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 1s
dn5_1    | 2022-07-31 01:17:48,999 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
dn5_1    | 2022-07-31 01:17:49,702 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn5_1    | 2022-07-31 01:17:50,376 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
dn5_1    | 2022-07-31 01:17:51,516 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
dn5_1    | 2022-07-31 01:17:51,576 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
dn5_1    | 2022-07-31 01:17:51,576 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
dn5_1    | 2022-07-31 01:17:51,578 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
dn5_1    | 2022-07-31 01:17:51,579 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn5_1    | 2022-07-31 01:17:51,582 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
dn5_1    | 2022-07-31 01:17:51,590 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn5_1    | 2022-07-31 01:17:51,825 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
dn5_1    | 2022-07-31 01:17:51,826 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
dn5_1    | 2022-07-31 01:17:54,235 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
dn5_1    | 2022-07-31 01:17:54,307 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
dn5_1    | 2022-07-31 01:17:54,309 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
dn5_1    | 2022-07-31 01:17:54,335 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn5_1    | 2022-07-31 01:17:54,335 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn5_1    | 2022-07-31 01:17:54,423 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn5_1    | 2022-07-31 01:17:54,449 [52aca038-7576-46a0-9ccd-b8aed29078e2-impl-thread1] INFO server.RaftServer: 52aca038-7576-46a0-9ccd-b8aed29078e2: found a subdirectory /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610
dn5_1    | 2022-07-31 01:17:54,560 [52aca038-7576-46a0-9ccd-b8aed29078e2-impl-thread1] INFO server.RaftServer: 52aca038-7576-46a0-9ccd-b8aed29078e2: addNew group-7BB2A1276610:[] returns group-7BB2A1276610:java.util.concurrent.CompletableFuture@4a61cea9[Not completed]
dn5_1    | 2022-07-31 01:17:54,562 [52aca038-7576-46a0-9ccd-b8aed29078e2-impl-thread1] INFO server.RaftServer: 52aca038-7576-46a0-9ccd-b8aed29078e2: found a subdirectory /data/metadata/ratis/106ad38c-cb28-4e98-a52d-cd003ecc1eed
dn5_1    | 2022-07-31 01:17:54,573 [52aca038-7576-46a0-9ccd-b8aed29078e2-impl-thread1] INFO server.RaftServer: 52aca038-7576-46a0-9ccd-b8aed29078e2: addNew group-CD003ECC1EED:[] returns group-CD003ECC1EED:java.util.concurrent.CompletableFuture@45f350cf[Not completed]
dn5_1    | 2022-07-31 01:17:54,575 [52aca038-7576-46a0-9ccd-b8aed29078e2-impl-thread1] INFO server.RaftServer: 52aca038-7576-46a0-9ccd-b8aed29078e2: found a subdirectory /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1
om2_1    | 2022-07-31 01:18:19,833 [pool-26-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/in_use.lock acquired by nodename 7@14febe149d7f
om2_1    | 2022-07-31 01:18:19,999 [pool-26-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=6, votedFor=om2} from /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/raft-meta
om2_1    | 2022-07-31 01:18:20,842 [pool-26-thread-1] INFO server.RaftServer$Division: om2@group-D66704EFC61C: set configuration 63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1    | 2022-07-31 01:18:20,853 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om2_1    | 2022-07-31 01:18:20,855 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om2_1    | 2022-07-31 01:18:20,969 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om2_1    | 2022-07-31 01:18:20,981 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1    | 2022-07-31 01:18:21,014 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om2_1    | 2022-07-31 01:18:21,119 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1    | 2022-07-31 01:18:21,249 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om2_1    | 2022-07-31 01:18:21,249 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om2_1    | 2022-07-31 01:18:21,319 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: new om2@group-D66704EFC61C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c
om2_1    | 2022-07-31 01:18:21,326 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om2_1    | 2022-07-31 01:18:21,332 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om2_1    | 2022-07-31 01:18:21,338 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1    | 2022-07-31 01:18:21,354 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om2_1    | 2022-07-31 01:18:21,355 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om2_1    | 2022-07-31 01:18:21,359 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om2_1    | 2022-07-31 01:18:21,385 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om2_1    | 2022-07-31 01:18:21,386 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om2_1    | 2022-07-31 01:18:21,466 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om2_1    | 2022-07-31 01:18:21,482 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om2_1    | 2022-07-31 01:18:21,487 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om2_1    | 2022-07-31 01:18:21,880 [pool-26-thread-1] INFO server.RaftServer$Division: om2@group-D66704EFC61C: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1    | 2022-07-31 01:18:21,962 [pool-26-thread-1] INFO segmented.LogSegment: Successfully read 21 entries from segment file /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_0-20
om2_1    | 2022-07-31 01:18:21,984 [pool-26-thread-1] INFO server.RaftServer$Division: om2@group-D66704EFC61C: set configuration 21: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1    | 2022-07-31 01:18:22,025 [pool-26-thread-1] INFO segmented.LogSegment: Successfully read 42 entries from segment file /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_21-62
om2_1    | 2022-07-31 01:18:22,026 [pool-26-thread-1] INFO server.RaftServer$Division: om2@group-D66704EFC61C: set configuration 63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1    | 2022-07-31 01:18:22,048 [pool-26-thread-1] INFO segmented.LogSegment: Successfully read 36 entries from segment file /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_inprogress_63
om2_1    | 2022-07-31 01:18:22,052 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-D66704EFC61C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 98
om2_1    | 2022-07-31 01:18:22,056 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-D66704EFC61C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 62
om2_1    | 2022-07-31 01:18:22,495 [pool-26-thread-1] INFO raftlog.RaftLog: om2@group-D66704EFC61C-SegmentedRaftLog: commitIndex: updateToMax old=98, new=97, updated? false
om2_1    | 2022-07-31 01:18:22,502 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om2_1    | 2022-07-31 01:18:22,506 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om2_1    | 2022-07-31 01:18:22,511 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om2_1    | 2022-07-31 01:18:22,512 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om2_1    | 2022-07-31 01:18:22,521 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om2_1    | 2022-07-31 01:18:22,524 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om2_1    | 2022-07-31 01:18:22,784 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1    | 2022-07-31 01:18:22,785 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om2_1    | 2022-07-31 01:18:22,786 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om2_1    | 2022-07-31 01:18:22,786 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om2_1    | 2022-07-31 01:18:22,787 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om2_1    | 2022-07-31 01:18:22,844 [main] INFO reflections.Reflections: Reflections took 3213 ms to scan 8 urls, producing 23 keys and 513 values [using 2 cores]
om2_1    | 2022-07-31 01:18:23,222 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om2_1    | 2022-07-31 01:18:23,258 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om2_1    | 2022-07-31 01:18:23,742 [Listener at om2/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
dn4_1    | 2022-07-31 01:18:25,473 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn4_1    | 2022-07-31 01:18:25,473 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-FollowerState] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: start 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-LeaderElection3
dn4_1    | 2022-07-31 01:18:25,487 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-LeaderElection3] INFO impl.LeaderElection: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-LeaderElection3 ELECTION round 0: submit vote requests at term 13 for 3: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn4_1    | 2022-07-31 01:18:25,533 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-LeaderElection3] INFO impl.LeaderElection: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-LeaderElection3: ELECTION REJECTED received 1 response(s) and 0 exception(s):
dn4_1    | 2022-07-31 01:18:25,533 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-LeaderElection3] INFO impl.LeaderElection:   Response 0: 310a080d-f635-46ff-a53d-49cc9a09fa5c<-52aca038-7576-46a0-9ccd-b8aed29078e2#0:FAIL-t13
dn4_1    | 2022-07-31 01:18:25,534 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-LeaderElection3] INFO impl.LeaderElection: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-LeaderElection3 ELECTION round 0: result REJECTED
dn4_1    | 2022-07-31 01:18:25,534 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-LeaderElection3] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610: changes role from CANDIDATE to FOLLOWER at term 13 for REJECTED
dn4_1    | 2022-07-31 01:18:25,534 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-LeaderElection3] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: shutdown 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-LeaderElection3
dn4_1    | 2022-07-31 01:18:25,535 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-LeaderElection3] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: start 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-FollowerState
dn4_1    | 2022-07-31 01:18:30,533 [grpc-default-executor-0] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610: receive requestVote(ELECTION, 52aca038-7576-46a0-9ccd-b8aed29078e2, group-7BB2A1276610, 14, (t:11, i:12))
dn4_1    | 2022-07-31 01:18:30,533 [grpc-default-executor-0] INFO impl.VoteContext: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-FOLLOWER: accept ELECTION from 52aca038-7576-46a0-9ccd-b8aed29078e2: our priority 0 <= candidate's priority 1
dn4_1    | 2022-07-31 01:18:30,534 [grpc-default-executor-0] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610: changes role from  FOLLOWER to FOLLOWER at term 14 for candidate:52aca038-7576-46a0-9ccd-b8aed29078e2
dn4_1    | 2022-07-31 01:18:30,535 [grpc-default-executor-0] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: shutdown 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-FollowerState
dn4_1    | 2022-07-31 01:18:30,535 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-FollowerState] INFO impl.FollowerState: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-FollowerState was interrupted
dn4_1    | 2022-07-31 01:18:30,536 [grpc-default-executor-0] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: start 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-FollowerState
dn4_1    | 2022-07-31 01:18:30,543 [grpc-default-executor-0] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610 replies to ELECTION vote request: 52aca038-7576-46a0-9ccd-b8aed29078e2<-310a080d-f635-46ff-a53d-49cc9a09fa5c#0:OK-t14. Peer's state: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610:t14, leader=null, voted=52aca038-7576-46a0-9ccd-b8aed29078e2, raftlog=310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-SegmentedRaftLog:OPENED:c12, conf=3: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn4_1    | 2022-07-31 01:18:30,933 [310a080d-f635-46ff-a53d-49cc9a09fa5c-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-7BB2A1276610 with new leaderId: 52aca038-7576-46a0-9ccd-b8aed29078e2
dn4_1    | 2022-07-31 01:18:30,935 [310a080d-f635-46ff-a53d-49cc9a09fa5c-server-thread1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610: change Leader from null to 52aca038-7576-46a0-9ccd-b8aed29078e2 at term 14 for appendEntries, leader elected after 29753ms
dn4_1    | 2022-07-31 01:18:31,077 [310a080d-f635-46ff-a53d-49cc9a09fa5c-server-thread1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610: set configuration 13: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-07-31 01:17:54,575 [52aca038-7576-46a0-9ccd-b8aed29078e2-impl-thread1] INFO server.RaftServer: 52aca038-7576-46a0-9ccd-b8aed29078e2: addNew group-65A101075AF1:[] returns group-65A101075AF1:java.util.concurrent.CompletableFuture@45e6a075[Not completed]
dn5_1    | 2022-07-31 01:17:54,750 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
dn5_1    | 2022-07-31 01:17:55,011 [pool-38-thread-1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2: new RaftServerImpl for group-7BB2A1276610:[] with ContainerStateMachine:uninitialized
dn5_1    | 2022-07-31 01:17:55,056 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn5_1    | 2022-07-31 01:17:55,061 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn5_1    | 2022-07-31 01:17:55,078 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn5_1    | 2022-07-31 01:17:55,079 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn5_1    | 2022-07-31 01:17:55,080 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn5_1    | 2022-07-31 01:17:55,097 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn5_1    | 2022-07-31 01:17:55,195 [pool-38-thread-1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn5_1    | 2022-07-31 01:17:55,230 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn5_1    | 2022-07-31 01:17:55,298 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn5_1    | 2022-07-31 01:17:55,300 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn5_1    | 2022-07-31 01:17:55,483 [pool-38-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/in_use.lock acquired by nodename 6@6c1f77753501
dn5_1    | 2022-07-31 01:17:55,577 [pool-38-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=11, votedFor=52aca038-7576-46a0-9ccd-b8aed29078e2} from /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/current/raft-meta
dn5_1    | 2022-07-31 01:17:55,878 [pool-38-thread-1] INFO ratis.ContainerStateMachine: group-7BB2A1276610: Setting the last applied index to (t:11, i:12)
dn5_1    | 2022-07-31 01:17:56,285 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
dn5_1    | 2022-07-31 01:17:56,458 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
dn5_1    | 2022-07-31 01:17:57,197 [main] INFO util.log: Logging initialized @45242ms to org.eclipse.jetty.util.log.Slf4jLog
dn5_1    | 2022-07-31 01:17:57,653 [pool-38-thread-1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610: set configuration 3: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-07-31 01:17:57,663 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn5_1    | 2022-07-31 01:17:57,683 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn5_1    | 2022-07-31 01:17:57,758 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn5_1    | 2022-07-31 01:17:57,759 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn5_1    | 2022-07-31 01:17:57,790 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn5_1    | 2022-07-31 01:17:57,974 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn5_1    | 2022-07-31 01:17:58,057 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn5_1    | 2022-07-31 01:17:58,058 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn5_1    | 2022-07-31 01:17:58,116 [pool-38-thread-1] INFO segmented.SegmentedRaftLogWorker: new 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610
dn5_1    | 2022-07-31 01:17:58,141 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn5_1    | 2022-07-31 01:17:58,160 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn5_1    | 2022-07-31 01:17:58,175 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn5_1    | 2022-07-31 01:17:58,183 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn5_1    | 2022-07-31 01:17:58,184 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn5_1    | 2022-07-31 01:17:58,200 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn5_1    | 2022-07-31 01:17:58,229 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn5_1    | 2022-07-31 01:17:58,230 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn5_1    | 2022-07-31 01:17:58,304 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn5_1    | 2022-07-31 01:17:58,332 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn5_1    | 2022-07-31 01:17:58,334 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn5_1    | 2022-07-31 01:17:58,460 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
dn5_1    | 2022-07-31 01:17:58,537 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
dn5_1    | 2022-07-31 01:17:58,622 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
dn5_1    | 2022-07-31 01:17:58,630 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
dn5_1    | 2022-07-31 01:17:58,638 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
dn5_1    | 2022-07-31 01:17:58,641 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
dn5_1    | 2022-07-31 01:17:58,802 [pool-38-thread-1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610: set configuration 0: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-07-31 01:19:01,889 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn3_1    | 2022-07-31 01:19:01,889 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 2001 to close, current state is: CLOSING
dn3_1    | 2022-07-31 01:19:01,889 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn3_1    | 2022-07-31 01:19:01,889 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn3_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn3_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn3_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn3_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn3_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn3_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn3_1    | 2022-07-31 01:19:01,890 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn3_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn3_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn3_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn3_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn3_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn3_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn3_1    | 2022-07-31 01:19:01,957 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn3_1    | 2022-07-31 01:19:01,968 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn3_1    | 2022-07-31 01:19:01,969 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn3_1    | 2022-07-31 01:19:01,973 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 2001 to close, current state is: CLOSING
dn3_1    | 2022-07-31 01:19:01,973 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn3_1    | 2022-07-31 01:19:01,973 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn3_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn3_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn3_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn3_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn3_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn3_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn3_1    | 2022-07-31 01:19:01,974 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn3_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn3_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn3_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn3_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn3_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn3_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn3_1    | 2022-07-31 01:19:01,974 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn3_1    | 2022-07-31 01:19:01,974 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn3_1    | 2022-07-31 01:19:01,974 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn3_1    | 2022-07-31 01:19:01,974 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 2001 to close, current state is: CLOSING
dn3_1    | 2022-07-31 01:19:01,974 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn3_1    | 2022-07-31 01:19:01,974 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn1_1    | 2022-07-31 01:20:03,698 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2022-07-31 01:20:03,702 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn1_1    | 2022-07-31 01:20:03,703 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn1_1    | 2022-07-31 01:20:03,703 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: new 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/ae7040c6-f723-491f-8b9e-7781ffa9f9e7
dn1_1    | 2022-07-31 01:20:03,703 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn1_1    | 2022-07-31 01:20:03,705 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn1_1    | 2022-07-31 01:20:03,705 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2022-07-31 01:20:03,705 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn1_1    | 2022-07-31 01:20:03,705 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn1_1    | 2022-07-31 01:20:03,705 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn1_1    | 2022-07-31 01:20:03,706 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn1_1    | 2022-07-31 01:20:03,706 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn1_1    | 2022-07-31 01:20:03,706 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn1_1    | 2022-07-31 01:20:03,708 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn1_1    | 2022-07-31 01:20:03,709 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn1_1    | 2022-07-31 01:20:03,709 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn1_1    | 2022-07-31 01:20:03,709 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn1_1    | 2022-07-31 01:20:03,713 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn1_1    | 2022-07-31 01:20:03,713 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn1_1    | 2022-07-31 01:20:03,713 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn1_1    | 2022-07-31 01:20:03,713 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn1_1    | 2022-07-31 01:20:03,714 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn1_1    | 2022-07-31 01:20:03,714 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn1_1    | 2022-07-31 01:20:03,715 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn1_1    | 2022-07-31 01:20:03,715 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn1_1    | 2022-07-31 01:20:03,715 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn1_1    | 2022-07-31 01:20:03,715 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn1_1    | 2022-07-31 01:20:03,715 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn1_1    | 2022-07-31 01:20:03,715 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7: start as a follower, conf=-1: [310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0], old=null
dn1_1    | 2022-07-31 01:20:03,715 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn1_1    | 2022-07-31 01:20:03,716 [pool-42-thread-1] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7-FollowerState
dn1_1    | 2022-07-31 01:20:03,718 [pool-42-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7781FFA9F9E7,id=609e7f2d-9474-472f-937f-8fa0a0bbb327
dn1_1    | 2022-07-31 01:20:03,722 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=ae7040c6-f723-491f-8b9e-7781ffa9f9e7
dn1_1    | 2022-07-31 01:20:04,081 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=ae7040c6-f723-491f-8b9e-7781ffa9f9e7.
dn1_1    | 2022-07-31 01:20:04,083 [Command processor thread] INFO server.RaftServer: 609e7f2d-9474-472f-937f-8fa0a0bbb327: addNew group-84A70A95B4C0:[3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0] returns group-84A70A95B4C0:java.util.concurrent.CompletableFuture@54d43f54[Not completed]
dn1_1    | 2022-07-31 01:20:04,084 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327: new RaftServerImpl for group-84A70A95B4C0:[3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0] with ContainerStateMachine:uninitialized
dn1_1    | 2022-07-31 01:20:04,085 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn1_1    | 2022-07-31 01:20:04,085 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn1_1    | 2022-07-31 01:20:04,085 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn1_1    | 2022-07-31 01:20:04,085 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn1_1    | 2022-07-31 01:20:04,085 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn1_1    | 2022-07-31 01:20:04,085 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn3_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn3_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn3_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn3_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn3_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn3_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn3_1    | 2022-07-31 01:19:01,974 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn3_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn3_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn3_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn3_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn3_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn3_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn3_1    | 2022-07-31 01:19:02,266 [ContainerOp-b88205de-97a2-4448-8e49-7bb2a1276610-0] INFO keyvalue.KeyValueContainer: Container 2001 is synced with bcsId 11.
dn3_1    | 2022-07-31 01:19:02,267 [ContainerOp-b88205de-97a2-4448-8e49-7bb2a1276610-0] INFO keyvalue.KeyValueContainer: Container 2001 is synced with bcsId 11.
dn3_1    | 2022-07-31 01:19:02,298 [ContainerOp-b88205de-97a2-4448-8e49-7bb2a1276610-0] INFO keyvalue.KeyValueContainer: Container 2001 is closed with bcsId 11.
dn3_1    | 2022-07-31 01:19:32,810 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn3_1    | 2022-07-31 01:19:32,810 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn3_1    | 2022-07-31 01:19:32,810 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn3_1    | 2022-07-31 01:19:32,810 [Command processor thread] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: ERASURE_CODED_STORAGE_SUPPORT.
dn3_1    | 2022-07-31 01:19:32,813 [Command processor thread] INFO upgrade.AbstractLayoutVersionManager: Layout feature ERASURE_CODED_STORAGE_SUPPORT has been finalized.
dn3_1    | 2022-07-31 01:19:32,814 [Command processor thread] INFO upgrade.UpgradeFinalizer: Running finalization actions for layout feature: DATANODE_SCHEMA_V3
dn3_1    | 2022-07-31 01:19:32,814 [Command processor thread] INFO upgrade.DatanodeSchemaV3FinalizeAction: Upgrading Datanode volume layout for Schema V3 support.
dn3_1    | 2022-07-31 01:19:32,866 [Command processor thread] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-2b5f2d05-a9c0-4b31-b820-5fa0b5f933e6/DS-a3277ede-673b-47ac-a196-d53f4807277a/container.db for volume DS-a3277ede-673b-47ac-a196-d53f4807277a
dn3_1    | 2022-07-31 01:19:32,867 [Command processor thread] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-2b5f2d05-a9c0-4b31-b820-5fa0b5f933e6/DS-a3277ede-673b-47ac-a196-d53f4807277a/container.db for volume DS-a3277ede-673b-47ac-a196-d53f4807277a
dn3_1    | 2022-07-31 01:19:32,868 [Command processor thread] INFO upgrade.DatanodeSchemaV3FinalizeAction: Schema V3 is disabled. Won't load RocksDB in upgrade.
dn3_1    | 2022-07-31 01:19:32,869 [Command processor thread] INFO upgrade.AbstractLayoutVersionManager: Layout feature DATANODE_SCHEMA_V3 has been finalized.
dn3_1    | 2022-07-31 01:19:32,869 [Command processor thread] INFO upgrade.AbstractLayoutVersionManager: Finalization is complete.
dn3_1    | 2022-07-31 01:19:32,869 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization is done.
dn3_1    | 2022-07-31 01:19:32,869 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn3_1    | 2022-07-31 01:19:32,870 [Command processor thread] INFO server.RaftServer: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: remove    LEADER 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246:t12, leader=3fc9f139-dd93-41e7-b235-52ce94d6fe3c, voted=3fc9f139-dd93-41e7-b235-52ce94d6fe3c, raftlog=3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-SegmentedRaftLog:OPENED:c29, conf=24: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null RUNNING
dn3_1    | 2022-07-31 01:19:32,872 [Command processor thread] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246: shutdown
dn3_1    | 2022-07-31 01:19:32,872 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-75041C4AA246,id=3fc9f139-dd93-41e7-b235-52ce94d6fe3c
dn3_1    | 2022-07-31 01:19:32,872 [Command processor thread] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: shutdown 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-LeaderStateImpl
dn3_1    | 2022-07-31 01:19:32,873 [Command processor thread] INFO impl.PendingRequests: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-PendingRequests: sendNotLeaderResponses
dn3_1    | 2022-07-31 01:19:32,873 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246->609e7f2d-9474-472f-937f-8fa0a0bbb327-GrpcLogAppender-LogAppenderDaemon] WARN server.GrpcLogAppender: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246->609e7f2d-9474-472f-937f-8fa0a0bbb327-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
dn3_1    | 2022-07-31 01:19:32,873 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246->11cba143-91f8-47cb-8422-c32a1e2d51df-GrpcLogAppender-LogAppenderDaemon] WARN server.GrpcLogAppender: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246->11cba143-91f8-47cb-8422-c32a1e2d51df-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
dn5_1    | 2022-07-31 01:17:58,811 [pool-38-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/current/log_0-0
dn5_1    | 2022-07-31 01:17:58,877 [pool-38-thread-1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610: set configuration 1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-07-31 01:17:58,906 [pool-38-thread-1] INFO segmented.LogSegment: Successfully read 2 entries from segment file /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/current/log_1-2
dn5_1    | 2022-07-31 01:17:58,913 [pool-38-thread-1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610: set configuration 3: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-07-31 01:17:58,982 [pool-38-thread-1] INFO segmented.LogSegment: Successfully read 10 entries from segment file /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/current/log_inprogress_3
dn5_1    | 2022-07-31 01:17:59,034 [pool-38-thread-1] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 12
dn5_1    | 2022-07-31 01:17:59,034 [pool-38-thread-1] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 2
dn5_1    | 2022-07-31 01:17:59,074 [main] INFO http.HttpServer2: Jetty bound to port 9882
dn5_1    | 2022-07-31 01:17:59,112 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
dn5_1    | 2022-07-31 01:17:59,527 [main] INFO server.session: DefaultSessionIdManager workerName=node0
dn5_1    | 2022-07-31 01:17:59,533 [main] INFO server.session: No SessionScavenger set, using defaults
dn5_1    | 2022-07-31 01:17:59,545 [main] INFO server.session: node0 Scavenging every 660000ms
dn5_1    | 2022-07-31 01:17:59,650 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1f536481{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
dn5_1    | 2022-07-31 01:17:59,658 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@16d0e521{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
dn5_1    | 2022-07-31 01:18:00,484 [pool-38-thread-1] INFO raftlog.RaftLog: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-SegmentedRaftLog: commitIndex: updateToMax old=12, new=11, updated? false
dn5_1    | 2022-07-31 01:18:00,534 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn5_1    | 2022-07-31 01:18:00,534 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn5_1    | 2022-07-31 01:18:00,535 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn5_1    | 2022-07-31 01:18:00,535 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn5_1    | 2022-07-31 01:18:00,584 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn5_1    | 2022-07-31 01:18:00,584 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn5_1    | 2022-07-31 01:18:00,785 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@42c0a16e{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-16162313186685938977/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
dn5_1    | 2022-07-31 01:18:00,921 [main] INFO server.AbstractConnector: Started ServerConnector@37af24cb{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
dn5_1    | 2022-07-31 01:18:00,921 [main] INFO server.Server: Started @48966ms
dn5_1    | 2022-07-31 01:18:00,984 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
dn5_1    | 2022-07-31 01:18:00,984 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
dn5_1    | 2022-07-31 01:18:00,993 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
dn5_1    | 2022-07-31 01:18:01,033 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
dn5_1    | 2022-07-31 01:18:01,164 [Datanode State Machine Daemon Thread] INFO upgrade.UpgradeFinalizer: Running pre-finalized state validations for unfinalized layout features.
dn5_1    | 2022-07-31 01:18:01,168 [Datanode State Machine Daemon Thread] INFO upgrade.UpgradeFinalizer: Running first upgrade commands for unfinalized layout features.
dn5_1    | 2022-07-31 01:18:01,198 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@79a0aabe] INFO util.JvmPauseMonitor: Starting JVM pause monitor
dn5_1    | 2022-07-31 01:18:01,456 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn5_1    | 2022-07-31 01:18:01,482 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn5_1    | 2022-07-31 01:18:01,490 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn5_1    | 2022-07-31 01:18:01,495 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn5_1    | 2022-07-31 01:18:01,499 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn5_1    | 2022-07-31 01:18:01,510 [pool-38-thread-1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2: new RaftServerImpl for group-CD003ECC1EED:[] with ContainerStateMachine:uninitialized
dn5_1    | 2022-07-31 01:18:01,551 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn5_1    | 2022-07-31 01:18:01,551 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn5_1    | 2022-07-31 01:18:01,552 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn5_1    | 2022-07-31 01:18:01,552 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn5_1    | 2022-07-31 01:18:01,553 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn5_1    | 2022-07-31 01:18:01,553 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn5_1    | 2022-07-31 01:18:01,553 [pool-38-thread-1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn5_1    | 2022-07-31 01:18:01,555 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn5_1    | 2022-07-31 01:18:01,563 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn2_1    | 2022-07-31 01:19:01,803 [ContainerOp-369e0910-4276-41cc-941b-75041c4aa246-1] INFO keyvalue.KeyValueContainer: Container 2002 is closed with bcsId 21.
dn2_1    | 2022-07-31 01:19:02,009 [ContainerOp-67b1342c-3bb3-4b48-a218-65a101075af1-0] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 10.
dn2_1    | 2022-07-31 01:19:02,009 [ContainerOp-67b1342c-3bb3-4b48-a218-65a101075af1-0] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 10.
dn2_1    | 2022-07-31 01:19:02,031 [ContainerOp-67b1342c-3bb3-4b48-a218-65a101075af1-0] INFO keyvalue.KeyValueContainer: Container 1 is closed with bcsId 10.
dn2_1    | 2022-07-31 01:19:02,299 [ContainerOp-67b1342c-3bb3-4b48-a218-65a101075af1-1] INFO keyvalue.KeyValueContainer: Container 1002 is synced with bcsId 29.
dn2_1    | 2022-07-31 01:19:02,299 [ContainerOp-67b1342c-3bb3-4b48-a218-65a101075af1-1] INFO keyvalue.KeyValueContainer: Container 1002 is synced with bcsId 29.
dn2_1    | 2022-07-31 01:19:02,314 [ContainerOp-67b1342c-3bb3-4b48-a218-65a101075af1-1] INFO keyvalue.KeyValueContainer: Container 1002 is closed with bcsId 29.
dn2_1    | 2022-07-31 01:19:02,486 [ContainerOp-67b1342c-3bb3-4b48-a218-65a101075af1-2] INFO keyvalue.KeyValueContainer: Container 2003 is synced with bcsId 34.
dn2_1    | 2022-07-31 01:19:02,486 [ContainerOp-67b1342c-3bb3-4b48-a218-65a101075af1-2] INFO keyvalue.KeyValueContainer: Container 2003 is synced with bcsId 34.
dn2_1    | 2022-07-31 01:19:02,501 [ContainerOp-67b1342c-3bb3-4b48-a218-65a101075af1-2] INFO keyvalue.KeyValueContainer: Container 2003 is closed with bcsId 34.
dn2_1    | 2022-07-31 01:19:18,045 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn2_1    | 2022-07-31 01:19:18,045 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn2_1    | 2022-07-31 01:19:18,045 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn2_1    | 2022-07-31 01:19:18,046 [Command processor thread] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: ERASURE_CODED_STORAGE_SUPPORT.
dn2_1    | 2022-07-31 01:19:18,050 [Command processor thread] INFO upgrade.AbstractLayoutVersionManager: Layout feature ERASURE_CODED_STORAGE_SUPPORT has been finalized.
dn2_1    | 2022-07-31 01:19:18,050 [Command processor thread] INFO upgrade.UpgradeFinalizer: Running finalization actions for layout feature: DATANODE_SCHEMA_V3
dn2_1    | 2022-07-31 01:19:18,050 [Command processor thread] INFO upgrade.DatanodeSchemaV3FinalizeAction: Upgrading Datanode volume layout for Schema V3 support.
dn2_1    | 2022-07-31 01:19:18,108 [Command processor thread] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-2b5f2d05-a9c0-4b31-b820-5fa0b5f933e6/DS-70a3a1e7-cd2c-444c-9b8b-62b75feac696/container.db for volume DS-70a3a1e7-cd2c-444c-9b8b-62b75feac696
dn2_1    | 2022-07-31 01:19:18,110 [Command processor thread] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-2b5f2d05-a9c0-4b31-b820-5fa0b5f933e6/DS-70a3a1e7-cd2c-444c-9b8b-62b75feac696/container.db for volume DS-70a3a1e7-cd2c-444c-9b8b-62b75feac696
dn2_1    | 2022-07-31 01:19:18,111 [Command processor thread] INFO upgrade.DatanodeSchemaV3FinalizeAction: Schema V3 is disabled. Won't load RocksDB in upgrade.
dn2_1    | 2022-07-31 01:19:18,113 [Command processor thread] INFO upgrade.AbstractLayoutVersionManager: Layout feature DATANODE_SCHEMA_V3 has been finalized.
dn2_1    | 2022-07-31 01:19:18,113 [Command processor thread] INFO upgrade.AbstractLayoutVersionManager: Finalization is complete.
dn2_1    | 2022-07-31 01:19:18,113 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization is done.
dn2_1    | 2022-07-31 01:19:18,113 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn2_1    | 2022-07-31 01:19:18,113 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn2_1    | 2022-07-31 01:19:18,113 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn2_1    | 2022-07-31 01:19:18,113 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn2_1    | 2022-07-31 01:19:18,113 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn2_1    | 2022-07-31 01:19:18,113 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn2_1    | 2022-07-31 01:19:32,887 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 11cba143-91f8-47cb-8422-c32a1e2d51df: Completed APPEND_ENTRIES, lastRequest: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c->11cba143-91f8-47cb-8422-c32a1e2d51df#286-t12,previous=(t:12, i:28),leaderCommit=28,initializing? true,entries: size=1, first=(t:12, i:29), METADATAENTRY(c:28)
dn2_1    | 2022-07-31 01:19:33,503 [Command processor thread] INFO server.RaftServer: 11cba143-91f8-47cb-8422-c32a1e2d51df: remove  FOLLOWER 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246:t12, leader=3fc9f139-dd93-41e7-b235-52ce94d6fe3c, voted=3fc9f139-dd93-41e7-b235-52ce94d6fe3c, raftlog=11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-SegmentedRaftLog:OPENED:c29, conf=24: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null RUNNING
dn2_1    | 2022-07-31 01:19:33,507 [Command processor thread] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246: shutdown
dn2_1    | 2022-07-31 01:19:33,507 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-75041C4AA246,id=11cba143-91f8-47cb-8422-c32a1e2d51df
dn2_1    | 2022-07-31 01:19:33,507 [Command processor thread] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: shutdown 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-FollowerState
dn2_1    | 2022-07-31 01:19:33,508 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-FollowerState] INFO impl.FollowerState: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-FollowerState was interrupted
dn2_1    | 2022-07-31 01:19:33,514 [Command processor thread] INFO impl.StateMachineUpdater: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-StateMachineUpdater: set stopIndex = 29
dn2_1    | 2022-07-31 01:19:33,514 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-75041C4AA246: Taking a snapshot at:(t:12, i:29) file /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/sm/snapshot.12_29
dn2_1    | 2022-07-31 01:19:33,529 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-75041C4AA246: Finished taking a snapshot at:(t:12, i:29) file:/data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/sm/snapshot.12_29 took: 15 ms
dn2_1    | 2022-07-31 01:19:33,531 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-StateMachineUpdater] INFO impl.StateMachineUpdater: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-StateMachineUpdater: Took a snapshot at index 29
dn2_1    | 2022-07-31 01:19:33,532 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-StateMachineUpdater] INFO impl.StateMachineUpdater: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-StateMachineUpdater: snapshotIndex: updateIncreasingly 23 -> 29
dn2_1    | 2022-07-31 01:19:33,535 [Command processor thread] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246: closes. applyIndex: 29
dn2_1    | 2022-07-31 01:19:33,536 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
dn2_1    | 2022-07-31 01:19:33,538 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246-SegmentedRaftLogWorker close()
dn2_1    | 2022-07-31 01:19:33,548 [Command processor thread] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-75041C4AA246: Succeed to remove RaftStorageDirectory Storage Directory /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246
dn2_1    | 2022-07-31 01:19:33,549 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline PipelineID=369e0910-4276-41cc-941b-75041c4aa246 command on datanode 11cba143-91f8-47cb-8422-c32a1e2d51df.
dn2_1    | 2022-07-31 01:19:33,550 [Command processor thread] INFO server.RaftServer: 11cba143-91f8-47cb-8422-c32a1e2d51df: remove  FOLLOWER 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1:t11, leader=609e7f2d-9474-472f-937f-8fa0a0bbb327, voted=609e7f2d-9474-472f-937f-8fa0a0bbb327, raftlog=11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-SegmentedRaftLog:OPENED:c43, conf=36: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null RUNNING
dn2_1    | 2022-07-31 01:19:33,550 [Command processor thread] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1: shutdown
dn2_1    | 2022-07-31 01:19:33,550 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-65A101075AF1,id=11cba143-91f8-47cb-8422-c32a1e2d51df
dn2_1    | 2022-07-31 01:19:33,550 [Command processor thread] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: shutdown 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-FollowerState
dn2_1    | 2022-07-31 01:19:33,551 [Command processor thread] INFO impl.StateMachineUpdater: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-StateMachineUpdater: set stopIndex = 43
dn2_1    | 2022-07-31 01:19:33,552 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-FollowerState] INFO impl.FollowerState: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-FollowerState was interrupted
dn2_1    | 2022-07-31 01:19:33,553 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-65A101075AF1: Taking a snapshot at:(t:11, i:43) file /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/sm/snapshot.11_43
dn2_1    | 2022-07-31 01:19:33,555 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-65A101075AF1: Finished taking a snapshot at:(t:11, i:43) file:/data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/sm/snapshot.11_43 took: 1 ms
dn2_1    | 2022-07-31 01:19:33,555 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-StateMachineUpdater] INFO impl.StateMachineUpdater: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-StateMachineUpdater: Took a snapshot at index 43
dn2_1    | 2022-07-31 01:19:33,555 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-StateMachineUpdater] INFO impl.StateMachineUpdater: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-StateMachineUpdater: snapshotIndex: updateIncreasingly 35 -> 43
dn2_1    | 2022-07-31 01:19:33,556 [Command processor thread] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1: closes. applyIndex: 43
dn2_1    | 2022-07-31 01:19:33,559 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
dn2_1    | 2022-07-31 01:19:33,561 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1-SegmentedRaftLogWorker close()
dn2_1    | 2022-07-31 01:19:33,579 [Command processor thread] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-65A101075AF1: Succeed to remove RaftStorageDirectory Storage Directory /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1
dn2_1    | 2022-07-31 01:19:33,579 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline PipelineID=67b1342c-3bb3-4b48-a218-65a101075af1 command on datanode 11cba143-91f8-47cb-8422-c32a1e2d51df.
dn2_1    | 2022-07-31 01:19:33,580 [Command processor thread] INFO server.RaftServer: 11cba143-91f8-47cb-8422-c32a1e2d51df: remove    LEADER 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB:t4, leader=11cba143-91f8-47cb-8422-c32a1e2d51df, voted=11cba143-91f8-47cb-8422-c32a1e2d51df, raftlog=11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-SegmentedRaftLog:OPENED:c6, conf=5: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1], old=null RUNNING
dn2_1    | 2022-07-31 01:19:33,580 [Command processor thread] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB: shutdown
dn2_1    | 2022-07-31 01:19:33,580 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-6999419922EB,id=11cba143-91f8-47cb-8422-c32a1e2d51df
dn2_1    | 2022-07-31 01:19:33,580 [Command processor thread] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: shutdown 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-LeaderStateImpl
dn2_1    | 2022-07-31 01:19:33,580 [Command processor thread] INFO impl.PendingRequests: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-PendingRequests: sendNotLeaderResponses
dn2_1    | 2022-07-31 01:19:33,582 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-6999419922EB: Taking a snapshot at:(t:4, i:6) file /data/metadata/ratis/8145371a-b336-4e64-a95d-6999419922eb/sm/snapshot.4_6
dn2_1    | 2022-07-31 01:19:33,582 [Command processor thread] INFO impl.StateMachineUpdater: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-StateMachineUpdater: set stopIndex = 6
dn2_1    | 2022-07-31 01:19:33,597 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-6999419922EB: Finished taking a snapshot at:(t:4, i:6) file:/data/metadata/ratis/8145371a-b336-4e64-a95d-6999419922eb/sm/snapshot.4_6 took: 15 ms
dn2_1    | 2022-07-31 01:19:33,598 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-StateMachineUpdater] INFO impl.StateMachineUpdater: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-StateMachineUpdater: Took a snapshot at index 6
dn2_1    | 2022-07-31 01:19:33,598 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-StateMachineUpdater] INFO impl.StateMachineUpdater: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-StateMachineUpdater: snapshotIndex: updateIncreasingly 4 -> 6
dn2_1    | 2022-07-31 01:19:33,600 [Command processor thread] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB: closes. applyIndex: 6
dn5_1    | 2022-07-31 01:18:01,584 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn5_1    | 2022-07-31 01:18:01,594 [pool-38-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/106ad38c-cb28-4e98-a52d-cd003ecc1eed/in_use.lock acquired by nodename 6@6c1f77753501
dn5_1    | 2022-07-31 01:18:01,594 [pool-38-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=3, votedFor=52aca038-7576-46a0-9ccd-b8aed29078e2} from /data/metadata/ratis/106ad38c-cb28-4e98-a52d-cd003ecc1eed/current/raft-meta
dn5_1    | 2022-07-31 01:18:01,602 [pool-38-thread-1] INFO ratis.ContainerStateMachine: group-CD003ECC1EED: Setting the last applied index to (t:3, i:4)
dn5_1    | 2022-07-31 01:18:01,604 [pool-38-thread-1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED: set configuration 3: [52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-07-31 01:18:01,617 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn5_1    | 2022-07-31 01:18:01,617 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn5_1    | 2022-07-31 01:18:01,619 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn5_1    | 2022-07-31 01:18:01,623 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn5_1    | 2022-07-31 01:18:01,635 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn5_1    | 2022-07-31 01:18:01,636 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn5_1    | 2022-07-31 01:18:01,636 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn5_1    | 2022-07-31 01:18:01,640 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn5_1    | 2022-07-31 01:18:01,657 [pool-38-thread-1] INFO segmented.SegmentedRaftLogWorker: new 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/106ad38c-cb28-4e98-a52d-cd003ecc1eed
dn5_1    | 2022-07-31 01:18:01,661 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn5_1    | 2022-07-31 01:18:01,661 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn5_1    | 2022-07-31 01:18:01,664 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn5_1    | 2022-07-31 01:18:01,665 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn5_1    | 2022-07-31 01:18:01,665 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn5_1    | 2022-07-31 01:18:01,665 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn5_1    | 2022-07-31 01:18:01,669 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn5_1    | 2022-07-31 01:18:01,670 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn5_1    | 2022-07-31 01:18:01,670 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn5_1    | 2022-07-31 01:18:01,702 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn5_1    | 2022-07-31 01:18:01,710 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn5_1    | 2022-07-31 01:18:01,731 [pool-38-thread-1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED: set configuration 0: [52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-07-31 01:18:01,739 [pool-38-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/106ad38c-cb28-4e98-a52d-cd003ecc1eed/current/log_0-0
dn5_1    | 2022-07-31 01:18:01,769 [pool-38-thread-1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED: set configuration 1: [52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-07-31 01:18:01,774 [pool-38-thread-1] INFO segmented.LogSegment: Successfully read 2 entries from segment file /data/metadata/ratis/106ad38c-cb28-4e98-a52d-cd003ecc1eed/current/log_1-2
dn5_1    | 2022-07-31 01:18:01,781 [pool-38-thread-1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED: set configuration 3: [52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-07-31 01:18:01,784 [pool-38-thread-1] INFO segmented.LogSegment: Successfully read 2 entries from segment file /data/metadata/ratis/106ad38c-cb28-4e98-a52d-cd003ecc1eed/current/log_inprogress_3
dn5_1    | 2022-07-31 01:18:01,785 [pool-38-thread-1] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 4
dn5_1    | 2022-07-31 01:18:01,787 [pool-38-thread-1] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 2
dn5_1    | 2022-07-31 01:18:01,805 [pool-38-thread-1] INFO raftlog.RaftLog: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-SegmentedRaftLog: commitIndex: updateToMax old=4, new=3, updated? false
dn5_1    | 2022-07-31 01:18:01,806 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn5_1    | 2022-07-31 01:18:01,813 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn5_1    | 2022-07-31 01:18:01,818 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn5_1    | 2022-07-31 01:18:01,823 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn5_1    | 2022-07-31 01:18:01,823 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn5_1    | 2022-07-31 01:18:01,824 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn5_1    | 2022-07-31 01:18:01,852 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn5_1    | 2022-07-31 01:18:01,873 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn5_1    | 2022-07-31 01:18:01,881 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn5_1    | 2022-07-31 01:18:01,881 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn5_1    | 2022-07-31 01:18:01,882 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn5_1    | 2022-07-31 01:18:01,900 [pool-38-thread-1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2: new RaftServerImpl for group-65A101075AF1:[] with ContainerStateMachine:uninitialized
dn5_1    | 2022-07-31 01:18:01,906 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om2_1    | 2022-07-31 01:18:23,817 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om2_1    | 2022-07-31 01:18:23,817 [Listener at om2/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om2_1    | 2022-07-31 01:18:24,001 [Listener at om2/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om2/10.9.0.12:9862
om2_1    | 2022-07-31 01:18:24,001 [Listener at om2/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om2 at port 9872
om2_1    | 2022-07-31 01:18:24,004 [om2-impl-thread1] INFO server.RaftServer$Division: om2@group-D66704EFC61C: start as a follower, conf=63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1    | 2022-07-31 01:18:24,005 [om2-impl-thread1] INFO server.RaftServer$Division: om2@group-D66704EFC61C: changes role from      null to FOLLOWER at term 6 for startAsFollower
om2_1    | 2022-07-31 01:18:24,007 [om2-impl-thread1] INFO impl.RoleInfo: om2: start om2@group-D66704EFC61C-FollowerState
om2_1    | 2022-07-31 01:18:24,030 [om2-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D66704EFC61C,id=om2
om2_1    | 2022-07-31 01:18:24,080 [Listener at om2/9862] INFO server.RaftServer: om2: start RPC server
om2_1    | 2022-07-31 01:18:24,287 [Listener at om2/9862] INFO server.GrpcService: om2: GrpcService started, listening on 9872
om2_1    | 2022-07-31 01:18:24,306 [Listener at om2/9862] INFO upgrade.UpgradeFinalizer: Running pre-finalized state validations for unfinalized layout features.
om2_1    | 2022-07-31 01:18:24,307 [Listener at om2/9862] INFO upgrade.UpgradeFinalizer: Running first upgrade commands for unfinalized layout features.
om2_1    | 2022-07-31 01:18:24,307 [Listener at om2/9862] INFO om.OzoneManager: Version File has different layout version (0) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om2_1    | 2022-07-31 01:18:24,325 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$428/0x000000084055fc40@2cccf134] INFO util.JvmPauseMonitor: JvmPauseMonitor-om2: Started
om2_1    | 2022-07-31 01:18:24,511 [Listener at om2/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om2_1    | 2022-07-31 01:18:24,512 [Listener at om2/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om2_1    | 2022-07-31 01:18:24,610 [Listener at om2/9862] INFO util.log: Logging initialized @67308ms to org.eclipse.jetty.util.log.Slf4jLog
om2_1    | 2022-07-31 01:18:25,052 [Listener at om2/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om2_1    | 2022-07-31 01:18:25,064 [Listener at om2/9862] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
om2_1    | 2022-07-31 01:18:25,097 [Listener at om2/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om2_1    | 2022-07-31 01:18:25,099 [Listener at om2/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om2_1    | 2022-07-31 01:18:25,099 [Listener at om2/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om2_1    | 2022-07-31 01:18:25,099 [Listener at om2/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om2_1    | 2022-07-31 01:18:25,283 [Listener at om2/9862] INFO http.HttpServer2: Jetty bound to port 9874
om2_1    | 2022-07-31 01:18:25,285 [Listener at om2/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om2_1    | 2022-07-31 01:18:25,431 [Listener at om2/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om2_1    | 2022-07-31 01:18:25,431 [Listener at om2/9862] INFO server.session: No SessionScavenger set, using defaults
om2_1    | 2022-07-31 01:18:25,438 [Listener at om2/9862] INFO server.session: node0 Scavenging every 660000ms
om2_1    | 2022-07-31 01:18:25,488 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@29170a47{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om2_1    | 2022-07-31 01:18:25,493 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4e8598d9{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om2_1    | 2022-07-31 01:18:25,872 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@75ed125a{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-15002064166537778924/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om2_1    | 2022-07-31 01:18:25,895 [Listener at om2/9862] INFO server.AbstractConnector: Started ServerConnector@c472300{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om2_1    | 2022-07-31 01:18:25,895 [Listener at om2/9862] INFO server.Server: Started @68593ms
om2_1    | 2022-07-31 01:18:25,897 [Listener at om2/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om2_1    | 2022-07-31 01:18:25,897 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om2_1    | 2022-07-31 01:18:25,899 [Listener at om2/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om2_1    | 2022-07-31 01:18:25,903 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1    | 2022-07-31 01:18:25,910 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om2_1    | 2022-07-31 01:18:25,953 [Listener at om2/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted won't move to trash
om2_1    | 2022-07-31 01:18:25,969 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@35e2b89f] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om2_1    | 2022-07-31 01:18:29,209 [om2@group-D66704EFC61C-FollowerState] INFO impl.FollowerState: om2@group-D66704EFC61C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5202506036ns, electionTimeout:5178ms
om2_1    | 2022-07-31 01:18:29,210 [om2@group-D66704EFC61C-FollowerState] INFO impl.RoleInfo: om2: shutdown om2@group-D66704EFC61C-FollowerState
om2_1    | 2022-07-31 01:18:29,211 [om2@group-D66704EFC61C-FollowerState] INFO server.RaftServer$Division: om2@group-D66704EFC61C: changes role from  FOLLOWER to CANDIDATE at term 6 for changeToCandidate
om2_1    | 2022-07-31 01:18:29,214 [om2@group-D66704EFC61C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om2_1    | 2022-07-31 01:18:29,214 [om2@group-D66704EFC61C-FollowerState] INFO impl.RoleInfo: om2: start om2@group-D66704EFC61C-LeaderElection1
om2_1    | 2022-07-31 01:18:29,316 [om2@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om2@group-D66704EFC61C-LeaderElection1 ELECTION round 0: submit vote requests at term 7 for 63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1    | 2022-07-31 01:18:30,775 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-D66704EFC61C: receive requestVote(ELECTION, om1, group-D66704EFC61C, 7, (t:6, i:98))
om2_1    | 2022-07-31 01:18:30,776 [grpc-default-executor-0] INFO impl.VoteContext: om2@group-D66704EFC61C-CANDIDATE: reject ELECTION from om1: already has voted for om2 at current term 7
om3_1    | 2022-07-31 01:17:58,900 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From eb852635f668/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2022-07-31 01:18:00,908 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From eb852635f668/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2022-07-31 01:18:02,911 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From eb852635f668/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2022-07-31 01:18:04,918 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From eb852635f668/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2022-07-31 01:18:06,920 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From eb852635f668/10.9.0.13 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1    | 2022-07-31 01:18:12,894 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1    | 2022-07-31 01:18:13,408 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om3_1    | 2022-07-31 01:18:13,416 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om3_1    | 2022-07-31 01:18:13,832 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om3_1    | 2022-07-31 01:18:13,969 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1    | 2022-07-31 01:18:13,984 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om3_1    | 2022-07-31 01:18:14,041 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om3_1    | 2022-07-31 01:18:14,562 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om3_1    | 2022-07-31 01:18:14,620 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1    | 2022-07-31 01:18:14,756 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: omservice and peers: om3:9872, om1:9872, om2:9872
om3_1    | 2022-07-31 01:18:14,818 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:6, i:98)
om3_1    | 2022-07-31 01:18:14,957 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om3_1    | 2022-07-31 01:18:15,738 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om3_1    | 2022-07-31 01:18:15,773 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1    | 2022-07-31 01:18:15,774 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om3_1    | 2022-07-31 01:18:15,774 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1    | 2022-07-31 01:18:15,774 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1    | 2022-07-31 01:18:15,776 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om3_1    | 2022-07-31 01:18:15,807 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1    | 2022-07-31 01:18:15,818 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om3_1    | 2022-07-31 01:18:15,820 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1    | 2022-07-31 01:18:16,112 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om3_1    | 2022-07-31 01:18:16,112 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om3_1    | 2022-07-31 01:18:18,497 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om3_1    | 2022-07-31 01:18:18,500 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om3_1    | 2022-07-31 01:18:18,500 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om3_1    | 2022-07-31 01:18:18,525 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1    | 2022-07-31 01:18:18,525 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1    | 2022-07-31 01:18:18,546 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1    | 2022-07-31 01:18:18,620 [om3-impl-thread1] INFO server.RaftServer: om3: found a subdirectory /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c
om3_1    | 2022-07-31 01:18:18,698 [main] INFO server.RaftServer: om3: addNew group-D66704EFC61C:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-D66704EFC61C:java.util.concurrent.CompletableFuture@4ef4f627[Not completed]
om3_1    | 2022-07-31 01:18:18,704 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om3_1    | 2022-07-31 01:18:19,307 [main] INFO om.OzoneManager: Creating RPC Server
om3_1    | 2022-07-31 01:18:19,445 [pool-26-thread-1] INFO server.RaftServer$Division: om3: new RaftServerImpl for group-D66704EFC61C:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om3_1    | 2022-07-31 01:18:19,460 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om3_1    | 2022-07-31 01:18:19,502 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om3_1    | 2022-07-31 01:18:19,508 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om3_1    | 2022-07-31 01:18:19,509 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1    | 2022-07-31 01:18:19,509 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1    | 2022-07-31 01:18:19,509 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om3_1    | 2022-07-31 01:18:19,564 [pool-26-thread-1] INFO server.RaftServer$Division: om3@group-D66704EFC61C: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
dn1_1    | 2022-07-31 01:20:04,086 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0: ConfigurationManager, init=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0], old=null, confs=<EMPTY_MAP>
dn1_1    | 2022-07-31 01:20:04,086 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn1_1    | 2022-07-31 01:20:04,086 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn1_1    | 2022-07-31 01:20:04,086 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn1_1    | 2022-07-31 01:20:04,086 [pool-42-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0 does not exist. Creating ...
dn1_1    | 2022-07-31 01:20:04,088 [pool-42-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0/in_use.lock acquired by nodename 8@b5a69c4cb320
dn1_1    | 2022-07-31 01:20:04,089 [pool-42-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0 has been successfully formatted.
dn1_1    | 2022-07-31 01:20:04,090 [pool-42-thread-1] INFO ratis.ContainerStateMachine: group-84A70A95B4C0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn1_1    | 2022-07-31 01:20:04,090 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn1_1    | 2022-07-31 01:20:04,090 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn1_1    | 2022-07-31 01:20:04,090 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn1_1    | 2022-07-31 01:20:04,091 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2022-07-31 01:20:04,091 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn1_1    | 2022-07-31 01:20:04,091 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2022-07-31 01:20:04,091 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn1_1    | 2022-07-31 01:20:04,092 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn1_1    | 2022-07-31 01:20:04,097 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: new 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0
dn1_1    | 2022-07-31 01:20:04,098 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn1_1    | 2022-07-31 01:20:04,100 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn1_1    | 2022-07-31 01:20:04,100 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2022-07-31 01:20:04,100 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn1_1    | 2022-07-31 01:20:04,100 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn1_1    | 2022-07-31 01:20:04,100 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn1_1    | 2022-07-31 01:20:04,100 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn1_1    | 2022-07-31 01:20:04,100 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn1_1    | 2022-07-31 01:20:04,101 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn1_1    | 2022-07-31 01:20:04,106 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn1_1    | 2022-07-31 01:20:04,106 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn1_1    | 2022-07-31 01:20:04,106 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn1_1    | 2022-07-31 01:20:04,107 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn1_1    | 2022-07-31 01:20:04,109 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn1_1    | 2022-07-31 01:20:04,109 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn1_1    | 2022-07-31 01:20:04,109 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn1_1    | 2022-07-31 01:20:04,109 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn1_1    | 2022-07-31 01:20:04,109 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn1_1    | 2022-07-31 01:20:04,109 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn1_1    | 2022-07-31 01:20:04,110 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn1_1    | 2022-07-31 01:20:04,110 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn1_1    | 2022-07-31 01:20:04,110 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn1_1    | 2022-07-31 01:20:04,110 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn1_1    | 2022-07-31 01:20:04,110 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn1_1    | 2022-07-31 01:20:04,110 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0: start as a follower, conf=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0], old=null
dn1_1    | 2022-07-31 01:20:04,110 [pool-42-thread-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn1_1    | 2022-07-31 01:20:04,110 [pool-42-thread-1] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState
dn1_1    | 2022-07-31 01:20:04,113 [pool-42-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-84A70A95B4C0,id=609e7f2d-9474-472f-937f-8fa0a0bbb327
dn1_1    | 2022-07-31 01:20:04,115 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0
dn1_1    | 2022-07-31 01:20:04,273 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0.
dn3_1    | 2022-07-31 01:19:32,880 [grpc-default-executor-0] INFO server.GrpcLogAppender: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246->609e7f2d-9474-472f-937f-8fa0a0bbb327-AppendLogResponseHandler: follower responses appendEntries COMPLETED
dn3_1    | 2022-07-31 01:19:32,883 [grpc-default-executor-0] INFO leader.FollowerInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246->609e7f2d-9474-472f-937f-8fa0a0bbb327: nextIndex: updateUnconditionally 30 -> 29
dn3_1    | 2022-07-31 01:19:32,890 [grpc-default-executor-0] INFO server.GrpcLogAppender: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246->11cba143-91f8-47cb-8422-c32a1e2d51df-AppendLogResponseHandler: follower responses appendEntries COMPLETED
dn3_1    | 2022-07-31 01:19:32,890 [grpc-default-executor-0] INFO leader.FollowerInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246->11cba143-91f8-47cb-8422-c32a1e2d51df: nextIndex: updateUnconditionally 30 -> 29
dn3_1    | 2022-07-31 01:19:32,891 [Command processor thread] INFO impl.StateMachineUpdater: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-StateMachineUpdater: set stopIndex = 29
dn3_1    | 2022-07-31 01:19:32,891 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-75041C4AA246: Taking a snapshot at:(t:12, i:29) file /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/sm/snapshot.12_29
dn3_1    | 2022-07-31 01:19:32,896 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-75041C4AA246: Finished taking a snapshot at:(t:12, i:29) file:/data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246/sm/snapshot.12_29 took: 5 ms
dn3_1    | 2022-07-31 01:19:32,897 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-StateMachineUpdater] INFO impl.StateMachineUpdater: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-StateMachineUpdater: Took a snapshot at index 29
dn3_1    | 2022-07-31 01:19:32,897 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-StateMachineUpdater] INFO impl.StateMachineUpdater: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-StateMachineUpdater: snapshotIndex: updateIncreasingly 23 -> 29
dn3_1    | 2022-07-31 01:19:32,901 [Command processor thread] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246: closes. applyIndex: 29
dn3_1    | 2022-07-31 01:19:32,901 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
dn3_1    | 2022-07-31 01:19:32,902 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246-SegmentedRaftLogWorker close()
dn3_1    | 2022-07-31 01:19:32,912 [Command processor thread] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-75041C4AA246: Succeed to remove RaftStorageDirectory Storage Directory /data/metadata/ratis/369e0910-4276-41cc-941b-75041c4aa246
dn3_1    | 2022-07-31 01:19:32,913 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline PipelineID=369e0910-4276-41cc-941b-75041c4aa246 command on datanode 3fc9f139-dd93-41e7-b235-52ce94d6fe3c.
dn3_1    | 2022-07-31 01:19:32,913 [Command processor thread] INFO server.RaftServer: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: remove  FOLLOWER 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610:t14, leader=52aca038-7576-46a0-9ccd-b8aed29078e2, voted=52aca038-7576-46a0-9ccd-b8aed29078e2, raftlog=3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-SegmentedRaftLog:OPENED:c16, conf=13: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null RUNNING
dn3_1    | 2022-07-31 01:19:32,913 [Command processor thread] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610: shutdown
dn3_1    | 2022-07-31 01:19:32,913 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-7BB2A1276610,id=3fc9f139-dd93-41e7-b235-52ce94d6fe3c
dn3_1    | 2022-07-31 01:19:32,914 [Command processor thread] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: shutdown 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-FollowerState
dn3_1    | 2022-07-31 01:19:32,914 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-FollowerState] INFO impl.FollowerState: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-FollowerState was interrupted
dn3_1    | 2022-07-31 01:19:32,915 [Command processor thread] INFO impl.StateMachineUpdater: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-StateMachineUpdater: set stopIndex = 16
dn3_1    | 2022-07-31 01:19:32,915 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-7BB2A1276610: Taking a snapshot at:(t:14, i:16) file /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/sm/snapshot.14_16
dn3_1    | 2022-07-31 01:19:32,917 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-7BB2A1276610: Finished taking a snapshot at:(t:14, i:16) file:/data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/sm/snapshot.14_16 took: 2 ms
dn3_1    | 2022-07-31 01:19:32,918 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-StateMachineUpdater] INFO impl.StateMachineUpdater: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-StateMachineUpdater: Took a snapshot at index 16
dn3_1    | 2022-07-31 01:19:32,918 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-StateMachineUpdater] INFO impl.StateMachineUpdater: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-StateMachineUpdater: snapshotIndex: updateIncreasingly 12 -> 16
dn3_1    | 2022-07-31 01:19:32,918 [Command processor thread] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610: closes. applyIndex: 16
dn3_1    | 2022-07-31 01:19:32,918 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
dn3_1    | 2022-07-31 01:19:32,919 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610-SegmentedRaftLogWorker close()
dn3_1    | 2022-07-31 01:19:32,923 [Command processor thread] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-7BB2A1276610: Succeed to remove RaftStorageDirectory Storage Directory /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610
dn3_1    | 2022-07-31 01:19:32,923 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline PipelineID=b88205de-97a2-4448-8e49-7bb2a1276610 command on datanode 3fc9f139-dd93-41e7-b235-52ce94d6fe3c.
dn3_1    | 2022-07-31 01:19:32,923 [Command processor thread] INFO server.RaftServer: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: remove    LEADER 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6:t4, leader=3fc9f139-dd93-41e7-b235-52ce94d6fe3c, voted=3fc9f139-dd93-41e7-b235-52ce94d6fe3c, raftlog=3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-SegmentedRaftLog:OPENED:c6, conf=5: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1], old=null RUNNING
dn3_1    | 2022-07-31 01:19:32,924 [Command processor thread] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6: shutdown
dn2_1    | 2022-07-31 01:19:33,600 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
dn2_1    | 2022-07-31 01:19:33,602 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB-SegmentedRaftLogWorker close()
dn2_1    | 2022-07-31 01:19:33,606 [Command processor thread] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-6999419922EB: Succeed to remove RaftStorageDirectory Storage Directory /data/metadata/ratis/8145371a-b336-4e64-a95d-6999419922eb
dn2_1    | 2022-07-31 01:19:33,606 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline PipelineID=8145371a-b336-4e64-a95d-6999419922eb command on datanode 11cba143-91f8-47cb-8422-c32a1e2d51df.
dn2_1    | 2022-07-31 01:19:33,633 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 11cba143-91f8-47cb-8422-c32a1e2d51df: Completed APPEND_ENTRIES, lastRequest: 609e7f2d-9474-472f-937f-8fa0a0bbb327->11cba143-91f8-47cb-8422-c32a1e2d51df#295-t11,previous=(t:11, i:42),leaderCommit=42,initializing? true,entries: size=1, first=(t:11, i:43), METADATAENTRY(c:42)
dn2_1    | 2022-07-31 01:19:34,013 [org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@1e54a6b1] INFO commandhandler.DeleteBlocksCommandHandler: Start to delete container blocks, TXIDs=[1(0)], numOfContainers=1, numOfBlocks=3
dn2_1    | 2022-07-31 01:20:03,532 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df: new RaftServerImpl for group-26397C6FFFAD:[11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:1] with ContainerStateMachine:uninitialized
dn2_1    | 2022-07-31 01:20:03,533 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn2_1    | 2022-07-31 01:20:03,533 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn2_1    | 2022-07-31 01:20:03,533 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn2_1    | 2022-07-31 01:20:03,533 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn2_1    | 2022-07-31 01:20:03,533 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn2_1    | 2022-07-31 01:20:03,534 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn2_1    | 2022-07-31 01:20:03,534 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD: ConfigurationManager, init=-1: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:1], old=null, confs=<EMPTY_MAP>
dn2_1    | 2022-07-31 01:20:03,534 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn2_1    | 2022-07-31 01:20:03,535 [Command processor thread] INFO server.RaftServer: 11cba143-91f8-47cb-8422-c32a1e2d51df: addNew group-26397C6FFFAD:[11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:1] returns group-26397C6FFFAD:java.util.concurrent.CompletableFuture@55a3e0e5[Not completed]
dn2_1    | 2022-07-31 01:20:03,538 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn2_1    | 2022-07-31 01:20:03,538 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn2_1    | 2022-07-31 01:20:03,539 [pool-42-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/da610dcf-61e8-4e48-8ead-26397c6fffad does not exist. Creating ...
dn2_1    | 2022-07-31 01:20:03,544 [pool-42-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/da610dcf-61e8-4e48-8ead-26397c6fffad/in_use.lock acquired by nodename 8@c5b89a034b5d
dn2_1    | 2022-07-31 01:20:03,553 [pool-42-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/da610dcf-61e8-4e48-8ead-26397c6fffad has been successfully formatted.
dn2_1    | 2022-07-31 01:20:03,554 [pool-42-thread-1] INFO ratis.ContainerStateMachine: group-26397C6FFFAD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn2_1    | 2022-07-31 01:20:03,562 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn2_1    | 2022-07-31 01:20:03,574 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn2_1    | 2022-07-31 01:20:03,580 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn2_1    | 2022-07-31 01:20:03,581 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2022-07-31 01:20:03,581 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn2_1    | 2022-07-31 01:20:03,581 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2022-07-31 01:20:03,582 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn2_1    | 2022-07-31 01:20:03,584 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn2_1    | 2022-07-31 01:20:03,585 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: new 11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/da610dcf-61e8-4e48-8ead-26397c6fffad
dn2_1    | 2022-07-31 01:20:03,585 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn2_1    | 2022-07-31 01:20:03,585 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn2_1    | 2022-07-31 01:20:03,585 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2022-07-31 01:20:03,585 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn2_1    | 2022-07-31 01:20:03,585 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn2_1    | 2022-07-31 01:20:03,586 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn2_1    | 2022-07-31 01:20:03,586 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn2_1    | 2022-07-31 01:20:03,586 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn2_1    | 2022-07-31 01:20:03,587 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn2_1    | 2022-07-31 01:20:03,587 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn2_1    | 2022-07-31 01:20:03,587 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn2_1    | 2022-07-31 01:20:03,587 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om1_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1    | 2022-07-31 01:17:27,259 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1    | /************************************************************
om1_1    | STARTUP_MSG: Starting OzoneManager
om1_1    | STARTUP_MSG:   host = 25d3afb12a88/10.9.0.11
om1_1    | STARTUP_MSG:   args = [--upgrade]
om1_1    | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
dn3_1    | 2022-07-31 01:19:32,924 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-039BB00381B6,id=3fc9f139-dd93-41e7-b235-52ce94d6fe3c
dn3_1    | 2022-07-31 01:19:32,924 [Command processor thread] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: shutdown 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-LeaderStateImpl
dn3_1    | 2022-07-31 01:19:32,924 [Command processor thread] INFO impl.PendingRequests: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-PendingRequests: sendNotLeaderResponses
dn3_1    | 2022-07-31 01:19:32,925 [Command processor thread] INFO impl.StateMachineUpdater: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-StateMachineUpdater: set stopIndex = 6
dn3_1    | 2022-07-31 01:19:32,925 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-039BB00381B6: Taking a snapshot at:(t:4, i:6) file /data/metadata/ratis/69ee0657-77f1-4021-b38b-039bb00381b6/sm/snapshot.4_6
dn3_1    | 2022-07-31 01:19:32,927 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-039BB00381B6: Finished taking a snapshot at:(t:4, i:6) file:/data/metadata/ratis/69ee0657-77f1-4021-b38b-039bb00381b6/sm/snapshot.4_6 took: 1 ms
dn3_1    | 2022-07-31 01:19:32,927 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-StateMachineUpdater] INFO impl.StateMachineUpdater: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-StateMachineUpdater: Took a snapshot at index 6
dn3_1    | 2022-07-31 01:19:32,927 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-StateMachineUpdater] INFO impl.StateMachineUpdater: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-StateMachineUpdater: snapshotIndex: updateIncreasingly 4 -> 6
dn3_1    | 2022-07-31 01:19:32,927 [Command processor thread] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6: closes. applyIndex: 6
dn3_1    | 2022-07-31 01:19:32,928 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
dn3_1    | 2022-07-31 01:19:32,929 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6-SegmentedRaftLogWorker close()
dn3_1    | 2022-07-31 01:19:32,931 [Command processor thread] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-039BB00381B6: Succeed to remove RaftStorageDirectory Storage Directory /data/metadata/ratis/69ee0657-77f1-4021-b38b-039bb00381b6
dn3_1    | 2022-07-31 01:19:32,931 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline PipelineID=69ee0657-77f1-4021-b38b-039bb00381b6 command on datanode 3fc9f139-dd93-41e7-b235-52ce94d6fe3c.
dn3_1    | 2022-07-31 01:19:33,818 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: Completed APPEND_ENTRIES, lastRequest: 52aca038-7576-46a0-9ccd-b8aed29078e2->3fc9f139-dd93-41e7-b235-52ce94d6fe3c#255-t14,previous=(t:14, i:15),leaderCommit=15,initializing? true,entries: size=1, first=(t:14, i:16), METADATAENTRY(c:15)
dn3_1    | 2022-07-31 01:20:03,300 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn3_1    | 2022-07-31 01:20:04,219 [grpc-default-executor-0] INFO server.RaftServer: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: addNew group-84A70A95B4C0:[3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0] returns group-84A70A95B4C0:java.util.concurrent.CompletableFuture@3d6f1337[Not completed]
dn3_1    | 2022-07-31 01:20:04,221 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: new RaftServerImpl for group-84A70A95B4C0:[3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
dn3_1    | 2022-07-31 01:20:04,221 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn3_1    | 2022-07-31 01:20:04,221 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn3_1    | 2022-07-31 01:20:04,221 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn3_1    | 2022-07-31 01:20:04,221 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn3_1    | 2022-07-31 01:20:04,221 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn3_1    | 2022-07-31 01:20:04,221 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn3_1    | 2022-07-31 01:20:04,222 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0: ConfigurationManager, init=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
dn3_1    | 2022-07-31 01:20:04,222 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn3_1    | 2022-07-31 01:20:04,223 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn3_1    | 2022-07-31 01:20:04,223 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn3_1    | 2022-07-31 01:20:04,223 [pool-34-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0 does not exist. Creating ...
dn3_1    | 2022-07-31 01:20:04,225 [pool-34-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0/in_use.lock acquired by nodename 6@6dca380edee9
dn3_1    | 2022-07-31 01:20:04,227 [pool-34-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0 has been successfully formatted.
dn3_1    | 2022-07-31 01:20:04,228 [pool-34-thread-1] INFO ratis.ContainerStateMachine: group-84A70A95B4C0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn3_1    | 2022-07-31 01:20:04,228 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn3_1    | 2022-07-31 01:20:04,228 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn3_1    | 2022-07-31 01:20:04,228 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn3_1    | 2022-07-31 01:20:04,228 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2022-07-31 01:20:04,228 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om2_1    | 2022-07-31 01:18:30,852 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-D66704EFC61C replies to ELECTION vote request: om1<-om2#0:FAIL-t7. Peer's state: om2@group-D66704EFC61C:t7, leader=null, voted=om2, raftlog=om2@group-D66704EFC61C-SegmentedRaftLog:OPENED:c98, conf=63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1    | 2022-07-31 01:18:30,928 [om2@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om2@group-D66704EFC61C-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om2_1    | 2022-07-31 01:18:30,936 [om2@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection:   Response 0: om2<-om1#0:FAIL-t7
om2_1    | 2022-07-31 01:18:30,937 [om2@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection:   Response 1: om2<-om3#0:FAIL-t7
om2_1    | 2022-07-31 01:18:30,938 [om2@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om2@group-D66704EFC61C-LeaderElection1 ELECTION round 0: result REJECTED
om2_1    | 2022-07-31 01:18:30,941 [om2@group-D66704EFC61C-LeaderElection1] INFO server.RaftServer$Division: om2@group-D66704EFC61C: changes role from CANDIDATE to FOLLOWER at term 7 for REJECTED
om2_1    | 2022-07-31 01:18:30,944 [om2@group-D66704EFC61C-LeaderElection1] INFO impl.RoleInfo: om2: shutdown om2@group-D66704EFC61C-LeaderElection1
om2_1    | 2022-07-31 01:18:30,945 [om2@group-D66704EFC61C-LeaderElection1] INFO impl.RoleInfo: om2: start om2@group-D66704EFC61C-FollowerState
om2_1    | 2022-07-31 01:18:30,986 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-D66704EFC61C: receive requestVote(ELECTION, om3, group-D66704EFC61C, 7, (t:6, i:98))
om2_1    | 2022-07-31 01:18:30,987 [grpc-default-executor-0] INFO impl.VoteContext: om2@group-D66704EFC61C-FOLLOWER: reject ELECTION from om3: already has voted for om2 at current term 7
om2_1    | 2022-07-31 01:18:30,987 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-D66704EFC61C replies to ELECTION vote request: om3<-om2#0:FAIL-t7. Peer's state: om2@group-D66704EFC61C:t7, leader=null, voted=om2, raftlog=om2@group-D66704EFC61C-SegmentedRaftLog:OPENED:c98, conf=63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1    | 2022-07-31 01:18:36,057 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-D66704EFC61C: receive requestVote(ELECTION, om1, group-D66704EFC61C, 8, (t:6, i:98))
om2_1    | 2022-07-31 01:18:36,058 [grpc-default-executor-0] INFO impl.VoteContext: om2@group-D66704EFC61C-FOLLOWER: accept ELECTION from om1: our priority 0 <= candidate's priority 0
om2_1    | 2022-07-31 01:18:36,059 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-D66704EFC61C: changes role from  FOLLOWER to FOLLOWER at term 8 for candidate:om1
om2_1    | 2022-07-31 01:18:36,059 [grpc-default-executor-0] INFO impl.RoleInfo: om2: shutdown om2@group-D66704EFC61C-FollowerState
om2_1    | 2022-07-31 01:18:36,059 [om2@group-D66704EFC61C-FollowerState] INFO impl.FollowerState: om2@group-D66704EFC61C-FollowerState was interrupted
om2_1    | 2022-07-31 01:18:36,060 [grpc-default-executor-0] INFO impl.RoleInfo: om2: start om2@group-D66704EFC61C-FollowerState
om2_1    | 2022-07-31 01:18:36,066 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-D66704EFC61C replies to ELECTION vote request: om1<-om2#0:OK-t8. Peer's state: om2@group-D66704EFC61C:t8, leader=null, voted=om1, raftlog=om2@group-D66704EFC61C-SegmentedRaftLog:OPENED:c98, conf=63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1    | 2022-07-31 01:18:36,256 [om2-server-thread1] INFO server.RaftServer$Division: om2@group-D66704EFC61C: change Leader from null to om1 at term 8 for appendEntries, leader elected after 15402ms
om2_1    | 2022-07-31 01:18:36,301 [om2-server-thread2] INFO server.RaftServer$Division: om2@group-D66704EFC61C: set configuration 99: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1    | 2022-07-31 01:18:36,308 [om2-server-thread2] INFO segmented.SegmentedRaftLogWorker: om2@group-D66704EFC61C-SegmentedRaftLogWorker: Rolling segment log-63_98 to index:98
om2_1    | 2022-07-31 01:18:36,315 [om2@group-D66704EFC61C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om2@group-D66704EFC61C-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_inprogress_63 to /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_63-98
om2_1    | 2022-07-31 01:18:36,364 [om2@group-D66704EFC61C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om2@group-D66704EFC61C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_inprogress_99
om2_1    | 2022-07-31 01:18:36,728 [om2@group-D66704EFC61C-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om2_1    | [id: "om1"
om2_1    | address: "om1:9872"
om2_1    | , id: "om3"
om2_1    | address: "om3:9872"
om2_1    | , id: "om2"
om2_1    | address: "om2:9872"
om2_1    | ]
om2_1    | 2022-07-31 01:20:17,627 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: Finalization started.
om2_1    | 2022-07-31 01:20:17,628 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: ERASURE_CODED_STORAGE_SUPPORT.
om2_1    | 2022-07-31 01:20:17,634 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.AbstractLayoutVersionManager: Layout feature ERASURE_CODED_STORAGE_SUPPORT has been finalized.
om2_1    | 2022-07-31 01:20:17,634 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: BUCKET_LAYOUT_SUPPORT.
om2_1    | 2022-07-31 01:20:17,635 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.AbstractLayoutVersionManager: Layout feature BUCKET_LAYOUT_SUPPORT has been finalized.
om2_1    | 2022-07-31 01:20:17,636 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: MULTITENANCY_SCHEMA.
om2_1    | 2022-07-31 01:20:17,637 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.AbstractLayoutVersionManager: Layout feature MULTITENANCY_SCHEMA has been finalized.
om2_1    | 2022-07-31 01:20:17,637 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.AbstractLayoutVersionManager: Finalization is complete.
om2_1    | 2022-07-31 01:20:17,637 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: Finalization is done.
om2_1    | 2022-07-31 01:20:17,644 [OMDoubleBufferFlushThread] INFO upgrade.OMFinalizeUpgradeResponse: Layout version to persist to DB : 3
om2_1    | 2022-07-31 01:21:33,630 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:new2-volume for user:hadoop
om2_1    | 2022-07-31 01:21:36,659 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: new2-bucket of layout LEGACY in volume: new2-volume
om2_1    | 2022-07-31 01:21:45,649 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: new2-bucket of layout LEGACY in volume: s3v
om2_1    | 2022-07-31 01:21:53,952 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:new2-bucket in volume:s3v
om2_1    | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
dn5_1    | 2022-07-31 01:18:01,906 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn5_1    | 2022-07-31 01:18:01,918 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn5_1    | 2022-07-31 01:18:01,919 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn5_1    | 2022-07-31 01:18:01,919 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn5_1    | 2022-07-31 01:18:01,919 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn5_1    | 2022-07-31 01:18:01,919 [pool-38-thread-1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn5_1    | 2022-07-31 01:18:01,920 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn5_1    | 2022-07-31 01:18:01,922 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn5_1    | 2022-07-31 01:18:01,936 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn5_1    | 2022-07-31 01:18:01,960 [pool-38-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/in_use.lock acquired by nodename 6@6c1f77753501
dn5_1    | 2022-07-31 01:18:01,960 [pool-38-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=8, votedFor=609e7f2d-9474-472f-937f-8fa0a0bbb327} from /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/current/raft-meta
dn5_1    | 2022-07-31 01:18:01,962 [pool-38-thread-1] INFO ratis.ContainerStateMachine: group-65A101075AF1: Setting the last applied index to (t:8, i:35)
dn5_1    | 2022-07-31 01:18:01,989 [pool-38-thread-1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1: set configuration 31: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn5_1    | 2022-07-31 01:18:01,991 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn5_1    | 2022-07-31 01:18:01,991 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn5_1    | 2022-07-31 01:18:01,991 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn5_1    | 2022-07-31 01:18:01,991 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn5_1    | 2022-07-31 01:18:01,992 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn5_1    | 2022-07-31 01:18:01,993 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn5_1    | 2022-07-31 01:18:02,015 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn5_1    | 2022-07-31 01:18:02,016 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn5_1    | 2022-07-31 01:18:02,016 [pool-38-thread-1] INFO segmented.SegmentedRaftLogWorker: new 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1
dn5_1    | 2022-07-31 01:18:02,025 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn5_1    | 2022-07-31 01:18:02,025 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn5_1    | 2022-07-31 01:18:02,025 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn5_1    | 2022-07-31 01:18:02,026 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn5_1    | 2022-07-31 01:18:02,040 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn5_1    | 2022-07-31 01:18:02,040 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn5_1    | 2022-07-31 01:18:02,041 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn5_1    | 2022-07-31 01:18:02,041 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn5_1    | 2022-07-31 01:18:02,042 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn5_1    | 2022-07-31 01:18:02,043 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn5_1    | 2022-07-31 01:18:02,043 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn5_1    | 2022-07-31 01:18:02,052 [pool-38-thread-1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1: set configuration 0: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn5_1    | 2022-07-31 01:18:02,066 [pool-38-thread-1] INFO segmented.LogSegment: Successfully read 13 entries from segment file /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/current/log_0-12
dn5_1    | 2022-07-31 01:18:02,077 [pool-38-thread-1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1: set configuration 13: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn5_1    | 2022-07-31 01:18:02,124 [Datanode State Machine Task Thread - 1] WARN statemachine.SCMConnectionManager: Trying to add an existing SCM Machine to Machines group. Ignoring the request.
dn5_1    | 2022-07-31 01:18:02,128 [Datanode State Machine Task Thread - 1] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/10.9.0.20:9891
dn5_1    | 2022-07-31 01:18:02,148 [pool-38-thread-1] INFO segmented.LogSegment: Successfully read 18 entries from segment file /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/current/log_13-30
dn5_1    | 2022-07-31 01:18:02,157 [pool-38-thread-1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1: set configuration 31: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn3_1    | 2022-07-31 01:20:04,228 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2022-07-31 01:20:04,229 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn3_1    | 2022-07-31 01:20:04,229 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn3_1    | 2022-07-31 01:20:04,229 [pool-34-thread-1] INFO segmented.SegmentedRaftLogWorker: new 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0
dn3_1    | 2022-07-31 01:20:04,229 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn3_1    | 2022-07-31 01:20:04,229 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn3_1    | 2022-07-31 01:20:04,229 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2022-07-31 01:20:04,229 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn3_1    | 2022-07-31 01:20:04,229 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn3_1    | 2022-07-31 01:20:04,229 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn3_1    | 2022-07-31 01:20:04,229 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn3_1    | 2022-07-31 01:20:04,229 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn3_1    | 2022-07-31 01:20:04,229 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn3_1    | 2022-07-31 01:20:04,229 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn3_1    | 2022-07-31 01:20:04,229 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn3_1    | 2022-07-31 01:20:04,230 [pool-34-thread-1] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn3_1    | 2022-07-31 01:20:04,230 [pool-34-thread-1] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn3_1    | 2022-07-31 01:20:04,242 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn3_1    | 2022-07-31 01:20:04,242 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn3_1    | 2022-07-31 01:20:04,242 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn3_1    | 2022-07-31 01:20:04,242 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn3_1    | 2022-07-31 01:20:04,242 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn3_1    | 2022-07-31 01:20:04,242 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn3_1    | 2022-07-31 01:20:04,243 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn3_1    | 2022-07-31 01:20:04,243 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn3_1    | 2022-07-31 01:20:04,244 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn3_1    | 2022-07-31 01:20:04,244 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn3_1    | 2022-07-31 01:20:04,244 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn3_1    | 2022-07-31 01:20:04,244 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0: start as a follower, conf=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn3_1    | 2022-07-31 01:20:04,244 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn3_1    | 2022-07-31 01:20:04,244 [pool-34-thread-1] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState
dn3_1    | 2022-07-31 01:20:04,249 [pool-34-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-84A70A95B4C0,id=3fc9f139-dd93-41e7-b235-52ce94d6fe3c
dn3_1    | 2022-07-31 01:20:09,136 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0: receive requestVote(ELECTION, 609e7f2d-9474-472f-937f-8fa0a0bbb327, group-84A70A95B4C0, 1, (t:0, i:0))
dn3_1    | 2022-07-31 01:20:09,137 [grpc-default-executor-0] INFO impl.VoteContext: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FOLLOWER: reject ELECTION from 609e7f2d-9474-472f-937f-8fa0a0bbb327: our priority 1 > candidate's priority 0
dn3_1    | 2022-07-31 01:20:09,137 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:609e7f2d-9474-472f-937f-8fa0a0bbb327
dn3_1    | 2022-07-31 01:20:09,137 [grpc-default-executor-0] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: shutdown 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState
dn3_1    | 2022-07-31 01:20:09,137 [grpc-default-executor-0] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState
dn3_1    | 2022-07-31 01:20:09,138 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState] INFO impl.FollowerState: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState was interrupted
dn3_1    | 2022-07-31 01:20:09,139 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0 replies to ELECTION vote request: 609e7f2d-9474-472f-937f-8fa0a0bbb327<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:FAIL-t1. Peer's state: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0:t1, leader=null, voted=null, raftlog=3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-SegmentedRaftLog:OPENED:c-1, conf=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn3_1    | 2022-07-31 01:20:14,242 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0: receive requestVote(ELECTION, 609e7f2d-9474-472f-937f-8fa0a0bbb327, group-84A70A95B4C0, 2, (t:0, i:0))
dn4_1    | 2022-07-31 01:18:31,081 [310a080d-f635-46ff-a53d-49cc9a09fa5c-server-thread1] INFO segmented.SegmentedRaftLogWorker: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-SegmentedRaftLogWorker: Rolling segment log-3_12 to index:12
dn4_1    | 2022-07-31 01:18:31,114 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/current/log_inprogress_3 to /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/current/log_3-12
dn4_1    | 2022-07-31 01:18:31,124 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/current/log_inprogress_13
dn4_1    | 2022-07-31 01:18:46,668 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn4_1    | 2022-07-31 01:18:46,669 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn4_1    | 2022-07-31 01:18:46,670 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn4_1    | 2022-07-31 01:18:46,670 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 2001 to close, current state is: CLOSING
dn4_1    | 2022-07-31 01:18:46,670 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn4_1    | 2022-07-31 01:18:46,671 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn4_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn4_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
om3_1    | 2022-07-31 01:18:19,596 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1    | 2022-07-31 01:18:19,635 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om3_1    | 2022-07-31 01:18:19,638 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om3_1    | 2022-07-31 01:18:19,838 [pool-26-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/in_use.lock acquired by nodename 7@eb852635f668
om3_1    | 2022-07-31 01:18:19,944 [pool-26-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=6, votedFor=om2} from /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/raft-meta
om3_1    | 2022-07-31 01:18:20,632 [pool-26-thread-1] INFO server.RaftServer$Division: om3@group-D66704EFC61C: set configuration 63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1    | 2022-07-31 01:18:20,639 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om3_1    | 2022-07-31 01:18:20,645 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om3_1    | 2022-07-31 01:18:20,731 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om3_1    | 2022-07-31 01:18:20,737 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1    | 2022-07-31 01:18:20,753 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om3_1    | 2022-07-31 01:18:20,844 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1    | 2022-07-31 01:18:20,914 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om3_1    | 2022-07-31 01:18:20,914 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om3_1    | 2022-07-31 01:18:20,972 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: new om3@group-D66704EFC61C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c
om3_1    | 2022-07-31 01:18:20,981 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om3_1    | 2022-07-31 01:18:20,982 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om3_1    | 2022-07-31 01:18:20,988 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1    | 2022-07-31 01:18:21,000 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om3_1    | 2022-07-31 01:18:21,052 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om3_1    | 2022-07-31 01:18:21,055 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om3_1    | 2022-07-31 01:18:21,056 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om3_1    | 2022-07-31 01:18:21,062 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om3_1    | 2022-07-31 01:18:21,142 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om3_1    | 2022-07-31 01:18:21,146 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om3_1    | 2022-07-31 01:18:21,155 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om3_1    | 2022-07-31 01:18:21,394 [pool-26-thread-1] INFO server.RaftServer$Division: om3@group-D66704EFC61C: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1    | 2022-07-31 01:18:21,448 [pool-26-thread-1] INFO segmented.LogSegment: Successfully read 21 entries from segment file /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_0-20
om3_1    | 2022-07-31 01:18:21,453 [pool-26-thread-1] INFO server.RaftServer$Division: om3@group-D66704EFC61C: set configuration 21: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1    | 2022-07-31 01:18:21,485 [pool-26-thread-1] INFO segmented.LogSegment: Successfully read 42 entries from segment file /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_21-62
om3_1    | 2022-07-31 01:18:21,487 [pool-26-thread-1] INFO server.RaftServer$Division: om3@group-D66704EFC61C: set configuration 63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1    | 2022-07-31 01:18:21,498 [pool-26-thread-1] INFO segmented.LogSegment: Successfully read 36 entries from segment file /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_inprogress_63
om3_1    | 2022-07-31 01:18:21,499 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-D66704EFC61C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 98
om3_1    | 2022-07-31 01:18:21,499 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-D66704EFC61C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 62
om3_1    | 2022-07-31 01:18:22,038 [pool-26-thread-1] INFO raftlog.RaftLog: om3@group-D66704EFC61C-SegmentedRaftLog: commitIndex: updateToMax old=98, new=97, updated? false
om3_1    | 2022-07-31 01:18:22,043 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om3_1    | 2022-07-31 01:18:22,046 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om3_1    | 2022-07-31 01:18:22,046 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om3_1    | 2022-07-31 01:18:22,049 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om3_1    | 2022-07-31 01:18:22,056 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om3_1    | 2022-07-31 01:18:22,056 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om3_1    | 2022-07-31 01:18:22,341 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1    | 2022-07-31 01:18:22,356 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om3_1    | 2022-07-31 01:18:22,356 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om3_1    | 2022-07-31 01:18:22,356 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om3_1    | 2022-07-31 01:18:22,357 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om3_1    | 2022-07-31 01:18:22,555 [main] INFO reflections.Reflections: Reflections took 2886 ms to scan 8 urls, producing 23 keys and 513 values [using 2 cores]
om3_1    | 2022-07-31 01:18:22,931 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1    | 2022-07-31 01:18:22,985 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om3_1    | 2022-07-31 01:18:23,506 [Listener at om3/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om3_1    | 2022-07-31 01:18:23,564 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om3_1    | 2022-07-31 01:18:23,564 [Listener at om3/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om3_1    | 2022-07-31 01:18:23,756 [Listener at om3/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om3/10.9.0.13:9862
om3_1    | 2022-07-31 01:18:23,756 [Listener at om3/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om3 at port 9872
om3_1    | 2022-07-31 01:18:23,759 [om3-impl-thread1] INFO server.RaftServer$Division: om3@group-D66704EFC61C: start as a follower, conf=63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1    | 2022-07-31 01:18:23,762 [om3-impl-thread1] INFO server.RaftServer$Division: om3@group-D66704EFC61C: changes role from      null to FOLLOWER at term 6 for startAsFollower
om3_1    | 2022-07-31 01:18:23,766 [om3-impl-thread1] INFO impl.RoleInfo: om3: start om3@group-D66704EFC61C-FollowerState
om3_1    | 2022-07-31 01:18:23,781 [om3-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D66704EFC61C,id=om3
om3_1    | 2022-07-31 01:18:23,792 [Listener at om3/9862] INFO server.RaftServer: om3: start RPC server
om3_1    | 2022-07-31 01:18:23,992 [Listener at om3/9862] INFO server.GrpcService: om3: GrpcService started, listening on 9872
om3_1    | 2022-07-31 01:18:24,006 [Listener at om3/9862] INFO upgrade.UpgradeFinalizer: Running pre-finalized state validations for unfinalized layout features.
om3_1    | 2022-07-31 01:18:24,008 [Listener at om3/9862] INFO upgrade.UpgradeFinalizer: Running first upgrade commands for unfinalized layout features.
om3_1    | 2022-07-31 01:18:24,013 [Listener at om3/9862] INFO om.OzoneManager: Version File has different layout version (0) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om3_1    | 2022-07-31 01:18:24,025 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$428/0x000000084055fc40@743c3520] INFO util.JvmPauseMonitor: JvmPauseMonitor-om3: Started
om3_1    | 2022-07-31 01:18:24,206 [Listener at om3/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om3_1    | 2022-07-31 01:18:24,207 [Listener at om3/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om3_1    | 2022-07-31 01:18:24,304 [Listener at om3/9862] INFO util.log: Logging initialized @68447ms to org.eclipse.jetty.util.log.Slf4jLog
om3_1    | 2022-07-31 01:18:24,644 [Listener at om3/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om3_1    | 2022-07-31 01:18:24,663 [Listener at om3/9862] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
om3_1    | 2022-07-31 01:18:24,679 [Listener at om3/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om3_1    | 2022-07-31 01:18:24,686 [Listener at om3/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om3_1    | 2022-07-31 01:18:24,688 [Listener at om3/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om3_1    | 2022-07-31 01:18:24,689 [Listener at om3/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om3_1    | 2022-07-31 01:18:24,804 [Listener at om3/9862] INFO http.HttpServer2: Jetty bound to port 9874
om3_1    | 2022-07-31 01:18:24,805 [Listener at om3/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om3_1    | 2022-07-31 01:18:24,910 [Listener at om3/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om3_1    | 2022-07-31 01:18:24,910 [Listener at om3/9862] INFO server.session: No SessionScavenger set, using defaults
om3_1    | 2022-07-31 01:18:24,911 [Listener at om3/9862] INFO server.session: node0 Scavenging every 600000ms
om3_1    | 2022-07-31 01:18:24,970 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@402b4f81{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om3_1    | 2022-07-31 01:18:24,971 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c4b5ceb{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om3_1    | 2022-07-31 01:18:25,632 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5a85b4e6{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-4999449658569113215/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om3_1    | 2022-07-31 01:18:25,670 [Listener at om3/9862] INFO server.AbstractConnector: Started ServerConnector@6826b70f{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om3_1    | 2022-07-31 01:18:25,670 [Listener at om3/9862] INFO server.Server: Started @69814ms
om3_1    | 2022-07-31 01:18:25,682 [Listener at om3/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om3_1    | 2022-07-31 01:18:25,685 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
dn3_1    | 2022-07-31 01:20:14,242 [grpc-default-executor-0] INFO impl.VoteContext: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FOLLOWER: reject ELECTION from 609e7f2d-9474-472f-937f-8fa0a0bbb327: our priority 1 > candidate's priority 0
dn3_1    | 2022-07-31 01:20:14,242 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:609e7f2d-9474-472f-937f-8fa0a0bbb327
dn3_1    | 2022-07-31 01:20:14,242 [grpc-default-executor-0] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: shutdown 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState
dn3_1    | 2022-07-31 01:20:14,242 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState] INFO impl.FollowerState: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState was interrupted
dn3_1    | 2022-07-31 01:20:14,242 [grpc-default-executor-0] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState
dn3_1    | 2022-07-31 01:20:14,245 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0 replies to ELECTION vote request: 609e7f2d-9474-472f-937f-8fa0a0bbb327<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:FAIL-t2. Peer's state: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0:t2, leader=null, voted=null, raftlog=3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-SegmentedRaftLog:OPENED:c-1, conf=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn3_1    | 2022-07-31 01:20:14,263 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0: receive requestVote(ELECTION, 310a080d-f635-46ff-a53d-49cc9a09fa5c, group-84A70A95B4C0, 2, (t:0, i:0))
dn3_1    | 2022-07-31 01:20:14,263 [grpc-default-executor-0] INFO impl.VoteContext: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FOLLOWER: reject ELECTION from 310a080d-f635-46ff-a53d-49cc9a09fa5c: our priority 1 > candidate's priority 0
dn3_1    | 2022-07-31 01:20:14,263 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:310a080d-f635-46ff-a53d-49cc9a09fa5c
dn3_1    | 2022-07-31 01:20:14,263 [grpc-default-executor-0] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: shutdown 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState
dn3_1    | 2022-07-31 01:20:14,263 [grpc-default-executor-0] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState
dn3_1    | 2022-07-31 01:20:14,263 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState] INFO impl.FollowerState: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState was interrupted
dn3_1    | 2022-07-31 01:20:14,265 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0 replies to ELECTION vote request: 310a080d-f635-46ff-a53d-49cc9a09fa5c<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:FAIL-t2. Peer's state: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0:t2, leader=null, voted=null, raftlog=3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-SegmentedRaftLog:OPENED:c-1, conf=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn3_1    | 2022-07-31 01:20:19,296 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0: receive requestVote(ELECTION, 609e7f2d-9474-472f-937f-8fa0a0bbb327, group-84A70A95B4C0, 3, (t:0, i:0))
dn3_1    | 2022-07-31 01:20:19,296 [grpc-default-executor-0] INFO impl.VoteContext: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FOLLOWER: reject ELECTION from 609e7f2d-9474-472f-937f-8fa0a0bbb327: our priority 1 > candidate's priority 0
dn3_1    | 2022-07-31 01:20:19,296 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:609e7f2d-9474-472f-937f-8fa0a0bbb327
dn3_1    | 2022-07-31 01:20:19,296 [grpc-default-executor-0] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: shutdown 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState
dn3_1    | 2022-07-31 01:20:19,296 [grpc-default-executor-0] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState
dn3_1    | 2022-07-31 01:20:19,296 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState] INFO impl.FollowerState: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState was interrupted
dn3_1    | 2022-07-31 01:20:19,303 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0 replies to ELECTION vote request: 609e7f2d-9474-472f-937f-8fa0a0bbb327<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:FAIL-t3. Peer's state: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0:t3, leader=null, voted=null, raftlog=3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-SegmentedRaftLog:OPENED:c-1, conf=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn3_1    | 2022-07-31 01:20:24,359 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0: receive requestVote(ELECTION, 310a080d-f635-46ff-a53d-49cc9a09fa5c, group-84A70A95B4C0, 4, (t:0, i:0))
dn3_1    | 2022-07-31 01:20:24,359 [grpc-default-executor-0] INFO impl.VoteContext: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FOLLOWER: reject ELECTION from 310a080d-f635-46ff-a53d-49cc9a09fa5c: our priority 1 > candidate's priority 0
dn3_1    | 2022-07-31 01:20:24,360 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:310a080d-f635-46ff-a53d-49cc9a09fa5c
dn3_1    | 2022-07-31 01:20:24,360 [grpc-default-executor-0] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: shutdown 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState
dn3_1    | 2022-07-31 01:20:24,361 [grpc-default-executor-0] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState
dn3_1    | 2022-07-31 01:20:24,361 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState] INFO impl.FollowerState: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState was interrupted
dn1_1    | 2022-07-31 01:20:08,748 [grpc-default-executor-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7: receive requestVote(ELECTION, 11cba143-91f8-47cb-8422-c32a1e2d51df, group-7781FFA9F9E7, 1, (t:0, i:0))
dn1_1    | 2022-07-31 01:20:08,749 [grpc-default-executor-1] INFO impl.VoteContext: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7-FOLLOWER: accept ELECTION from 11cba143-91f8-47cb-8422-c32a1e2d51df: our priority 0 <= candidate's priority 0
dn1_1    | 2022-07-31 01:20:08,749 [grpc-default-executor-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:11cba143-91f8-47cb-8422-c32a1e2d51df
dn1_1    | 2022-07-31 01:20:08,749 [grpc-default-executor-1] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7-FollowerState
dn1_1    | 2022-07-31 01:20:08,749 [grpc-default-executor-1] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7-FollowerState
dn1_1    | 2022-07-31 01:20:08,749 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7-FollowerState] INFO impl.FollowerState: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7-FollowerState was interrupted
dn1_1    | 2022-07-31 01:20:08,758 [grpc-default-executor-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7 replies to ELECTION vote request: 11cba143-91f8-47cb-8422-c32a1e2d51df<-609e7f2d-9474-472f-937f-8fa0a0bbb327#0:OK-t1. Peer's state: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7:t1, leader=null, voted=11cba143-91f8-47cb-8422-c32a1e2d51df, raftlog=609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7-SegmentedRaftLog:OPENED:c-1, conf=-1: [310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0], old=null
dn1_1    | 2022-07-31 01:20:08,829 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-FollowerState] INFO impl.FollowerState: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5160968106ns, electionTimeout:5155ms
dn1_1    | 2022-07-31 01:20:08,829 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-FollowerState] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-FollowerState
dn1_1    | 2022-07-31 01:20:08,829 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-FollowerState] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
dn1_1    | 2022-07-31 01:20:08,829 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn1_1    | 2022-07-31 01:20:08,829 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-FollowerState] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-LeaderElection7
dn1_1    | 2022-07-31 01:20:08,832 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-LeaderElection7] INFO impl.LeaderElection: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-LeaderElection7 ELECTION round 0: submit vote requests at term 1 for -1: [609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:1], old=null
dn1_1    | 2022-07-31 01:20:08,832 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-LeaderElection7] INFO impl.LeaderElection: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-LeaderElection7 ELECTION round 0: result PASSED (term=1)
dn1_1    | 2022-07-31 01:20:08,832 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-LeaderElection7] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-LeaderElection7
dn1_1    | 2022-07-31 01:20:08,832 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-LeaderElection7] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
dn1_1    | 2022-07-31 01:20:08,832 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-LeaderElection7] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-B37BD276617A with new leaderId: 609e7f2d-9474-472f-937f-8fa0a0bbb327
dn1_1    | 2022-07-31 01:20:08,833 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-LeaderElection7] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A: change Leader from null to 609e7f2d-9474-472f-937f-8fa0a0bbb327 at term 1 for becomeLeader, leader elected after 5209ms
dn1_1    | 2022-07-31 01:20:08,833 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn1_1    | 2022-07-31 01:20:08,833 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn1_1    | 2022-07-31 01:20:08,833 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn1_1    | 2022-07-31 01:20:08,833 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn1_1    | 2022-07-31 01:20:08,833 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn1_1    | 2022-07-31 01:20:08,833 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn1_1    | 2022-07-31 01:20:08,833 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn1_1    | 2022-07-31 01:20:08,833 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn1_1    | 2022-07-31 01:20:08,834 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-LeaderElection7] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-LeaderStateImpl
dn1_1    | 2022-07-31 01:20:08,834 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-LeaderElection7] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-SegmentedRaftLogWorker: Starting segment from index:0
dn1_1    | 2022-07-31 01:20:08,835 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/f058582a-59a2-4a37-8200-b37bd276617a/current/log_inprogress_0
dn1_1    | 2022-07-31 01:20:08,836 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A-LeaderElection7] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-B37BD276617A: set configuration 0: [609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1], old=null
dn1_1    | 2022-07-31 01:20:09,129 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState] INFO impl.FollowerState: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5018320739ns, electionTimeout:5015ms
dn2_1    | 2022-07-31 01:20:03,590 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn2_1    | 2022-07-31 01:20:03,596 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn2_1    | 2022-07-31 01:20:03,596 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn2_1    | 2022-07-31 01:20:03,596 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn2_1    | 2022-07-31 01:20:03,596 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn2_1    | 2022-07-31 01:20:03,596 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn2_1    | 2022-07-31 01:20:03,597 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn2_1    | 2022-07-31 01:20:03,599 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn2_1    | 2022-07-31 01:20:03,600 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn2_1    | 2022-07-31 01:20:03,601 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn2_1    | 2022-07-31 01:20:03,601 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn2_1    | 2022-07-31 01:20:03,602 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn2_1    | 2022-07-31 01:20:03,603 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD: start as a follower, conf=-1: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:1], old=null
dn2_1    | 2022-07-31 01:20:03,603 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn2_1    | 2022-07-31 01:20:03,605 [pool-42-thread-1] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: start 11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-FollowerState
dn2_1    | 2022-07-31 01:20:03,605 [pool-42-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-26397C6FFFAD,id=11cba143-91f8-47cb-8422-c32a1e2d51df
dn2_1    | 2022-07-31 01:20:03,606 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=da610dcf-61e8-4e48-8ead-26397c6fffad
dn2_1    | 2022-07-31 01:20:03,609 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=da610dcf-61e8-4e48-8ead-26397c6fffad.
dn2_1    | 2022-07-31 01:20:03,611 [Command processor thread] INFO server.RaftServer: 11cba143-91f8-47cb-8422-c32a1e2d51df: addNew group-7781FFA9F9E7:[310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0] returns group-7781FFA9F9E7:java.util.concurrent.CompletableFuture@bf56496[Not completed]
dn2_1    | 2022-07-31 01:20:03,616 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df: new RaftServerImpl for group-7781FFA9F9E7:[310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0] with ContainerStateMachine:uninitialized
dn2_1    | 2022-07-31 01:20:03,620 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn2_1    | 2022-07-31 01:20:03,621 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn2_1    | 2022-07-31 01:20:03,621 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn2_1    | 2022-07-31 01:20:03,622 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn2_1    | 2022-07-31 01:20:03,634 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn2_1    | 2022-07-31 01:20:03,634 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn2_1    | 2022-07-31 01:20:03,635 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7: ConfigurationManager, init=-1: [310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0], old=null, confs=<EMPTY_MAP>
dn2_1    | 2022-07-31 01:20:03,635 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn2_1    | 2022-07-31 01:20:03,636 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn2_1    | 2022-07-31 01:20:03,636 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn2_1    | 2022-07-31 01:20:03,638 [pool-42-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/ae7040c6-f723-491f-8b9e-7781ffa9f9e7 does not exist. Creating ...
dn2_1    | 2022-07-31 01:20:03,646 [pool-42-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/ae7040c6-f723-491f-8b9e-7781ffa9f9e7/in_use.lock acquired by nodename 8@c5b89a034b5d
dn2_1    | 2022-07-31 01:20:03,649 [pool-42-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/ae7040c6-f723-491f-8b9e-7781ffa9f9e7 has been successfully formatted.
dn2_1    | 2022-07-31 01:20:03,650 [pool-42-thread-1] INFO ratis.ContainerStateMachine: group-7781FFA9F9E7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn2_1    | 2022-07-31 01:20:03,650 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn2_1    | 2022-07-31 01:20:03,650 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn2_1    | 2022-07-31 01:20:03,651 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn2_1    | 2022-07-31 01:20:03,651 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2022-07-31 01:20:03,651 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn2_1    | 2022-07-31 01:20:03,674 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2022-07-31 01:20:03,674 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn2_1    | 2022-07-31 01:20:03,674 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn2_1    | 2022-07-31 01:20:03,675 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: new 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/ae7040c6-f723-491f-8b9e-7781ffa9f9e7
dn2_1    | 2022-07-31 01:20:03,675 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn2_1    | 2022-07-31 01:20:03,675 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn2_1    | 2022-07-31 01:20:03,675 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2022-07-31 01:20:03,675 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn2_1    | 2022-07-31 01:20:03,675 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn2_1    | 2022-07-31 01:20:03,675 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn2_1    | 2022-07-31 01:20:03,675 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn2_1    | 2022-07-31 01:20:03,675 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn2_1    | 2022-07-31 01:20:03,675 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn2_1    | 2022-07-31 01:20:03,677 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn2_1    | 2022-07-31 01:20:03,684 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn2_1    | 2022-07-31 01:20:03,684 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn2_1    | 2022-07-31 01:20:03,684 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn2_1    | 2022-07-31 01:20:03,687 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn2_1    | 2022-07-31 01:20:03,687 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn2_1    | 2022-07-31 01:20:03,687 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn2_1    | 2022-07-31 01:20:03,687 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn2_1    | 2022-07-31 01:20:03,687 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn2_1    | 2022-07-31 01:20:03,687 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn2_1    | 2022-07-31 01:20:03,688 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn2_1    | 2022-07-31 01:20:03,691 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn2_1    | 2022-07-31 01:20:03,692 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn2_1    | 2022-07-31 01:20:03,692 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn2_1    | 2022-07-31 01:20:03,692 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn2_1    | 2022-07-31 01:20:03,692 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7: start as a follower, conf=-1: [310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0], old=null
dn2_1    | 2022-07-31 01:20:03,692 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn2_1    | 2022-07-31 01:20:03,692 [pool-42-thread-1] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: start 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-FollowerState
dn2_1    | 2022-07-31 01:20:03,697 [pool-42-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7781FFA9F9E7,id=11cba143-91f8-47cb-8422-c32a1e2d51df
dn2_1    | 2022-07-31 01:20:03,704 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=ae7040c6-f723-491f-8b9e-7781ffa9f9e7
dn2_1    | 2022-07-31 01:20:04,045 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=ae7040c6-f723-491f-8b9e-7781ffa9f9e7.
dn2_1    | 2022-07-31 01:20:08,732 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-FollowerState] INFO impl.FollowerState: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5039735447ns, electionTimeout:5030ms
dn2_1    | 2022-07-31 01:20:08,733 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-FollowerState] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: shutdown 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-FollowerState
dn2_1    | 2022-07-31 01:20:08,733 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-FollowerState] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
dn2_1    | 2022-07-31 01:20:08,734 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn2_1    | 2022-07-31 01:20:08,734 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-FollowerState] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: start 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-LeaderElection5
dn2_1    | 2022-07-31 01:20:08,738 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-LeaderElection5] INFO impl.LeaderElection: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-LeaderElection5 ELECTION round 0: submit vote requests at term 1 for -1: [310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0], old=null
dn2_1    | 2022-07-31 01:20:08,762 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-LeaderElection5] INFO impl.LeaderElection: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-LeaderElection5: ELECTION REJECTED received 1 response(s) and 0 exception(s):
dn2_1    | 2022-07-31 01:20:08,762 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-LeaderElection5] INFO impl.LeaderElection:   Response 0: 11cba143-91f8-47cb-8422-c32a1e2d51df<-310a080d-f635-46ff-a53d-49cc9a09fa5c#0:FAIL-t1
dn1_1    | 2022-07-31 01:20:09,129 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState
dn1_1    | 2022-07-31 01:20:09,129 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
dn1_1    | 2022-07-31 01:20:09,129 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn1_1    | 2022-07-31 01:20:09,129 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection8
dn1_1    | 2022-07-31 01:20:09,133 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection8] INFO impl.LeaderElection: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection8 ELECTION round 0: submit vote requests at term 1 for -1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0], old=null
dn1_1    | 2022-07-31 01:20:09,158 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection8] INFO impl.LeaderElection: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection8: ELECTION REJECTED received 1 response(s) and 0 exception(s):
dn1_1    | 2022-07-31 01:20:09,158 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection8] INFO impl.LeaderElection:   Response 0: 609e7f2d-9474-472f-937f-8fa0a0bbb327<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:FAIL-t1
dn1_1    | 2022-07-31 01:20:09,158 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection8] INFO impl.LeaderElection: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection8 ELECTION round 0: result REJECTED
dn1_1    | 2022-07-31 01:20:09,158 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection8] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
dn1_1    | 2022-07-31 01:20:09,158 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection8] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection8
dn1_1    | 2022-07-31 01:20:09,158 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection8] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState
dn1_1    | 2022-07-31 01:20:10,744 [BlockDeletingService#0] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-2b5f2d05-a9c0-4b31-b820-5fa0b5f933e6/current/containerDir0/1/chunks/109611004723200001.block
dn1_1    | 2022-07-31 01:20:10,746 [BlockDeletingService#0] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-2b5f2d05-a9c0-4b31-b820-5fa0b5f933e6/current/containerDir0/1/chunks/109611004723200002.block
dn1_1    | 2022-07-31 01:20:10,753 [BlockDeletingService#0] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-2b5f2d05-a9c0-4b31-b820-5fa0b5f933e6/current/containerDir0/1/chunks/109611004723200003.block
dn1_1    | 2022-07-31 01:20:13,809 [grpc-default-executor-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7: receive requestVote(ELECTION, 310a080d-f635-46ff-a53d-49cc9a09fa5c, group-7781FFA9F9E7, 2, (t:0, i:0))
dn1_1    | 2022-07-31 01:20:13,809 [grpc-default-executor-1] INFO impl.VoteContext: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7-FOLLOWER: accept ELECTION from 310a080d-f635-46ff-a53d-49cc9a09fa5c: our priority 0 <= candidate's priority 1
dn1_1    | 2022-07-31 01:20:13,809 [grpc-default-executor-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:310a080d-f635-46ff-a53d-49cc9a09fa5c
dn1_1    | 2022-07-31 01:20:13,809 [grpc-default-executor-1] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7-FollowerState
dn1_1    | 2022-07-31 01:20:13,809 [grpc-default-executor-1] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7-FollowerState
dn1_1    | 2022-07-31 01:20:13,809 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7-FollowerState] INFO impl.FollowerState: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7-FollowerState was interrupted
dn1_1    | 2022-07-31 01:20:13,812 [grpc-default-executor-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7 replies to ELECTION vote request: 310a080d-f635-46ff-a53d-49cc9a09fa5c<-609e7f2d-9474-472f-937f-8fa0a0bbb327#0:OK-t2. Peer's state: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7:t2, leader=null, voted=310a080d-f635-46ff-a53d-49cc9a09fa5c, raftlog=609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7-SegmentedRaftLog:OPENED:c-1, conf=-1: [310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0], old=null
dn1_1    | 2022-07-31 01:20:13,982 [609e7f2d-9474-472f-937f-8fa0a0bbb327-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-7781FFA9F9E7 with new leaderId: 310a080d-f635-46ff-a53d-49cc9a09fa5c
dn1_1    | 2022-07-31 01:20:13,983 [609e7f2d-9474-472f-937f-8fa0a0bbb327-server-thread1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7: change Leader from null to 310a080d-f635-46ff-a53d-49cc9a09fa5c at term 2 for appendEntries, leader elected after 10285ms
dn1_1    | 2022-07-31 01:20:13,997 [609e7f2d-9474-472f-937f-8fa0a0bbb327-server-thread1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7: set configuration 0: [310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-07-31 01:20:13,998 [609e7f2d-9474-472f-937f-8fa0a0bbb327-server-thread1] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7-SegmentedRaftLogWorker: Starting segment from index:0
dn1_1    | 2022-07-31 01:20:14,007 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-7781FFA9F9E7-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/ae7040c6-f723-491f-8b9e-7781ffa9f9e7/current/log_inprogress_0
dn1_1    | 2022-07-31 01:20:14,235 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState] INFO impl.FollowerState: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5076781539ns, electionTimeout:5071ms
om2_1    | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om2_1    | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:300)
om2_1    | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1    | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1    | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1    | 2022-07-31 01:22:14,966 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:ectest-new for user:hadoop
om2_1    | 2022-07-31 01:22:17,954 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ectest of layout LEGACY in volume: ectest-new
om2_1    | 2022-07-31 01:22:24,184 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: testpropchange of layout LEGACY in volume: ectest-new
dn5_1    | 2022-07-31 01:18:02,188 [pool-38-thread-1] INFO segmented.LogSegment: Successfully read 5 entries from segment file /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/current/log_inprogress_31
dn5_1    | 2022-07-31 01:18:02,188 [pool-38-thread-1] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 35
dn5_1    | 2022-07-31 01:18:02,200 [pool-38-thread-1] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 30
dn5_1    | 2022-07-31 01:18:02,173 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/10.9.0.20:9891
dn5_1    | 2022-07-31 01:18:02,226 [Datanode State Machine Task Thread - 0] WARN statemachine.SCMConnectionManager: Trying to add an existing SCM Machine to Machines group. Ignoring the request.
dn5_1    | 2022-07-31 01:18:02,226 [pool-38-thread-1] INFO raftlog.RaftLog: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-SegmentedRaftLog: commitIndex: updateToMax old=35, new=34, updated? false
dn5_1    | 2022-07-31 01:18:02,226 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn5_1    | 2022-07-31 01:18:02,227 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn5_1    | 2022-07-31 01:18:02,227 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn5_1    | 2022-07-31 01:18:02,235 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn5_1    | 2022-07-31 01:18:02,235 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn5_1    | 2022-07-31 01:18:02,237 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn5_1    | 2022-07-31 01:18:02,238 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn5_1    | 2022-07-31 01:18:02,239 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn5_1    | 2022-07-31 01:18:02,239 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn5_1    | 2022-07-31 01:18:02,240 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn5_1    | 2022-07-31 01:18:02,240 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn5_1    | 2022-07-31 01:18:02,227 [Datanode State Machine Task Thread - 1] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
dn5_1    | 2022-07-31 01:18:02,241 [Datanode State Machine Task Thread - 1] WARN statemachine.SCMConnectionManager: Trying to add an existing SCM Machine to Machines group. Ignoring the request.
dn5_1    | 2022-07-31 01:18:02,229 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
dn5_1    | 2022-07-31 01:18:02,243 [Datanode State Machine Task Thread - 1] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/10.9.0.20:9891
dn5_1    | 2022-07-31 01:18:02,243 [Datanode State Machine Task Thread - 1] WARN statemachine.SCMConnectionManager: Trying to add an existing SCM Machine to Machines group. Ignoring the request.
dn5_1    | 2022-07-31 01:18:02,246 [Datanode State Machine Task Thread - 1] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
dn5_1    | 2022-07-31 01:18:05,407 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn5_1    | 2022-07-31 01:18:06,408 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn5_1    | 2022-07-31 01:18:07,410 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn5_1    | 2022-07-31 01:18:08,411 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.14:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn5_1    | 2022-07-31 01:18:09,543 [EndpointStateMachine task thread for recon/10.9.0.20:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
dn5_1    | java.net.SocketTimeoutException: Call From 6c1f77753501/10.9.0.19 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.19:55840 remote=recon/10.9.0.20:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
dn5_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
dn5_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
dn5_1    | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
dn5_1    | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
dn5_1    | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
dn5_1    | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:848)
dn5_1    | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
dn5_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
dn5_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
dn5_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:236)
dn5_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:123)
dn5_1    | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
dn5_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
dn5_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
dn5_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn5_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn5_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.19:55840 remote=recon/10.9.0.20:9891]
dn5_1    | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
dn5_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
dn5_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
dn5_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
om3_1    | 2022-07-31 01:18:25,689 [Listener at om3/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om3_1    | 2022-07-31 01:18:25,690 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om3_1    | 2022-07-31 01:18:25,737 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om3_1    | 2022-07-31 01:18:25,772 [Listener at om3/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted won't move to trash
om3_1    | 2022-07-31 01:18:25,806 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4c063cb9] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om3_1    | 2022-07-31 01:18:28,956 [om3@group-D66704EFC61C-FollowerState] INFO impl.FollowerState: om3@group-D66704EFC61C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5190360601ns, electionTimeout:5154ms
om3_1    | 2022-07-31 01:18:28,958 [om3@group-D66704EFC61C-FollowerState] INFO impl.RoleInfo: om3: shutdown om3@group-D66704EFC61C-FollowerState
om3_1    | 2022-07-31 01:18:28,958 [om3@group-D66704EFC61C-FollowerState] INFO server.RaftServer$Division: om3@group-D66704EFC61C: changes role from  FOLLOWER to CANDIDATE at term 6 for changeToCandidate
om3_1    | 2022-07-31 01:18:28,962 [om3@group-D66704EFC61C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om3_1    | 2022-07-31 01:18:28,965 [om3@group-D66704EFC61C-FollowerState] INFO impl.RoleInfo: om3: start om3@group-D66704EFC61C-LeaderElection1
om3_1    | 2022-07-31 01:18:29,017 [om3@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om3@group-D66704EFC61C-LeaderElection1 ELECTION round 0: submit vote requests at term 7 for 63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
dn1_1    | 2022-07-31 01:20:14,235 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState
dn1_1    | 2022-07-31 01:20:14,235 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
dn1_1    | 2022-07-31 01:20:14,236 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn1_1    | 2022-07-31 01:20:14,236 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection9
dn1_1    | 2022-07-31 01:20:14,239 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection9] INFO impl.LeaderElection: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection9 ELECTION round 0: submit vote requests at term 2 for -1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0], old=null
dn1_1    | 2022-07-31 01:20:14,247 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection9] INFO impl.LeaderElection: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection9: ELECTION REJECTED received 1 response(s) and 0 exception(s):
dn1_1    | 2022-07-31 01:20:14,248 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection9] INFO impl.LeaderElection:   Response 0: 609e7f2d-9474-472f-937f-8fa0a0bbb327<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:FAIL-t2
dn1_1    | 2022-07-31 01:20:14,248 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection9] INFO impl.LeaderElection: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection9 ELECTION round 0: result REJECTED
dn1_1    | 2022-07-31 01:20:14,248 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection9] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
dn1_1    | 2022-07-31 01:20:14,248 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection9] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection9
dn1_1    | 2022-07-31 01:20:14,248 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection9] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState
dn1_1    | 2022-07-31 01:20:14,271 [grpc-default-executor-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0: receive requestVote(ELECTION, 310a080d-f635-46ff-a53d-49cc9a09fa5c, group-84A70A95B4C0, 2, (t:0, i:0))
dn1_1    | 2022-07-31 01:20:14,271 [grpc-default-executor-1] INFO impl.VoteContext: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FOLLOWER: reject ELECTION from 310a080d-f635-46ff-a53d-49cc9a09fa5c: already has voted for 609e7f2d-9474-472f-937f-8fa0a0bbb327 at current term 2
dn1_1    | 2022-07-31 01:20:14,271 [grpc-default-executor-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0 replies to ELECTION vote request: 310a080d-f635-46ff-a53d-49cc9a09fa5c<-609e7f2d-9474-472f-937f-8fa0a0bbb327#0:FAIL-t2. Peer's state: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0:t2, leader=null, voted=609e7f2d-9474-472f-937f-8fa0a0bbb327, raftlog=609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-SegmentedRaftLog:OPENED:c-1, conf=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0], old=null
dn1_1    | 2022-07-31 01:20:19,288 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState] INFO impl.FollowerState: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5039918480ns, electionTimeout:5037ms
dn1_1    | 2022-07-31 01:20:19,288 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState
dn1_1    | 2022-07-31 01:20:19,288 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
dn1_1    | 2022-07-31 01:20:19,288 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn1_1    | 2022-07-31 01:20:19,288 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection10
dn1_1    | 2022-07-31 01:20:19,291 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection10] INFO impl.LeaderElection: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection10 ELECTION round 0: submit vote requests at term 3 for -1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0], old=null
dn1_1    | 2022-07-31 01:20:19,306 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection10] INFO impl.LeaderElection: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection10: ELECTION REJECTED received 1 response(s) and 0 exception(s):
dn1_1    | 2022-07-31 01:20:19,306 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection10] INFO impl.LeaderElection:   Response 0: 609e7f2d-9474-472f-937f-8fa0a0bbb327<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:FAIL-t3
dn1_1    | 2022-07-31 01:20:19,306 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection10] INFO impl.LeaderElection: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection10 ELECTION round 0: result REJECTED
dn1_1    | 2022-07-31 01:20:19,306 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection10] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
dn1_1    | 2022-07-31 01:20:19,306 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection10] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection10
dn1_1    | 2022-07-31 01:20:19,306 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-LeaderElection10] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState
dn1_1    | 2022-07-31 01:20:24,361 [grpc-default-executor-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0: receive requestVote(ELECTION, 310a080d-f635-46ff-a53d-49cc9a09fa5c, group-84A70A95B4C0, 4, (t:0, i:0))
dn1_1    | 2022-07-31 01:20:24,373 [grpc-default-executor-1] INFO impl.VoteContext: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FOLLOWER: accept ELECTION from 310a080d-f635-46ff-a53d-49cc9a09fa5c: our priority 0 <= candidate's priority 0
dn3_1    | 2022-07-31 01:20:24,376 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0 replies to ELECTION vote request: 310a080d-f635-46ff-a53d-49cc9a09fa5c<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:FAIL-t4. Peer's state: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0:t4, leader=null, voted=null, raftlog=3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-SegmentedRaftLog:OPENED:c-1, conf=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn3_1    | 2022-07-31 01:20:29,497 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0: receive requestVote(ELECTION, 310a080d-f635-46ff-a53d-49cc9a09fa5c, group-84A70A95B4C0, 5, (t:0, i:0))
dn3_1    | 2022-07-31 01:20:29,498 [grpc-default-executor-0] INFO impl.VoteContext: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FOLLOWER: reject ELECTION from 310a080d-f635-46ff-a53d-49cc9a09fa5c: our priority 1 > candidate's priority 0
dn3_1    | 2022-07-31 01:20:29,498 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:310a080d-f635-46ff-a53d-49cc9a09fa5c
dn3_1    | 2022-07-31 01:20:29,498 [grpc-default-executor-0] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: shutdown 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState
dn3_1    | 2022-07-31 01:20:29,499 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState] INFO impl.FollowerState: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState was interrupted
dn3_1    | 2022-07-31 01:20:29,501 [grpc-default-executor-0] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState
dn3_1    | 2022-07-31 01:20:29,509 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0 replies to ELECTION vote request: 310a080d-f635-46ff-a53d-49cc9a09fa5c<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:FAIL-t5. Peer's state: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0:t5, leader=null, voted=null, raftlog=3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-SegmentedRaftLog:OPENED:c-1, conf=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn3_1    | 2022-07-31 01:20:33,340 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: new RaftServerImpl for group-5058278E2312:[3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:1] with ContainerStateMachine:uninitialized
dn3_1    | 2022-07-31 01:20:33,340 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn3_1    | 2022-07-31 01:20:33,340 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn3_1    | 2022-07-31 01:20:33,340 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn3_1    | 2022-07-31 01:20:33,341 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn3_1    | 2022-07-31 01:20:33,341 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn3_1    | 2022-07-31 01:20:33,341 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn3_1    | 2022-07-31 01:20:33,341 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312: ConfigurationManager, init=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:1], old=null, confs=<EMPTY_MAP>
dn3_1    | 2022-07-31 01:20:33,341 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn3_1    | 2022-07-31 01:20:33,341 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn3_1    | 2022-07-31 01:20:33,342 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn3_1    | 2022-07-31 01:20:33,342 [pool-34-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/e372288d-28a7-4132-a525-5058278e2312 does not exist. Creating ...
dn3_1    | 2022-07-31 01:20:33,344 [Command processor thread] INFO server.RaftServer: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: addNew group-5058278E2312:[3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:1] returns group-5058278E2312:java.util.concurrent.CompletableFuture@60ad5358[Not completed]
dn3_1    | 2022-07-31 01:20:33,346 [pool-34-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/e372288d-28a7-4132-a525-5058278e2312/in_use.lock acquired by nodename 6@6dca380edee9
dn3_1    | 2022-07-31 01:20:33,349 [pool-34-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/e372288d-28a7-4132-a525-5058278e2312 has been successfully formatted.
dn3_1    | 2022-07-31 01:20:33,350 [pool-34-thread-1] INFO ratis.ContainerStateMachine: group-5058278E2312: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn3_1    | 2022-07-31 01:20:33,350 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn3_1    | 2022-07-31 01:20:33,350 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn3_1    | 2022-07-31 01:20:33,350 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn3_1    | 2022-07-31 01:20:33,351 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2022-07-31 01:20:33,351 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn3_1    | 2022-07-31 01:20:33,351 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2022-07-31 01:20:33,351 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn3_1    | 2022-07-31 01:20:33,352 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn3_1    | 2022-07-31 01:20:33,352 [pool-34-thread-1] INFO segmented.SegmentedRaftLogWorker: new 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/e372288d-28a7-4132-a525-5058278e2312
dn3_1    | 2022-07-31 01:20:33,352 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn3_1    | 2022-07-31 01:20:33,353 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn3_1    | 2022-07-31 01:20:33,355 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2022-07-31 01:20:33,355 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn3_1    | 2022-07-31 01:20:33,355 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn3_1    | 2022-07-31 01:20:33,355 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn3_1    | 2022-07-31 01:20:33,355 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om1_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.6.3.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jcl-over-slf4j-1.7.24.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om1_1    | STARTUP_MSG:   build = https://github.com/apache/ozone/57d620dbd4cb5dfec746cc16039d3843e64c181c ; compiled by 'runner' on 2022-07-31T00:52Z
om1_1    | STARTUP_MSG:   java = 11.0.14.1
om1_1    | ************************************************************/
om1_1    | 2022-07-31 01:17:27,309 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1    | 2022-07-31 01:17:36,988 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om1_1    | 2022-07-31 01:17:40,386 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om1_1    | 2022-07-31 01:17:40,814 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: omservice, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1    | 2022-07-31 01:17:40,817 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.omservice.om1: om1
om1_1    | 2022-07-31 01:17:40,829 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1    | 2022-07-31 01:17:41,071 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = MULTITENANCY_SCHEMA (version = 3)
om1_1    | 2022-07-31 01:17:44,377 [main] INFO reflections.Reflections: Reflections took 2833 ms to scan 1 urls, producing 112 keys and 332 values [using 2 cores]
om1_1    | 2022-07-31 01:17:44,647 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1    | 2022-07-31 01:17:47,451 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863]
om1_1    | 2022-07-31 01:17:47,653 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863]
om1_1    | 2022-07-31 01:17:50,860 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 25d3afb12a88/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1    | 2022-07-31 01:17:52,861 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 25d3afb12a88/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1    | 2022-07-31 01:17:54,864 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 25d3afb12a88/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1    | 2022-07-31 01:17:56,865 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 25d3afb12a88/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
dn1_1    | 2022-07-31 01:20:24,373 [grpc-default-executor-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:310a080d-f635-46ff-a53d-49cc9a09fa5c
dn1_1    | 2022-07-31 01:20:24,373 [grpc-default-executor-1] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState
dn1_1    | 2022-07-31 01:20:24,373 [grpc-default-executor-1] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState
dn1_1    | 2022-07-31 01:20:24,373 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState] INFO impl.FollowerState: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState was interrupted
dn1_1    | 2022-07-31 01:20:24,384 [grpc-default-executor-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0 replies to ELECTION vote request: 310a080d-f635-46ff-a53d-49cc9a09fa5c<-609e7f2d-9474-472f-937f-8fa0a0bbb327#0:OK-t4. Peer's state: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0:t4, leader=null, voted=310a080d-f635-46ff-a53d-49cc9a09fa5c, raftlog=609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-SegmentedRaftLog:OPENED:c-1, conf=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0], old=null
dn1_1    | 2022-07-31 01:20:29,491 [grpc-default-executor-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0: receive requestVote(ELECTION, 310a080d-f635-46ff-a53d-49cc9a09fa5c, group-84A70A95B4C0, 5, (t:0, i:0))
dn1_1    | 2022-07-31 01:20:29,491 [grpc-default-executor-1] INFO impl.VoteContext: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FOLLOWER: accept ELECTION from 310a080d-f635-46ff-a53d-49cc9a09fa5c: our priority 0 <= candidate's priority 0
dn1_1    | 2022-07-31 01:20:29,491 [grpc-default-executor-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:310a080d-f635-46ff-a53d-49cc9a09fa5c
dn1_1    | 2022-07-31 01:20:29,491 [grpc-default-executor-1] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState
dn1_1    | 2022-07-31 01:20:29,491 [grpc-default-executor-1] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState
dn1_1    | 2022-07-31 01:20:29,493 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState] INFO impl.FollowerState: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState was interrupted
dn1_1    | 2022-07-31 01:20:29,499 [grpc-default-executor-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0 replies to ELECTION vote request: 310a080d-f635-46ff-a53d-49cc9a09fa5c<-609e7f2d-9474-472f-937f-8fa0a0bbb327#0:OK-t5. Peer's state: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0:t5, leader=null, voted=310a080d-f635-46ff-a53d-49cc9a09fa5c, raftlog=609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-SegmentedRaftLog:OPENED:c-1, conf=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0], old=null
dn1_1    | 2022-07-31 01:20:34,599 [grpc-default-executor-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0: receive requestVote(ELECTION, 3fc9f139-dd93-41e7-b235-52ce94d6fe3c, group-84A70A95B4C0, 6, (t:0, i:0))
dn1_1    | 2022-07-31 01:20:34,599 [grpc-default-executor-1] INFO impl.VoteContext: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FOLLOWER: accept ELECTION from 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: our priority 0 <= candidate's priority 1
dn1_1    | 2022-07-31 01:20:34,599 [grpc-default-executor-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0: changes role from  FOLLOWER to FOLLOWER at term 6 for candidate:3fc9f139-dd93-41e7-b235-52ce94d6fe3c
dn1_1    | 2022-07-31 01:20:34,599 [grpc-default-executor-1] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: shutdown 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState
dn1_1    | 2022-07-31 01:20:34,599 [grpc-default-executor-1] INFO impl.RoleInfo: 609e7f2d-9474-472f-937f-8fa0a0bbb327: start 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState
dn1_1    | 2022-07-31 01:20:34,602 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState] INFO impl.FollowerState: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-FollowerState was interrupted
dn1_1    | 2022-07-31 01:20:34,604 [grpc-default-executor-1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0 replies to ELECTION vote request: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c<-609e7f2d-9474-472f-937f-8fa0a0bbb327#0:OK-t6. Peer's state: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0:t6, leader=null, voted=3fc9f139-dd93-41e7-b235-52ce94d6fe3c, raftlog=609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-SegmentedRaftLog:OPENED:c-1, conf=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0], old=null
dn1_1    | 2022-07-31 01:20:34,669 [609e7f2d-9474-472f-937f-8fa0a0bbb327-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-84A70A95B4C0 with new leaderId: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c
dn1_1    | 2022-07-31 01:20:34,669 [609e7f2d-9474-472f-937f-8fa0a0bbb327-server-thread1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0: change Leader from null to 3fc9f139-dd93-41e7-b235-52ce94d6fe3c at term 6 for appendEntries, leader elected after 30579ms
dn1_1    | 2022-07-31 01:20:34,675 [609e7f2d-9474-472f-937f-8fa0a0bbb327-server-thread1] INFO server.RaftServer$Division: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0: set configuration 0: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn1_1    | 2022-07-31 01:20:34,676 [609e7f2d-9474-472f-937f-8fa0a0bbb327-server-thread1] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-SegmentedRaftLogWorker: Starting segment from index:0
dn1_1    | 2022-07-31 01:20:34,678 [609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 609e7f2d-9474-472f-937f-8fa0a0bbb327@group-84A70A95B4C0-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0/current/log_inprogress_0
dn5_1    | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
dn5_1    | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
dn5_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn5_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn5_1    | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563)
dn5_1    | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
dn5_1    | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
dn5_1    | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
dn5_1    | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
dn5_1    | 2022-07-31 01:18:09,757 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
dn5_1    | 2022-07-31 01:18:09,766 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
dn5_1    | 2022-07-31 01:18:10,335 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 52aca038-7576-46a0-9ccd-b8aed29078e2
dn5_1    | 2022-07-31 01:18:10,358 [52aca038-7576-46a0-9ccd-b8aed29078e2-impl-thread1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1: start as a follower, conf=31: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn5_1    | 2022-07-31 01:18:10,359 [52aca038-7576-46a0-9ccd-b8aed29078e2-impl-thread1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1: changes role from      null to FOLLOWER at term 8 for startAsFollower
dn5_1    | 2022-07-31 01:18:10,360 [52aca038-7576-46a0-9ccd-b8aed29078e2-impl-thread1] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: start 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-FollowerState
dn5_1    | 2022-07-31 01:18:10,447 [52aca038-7576-46a0-9ccd-b8aed29078e2-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-65A101075AF1,id=52aca038-7576-46a0-9ccd-b8aed29078e2
dn5_1    | 2022-07-31 01:18:10,465 [52aca038-7576-46a0-9ccd-b8aed29078e2-impl-thread1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610: start as a follower, conf=3: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-07-31 01:18:10,466 [52aca038-7576-46a0-9ccd-b8aed29078e2-impl-thread1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610: changes role from      null to FOLLOWER at term 11 for startAsFollower
dn5_1    | 2022-07-31 01:18:10,466 [52aca038-7576-46a0-9ccd-b8aed29078e2-impl-thread1] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: start 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-FollowerState
dn5_1    | 2022-07-31 01:18:10,473 [52aca038-7576-46a0-9ccd-b8aed29078e2-impl-thread2] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED: start as a follower, conf=3: [52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-07-31 01:18:10,535 [52aca038-7576-46a0-9ccd-b8aed29078e2-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7BB2A1276610,id=52aca038-7576-46a0-9ccd-b8aed29078e2
dn5_1    | 2022-07-31 01:18:10,537 [52aca038-7576-46a0-9ccd-b8aed29078e2-impl-thread2] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED: changes role from      null to FOLLOWER at term 3 for startAsFollower
dn5_1    | 2022-07-31 01:18:10,537 [52aca038-7576-46a0-9ccd-b8aed29078e2-impl-thread2] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: start 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-FollowerState
dn5_1    | 2022-07-31 01:18:10,569 [52aca038-7576-46a0-9ccd-b8aed29078e2-impl-thread2] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CD003ECC1EED,id=52aca038-7576-46a0-9ccd-b8aed29078e2
dn5_1    | 2022-07-31 01:18:10,604 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.RaftServer: 52aca038-7576-46a0-9ccd-b8aed29078e2: start RPC server
dn5_1    | 2022-07-31 01:18:10,664 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 52aca038-7576-46a0-9ccd-b8aed29078e2: GrpcService started, listening on 9856
dn5_1    | 2022-07-31 01:18:10,674 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 52aca038-7576-46a0-9ccd-b8aed29078e2: GrpcService started, listening on 9857
dn5_1    | 2022-07-31 01:18:10,681 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO server.GrpcService: 52aca038-7576-46a0-9ccd-b8aed29078e2: GrpcService started, listening on 9858
dn5_1    | 2022-07-31 01:18:10,725 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 52aca038-7576-46a0-9ccd-b8aed29078e2 is started using port 9858 for RATIS
dn5_1    | 2022-07-31 01:18:10,726 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 52aca038-7576-46a0-9ccd-b8aed29078e2 is started using port 9857 for RATIS_ADMIN
dn5_1    | 2022-07-31 01:18:10,726 [EndpointStateMachine task thread for scm/10.9.0.14:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 52aca038-7576-46a0-9ccd-b8aed29078e2 is started using port 9856 for RATIS_SERVER
dn5_1    | 2022-07-31 01:18:10,727 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$487/0x0000000840571840@661cabca] INFO util.JvmPauseMonitor: JvmPauseMonitor-52aca038-7576-46a0-9ccd-b8aed29078e2: Started
dn5_1    | 2022-07-31 01:18:15,631 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-FollowerState] INFO impl.FollowerState: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5271507573ns, electionTimeout:5167ms
dn5_1    | 2022-07-31 01:18:15,633 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-FollowerState] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: shutdown 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-FollowerState
dn5_1    | 2022-07-31 01:18:15,633 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-FollowerState] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1: changes role from  FOLLOWER to CANDIDATE at term 8 for changeToCandidate
dn5_1    | 2022-07-31 01:18:15,639 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-FollowerState] INFO impl.FollowerState: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5172934408ns, electionTimeout:5102ms
dn5_1    | 2022-07-31 01:18:15,641 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-FollowerState] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: shutdown 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-FollowerState
om1_1    | 2022-07-31 01:17:58,867 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 25d3afb12a88/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1    | 2022-07-31 01:18:00,868 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 25d3afb12a88/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1    | 2022-07-31 01:18:02,870 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 25d3afb12a88/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1    | 2022-07-31 01:18:04,872 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 25d3afb12a88/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1    | 2022-07-31 01:18:06,873 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 25d3afb12a88/10.9.0.11 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy33.send over nodeId=scmNodeId,nodeAddress=scm/10.9.0.14:9863 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1    | 2022-07-31 01:18:12,573 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1    | 2022-07-31 01:18:13,341 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om1_1    | 2022-07-31 01:18:13,346 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om1_1    | 2022-07-31 01:18:13,761 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om1_1    | 2022-07-31 01:18:13,975 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1    | 2022-07-31 01:18:13,975 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om1_1    | 2022-07-31 01:18:14,016 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om1_1    | 2022-07-31 01:18:14,621 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om1_1    | 2022-07-31 01:18:14,716 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1    | 2022-07-31 01:18:14,879 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: omservice and peers: om1:9872, om3:9872, om2:9872
om1_1    | 2022-07-31 01:18:14,942 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:6, i:98)
om1_1    | 2022-07-31 01:18:15,182 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om1_1    | 2022-07-31 01:18:16,158 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om1_1    | 2022-07-31 01:18:16,169 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1    | 2022-07-31 01:18:16,184 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om1_1    | 2022-07-31 01:18:16,199 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1    | 2022-07-31 01:18:16,203 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1    | 2022-07-31 01:18:16,215 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om1_1    | 2022-07-31 01:18:16,250 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1    | 2022-07-31 01:18:16,275 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om1_1    | 2022-07-31 01:18:16,306 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1    | 2022-07-31 01:18:16,557 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om1_1    | 2022-07-31 01:18:16,573 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om1_1    | 2022-07-31 01:18:18,824 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om1_1    | 2022-07-31 01:18:18,912 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om1_1    | 2022-07-31 01:18:18,929 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om1_1    | 2022-07-31 01:18:18,932 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1    | 2022-07-31 01:18:18,936 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1    | 2022-07-31 01:18:18,994 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1    | 2022-07-31 01:18:19,071 [om1-impl-thread1] INFO server.RaftServer: om1: found a subdirectory /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c
om1_1    | 2022-07-31 01:18:19,115 [main] INFO server.RaftServer: om1: addNew group-D66704EFC61C:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-D66704EFC61C:java.util.concurrent.CompletableFuture@4ef4f627[Not completed]
om1_1    | 2022-07-31 01:18:19,133 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om1_1    | 2022-07-31 01:18:19,605 [main] INFO om.OzoneManager: Creating RPC Server
om1_1    | 2022-07-31 01:18:19,614 [pool-26-thread-1] INFO server.RaftServer$Division: om1: new RaftServerImpl for group-D66704EFC61C:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om1_1    | 2022-07-31 01:18:19,648 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om1_1    | 2022-07-31 01:18:19,655 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om1_1    | 2022-07-31 01:18:19,659 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om1_1    | 2022-07-31 01:18:19,676 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1    | 2022-07-31 01:18:19,688 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1    | 2022-07-31 01:18:19,689 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om1_1    | 2022-07-31 01:18:19,866 [pool-26-thread-1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om1_1    | 2022-07-31 01:18:19,882 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1    | 2022-07-31 01:18:19,918 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om1_1    | 2022-07-31 01:18:19,945 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om1_1    | 2022-07-31 01:18:20,251 [pool-26-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/in_use.lock acquired by nodename 7@25d3afb12a88
om1_1    | 2022-07-31 01:18:20,303 [pool-26-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=6, votedFor=om2} from /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/raft-meta
om1_1    | 2022-07-31 01:18:20,834 [pool-26-thread-1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: set configuration 63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1    | 2022-07-31 01:18:20,845 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om1_1    | 2022-07-31 01:18:20,853 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1    | 2022-07-31 01:18:20,949 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om1_1    | 2022-07-31 01:18:20,951 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1    | 2022-07-31 01:18:20,958 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om1_1    | 2022-07-31 01:18:21,081 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1    | 2022-07-31 01:18:21,160 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om1_1    | 2022-07-31 01:18:21,160 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om1_1    | 2022-07-31 01:18:21,312 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: new om1@group-D66704EFC61C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c
om1_1    | 2022-07-31 01:18:21,351 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om1_1    | 2022-07-31 01:18:21,351 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om1_1    | 2022-07-31 01:18:21,352 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1    | 2022-07-31 01:18:21,352 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om1_1    | 2022-07-31 01:18:21,353 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om1_1    | 2022-07-31 01:18:21,399 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om1_1    | 2022-07-31 01:18:21,399 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om1_1    | 2022-07-31 01:18:21,399 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om1_1    | 2022-07-31 01:18:21,486 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om1_1    | 2022-07-31 01:18:21,487 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om1_1    | 2022-07-31 01:18:21,496 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om1_1    | 2022-07-31 01:18:21,714 [pool-26-thread-1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1    | 2022-07-31 01:18:21,756 [pool-26-thread-1] INFO segmented.LogSegment: Successfully read 21 entries from segment file /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_0-20
om1_1    | 2022-07-31 01:18:21,769 [pool-26-thread-1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: set configuration 21: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1    | 2022-07-31 01:18:21,781 [pool-26-thread-1] INFO segmented.LogSegment: Successfully read 42 entries from segment file /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_21-62
om1_1    | 2022-07-31 01:18:21,790 [pool-26-thread-1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: set configuration 63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1    | 2022-07-31 01:18:21,829 [pool-26-thread-1] INFO segmented.LogSegment: Successfully read 36 entries from segment file /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_inprogress_63
om1_1    | 2022-07-31 01:18:21,832 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-D66704EFC61C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 98
om1_1    | 2022-07-31 01:18:21,839 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-D66704EFC61C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 62
om1_1    | 2022-07-31 01:18:22,331 [pool-26-thread-1] INFO raftlog.RaftLog: om1@group-D66704EFC61C-SegmentedRaftLog: commitIndex: updateToMax old=98, new=97, updated? false
om1_1    | 2022-07-31 01:18:22,363 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om1_1    | 2022-07-31 01:18:22,369 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om1_1    | 2022-07-31 01:18:22,369 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om1_1    | 2022-07-31 01:18:22,376 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
dn5_1    | 2022-07-31 01:18:15,641 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-FollowerState] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610: changes role from  FOLLOWER to CANDIDATE at term 11 for changeToCandidate
dn5_1    | 2022-07-31 01:18:15,645 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-FollowerState] INFO impl.FollowerState: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5107194229ns, electionTimeout:5061ms
dn5_1    | 2022-07-31 01:18:15,645 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-FollowerState] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: shutdown 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-FollowerState
dn5_1    | 2022-07-31 01:18:15,645 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-FollowerState] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
dn5_1    | 2022-07-31 01:18:15,645 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn5_1    | 2022-07-31 01:18:15,645 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-FollowerState] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: start 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-LeaderElection2
dn5_1    | 2022-07-31 01:18:15,646 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn5_1    | 2022-07-31 01:18:15,646 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-FollowerState] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: start 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection1
dn5_1    | 2022-07-31 01:18:15,646 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn5_1    | 2022-07-31 01:18:15,646 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-FollowerState] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: start 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-LeaderElection3
dn5_1    | 2022-07-31 01:18:15,888 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-LeaderElection3] INFO impl.LeaderElection: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-LeaderElection3 ELECTION round 0: submit vote requests at term 9 for 31: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn5_1    | 2022-07-31 01:18:15,919 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection1] INFO impl.LeaderElection: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection1 ELECTION round 0: submit vote requests at term 12 for 3: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-07-31 01:18:15,954 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-LeaderElection2] INFO impl.LeaderElection: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-LeaderElection2 ELECTION round 0: submit vote requests at term 4 for 3: [52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-07-31 01:18:15,955 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-LeaderElection2] INFO impl.LeaderElection: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-LeaderElection2 ELECTION round 0: result PASSED (term=4)
dn5_1    | 2022-07-31 01:18:15,956 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-LeaderElection2] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: shutdown 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-LeaderElection2
dn5_1    | 2022-07-31 01:18:15,956 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-LeaderElection2] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED: changes role from CANDIDATE to LEADER at term 4 for changeToLeader
dn5_1    | 2022-07-31 01:18:16,009 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-CD003ECC1EED with new leaderId: 52aca038-7576-46a0-9ccd-b8aed29078e2
dn5_1    | 2022-07-31 01:18:16,028 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-LeaderElection2] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED: change Leader from null to 52aca038-7576-46a0-9ccd-b8aed29078e2 at term 4 for becomeLeader, leader elected after 14391ms
dn5_1    | 2022-07-31 01:18:16,265 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn5_1    | 2022-07-31 01:18:16,323 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn5_1    | 2022-07-31 01:18:16,324 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn5_1    | 2022-07-31 01:18:16,422 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn5_1    | 2022-07-31 01:18:16,508 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn5_1    | 2022-07-31 01:18:16,509 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn5_1    | 2022-07-31 01:18:16,657 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn5_1    | 2022-07-31 01:18:16,671 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn5_1    | 2022-07-31 01:18:16,717 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-LeaderElection2] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: start 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-LeaderStateImpl
dn5_1    | 2022-07-31 01:18:17,038 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-SegmentedRaftLogWorker: Rolling segment log-3_4 to index:4
dn5_1    | 2022-07-31 01:18:17,147 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/106ad38c-cb28-4e98-a52d-cd003ecc1eed/current/log_inprogress_3 to /data/metadata/ratis/106ad38c-cb28-4e98-a52d-cd003ecc1eed/current/log_3-4
dn5_1    | 2022-07-31 01:18:17,266 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/106ad38c-cb28-4e98-a52d-cd003ecc1eed/current/log_inprogress_5
dn3_1    | 2022-07-31 01:20:33,355 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn3_1    | 2022-07-31 01:20:33,356 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn3_1    | 2022-07-31 01:20:33,356 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn3_1    | 2022-07-31 01:20:33,356 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn3_1    | 2022-07-31 01:20:33,357 [pool-34-thread-1] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn3_1    | 2022-07-31 01:20:33,357 [pool-34-thread-1] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn3_1    | 2022-07-31 01:20:33,365 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn3_1    | 2022-07-31 01:20:33,366 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn3_1    | 2022-07-31 01:20:33,366 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn3_1    | 2022-07-31 01:20:33,366 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn3_1    | 2022-07-31 01:20:33,366 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn3_1    | 2022-07-31 01:20:33,366 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn3_1    | 2022-07-31 01:20:33,367 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn3_1    | 2022-07-31 01:20:33,368 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn3_1    | 2022-07-31 01:20:33,368 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn3_1    | 2022-07-31 01:20:33,368 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn3_1    | 2022-07-31 01:20:33,368 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn3_1    | 2022-07-31 01:20:33,368 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312: start as a follower, conf=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:1], old=null
dn3_1    | 2022-07-31 01:20:33,368 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn3_1    | 2022-07-31 01:20:33,368 [pool-34-thread-1] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-FollowerState
dn3_1    | 2022-07-31 01:20:33,369 [pool-34-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5058278E2312,id=3fc9f139-dd93-41e7-b235-52ce94d6fe3c
dn3_1    | 2022-07-31 01:20:33,406 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=e372288d-28a7-4132-a525-5058278e2312
dn3_1    | 2022-07-31 01:20:33,407 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=e372288d-28a7-4132-a525-5058278e2312.
dn3_1    | 2022-07-31 01:20:34,180 [grpc-default-executor-0] INFO server.RaftServer: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: addNew group-4B35CFA778DC:[3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0] returns group-4B35CFA778DC:java.util.concurrent.CompletableFuture@2dacfdc7[Not completed]
dn3_1    | 2022-07-31 01:20:34,182 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: new RaftServerImpl for group-4B35CFA778DC:[3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
dn3_1    | 2022-07-31 01:20:34,182 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn3_1    | 2022-07-31 01:20:34,182 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn3_1    | 2022-07-31 01:20:34,182 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn3_1    | 2022-07-31 01:20:34,183 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn3_1    | 2022-07-31 01:20:34,183 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn3_1    | 2022-07-31 01:20:34,183 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn3_1    | 2022-07-31 01:20:34,183 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC: ConfigurationManager, init=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
dn3_1    | 2022-07-31 01:20:34,183 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn3_1    | 2022-07-31 01:20:34,184 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn3_1    | 2022-07-31 01:20:34,184 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn3_1    | 2022-07-31 01:20:34,184 [pool-34-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/e19f4611-626e-4580-84ca-4b35cfa778dc does not exist. Creating ...
dn3_1    | 2022-07-31 01:20:34,189 [pool-34-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/e19f4611-626e-4580-84ca-4b35cfa778dc/in_use.lock acquired by nodename 6@6dca380edee9
dn3_1    | 2022-07-31 01:20:34,191 [pool-34-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/e19f4611-626e-4580-84ca-4b35cfa778dc has been successfully formatted.
dn3_1    | 2022-07-31 01:20:34,197 [pool-34-thread-1] INFO ratis.ContainerStateMachine: group-4B35CFA778DC: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn3_1    | 2022-07-31 01:20:34,197 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn3_1    | 2022-07-31 01:20:34,198 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn3_1    | 2022-07-31 01:20:34,198 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn5_1    | 2022-07-31 01:18:17,341 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-LeaderElection2] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED: set configuration 5: [52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-07-31 01:18:17,981 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$487/0x0000000840571840@661cabca] WARN util.JvmPauseMonitor: JvmPauseMonitor-52aca038-7576-46a0-9ccd-b8aed29078e2: Detected pause in JVM or host machine (eg GC): pause of approximately 139556071ns.
dn5_1    | GC pool 'ParNew' had collection(s): count=1 time=145ms
dn5_1    | 2022-07-31 01:18:20,060 [grpc-default-executor-0] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1: receive requestVote(ELECTION, 11cba143-91f8-47cb-8422-c32a1e2d51df, group-65A101075AF1, 9, (t:8, i:35))
dn5_1    | 2022-07-31 01:18:20,081 [grpc-default-executor-0] INFO impl.VoteContext: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-CANDIDATE: reject ELECTION from 11cba143-91f8-47cb-8422-c32a1e2d51df: already has voted for 52aca038-7576-46a0-9ccd-b8aed29078e2 at current term 9
dn5_1    | 2022-07-31 01:18:20,082 [grpc-default-executor-1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610: receive requestVote(ELECTION, 310a080d-f635-46ff-a53d-49cc9a09fa5c, group-7BB2A1276610, 12, (t:11, i:12))
dn5_1    | 2022-07-31 01:18:20,109 [grpc-default-executor-1] INFO impl.VoteContext: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-CANDIDATE: reject ELECTION from 310a080d-f635-46ff-a53d-49cc9a09fa5c: already has voted for 52aca038-7576-46a0-9ccd-b8aed29078e2 at current term 12
dn5_1    | 2022-07-31 01:18:20,178 [grpc-default-executor-1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610 replies to ELECTION vote request: 310a080d-f635-46ff-a53d-49cc9a09fa5c<-52aca038-7576-46a0-9ccd-b8aed29078e2#0:FAIL-t12. Peer's state: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610:t12, leader=null, voted=52aca038-7576-46a0-9ccd-b8aed29078e2, raftlog=52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-SegmentedRaftLog:OPENED:c12, conf=3: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-07-31 01:18:20,204 [grpc-default-executor-0] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1 replies to ELECTION vote request: 11cba143-91f8-47cb-8422-c32a1e2d51df<-52aca038-7576-46a0-9ccd-b8aed29078e2#0:FAIL-t9. Peer's state: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1:t9, leader=null, voted=52aca038-7576-46a0-9ccd-b8aed29078e2, raftlog=52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-SegmentedRaftLog:OPENED:c35, conf=31: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn5_1    | 2022-07-31 01:18:20,333 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-LeaderElection3] INFO impl.LeaderElection: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-LeaderElection3: ELECTION REJECTED received 1 response(s) and 0 exception(s):
dn5_1    | 2022-07-31 01:18:20,336 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-LeaderElection3] INFO impl.LeaderElection:   Response 0: 52aca038-7576-46a0-9ccd-b8aed29078e2<-609e7f2d-9474-472f-937f-8fa0a0bbb327#0:FAIL-t9
dn5_1    | 2022-07-31 01:18:20,336 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-LeaderElection3] INFO impl.LeaderElection: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-LeaderElection3 ELECTION round 0: result REJECTED
dn5_1    | 2022-07-31 01:18:20,337 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-LeaderElection3] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1: changes role from CANDIDATE to FOLLOWER at term 9 for REJECTED
dn5_1    | 2022-07-31 01:18:20,340 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-LeaderElection3] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: shutdown 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-LeaderElection3
dn5_1    | 2022-07-31 01:18:20,341 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-LeaderElection3] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: start 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-FollowerState
dn5_1    | 2022-07-31 01:18:20,408 [grpc-default-executor-0] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1: receive requestVote(ELECTION, 609e7f2d-9474-472f-937f-8fa0a0bbb327, group-65A101075AF1, 9, (t:8, i:35))
dn5_1    | 2022-07-31 01:18:20,409 [grpc-default-executor-0] INFO impl.VoteContext: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-FOLLOWER: reject ELECTION from 609e7f2d-9474-472f-937f-8fa0a0bbb327: already has voted for 52aca038-7576-46a0-9ccd-b8aed29078e2 at current term 9
dn5_1    | 2022-07-31 01:18:20,413 [grpc-default-executor-0] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1 replies to ELECTION vote request: 609e7f2d-9474-472f-937f-8fa0a0bbb327<-52aca038-7576-46a0-9ccd-b8aed29078e2#0:FAIL-t9. Peer's state: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1:t9, leader=null, voted=52aca038-7576-46a0-9ccd-b8aed29078e2, raftlog=52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-SegmentedRaftLog:OPENED:c35, conf=31: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn5_1    | 2022-07-31 01:18:20,414 [grpc-default-executor-0] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610: receive requestVote(ELECTION, 3fc9f139-dd93-41e7-b235-52ce94d6fe3c, group-7BB2A1276610, 12, (t:11, i:12))
dn5_1    | 2022-07-31 01:18:20,416 [grpc-default-executor-0] INFO impl.VoteContext: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-CANDIDATE: reject ELECTION from 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: already has voted for 52aca038-7576-46a0-9ccd-b8aed29078e2 at current term 12
dn5_1    | 2022-07-31 01:18:20,417 [grpc-default-executor-0] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610 replies to ELECTION vote request: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c<-52aca038-7576-46a0-9ccd-b8aed29078e2#0:FAIL-t12. Peer's state: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610:t12, leader=null, voted=52aca038-7576-46a0-9ccd-b8aed29078e2, raftlog=52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-SegmentedRaftLog:OPENED:c12, conf=3: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn4_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn4_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn4_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn4_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn4_1    | 2022-07-31 01:18:46,671 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn4_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn4_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn4_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn4_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn4_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn4_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn4_1    | 2022-07-31 01:18:46,672 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn4_1    | 2022-07-31 01:18:46,672 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn4_1    | 2022-07-31 01:18:46,672 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn4_1    | 2022-07-31 01:18:46,672 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 2001 to close, current state is: CLOSING
dn4_1    | 2022-07-31 01:18:46,672 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn4_1    | 2022-07-31 01:18:46,672 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn4_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn4_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn4_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn4_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn4_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn4_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn4_1    | 2022-07-31 01:18:46,672 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn4_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn4_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn4_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn4_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn4_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn4_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn4_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn4_1    | 2022-07-31 01:19:02,452 [ContainerOp-b88205de-97a2-4448-8e49-7bb2a1276610-0] INFO keyvalue.KeyValueContainer: Container 2001 is synced with bcsId 11.
dn4_1    | 2022-07-31 01:19:02,453 [ContainerOp-b88205de-97a2-4448-8e49-7bb2a1276610-0] INFO keyvalue.KeyValueContainer: Container 2001 is synced with bcsId 11.
dn4_1    | 2022-07-31 01:19:02,497 [ContainerOp-b88205de-97a2-4448-8e49-7bb2a1276610-0] INFO keyvalue.KeyValueContainer: Container 2001 is closed with bcsId 11.
dn4_1    | 2022-07-31 01:19:33,499 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn4_1    | 2022-07-31 01:19:33,499 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn4_1    | 2022-07-31 01:19:33,499 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn4_1    | 2022-07-31 01:19:33,500 [Command processor thread] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: ERASURE_CODED_STORAGE_SUPPORT.
dn4_1    | 2022-07-31 01:19:33,504 [Command processor thread] INFO upgrade.AbstractLayoutVersionManager: Layout feature ERASURE_CODED_STORAGE_SUPPORT has been finalized.
dn4_1    | 2022-07-31 01:19:33,505 [Command processor thread] INFO upgrade.UpgradeFinalizer: Running finalization actions for layout feature: DATANODE_SCHEMA_V3
dn4_1    | 2022-07-31 01:19:33,505 [Command processor thread] INFO upgrade.DatanodeSchemaV3FinalizeAction: Upgrading Datanode volume layout for Schema V3 support.
dn5_1    | 2022-07-31 01:18:20,460 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection1] INFO impl.LeaderElection: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
dn5_1    | 2022-07-31 01:18:20,461 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection1] INFO impl.LeaderElection:   Response 0: 52aca038-7576-46a0-9ccd-b8aed29078e2<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:FAIL-t12
dn5_1    | 2022-07-31 01:18:20,465 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection1] INFO impl.LeaderElection:   Response 1: 52aca038-7576-46a0-9ccd-b8aed29078e2<-310a080d-f635-46ff-a53d-49cc9a09fa5c#0:FAIL-t12
dn5_1    | 2022-07-31 01:18:20,465 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection1] INFO impl.LeaderElection: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection1 ELECTION round 0: result REJECTED
dn5_1    | 2022-07-31 01:18:20,466 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610: changes role from CANDIDATE to FOLLOWER at term 12 for REJECTED
dn5_1    | 2022-07-31 01:18:20,466 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection1] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: shutdown 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection1
dn5_1    | 2022-07-31 01:18:20,466 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection1] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: start 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-FollowerState
dn5_1    | 2022-07-31 01:18:25,308 [grpc-default-executor-0] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1: receive requestVote(ELECTION, 11cba143-91f8-47cb-8422-c32a1e2d51df, group-65A101075AF1, 10, (t:8, i:35))
dn5_1    | 2022-07-31 01:18:25,309 [grpc-default-executor-0] INFO impl.VoteContext: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-FOLLOWER: accept ELECTION from 11cba143-91f8-47cb-8422-c32a1e2d51df: our priority 0 <= candidate's priority 0
dn5_1    | 2022-07-31 01:18:25,309 [grpc-default-executor-0] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1: changes role from  FOLLOWER to FOLLOWER at term 10 for candidate:11cba143-91f8-47cb-8422-c32a1e2d51df
dn5_1    | 2022-07-31 01:18:25,309 [grpc-default-executor-0] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: shutdown 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-FollowerState
dn5_1    | 2022-07-31 01:18:25,309 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-FollowerState] INFO impl.FollowerState: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-FollowerState was interrupted
dn5_1    | 2022-07-31 01:18:25,310 [grpc-default-executor-0] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: start 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-FollowerState
dn5_1    | 2022-07-31 01:18:25,317 [grpc-default-executor-0] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1 replies to ELECTION vote request: 11cba143-91f8-47cb-8422-c32a1e2d51df<-52aca038-7576-46a0-9ccd-b8aed29078e2#0:OK-t10. Peer's state: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1:t10, leader=null, voted=11cba143-91f8-47cb-8422-c32a1e2d51df, raftlog=52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-SegmentedRaftLog:OPENED:c35, conf=31: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn5_1    | 2022-07-31 01:18:25,516 [grpc-default-executor-0] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610: receive requestVote(ELECTION, 310a080d-f635-46ff-a53d-49cc9a09fa5c, group-7BB2A1276610, 13, (t:11, i:12))
dn5_1    | 2022-07-31 01:18:25,516 [grpc-default-executor-0] INFO impl.VoteContext: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-FOLLOWER: reject ELECTION from 310a080d-f635-46ff-a53d-49cc9a09fa5c: our priority 1 > candidate's priority 0
dn5_1    | 2022-07-31 01:18:25,516 [grpc-default-executor-0] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610: changes role from  FOLLOWER to FOLLOWER at term 13 for candidate:310a080d-f635-46ff-a53d-49cc9a09fa5c
dn5_1    | 2022-07-31 01:18:25,517 [grpc-default-executor-0] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: shutdown 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-FollowerState
dn5_1    | 2022-07-31 01:18:25,517 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-FollowerState] INFO impl.FollowerState: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-FollowerState was interrupted
dn5_1    | 2022-07-31 01:18:25,519 [grpc-default-executor-0] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: start 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-FollowerState
dn5_1    | 2022-07-31 01:18:25,522 [grpc-default-executor-0] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610 replies to ELECTION vote request: 310a080d-f635-46ff-a53d-49cc9a09fa5c<-52aca038-7576-46a0-9ccd-b8aed29078e2#0:FAIL-t13. Peer's state: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610:t13, leader=null, voted=null, raftlog=52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-SegmentedRaftLog:OPENED:c12, conf=3: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-07-31 01:18:30,513 [grpc-default-executor-0] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1: receive requestVote(ELECTION, 609e7f2d-9474-472f-937f-8fa0a0bbb327, group-65A101075AF1, 11, (t:8, i:35))
dn5_1    | 2022-07-31 01:18:30,513 [grpc-default-executor-0] INFO impl.VoteContext: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-FOLLOWER: accept ELECTION from 609e7f2d-9474-472f-937f-8fa0a0bbb327: our priority 0 <= candidate's priority 1
dn5_1    | 2022-07-31 01:18:30,513 [grpc-default-executor-0] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1: changes role from  FOLLOWER to FOLLOWER at term 11 for candidate:609e7f2d-9474-472f-937f-8fa0a0bbb327
dn5_1    | 2022-07-31 01:18:30,514 [grpc-default-executor-0] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: shutdown 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-FollowerState
dn5_1    | 2022-07-31 01:18:30,514 [grpc-default-executor-0] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: start 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-FollowerState
dn5_1    | 2022-07-31 01:18:30,514 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-FollowerState] INFO impl.FollowerState: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-FollowerState was interrupted
dn5_1    | 2022-07-31 01:18:30,517 [grpc-default-executor-0] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1 replies to ELECTION vote request: 609e7f2d-9474-472f-937f-8fa0a0bbb327<-52aca038-7576-46a0-9ccd-b8aed29078e2#0:OK-t11. Peer's state: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1:t11, leader=null, voted=609e7f2d-9474-472f-937f-8fa0a0bbb327, raftlog=52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-SegmentedRaftLog:OPENED:c35, conf=31: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn5_1    | 2022-07-31 01:18:30,523 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-FollowerState] INFO impl.FollowerState: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5006028001ns, electionTimeout:5002ms
dn5_1    | 2022-07-31 01:18:30,523 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-FollowerState] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: shutdown 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-FollowerState
dn5_1    | 2022-07-31 01:18:30,523 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-FollowerState] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610: changes role from  FOLLOWER to CANDIDATE at term 13 for changeToCandidate
dn5_1    | 2022-07-31 01:18:30,524 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn5_1    | 2022-07-31 01:18:30,525 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-FollowerState] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: start 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4
dn5_1    | 2022-07-31 01:18:30,529 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO impl.LeaderElection: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4 ELECTION round 0: submit vote requests at term 14 for 3: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-07-31 01:18:30,557 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO impl.LeaderElection: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4: ELECTION PASSED received 1 response(s) and 0 exception(s):
dn5_1    | 2022-07-31 01:18:30,557 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO impl.LeaderElection:   Response 0: 52aca038-7576-46a0-9ccd-b8aed29078e2<-310a080d-f635-46ff-a53d-49cc9a09fa5c#0:OK-t14
dn5_1    | 2022-07-31 01:18:30,557 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO impl.LeaderElection: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4 ELECTION round 0: result PASSED
dn5_1    | 2022-07-31 01:18:30,558 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: shutdown 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4
dn5_1    | 2022-07-31 01:18:30,558 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610: changes role from CANDIDATE to LEADER at term 14 for changeToLeader
dn5_1    | 2022-07-31 01:18:30,558 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-7BB2A1276610 with new leaderId: 52aca038-7576-46a0-9ccd-b8aed29078e2
dn5_1    | 2022-07-31 01:18:30,558 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610: change Leader from null to 52aca038-7576-46a0-9ccd-b8aed29078e2 at term 14 for becomeLeader, leader elected after 32903ms
dn5_1    | 2022-07-31 01:18:30,558 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn5_1    | 2022-07-31 01:18:30,578 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn5_1    | 2022-07-31 01:18:30,578 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn5_1    | 2022-07-31 01:18:30,578 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn5_1    | 2022-07-31 01:18:30,578 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn5_1    | 2022-07-31 01:18:30,582 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn5_1    | 2022-07-31 01:18:30,583 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn5_1    | 2022-07-31 01:18:30,585 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn5_1    | 2022-07-31 01:18:30,698 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn5_1    | 2022-07-31 01:18:30,709 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn5_1    | 2022-07-31 01:18:30,710 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
dn5_1    | 2022-07-31 01:18:30,715 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn5_1    | 2022-07-31 01:18:30,725 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn5_1    | 2022-07-31 01:18:30,729 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn5_1    | 2022-07-31 01:18:30,737 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn5_1    | 2022-07-31 01:18:30,740 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn5_1    | 2022-07-31 01:18:30,741 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
dn5_1    | 2022-07-31 01:18:30,741 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn5_1    | 2022-07-31 01:18:30,741 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn5_1    | 2022-07-31 01:18:30,741 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn2_1    | 2022-07-31 01:20:08,763 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-LeaderElection5] INFO impl.LeaderElection: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-LeaderElection5 ELECTION round 0: result REJECTED
dn2_1    | 2022-07-31 01:20:08,763 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-LeaderElection5] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
dn2_1    | 2022-07-31 01:20:08,763 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-LeaderElection5] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: shutdown 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-LeaderElection5
dn2_1    | 2022-07-31 01:20:08,763 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-LeaderElection5] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: start 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-FollowerState
dn2_1    | 2022-07-31 01:20:08,800 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-FollowerState] INFO impl.FollowerState: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5197060839ns, electionTimeout:5194ms
dn2_1    | 2022-07-31 01:20:08,800 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-FollowerState] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: shutdown 11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-FollowerState
dn2_1    | 2022-07-31 01:20:08,801 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-FollowerState] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
dn2_1    | 2022-07-31 01:20:08,801 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn2_1    | 2022-07-31 01:20:08,801 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-FollowerState] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: start 11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-LeaderElection6
dn2_1    | 2022-07-31 01:20:08,805 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-LeaderElection6] INFO impl.LeaderElection: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-LeaderElection6 ELECTION round 0: submit vote requests at term 1 for -1: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:1], old=null
dn2_1    | 2022-07-31 01:20:08,805 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-LeaderElection6] INFO impl.LeaderElection: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-LeaderElection6 ELECTION round 0: result PASSED (term=1)
dn2_1    | 2022-07-31 01:20:08,805 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-LeaderElection6] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: shutdown 11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-LeaderElection6
dn2_1    | 2022-07-31 01:20:08,805 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-LeaderElection6] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
dn2_1    | 2022-07-31 01:20:08,805 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-LeaderElection6] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-26397C6FFFAD with new leaderId: 11cba143-91f8-47cb-8422-c32a1e2d51df
dn2_1    | 2022-07-31 01:20:08,805 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-LeaderElection6] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD: change Leader from null to 11cba143-91f8-47cb-8422-c32a1e2d51df at term 1 for becomeLeader, leader elected after 5243ms
dn2_1    | 2022-07-31 01:20:08,806 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn2_1    | 2022-07-31 01:20:08,806 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn2_1    | 2022-07-31 01:20:08,807 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn2_1    | 2022-07-31 01:20:08,808 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn2_1    | 2022-07-31 01:20:08,809 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn2_1    | 2022-07-31 01:20:08,809 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn2_1    | 2022-07-31 01:20:08,816 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn2_1    | 2022-07-31 01:20:08,816 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn2_1    | 2022-07-31 01:20:08,817 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-LeaderElection6] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: start 11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-LeaderStateImpl
dn2_1    | 2022-07-31 01:20:08,817 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-LeaderElection6] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-SegmentedRaftLogWorker: Starting segment from index:0
dn2_1    | 2022-07-31 01:20:08,819 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/da610dcf-61e8-4e48-8ead-26397c6fffad/current/log_inprogress_0
dn2_1    | 2022-07-31 01:20:08,820 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD-LeaderElection6] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-26397C6FFFAD: set configuration 0: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1], old=null
dn2_1    | 2022-07-31 01:20:10,935 [BlockDeletingService#0] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-2b5f2d05-a9c0-4b31-b820-5fa0b5f933e6/current/containerDir0/1/chunks/109611004723200001.block
dn2_1    | 2022-07-31 01:20:10,936 [BlockDeletingService#0] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-2b5f2d05-a9c0-4b31-b820-5fa0b5f933e6/current/containerDir0/1/chunks/109611004723200002.block
dn2_1    | 2022-07-31 01:20:10,936 [BlockDeletingService#0] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-2b5f2d05-a9c0-4b31-b820-5fa0b5f933e6/current/containerDir0/1/chunks/109611004723200003.block
dn2_1    | 2022-07-31 01:20:13,802 [grpc-default-executor-0] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7: receive requestVote(ELECTION, 310a080d-f635-46ff-a53d-49cc9a09fa5c, group-7781FFA9F9E7, 2, (t:0, i:0))
dn2_1    | 2022-07-31 01:20:13,803 [grpc-default-executor-0] INFO impl.VoteContext: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-FOLLOWER: accept ELECTION from 310a080d-f635-46ff-a53d-49cc9a09fa5c: our priority 0 <= candidate's priority 1
dn2_1    | 2022-07-31 01:20:13,803 [grpc-default-executor-0] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:310a080d-f635-46ff-a53d-49cc9a09fa5c
dn2_1    | 2022-07-31 01:20:13,803 [grpc-default-executor-0] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: shutdown 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-FollowerState
dn2_1    | 2022-07-31 01:20:13,803 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-FollowerState] INFO impl.FollowerState: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-FollowerState was interrupted
dn2_1    | 2022-07-31 01:20:13,803 [grpc-default-executor-0] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: start 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-FollowerState
om3_1    | 2022-07-31 01:18:30,352 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-D66704EFC61C: receive requestVote(ELECTION, om1, group-D66704EFC61C, 7, (t:6, i:98))
om3_1    | 2022-07-31 01:18:30,354 [grpc-default-executor-1] INFO impl.VoteContext: om3@group-D66704EFC61C-CANDIDATE: reject ELECTION from om1: already has voted for om3 at current term 7
om3_1    | 2022-07-31 01:18:30,436 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-D66704EFC61C replies to ELECTION vote request: om1<-om3#0:FAIL-t7. Peer's state: om3@group-D66704EFC61C:t7, leader=null, voted=om3, raftlog=om3@group-D66704EFC61C-SegmentedRaftLog:OPENED:c98, conf=63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1    | 2022-07-31 01:18:30,870 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-D66704EFC61C: receive requestVote(ELECTION, om2, group-D66704EFC61C, 7, (t:6, i:98))
om3_1    | 2022-07-31 01:18:30,870 [grpc-default-executor-1] INFO impl.VoteContext: om3@group-D66704EFC61C-CANDIDATE: reject ELECTION from om2: already has voted for om3 at current term 7
om3_1    | 2022-07-31 01:18:30,872 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-D66704EFC61C replies to ELECTION vote request: om2<-om3#0:FAIL-t7. Peer's state: om3@group-D66704EFC61C:t7, leader=null, voted=om3, raftlog=om3@group-D66704EFC61C-SegmentedRaftLog:OPENED:c98, conf=63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1    | 2022-07-31 01:18:31,051 [om3@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om3@group-D66704EFC61C-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om3_1    | 2022-07-31 01:18:31,051 [om3@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection:   Response 0: om3<-om1#0:FAIL-t7
om3_1    | 2022-07-31 01:18:31,051 [om3@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection:   Response 1: om3<-om2#0:FAIL-t7
om3_1    | 2022-07-31 01:18:31,052 [om3@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om3@group-D66704EFC61C-LeaderElection1 ELECTION round 0: result REJECTED
om3_1    | 2022-07-31 01:18:31,059 [om3@group-D66704EFC61C-LeaderElection1] INFO server.RaftServer$Division: om3@group-D66704EFC61C: changes role from CANDIDATE to FOLLOWER at term 7 for REJECTED
om3_1    | 2022-07-31 01:18:31,063 [om3@group-D66704EFC61C-LeaderElection1] INFO impl.RoleInfo: om3: shutdown om3@group-D66704EFC61C-LeaderElection1
om3_1    | 2022-07-31 01:18:31,064 [om3@group-D66704EFC61C-LeaderElection1] INFO impl.RoleInfo: om3: start om3@group-D66704EFC61C-FollowerState
om3_1    | 2022-07-31 01:18:36,054 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-D66704EFC61C: receive requestVote(ELECTION, om1, group-D66704EFC61C, 8, (t:6, i:98))
om3_1    | 2022-07-31 01:18:36,055 [grpc-default-executor-1] INFO impl.VoteContext: om3@group-D66704EFC61C-FOLLOWER: accept ELECTION from om1: our priority 0 <= candidate's priority 0
om3_1    | 2022-07-31 01:18:36,056 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-D66704EFC61C: changes role from  FOLLOWER to FOLLOWER at term 8 for candidate:om1
om3_1    | 2022-07-31 01:18:36,056 [grpc-default-executor-1] INFO impl.RoleInfo: om3: shutdown om3@group-D66704EFC61C-FollowerState
om3_1    | 2022-07-31 01:18:36,056 [grpc-default-executor-1] INFO impl.RoleInfo: om3: start om3@group-D66704EFC61C-FollowerState
om3_1    | 2022-07-31 01:18:36,056 [om3@group-D66704EFC61C-FollowerState] INFO impl.FollowerState: om3@group-D66704EFC61C-FollowerState was interrupted
om3_1    | 2022-07-31 01:18:36,069 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-D66704EFC61C replies to ELECTION vote request: om1<-om3#0:OK-t8. Peer's state: om3@group-D66704EFC61C:t8, leader=null, voted=om1, raftlog=om3@group-D66704EFC61C-SegmentedRaftLog:OPENED:c98, conf=63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1    | 2022-07-31 01:18:36,305 [om3-server-thread1] INFO server.RaftServer$Division: om3@group-D66704EFC61C: change Leader from null to om1 at term 8 for appendEntries, leader elected after 15665ms
om3_1    | 2022-07-31 01:18:36,370 [om3-server-thread2] INFO server.RaftServer$Division: om3@group-D66704EFC61C: set configuration 99: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1    | 2022-07-31 01:18:36,376 [om3-server-thread2] INFO segmented.SegmentedRaftLogWorker: om3@group-D66704EFC61C-SegmentedRaftLogWorker: Rolling segment log-63_98 to index:98
om3_1    | 2022-07-31 01:18:36,382 [om3@group-D66704EFC61C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om3@group-D66704EFC61C-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_inprogress_63 to /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_63-98
om3_1    | 2022-07-31 01:18:36,490 [om3@group-D66704EFC61C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om3@group-D66704EFC61C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_inprogress_99
om3_1    | 2022-07-31 01:18:36,764 [om3@group-D66704EFC61C-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om3_1    | [id: "om1"
om3_1    | address: "om1:9872"
om3_1    | , id: "om3"
om3_1    | address: "om3:9872"
om3_1    | , id: "om2"
om3_1    | address: "om2:9872"
om3_1    | ]
om3_1    | 2022-07-31 01:20:17,529 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: Finalization started.
om3_1    | 2022-07-31 01:20:17,532 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: ERASURE_CODED_STORAGE_SUPPORT.
om3_1    | 2022-07-31 01:20:17,535 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.AbstractLayoutVersionManager: Layout feature ERASURE_CODED_STORAGE_SUPPORT has been finalized.
om3_1    | 2022-07-31 01:20:17,535 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: BUCKET_LAYOUT_SUPPORT.
om3_1    | 2022-07-31 01:20:17,538 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.AbstractLayoutVersionManager: Layout feature BUCKET_LAYOUT_SUPPORT has been finalized.
om3_1    | 2022-07-31 01:20:17,538 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: MULTITENANCY_SCHEMA.
om3_1    | 2022-07-31 01:20:17,540 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.AbstractLayoutVersionManager: Layout feature MULTITENANCY_SCHEMA has been finalized.
om3_1    | 2022-07-31 01:20:17,540 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.AbstractLayoutVersionManager: Finalization is complete.
om3_1    | 2022-07-31 01:20:17,542 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: Finalization is done.
om3_1    | 2022-07-31 01:20:17,561 [OMDoubleBufferFlushThread] INFO upgrade.OMFinalizeUpgradeResponse: Layout version to persist to DB : 3
om3_1    | 2022-07-31 01:21:33,633 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:new2-volume for user:hadoop
om3_1    | 2022-07-31 01:21:36,642 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: new2-bucket of layout LEGACY in volume: new2-volume
dn2_1    | 2022-07-31 01:20:13,807 [grpc-default-executor-0] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7 replies to ELECTION vote request: 310a080d-f635-46ff-a53d-49cc9a09fa5c<-11cba143-91f8-47cb-8422-c32a1e2d51df#0:OK-t2. Peer's state: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7:t2, leader=null, voted=310a080d-f635-46ff-a53d-49cc9a09fa5c, raftlog=11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-SegmentedRaftLog:OPENED:c-1, conf=-1: [310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|priority:0], old=null
dn2_1    | 2022-07-31 01:20:13,929 [11cba143-91f8-47cb-8422-c32a1e2d51df-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-7781FFA9F9E7 with new leaderId: 310a080d-f635-46ff-a53d-49cc9a09fa5c
dn2_1    | 2022-07-31 01:20:13,930 [11cba143-91f8-47cb-8422-c32a1e2d51df-server-thread1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7: change Leader from null to 310a080d-f635-46ff-a53d-49cc9a09fa5c at term 2 for appendEntries, leader elected after 10279ms
dn2_1    | 2022-07-31 01:20:13,971 [11cba143-91f8-47cb-8422-c32a1e2d51df-server-thread1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7: set configuration 0: [310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-07-31 01:20:13,971 [11cba143-91f8-47cb-8422-c32a1e2d51df-server-thread1] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-SegmentedRaftLogWorker: Starting segment from index:0
dn2_1    | 2022-07-31 01:20:13,973 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-7781FFA9F9E7-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/ae7040c6-f723-491f-8b9e-7781ffa9f9e7/current/log_inprogress_0
dn2_1    | 2022-07-31 01:20:34,016 [grpc-default-executor-0] INFO server.RaftServer: 11cba143-91f8-47cb-8422-c32a1e2d51df: addNew group-4B35CFA778DC:[3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0] returns group-4B35CFA778DC:java.util.concurrent.CompletableFuture@4561604b[Not completed]
dn2_1    | 2022-07-31 01:20:34,018 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df: new RaftServerImpl for group-4B35CFA778DC:[3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
dn2_1    | 2022-07-31 01:20:34,018 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn2_1    | 2022-07-31 01:20:34,018 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn2_1    | 2022-07-31 01:20:34,019 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn2_1    | 2022-07-31 01:20:34,019 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn2_1    | 2022-07-31 01:20:34,019 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn2_1    | 2022-07-31 01:20:34,019 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn2_1    | 2022-07-31 01:20:34,019 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC: ConfigurationManager, init=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
dn2_1    | 2022-07-31 01:20:34,019 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn2_1    | 2022-07-31 01:20:34,020 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn2_1    | 2022-07-31 01:20:34,020 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn2_1    | 2022-07-31 01:20:34,020 [pool-42-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/e19f4611-626e-4580-84ca-4b35cfa778dc does not exist. Creating ...
dn2_1    | 2022-07-31 01:20:34,023 [pool-42-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/e19f4611-626e-4580-84ca-4b35cfa778dc/in_use.lock acquired by nodename 8@c5b89a034b5d
dn2_1    | 2022-07-31 01:20:34,028 [pool-42-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/e19f4611-626e-4580-84ca-4b35cfa778dc has been successfully formatted.
dn2_1    | 2022-07-31 01:20:34,034 [pool-42-thread-1] INFO ratis.ContainerStateMachine: group-4B35CFA778DC: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn2_1    | 2022-07-31 01:20:34,035 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn2_1    | 2022-07-31 01:20:34,035 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn2_1    | 2022-07-31 01:20:34,035 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn2_1    | 2022-07-31 01:20:34,035 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2022-07-31 01:20:34,036 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn2_1    | 2022-07-31 01:20:34,036 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2022-07-31 01:20:34,036 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn2_1    | 2022-07-31 01:20:34,036 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn2_1    | 2022-07-31 01:20:34,037 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: new 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/e19f4611-626e-4580-84ca-4b35cfa778dc
dn2_1    | 2022-07-31 01:20:34,037 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn2_1    | 2022-07-31 01:20:34,037 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn3_1    | 2022-07-31 01:20:34,198 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2022-07-31 01:20:34,199 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn3_1    | 2022-07-31 01:20:34,199 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2022-07-31 01:20:34,200 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn3_1    | 2022-07-31 01:20:34,200 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn3_1    | 2022-07-31 01:20:34,200 [pool-34-thread-1] INFO segmented.SegmentedRaftLogWorker: new 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/e19f4611-626e-4580-84ca-4b35cfa778dc
dn3_1    | 2022-07-31 01:20:34,200 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn3_1    | 2022-07-31 01:20:34,200 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn3_1    | 2022-07-31 01:20:34,200 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2022-07-31 01:20:34,200 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn3_1    | 2022-07-31 01:20:34,200 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn3_1    | 2022-07-31 01:20:34,200 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn3_1    | 2022-07-31 01:20:34,200 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn3_1    | 2022-07-31 01:20:34,201 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn3_1    | 2022-07-31 01:20:34,201 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn3_1    | 2022-07-31 01:20:34,202 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn3_1    | 2022-07-31 01:20:34,202 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn3_1    | 2022-07-31 01:20:34,202 [pool-34-thread-1] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn3_1    | 2022-07-31 01:20:34,202 [pool-34-thread-1] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn3_1    | 2022-07-31 01:20:34,207 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn3_1    | 2022-07-31 01:20:34,208 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn3_1    | 2022-07-31 01:20:34,208 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn3_1    | 2022-07-31 01:20:34,208 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn3_1    | 2022-07-31 01:20:34,208 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn3_1    | 2022-07-31 01:20:34,208 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn3_1    | 2022-07-31 01:20:34,209 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn3_1    | 2022-07-31 01:20:34,210 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn3_1    | 2022-07-31 01:20:34,210 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn3_1    | 2022-07-31 01:20:34,211 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn3_1    | 2022-07-31 01:20:34,211 [pool-34-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn3_1    | 2022-07-31 01:20:34,211 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC: start as a follower, conf=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn3_1    | 2022-07-31 01:20:34,211 [pool-34-thread-1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn3_1    | 2022-07-31 01:20:34,211 [pool-34-thread-1] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC-FollowerState
dn3_1    | 2022-07-31 01:20:34,215 [pool-34-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4B35CFA778DC,id=3fc9f139-dd93-41e7-b235-52ce94d6fe3c
dn3_1    | 2022-07-31 01:20:34,576 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState] INFO impl.FollowerState: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5074943755ns, electionTimeout:5067ms
dn3_1    | 2022-07-31 01:20:34,576 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: shutdown 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState
dn3_1    | 2022-07-31 01:20:34,577 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0: changes role from  FOLLOWER to CANDIDATE at term 5 for changeToCandidate
dn3_1    | 2022-07-31 01:20:34,577 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn3_1    | 2022-07-31 01:20:34,578 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-FollowerState] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5
dn3_1    | 2022-07-31 01:20:34,586 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO impl.LeaderElection: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5 ELECTION round 0: submit vote requests at term 6 for -1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn3_1    | 2022-07-31 01:20:34,607 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO impl.LeaderElection: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5: ELECTION PASSED received 1 response(s) and 0 exception(s):
recon_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
recon_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1  | 2022-07-31 01:17:25,120 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1  | /************************************************************
recon_1  | STARTUP_MSG: Starting ReconServer
recon_1  | STARTUP_MSG:   host = 3f4b2fd7f519/10.9.0.20
recon_1  | STARTUP_MSG:   args = []
recon_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
recon_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.33.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-tools-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.33.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.6.3.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.33.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jcl-over-slf4j-1.7.24.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/ozone-reconcodegen-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar
recon_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/57d620dbd4cb5dfec746cc16039d3843e64c181c ; compiled by 'runner' on 2022-07-31T00:52Z
recon_1  | STARTUP_MSG:   java = 11.0.14.1
recon_1  | ************************************************************/
recon_1  | 2022-07-31 01:17:25,192 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1  | WARNING: An illegal reflective access operation has occurred
recon_1  | WARNING: Illegal reflective access by com.google.inject.internal.cglib.core.$ReflectUtils$2 (file:/opt/hadoop/share/ozone/lib/guice-4.0.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int,java.security.ProtectionDomain)
recon_1  | WARNING: Please consider reporting this to the maintainers of com.google.inject.internal.cglib.core.$ReflectUtils$2
recon_1  | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1  | WARNING: All illegal access operations will be denied in a future release
recon_1  | 2022-07-31 01:17:30,607 [main] INFO reflections.Reflections: Reflections took 548 ms to scan 1 urls, producing 13 keys and 35 values 
recon_1  | 2022-07-31 01:17:36,118 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1  | 2022-07-31 01:17:36,131 [main] INFO impl.ReconDBProvider: Last known Recon DB : /data/metadata/recon/recon-container-key.db_1659229682693
recon_1  | 2022-07-31 01:17:37,945 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1  | 2022-07-31 01:17:44,695 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1  | 2022-07-31 01:17:47,769 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
dn5_1    | 2022-07-31 01:18:30,745 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: start 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderStateImpl
dn5_1    | 2022-07-31 01:18:30,748 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-SegmentedRaftLogWorker: Rolling segment log-3_12 to index:12
dn5_1    | 2022-07-31 01:18:30,778 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/current/log_inprogress_3 to /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/current/log_3-12
dn5_1    | 2022-07-31 01:18:30,788 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/current/log_inprogress_13
dn5_1    | 2022-07-31 01:18:30,819 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderElection4] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610: set configuration 13: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-07-31 01:18:31,324 [52aca038-7576-46a0-9ccd-b8aed29078e2-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-65A101075AF1 with new leaderId: 609e7f2d-9474-472f-937f-8fa0a0bbb327
dn5_1    | 2022-07-31 01:18:31,324 [52aca038-7576-46a0-9ccd-b8aed29078e2-server-thread1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1: change Leader from null to 609e7f2d-9474-472f-937f-8fa0a0bbb327 at term 11 for appendEntries, leader elected after 29333ms
dn5_1    | 2022-07-31 01:18:31,407 [52aca038-7576-46a0-9ccd-b8aed29078e2-server-thread1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1: set configuration 36: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn5_1    | 2022-07-31 01:18:31,408 [52aca038-7576-46a0-9ccd-b8aed29078e2-server-thread1] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-SegmentedRaftLogWorker: Rolling segment log-31_35 to index:35
dn5_1    | 2022-07-31 01:18:31,414 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/current/log_inprogress_31 to /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/current/log_31-35
dn5_1    | 2022-07-31 01:18:31,424 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/current/log_inprogress_36
dn5_1    | 2022-07-31 01:19:02,440 [ContainerOp-67b1342c-3bb3-4b48-a218-65a101075af1-0] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 10.
dn5_1    | 2022-07-31 01:19:02,448 [ContainerOp-67b1342c-3bb3-4b48-a218-65a101075af1-0] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 10.
dn5_1    | 2022-07-31 01:19:02,455 [ContainerOp-b88205de-97a2-4448-8e49-7bb2a1276610-0] INFO keyvalue.KeyValueContainer: Container 2001 is synced with bcsId 11.
dn5_1    | 2022-07-31 01:19:02,458 [ContainerOp-b88205de-97a2-4448-8e49-7bb2a1276610-0] INFO keyvalue.KeyValueContainer: Container 2001 is synced with bcsId 11.
dn5_1    | 2022-07-31 01:19:02,472 [ContainerOp-67b1342c-3bb3-4b48-a218-65a101075af1-0] INFO keyvalue.KeyValueContainer: Container 1 is closed with bcsId 10.
dn5_1    | 2022-07-31 01:19:02,485 [ContainerOp-b88205de-97a2-4448-8e49-7bb2a1276610-0] INFO keyvalue.KeyValueContainer: Container 2001 is closed with bcsId 11.
dn5_1    | 2022-07-31 01:19:02,604 [ContainerOp-67b1342c-3bb3-4b48-a218-65a101075af1-1] INFO keyvalue.KeyValueContainer: Container 1002 is synced with bcsId 29.
dn5_1    | 2022-07-31 01:19:02,605 [ContainerOp-67b1342c-3bb3-4b48-a218-65a101075af1-1] INFO keyvalue.KeyValueContainer: Container 1002 is synced with bcsId 29.
dn5_1    | 2022-07-31 01:19:02,616 [ContainerOp-67b1342c-3bb3-4b48-a218-65a101075af1-1] INFO keyvalue.KeyValueContainer: Container 1002 is closed with bcsId 29.
dn5_1    | 2022-07-31 01:19:02,667 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | 2022-07-31 01:19:02,670 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn5_1    | 2022-07-31 01:19:02,671 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn5_1    | 2022-07-31 01:19:02,671 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 2003 to close, current state is: CLOSING
dn5_1    | 2022-07-31 01:19:02,671 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn5_1    | 2022-07-31 01:19:02,672 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-07-31 01:19:02,672 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
recon_1  | 2022-07-31 01:17:47,792 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1  | 2022-07-31 01:17:47,810 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1  | 2022-07-31 01:17:51,909 [main] INFO codegen.SqlDbUtils: FILE_COUNT_BY_SIZE table already exists, skipping creation.
recon_1  | 2022-07-31 01:17:51,975 [main] INFO codegen.SqlDbUtils: CLUSTER_GROWTH_DAILY table already exists, skipping creation.
recon_1  | 2022-07-31 01:17:52,094 [main] INFO codegen.SqlDbUtils: RECON_TASK_STATUS table already exists, skipping creation.
recon_1  | 2022-07-31 01:17:52,144 [main] INFO codegen.SqlDbUtils: GLOBAL_STATS table already exists, skipping creation.
recon_1  | 2022-07-31 01:17:52,329 [main] INFO codegen.SqlDbUtils: UNHEALTHY_CONTAINERS table already exists, skipping creation.
recon_1  | 2022-07-31 01:17:53,033 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1  | 2022-07-31 01:17:53,172 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
recon_1  | 2022-07-31 01:17:53,286 [main] INFO util.log: Logging initialized @40125ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1  | 2022-07-31 01:17:53,935 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
recon_1  | 2022-07-31 01:17:53,988 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1  | 2022-07-31 01:17:54,065 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1  | 2022-07-31 01:17:54,086 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context recon
recon_1  | 2022-07-31 01:17:54,096 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
recon_1  | 2022-07-31 01:17:54,101 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
recon_1  | 2022-07-31 01:17:54,930 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1  | 2022-07-31 01:17:55,286 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1  | 2022-07-31 01:17:55,299 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
recon_1  | 2022-07-31 01:17:55,306 [main] INFO tasks.ReconTaskControllerImpl: Registered task NSSummaryTask with controller.
recon_1  | 2022-07-31 01:17:55,396 [main] INFO ozone.OmUtils: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
recon_1  | 2022-07-31 01:17:55,404 [main] INFO ozone.OmUtils: Using OzoneManager ServiceID 'omservice'.
recon_1  | 2022-07-31 01:17:58,691 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1  | 2022-07-31 01:17:59,522 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1  | 2022-07-31 01:17:59,816 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
recon_1  | 2022-07-31 01:17:59,836 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1  | 2022-07-31 01:18:00,517 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1  | 2022-07-31 01:18:00,911 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
recon_1  | 2022-07-31 01:18:01,423 [main] INFO reflections.Reflections: Reflections took 466 ms to scan 3 urls, producing 109 keys and 246 values 
recon_1  | 2022-07-31 01:18:01,758 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
recon_1  | 2022-07-31 01:18:01,920 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1  | 2022-07-31 01:18:02,055 [main] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/11cba143-91f8-47cb-8422-c32a1e2d51df
recon_1  | 2022-07-31 01:18:02,057 [main] INFO node.SCMNodeManager: Registered Data node : 11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2022-07-31 01:18:02,064 [main] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/310a080d-f635-46ff-a53d-49cc9a09fa5c
recon_1  | 2022-07-31 01:18:02,069 [main] INFO node.SCMNodeManager: Registered Data node : 310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2022-07-31 01:18:02,073 [main] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/3fc9f139-dd93-41e7-b235-52ce94d6fe3c
recon_1  | 2022-07-31 01:18:02,073 [main] INFO node.SCMNodeManager: Registered Data node : 3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2022-07-31 01:18:02,073 [main] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/52aca038-7576-46a0-9ccd-b8aed29078e2
recon_1  | 2022-07-31 01:18:02,074 [main] INFO node.SCMNodeManager: Registered Data node : 52aca038-7576-46a0-9ccd-b8aed29078e2{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2022-07-31 01:18:02,074 [main] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/609e7f2d-9474-472f-937f-8fa0a0bbb327
recon_1  | 2022-07-31 01:18:02,077 [main] INFO node.SCMNodeManager: Registered Data node : 609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2022-07-31 01:18:02,077 [main] INFO scm.ReconNodeManager: Loaded 5 nodes from node DB.
recon_1  | 2022-07-31 01:18:02,093 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1  | 2022-07-31 01:18:03,842 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
recon_1  | 2022-07-31 01:18:03,974 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1  | 2022-07-31 01:18:04,154 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1  | 2022-07-31 01:18:04,752 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
recon_1  | 2022-07-31 01:18:04,759 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
recon_1  | 2022-07-31 01:18:05,136 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1  | 2022-07-31 01:18:05,163 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1  | 2022-07-31 01:18:05,163 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1  | 2022-07-31 01:18:05,567 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1  | 2022-07-31 01:18:05,582 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
recon_1  | 2022-07-31 01:18:05,671 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1  | 2022-07-31 01:18:05,671 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1  | 2022-07-31 01:18:05,678 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 660000ms
recon_1  | 2022-07-31 01:18:05,716 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@716185fe{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1  | 2022-07-31 01:18:05,721 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@fd09e43{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1  | 2022-07-31 01:18:09,158 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@2eb03908{recon,/,file:///tmp/jetty-0_0_0_0-9888-ozone-recon-1_3_0-SNAPSHOT_jar-_-any-12090029586393472271/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/recon}
recon_1  | 2022-07-31 01:18:09,172 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@6ddee60f{HTTP/1.1, (http/1.1)}{0.0.0.0:9888}
recon_1  | 2022-07-31 01:18:09,175 [Listener at 0.0.0.0/9891] INFO server.Server: Started @56012ms
recon_1  | 2022-07-31 01:18:09,181 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1  | 2022-07-31 01:18:09,182 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1  | 2022-07-31 01:18:09,184 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1  | 2022-07-31 01:18:09,184 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1  | 2022-07-31 01:18:09,189 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
recon_1  | 2022-07-31 01:18:09,189 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1  | 2022-07-31 01:18:09,190 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Last known snapshot for OM : /data/metadata/om.snapshot.db_1659230173349
recon_1  | 2022-07-31 01:18:09,198 [Listener at 0.0.0.0/9891] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1  | 2022-07-31 01:18:09,204 [Listener at 0.0.0.0/9891] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
recon_1  | 2022-07-31 01:18:09,287 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Created OM DB handle from snapshot at /data/metadata/om.snapshot.db_1659230173349.
recon_1  | 2022-07-31 01:18:09,308 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1  | 2022-07-31 01:18:09,315 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1  | 2022-07-31 01:18:11,869 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 8 pipelines from SCM.
recon_1  | 2022-07-31 01:18:11,870 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 8 pipelines in house.
recon_1  | 2022-07-31 01:18:12,016 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1  | 2022-07-31 01:18:12,035 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1  | 2022-07-31 01:18:12,119 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1  | 2022-07-31 01:18:12,264 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1  | 2022-07-31 01:18:12,363 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting ContainerHealthTask Thread.
recon_1  | 2022-07-31 01:18:12,407 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 8 pipelines in house.
recon_1  | 2022-07-31 01:18:12,651 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 287 milliseconds.
recon_1  | 2022-07-31 01:18:13,558 [IPC Server handler 1 on default port 9891] WARN ipc.Server: IPC Server handler 1 on default port 9891, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.19:55840: output error
recon_1  | 2022-07-31 01:18:13,558 [IPC Server handler 4 on default port 9891] WARN ipc.Server: IPC Server handler 4 on default port 9891, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.16:37832: output error
recon_1  | 2022-07-31 01:18:13,559 [IPC Server handler 6 on default port 9891] WARN ipc.Server: IPC Server handler 6 on default port 9891, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.15:47394: output error
recon_1  | 2022-07-31 01:18:13,564 [IPC Server handler 0 on default port 9891] WARN ipc.Server: IPC Server handler 0 on default port 9891, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.17:59242: output error
recon_1  | 2022-07-31 01:18:13,565 [IPC Server handler 5 on default port 9891] WARN ipc.Server: IPC Server handler 5 on default port 9891, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.18:48198: output error
recon_1  | 2022-07-31 01:18:13,572 [IPC Server handler 1 on default port 9891] INFO ipc.Server: IPC Server handler 1 on default port 9891 caught an exception
recon_1  | java.nio.channels.ClosedChannelException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3605)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:141)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1667)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1737)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2837)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1809)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1117)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:909)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:895)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1052)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
dn4_1    | 2022-07-31 01:19:33,646 [Command processor thread] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-2b5f2d05-a9c0-4b31-b820-5fa0b5f933e6/DS-7f823c72-3ff9-411f-b395-ee1edcfc5ad1/container.db for volume DS-7f823c72-3ff9-411f-b395-ee1edcfc5ad1
dn4_1    | 2022-07-31 01:19:33,650 [Command processor thread] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-2b5f2d05-a9c0-4b31-b820-5fa0b5f933e6/DS-7f823c72-3ff9-411f-b395-ee1edcfc5ad1/container.db for volume DS-7f823c72-3ff9-411f-b395-ee1edcfc5ad1
dn4_1    | 2022-07-31 01:19:33,653 [Command processor thread] INFO upgrade.DatanodeSchemaV3FinalizeAction: Schema V3 is disabled. Won't load RocksDB in upgrade.
dn4_1    | 2022-07-31 01:19:33,655 [Command processor thread] INFO upgrade.AbstractLayoutVersionManager: Layout feature DATANODE_SCHEMA_V3 has been finalized.
dn4_1    | 2022-07-31 01:19:33,655 [Command processor thread] INFO upgrade.AbstractLayoutVersionManager: Finalization is complete.
dn4_1    | 2022-07-31 01:19:33,656 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization is done.
dn4_1    | 2022-07-31 01:19:33,664 [Command processor thread] INFO server.RaftServer: 310a080d-f635-46ff-a53d-49cc9a09fa5c: remove    LEADER 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF:t4, leader=310a080d-f635-46ff-a53d-49cc9a09fa5c, voted=310a080d-f635-46ff-a53d-49cc9a09fa5c, raftlog=310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-SegmentedRaftLog:OPENED:c6, conf=5: [310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1], old=null RUNNING
dn4_1    | 2022-07-31 01:19:33,674 [Command processor thread] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF: shutdown
dn4_1    | 2022-07-31 01:19:33,675 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B3503D3184BF,id=310a080d-f635-46ff-a53d-49cc9a09fa5c
dn4_1    | 2022-07-31 01:19:33,676 [Command processor thread] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: shutdown 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-LeaderStateImpl
dn4_1    | 2022-07-31 01:19:33,680 [Command processor thread] INFO impl.PendingRequests: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-PendingRequests: sendNotLeaderResponses
dn4_1    | 2022-07-31 01:19:33,686 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-B3503D3184BF: Taking a snapshot at:(t:4, i:6) file /data/metadata/ratis/c06adbe4-99b1-4236-a662-b3503d3184bf/sm/snapshot.4_6
dn4_1    | 2022-07-31 01:19:33,691 [Command processor thread] INFO impl.StateMachineUpdater: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-StateMachineUpdater: set stopIndex = 6
dn4_1    | 2022-07-31 01:19:33,692 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-B3503D3184BF: Finished taking a snapshot at:(t:4, i:6) file:/data/metadata/ratis/c06adbe4-99b1-4236-a662-b3503d3184bf/sm/snapshot.4_6 took: 6 ms
dn4_1    | 2022-07-31 01:19:33,693 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-StateMachineUpdater] INFO impl.StateMachineUpdater: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-StateMachineUpdater: Took a snapshot at index 6
dn4_1    | 2022-07-31 01:19:33,697 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-StateMachineUpdater] INFO impl.StateMachineUpdater: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-StateMachineUpdater: snapshotIndex: updateIncreasingly 4 -> 6
dn4_1    | 2022-07-31 01:19:33,704 [Command processor thread] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF: closes. applyIndex: 6
dn4_1    | 2022-07-31 01:19:33,704 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
dn4_1    | 2022-07-31 01:19:33,712 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF-SegmentedRaftLogWorker close()
dn4_1    | 2022-07-31 01:19:33,716 [Command processor thread] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-B3503D3184BF: Succeed to remove RaftStorageDirectory Storage Directory /data/metadata/ratis/c06adbe4-99b1-4236-a662-b3503d3184bf
dn4_1    | 2022-07-31 01:19:33,717 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline PipelineID=c06adbe4-99b1-4236-a662-b3503d3184bf command on datanode 310a080d-f635-46ff-a53d-49cc9a09fa5c.
dn4_1    | 2022-07-31 01:19:33,717 [Command processor thread] INFO server.RaftServer: 310a080d-f635-46ff-a53d-49cc9a09fa5c: remove  FOLLOWER 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610:t14, leader=52aca038-7576-46a0-9ccd-b8aed29078e2, voted=52aca038-7576-46a0-9ccd-b8aed29078e2, raftlog=310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-SegmentedRaftLog:OPENED:c16, conf=13: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null RUNNING
dn4_1    | 2022-07-31 01:19:33,717 [Command processor thread] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610: shutdown
dn4_1    | 2022-07-31 01:19:33,718 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-7BB2A1276610,id=310a080d-f635-46ff-a53d-49cc9a09fa5c
dn4_1    | 2022-07-31 01:19:33,718 [Command processor thread] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: shutdown 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-FollowerState
dn4_1    | 2022-07-31 01:19:33,718 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-FollowerState] INFO impl.FollowerState: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-FollowerState was interrupted
dn4_1    | 2022-07-31 01:19:33,718 [Command processor thread] INFO impl.StateMachineUpdater: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-StateMachineUpdater: set stopIndex = 16
dn4_1    | 2022-07-31 01:19:33,719 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-7BB2A1276610: Taking a snapshot at:(t:14, i:16) file /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/sm/snapshot.14_16
dn4_1    | 2022-07-31 01:19:33,728 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-7BB2A1276610: Finished taking a snapshot at:(t:14, i:16) file:/data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/sm/snapshot.14_16 took: 9 ms
dn4_1    | 2022-07-31 01:19:33,729 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-StateMachineUpdater] INFO impl.StateMachineUpdater: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-StateMachineUpdater: Took a snapshot at index 16
dn4_1    | 2022-07-31 01:19:33,729 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-StateMachineUpdater] INFO impl.StateMachineUpdater: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-StateMachineUpdater: snapshotIndex: updateIncreasingly 12 -> 16
dn4_1    | 2022-07-31 01:19:33,730 [Command processor thread] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610: closes. applyIndex: 16
dn4_1    | 2022-07-31 01:19:33,733 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-07-31 01:19:02,672 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | 2022-07-31 01:19:02,673 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn5_1    | 2022-07-31 01:19:02,673 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn5_1    | 2022-07-31 01:19:02,673 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 2003 to close, current state is: CLOSING
dn5_1    | 2022-07-31 01:19:02,673 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn5_1    | 2022-07-31 01:19:02,673 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-07-31 01:19:02,673 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-07-31 01:19:02,673 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | 2022-07-31 01:19:02,673 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn5_1    | 2022-07-31 01:19:02,673 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn5_1    | 2022-07-31 01:19:02,673 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 2003 to close, current state is: CLOSING
dn5_1    | 2022-07-31 01:19:02,673 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn5_1    | 2022-07-31 01:19:02,673 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-07-31 01:19:02,673 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
om3_1    | 2022-07-31 01:21:45,658 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: new2-bucket of layout LEGACY in volume: s3v
om3_1    | 2022-07-31 01:21:53,930 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:new2-bucket in volume:s3v
om3_1    | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1    | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om3_1    | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:300)
om3_1    | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1    | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1    | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1    | 2022-07-31 01:22:14,961 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:ectest-new for user:hadoop
om3_1    | 2022-07-31 01:22:17,925 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ectest of layout LEGACY in volume: ectest-new
om3_1    | 2022-07-31 01:22:24,177 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: testpropchange of layout LEGACY in volume: ectest-new
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1  | 2022-07-31 01:18:13,574 [IPC Server handler 5 on default port 9891] INFO ipc.Server: IPC Server handler 5 on default port 9891 caught an exception
recon_1  | java.nio.channels.ClosedChannelException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3605)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:141)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1667)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1737)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2837)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1809)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1117)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:909)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:895)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1052)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1  | 2022-07-31 01:18:13,575 [IPC Server handler 4 on default port 9891] INFO ipc.Server: IPC Server handler 4 on default port 9891 caught an exception
recon_1  | java.nio.channels.ClosedChannelException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3605)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:141)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1667)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1737)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2837)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1809)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1117)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:909)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:895)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1052)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1  | 2022-07-31 01:18:13,575 [IPC Server handler 6 on default port 9891] INFO ipc.Server: IPC Server handler 6 on default port 9891 caught an exception
recon_1  | java.nio.channels.ClosedChannelException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3605)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:141)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1667)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1737)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2837)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1809)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1117)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:909)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:895)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1052)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1  | 2022-07-31 01:18:13,575 [IPC Server handler 0 on default port 9891] INFO ipc.Server: IPC Server handler 0 on default port 9891 caught an exception
recon_1  | java.nio.channels.ClosedChannelException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3605)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:141)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1667)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1737)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2837)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1809)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1117)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:909)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:895)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1052)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1  | 2022-07-31 01:18:14,125 [IPC Server handler 11 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ha_dn5_1.ha_net
recon_1  | 2022-07-31 01:18:14,478 [IPC Server handler 2 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ha_dn3_1.ha_net
recon_1  | 2022-07-31 01:18:15,647 [IPC Server handler 13 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ha_dn4_1.ha_net
recon_1  | 2022-07-31 01:18:15,858 [IPC Server handler 11 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ha_dn1_1.ha_net
recon_1  | 2022-07-31 01:18:15,992 [IPC Server handler 14 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ha_dn2_1.ha_net
recon_1  | 2022-07-31 01:18:16,165 [IPC Server handler 15 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:18:16,168 [IPC Server handler 15 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ha_dn3_1.ha_net
recon_1  | 2022-07-31 01:18:16,370 [IPC Server handler 2 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:18:16,370 [IPC Server handler 2 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ha_dn5_1.ha_net
recon_1  | 2022-07-31 01:18:30,310 [IPC Server handler 99 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ha_dn3_1.ha_net
recon_1  | 2022-07-31 01:18:30,654 [IPC Server handler 13 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ha_dn5_1.ha_net
recon_1  | 2022-07-31 01:18:30,717 [IPC Server handler 11 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:18:30,717 [IPC Server handler 11 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ha_dn1_1.ha_net
recon_1  | 2022-07-31 01:18:45,603 [IPC Server handler 13 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:18:45,603 [IPC Server handler 13 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ha_dn4_1.ha_net
recon_1  | 2022-07-31 01:18:45,962 [IPC Server handler 14 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:18:45,962 [IPC Server handler 14 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ha_dn2_1.ha_net
recon_1  | 2022-07-31 01:18:46,623 [IPC Server handler 11 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ha_dn4_1.ha_net
recon_1  | 2022-07-31 01:18:46,625 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: Container #2001 has state OPEN, but given state is CLOSING.
recon_1  | 2022-07-31 01:18:46,962 [IPC Server handler 14 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ha_dn2_1.ha_net
recon_1  | 2022-07-31 01:18:46,964 [FixedThreadPoolWithAffinityExecutor-9-0] INFO scm.ReconContainerManager: Container #1001 has state OPEN, but given state is CLOSING.
recon_1  | 2022-07-31 01:18:47,007 [IPC Server handler 12 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:18:47,009 [FixedThreadPoolWithAffinityExecutor-8-0] INFO scm.ReconContainerManager: Container #2002 has state OPEN, but given state is CLOSING.
recon_1  | 2022-07-31 01:18:47,034 [IPC Server handler 20 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:18:47,034 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: Container #1 has state OPEN, but given state is CLOSING.
recon_1  | 2022-07-31 01:18:47,041 [IPC Server handler 17 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:18:47,041 [FixedThreadPoolWithAffinityExecutor-9-0] INFO scm.ReconContainerManager: Container #1002 has state OPEN, but given state is CLOSING.
recon_1  | 2022-07-31 01:18:47,054 [IPC Server handler 19 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:18:47,054 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: Container #2003 has state OPEN, but given state is CLOSING.
recon_1  | 2022-07-31 01:19:00,216 [IPC Server handler 33 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:00,543 [IPC Server handler 15 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ha_dn1_1.ha_net
recon_1  | 2022-07-31 01:19:00,580 [IPC Server handler 10 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:01,230 [IPC Server handler 40 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:01,478 [IPC Server handler 15 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:01,508 [IPC Server handler 2 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:01,509 [FixedThreadPoolWithAffinityExecutor-0-0] INFO container.IncrementalContainerReportHandler: Moving container #1001 to CLOSED state, datanode 3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
recon_1  | 2022-07-31 01:19:01,558 [IPC Server handler 10 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:01,629 [IPC Server handler 11 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:01,644 [IPC Server handler 14 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:01,702 [IPC Server handler 12 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:01,716 [IPC Server handler 20 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:01,788 [IPC Server handler 17 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
dn2_1    | 2022-07-31 01:20:34,037 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2022-07-31 01:20:34,038 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn2_1    | 2022-07-31 01:20:34,039 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn2_1    | 2022-07-31 01:20:34,039 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn2_1    | 2022-07-31 01:20:34,039 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn2_1    | 2022-07-31 01:20:34,039 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn2_1    | 2022-07-31 01:20:34,040 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn2_1    | 2022-07-31 01:20:34,041 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn2_1    | 2022-07-31 01:20:34,041 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn2_1    | 2022-07-31 01:20:34,042 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn2_1    | 2022-07-31 01:20:34,044 [pool-42-thread-1] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn2_1    | 2022-07-31 01:20:34,055 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn2_1    | 2022-07-31 01:20:34,055 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn2_1    | 2022-07-31 01:20:34,055 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn2_1    | 2022-07-31 01:20:34,055 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn2_1    | 2022-07-31 01:20:34,056 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn2_1    | 2022-07-31 01:20:34,056 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn2_1    | 2022-07-31 01:20:34,057 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn2_1    | 2022-07-31 01:20:34,057 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn2_1    | 2022-07-31 01:20:34,057 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn2_1    | 2022-07-31 01:20:34,057 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn2_1    | 2022-07-31 01:20:34,059 [pool-42-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn2_1    | 2022-07-31 01:20:34,059 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC: start as a follower, conf=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-07-31 01:20:34,059 [pool-42-thread-1] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn2_1    | 2022-07-31 01:20:34,065 [pool-42-thread-1] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: start 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-FollowerState
dn2_1    | 2022-07-31 01:20:34,087 [pool-42-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4B35CFA778DC,id=11cba143-91f8-47cb-8422-c32a1e2d51df
dn2_1    | 2022-07-31 01:20:39,086 [grpc-default-executor-0] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC: receive requestVote(ELECTION, 52aca038-7576-46a0-9ccd-b8aed29078e2, group-4B35CFA778DC, 1, (t:0, i:0))
dn2_1    | 2022-07-31 01:20:39,086 [grpc-default-executor-0] INFO impl.VoteContext: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-FOLLOWER: reject ELECTION from 52aca038-7576-46a0-9ccd-b8aed29078e2: our priority 1 > candidate's priority 0
dn2_1    | 2022-07-31 01:20:39,086 [grpc-default-executor-0] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:52aca038-7576-46a0-9ccd-b8aed29078e2
dn2_1    | 2022-07-31 01:20:39,087 [grpc-default-executor-0] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: shutdown 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-FollowerState
dn2_1    | 2022-07-31 01:20:39,087 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-FollowerState] INFO impl.FollowerState: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-FollowerState was interrupted
dn2_1    | 2022-07-31 01:20:39,087 [grpc-default-executor-0] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: start 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-FollowerState
dn2_1    | 2022-07-31 01:20:39,090 [grpc-default-executor-0] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC replies to ELECTION vote request: 52aca038-7576-46a0-9ccd-b8aed29078e2<-11cba143-91f8-47cb-8422-c32a1e2d51df#0:FAIL-t1. Peer's state: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC:t1, leader=null, voted=null, raftlog=11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-SegmentedRaftLog:OPENED:c-1, conf=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-07-31 01:20:44,159 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-FollowerState] INFO impl.FollowerState: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5071677624ns, electionTimeout:5069ms
dn2_1    | 2022-07-31 01:20:44,159 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-FollowerState] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: shutdown 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-FollowerState
dn2_1    | 2022-07-31 01:20:44,159 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-FollowerState] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
dn2_1    | 2022-07-31 01:20:44,160 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn2_1    | 2022-07-31 01:20:44,160 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-FollowerState] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: start 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7
om1_1    | 2022-07-31 01:18:22,382 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om1_1    | 2022-07-31 01:18:22,385 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om1_1    | 2022-07-31 01:18:22,634 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1    | 2022-07-31 01:18:22,641 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om1_1    | 2022-07-31 01:18:22,645 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om1_1    | 2022-07-31 01:18:22,653 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om1_1    | 2022-07-31 01:18:22,654 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om1_1    | 2022-07-31 01:18:22,678 [main] INFO reflections.Reflections: Reflections took 2743 ms to scan 8 urls, producing 23 keys and 513 values [using 2 cores]
dn3_1    | 2022-07-31 01:20:34,607 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO impl.LeaderElection:   Response 0: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c<-609e7f2d-9474-472f-937f-8fa0a0bbb327#0:OK-t6
dn3_1    | 2022-07-31 01:20:34,607 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO impl.LeaderElection: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5 ELECTION round 0: result PASSED
dn3_1    | 2022-07-31 01:20:34,607 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: shutdown 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5
dn3_1    | 2022-07-31 01:20:34,609 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0: changes role from CANDIDATE to LEADER at term 6 for changeToLeader
dn3_1    | 2022-07-31 01:20:34,609 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-84A70A95B4C0 with new leaderId: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c
dn3_1    | 2022-07-31 01:20:34,610 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0: change Leader from null to 3fc9f139-dd93-41e7-b235-52ce94d6fe3c at term 6 for becomeLeader, leader elected after 30381ms
dn3_1    | 2022-07-31 01:20:34,610 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn3_1    | 2022-07-31 01:20:34,621 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn3_1    | 2022-07-31 01:20:34,622 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn3_1    | 2022-07-31 01:20:34,623 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn3_1    | 2022-07-31 01:20:34,623 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn3_1    | 2022-07-31 01:20:34,623 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn3_1    | 2022-07-31 01:20:34,623 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn3_1    | 2022-07-31 01:20:34,624 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn3_1    | 2022-07-31 01:20:34,625 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn3_1    | 2022-07-31 01:20:34,625 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2022-07-31 01:20:34,625 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
dn3_1    | 2022-07-31 01:20:34,625 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn3_1    | 2022-07-31 01:20:34,640 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn3_1    | 2022-07-31 01:20:34,640 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn3_1    | 2022-07-31 01:20:34,641 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn3_1    | 2022-07-31 01:20:34,641 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2022-07-31 01:20:34,641 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
dn3_1    | 2022-07-31 01:20:34,642 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn3_1    | 2022-07-31 01:20:34,642 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn3_1    | 2022-07-31 01:20:34,642 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn3_1    | 2022-07-31 01:20:34,643 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderStateImpl
dn3_1    | 2022-07-31 01:20:34,643 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-SegmentedRaftLogWorker: Starting segment from index:0
dn3_1    | 2022-07-31 01:20:34,646 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0/current/log_inprogress_0
dn3_1    | 2022-07-31 01:20:34,680 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0-LeaderElection5] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-84A70A95B4C0: set configuration 0: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn3_1    | 2022-07-31 01:20:38,490 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-FollowerState] INFO impl.FollowerState: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5121975724ns, electionTimeout:5088ms
dn3_1    | 2022-07-31 01:20:38,491 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-FollowerState] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: shutdown 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-FollowerState
dn3_1    | 2022-07-31 01:20:38,491 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-FollowerState] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
dn3_1    | 2022-07-31 01:20:38,491 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn3_1    | 2022-07-31 01:20:38,491 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-FollowerState] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-LeaderElection6
dn3_1    | 2022-07-31 01:20:38,499 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-LeaderElection6] INFO impl.LeaderElection: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-LeaderElection6 ELECTION round 0: submit vote requests at term 1 for -1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:1], old=null
dn3_1    | 2022-07-31 01:20:38,499 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-LeaderElection6] INFO impl.LeaderElection: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-LeaderElection6 ELECTION round 0: result PASSED (term=1)
dn3_1    | 2022-07-31 01:20:38,499 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-LeaderElection6] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: shutdown 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-LeaderElection6
dn3_1    | 2022-07-31 01:20:38,500 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-LeaderElection6] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
dn3_1    | 2022-07-31 01:20:38,500 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-LeaderElection6] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-5058278E2312 with new leaderId: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c
dn3_1    | 2022-07-31 01:20:38,500 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-LeaderElection6] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312: change Leader from null to 3fc9f139-dd93-41e7-b235-52ce94d6fe3c at term 1 for becomeLeader, leader elected after 5149ms
dn3_1    | 2022-07-31 01:20:38,500 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn3_1    | 2022-07-31 01:20:38,500 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn3_1    | 2022-07-31 01:20:38,500 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn3_1    | 2022-07-31 01:20:38,501 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn3_1    | 2022-07-31 01:20:38,501 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn3_1    | 2022-07-31 01:20:38,501 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn3_1    | 2022-07-31 01:20:38,501 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn3_1    | 2022-07-31 01:20:38,501 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn3_1    | 2022-07-31 01:20:38,501 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-LeaderElection6] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-LeaderStateImpl
dn3_1    | 2022-07-31 01:20:38,501 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-LeaderElection6] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-SegmentedRaftLogWorker: Starting segment from index:0
dn3_1    | 2022-07-31 01:20:38,503 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/e372288d-28a7-4132-a525-5058278e2312/current/log_inprogress_0
dn3_1    | 2022-07-31 01:20:38,522 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312-LeaderElection6] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-5058278E2312: set configuration 0: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1], old=null
dn3_1    | 2022-07-31 01:20:39,074 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC: receive requestVote(ELECTION, 52aca038-7576-46a0-9ccd-b8aed29078e2, group-4B35CFA778DC, 1, (t:0, i:0))
dn3_1    | 2022-07-31 01:20:39,074 [grpc-default-executor-0] INFO impl.VoteContext: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC-FOLLOWER: accept ELECTION from 52aca038-7576-46a0-9ccd-b8aed29078e2: our priority 0 <= candidate's priority 0
dn3_1    | 2022-07-31 01:20:39,075 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:52aca038-7576-46a0-9ccd-b8aed29078e2
dn3_1    | 2022-07-31 01:20:39,075 [grpc-default-executor-0] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: shutdown 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC-FollowerState
dn3_1    | 2022-07-31 01:20:39,075 [grpc-default-executor-0] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC-FollowerState
dn3_1    | 2022-07-31 01:20:39,081 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC-FollowerState] INFO impl.FollowerState: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC-FollowerState was interrupted
dn3_1    | 2022-07-31 01:20:39,092 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC replies to ELECTION vote request: 52aca038-7576-46a0-9ccd-b8aed29078e2<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:OK-t1. Peer's state: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC:t1, leader=null, voted=52aca038-7576-46a0-9ccd-b8aed29078e2, raftlog=3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC-SegmentedRaftLog:OPENED:c-1, conf=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn3_1    | 2022-07-31 01:20:44,176 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC: receive requestVote(ELECTION, 11cba143-91f8-47cb-8422-c32a1e2d51df, group-4B35CFA778DC, 2, (t:0, i:0))
dn3_1    | 2022-07-31 01:20:44,176 [grpc-default-executor-0] INFO impl.VoteContext: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC-FOLLOWER: accept ELECTION from 11cba143-91f8-47cb-8422-c32a1e2d51df: our priority 0 <= candidate's priority 1
dn3_1    | 2022-07-31 01:20:44,176 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:11cba143-91f8-47cb-8422-c32a1e2d51df
dn3_1    | 2022-07-31 01:20:44,176 [grpc-default-executor-0] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: shutdown 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC-FollowerState
dn3_1    | 2022-07-31 01:20:44,176 [grpc-default-executor-0] INFO impl.RoleInfo: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: start 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC-FollowerState
dn3_1    | 2022-07-31 01:20:44,177 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC-FollowerState] INFO impl.FollowerState: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC-FollowerState was interrupted
dn2_1    | 2022-07-31 01:20:44,172 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO impl.LeaderElection: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7 ELECTION round 0: submit vote requests at term 2 for -1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-07-31 01:20:44,184 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO impl.LeaderElection: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7: ELECTION PASSED received 1 response(s) and 0 exception(s):
dn2_1    | 2022-07-31 01:20:44,185 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO impl.LeaderElection:   Response 0: 11cba143-91f8-47cb-8422-c32a1e2d51df<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:OK-t2
dn2_1    | 2022-07-31 01:20:44,185 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO impl.LeaderElection: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7 ELECTION round 0: result PASSED
dn2_1    | 2022-07-31 01:20:44,185 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: shutdown 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7
dn2_1    | 2022-07-31 01:20:44,185 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
dn2_1    | 2022-07-31 01:20:44,185 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-4B35CFA778DC with new leaderId: 11cba143-91f8-47cb-8422-c32a1e2d51df
dn2_1    | 2022-07-31 01:20:44,185 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC: change Leader from null to 11cba143-91f8-47cb-8422-c32a1e2d51df at term 2 for becomeLeader, leader elected after 10150ms
dn2_1    | 2022-07-31 01:20:44,188 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn2_1    | 2022-07-31 01:20:44,188 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn2_1    | 2022-07-31 01:20:44,188 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn2_1    | 2022-07-31 01:20:44,188 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn2_1    | 2022-07-31 01:20:44,188 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn2_1    | 2022-07-31 01:20:44,188 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn2_1    | 2022-07-31 01:20:44,188 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn2_1    | 2022-07-31 01:20:44,188 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn2_1    | 2022-07-31 01:20:44,229 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn2_1    | 2022-07-31 01:20:44,230 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2022-07-31 01:20:44,231 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
dn2_1    | 2022-07-31 01:20:44,239 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn2_1    | 2022-07-31 01:20:44,239 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn2_1    | 2022-07-31 01:20:44,239 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn2_1    | 2022-07-31 01:20:44,246 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn2_1    | 2022-07-31 01:20:44,246 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2022-07-31 01:20:44,246 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
dn2_1    | 2022-07-31 01:20:44,246 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn2_1    | 2022-07-31 01:20:44,247 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn2_1    | 2022-07-31 01:20:44,247 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn2_1    | 2022-07-31 01:20:44,247 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO impl.RoleInfo: 11cba143-91f8-47cb-8422-c32a1e2d51df: start 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderStateImpl
dn2_1    | 2022-07-31 01:20:44,248 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-SegmentedRaftLogWorker: Starting segment from index:0
dn2_1    | 2022-07-31 01:20:44,261 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-LeaderElection7] INFO server.RaftServer$Division: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC: set configuration 0: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn2_1    | 2022-07-31 01:20:44,269 [11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 11cba143-91f8-47cb-8422-c32a1e2d51df@group-4B35CFA778DC-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/e19f4611-626e-4580-84ca-4b35cfa778dc/current/log_inprogress_0
recon_1  | 2022-07-31 01:19:01,790 [FixedThreadPoolWithAffinityExecutor-1-0] INFO container.IncrementalContainerReportHandler: Moving container #2002 to CLOSED state, datanode 3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
recon_1  | 2022-07-31 01:19:01,813 [IPC Server handler 19 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
om1_1    | 2022-07-31 01:18:22,984 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1    | 2022-07-31 01:18:23,019 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om1_1    | 2022-07-31 01:18:23,402 [Listener at om1/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om1_1    | 2022-07-31 01:18:23,451 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om1_1    | 2022-07-31 01:18:23,456 [Listener at om1/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om1_1    | 2022-07-31 01:18:23,560 [Listener at om1/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om1/10.9.0.11:9862
om1_1    | 2022-07-31 01:18:23,563 [Listener at om1/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
om1_1    | 2022-07-31 01:18:23,564 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: start as a follower, conf=63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1    | 2022-07-31 01:18:23,568 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: changes role from      null to FOLLOWER at term 6 for startAsFollower
om1_1    | 2022-07-31 01:18:23,574 [om1-impl-thread1] INFO impl.RoleInfo: om1: start om1@group-D66704EFC61C-FollowerState
om1_1    | 2022-07-31 01:18:23,590 [om1-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D66704EFC61C,id=om1
om1_1    | 2022-07-31 01:18:23,594 [Listener at om1/9862] INFO server.RaftServer: om1: start RPC server
om1_1    | 2022-07-31 01:18:23,745 [Listener at om1/9862] INFO server.GrpcService: om1: GrpcService started, listening on 9872
om1_1    | 2022-07-31 01:18:23,756 [Listener at om1/9862] INFO upgrade.UpgradeFinalizer: Running pre-finalized state validations for unfinalized layout features.
om1_1    | 2022-07-31 01:18:23,758 [Listener at om1/9862] INFO upgrade.UpgradeFinalizer: Running first upgrade commands for unfinalized layout features.
om1_1    | 2022-07-31 01:18:23,762 [Listener at om1/9862] INFO om.OzoneManager: Version File has different layout version (0) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om1_1    | 2022-07-31 01:18:23,776 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$428/0x000000084055fc40@743c3520] INFO util.JvmPauseMonitor: JvmPauseMonitor-om1: Started
om1_1    | 2022-07-31 01:18:24,012 [Listener at om1/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om1_1    | 2022-07-31 01:18:24,013 [Listener at om1/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om1_1    | 2022-07-31 01:18:24,110 [Listener at om1/9862] INFO util.log: Logging initialized @69133ms to org.eclipse.jetty.util.log.Slf4jLog
om1_1    | 2022-07-31 01:18:24,524 [Listener at om1/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om1_1    | 2022-07-31 01:18:24,542 [Listener at om1/9862] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
om1_1    | 2022-07-31 01:18:24,574 [Listener at om1/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om1_1    | 2022-07-31 01:18:24,583 [Listener at om1/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om1_1    | 2022-07-31 01:18:24,583 [Listener at om1/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om1_1    | 2022-07-31 01:18:24,589 [Listener at om1/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om1_1    | 2022-07-31 01:18:24,869 [Listener at om1/9862] INFO http.HttpServer2: Jetty bound to port 9874
om1_1    | 2022-07-31 01:18:24,873 [Listener at om1/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om1_1    | 2022-07-31 01:18:25,028 [Listener at om1/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om1_1    | 2022-07-31 01:18:25,028 [Listener at om1/9862] INFO server.session: No SessionScavenger set, using defaults
om1_1    | 2022-07-31 01:18:25,040 [Listener at om1/9862] INFO server.session: node0 Scavenging every 600000ms
om1_1    | 2022-07-31 01:18:25,116 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@402b4f81{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om1_1    | 2022-07-31 01:18:25,133 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c4b5ceb{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om1_1    | 2022-07-31 01:18:25,667 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5a85b4e6{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-16804396159242700667/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om1_1    | 2022-07-31 01:18:25,706 [Listener at om1/9862] INFO server.AbstractConnector: Started ServerConnector@6826b70f{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om1_1    | 2022-07-31 01:18:25,713 [Listener at om1/9862] INFO server.Server: Started @70730ms
om1_1    | 2022-07-31 01:18:25,727 [Listener at om1/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om1_1    | 2022-07-31 01:18:25,727 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om1_1    | 2022-07-31 01:18:25,729 [Listener at om1/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om1_1    | 2022-07-31 01:18:25,731 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om1_1    | 2022-07-31 01:18:25,807 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om1_1    | 2022-07-31 01:18:25,968 [Listener at om1/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted won't move to trash
om1_1    | 2022-07-31 01:18:25,991 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4c063cb9] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om1_1    | 2022-07-31 01:18:28,614 [om1@group-D66704EFC61C-FollowerState] INFO impl.FollowerState: om1@group-D66704EFC61C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5040153814ns, electionTimeout:5002ms
om1_1    | 2022-07-31 01:18:28,615 [om1@group-D66704EFC61C-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-D66704EFC61C-FollowerState
om1_1    | 2022-07-31 01:18:28,615 [om1@group-D66704EFC61C-FollowerState] INFO server.RaftServer$Division: om1@group-D66704EFC61C: changes role from  FOLLOWER to CANDIDATE at term 6 for changeToCandidate
om1_1    | 2022-07-31 01:18:28,618 [om1@group-D66704EFC61C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om1_1    | 2022-07-31 01:18:28,619 [om1@group-D66704EFC61C-FollowerState] INFO impl.RoleInfo: om1: start om1@group-D66704EFC61C-LeaderElection1
om1_1    | 2022-07-31 01:18:28,649 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om1@group-D66704EFC61C-LeaderElection1 ELECTION round 0: submit vote requests at term 7 for 63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-07-31 01:19:02,673 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | 2022-07-31 01:19:02,673 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn5_1    | 2022-07-31 01:19:02,673 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn5_1    | 2022-07-31 01:19:02,673 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 2003 to close, current state is: CLOSING
dn5_1    | 2022-07-31 01:19:02,674 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn5_1    | 2022-07-31 01:19:02,674 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-07-31 01:19:02,675 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-07-31 01:19:02,676 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | 2022-07-31 01:19:02,676 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn5_1    | 2022-07-31 01:19:02,676 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn5_1    | 2022-07-31 01:19:02,676 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 2003 to close, current state is: CLOSING
dn5_1    | 2022-07-31 01:19:02,676 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn5_1    | 2022-07-31 01:19:02,676 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-07-31 01:19:02,677 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-07-31 01:19:02,678 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
om1_1    | 2022-07-31 01:18:30,580 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: receive requestVote(ELECTION, om3, group-D66704EFC61C, 7, (t:6, i:98))
om1_1    | 2022-07-31 01:18:30,592 [grpc-default-executor-1] INFO impl.VoteContext: om1@group-D66704EFC61C-CANDIDATE: reject ELECTION from om3: already has voted for om1 at current term 7
om1_1    | 2022-07-31 01:18:30,633 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-D66704EFC61C replies to ELECTION vote request: om3<-om1#0:FAIL-t7. Peer's state: om1@group-D66704EFC61C:t7, leader=null, voted=om1, raftlog=om1@group-D66704EFC61C-SegmentedRaftLog:OPENED:c98, conf=63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1    | 2022-07-31 01:18:30,758 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: receive requestVote(ELECTION, om2, group-D66704EFC61C, 7, (t:6, i:98))
om1_1    | 2022-07-31 01:18:30,758 [grpc-default-executor-1] INFO impl.VoteContext: om1@group-D66704EFC61C-CANDIDATE: reject ELECTION from om2: already has voted for om1 at current term 7
om1_1    | 2022-07-31 01:18:30,759 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-D66704EFC61C replies to ELECTION vote request: om2<-om1#0:FAIL-t7. Peer's state: om1@group-D66704EFC61C:t7, leader=null, voted=om1, raftlog=om1@group-D66704EFC61C-SegmentedRaftLog:OPENED:c98, conf=63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1    | 2022-07-31 01:18:31,035 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om1@group-D66704EFC61C-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om1_1    | 2022-07-31 01:18:31,035 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection:   Response 0: om1<-om3#0:FAIL-t7
om1_1    | 2022-07-31 01:18:31,035 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection:   Response 1: om1<-om2#0:FAIL-t7
om1_1    | 2022-07-31 01:18:31,036 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.LeaderElection: om1@group-D66704EFC61C-LeaderElection1 ELECTION round 0: result REJECTED
om1_1    | 2022-07-31 01:18:31,037 [om1@group-D66704EFC61C-LeaderElection1] INFO server.RaftServer$Division: om1@group-D66704EFC61C: changes role from CANDIDATE to FOLLOWER at term 7 for REJECTED
om1_1    | 2022-07-31 01:18:31,037 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.RoleInfo: om1: shutdown om1@group-D66704EFC61C-LeaderElection1
om1_1    | 2022-07-31 01:18:31,038 [om1@group-D66704EFC61C-LeaderElection1] INFO impl.RoleInfo: om1: start om1@group-D66704EFC61C-FollowerState
om1_1    | 2022-07-31 01:18:36,042 [om1@group-D66704EFC61C-FollowerState] INFO impl.FollowerState: om1@group-D66704EFC61C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5004543057ns, electionTimeout:5004ms
om1_1    | 2022-07-31 01:18:36,043 [om1@group-D66704EFC61C-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-D66704EFC61C-FollowerState
om1_1    | 2022-07-31 01:18:36,043 [om1@group-D66704EFC61C-FollowerState] INFO server.RaftServer$Division: om1@group-D66704EFC61C: changes role from  FOLLOWER to CANDIDATE at term 7 for changeToCandidate
om1_1    | 2022-07-31 01:18:36,043 [om1@group-D66704EFC61C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om1_1    | 2022-07-31 01:18:36,043 [om1@group-D66704EFC61C-FollowerState] INFO impl.RoleInfo: om1: start om1@group-D66704EFC61C-LeaderElection2
om1_1    | 2022-07-31 01:18:36,046 [om1@group-D66704EFC61C-LeaderElection2] INFO impl.LeaderElection: om1@group-D66704EFC61C-LeaderElection2 ELECTION round 0: submit vote requests at term 8 for 63: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1    | 2022-07-31 01:18:36,074 [om1@group-D66704EFC61C-LeaderElection2] INFO impl.LeaderElection: om1@group-D66704EFC61C-LeaderElection2: ELECTION PASSED received 1 response(s) and 0 exception(s):
om1_1    | 2022-07-31 01:18:36,074 [om1@group-D66704EFC61C-LeaderElection2] INFO impl.LeaderElection:   Response 0: om1<-om3#0:OK-t8
om1_1    | 2022-07-31 01:18:36,078 [om1@group-D66704EFC61C-LeaderElection2] INFO impl.LeaderElection: om1@group-D66704EFC61C-LeaderElection2 ELECTION round 0: result PASSED
om1_1    | 2022-07-31 01:18:36,082 [om1@group-D66704EFC61C-LeaderElection2] INFO impl.RoleInfo: om1: shutdown om1@group-D66704EFC61C-LeaderElection2
om1_1    | 2022-07-31 01:18:36,082 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServer$Division: om1@group-D66704EFC61C: changes role from CANDIDATE to LEADER at term 8 for changeToLeader
om1_1    | 2022-07-31 01:18:36,083 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServer$Division: om1@group-D66704EFC61C: change Leader from null to om1 at term 8 for becomeLeader, leader elected after 15238ms
om1_1    | 2022-07-31 01:18:36,091 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om1_1    | 2022-07-31 01:18:36,096 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om1_1    | 2022-07-31 01:18:36,099 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
om1_1    | 2022-07-31 01:18:36,105 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om1_1    | 2022-07-31 01:18:36,105 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om1_1    | 2022-07-31 01:18:36,106 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om1_1    | 2022-07-31 01:18:36,111 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om1_1    | 2022-07-31 01:18:36,113 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
om1_1    | 2022-07-31 01:18:36,130 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om1_1    | 2022-07-31 01:18:36,131 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1    | 2022-07-31 01:18:36,131 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om1_1    | 2022-07-31 01:18:36,134 [om1@group-D66704EFC61C-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om1_1    | 2022-07-31 01:18:36,134 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1    | 2022-07-31 01:18:36,134 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1    | 2022-07-31 01:18:36,136 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om1_1    | 2022-07-31 01:18:36,136 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1    | 2022-07-31 01:18:36,137 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
dn3_1    | 2022-07-31 01:20:44,182 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC replies to ELECTION vote request: 11cba143-91f8-47cb-8422-c32a1e2d51df<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:OK-t2. Peer's state: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC:t2, leader=null, voted=11cba143-91f8-47cb-8422-c32a1e2d51df, raftlog=3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC-SegmentedRaftLog:OPENED:c-1, conf=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn3_1    | 2022-07-31 01:20:44,307 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-4B35CFA778DC with new leaderId: 11cba143-91f8-47cb-8422-c32a1e2d51df
dn3_1    | 2022-07-31 01:20:44,307 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c-server-thread1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC: change Leader from null to 11cba143-91f8-47cb-8422-c32a1e2d51df at term 2 for appendEntries, leader elected after 10109ms
dn3_1    | 2022-07-31 01:20:44,323 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c-server-thread1] INFO server.RaftServer$Division: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC: set configuration 0: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn3_1    | 2022-07-31 01:20:44,334 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c-server-thread1] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC-SegmentedRaftLogWorker: Starting segment from index:0
dn3_1    | 2022-07-31 01:20:44,350 [3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c@group-4B35CFA778DC-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/e19f4611-626e-4580-84ca-4b35cfa778dc/current/log_inprogress_0
dn5_1    | 2022-07-31 01:19:02,678 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn5_1    | 2022-07-31 01:19:02,678 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn5_1    | 2022-07-31 01:19:02,678 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 2003 to close, current state is: CLOSING
dn5_1    | 2022-07-31 01:19:02,678 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn5_1    | 2022-07-31 01:19:02,678 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-07-31 01:19:02,678 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-07-31 01:19:02,679 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | 2022-07-31 01:19:02,679 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn5_1    | 2022-07-31 01:19:02,679 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn5_1    | 2022-07-31 01:19:02,679 [Command processor thread] WARN upgrade.UpgradeFinalizer: FinalizeUpgrade : Waiting for container 2003 to close, current state is: CLOSING
dn5_1    | 2022-07-31 01:19:02,679 [Command processor thread] INFO upgrade.UpgradeFinalizer: Pre Finalization checks failed on the DataNode.
dn5_1    | 2022-07-31 01:19:02,679 [Command processor thread] WARN upgrade.DefaultUpgradeFinalizationExecutor: Upgrade Finalization failed with following Exception. 
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-07-31 01:19:02,679 [Command processor thread] ERROR commandhandler.FinalizeNewLayoutVersionCommandHandler: Exception during finalization.
dn5_1    | PREFINALIZE_VALIDATION_FAILED org.apache.hadoop.ozone.upgrade.UpgradeException: Pre Finalization checks failed on the DataNode.
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:57)
dn5_1    | 	at org.apache.hadoop.ozone.container.upgrade.DataNodeUpgradeFinalizer.preFinalizeUpgrade(DataNodeUpgradeFinalizer.java:41)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:46)
dn5_1    | 	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.finalizeUpgrade(DatanodeStateMachine.java:692)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.FinalizeNewLayoutVersionCommandHandler.handle(FinalizeNewLayoutVersionCommandHandler.java:78)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
dn5_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:621)
dn5_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
dn5_1    | 2022-07-31 01:19:02,690 [ContainerOp-67b1342c-3bb3-4b48-a218-65a101075af1-2] INFO keyvalue.KeyValueContainer: Container 2003 is synced with bcsId 34.
dn5_1    | 2022-07-31 01:19:02,690 [ContainerOp-67b1342c-3bb3-4b48-a218-65a101075af1-2] INFO keyvalue.KeyValueContainer: Container 2003 is synced with bcsId 34.
dn5_1    | 2022-07-31 01:19:02,693 [ContainerOp-67b1342c-3bb3-4b48-a218-65a101075af1-2] INFO keyvalue.KeyValueContainer: Container 2003 is closed with bcsId 34.
dn5_1    | 2022-07-31 01:19:33,611 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: 52aca038-7576-46a0-9ccd-b8aed29078e2: Completed APPEND_ENTRIES, lastRequest: 609e7f2d-9474-472f-937f-8fa0a0bbb327->52aca038-7576-46a0-9ccd-b8aed29078e2#305-t11,previous=(t:11, i:42),leaderCommit=42,initializing? true,entries: size=1, first=(t:11, i:43), METADATAENTRY(c:42)
recon_1  | 2022-07-31 01:19:01,836 [IPC Server handler 3 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:01,846 [IPC Server handler 21 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:01,868 [IPC Server handler 22 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:01,901 [IPC Server handler 24 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:01,964 [IPC Server handler 23 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:02,002 [IPC Server handler 27 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:02,044 [IPC Server handler 16 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:02,044 [FixedThreadPoolWithAffinityExecutor-1-0] INFO container.IncrementalContainerReportHandler: Moving container #1 to CLOSED state, datanode 11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
recon_1  | 2022-07-31 01:19:02,162 [IPC Server handler 18 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:02,183 [IPC Server handler 26 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:02,307 [IPC Server handler 99 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:02,308 [FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Moving container #2001 to CLOSED state, datanode 3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
recon_1  | 2022-07-31 01:19:02,328 [IPC Server handler 15 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:02,328 [FixedThreadPoolWithAffinityExecutor-1-0] INFO container.IncrementalContainerReportHandler: Moving container #1002 to CLOSED state, datanode 11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
recon_1  | 2022-07-31 01:19:02,360 [IPC Server handler 2 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:02,419 [IPC Server handler 10 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:02,475 [IPC Server handler 8 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:02,488 [IPC Server handler 9 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:02,507 [IPC Server handler 1 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:02,508 [FixedThreadPoolWithAffinityExecutor-9-0] INFO container.IncrementalContainerReportHandler: Moving container #2003 to CLOSED state, datanode 11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
recon_1  | 2022-07-31 01:19:02,527 [IPC Server handler 0 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:02,543 [IPC Server handler 4 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:02,623 [IPC Server handler 11 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:02,699 [IPC Server handler 12 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:09,314 [pool-26-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1  | 2022-07-31 01:19:09,316 [pool-26-thread-1] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
recon_1  | 2022-07-31 01:19:09,317 [pool-26-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1  | 2022-07-31 01:19:09,317 [pool-26-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1  | 2022-07-31 01:19:09,317 [pool-26-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1  | 2022-07-31 01:19:09,317 [pool-26-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1  | 2022-07-31 01:19:09,317 [pool-26-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1  | 2022-07-31 01:19:09,317 [pool-26-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1  | 2022-07-31 01:19:09,317 [pool-26-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 100 
recon_1  | 2022-07-31 01:19:09,438 [pool-26-thread-1] WARN impl.OzoneManagerServiceProviderImpl: Unable to get and apply delta updates from OM.
recon_1  | INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Invalid transaction log iterator when getting updates since sequence number 100
dn5_1    | 2022-07-31 01:19:33,617 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | 2022-07-31 01:19:33,617 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Finalize Upgrade called!
dn5_1    | 2022-07-31 01:19:33,617 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization started.
dn5_1    | 2022-07-31 01:19:33,617 [Command processor thread] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: ERASURE_CODED_STORAGE_SUPPORT.
dn5_1    | 2022-07-31 01:19:33,620 [Command processor thread] INFO upgrade.AbstractLayoutVersionManager: Layout feature ERASURE_CODED_STORAGE_SUPPORT has been finalized.
dn5_1    | 2022-07-31 01:19:33,620 [Command processor thread] INFO upgrade.UpgradeFinalizer: Running finalization actions for layout feature: DATANODE_SCHEMA_V3
dn5_1    | 2022-07-31 01:19:33,620 [Command processor thread] INFO upgrade.DatanodeSchemaV3FinalizeAction: Upgrading Datanode volume layout for Schema V3 support.
dn5_1    | 2022-07-31 01:19:33,738 [Command processor thread] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-2b5f2d05-a9c0-4b31-b820-5fa0b5f933e6/DS-4330f79d-dd6b-4a3a-8920-c1ea38ae6371/container.db for volume DS-4330f79d-dd6b-4a3a-8920-c1ea38ae6371
dn5_1    | 2022-07-31 01:19:33,750 [Command processor thread] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-2b5f2d05-a9c0-4b31-b820-5fa0b5f933e6/DS-4330f79d-dd6b-4a3a-8920-c1ea38ae6371/container.db for volume DS-4330f79d-dd6b-4a3a-8920-c1ea38ae6371
dn5_1    | 2022-07-31 01:19:33,752 [Command processor thread] INFO upgrade.DatanodeSchemaV3FinalizeAction: Schema V3 is disabled. Won't load RocksDB in upgrade.
dn5_1    | 2022-07-31 01:19:33,754 [Command processor thread] INFO upgrade.AbstractLayoutVersionManager: Layout feature DATANODE_SCHEMA_V3 has been finalized.
dn5_1    | 2022-07-31 01:19:33,754 [Command processor thread] INFO upgrade.AbstractLayoutVersionManager: Finalization is complete.
dn5_1    | 2022-07-31 01:19:33,754 [Command processor thread] INFO upgrade.UpgradeFinalizer: Finalization is done.
dn5_1    | 2022-07-31 01:19:33,755 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | 2022-07-31 01:19:33,756 [Command processor thread] INFO server.RaftServer: 52aca038-7576-46a0-9ccd-b8aed29078e2: remove  FOLLOWER 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1:t11, leader=609e7f2d-9474-472f-937f-8fa0a0bbb327, voted=609e7f2d-9474-472f-937f-8fa0a0bbb327, raftlog=52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-SegmentedRaftLog:OPENED:c43, conf=36: [11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null RUNNING
dn5_1    | 2022-07-31 01:19:33,760 [Command processor thread] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1: shutdown
dn5_1    | 2022-07-31 01:19:33,761 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-65A101075AF1,id=52aca038-7576-46a0-9ccd-b8aed29078e2
dn5_1    | 2022-07-31 01:19:33,761 [Command processor thread] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: shutdown 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-FollowerState
dn5_1    | 2022-07-31 01:19:33,761 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-FollowerState] INFO impl.FollowerState: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-FollowerState was interrupted
dn5_1    | 2022-07-31 01:19:33,766 [Command processor thread] INFO impl.StateMachineUpdater: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-StateMachineUpdater: set stopIndex = 43
dn5_1    | 2022-07-31 01:19:33,766 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-65A101075AF1: Taking a snapshot at:(t:11, i:43) file /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/sm/snapshot.11_43
dn5_1    | 2022-07-31 01:19:33,778 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-65A101075AF1: Finished taking a snapshot at:(t:11, i:43) file:/data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1/sm/snapshot.11_43 took: 12 ms
dn5_1    | 2022-07-31 01:19:33,780 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-StateMachineUpdater] INFO impl.StateMachineUpdater: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-StateMachineUpdater: Took a snapshot at index 43
dn5_1    | 2022-07-31 01:19:33,780 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-StateMachineUpdater] INFO impl.StateMachineUpdater: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-StateMachineUpdater: snapshotIndex: updateIncreasingly 35 -> 43
dn5_1    | 2022-07-31 01:19:33,786 [Command processor thread] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1: closes. applyIndex: 43
dn5_1    | 2022-07-31 01:19:33,787 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
dn5_1    | 2022-07-31 01:19:33,788 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1-SegmentedRaftLogWorker close()
dn5_1    | 2022-07-31 01:19:33,793 [Command processor thread] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-65A101075AF1: Succeed to remove RaftStorageDirectory Storage Directory /data/metadata/ratis/67b1342c-3bb3-4b48-a218-65a101075af1
dn5_1    | 2022-07-31 01:19:33,794 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline PipelineID=67b1342c-3bb3-4b48-a218-65a101075af1 command on datanode 52aca038-7576-46a0-9ccd-b8aed29078e2.
dn5_1    | 2022-07-31 01:19:33,794 [Command processor thread] INFO server.RaftServer: 52aca038-7576-46a0-9ccd-b8aed29078e2: remove    LEADER 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED:t4, leader=52aca038-7576-46a0-9ccd-b8aed29078e2, voted=52aca038-7576-46a0-9ccd-b8aed29078e2, raftlog=52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-SegmentedRaftLog:OPENED:c6, conf=5: [52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null RUNNING
dn5_1    | 2022-07-31 01:19:33,795 [Command processor thread] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED: shutdown
dn5_1    | 2022-07-31 01:19:33,795 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-CD003ECC1EED,id=52aca038-7576-46a0-9ccd-b8aed29078e2
dn5_1    | 2022-07-31 01:19:33,795 [Command processor thread] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: shutdown 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-LeaderStateImpl
dn5_1    | 2022-07-31 01:19:33,796 [Command processor thread] INFO impl.PendingRequests: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-PendingRequests: sendNotLeaderResponses
dn5_1    | 2022-07-31 01:19:33,802 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-CD003ECC1EED: Taking a snapshot at:(t:4, i:6) file /data/metadata/ratis/106ad38c-cb28-4e98-a52d-cd003ecc1eed/sm/snapshot.4_6
dn5_1    | 2022-07-31 01:19:33,803 [Command processor thread] INFO impl.StateMachineUpdater: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-StateMachineUpdater: set stopIndex = 6
dn5_1    | 2022-07-31 01:19:33,805 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-CD003ECC1EED: Finished taking a snapshot at:(t:4, i:6) file:/data/metadata/ratis/106ad38c-cb28-4e98-a52d-cd003ecc1eed/sm/snapshot.4_6 took: 2 ms
dn5_1    | 2022-07-31 01:19:33,805 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-StateMachineUpdater] INFO impl.StateMachineUpdater: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-StateMachineUpdater: Took a snapshot at index 6
dn5_1    | 2022-07-31 01:19:33,805 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-StateMachineUpdater] INFO impl.StateMachineUpdater: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-StateMachineUpdater: snapshotIndex: updateIncreasingly 4 -> 6
dn5_1    | 2022-07-31 01:19:33,806 [Command processor thread] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED: closes. applyIndex: 6
dn5_1    | 2022-07-31 01:19:33,806 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
dn5_1    | 2022-07-31 01:19:33,807 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED-SegmentedRaftLogWorker close()
dn5_1    | 2022-07-31 01:19:33,809 [Command processor thread] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-CD003ECC1EED: Succeed to remove RaftStorageDirectory Storage Directory /data/metadata/ratis/106ad38c-cb28-4e98-a52d-cd003ecc1eed
dn5_1    | 2022-07-31 01:19:33,812 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline PipelineID=106ad38c-cb28-4e98-a52d-cd003ecc1eed command on datanode 52aca038-7576-46a0-9ccd-b8aed29078e2.
dn5_1    | 2022-07-31 01:19:33,812 [Command processor thread] INFO server.RaftServer: 52aca038-7576-46a0-9ccd-b8aed29078e2: remove    LEADER 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610:t14, leader=52aca038-7576-46a0-9ccd-b8aed29078e2, voted=52aca038-7576-46a0-9ccd-b8aed29078e2, raftlog=52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-SegmentedRaftLog:OPENED:c16, conf=13: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null RUNNING
dn5_1    | 2022-07-31 01:19:33,813 [Command processor thread] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610: shutdown
dn5_1    | 2022-07-31 01:19:33,813 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-7BB2A1276610,id=52aca038-7576-46a0-9ccd-b8aed29078e2
dn5_1    | 2022-07-31 01:19:33,814 [Command processor thread] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: shutdown 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-LeaderStateImpl
dn5_1    | 2022-07-31 01:19:33,814 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610->3fc9f139-dd93-41e7-b235-52ce94d6fe3c-GrpcLogAppender-LogAppenderDaemon] WARN server.GrpcLogAppender: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610->3fc9f139-dd93-41e7-b235-52ce94d6fe3c-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
dn5_1    | 2022-07-31 01:19:33,827 [grpc-default-executor-1] INFO server.GrpcLogAppender: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610->3fc9f139-dd93-41e7-b235-52ce94d6fe3c-AppendLogResponseHandler: follower responses appendEntries COMPLETED
dn5_1    | 2022-07-31 01:19:33,833 [grpc-default-executor-1] INFO leader.FollowerInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610->3fc9f139-dd93-41e7-b235-52ce94d6fe3c: nextIndex: updateUnconditionally 17 -> 16
dn5_1    | 2022-07-31 01:19:33,833 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610->310a080d-f635-46ff-a53d-49cc9a09fa5c-GrpcLogAppender-LogAppenderDaemon] WARN server.GrpcLogAppender: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610->310a080d-f635-46ff-a53d-49cc9a09fa5c-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
dn5_1    | 2022-07-31 01:19:33,837 [Command processor thread] INFO impl.PendingRequests: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-PendingRequests: sendNotLeaderResponses
dn5_1    | 2022-07-31 01:19:33,839 [grpc-default-executor-1] INFO server.GrpcLogAppender: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610->310a080d-f635-46ff-a53d-49cc9a09fa5c-AppendLogResponseHandler: follower responses appendEntries COMPLETED
dn5_1    | 2022-07-31 01:19:33,842 [grpc-default-executor-1] INFO leader.FollowerInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610->310a080d-f635-46ff-a53d-49cc9a09fa5c: nextIndex: updateUnconditionally 17 -> 16
dn5_1    | 2022-07-31 01:19:33,843 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-7BB2A1276610: Taking a snapshot at:(t:14, i:16) file /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/sm/snapshot.14_16
dn5_1    | 2022-07-31 01:19:33,845 [Command processor thread] INFO impl.StateMachineUpdater: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-StateMachineUpdater: set stopIndex = 16
dn5_1    | 2022-07-31 01:19:33,848 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-StateMachineUpdater] INFO ratis.ContainerStateMachine: group-7BB2A1276610: Finished taking a snapshot at:(t:14, i:16) file:/data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610/sm/snapshot.14_16 took: 5 ms
dn5_1    | 2022-07-31 01:19:33,849 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-StateMachineUpdater] INFO impl.StateMachineUpdater: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-StateMachineUpdater: Took a snapshot at index 16
dn5_1    | 2022-07-31 01:19:33,849 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-StateMachineUpdater] INFO impl.StateMachineUpdater: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-StateMachineUpdater: snapshotIndex: updateIncreasingly 12 -> 16
dn5_1    | 2022-07-31 01:19:33,850 [Command processor thread] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610: closes. applyIndex: 16
dn5_1    | 2022-07-31 01:19:33,852 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
dn5_1    | 2022-07-31 01:19:33,854 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610-SegmentedRaftLogWorker close()
dn5_1    | 2022-07-31 01:19:33,863 [Command processor thread] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-7BB2A1276610: Succeed to remove RaftStorageDirectory Storage Directory /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610
dn5_1    | 2022-07-31 01:19:33,864 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline PipelineID=b88205de-97a2-4448-8e49-7bb2a1276610 command on datanode 52aca038-7576-46a0-9ccd-b8aed29078e2.
dn5_1    | 2022-07-31 01:19:35,699 [org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@159424e2] INFO commandhandler.DeleteBlocksCommandHandler: Start to delete container blocks, TXIDs=[1(0)], numOfContainers=1, numOfBlocks=3
dn4_1    | 2022-07-31 01:19:33,735 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610-SegmentedRaftLogWorker close()
dn4_1    | 2022-07-31 01:19:33,739 [Command processor thread] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7BB2A1276610: Succeed to remove RaftStorageDirectory Storage Directory /data/metadata/ratis/b88205de-97a2-4448-8e49-7bb2a1276610
dn4_1    | 2022-07-31 01:19:33,739 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline PipelineID=b88205de-97a2-4448-8e49-7bb2a1276610 command on datanode 310a080d-f635-46ff-a53d-49cc9a09fa5c.
dn4_1    | 2022-07-31 01:19:33,838 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 310a080d-f635-46ff-a53d-49cc9a09fa5c: Completed APPEND_ENTRIES, lastRequest: 52aca038-7576-46a0-9ccd-b8aed29078e2->310a080d-f635-46ff-a53d-49cc9a09fa5c#261-t14,previous=(t:14, i:15),leaderCommit=15,initializing? true,entries: size=1, first=(t:14, i:16), METADATAENTRY(c:15)
dn4_1    | 2022-07-31 01:20:03,499 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn4_1    | 2022-07-31 01:20:03,930 [pool-26-thread-1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c: new RaftServerImpl for group-7781FFA9F9E7:[310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
dn4_1    | 2022-07-31 01:20:03,932 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn4_1    | 2022-07-31 01:20:03,932 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn4_1    | 2022-07-31 01:20:03,932 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn4_1    | 2022-07-31 01:20:03,934 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn4_1    | 2022-07-31 01:20:03,934 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn4_1    | 2022-07-31 01:20:03,935 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn4_1    | 2022-07-31 01:20:03,935 [pool-26-thread-1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7: ConfigurationManager, init=-1: [310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
dn4_1    | 2022-07-31 01:20:03,935 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn4_1    | 2022-07-31 01:20:03,938 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn4_1    | 2022-07-31 01:20:03,938 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn4_1    | 2022-07-31 01:20:03,939 [pool-26-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/ae7040c6-f723-491f-8b9e-7781ffa9f9e7 does not exist. Creating ...
dn4_1    | 2022-07-31 01:20:03,941 [grpc-default-executor-0] INFO server.RaftServer: 310a080d-f635-46ff-a53d-49cc9a09fa5c: addNew group-7781FFA9F9E7:[310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0] returns group-7781FFA9F9E7:java.util.concurrent.CompletableFuture@37469199[Not completed]
dn4_1    | 2022-07-31 01:20:03,943 [pool-26-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/ae7040c6-f723-491f-8b9e-7781ffa9f9e7/in_use.lock acquired by nodename 6@6d05c26d6799
dn4_1    | 2022-07-31 01:20:03,946 [pool-26-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/ae7040c6-f723-491f-8b9e-7781ffa9f9e7 has been successfully formatted.
dn4_1    | 2022-07-31 01:20:03,947 [pool-26-thread-1] INFO ratis.ContainerStateMachine: group-7781FFA9F9E7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn4_1    | 2022-07-31 01:20:03,947 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn4_1    | 2022-07-31 01:20:03,947 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn4_1    | 2022-07-31 01:20:03,947 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn4_1    | 2022-07-31 01:20:03,947 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn4_1    | 2022-07-31 01:20:03,947 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn4_1    | 2022-07-31 01:20:03,948 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn4_1    | 2022-07-31 01:20:03,948 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn4_1    | 2022-07-31 01:20:03,949 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn4_1    | 2022-07-31 01:20:03,949 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: new 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/ae7040c6-f723-491f-8b9e-7781ffa9f9e7
dn4_1    | 2022-07-31 01:20:03,949 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn4_1    | 2022-07-31 01:20:03,949 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn4_1    | 2022-07-31 01:20:03,949 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn4_1    | 2022-07-31 01:20:03,949 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn4_1    | 2022-07-31 01:20:03,949 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn4_1    | 2022-07-31 01:20:03,955 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn4_1    | 2022-07-31 01:20:03,955 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn4_1    | 2022-07-31 01:20:03,957 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn4_1    | 2022-07-31 01:20:03,958 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn4_1    | 2022-07-31 01:20:03,979 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn4_1    | 2022-07-31 01:20:03,980 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn4_1    | 2022-07-31 01:20:03,981 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn4_1    | 2022-07-31 01:20:03,981 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn4_1    | 2022-07-31 01:20:03,988 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn4_1    | 2022-07-31 01:20:03,988 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn4_1    | 2022-07-31 01:20:03,988 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn4_1    | 2022-07-31 01:20:03,988 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn4_1    | 2022-07-31 01:20:03,990 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn4_1    | 2022-07-31 01:20:03,991 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn4_1    | 2022-07-31 01:20:03,992 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn4_1    | 2022-07-31 01:20:03,992 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn4_1    | 2022-07-31 01:20:03,994 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn4_1    | 2022-07-31 01:20:03,996 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn4_1    | 2022-07-31 01:20:03,996 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn4_1    | 2022-07-31 01:20:03,996 [pool-26-thread-1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7: start as a follower, conf=-1: [310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn4_1    | 2022-07-31 01:20:03,997 [pool-26-thread-1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn4_1    | 2022-07-31 01:20:03,997 [pool-26-thread-1] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: start 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-FollowerState
dn4_1    | 2022-07-31 01:20:03,998 [pool-26-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7781FFA9F9E7,id=310a080d-f635-46ff-a53d-49cc9a09fa5c
dn4_1    | 2022-07-31 01:20:04,136 [grpc-default-executor-0] INFO server.RaftServer: 310a080d-f635-46ff-a53d-49cc9a09fa5c: addNew group-84A70A95B4C0:[3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0] returns group-84A70A95B4C0:java.util.concurrent.CompletableFuture@70844a80[Not completed]
dn4_1    | 2022-07-31 01:20:04,139 [pool-26-thread-1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c: new RaftServerImpl for group-84A70A95B4C0:[3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
dn4_1    | 2022-07-31 01:20:04,139 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn4_1    | 2022-07-31 01:20:04,139 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn4_1    | 2022-07-31 01:20:04,139 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn4_1    | 2022-07-31 01:20:04,139 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn4_1    | 2022-07-31 01:20:04,140 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn4_1    | 2022-07-31 01:20:04,140 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn4_1    | 2022-07-31 01:20:04,140 [pool-26-thread-1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0: ConfigurationManager, init=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
dn4_1    | 2022-07-31 01:20:04,140 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn4_1    | 2022-07-31 01:20:04,140 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn4_1    | 2022-07-31 01:20:04,140 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn4_1    | 2022-07-31 01:20:04,141 [pool-26-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0 does not exist. Creating ...
dn4_1    | 2022-07-31 01:20:04,142 [pool-26-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0/in_use.lock acquired by nodename 6@6d05c26d6799
dn4_1    | 2022-07-31 01:20:04,145 [pool-26-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0 has been successfully formatted.
dn4_1    | 2022-07-31 01:20:04,145 [pool-26-thread-1] INFO ratis.ContainerStateMachine: group-84A70A95B4C0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn4_1    | 2022-07-31 01:20:04,146 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn4_1    | 2022-07-31 01:20:04,146 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn4_1    | 2022-07-31 01:20:04,146 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn4_1    | 2022-07-31 01:20:04,146 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn4_1    | 2022-07-31 01:20:04,146 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn4_1    | 2022-07-31 01:20:04,147 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn4_1    | 2022-07-31 01:20:04,147 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
recon_1  | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:696)
recon_1  | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getDBUpdates(OzoneManagerProtocolClientSideTranslatorPB.java:1810)
recon_1  | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.innerGetAndApplyDeltaUpdatesFromOM(OzoneManagerServiceProviderImpl.java:409)
recon_1  | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getAndApplyDeltaUpdatesFromOM(OzoneManagerServiceProviderImpl.java:381)
recon_1  | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:458)
recon_1  | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1  | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1  | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1  | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1  | 2022-07-31 01:19:09,439 [pool-26-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1  | 2022-07-31 01:19:09,669 [pool-26-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Got new checkpoint from OM : /data/metadata/om.snapshot.db_1659230349439
recon_1  | 2022-07-31 01:19:09,669 [pool-26-thread-1] INFO recovery.ReconOmMetadataManagerImpl: Cleaning up old OM snapshot db at /data/metadata/om.snapshot.db_1659230173349.
recon_1  | 2022-07-31 01:19:09,679 [pool-26-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1  | 2022-07-31 01:19:09,679 [pool-26-thread-1] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
recon_1  | 2022-07-31 01:19:09,737 [pool-26-thread-1] INFO recovery.ReconOmMetadataManagerImpl: Created OM DB handle from snapshot at /data/metadata/om.snapshot.db_1659230349439.
recon_1  | 2022-07-31 01:19:09,744 [pool-26-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Calling reprocess on Recon tasks.
recon_1  | 2022-07-31 01:19:09,780 [pool-46-thread-1] INFO tasks.NSSummaryTask: Completed a reprocess run of NSSummaryTask
recon_1  | 2022-07-31 01:19:09,966 [pool-46-thread-1] INFO tasks.TableCountTask: Completed a 'reprocess' run of TableCountTask.
recon_1  | 2022-07-31 01:19:09,966 [pool-46-thread-1] INFO tasks.ContainerKeyMapperTask: Starting a 'reprocess' run of ContainerKeyMapperTask.
recon_1  | 2022-07-31 01:19:10,012 [pool-46-thread-1] INFO tasks.ContainerKeyMapperTask: Completed 'reprocess' of ContainerKeyMapperTask.
recon_1  | 2022-07-31 01:19:10,013 [pool-46-thread-1] INFO tasks.ContainerKeyMapperTask: It took me 0.046 seconds to process 9 keys.
recon_1  | 2022-07-31 01:19:10,031 [pool-46-thread-1] INFO tasks.FileSizeCountTask: Deleted 4 records from "FILE_COUNT_BY_SIZE"
recon_1  | 2022-07-31 01:19:10,072 [pool-46-thread-1] INFO tasks.FileSizeCountTask: Completed a 'reprocess' run of FileSizeCountTask.
recon_1  | 2022-07-31 01:19:32,322 [IPC Server handler 15 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:32,534 [IPC Server handler 4 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:19:32,706 [IPC Server handler 20 on default port 9891] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
recon_1  | 2022-07-31 01:20:03,558 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=da610dcf-61e8-4e48-8ead-26397c6fffad. Trying to get from SCM.
recon_1  | 2022-07-31 01:20:03,584 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: da610dcf-61e8-4e48-8ead-26397c6fffad, Nodes: 11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:11cba143-91f8-47cb-8422-c32a1e2d51df, CreationTimestamp2022-07-31T01:19:32.680Z[UTC]] to Recon pipeline metadata.
recon_1  | 2022-07-31 01:20:03,586 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: da610dcf-61e8-4e48-8ead-26397c6fffad, Nodes: 11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:11cba143-91f8-47cb-8422-c32a1e2d51df, CreationTimestamp2022-07-31T01:19:32.680Z[UTC]].
recon_1  | 2022-07-31 01:20:03,623 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=f058582a-59a2-4a37-8200-b37bd276617a. Trying to get from SCM.
recon_1  | 2022-07-31 01:20:03,630 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: f058582a-59a2-4a37-8200-b37bd276617a, Nodes: 609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:609e7f2d-9474-472f-937f-8fa0a0bbb327, CreationTimestamp2022-07-31T01:19:32.687Z[UTC]] to Recon pipeline metadata.
recon_1  | 2022-07-31 01:20:03,631 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: f058582a-59a2-4a37-8200-b37bd276617a, Nodes: 609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:609e7f2d-9474-472f-937f-8fa0a0bbb327, CreationTimestamp2022-07-31T01:19:32.687Z[UTC]].
recon_1  | 2022-07-31 01:20:03,632 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=f058582a-59a2-4a37-8200-b37bd276617a reported by 609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
om1_1    | 2022-07-31 01:18:36,137 [om1@group-D66704EFC61C-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om1_1    | 2022-07-31 01:18:36,137 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1    | 2022-07-31 01:18:36,137 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1    | 2022-07-31 01:18:36,143 [om1@group-D66704EFC61C-LeaderElection2] INFO impl.RoleInfo: om1: start om1@group-D66704EFC61C-LeaderStateImpl
om1_1    | 2022-07-31 01:18:36,156 [om1@group-D66704EFC61C-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: om1@group-D66704EFC61C-SegmentedRaftLogWorker: Rolling segment log-63_98 to index:98
om1_1    | 2022-07-31 01:18:36,160 [om1@group-D66704EFC61C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-D66704EFC61C-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_inprogress_63 to /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_63-98
om1_1    | 2022-07-31 01:18:36,178 [om1@group-D66704EFC61C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-D66704EFC61C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/5cb24680-b9e7-3c90-a862-d66704efc61c/current/log_inprogress_99
om1_1    | 2022-07-31 01:18:36,183 [om1@group-D66704EFC61C-LeaderElection2] INFO server.RaftServer$Division: om1@group-D66704EFC61C: set configuration 99: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1    | 2022-07-31 01:18:36,693 [om1@group-D66704EFC61C-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om1_1    | [id: "om1"
om1_1    | address: "om1:9872"
om1_1    | , id: "om3"
om1_1    | address: "om3:9872"
om1_1    | , id: "om2"
om1_1    | address: "om2:9872"
om1_1    | ]
om1_1    | 2022-07-31 01:19:09,341 [IPC Server handler 4 on default port 9862] WARN db.RDBStore: Unable to get delta updates since sequenceNumber 100. This exception will be thrown to the client
om1_1    | org.apache.hadoop.hdds.utils.db.SequenceNumberNotFoundException: Invalid transaction log iterator when getting updates since sequence number 100
om1_1    | 	at org.apache.hadoop.hdds.utils.db.RDBStore.getUpdatesSince(RDBStore.java:294)
om1_1    | 	at org.apache.hadoop.ozone.om.OzoneManager.getDBUpdates(OzoneManager.java:4045)
om1_1    | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOMDBUpdates(OzoneManagerRequestHandler.java:317)
om1_1    | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleReadRequest(OzoneManagerRequestHandler.java:219)
om1_1    | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:226)
om1_1    | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
om1_1    | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1    | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
om1_1    | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
om1_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
om1_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
om1_1    | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
om1_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
om1_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
om1_1    | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1    | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1    | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om1_1    | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
om1_1    | 2022-07-31 01:19:09,543 [qtp960795749-57] INFO utils.DBCheckpointServlet: Received request to obtain DB checkpoint snapshot
om1_1    | 2022-07-31 01:19:09,549 [qtp960795749-57] INFO db.RDBCheckpointManager: Created checkpoint at /data/metadata/db.checkpoints/om.db_checkpoint_1659230349544 in 4 milliseconds
om1_1    | 2022-07-31 01:19:09,611 [qtp960795749-57] INFO utils.DBCheckpointServlet: Time taken to write the checkpoint to response output stream: 60 milliseconds
om1_1    | 2022-07-31 01:19:09,613 [qtp960795749-57] INFO db.RocksDBCheckpoint: Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/om.db_checkpoint_1659230349544
om1_1    | 2022-07-31 01:20:17,362 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: Finalization started.
om1_1    | 2022-07-31 01:20:17,378 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: ERASURE_CODED_STORAGE_SUPPORT.
om1_1    | 2022-07-31 01:20:17,391 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.AbstractLayoutVersionManager: Layout feature ERASURE_CODED_STORAGE_SUPPORT has been finalized.
om1_1    | 2022-07-31 01:20:17,393 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: BUCKET_LAYOUT_SUPPORT.
om1_1    | 2022-07-31 01:20:17,398 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.AbstractLayoutVersionManager: Layout feature BUCKET_LAYOUT_SUPPORT has been finalized.
om1_1    | 2022-07-31 01:20:17,398 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: MULTITENANCY_SCHEMA.
om1_1    | 2022-07-31 01:20:17,400 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.AbstractLayoutVersionManager: Layout feature MULTITENANCY_SCHEMA has been finalized.
om1_1    | 2022-07-31 01:20:17,400 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.AbstractLayoutVersionManager: Finalization is complete.
om1_1    | 2022-07-31 01:20:17,400 [OM StateMachine ApplyTransaction Thread - 0] INFO upgrade.UpgradeFinalizer: Finalization is done.
om1_1    | 2022-07-31 01:20:17,438 [OMDoubleBufferFlushThread] INFO upgrade.OMFinalizeUpgradeResponse: Layout version to persist to DB : 3
om1_1    | 2022-07-31 01:21:33,588 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:new2-volume for user:hadoop
om1_1    | 2022-07-31 01:21:36,625 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: new2-bucket of layout LEGACY in volume: new2-volume
om1_1    | 2022-07-31 01:21:45,644 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: new2-bucket of layout LEGACY in volume: s3v
om1_1    | 2022-07-31 01:21:53,933 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:new2-bucket in volume:s3v
om1_1    | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1    | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om1_1    | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:300)
om1_1    | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1    | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1    | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1    | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1    | 2022-07-31 01:22:14,947 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:ectest-new for user:hadoop
om1_1    | 2022-07-31 01:22:17,934 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ectest of layout LEGACY in volume: ectest-new
om1_1    | 2022-07-31 01:22:24,172 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: testpropchange of layout LEGACY in volume: ectest-new
recon_1  | 2022-07-31 01:20:03,632 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: f058582a-59a2-4a37-8200-b37bd276617a, Nodes: 609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:609e7f2d-9474-472f-937f-8fa0a0bbb327, CreationTimestamp2022-07-31T01:19:32.687Z[UTC]] moved to OPEN state
recon_1  | 2022-07-31 01:20:03,658 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=ae7040c6-f723-491f-8b9e-7781ffa9f9e7. Trying to get from SCM.
recon_1  | 2022-07-31 01:20:03,661 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: ae7040c6-f723-491f-8b9e-7781ffa9f9e7, Nodes: 609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-31T01:20:02.683Z[UTC]] to Recon pipeline metadata.
recon_1  | 2022-07-31 01:20:03,662 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: ae7040c6-f723-491f-8b9e-7781ffa9f9e7, Nodes: 609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-31T01:20:02.683Z[UTC]].
recon_1  | 2022-07-31 01:20:03,662 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=ae7040c6-f723-491f-8b9e-7781ffa9f9e7 reported by 11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2022-07-31 01:20:03,701 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=ae7040c6-f723-491f-8b9e-7781ffa9f9e7 reported by 609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2022-07-31 01:20:03,954 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=ae7040c6-f723-491f-8b9e-7781ffa9f9e7 reported by 310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2022-07-31 01:20:04,095 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0. Trying to get from SCM.
recon_1  | 2022-07-31 01:20:04,098 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0, Nodes: 310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-31T01:20:02.686Z[UTC]] to Recon pipeline metadata.
recon_1  | 2022-07-31 01:20:04,099 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0, Nodes: 310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-31T01:20:02.686Z[UTC]].
recon_1  | 2022-07-31 01:20:04,100 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0 reported by 609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2022-07-31 01:20:04,100 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=ae7040c6-f723-491f-8b9e-7781ffa9f9e7 reported by 609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
dn4_1    | 2022-07-31 01:20:04,147 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn4_1    | 2022-07-31 01:20:04,148 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: new 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0
dn4_1    | 2022-07-31 01:20:04,148 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn4_1    | 2022-07-31 01:20:04,148 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn4_1    | 2022-07-31 01:20:04,149 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn4_1    | 2022-07-31 01:20:04,149 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn4_1    | 2022-07-31 01:20:04,149 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn4_1    | 2022-07-31 01:20:04,149 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn4_1    | 2022-07-31 01:20:04,150 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn4_1    | 2022-07-31 01:20:04,150 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn4_1    | 2022-07-31 01:20:04,154 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn4_1    | 2022-07-31 01:20:04,156 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn4_1    | 2022-07-31 01:20:04,156 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn4_1    | 2022-07-31 01:20:04,157 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn4_1    | 2022-07-31 01:20:04,157 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn4_1    | 2022-07-31 01:20:04,162 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn4_1    | 2022-07-31 01:20:04,162 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn4_1    | 2022-07-31 01:20:04,162 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn4_1    | 2022-07-31 01:20:04,162 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn4_1    | 2022-07-31 01:20:04,162 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn4_1    | 2022-07-31 01:20:04,162 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn4_1    | 2022-07-31 01:20:04,172 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn4_1    | 2022-07-31 01:20:04,173 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn4_1    | 2022-07-31 01:20:04,173 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn4_1    | 2022-07-31 01:20:04,174 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn4_1    | 2022-07-31 01:20:04,174 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn4_1    | 2022-07-31 01:20:04,175 [pool-26-thread-1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0: start as a follower, conf=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn4_1    | 2022-07-31 01:20:04,176 [pool-26-thread-1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn4_1    | 2022-07-31 01:20:04,176 [pool-26-thread-1] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: start 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState
dn4_1    | 2022-07-31 01:20:04,178 [pool-26-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-84A70A95B4C0,id=310a080d-f635-46ff-a53d-49cc9a09fa5c
dn4_1    | 2022-07-31 01:20:08,753 [grpc-default-executor-0] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7: receive requestVote(ELECTION, 11cba143-91f8-47cb-8422-c32a1e2d51df, group-7781FFA9F9E7, 1, (t:0, i:0))
dn4_1    | 2022-07-31 01:20:08,753 [grpc-default-executor-0] INFO impl.VoteContext: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-FOLLOWER: reject ELECTION from 11cba143-91f8-47cb-8422-c32a1e2d51df: our priority 1 > candidate's priority 0
dn4_1    | 2022-07-31 01:20:08,753 [grpc-default-executor-0] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:11cba143-91f8-47cb-8422-c32a1e2d51df
dn4_1    | 2022-07-31 01:20:08,754 [grpc-default-executor-0] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: shutdown 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-FollowerState
dn4_1    | 2022-07-31 01:20:08,754 [grpc-default-executor-0] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: start 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-FollowerState
dn4_1    | 2022-07-31 01:20:08,754 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-FollowerState] INFO impl.FollowerState: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-FollowerState was interrupted
dn4_1    | 2022-07-31 01:20:08,755 [grpc-default-executor-0] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7 replies to ELECTION vote request: 11cba143-91f8-47cb-8422-c32a1e2d51df<-310a080d-f635-46ff-a53d-49cc9a09fa5c#0:FAIL-t1. Peer's state: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7:t1, leader=null, voted=null, raftlog=310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-SegmentedRaftLog:OPENED:c-1, conf=-1: [310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn4_1    | 2022-07-31 01:20:09,155 [grpc-default-executor-0] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0: receive requestVote(ELECTION, 609e7f2d-9474-472f-937f-8fa0a0bbb327, group-84A70A95B4C0, 1, (t:0, i:0))
dn4_1    | 2022-07-31 01:20:09,155 [grpc-default-executor-0] INFO impl.VoteContext: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FOLLOWER: accept ELECTION from 609e7f2d-9474-472f-937f-8fa0a0bbb327: our priority 0 <= candidate's priority 0
dn4_1    | 2022-07-31 01:20:09,155 [grpc-default-executor-0] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:609e7f2d-9474-472f-937f-8fa0a0bbb327
dn4_1    | 2022-07-31 01:20:09,155 [grpc-default-executor-0] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: shutdown 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState
dn4_1    | 2022-07-31 01:20:09,155 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState] INFO impl.FollowerState: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState was interrupted
dn4_1    | 2022-07-31 01:20:09,156 [grpc-default-executor-0] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: start 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState
dn4_1    | 2022-07-31 01:20:09,159 [grpc-default-executor-0] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0 replies to ELECTION vote request: 609e7f2d-9474-472f-937f-8fa0a0bbb327<-310a080d-f635-46ff-a53d-49cc9a09fa5c#0:OK-t1. Peer's state: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0:t1, leader=null, voted=609e7f2d-9474-472f-937f-8fa0a0bbb327, raftlog=310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-SegmentedRaftLog:OPENED:c-1, conf=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn4_1    | 2022-07-31 01:20:13,779 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-FollowerState] INFO impl.FollowerState: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5025439680ns, electionTimeout:5024ms
dn4_1    | 2022-07-31 01:20:13,780 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-FollowerState] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: shutdown 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-FollowerState
dn4_1    | 2022-07-31 01:20:13,780 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-FollowerState] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
dn4_1    | 2022-07-31 01:20:13,780 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn4_1    | 2022-07-31 01:20:13,780 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-FollowerState] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: start 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4
dn4_1    | 2022-07-31 01:20:13,787 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO impl.LeaderElection: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4 ELECTION round 0: submit vote requests at term 2 for -1: [310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn4_1    | 2022-07-31 01:20:13,815 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO impl.LeaderElection: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4: ELECTION PASSED received 1 response(s) and 0 exception(s):
dn4_1    | 2022-07-31 01:20:13,815 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO impl.LeaderElection:   Response 0: 310a080d-f635-46ff-a53d-49cc9a09fa5c<-609e7f2d-9474-472f-937f-8fa0a0bbb327#0:OK-t2
dn4_1    | 2022-07-31 01:20:13,815 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO impl.LeaderElection: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4 ELECTION round 0: result PASSED
dn4_1    | 2022-07-31 01:20:13,815 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: shutdown 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4
dn4_1    | 2022-07-31 01:20:13,815 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
dn4_1    | 2022-07-31 01:20:13,815 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-7781FFA9F9E7 with new leaderId: 310a080d-f635-46ff-a53d-49cc9a09fa5c
dn4_1    | 2022-07-31 01:20:13,815 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7: change Leader from null to 310a080d-f635-46ff-a53d-49cc9a09fa5c at term 2 for becomeLeader, leader elected after 9868ms
dn4_1    | 2022-07-31 01:20:13,817 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn4_1    | 2022-07-31 01:20:13,817 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn4_1    | 2022-07-31 01:20:13,817 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn4_1    | 2022-07-31 01:20:13,818 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn4_1    | 2022-07-31 01:20:13,818 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn4_1    | 2022-07-31 01:20:13,820 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn4_1    | 2022-07-31 01:20:13,820 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn4_1    | 2022-07-31 01:20:13,820 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn4_1    | 2022-07-31 01:20:13,834 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn4_1    | 2022-07-31 01:20:13,834 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn4_1    | 2022-07-31 01:20:13,835 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
dn4_1    | 2022-07-31 01:20:13,850 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn4_1    | 2022-07-31 01:20:13,857 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn4_1    | 2022-07-31 01:20:13,857 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
recon_1  | 2022-07-31 01:20:04,153 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0 reported by 310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2022-07-31 01:20:04,154 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=ae7040c6-f723-491f-8b9e-7781ffa9f9e7 reported by 310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2022-07-31 01:20:04,237 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0 reported by 3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2022-07-31 01:20:08,808 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=ae7040c6-f723-491f-8b9e-7781ffa9f9e7 reported by 11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2022-07-31 01:20:08,836 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0 reported by 609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2022-07-31 01:20:08,837 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=ae7040c6-f723-491f-8b9e-7781ffa9f9e7 reported by 609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2022-07-31 01:20:10,081 [pool-26-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1  | 2022-07-31 01:20:10,081 [pool-26-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1  | 2022-07-31 01:20:10,082 [pool-26-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 148 
recon_1  | 2022-07-31 01:20:10,089 [pool-26-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0.
recon_1  | 2022-07-31 01:20:10,089 [pool-26-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 0 records
recon_1  | 2022-07-31 01:20:13,822 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0 reported by 310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2022-07-31 01:20:13,822 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=ae7040c6-f723-491f-8b9e-7781ffa9f9e7 reported by 310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2022-07-31 01:20:13,822 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: ae7040c6-f723-491f-8b9e-7781ffa9f9e7, Nodes: 609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:310a080d-f635-46ff-a53d-49cc9a09fa5c, CreationTimestamp2022-07-31T01:20:02.683Z[UTC]] moved to OPEN state
recon_1  | 2022-07-31 01:20:33,383 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0 reported by 3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2022-07-31 01:20:33,383 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=e372288d-28a7-4132-a525-5058278e2312. Trying to get from SCM.
recon_1  | 2022-07-31 01:20:33,496 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: e372288d-28a7-4132-a525-5058278e2312, Nodes: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:3fc9f139-dd93-41e7-b235-52ce94d6fe3c, CreationTimestamp2022-07-31T01:20:02.682Z[UTC]] to Recon pipeline metadata.
recon_1  | 2022-07-31 01:20:33,497 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: e372288d-28a7-4132-a525-5058278e2312, Nodes: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:3fc9f139-dd93-41e7-b235-52ce94d6fe3c, CreationTimestamp2022-07-31T01:20:02.682Z[UTC]].
dn5_1    | 2022-07-31 01:20:03,693 [Command processor thread] INFO commandhandler.FinalizeNewLayoutVersionCommandHandler: Processing FinalizeNewLayoutVersionCommandHandler command.
dn5_1    | 2022-07-31 01:20:10,873 [BlockDeletingService#0] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-2b5f2d05-a9c0-4b31-b820-5fa0b5f933e6/current/containerDir0/1/chunks/109611004723200001.block
dn5_1    | 2022-07-31 01:20:10,874 [BlockDeletingService#0] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-2b5f2d05-a9c0-4b31-b820-5fa0b5f933e6/current/containerDir0/1/chunks/109611004723200002.block
dn5_1    | 2022-07-31 01:20:10,874 [BlockDeletingService#0] INFO impl.FilePerBlockStrategy: Deleted block file: /data/hdds/hdds/CID-2b5f2d05-a9c0-4b31-b820-5fa0b5f933e6/current/containerDir0/1/chunks/109611004723200003.block
dn5_1    | 2022-07-31 01:20:33,779 [Command processor thread] INFO server.RaftServer: 52aca038-7576-46a0-9ccd-b8aed29078e2: addNew group-F5ADBE2EE252:[52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|priority:1] returns group-F5ADBE2EE252:java.util.concurrent.CompletableFuture@29a31d78[Not completed]
dn5_1    | 2022-07-31 01:20:33,782 [pool-38-thread-1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2: new RaftServerImpl for group-F5ADBE2EE252:[52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|priority:1] with ContainerStateMachine:uninitialized
dn5_1    | 2022-07-31 01:20:33,783 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn5_1    | 2022-07-31 01:20:33,784 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn5_1    | 2022-07-31 01:20:33,784 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn5_1    | 2022-07-31 01:20:33,784 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn5_1    | 2022-07-31 01:20:33,784 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn5_1    | 2022-07-31 01:20:33,784 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn5_1    | 2022-07-31 01:20:33,784 [pool-38-thread-1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252: ConfigurationManager, init=-1: [52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|priority:1], old=null, confs=<EMPTY_MAP>
dn5_1    | 2022-07-31 01:20:33,785 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn5_1    | 2022-07-31 01:20:33,790 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn5_1    | 2022-07-31 01:20:33,790 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn5_1    | 2022-07-31 01:20:33,792 [pool-38-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/9a50af78-96a4-4a72-b811-f5adbe2ee252 does not exist. Creating ...
dn5_1    | 2022-07-31 01:20:33,797 [pool-38-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/9a50af78-96a4-4a72-b811-f5adbe2ee252/in_use.lock acquired by nodename 6@6c1f77753501
dn5_1    | 2022-07-31 01:20:33,799 [pool-38-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/9a50af78-96a4-4a72-b811-f5adbe2ee252 has been successfully formatted.
dn5_1    | 2022-07-31 01:20:33,817 [pool-38-thread-1] INFO ratis.ContainerStateMachine: group-F5ADBE2EE252: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn5_1    | 2022-07-31 01:20:33,817 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn5_1    | 2022-07-31 01:20:33,817 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn5_1    | 2022-07-31 01:20:33,818 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn5_1    | 2022-07-31 01:20:33,818 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn5_1    | 2022-07-31 01:20:33,818 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn5_1    | 2022-07-31 01:20:33,819 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn5_1    | 2022-07-31 01:20:33,819 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn5_1    | 2022-07-31 01:20:33,819 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn5_1    | 2022-07-31 01:20:33,819 [pool-38-thread-1] INFO segmented.SegmentedRaftLogWorker: new 52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/9a50af78-96a4-4a72-b811-f5adbe2ee252
dn5_1    | 2022-07-31 01:20:33,819 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn5_1    | 2022-07-31 01:20:33,819 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn5_1    | 2022-07-31 01:20:33,819 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn5_1    | 2022-07-31 01:20:33,819 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn5_1    | 2022-07-31 01:20:33,819 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn5_1    | 2022-07-31 01:20:33,819 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn5_1    | 2022-07-31 01:20:33,819 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn5_1    | 2022-07-31 01:20:33,819 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn5_1    | 2022-07-31 01:20:33,820 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn5_1    | 2022-07-31 01:20:33,820 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn5_1    | 2022-07-31 01:20:33,820 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn5_1    | 2022-07-31 01:20:33,820 [pool-38-thread-1] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn5_1    | 2022-07-31 01:20:33,820 [pool-38-thread-1] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn5_1    | 2022-07-31 01:20:33,829 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn5_1    | 2022-07-31 01:20:33,830 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn5_1    | 2022-07-31 01:20:33,832 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn5_1    | 2022-07-31 01:20:33,832 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn5_1    | 2022-07-31 01:20:33,832 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
recon_1  | 2022-07-31 01:20:33,590 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0 reported by 310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2022-07-31 01:20:33,590 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=6f4f1d7d-a1c2-4efd-bea9-18489625bc71. Trying to get from SCM.
recon_1  | 2022-07-31 01:20:33,599 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 6f4f1d7d-a1c2-4efd-bea9-18489625bc71, Nodes: 310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:310a080d-f635-46ff-a53d-49cc9a09fa5c, CreationTimestamp2022-07-31T01:20:02.685Z[UTC]] to Recon pipeline metadata.
recon_1  | 2022-07-31 01:20:33,603 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 6f4f1d7d-a1c2-4efd-bea9-18489625bc71, Nodes: 310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:310a080d-f635-46ff-a53d-49cc9a09fa5c, CreationTimestamp2022-07-31T01:20:02.685Z[UTC]].
recon_1  | 2022-07-31 01:20:33,804 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=9a50af78-96a4-4a72-b811-f5adbe2ee252. Trying to get from SCM.
recon_1  | 2022-07-31 01:20:33,807 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 9a50af78-96a4-4a72-b811-f5adbe2ee252, Nodes: 52aca038-7576-46a0-9ccd-b8aed29078e2{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-31T01:20:05.683Z[UTC]] to Recon pipeline metadata.
recon_1  | 2022-07-31 01:20:33,808 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 9a50af78-96a4-4a72-b811-f5adbe2ee252, Nodes: 52aca038-7576-46a0-9ccd-b8aed29078e2{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-31T01:20:05.683Z[UTC]].
recon_1  | 2022-07-31 01:20:33,809 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=9a50af78-96a4-4a72-b811-f5adbe2ee252 reported by 52aca038-7576-46a0-9ccd-b8aed29078e2{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2022-07-31 01:20:33,809 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 9a50af78-96a4-4a72-b811-f5adbe2ee252, Nodes: 52aca038-7576-46a0-9ccd-b8aed29078e2{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:52aca038-7576-46a0-9ccd-b8aed29078e2, CreationTimestamp2022-07-31T01:20:05.683Z[UTC]] moved to OPEN state
recon_1  | 2022-07-31 01:20:33,859 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=e19f4611-626e-4580-84ca-4b35cfa778dc. Trying to get from SCM.
recon_1  | 2022-07-31 01:20:33,862 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: e19f4611-626e-4580-84ca-4b35cfa778dc, Nodes: 52aca038-7576-46a0-9ccd-b8aed29078e2{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-31T01:20:05.685Z[UTC]] to Recon pipeline metadata.
recon_1  | 2022-07-31 01:20:33,863 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: e19f4611-626e-4580-84ca-4b35cfa778dc, Nodes: 52aca038-7576-46a0-9ccd-b8aed29078e2{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-31T01:20:05.685Z[UTC]].
recon_1  | 2022-07-31 01:20:33,868 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=e19f4611-626e-4580-84ca-4b35cfa778dc reported by 52aca038-7576-46a0-9ccd-b8aed29078e2{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2022-07-31 01:20:34,105 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=e19f4611-626e-4580-84ca-4b35cfa778dc reported by 11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
dn5_1    | 2022-07-31 01:20:33,832 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn5_1    | 2022-07-31 01:20:33,833 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn5_1    | 2022-07-31 01:20:33,833 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn5_1    | 2022-07-31 01:20:33,833 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn5_1    | 2022-07-31 01:20:33,833 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn5_1    | 2022-07-31 01:20:33,833 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn5_1    | 2022-07-31 01:20:33,833 [pool-38-thread-1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252: start as a follower, conf=-1: [52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|priority:1], old=null
dn5_1    | 2022-07-31 01:20:33,833 [pool-38-thread-1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn5_1    | 2022-07-31 01:20:33,833 [pool-38-thread-1] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: start 52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-FollowerState
dn5_1    | 2022-07-31 01:20:33,839 [pool-38-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F5ADBE2EE252,id=52aca038-7576-46a0-9ccd-b8aed29078e2
dn5_1    | 2022-07-31 01:20:33,844 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=9a50af78-96a4-4a72-b811-f5adbe2ee252
dn5_1    | 2022-07-31 01:20:33,845 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=9a50af78-96a4-4a72-b811-f5adbe2ee252.
dn5_1    | 2022-07-31 01:20:33,846 [Command processor thread] INFO server.RaftServer: 52aca038-7576-46a0-9ccd-b8aed29078e2: addNew group-4B35CFA778DC:[3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|priority:0] returns group-4B35CFA778DC:java.util.concurrent.CompletableFuture@62e83fd8[Not completed]
dn5_1    | 2022-07-31 01:20:33,847 [pool-38-thread-1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2: new RaftServerImpl for group-4B35CFA778DC:[3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|priority:0] with ContainerStateMachine:uninitialized
dn5_1    | 2022-07-31 01:20:33,848 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn5_1    | 2022-07-31 01:20:33,848 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn5_1    | 2022-07-31 01:20:33,848 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn5_1    | 2022-07-31 01:20:33,848 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn5_1    | 2022-07-31 01:20:33,848 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn5_1    | 2022-07-31 01:20:33,848 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn5_1    | 2022-07-31 01:20:33,848 [pool-38-thread-1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC: ConfigurationManager, init=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|priority:0], old=null, confs=<EMPTY_MAP>
dn5_1    | 2022-07-31 01:20:33,849 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn5_1    | 2022-07-31 01:20:33,849 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn5_1    | 2022-07-31 01:20:33,849 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn5_1    | 2022-07-31 01:20:33,849 [pool-38-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/e19f4611-626e-4580-84ca-4b35cfa778dc does not exist. Creating ...
dn5_1    | 2022-07-31 01:20:33,851 [pool-38-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/e19f4611-626e-4580-84ca-4b35cfa778dc/in_use.lock acquired by nodename 6@6c1f77753501
dn5_1    | 2022-07-31 01:20:33,853 [pool-38-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/e19f4611-626e-4580-84ca-4b35cfa778dc has been successfully formatted.
dn5_1    | 2022-07-31 01:20:33,866 [pool-38-thread-1] INFO ratis.ContainerStateMachine: group-4B35CFA778DC: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn5_1    | 2022-07-31 01:20:33,867 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn5_1    | 2022-07-31 01:20:33,867 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn5_1    | 2022-07-31 01:20:33,868 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn5_1    | 2022-07-31 01:20:33,868 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn5_1    | 2022-07-31 01:20:33,868 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn5_1    | 2022-07-31 01:20:33,869 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn5_1    | 2022-07-31 01:20:33,871 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn5_1    | 2022-07-31 01:20:33,871 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn5_1    | 2022-07-31 01:20:33,871 [pool-38-thread-1] INFO segmented.SegmentedRaftLogWorker: new 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/e19f4611-626e-4580-84ca-4b35cfa778dc
dn5_1    | 2022-07-31 01:20:33,871 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn5_1    | 2022-07-31 01:20:33,871 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn5_1    | 2022-07-31 01:20:33,871 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn5_1    | 2022-07-31 01:20:33,871 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn5_1    | 2022-07-31 01:20:33,871 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
recon_1  | 2022-07-31 01:20:34,198 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=e19f4611-626e-4580-84ca-4b35cfa778dc reported by 3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2022-07-31 01:20:34,198 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0 reported by 3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2022-07-31 01:20:34,627 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=e19f4611-626e-4580-84ca-4b35cfa778dc reported by 3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2022-07-31 01:20:34,627 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0 reported by 3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2022-07-31 01:20:34,628 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0, Nodes: 310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:3fc9f139-dd93-41e7-b235-52ce94d6fe3c, CreationTimestamp2022-07-31T01:20:02.686Z[UTC]] moved to OPEN state
recon_1  | 2022-07-31 01:20:38,515 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=e19f4611-626e-4580-84ca-4b35cfa778dc reported by 3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2022-07-31 01:20:38,904 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=e19f4611-626e-4580-84ca-4b35cfa778dc reported by 52aca038-7576-46a0-9ccd-b8aed29078e2{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2022-07-31 01:20:44,232 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=e19f4611-626e-4580-84ca-4b35cfa778dc reported by 11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2022-07-31 01:20:44,233 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: e19f4611-626e-4580-84ca-4b35cfa778dc, Nodes: 52aca038-7576-46a0-9ccd-b8aed29078e2{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:11cba143-91f8-47cb-8422-c32a1e2d51df, CreationTimestamp2022-07-31T01:20:05.685Z[UTC]] moved to OPEN state
recon_1  | 2022-07-31 01:21:10,092 [pool-26-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1  | 2022-07-31 01:21:10,093 [pool-26-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1  | 2022-07-31 01:21:10,093 [pool-26-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 148 
recon_1  | 2022-07-31 01:21:10,109 [pool-26-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 1, SequenceNumber diff: 2, SequenceNumber Lag from OM 0.
recon_1  | 2022-07-31 01:21:10,109 [pool-26-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 2 records
recon_1  | 2022-07-31 01:21:10,117 [pool-46-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1  | 2022-07-31 01:21:10,471 [pool-46-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1  | 2022-07-31 01:21:10,471 [pool-46-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
recon_1  | 2022-07-31 01:21:10,473 [pool-46-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1  | 2022-07-31 01:21:41,868 [FixedThreadPoolWithAffinityExecutor-8-0] INFO scm.ReconContainerManager: New container #3001 got from ha_dn1_1.ha_net.
recon_1  | 2022-07-31 01:21:41,891 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: New container #3001 got from ha_dn4_1.ha_net.
recon_1  | 2022-07-31 01:21:41,915 [FixedThreadPoolWithAffinityExecutor-8-0] INFO scm.ReconContainerManager: Successfully added container #3001 to Recon.
recon_1  | 2022-07-31 01:21:41,916 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: Successfully added container #3001 to Recon.
recon_1  | 2022-07-31 01:21:50,462 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #3002 got from ha_dn3_1.ha_net.
recon_1  | 2022-07-31 01:21:50,467 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: Successfully added container #3002 to Recon.
recon_1  | 2022-07-31 01:21:55,020 [FixedThreadPoolWithAffinityExecutor-8-0] INFO scm.ReconContainerManager: New container #3003 got from ha_dn1_1.ha_net.
recon_1  | 2022-07-31 01:21:55,025 [FixedThreadPoolWithAffinityExecutor-8-0] INFO scm.ReconContainerManager: Successfully added container #3003 to Recon.
dn5_1    | 2022-07-31 01:20:33,872 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn5_1    | 2022-07-31 01:20:33,872 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn5_1    | 2022-07-31 01:20:33,872 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn5_1    | 2022-07-31 01:20:33,873 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn5_1    | 2022-07-31 01:20:33,875 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn5_1    | 2022-07-31 01:20:33,875 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn5_1    | 2022-07-31 01:20:33,875 [pool-38-thread-1] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn5_1    | 2022-07-31 01:20:33,875 [pool-38-thread-1] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn5_1    | 2022-07-31 01:20:33,883 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn5_1    | 2022-07-31 01:20:33,883 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn5_1    | 2022-07-31 01:20:33,883 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn5_1    | 2022-07-31 01:20:33,883 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn5_1    | 2022-07-31 01:20:33,883 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn5_1    | 2022-07-31 01:20:33,883 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn5_1    | 2022-07-31 01:20:33,884 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn5_1    | 2022-07-31 01:20:33,884 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn5_1    | 2022-07-31 01:20:33,884 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn5_1    | 2022-07-31 01:20:33,884 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn5_1    | 2022-07-31 01:20:33,884 [pool-38-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn5_1    | 2022-07-31 01:20:33,884 [pool-38-thread-1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC: start as a follower, conf=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|priority:0], old=null
dn5_1    | 2022-07-31 01:20:33,884 [pool-38-thread-1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn5_1    | 2022-07-31 01:20:33,884 [pool-38-thread-1] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: start 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-FollowerState
dn5_1    | 2022-07-31 01:20:33,887 [pool-38-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4B35CFA778DC,id=52aca038-7576-46a0-9ccd-b8aed29078e2
dn5_1    | 2022-07-31 01:20:33,892 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=e19f4611-626e-4580-84ca-4b35cfa778dc
dn5_1    | 2022-07-31 01:20:34,230 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=e19f4611-626e-4580-84ca-4b35cfa778dc.
dn5_1    | 2022-07-31 01:20:38,894 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-FollowerState] INFO impl.FollowerState: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5060320727ns, electionTimeout:5053ms
dn5_1    | 2022-07-31 01:20:38,894 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-FollowerState] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: shutdown 52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-FollowerState
dn5_1    | 2022-07-31 01:20:38,894 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-FollowerState] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
dn5_1    | 2022-07-31 01:20:38,894 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn5_1    | 2022-07-31 01:20:38,894 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-FollowerState] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: start 52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-LeaderElection5
dn5_1    | 2022-07-31 01:20:38,900 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-LeaderElection5] INFO impl.LeaderElection: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-LeaderElection5 ELECTION round 0: submit vote requests at term 1 for -1: [52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|priority:1], old=null
dn5_1    | 2022-07-31 01:20:38,900 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-LeaderElection5] INFO impl.LeaderElection: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-LeaderElection5 ELECTION round 0: result PASSED (term=1)
dn5_1    | 2022-07-31 01:20:38,900 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-LeaderElection5] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: shutdown 52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-LeaderElection5
dn5_1    | 2022-07-31 01:20:38,900 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-LeaderElection5] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
dn5_1    | 2022-07-31 01:20:38,900 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-LeaderElection5] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-F5ADBE2EE252 with new leaderId: 52aca038-7576-46a0-9ccd-b8aed29078e2
dn5_1    | 2022-07-31 01:20:38,900 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-LeaderElection5] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252: change Leader from null to 52aca038-7576-46a0-9ccd-b8aed29078e2 at term 1 for becomeLeader, leader elected after 5083ms
dn5_1    | 2022-07-31 01:20:38,900 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn5_1    | 2022-07-31 01:20:38,901 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn5_1    | 2022-07-31 01:20:38,901 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn5_1    | 2022-07-31 01:20:38,901 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn5_1    | 2022-07-31 01:20:38,901 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn5_1    | 2022-07-31 01:20:38,901 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn5_1    | 2022-07-31 01:20:38,901 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn5_1    | 2022-07-31 01:20:38,901 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn5_1    | 2022-07-31 01:20:38,902 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-LeaderElection5] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: start 52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-LeaderStateImpl
dn5_1    | 2022-07-31 01:20:38,903 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-LeaderElection5] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-SegmentedRaftLogWorker: Starting segment from index:0
dn5_1    | 2022-07-31 01:20:38,907 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/9a50af78-96a4-4a72-b811-f5adbe2ee252/current/log_inprogress_0
dn5_1    | 2022-07-31 01:20:38,923 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252-LeaderElection5] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-F5ADBE2EE252: set configuration 0: [52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:1], old=null
dn5_1    | 2022-07-31 01:20:39,057 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-FollowerState] INFO impl.FollowerState: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5172268577ns, electionTimeout:5169ms
dn5_1    | 2022-07-31 01:20:39,057 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-FollowerState] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: shutdown 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-FollowerState
dn5_1    | 2022-07-31 01:20:39,057 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-FollowerState] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
dn5_1    | 2022-07-31 01:20:39,061 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn5_1    | 2022-07-31 01:20:39,061 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-FollowerState] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: start 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-LeaderElection6
dn5_1    | 2022-07-31 01:20:39,070 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-LeaderElection6] INFO impl.LeaderElection: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-LeaderElection6 ELECTION round 0: submit vote requests at term 1 for -1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|priority:0], old=null
dn5_1    | 2022-07-31 01:20:39,104 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-LeaderElection6] INFO impl.LeaderElection: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-LeaderElection6: ELECTION REJECTED received 2 response(s) and 0 exception(s):
dn5_1    | 2022-07-31 01:20:39,104 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-LeaderElection6] INFO impl.LeaderElection:   Response 0: 52aca038-7576-46a0-9ccd-b8aed29078e2<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:OK-t1
dn5_1    | 2022-07-31 01:20:39,104 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-LeaderElection6] INFO impl.LeaderElection:   Response 1: 52aca038-7576-46a0-9ccd-b8aed29078e2<-11cba143-91f8-47cb-8422-c32a1e2d51df#0:FAIL-t1
dn5_1    | 2022-07-31 01:20:39,104 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-LeaderElection6] INFO impl.LeaderElection: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-LeaderElection6 ELECTION round 0: result REJECTED
dn5_1    | 2022-07-31 01:20:39,104 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-LeaderElection6] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
dn5_1    | 2022-07-31 01:20:39,104 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-LeaderElection6] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: shutdown 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-LeaderElection6
dn5_1    | 2022-07-31 01:20:39,105 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-LeaderElection6] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: start 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-FollowerState
dn5_1    | 2022-07-31 01:20:44,199 [grpc-default-executor-4] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC: receive requestVote(ELECTION, 11cba143-91f8-47cb-8422-c32a1e2d51df, group-4B35CFA778DC, 2, (t:0, i:0))
dn5_1    | 2022-07-31 01:20:44,200 [grpc-default-executor-4] INFO impl.VoteContext: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-FOLLOWER: accept ELECTION from 11cba143-91f8-47cb-8422-c32a1e2d51df: our priority 0 <= candidate's priority 1
dn5_1    | 2022-07-31 01:20:44,200 [grpc-default-executor-4] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:11cba143-91f8-47cb-8422-c32a1e2d51df
dn5_1    | 2022-07-31 01:20:44,200 [grpc-default-executor-4] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: shutdown 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-FollowerState
dn5_1    | 2022-07-31 01:20:44,200 [grpc-default-executor-4] INFO impl.RoleInfo: 52aca038-7576-46a0-9ccd-b8aed29078e2: start 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-FollowerState
dn5_1    | 2022-07-31 01:20:44,200 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-FollowerState] INFO impl.FollowerState: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-FollowerState was interrupted
dn5_1    | 2022-07-31 01:20:44,207 [grpc-default-executor-4] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC replies to ELECTION vote request: 11cba143-91f8-47cb-8422-c32a1e2d51df<-52aca038-7576-46a0-9ccd-b8aed29078e2#0:OK-t2. Peer's state: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC:t2, leader=null, voted=11cba143-91f8-47cb-8422-c32a1e2d51df, raftlog=52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-SegmentedRaftLog:OPENED:c-1, conf=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|priority:0, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|priority:0], old=null
dn5_1    | 2022-07-31 01:20:44,294 [52aca038-7576-46a0-9ccd-b8aed29078e2-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-4B35CFA778DC with new leaderId: 11cba143-91f8-47cb-8422-c32a1e2d51df
dn4_1    | 2022-07-31 01:20:13,863 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn4_1    | 2022-07-31 01:20:13,863 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn4_1    | 2022-07-31 01:20:13,863 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
dn4_1    | 2022-07-31 01:20:13,864 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn4_1    | 2022-07-31 01:20:13,864 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn4_1    | 2022-07-31 01:20:13,864 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn4_1    | 2022-07-31 01:20:13,884 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: start 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderStateImpl
dn4_1    | 2022-07-31 01:20:13,889 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO segmented.SegmentedRaftLogWorker: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-SegmentedRaftLogWorker: Starting segment from index:0
dn4_1    | 2022-07-31 01:20:13,892 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/ae7040c6-f723-491f-8b9e-7781ffa9f9e7/current/log_inprogress_0
dn4_1    | 2022-07-31 01:20:13,921 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7-LeaderElection4] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-7781FFA9F9E7: set configuration 0: [310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn4_1    | 2022-07-31 01:20:14,236 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState] INFO impl.FollowerState: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5077200362ns, electionTimeout:5077ms
dn4_1    | 2022-07-31 01:20:14,237 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: shutdown 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState
dn4_1    | 2022-07-31 01:20:14,237 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
dn4_1    | 2022-07-31 01:20:14,237 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn4_1    | 2022-07-31 01:20:14,238 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: start 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection5
dn4_1    | 2022-07-31 01:20:14,240 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection5] INFO impl.LeaderElection: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection5 ELECTION round 0: submit vote requests at term 2 for -1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn4_1    | 2022-07-31 01:20:14,253 [grpc-default-executor-2] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0: receive requestVote(ELECTION, 609e7f2d-9474-472f-937f-8fa0a0bbb327, group-84A70A95B4C0, 2, (t:0, i:0))
dn4_1    | 2022-07-31 01:20:14,253 [grpc-default-executor-2] INFO impl.VoteContext: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-CANDIDATE: reject ELECTION from 609e7f2d-9474-472f-937f-8fa0a0bbb327: already has voted for 310a080d-f635-46ff-a53d-49cc9a09fa5c at current term 2
dn4_1    | 2022-07-31 01:20:14,258 [grpc-default-executor-2] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0 replies to ELECTION vote request: 609e7f2d-9474-472f-937f-8fa0a0bbb327<-310a080d-f635-46ff-a53d-49cc9a09fa5c#0:FAIL-t2. Peer's state: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0:t2, leader=null, voted=310a080d-f635-46ff-a53d-49cc9a09fa5c, raftlog=310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-SegmentedRaftLog:OPENED:c-1, conf=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn4_1    | 2022-07-31 01:20:14,286 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection5] INFO impl.LeaderElection: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection5: ELECTION REJECTED received 2 response(s) and 0 exception(s):
dn4_1    | 2022-07-31 01:20:14,288 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection5] INFO impl.LeaderElection:   Response 0: 310a080d-f635-46ff-a53d-49cc9a09fa5c<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:FAIL-t2
dn4_1    | 2022-07-31 01:20:14,288 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection5] INFO impl.LeaderElection:   Response 1: 310a080d-f635-46ff-a53d-49cc9a09fa5c<-609e7f2d-9474-472f-937f-8fa0a0bbb327#0:FAIL-t2
dn4_1    | 2022-07-31 01:20:14,288 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection5] INFO impl.LeaderElection: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection5 ELECTION round 0: result REJECTED
dn4_1    | 2022-07-31 01:20:14,289 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection5] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
dn4_1    | 2022-07-31 01:20:14,289 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection5] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: shutdown 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection5
dn4_1    | 2022-07-31 01:20:14,289 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection5] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: start 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState
dn4_1    | 2022-07-31 01:20:19,298 [grpc-default-executor-2] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0: receive requestVote(ELECTION, 609e7f2d-9474-472f-937f-8fa0a0bbb327, group-84A70A95B4C0, 3, (t:0, i:0))
dn4_1    | 2022-07-31 01:20:19,302 [grpc-default-executor-2] INFO impl.VoteContext: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FOLLOWER: accept ELECTION from 609e7f2d-9474-472f-937f-8fa0a0bbb327: our priority 0 <= candidate's priority 0
s3g_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
s3g_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1    | 2022-07-31 01:17:25,187 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1    | 2022-07-31 01:17:25,225 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
s3g_1    | 2022-07-31 01:17:25,685 [main] INFO util.log: Logging initialized @12153ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1    | 2022-07-31 01:17:26,765 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g_1    | 2022-07-31 01:17:26,999 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1    | 2022-07-31 01:17:27,086 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1    | 2022-07-31 01:17:27,101 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context s3gateway
s3g_1    | 2022-07-31 01:17:27,126 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
s3g_1    | 2022-07-31 01:17:27,132 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
s3g_1    | 2022-07-31 01:17:27,823 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1    | /************************************************************
s3g_1    | STARTUP_MSG: Starting Gateway
s3g_1    | STARTUP_MSG:   host = 0e6421787b73/10.9.0.21
s3g_1    | STARTUP_MSG:   args = []
s3g_1    | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
dn5_1    | 2022-07-31 01:20:44,294 [52aca038-7576-46a0-9ccd-b8aed29078e2-server-thread1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC: change Leader from null to 11cba143-91f8-47cb-8422-c32a1e2d51df at term 2 for appendEntries, leader elected after 10426ms
dn5_1    | 2022-07-31 01:20:44,323 [52aca038-7576-46a0-9ccd-b8aed29078e2-server-thread1] INFO server.RaftServer$Division: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC: set configuration 0: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:0, 11cba143-91f8-47cb-8422-c32a1e2d51df|rpc:10.9.0.16:9856|admin:10.9.0.16:9857|client:10.9.0.16:9858|dataStream:|priority:1, 52aca038-7576-46a0-9ccd-b8aed29078e2|rpc:10.9.0.19:9856|admin:10.9.0.19:9857|client:10.9.0.19:9858|dataStream:|priority:0], old=null
dn5_1    | 2022-07-31 01:20:44,324 [52aca038-7576-46a0-9ccd-b8aed29078e2-server-thread1] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-SegmentedRaftLogWorker: Starting segment from index:0
dn5_1    | 2022-07-31 01:20:44,325 [52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 52aca038-7576-46a0-9ccd-b8aed29078e2@group-4B35CFA778DC-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/e19f4611-626e-4580-84ca-4b35cfa778dc/current/log_inprogress_0
dn4_1    | 2022-07-31 01:20:19,302 [grpc-default-executor-2] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:609e7f2d-9474-472f-937f-8fa0a0bbb327
dn4_1    | 2022-07-31 01:20:19,302 [grpc-default-executor-2] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: shutdown 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState
dn4_1    | 2022-07-31 01:20:19,302 [grpc-default-executor-2] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: start 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState
dn4_1    | 2022-07-31 01:20:19,302 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState] INFO impl.FollowerState: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState was interrupted
dn4_1    | 2022-07-31 01:20:19,314 [grpc-default-executor-2] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0 replies to ELECTION vote request: 609e7f2d-9474-472f-937f-8fa0a0bbb327<-310a080d-f635-46ff-a53d-49cc9a09fa5c#0:OK-t3. Peer's state: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0:t3, leader=null, voted=609e7f2d-9474-472f-937f-8fa0a0bbb327, raftlog=310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-SegmentedRaftLog:OPENED:c-1, conf=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn4_1    | 2022-07-31 01:20:24,344 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState] INFO impl.FollowerState: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5029811055ns, electionTimeout:5029ms
dn4_1    | 2022-07-31 01:20:24,344 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: shutdown 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState
dn4_1    | 2022-07-31 01:20:24,344 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
dn4_1    | 2022-07-31 01:20:24,344 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn4_1    | 2022-07-31 01:20:24,344 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: start 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection6
dn4_1    | 2022-07-31 01:20:24,354 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection6] INFO impl.LeaderElection: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection6 ELECTION round 0: submit vote requests at term 4 for -1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn4_1    | 2022-07-31 01:20:24,390 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection6] INFO impl.LeaderElection: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection6: ELECTION REJECTED received 2 response(s) and 0 exception(s):
dn4_1    | 2022-07-31 01:20:24,391 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection6] INFO impl.LeaderElection:   Response 0: 310a080d-f635-46ff-a53d-49cc9a09fa5c<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:FAIL-t4
dn4_1    | 2022-07-31 01:20:24,391 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection6] INFO impl.LeaderElection:   Response 1: 310a080d-f635-46ff-a53d-49cc9a09fa5c<-609e7f2d-9474-472f-937f-8fa0a0bbb327#0:OK-t4
dn4_1    | 2022-07-31 01:20:24,391 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection6] INFO impl.LeaderElection: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection6 ELECTION round 0: result REJECTED
dn4_1    | 2022-07-31 01:20:24,391 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection6] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
dn4_1    | 2022-07-31 01:20:24,391 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection6] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: shutdown 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection6
dn4_1    | 2022-07-31 01:20:24,392 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection6] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: start 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState
dn4_1    | 2022-07-31 01:20:29,475 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState] INFO impl.FollowerState: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5083790508ns, electionTimeout:5079ms
dn4_1    | 2022-07-31 01:20:29,476 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: shutdown 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState
dn4_1    | 2022-07-31 01:20:29,476 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
dn4_1    | 2022-07-31 01:20:29,476 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn4_1    | 2022-07-31 01:20:29,476 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: start 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection7
dn4_1    | 2022-07-31 01:20:29,481 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection7] INFO impl.LeaderElection: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection7 ELECTION round 0: submit vote requests at term 5 for -1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn4_1    | 2022-07-31 01:20:29,511 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection7] INFO impl.LeaderElection: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection7: ELECTION REJECTED received 2 response(s) and 0 exception(s):
dn4_1    | 2022-07-31 01:20:29,511 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection7] INFO impl.LeaderElection:   Response 0: 310a080d-f635-46ff-a53d-49cc9a09fa5c<-3fc9f139-dd93-41e7-b235-52ce94d6fe3c#0:FAIL-t5
dn4_1    | 2022-07-31 01:20:29,511 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection7] INFO impl.LeaderElection:   Response 1: 310a080d-f635-46ff-a53d-49cc9a09fa5c<-609e7f2d-9474-472f-937f-8fa0a0bbb327#0:OK-t5
recon_1  | 2022-07-31 01:22:10,485 [pool-26-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1  | 2022-07-31 01:22:10,486 [pool-26-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1  | 2022-07-31 01:22:10,486 [pool-26-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 150 
recon_1  | 2022-07-31 01:22:10,501 [pool-26-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 10, SequenceNumber diff: 28, SequenceNumber Lag from OM 0.
recon_1  | 2022-07-31 01:22:10,501 [pool-26-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 28 records
recon_1  | 2022-07-31 01:22:10,504 [pool-46-thread-1] INFO tasks.NSSummaryTask: Completed a process run of NSSummaryTask
recon_1  | 2022-07-31 01:22:10,777 [pool-46-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1  | 2022-07-31 01:22:10,817 [pool-46-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 3 OM DB update event(s).
recon_1  | 2022-07-31 01:22:10,870 [pool-46-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1  | 2022-07-31 01:22:35,200 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: New container #3004 got from ha_dn2_1.ha_net.
recon_1  | 2022-07-31 01:22:35,217 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=3d8ba3cf-b534-4c5b-87ac-9fdeb6052515 not found. Cannot add container #3004
recon_1  | 2022-07-31 01:22:35,218 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconIncrementalContainerReportHandler: Container 3004 not found!
recon_1  | 2022-07-31 01:22:35,269 [FixedThreadPoolWithAffinityExecutor-8-0] INFO scm.ReconContainerManager: New container #3004 got from ha_dn1_1.ha_net.
recon_1  | 2022-07-31 01:22:35,273 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #3004 got from ha_dn3_1.ha_net.
recon_1  | 2022-07-31 01:22:35,278 [FixedThreadPoolWithAffinityExecutor-8-0] WARN scm.ReconContainerManager: Pipeline PipelineID=3d8ba3cf-b534-4c5b-87ac-9fdeb6052515 not found. Cannot add container #3004
recon_1  | 2022-07-31 01:22:35,278 [FixedThreadPoolWithAffinityExecutor-8-0] WARN scm.ReconIncrementalContainerReportHandler: Container 3004 not found!
recon_1  | 2022-07-31 01:22:35,281 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconContainerManager: Pipeline PipelineID=3d8ba3cf-b534-4c5b-87ac-9fdeb6052515 not found. Cannot add container #3004
recon_1  | 2022-07-31 01:22:35,281 [FixedThreadPoolWithAffinityExecutor-0-0] WARN scm.ReconIncrementalContainerReportHandler: Container 3004 not found!
recon_1  | 2022-07-31 01:22:35,459 [FixedThreadPoolWithAffinityExecutor-9-0] INFO scm.ReconContainerManager: New container #3004 got from ha_dn4_1.ha_net.
recon_1  | 2022-07-31 01:22:35,471 [FixedThreadPoolWithAffinityExecutor-9-0] WARN scm.ReconContainerManager: Pipeline PipelineID=3d8ba3cf-b534-4c5b-87ac-9fdeb6052515 not found. Cannot add container #3004
recon_1  | 2022-07-31 01:22:35,471 [FixedThreadPoolWithAffinityExecutor-9-0] WARN scm.ReconIncrementalContainerReportHandler: Container 3004 not found!
recon_1  | 2022-07-31 01:22:35,478 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: New container #3004 got from ha_dn5_1.ha_net.
recon_1  | 2022-07-31 01:22:35,482 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconContainerManager: Pipeline PipelineID=3d8ba3cf-b534-4c5b-87ac-9fdeb6052515 not found. Cannot add container #3004
recon_1  | 2022-07-31 01:22:35,482 [FixedThreadPoolWithAffinityExecutor-1-0] WARN scm.ReconIncrementalContainerReportHandler: Container 3004 not found!
s3g_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.13.2.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.33.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar
s3g_1    | STARTUP_MSG:   build = https://github.com/apache/ozone/57d620dbd4cb5dfec746cc16039d3843e64c181c ; compiled by 'runner' on 2022-07-31T00:52Z
s3g_1    | STARTUP_MSG:   java = 11.0.14.1
s3g_1    | ************************************************************/
s3g_1    | 2022-07-31 01:17:27,907 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1    | 2022-07-31 01:17:28,186 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1    | 2022-07-31 01:17:29,010 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1    | 2022-07-31 01:17:30,594 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1    | 2022-07-31 01:17:30,594 [main] INFO impl.MetricsSystemImpl: S3Gateway metrics system started
s3g_1    | 2022-07-31 01:17:31,018 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1    | 2022-07-31 01:17:31,040 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
s3g_1    | 2022-07-31 01:17:31,448 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1    | 2022-07-31 01:17:31,448 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1    | 2022-07-31 01:17:31,486 [main] INFO server.session: node0 Scavenging every 660000ms
s3g_1    | 2022-07-31 01:17:31,672 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@13d4992d{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1    | 2022-07-31 01:17:31,689 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6057aebb{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1    | WARNING: An illegal reflective access operation has occurred
s3g_1    | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1    | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1    | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1    | WARNING: All illegal access operations will be denied in a future release
s3g_1    | Jul 31, 2022 1:18:01 AM org.glassfish.jersey.internal.Errors logErrors
s3g_1    | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1    | 
dn4_1    | 2022-07-31 01:20:29,511 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection7] INFO impl.LeaderElection: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection7 ELECTION round 0: result REJECTED
dn4_1    | 2022-07-31 01:20:29,512 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection7] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0: changes role from CANDIDATE to FOLLOWER at term 5 for REJECTED
dn4_1    | 2022-07-31 01:20:29,512 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection7] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: shutdown 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection7
dn4_1    | 2022-07-31 01:20:29,512 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-LeaderElection7] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: start 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState
dn4_1    | 2022-07-31 01:20:33,539 [Command processor thread] INFO server.RaftServer: 310a080d-f635-46ff-a53d-49cc9a09fa5c: addNew group-18489625BC71:[310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1] returns group-18489625BC71:java.util.concurrent.CompletableFuture@7cdd5767[Not completed]
dn4_1    | 2022-07-31 01:20:33,543 [pool-26-thread-1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c: new RaftServerImpl for group-18489625BC71:[310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1] with ContainerStateMachine:uninitialized
dn4_1    | 2022-07-31 01:20:33,543 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn4_1    | 2022-07-31 01:20:33,543 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn4_1    | 2022-07-31 01:20:33,543 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn4_1    | 2022-07-31 01:20:33,543 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn4_1    | 2022-07-31 01:20:33,543 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn4_1    | 2022-07-31 01:20:33,543 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
dn4_1    | 2022-07-31 01:20:33,543 [pool-26-thread-1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71: ConfigurationManager, init=-1: [310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1], old=null, confs=<EMPTY_MAP>
dn4_1    | 2022-07-31 01:20:33,543 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn4_1    | 2022-07-31 01:20:33,543 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn4_1    | 2022-07-31 01:20:33,544 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
dn4_1    | 2022-07-31 01:20:33,544 [pool-26-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/6f4f1d7d-a1c2-4efd-bea9-18489625bc71 does not exist. Creating ...
dn4_1    | 2022-07-31 01:20:33,550 [pool-26-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/6f4f1d7d-a1c2-4efd-bea9-18489625bc71/in_use.lock acquired by nodename 6@6d05c26d6799
dn4_1    | 2022-07-31 01:20:33,553 [pool-26-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/6f4f1d7d-a1c2-4efd-bea9-18489625bc71 has been successfully formatted.
dn4_1    | 2022-07-31 01:20:33,553 [pool-26-thread-1] INFO ratis.ContainerStateMachine: group-18489625BC71: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn4_1    | 2022-07-31 01:20:33,553 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn4_1    | 2022-07-31 01:20:33,553 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn4_1    | 2022-07-31 01:20:33,553 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn4_1    | 2022-07-31 01:20:33,553 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn4_1    | 2022-07-31 01:20:33,553 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
dn4_1    | 2022-07-31 01:20:33,555 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn4_1    | 2022-07-31 01:20:33,556 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn4_1    | 2022-07-31 01:20:33,556 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
dn4_1    | 2022-07-31 01:20:33,556 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: new 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/6f4f1d7d-a1c2-4efd-bea9-18489625bc71
dn4_1    | 2022-07-31 01:20:33,556 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
dn4_1    | 2022-07-31 01:20:33,556 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn4_1    | 2022-07-31 01:20:33,556 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn4_1    | 2022-07-31 01:20:33,557 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn4_1    | 2022-07-31 01:20:33,557 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn4_1    | 2022-07-31 01:20:33,557 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn4_1    | 2022-07-31 01:20:33,557 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn4_1    | 2022-07-31 01:20:33,557 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn4_1    | 2022-07-31 01:20:33,558 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn4_1    | 2022-07-31 01:20:33,562 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
dn4_1    | 2022-07-31 01:20:33,562 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn4_1    | 2022-07-31 01:20:33,579 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn4_1    | 2022-07-31 01:20:33,579 [pool-26-thread-1] INFO segmented.SegmentedRaftLogWorker: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn4_1    | 2022-07-31 01:20:33,580 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn4_1    | 2022-07-31 01:20:33,580 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn4_1    | 2022-07-31 01:20:33,580 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn4_1    | 2022-07-31 01:20:33,580 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn4_1    | 2022-07-31 01:20:33,580 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
s3g_1    | 2022-07-31 01:18:01,881 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@61a704d3{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-ozone-s3gateway-1_3_0-SNAPSHOT_jar-_-any-6221141476882595822/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1    | 2022-07-31 01:18:02,012 [main] INFO server.AbstractConnector: Started ServerConnector@1984b1f{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1    | 2022-07-31 01:18:02,013 [main] INFO server.Server: Started @48521ms
s3g_1    | 2022-07-31 01:18:02,058 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
s3g_1    | 2022-07-31 01:18:02,060 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
s3g_1    | 2022-07-31 01:18:02,064 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
s3g_1    | 2022-07-31 01:20:58,918 [qtp1076641925-21] INFO audit.AuditLogger: Refresh DebugCmdSet for S3GAudit to [].
s3g_1    | 2022-07-31 01:20:58,938 [qtp1076641925-21] INFO audit.AuditLogger: Refresh DebugCmdSet for S3GAudit to [].
s3g_1    | 2022-07-31 01:20:58,942 [qtp1076641925-21] INFO ozone.OmUtils: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
s3g_1    | 2022-07-31 01:20:58,942 [qtp1076641925-21] INFO ozone.OmUtils: Using OzoneManager ServiceID 'omservice'.
s3g_1    | 2022-07-31 01:21:00,048 [qtp1076641925-21] WARN impl.MetricsSystemImpl: S3Gateway metrics system already initialized!
s3g_1    | 2022-07-31 01:21:53,899 [qtp1076641925-20] INFO rpc.RpcClient: Creating Bucket: s3v/new2-bucket, with server-side default bucket layout, dlfknslnfslf as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1    | 2022-07-31 01:21:54,838 [qtp1076641925-22] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
dn4_1    | 2022-07-31 01:20:33,581 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
dn4_1    | 2022-07-31 01:20:33,581 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn4_1    | 2022-07-31 01:20:33,583 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
dn4_1    | 2022-07-31 01:20:33,584 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
dn4_1    | 2022-07-31 01:20:33,584 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
dn4_1    | 2022-07-31 01:20:33,584 [pool-26-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
dn4_1    | 2022-07-31 01:20:33,584 [pool-26-thread-1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71: start as a follower, conf=-1: [310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1], old=null
dn4_1    | 2022-07-31 01:20:33,584 [pool-26-thread-1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn4_1    | 2022-07-31 01:20:33,584 [pool-26-thread-1] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: start 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-FollowerState
dn4_1    | 2022-07-31 01:20:33,589 [pool-26-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-18489625BC71,id=310a080d-f635-46ff-a53d-49cc9a09fa5c
dn4_1    | 2022-07-31 01:20:33,590 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=6f4f1d7d-a1c2-4efd-bea9-18489625bc71
dn4_1    | 2022-07-31 01:20:33,594 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=6f4f1d7d-a1c2-4efd-bea9-18489625bc71.
dn4_1    | 2022-07-31 01:20:34,590 [grpc-default-executor-2] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0: receive requestVote(ELECTION, 3fc9f139-dd93-41e7-b235-52ce94d6fe3c, group-84A70A95B4C0, 6, (t:0, i:0))
dn4_1    | 2022-07-31 01:20:34,591 [grpc-default-executor-2] INFO impl.VoteContext: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FOLLOWER: accept ELECTION from 3fc9f139-dd93-41e7-b235-52ce94d6fe3c: our priority 0 <= candidate's priority 1
dn4_1    | 2022-07-31 01:20:34,591 [grpc-default-executor-2] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0: changes role from  FOLLOWER to FOLLOWER at term 6 for candidate:3fc9f139-dd93-41e7-b235-52ce94d6fe3c
dn4_1    | 2022-07-31 01:20:34,591 [grpc-default-executor-2] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: shutdown 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState
dn4_1    | 2022-07-31 01:20:34,592 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState] INFO impl.FollowerState: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState was interrupted
dn4_1    | 2022-07-31 01:20:34,592 [grpc-default-executor-2] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: start 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-FollowerState
dn4_1    | 2022-07-31 01:20:34,595 [grpc-default-executor-2] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0 replies to ELECTION vote request: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c<-310a080d-f635-46ff-a53d-49cc9a09fa5c#0:OK-t6. Peer's state: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0:t6, leader=null, voted=3fc9f139-dd93-41e7-b235-52ce94d6fe3c, raftlog=310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-SegmentedRaftLog:OPENED:c-1, conf=-1: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn4_1    | 2022-07-31 01:20:34,656 [310a080d-f635-46ff-a53d-49cc9a09fa5c-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-84A70A95B4C0 with new leaderId: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c
dn4_1    | 2022-07-31 01:20:34,657 [310a080d-f635-46ff-a53d-49cc9a09fa5c-server-thread1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0: change Leader from null to 3fc9f139-dd93-41e7-b235-52ce94d6fe3c at term 6 for appendEntries, leader elected after 30510ms
dn4_1    | 2022-07-31 01:20:34,664 [310a080d-f635-46ff-a53d-49cc9a09fa5c-server-thread1] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0: set configuration 0: [3fc9f139-dd93-41e7-b235-52ce94d6fe3c|rpc:10.9.0.17:9856|admin:10.9.0.17:9857|client:10.9.0.17:9858|dataStream:|priority:1, 310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:0, 609e7f2d-9474-472f-937f-8fa0a0bbb327|rpc:10.9.0.15:9856|admin:10.9.0.15:9857|client:10.9.0.15:9858|dataStream:|priority:0], old=null
dn4_1    | 2022-07-31 01:20:34,664 [310a080d-f635-46ff-a53d-49cc9a09fa5c-server-thread1] INFO segmented.SegmentedRaftLogWorker: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-SegmentedRaftLogWorker: Starting segment from index:0
dn4_1    | 2022-07-31 01:20:34,666 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-84A70A95B4C0-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0/current/log_inprogress_0
dn4_1    | 2022-07-31 01:20:38,710 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-FollowerState] INFO impl.FollowerState: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5125460774ns, electionTimeout:5115ms
dn4_1    | 2022-07-31 01:20:38,710 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-FollowerState] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: shutdown 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-FollowerState
dn4_1    | 2022-07-31 01:20:38,711 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-FollowerState] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
dn4_1    | 2022-07-31 01:20:38,711 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
dn4_1    | 2022-07-31 01:20:38,711 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-FollowerState] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: start 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-LeaderElection8
dn4_1    | 2022-07-31 01:20:38,717 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-LeaderElection8] INFO impl.LeaderElection: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-LeaderElection8 ELECTION round 0: submit vote requests at term 1 for -1: [310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|priority:1], old=null
dn4_1    | 2022-07-31 01:20:38,718 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-LeaderElection8] INFO impl.LeaderElection: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-LeaderElection8 ELECTION round 0: result PASSED (term=1)
scm_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1    | 2022-07-31 01:17:33,817 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1    | /************************************************************
scm_1    | STARTUP_MSG: Starting StorageContainerManager
scm_1    | STARTUP_MSG:   host = 926e3436bad9/10.9.0.14
scm_1    | STARTUP_MSG:   args = []
scm_1    | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
dn4_1    | 2022-07-31 01:20:38,718 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-LeaderElection8] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: shutdown 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-LeaderElection8
dn4_1    | 2022-07-31 01:20:38,718 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-LeaderElection8] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
dn4_1    | 2022-07-31 01:20:38,718 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-LeaderElection8] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-18489625BC71 with new leaderId: 310a080d-f635-46ff-a53d-49cc9a09fa5c
dn4_1    | 2022-07-31 01:20:38,719 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-LeaderElection8] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71: change Leader from null to 310a080d-f635-46ff-a53d-49cc9a09fa5c at term 1 for becomeLeader, leader elected after 5165ms
dn4_1    | 2022-07-31 01:20:38,719 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-LeaderElection8] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn4_1    | 2022-07-31 01:20:38,725 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-LeaderElection8] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn4_1    | 2022-07-31 01:20:38,726 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-LeaderElection8] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
dn4_1    | 2022-07-31 01:20:38,726 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-LeaderElection8] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn4_1    | 2022-07-31 01:20:38,726 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-LeaderElection8] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn4_1    | 2022-07-31 01:20:38,726 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-LeaderElection8] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn4_1    | 2022-07-31 01:20:38,727 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-LeaderElection8] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn4_1    | 2022-07-31 01:20:38,727 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-LeaderElection8] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
dn4_1    | 2022-07-31 01:20:38,727 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-LeaderElection8] INFO impl.RoleInfo: 310a080d-f635-46ff-a53d-49cc9a09fa5c: start 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-LeaderStateImpl
dn4_1    | 2022-07-31 01:20:38,727 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-LeaderElection8] INFO segmented.SegmentedRaftLogWorker: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-SegmentedRaftLogWorker: Starting segment from index:0
dn4_1    | 2022-07-31 01:20:38,732 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-LeaderElection8] INFO server.RaftServer$Division: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71: set configuration 0: [310a080d-f635-46ff-a53d-49cc9a09fa5c|rpc:10.9.0.18:9856|admin:10.9.0.18:9857|client:10.9.0.18:9858|dataStream:|priority:1], old=null
dn4_1    | 2022-07-31 01:20:38,733 [310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 310a080d-f635-46ff-a53d-49cc9a09fa5c@group-18489625BC71-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/6f4f1d7d-a1c2-4efd-bea9-18489625bc71/current/log_inprogress_0
scm_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm_1    | STARTUP_MSG:   build = https://github.com/apache/ozone/57d620dbd4cb5dfec746cc16039d3843e64c181c ; compiled by 'runner' on 2022-07-31T00:51Z
scm_1    | STARTUP_MSG:   java = 11.0.14.1
scm_1    | ************************************************************/
scm_1    | 2022-07-31 01:17:34,026 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1    | 2022-07-31 01:17:34,906 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1    | 2022-07-31 01:17:35,642 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm_1    | 2022-07-31 01:17:36,484 [main] WARN ha.SCMHANodeDetails: Invalid config ozone.scm.ratis.enable. The config was not specified, but the default value true conflicts with the expected config value false. Falling back to the expected value. Current State of SCM: SCM is running in Non-HA without Ratis Ratis SCM -> Non Ratis SCM or Non HA SCM -> HA SCM is not supported
scm_1    | 2022-07-31 01:17:36,491 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm_1    | 2022-07-31 01:17:49,867 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1    | 2022-07-31 01:17:52,745 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1    | 2022-07-31 01:17:55,361 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm_1    | 2022-07-31 01:17:55,400 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1    | 2022-07-31 01:17:56,489 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm_1    | 2022-07-31 01:17:56,572 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = DATANODE_SCHEMA_V3 (version = 4)
scm_1    | 2022-07-31 01:18:00,909 [main] INFO reflections.Reflections: Reflections took 2032 ms to scan 3 urls, producing 109 keys and 246 values 
scm_1    | 2022-07-31 01:18:01,851 [main] INFO upgrade.HDDSLayoutVersionManager: Registering Upgrade Action : DatanodeSchemaV3FinalizeAction
scm_1    | 2022-07-31 01:18:02,176 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm_1    | 2022-07-31 01:18:02,634 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1    | 2022-07-31 01:18:02,782 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm_1    | 2022-07-31 01:18:02,795 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm_1    | 2022-07-31 01:18:03,497 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm_1    | 2022-07-31 01:18:03,509 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm_1    | 2022-07-31 01:18:03,523 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm_1    | 2022-07-31 01:18:03,553 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm_1    | 2022-07-31 01:18:03,589 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm_1    | 2022-07-31 01:18:03,604 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
scm_1    | 2022-07-31 01:18:03,618 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
scm_1    | 2022-07-31 01:18:03,633 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
scm_1    | 2022-07-31 01:18:03,847 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm_1    | 2022-07-31 01:18:04,069 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm_1    | 2022-07-31 01:18:04,356 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm_1    | 2022-07-31 01:18:04,614 [main] INFO UnderReplicatedQueueThread: Starting UnderReplicatedQueueThread Service.
scm_1    | 2022-07-31 01:18:04,649 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 5000ms after safemode exit
scm_1    | 2022-07-31 01:18:04,650 [main] INFO ha.SCMServiceManager: Registering service UnderReplicatedQueueThread.
scm_1    | 2022-07-31 01:18:04,652 [main] INFO OverReplicatedQueueThread: Starting OverReplicatedQueueThread Service.
scm_1    | 2022-07-31 01:18:04,670 [main] INFO ha.SCMServiceManager: Registering service OverReplicatedQueueThread.
scm_1    | 2022-07-31 01:18:04,670 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm_1    | 2022-07-31 01:18:04,883 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm_1    | 2022-07-31 01:18:04,945 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 3, healthy pipeline threshold count is 1
scm_1    | 2022-07-31 01:18:04,984 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 3, pipeline's with at least one datanode reported threshold count is 3
scm_1    | 2022-07-31 01:18:07,220 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm_1    | 2022-07-31 01:18:07,305 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1    | 2022-07-31 01:18:07,503 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1    | 2022-07-31 01:18:07,753 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm_1    | 2022-07-31 01:18:07,761 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1    | 2022-07-31 01:18:07,775 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1    | 2022-07-31 01:18:07,944 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm_1    | 2022-07-31 01:18:07,966 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1    | 2022-07-31 01:18:07,981 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1    | 2022-07-31 01:18:08,144 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
scm_1    | 2022-07-31 01:18:08,145 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm_1    | Container Balancer status:
scm_1    | Key                            Value
scm_1    | Running                        false
scm_1    | Container Balancer Configuration values:
scm_1    | Key                                                Value
scm_1    | Threshold                                          10
scm_1    | Max Datanodes to Involve per Iteration(percent)    20
scm_1    | Max Size to Move per Iteration                     500GB
scm_1    | Max Size Entering Target per Iteration             26GB
scm_1    | Max Size Leaving Source per Iteration              26GB
scm_1    | 
scm_1    | 2022-07-31 01:18:08,146 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm_1    | 2022-07-31 01:18:08,146 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm_1    | 2022-07-31 01:18:08,151 [Listener at 0.0.0.0/9860] INFO upgrade.UpgradeFinalizer: Running pre-finalized state validations for unfinalized layout features.
scm_1    | 2022-07-31 01:18:08,155 [Listener at 0.0.0.0/9860] INFO upgrade.UpgradeFinalizer: Running first upgrade commands for unfinalized layout features.
scm_1    | 2022-07-31 01:18:08,158 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1    | 2022-07-31 01:18:08,332 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1    | 2022-07-31 01:18:08,365 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1    | 2022-07-31 01:18:08,365 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1    | 2022-07-31 01:18:08,874 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1    | 2022-07-31 01:18:08,877 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1    | 2022-07-31 01:18:08,878 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1    | 2022-07-31 01:18:08,906 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1    | 2022-07-31 01:18:08,919 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1    | 2022-07-31 01:18:08,920 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1    | 2022-07-31 01:18:08,956 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1    | 2022-07-31 01:18:09,004 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1    | 2022-07-31 01:18:09,052 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm_1    | 2022-07-31 01:18:09,061 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1    | 2022-07-31 01:18:09,167 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@67332b1e] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1    | 2022-07-31 01:18:09,213 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm_1    | 2022-07-31 01:18:09,213 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
scm_1    | 2022-07-31 01:18:09,296 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @54174ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1    | 2022-07-31 01:18:09,796 [Listener at 0.0.0.0/9860] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1    | 2022-07-31 01:18:09,884 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1    | 2022-07-31 01:18:10,150 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1    | 2022-07-31 01:18:10,252 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
scm_1    | 2022-07-31 01:18:10,253 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
scm_1    | 2022-07-31 01:18:10,265 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
scm_1    | 2022-07-31 01:18:10,964 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm_1    | 2022-07-31 01:18:10,966 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm_1    | 2022-07-31 01:18:11,238 [IPC Server handler 86 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/310a080d-f635-46ff-a53d-49cc9a09fa5c
scm_1    | 2022-07-31 01:18:11,334 [IPC Server handler 86 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
scm_1    | 2022-07-31 01:18:11,334 [IPC Server handler 0 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/11cba143-91f8-47cb-8422-c32a1e2d51df
scm_1    | 2022-07-31 01:18:11,382 [IPC Server handler 0 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
scm_1    | 2022-07-31 01:18:11,605 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1    | 2022-07-31 01:18:11,669 [IPC Server handler 4 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/609e7f2d-9474-472f-937f-8fa0a0bbb327
scm_1    | 2022-07-31 01:18:11,672 [IPC Server handler 4 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
scm_1    | 2022-07-31 01:18:11,606 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm_1    | 2022-07-31 01:18:11,705 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm_1    | 2022-07-31 01:18:11,629 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Pipelines with at least one datanode reported count is 2, required at least one datanode reported per pipeline count is 3
scm_1    | 2022-07-31 01:18:11,709 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Pipelines with at least one datanode reported count is 3, required at least one datanode reported per pipeline count is 3
scm_1    | 2022-07-31 01:18:11,721 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1    | 2022-07-31 01:18:11,735 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm_1    | 2022-07-31 01:18:11,736 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1    | 2022-07-31 01:18:11,736 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm_1    | 2022-07-31 01:18:11,762 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1    | 2022-07-31 01:18:11,778 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm_1    | 2022-07-31 01:18:11,737 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm_1    | 2022-07-31 01:18:11,714 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1    | 2022-07-31 01:18:11,801 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
scm_1    | 2022-07-31 01:18:11,779 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm_1    | 2022-07-31 01:18:11,844 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1    | 2022-07-31 01:18:11,845 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1    | 2022-07-31 01:18:11,845 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1    | 2022-07-31 01:18:11,845 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1    | 2022-07-31 01:18:11,846 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1    | 2022-07-31 01:18:11,926 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1    | 2022-07-31 01:18:11,944 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@e5c2463{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1    | 2022-07-31 01:18:11,957 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@59303963{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1    | 2022-07-31 01:18:12,136 [IPC Server handler 56 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/52aca038-7576-46a0-9ccd-b8aed29078e2
scm_1    | 2022-07-31 01:18:12,136 [IPC Server handler 56 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 52aca038-7576-46a0-9ccd-b8aed29078e2{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
scm_1    | 2022-07-31 01:18:12,166 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm_1    | 2022-07-31 01:18:12,168 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1    | 2022-07-31 01:18:12,169 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1    | 2022-07-31 01:18:12,169 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm_1    | 2022-07-31 01:18:12,171 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm_1    | 2022-07-31 01:18:12,172 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm_1    | 2022-07-31 01:18:12,167 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1    | 2022-07-31 01:18:12,180 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
scm_1    | 2022-07-31 01:18:12,181 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO BackgroundPipelineScrubber: Service BackgroundPipelineScrubber transitions to RUNNING.
scm_1    | 2022-07-31 01:18:12,188 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ExpiredContainerReplicaOpScrubber: Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
scm_1    | 2022-07-31 01:18:12,191 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO UnderReplicatedQueueThread: Service UnderReplicatedQueueThread transitions to RUNNING.
scm_1    | 2022-07-31 01:18:12,194 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO OverReplicatedQueueThread: Service OverReplicatedQueueThread transitions to RUNNING.
scm_1    | 2022-07-31 01:18:12,199 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO replication.ReplicationManager: Service ReplicationManager transitions to RUNNING.
scm_1    | 2022-07-31 01:18:12,200 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
scm_1    | 2022-07-31 01:18:12,667 [IPC Server handler 86 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/3fc9f139-dd93-41e7-b235-52ce94d6fe3c
scm_1    | 2022-07-31 01:18:12,671 [IPC Server handler 86 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
scm_1    | 2022-07-31 01:18:12,671 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1    | 2022-07-31 01:18:13,239 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@13cc0b90{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-3346501228324608869/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm_1    | 2022-07-31 01:18:13,304 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@62ade015{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm_1    | 2022-07-31 01:18:13,305 [Listener at 0.0.0.0/9860] INFO server.Server: Started @58183ms
scm_1    | 2022-07-31 01:18:13,328 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1    | 2022-07-31 01:18:13,328 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1    | 2022-07-31 01:18:13,330 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm_1    | 2022-07-31 01:18:34,652 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1    | 2022-07-31 01:18:34,680 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1    | 2022-07-31 01:18:43,750 [IPC Server handler 6 on default port 9860] INFO upgrade.UpgradeFinalizer: Finalization started.
scm_1    | 2022-07-31 01:18:43,752 [IPC Server handler 6 on default port 9860] INFO pipeline.BackgroundPipelineCreator: Stopping RatisPipelineUtilsThread.
scm_1    | 2022-07-31 01:18:43,752 [RatisPipelineUtilsThread - 0] WARN pipeline.BackgroundPipelineCreator: RatisPipelineUtilsThread is interrupted.
scm_1    | 2022-07-31 01:18:43,753 [IPC Server handler 6 on default port 9860] INFO upgrade.UpgradeFinalizer: SCM Finalization has crossed checkpoint FINALIZATION_STARTED
scm_1    | 2022-07-31 01:18:43,756 [IPC Server handler 6 on default port 9860] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: c57ff3c1-98cc-4640-a639-ffc093016e58, Nodes: 609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:609e7f2d-9474-472f-937f-8fa0a0bbb327, CreationTimestamp2022-07-31T01:18:03.409753Z[UTC]] moved to CLOSED state
scm_1    | 2022-07-31 01:18:43,757 [IPC Server handler 6 on default port 9860] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: c06adbe4-99b1-4236-a662-b3503d3184bf, Nodes: 310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:310a080d-f635-46ff-a53d-49cc9a09fa5c, CreationTimestamp2022-07-31T01:18:03.409502Z[UTC]] moved to CLOSED state
scm_1    | 2022-07-31 01:18:43,766 [IPC Server handler 6 on default port 9860] INFO pipeline.PipelineManagerImpl: Container #1001 closed for pipeline=PipelineID=369e0910-4276-41cc-941b-75041c4aa246
scm_1    | 2022-07-31 01:18:43,767 [IPC Server handler 6 on default port 9860] INFO pipeline.PipelineManagerImpl: Container #2002 closed for pipeline=PipelineID=369e0910-4276-41cc-941b-75041c4aa246
scm_1    | 2022-07-31 01:18:43,769 [IPC Server handler 6 on default port 9860] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 369e0910-4276-41cc-941b-75041c4aa246, Nodes: 11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:3fc9f139-dd93-41e7-b235-52ce94d6fe3c, CreationTimestamp2022-07-31T01:18:03.392031Z[UTC]] moved to CLOSED state
scm_1    | 2022-07-31 01:18:43,769 [IPC Server handler 6 on default port 9860] INFO pipeline.PipelineManagerImpl: Container #1 closed for pipeline=PipelineID=67b1342c-3bb3-4b48-a218-65a101075af1
scm_1    | 2022-07-31 01:18:43,770 [IPC Server handler 6 on default port 9860] INFO pipeline.PipelineManagerImpl: Container #1002 closed for pipeline=PipelineID=67b1342c-3bb3-4b48-a218-65a101075af1
scm_1    | 2022-07-31 01:18:43,770 [IPC Server handler 6 on default port 9860] INFO pipeline.PipelineManagerImpl: Container #2003 closed for pipeline=PipelineID=67b1342c-3bb3-4b48-a218-65a101075af1
scm_1    | 2022-07-31 01:18:43,771 [IPC Server handler 6 on default port 9860] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 67b1342c-3bb3-4b48-a218-65a101075af1, Nodes: 52aca038-7576-46a0-9ccd-b8aed29078e2{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:609e7f2d-9474-472f-937f-8fa0a0bbb327, CreationTimestamp2022-07-31T01:18:03.392459Z[UTC]] moved to CLOSED state
scm_1    | 2022-07-31 01:18:43,774 [IPC Server handler 6 on default port 9860] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 106ad38c-cb28-4e98-a52d-cd003ecc1eed, Nodes: 52aca038-7576-46a0-9ccd-b8aed29078e2{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:52aca038-7576-46a0-9ccd-b8aed29078e2, CreationTimestamp2022-07-31T01:18:03.368326Z[UTC]] moved to CLOSED state
scm_1    | 2022-07-31 01:18:43,775 [IPC Server handler 6 on default port 9860] INFO pipeline.PipelineManagerImpl: Container #2001 closed for pipeline=PipelineID=b88205de-97a2-4448-8e49-7bb2a1276610
scm_1    | 2022-07-31 01:18:43,776 [IPC Server handler 6 on default port 9860] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: b88205de-97a2-4448-8e49-7bb2a1276610, Nodes: 310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}52aca038-7576-46a0-9ccd-b8aed29078e2{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:52aca038-7576-46a0-9ccd-b8aed29078e2, CreationTimestamp2022-07-31T01:18:03.393190Z[UTC]] moved to CLOSED state
scm_1    | 2022-07-31 01:18:43,779 [IPC Server handler 6 on default port 9860] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 8145371a-b336-4e64-a95d-6999419922eb, Nodes: 11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:11cba143-91f8-47cb-8422-c32a1e2d51df, CreationTimestamp2022-07-31T01:18:03.392862Z[UTC]] moved to CLOSED state
scm_1    | 2022-07-31 01:18:43,780 [IPC Server handler 6 on default port 9860] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 69ee0657-77f1-4021-b38b-039bb00381b6, Nodes: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:3fc9f139-dd93-41e7-b235-52ce94d6fe3c, CreationTimestamp2022-07-31T01:18:03.392667Z[UTC]] moved to CLOSED state
scm_1    | 2022-07-31 01:18:43,780 [IPC Server handler 6 on default port 9860] INFO upgrade.UpgradeFinalizer:   Existing pipelines and containers will be closed during Upgrade.
scm_1    |   New pipelines creation will remain frozen until Upgrade is finalized.
scm_1    | 2022-07-31 01:18:43,781 [IPC Server handler 6 on default port 9860] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: ERASURE_CODED_STORAGE_SUPPORT.
scm_1    | 2022-07-31 01:18:43,785 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #1001
scm_1    | 2022-07-31 01:18:43,801 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #2002
scm_1    | 2022-07-31 01:18:43,801 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #1
scm_1    | 2022-07-31 01:18:43,802 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #1002
scm_1    | 2022-07-31 01:18:43,802 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #2003
scm_1    | 2022-07-31 01:18:43,802 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #2001
scm_1    | 2022-07-31 01:18:43,811 [IPC Server handler 6 on default port 9860] INFO upgrade.AbstractLayoutVersionManager: Layout feature ERASURE_CODED_STORAGE_SUPPORT has been finalized.
scm_1    | 2022-07-31 01:18:43,812 [IPC Server handler 6 on default port 9860] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: DATANODE_SCHEMA_V3.
scm_1    | 2022-07-31 01:18:43,813 [IPC Server handler 6 on default port 9860] INFO upgrade.AbstractLayoutVersionManager: Layout feature DATANODE_SCHEMA_V3 has been finalized.
scm_1    | 2022-07-31 01:18:43,813 [IPC Server handler 6 on default port 9860] INFO upgrade.AbstractLayoutVersionManager: Finalization is complete.
scm_1    | 2022-07-31 01:18:43,815 [IPC Server handler 6 on default port 9860] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm_1    | 2022-07-31 01:18:43,815 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Datanode 11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to HEALTHY READONLY state.
scm_1    | 2022-07-31 01:18:43,816 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=369e0910-4276-41cc-941b-75041c4aa246 in state CLOSED which uses HEALTHY_READONLY datanode 11cba143-91f8-47cb-8422-c32a1e2d51df. This will send close commands for its containers.
scm_1    | 2022-07-31 01:18:43,816 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=67b1342c-3bb3-4b48-a218-65a101075af1 in state CLOSED which uses HEALTHY_READONLY datanode 11cba143-91f8-47cb-8422-c32a1e2d51df. This will send close commands for its containers.
scm_1    | 2022-07-31 01:18:43,816 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=8145371a-b336-4e64-a95d-6999419922eb in state CLOSED which uses HEALTHY_READONLY datanode 11cba143-91f8-47cb-8422-c32a1e2d51df. This will send close commands for its containers.
scm_1    | 2022-07-31 01:18:43,816 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Datanode 52aca038-7576-46a0-9ccd-b8aed29078e2{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to HEALTHY READONLY state.
scm_1    | 2022-07-31 01:18:43,817 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=67b1342c-3bb3-4b48-a218-65a101075af1 in state CLOSED which uses HEALTHY_READONLY datanode 52aca038-7576-46a0-9ccd-b8aed29078e2. This will send close commands for its containers.
scm_1    | 2022-07-31 01:18:43,817 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=106ad38c-cb28-4e98-a52d-cd003ecc1eed in state CLOSED which uses HEALTHY_READONLY datanode 52aca038-7576-46a0-9ccd-b8aed29078e2. This will send close commands for its containers.
scm_1    | 2022-07-31 01:18:43,817 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=b88205de-97a2-4448-8e49-7bb2a1276610 in state CLOSED which uses HEALTHY_READONLY datanode 52aca038-7576-46a0-9ccd-b8aed29078e2. This will send close commands for its containers.
scm_1    | 2022-07-31 01:18:43,817 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Datanode 3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to HEALTHY READONLY state.
scm_1    | 2022-07-31 01:18:43,817 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=369e0910-4276-41cc-941b-75041c4aa246 in state CLOSED which uses HEALTHY_READONLY datanode 3fc9f139-dd93-41e7-b235-52ce94d6fe3c. This will send close commands for its containers.
scm_1    | 2022-07-31 01:18:43,817 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=b88205de-97a2-4448-8e49-7bb2a1276610 in state CLOSED which uses HEALTHY_READONLY datanode 3fc9f139-dd93-41e7-b235-52ce94d6fe3c. This will send close commands for its containers.
scm_1    | 2022-07-31 01:18:43,824 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=69ee0657-77f1-4021-b38b-039bb00381b6 in state CLOSED which uses HEALTHY_READONLY datanode 3fc9f139-dd93-41e7-b235-52ce94d6fe3c. This will send close commands for its containers.
scm_1    | 2022-07-31 01:18:43,826 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Datanode 310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to HEALTHY READONLY state.
scm_1    | 2022-07-31 01:18:43,826 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=c06adbe4-99b1-4236-a662-b3503d3184bf in state CLOSED which uses HEALTHY_READONLY datanode 310a080d-f635-46ff-a53d-49cc9a09fa5c. This will send close commands for its containers.
scm_1    | 2022-07-31 01:18:43,826 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=b88205de-97a2-4448-8e49-7bb2a1276610 in state CLOSED which uses HEALTHY_READONLY datanode 310a080d-f635-46ff-a53d-49cc9a09fa5c. This will send close commands for its containers.
scm_1    | 2022-07-31 01:18:43,826 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Datanode 609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to HEALTHY READONLY state.
scm_1    | 2022-07-31 01:18:43,827 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=c57ff3c1-98cc-4640-a639-ffc093016e58 in state CLOSED which uses HEALTHY_READONLY datanode 609e7f2d-9474-472f-937f-8fa0a0bbb327. This will send close commands for its containers.
scm_1    | 2022-07-31 01:18:43,827 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=369e0910-4276-41cc-941b-75041c4aa246 in state CLOSED which uses HEALTHY_READONLY datanode 609e7f2d-9474-472f-937f-8fa0a0bbb327. This will send close commands for its containers.
scm_1    | 2022-07-31 01:18:43,829 [EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=67b1342c-3bb3-4b48-a218-65a101075af1 in state CLOSED which uses HEALTHY_READONLY datanode 609e7f2d-9474-472f-937f-8fa0a0bbb327. This will send close commands for its containers.
scm_1    | 2022-07-31 01:18:43,829 [IPC Server handler 6 on default port 9860] INFO upgrade.UpgradeFinalizer: SCM Finalization has crossed checkpoint MLV_EQUALS_SLV
scm_1    | 2022-07-31 01:18:43,829 [IPC Server handler 6 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-07-31 01:18:43,832 [RatisPipelineUtilsThread - 0] ERROR scm.SCMCommonPlacementPolicy: Unable to find enough nodes that meet the space requirement of 1073741824 bytes for metadata and 1073741824 bytes for data in healthy node set. Required 3. Found 0.
scm_1    | 2022-07-31 01:18:45,602 [IPC Server handler 3 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:18:45,954 [IPC Server handler 9 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:18:46,625 [IPC Server handler 3 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:18:46,959 [IPC Server handler 9 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:18:47,004 [IPC Server handler 11 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:18:47,020 [IPC Server handler 15 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:18:47,049 [IPC Server handler 6 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:18:47,056 [IPC Server handler 47 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:18:48,830 [IPC Server handler 6 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-07-31 01:18:53,830 [IPC Server handler 6 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-07-31 01:18:58,831 [IPC Server handler 6 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-07-31 01:19:00,223 [IPC Server handler 56 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:00,538 [IPC Server handler 3 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:00,569 [IPC Server handler 4 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:01,222 [IPC Server handler 56 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:01,477 [IPC Server handler 3 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:01,506 [IPC Server handler 4 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:01,507 [FixedThreadPoolWithAffinityExecutor-0-0] INFO container.IncrementalContainerReportHandler: Moving container #1001 to CLOSED state, datanode 3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm_1    | 2022-07-31 01:19:01,557 [IPC Server handler 2 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:01,630 [IPC Server handler 1 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:01,644 [IPC Server handler 5 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:01,689 [IPC Server handler 9 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:01,716 [IPC Server handler 11 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:01,787 [IPC Server handler 15 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:01,788 [FixedThreadPoolWithAffinityExecutor-9-0] INFO container.IncrementalContainerReportHandler: Moving container #2002 to CLOSED state, datanode 3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm_1    | 2022-07-31 01:19:01,815 [IPC Server handler 6 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:01,837 [IPC Server handler 47 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:01,845 [IPC Server handler 46 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:01,868 [IPC Server handler 19 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:01,899 [IPC Server handler 21 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:01,964 [IPC Server handler 20 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:01,996 [IPC Server handler 18 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:02,043 [IPC Server handler 7 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:02,045 [FixedThreadPoolWithAffinityExecutor-9-0] INFO container.IncrementalContainerReportHandler: Moving container #1 to CLOSED state, datanode 11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm_1    | 2022-07-31 01:19:02,158 [IPC Server handler 64 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:02,181 [IPC Server handler 93 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:02,307 [IPC Server handler 3 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:02,308 [FixedThreadPoolWithAffinityExecutor-1-0] INFO container.IncrementalContainerReportHandler: Moving container #2001 to CLOSED state, datanode 3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm_1    | 2022-07-31 01:19:02,342 [IPC Server handler 4 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:02,344 [FixedThreadPoolWithAffinityExecutor-9-0] INFO container.IncrementalContainerReportHandler: Moving container #1002 to CLOSED state, datanode 11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm_1    | 2022-07-31 01:19:02,364 [IPC Server handler 2 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:02,416 [IPC Server handler 1 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:02,475 [IPC Server handler 5 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:02,489 [IPC Server handler 9 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:02,504 [IPC Server handler 11 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:02,505 [FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Moving container #2003 to CLOSED state, datanode 11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm_1    | 2022-07-31 01:19:02,536 [IPC Server handler 15 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:02,547 [IPC Server handler 6 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:02,631 [IPC Server handler 47 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:02,695 [IPC Server handler 46 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:03,617 [BackgroundPipelineScrubberThread] INFO pipeline.PipelineManagerImpl: Scrubbing pipeline: id: PipelineID=c57ff3c1-98cc-4640-a639-ffc093016e58 since it stays at CLOSED stage.
scm_1    | 2022-07-31 01:19:03,619 [BackgroundPipelineScrubberThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=c57ff3c1-98cc-4640-a639-ffc093016e58 close command to datanode 609e7f2d-9474-472f-937f-8fa0a0bbb327
scm_1    | 2022-07-31 01:19:03,621 [BackgroundPipelineScrubberThread] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: c57ff3c1-98cc-4640-a639-ffc093016e58, Nodes: 609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:609e7f2d-9474-472f-937f-8fa0a0bbb327, CreationTimestamp2022-07-31T01:18:03.409753Z[UTC]] removed.
scm_1    | 2022-07-31 01:19:03,621 [BackgroundPipelineScrubberThread] INFO pipeline.PipelineManagerImpl: Scrubbing pipeline: id: PipelineID=c06adbe4-99b1-4236-a662-b3503d3184bf since it stays at CLOSED stage.
scm_1    | 2022-07-31 01:19:03,622 [BackgroundPipelineScrubberThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=c06adbe4-99b1-4236-a662-b3503d3184bf close command to datanode 310a080d-f635-46ff-a53d-49cc9a09fa5c
scm_1    | 2022-07-31 01:19:03,622 [BackgroundPipelineScrubberThread] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: c06adbe4-99b1-4236-a662-b3503d3184bf, Nodes: 310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:310a080d-f635-46ff-a53d-49cc9a09fa5c, CreationTimestamp2022-07-31T01:18:03.409502Z[UTC]] removed.
scm_1    | 2022-07-31 01:19:03,622 [BackgroundPipelineScrubberThread] INFO pipeline.PipelineManagerImpl: Scrubbing pipeline: id: PipelineID=369e0910-4276-41cc-941b-75041c4aa246 since it stays at CLOSED stage.
scm_1    | 2022-07-31 01:19:03,622 [BackgroundPipelineScrubberThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=369e0910-4276-41cc-941b-75041c4aa246 close command to datanode 11cba143-91f8-47cb-8422-c32a1e2d51df
scm_1    | 2022-07-31 01:19:03,622 [BackgroundPipelineScrubberThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=369e0910-4276-41cc-941b-75041c4aa246 close command to datanode 609e7f2d-9474-472f-937f-8fa0a0bbb327
scm_1    | 2022-07-31 01:19:03,622 [BackgroundPipelineScrubberThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=369e0910-4276-41cc-941b-75041c4aa246 close command to datanode 3fc9f139-dd93-41e7-b235-52ce94d6fe3c
scm_1    | 2022-07-31 01:19:03,622 [BackgroundPipelineScrubberThread] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: 369e0910-4276-41cc-941b-75041c4aa246, Nodes: 11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:3fc9f139-dd93-41e7-b235-52ce94d6fe3c, CreationTimestamp2022-07-31T01:18:03.392031Z[UTC]] removed.
scm_1    | 2022-07-31 01:19:03,623 [BackgroundPipelineScrubberThread] INFO pipeline.PipelineManagerImpl: Scrubbing pipeline: id: PipelineID=67b1342c-3bb3-4b48-a218-65a101075af1 since it stays at CLOSED stage.
scm_1    | 2022-07-31 01:19:03,623 [BackgroundPipelineScrubberThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=67b1342c-3bb3-4b48-a218-65a101075af1 close command to datanode 52aca038-7576-46a0-9ccd-b8aed29078e2
scm_1    | 2022-07-31 01:19:03,623 [BackgroundPipelineScrubberThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=67b1342c-3bb3-4b48-a218-65a101075af1 close command to datanode 609e7f2d-9474-472f-937f-8fa0a0bbb327
scm_1    | 2022-07-31 01:19:03,623 [BackgroundPipelineScrubberThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=67b1342c-3bb3-4b48-a218-65a101075af1 close command to datanode 11cba143-91f8-47cb-8422-c32a1e2d51df
scm_1    | 2022-07-31 01:19:03,623 [BackgroundPipelineScrubberThread] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: 67b1342c-3bb3-4b48-a218-65a101075af1, Nodes: 52aca038-7576-46a0-9ccd-b8aed29078e2{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:609e7f2d-9474-472f-937f-8fa0a0bbb327, CreationTimestamp2022-07-31T01:18:03.392459Z[UTC]] removed.
scm_1    | 2022-07-31 01:19:03,623 [BackgroundPipelineScrubberThread] INFO pipeline.PipelineManagerImpl: Scrubbing pipeline: id: PipelineID=106ad38c-cb28-4e98-a52d-cd003ecc1eed since it stays at CLOSED stage.
scm_1    | 2022-07-31 01:19:03,623 [BackgroundPipelineScrubberThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=106ad38c-cb28-4e98-a52d-cd003ecc1eed close command to datanode 52aca038-7576-46a0-9ccd-b8aed29078e2
scm_1    | 2022-07-31 01:19:03,624 [BackgroundPipelineScrubberThread] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: 106ad38c-cb28-4e98-a52d-cd003ecc1eed, Nodes: 52aca038-7576-46a0-9ccd-b8aed29078e2{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:52aca038-7576-46a0-9ccd-b8aed29078e2, CreationTimestamp2022-07-31T01:18:03.368326Z[UTC]] removed.
scm_1    | 2022-07-31 01:19:03,624 [BackgroundPipelineScrubberThread] INFO pipeline.PipelineManagerImpl: Scrubbing pipeline: id: PipelineID=b88205de-97a2-4448-8e49-7bb2a1276610 since it stays at CLOSED stage.
scm_1    | 2022-07-31 01:19:03,624 [BackgroundPipelineScrubberThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b88205de-97a2-4448-8e49-7bb2a1276610 close command to datanode 310a080d-f635-46ff-a53d-49cc9a09fa5c
scm_1    | 2022-07-31 01:19:03,624 [BackgroundPipelineScrubberThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b88205de-97a2-4448-8e49-7bb2a1276610 close command to datanode 3fc9f139-dd93-41e7-b235-52ce94d6fe3c
scm_1    | 2022-07-31 01:19:03,624 [BackgroundPipelineScrubberThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b88205de-97a2-4448-8e49-7bb2a1276610 close command to datanode 52aca038-7576-46a0-9ccd-b8aed29078e2
scm_1    | 2022-07-31 01:19:03,624 [BackgroundPipelineScrubberThread] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: b88205de-97a2-4448-8e49-7bb2a1276610, Nodes: 310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}52aca038-7576-46a0-9ccd-b8aed29078e2{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:52aca038-7576-46a0-9ccd-b8aed29078e2, CreationTimestamp2022-07-31T01:18:03.393190Z[UTC]] removed.
scm_1    | 2022-07-31 01:19:03,624 [BackgroundPipelineScrubberThread] INFO pipeline.PipelineManagerImpl: Scrubbing pipeline: id: PipelineID=8145371a-b336-4e64-a95d-6999419922eb since it stays at CLOSED stage.
scm_1    | 2022-07-31 01:19:03,625 [BackgroundPipelineScrubberThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=8145371a-b336-4e64-a95d-6999419922eb close command to datanode 11cba143-91f8-47cb-8422-c32a1e2d51df
scm_1    | 2022-07-31 01:19:03,625 [BackgroundPipelineScrubberThread] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: 8145371a-b336-4e64-a95d-6999419922eb, Nodes: 11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:11cba143-91f8-47cb-8422-c32a1e2d51df, CreationTimestamp2022-07-31T01:18:03.392862Z[UTC]] removed.
scm_1    | 2022-07-31 01:19:03,625 [BackgroundPipelineScrubberThread] INFO pipeline.PipelineManagerImpl: Scrubbing pipeline: id: PipelineID=69ee0657-77f1-4021-b38b-039bb00381b6 since it stays at CLOSED stage.
scm_1    | 2022-07-31 01:19:03,625 [BackgroundPipelineScrubberThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=69ee0657-77f1-4021-b38b-039bb00381b6 close command to datanode 3fc9f139-dd93-41e7-b235-52ce94d6fe3c
scm_1    | 2022-07-31 01:19:03,625 [BackgroundPipelineScrubberThread] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: 69ee0657-77f1-4021-b38b-039bb00381b6, Nodes: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:3fc9f139-dd93-41e7-b235-52ce94d6fe3c, CreationTimestamp2022-07-31T01:18:03.392667Z[UTC]] removed.
scm_1    | 2022-07-31 01:19:03,831 [IPC Server handler 6 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-07-31 01:19:04,653 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1    | 2022-07-31 01:19:04,680 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1    | 2022-07-31 01:19:08,832 [IPC Server handler 6 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-07-31 01:19:09,182 [SCMBlockDeletingService#0] INFO block.SCMBlockDeletingService: Totally added 9 blocks to be deleted for 3 datanodes, task elapsed time: 4ms
scm_1    | 2022-07-31 01:19:13,832 [IPC Server handler 6 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-07-31 01:19:13,833 [RatisPipelineUtilsThread - 0] ERROR scm.SCMCommonPlacementPolicy: Unable to find enough nodes that meet the space requirement of 1073741824 bytes for metadata and 1073741824 bytes for data in healthy node set. Required 3. Found 0.
scm_1    | 2022-07-31 01:19:18,833 [IPC Server handler 6 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-07-31 01:19:23,833 [IPC Server handler 6 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-07-31 01:19:28,834 [IPC Server handler 6 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-07-31 01:19:32,311 [IPC Server handler 3 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:32,313 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Reported pipeline PipelineID=369e0910-4276-41cc-941b-75041c4aa246 is not found
scm_1    | 2022-07-31 01:19:32,313 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Reported pipeline PipelineID=b88205de-97a2-4448-8e49-7bb2a1276610 is not found
scm_1    | 2022-07-31 01:19:32,314 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Reported pipeline PipelineID=69ee0657-77f1-4021-b38b-039bb00381b6 is not found
scm_1    | 2022-07-31 01:19:32,513 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Reported pipeline PipelineID=369e0910-4276-41cc-941b-75041c4aa246 is not found
scm_1    | 2022-07-31 01:19:32,513 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Reported pipeline PipelineID=67b1342c-3bb3-4b48-a218-65a101075af1 is not found
scm_1    | 2022-07-31 01:19:32,513 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Reported pipeline PipelineID=8145371a-b336-4e64-a95d-6999419922eb is not found
scm_1    | 2022-07-31 01:19:32,532 [IPC Server handler 6 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:32,533 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Reported pipeline PipelineID=c06adbe4-99b1-4236-a662-b3503d3184bf is not found
scm_1    | 2022-07-31 01:19:32,533 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Reported pipeline PipelineID=b88205de-97a2-4448-8e49-7bb2a1276610 is not found
scm_1    | 2022-07-31 01:19:32,548 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Reported pipeline PipelineID=c57ff3c1-98cc-4640-a639-ffc093016e58 is not found
scm_1    | 2022-07-31 01:19:32,548 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Reported pipeline PipelineID=369e0910-4276-41cc-941b-75041c4aa246 is not found
scm_1    | 2022-07-31 01:19:32,548 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Reported pipeline PipelineID=67b1342c-3bb3-4b48-a218-65a101075af1 is not found
scm_1    | 2022-07-31 01:19:32,678 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO node.ReadOnlyHealthyToHealthyNodeHandler: Datanode 11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to HEALTHY state.
scm_1    | 2022-07-31 01:19:32,679 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1    | 2022-07-31 01:19:32,681 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO node.ReadOnlyHealthyToHealthyNodeHandler: Datanode 609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to HEALTHY state.
scm_1    | 2022-07-31 01:19:32,682 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1    | 2022-07-31 01:19:32,681 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=da610dcf-61e8-4e48-8ead-26397c6fffad to datanode:11cba143-91f8-47cb-8422-c32a1e2d51df
scm_1    | 2022-07-31 01:19:32,683 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: da610dcf-61e8-4e48-8ead-26397c6fffad, Nodes: 11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-31T01:19:32.680Z[UTC]].
scm_1    | 2022-07-31 01:19:32,687 [RatisPipelineUtilsThread - 0] ERROR scm.SCMCommonPlacementPolicy: Unable to find enough nodes that meet the space requirement of 1073741824 bytes for metadata and 1073741824 bytes for data in healthy node set. Required 3. Found 2.
scm_1    | 2022-07-31 01:19:32,687 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=f058582a-59a2-4a37-8200-b37bd276617a to datanode:609e7f2d-9474-472f-937f-8fa0a0bbb327
scm_1    | 2022-07-31 01:19:32,688 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: f058582a-59a2-4a37-8200-b37bd276617a, Nodes: 609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-31T01:19:32.687Z[UTC]].
scm_1    | 2022-07-31 01:19:32,689 [RatisPipelineUtilsThread - 0] ERROR scm.SCMCommonPlacementPolicy: Unable to find enough nodes that meet the space requirement of 1073741824 bytes for metadata and 1073741824 bytes for data in healthy node set. Required 3. Found 2.
scm_1    | 2022-07-31 01:19:32,705 [IPC Server handler 19 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 2, SCM MetadataLayoutVersion = 4
scm_1    | 2022-07-31 01:19:32,710 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Reported pipeline PipelineID=67b1342c-3bb3-4b48-a218-65a101075af1 is not found
scm_1    | 2022-07-31 01:19:32,711 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Reported pipeline PipelineID=b88205de-97a2-4448-8e49-7bb2a1276610 is not found
scm_1    | 2022-07-31 01:19:32,711 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Reported pipeline PipelineID=106ad38c-cb28-4e98-a52d-cd003ecc1eed is not found
scm_1    | 2022-07-31 01:19:33,834 [IPC Server handler 6 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-07-31 01:19:34,654 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1    | 2022-07-31 01:19:34,681 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1    | 2022-07-31 01:19:38,834 [IPC Server handler 6 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-07-31 01:19:43,835 [IPC Server handler 6 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-07-31 01:19:48,835 [IPC Server handler 6 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-07-31 01:19:53,836 [IPC Server handler 6 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-07-31 01:19:58,836 [IPC Server handler 6 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-07-31 01:20:02,681 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO node.ReadOnlyHealthyToHealthyNodeHandler: Datanode 3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to HEALTHY state.
scm_1    | 2022-07-31 01:20:02,681 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1    | 2022-07-31 01:20:02,682 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=e372288d-28a7-4132-a525-5058278e2312 to datanode:3fc9f139-dd93-41e7-b235-52ce94d6fe3c
scm_1    | 2022-07-31 01:20:02,682 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO node.ReadOnlyHealthyToHealthyNodeHandler: Datanode 310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to HEALTHY state.
scm_1    | 2022-07-31 01:20:02,682 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1    | 2022-07-31 01:20:02,683 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: e372288d-28a7-4132-a525-5058278e2312, Nodes: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-31T01:20:02.682Z[UTC]].
scm_1    | 2022-07-31 01:20:02,684 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=ae7040c6-f723-491f-8b9e-7781ffa9f9e7 to datanode:609e7f2d-9474-472f-937f-8fa0a0bbb327
scm_1    | 2022-07-31 01:20:02,684 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=ae7040c6-f723-491f-8b9e-7781ffa9f9e7 to datanode:11cba143-91f8-47cb-8422-c32a1e2d51df
scm_1    | 2022-07-31 01:20:02,684 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=ae7040c6-f723-491f-8b9e-7781ffa9f9e7 to datanode:310a080d-f635-46ff-a53d-49cc9a09fa5c
scm_1    | 2022-07-31 01:20:02,684 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: ae7040c6-f723-491f-8b9e-7781ffa9f9e7, Nodes: 609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-31T01:20:02.683Z[UTC]].
scm_1    | 2022-07-31 01:20:02,685 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=6f4f1d7d-a1c2-4efd-bea9-18489625bc71 to datanode:310a080d-f635-46ff-a53d-49cc9a09fa5c
scm_1    | 2022-07-31 01:20:02,685 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 6f4f1d7d-a1c2-4efd-bea9-18489625bc71, Nodes: 310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-31T01:20:02.685Z[UTC]].
scm_1    | 2022-07-31 01:20:02,686 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0 to datanode:310a080d-f635-46ff-a53d-49cc9a09fa5c
scm_1    | 2022-07-31 01:20:02,686 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0 to datanode:3fc9f139-dd93-41e7-b235-52ce94d6fe3c
scm_1    | 2022-07-31 01:20:02,686 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0 to datanode:609e7f2d-9474-472f-937f-8fa0a0bbb327
scm_1    | 2022-07-31 01:20:02,686 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0, Nodes: 310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-31T01:20:02.686Z[UTC]].
scm_1    | 2022-07-31 01:20:03,569 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: da610dcf-61e8-4e48-8ead-26397c6fffad, Nodes: 11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:11cba143-91f8-47cb-8422-c32a1e2d51df, CreationTimestamp2022-07-31T01:19:32.680Z[UTC]] moved to OPEN state
scm_1    | 2022-07-31 01:20:03,625 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: f058582a-59a2-4a37-8200-b37bd276617a, Nodes: 609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:609e7f2d-9474-472f-937f-8fa0a0bbb327, CreationTimestamp2022-07-31T01:19:32.687Z[UTC]] moved to OPEN state
scm_1    | 2022-07-31 01:20:03,837 [IPC Server handler 6 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-07-31 01:20:04,654 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1    | 2022-07-31 01:20:04,681 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1    | 2022-07-31 01:20:05,681 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO node.ReadOnlyHealthyToHealthyNodeHandler: Datanode 52aca038-7576-46a0-9ccd-b8aed29078e2{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to HEALTHY state.
scm_1    | 2022-07-31 01:20:05,682 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1    | 2022-07-31 01:20:05,683 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=9a50af78-96a4-4a72-b811-f5adbe2ee252 to datanode:52aca038-7576-46a0-9ccd-b8aed29078e2
scm_1    | 2022-07-31 01:20:05,684 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 9a50af78-96a4-4a72-b811-f5adbe2ee252, Nodes: 52aca038-7576-46a0-9ccd-b8aed29078e2{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-31T01:20:05.683Z[UTC]].
scm_1    | 2022-07-31 01:20:05,685 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=e19f4611-626e-4580-84ca-4b35cfa778dc to datanode:52aca038-7576-46a0-9ccd-b8aed29078e2
scm_1    | 2022-07-31 01:20:05,685 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=e19f4611-626e-4580-84ca-4b35cfa778dc to datanode:11cba143-91f8-47cb-8422-c32a1e2d51df
scm_1    | 2022-07-31 01:20:05,685 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=e19f4611-626e-4580-84ca-4b35cfa778dc to datanode:3fc9f139-dd93-41e7-b235-52ce94d6fe3c
scm_1    | 2022-07-31 01:20:05,686 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: e19f4611-626e-4580-84ca-4b35cfa778dc, Nodes: 52aca038-7576-46a0-9ccd-b8aed29078e2{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-31T01:20:05.685Z[UTC]].
scm_1    | 2022-07-31 01:20:08,838 [IPC Server handler 6 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
scm_1    | 2022-07-31 01:20:13,822 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: ae7040c6-f723-491f-8b9e-7781ffa9f9e7, Nodes: 609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:310a080d-f635-46ff-a53d-49cc9a09fa5c, CreationTimestamp2022-07-31T01:20:02.683Z[UTC]] moved to OPEN state
scm_1    | 2022-07-31 01:20:13,838 [IPC Server handler 6 on default port 9860] INFO upgrade.UpgradeFinalizer: Open pipeline found after SCM finalization
scm_1    | 2022-07-31 01:20:13,839 [IPC Server handler 6 on default port 9860] INFO upgrade.UpgradeFinalizer: Finalization is done.
scm_1    | 2022-07-31 01:20:33,473 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: e372288d-28a7-4132-a525-5058278e2312, Nodes: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:3fc9f139-dd93-41e7-b235-52ce94d6fe3c, CreationTimestamp2022-07-31T01:20:02.682Z[UTC]] moved to OPEN state
scm_1    | 2022-07-31 01:20:33,577 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 6f4f1d7d-a1c2-4efd-bea9-18489625bc71, Nodes: 310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:310a080d-f635-46ff-a53d-49cc9a09fa5c, CreationTimestamp2022-07-31T01:20:02.685Z[UTC]] moved to OPEN state
scm_1    | 2022-07-31 01:20:33,813 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 9a50af78-96a4-4a72-b811-f5adbe2ee252, Nodes: 52aca038-7576-46a0-9ccd-b8aed29078e2{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:52aca038-7576-46a0-9ccd-b8aed29078e2, CreationTimestamp2022-07-31T01:20:05.683Z[UTC]] moved to OPEN state
scm_1    | 2022-07-31 01:20:34,633 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 7a622ef2-8b3d-4dc3-8c19-84a70a95b4c0, Nodes: 310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:3fc9f139-dd93-41e7-b235-52ce94d6fe3c, CreationTimestamp2022-07-31T01:20:02.686Z[UTC]] moved to OPEN state
scm_1    | 2022-07-31 01:20:34,655 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1    | 2022-07-31 01:20:34,682 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1    | 2022-07-31 01:20:44,221 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: e19f4611-626e-4580-84ca-4b35cfa778dc, Nodes: 52aca038-7576-46a0-9ccd-b8aed29078e2{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:11cba143-91f8-47cb-8422-c32a1e2d51df, CreationTimestamp2022-07-31T01:20:05.685Z[UTC]] moved to OPEN state
scm_1    | 2022-07-31 01:21:04,658 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1    | 2022-07-31 01:21:04,683 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1    | 2022-07-31 01:21:34,658 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1    | 2022-07-31 01:21:34,684 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1    | 2022-07-31 01:21:39,601 [IPC Server handler 1 on default port 9863] WARN ha.SequenceIdGenerator: Failed to allocate a batch for containerId, expected lastId is 0, actual lastId is 3000.
scm_1    | 2022-07-31 01:21:39,608 [IPC Server handler 1 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 3000 to 4000.
scm_1    | 2022-07-31 01:21:39,610 [IPC Server handler 1 on default port 9863] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723203000.
scm_1    | 2022-07-31 01:21:39,610 [IPC Server handler 1 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 109611004723203000 to 109611004723204000.
scm_1    | 2022-07-31 01:22:04,659 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1    | 2022-07-31 01:22:04,684 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm_1    | 2022-07-31 01:22:33,290 [IPC Server handler 1 on default port 9863] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 3d8ba3cf-b534-4c5b-87ac-9fdeb6052515, Nodes: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}52aca038-7576-46a0-9ccd-b8aed29078e2{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-31T01:22:33.289Z[UTC]].
scm_1    | 2022-07-31 01:22:33,291 [IPC Server handler 1 on default port 9863] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 3d8ba3cf-b534-4c5b-87ac-9fdeb6052515, Nodes: 3fc9f139-dd93-41e7-b235-52ce94d6fe3c{ip: 10.9.0.17, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}52aca038-7576-46a0-9ccd-b8aed29078e2{ip: 10.9.0.19, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}310a080d-f635-46ff-a53d-49cc9a09fa5c{ip: 10.9.0.18, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11cba143-91f8-47cb-8422-c32a1e2d51df{ip: 10.9.0.16, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}609e7f2d-9474-472f-937f-8fa0a0bbb327{ip: 10.9.0.15, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:ALLOCATED, leaderId:, CreationTimestamp2022-07-31T01:22:33.289Z[UTC]] moved to OPEN state
scm_1    | 2022-07-31 01:22:34,660 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm_1    | 2022-07-31 01:22:34,685 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
