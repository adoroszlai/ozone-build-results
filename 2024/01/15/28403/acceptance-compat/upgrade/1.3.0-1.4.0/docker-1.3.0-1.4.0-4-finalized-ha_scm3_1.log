Waiting for the service scm2.org:9894
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2024-01-15 07:56:28,153 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = scm3.org/10.9.0.16
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.5.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jgraphx-2.0.0.1.jar:/opt/hadoop/share/ozone/lib/commons-net-3.10.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/okhttp-4.12.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.9.22.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.3.2.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.25.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-2.0.10.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.6.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.2.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.16.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-text-1.10.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.6.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.0.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.16.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/okio-3.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-2.0.10.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.9.22.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.5.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.9.22.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.12.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/jgraph-5.13.0.0.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/antlr4-runtime-4.5.3.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.5.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.25.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.9.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-1.2.2.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.9.22.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.16.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.14.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.58.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.9.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.0.1.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.5.0-SNAPSHOT.jar
STARTUP_MSG:   build = https://github.com/apache/ozone/26be5d9ce6d871bdab56b32fdc8bb85511f51f24 ; compiled by 'runner' on 2024-01-15T07:23Z
STARTUP_MSG:   java = 11.0.19
STARTUP_MSG:   conf = {dfs.container.chunk.write.sync=false, dfs.container.ipc=9859, dfs.container.ipc.random.port=false, dfs.container.ratis.admin.port=9857, dfs.container.ratis.datastream.enabled=false, dfs.container.ratis.datastream.port=9855, dfs.container.ratis.datastream.random.port=false, dfs.container.ratis.enabled=false, dfs.container.ratis.ipc=9858, dfs.container.ratis.ipc.random.port=false, dfs.container.ratis.leader.pending.bytes.limit=1GB, dfs.container.ratis.log.appender.queue.byte-limit=32MB, dfs.container.ratis.log.appender.queue.num-elements=1, dfs.container.ratis.log.purge.gap=1000000, dfs.container.ratis.log.queue.byte-limit=4GB, dfs.container.ratis.log.queue.num-elements=1024, dfs.container.ratis.num.container.op.executors=10, dfs.container.ratis.num.write.chunk.threads.per.volume=10, dfs.container.ratis.replication.level=MAJORITY, dfs.container.ratis.rpc.type=GRPC, dfs.container.ratis.segment.preallocated.size=4MB, dfs.container.ratis.segment.size=64MB, dfs.container.ratis.server.port=9856, dfs.container.ratis.statemachine.max.pending.apply-transactions=10000, dfs.container.ratis.statemachinedata.sync.timeout=10s, dfs.ratis.leader.election.minimum.timeout.duration=5s, dfs.ratis.server.retry-cache.timeout.duration=600000ms, dfs.ratis.snapshot.threshold=10000, hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=true, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.close.threshold=0.9f, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=false, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=true, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/db@EXAMPLE.COM, hdds.datanode.http.auth.type=kerberos, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=true, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/scm@EXAMPLE.COM, hdds.scm.http.auth.type=kerberos, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/scm.keytab, hdds.scm.kerberos.principal=scm/scm@EXAMPLE.COM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=3, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5s, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=10m, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=1h, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=1m, hdds.secret.key.rotate.duration=5m, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneNativeAuthorizer, ozone.acl.enabled=true, ozone.administrators=testuser,recon,om, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=6, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.directory.deleting.service.interval=1m, ozone.ec.grpc.zerocopy.enabled=true, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.http.filter.initializers=org.apache.hadoop.security.AuthenticationFilterInitializer, ozone.http.policy=HTTP_ONLY, ozone.httpfs.http.auth.kerberos.keytab=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.http.auth.kerberos.principal=HTTP/httpfs@EXAMPLE.COM, ozone.httpfs.http.auth.type=kerberos, ozone.httpfs.kerberos.keytab.file=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.kerberos.principal=httpfs/httpfs@EXAMPLE.COM, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=0.0.0.0:9862, ozone.om.address.omservice.om1=om1, ozone.om.address.omservice.om2=om2, ozone.om.address.omservice.om3=om3, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=0.0.0.0:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/om@EXAMPLE.COM, ozone.om.http.auth.type=kerberos, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.kerberos.keytab.file=/etc/security/keytabs/om.keytab, ozone.om.kerberos.principal=om/om@EXAMPLE.COM, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.nodes.omservice=om1,om2,om3, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.service.ids=omservice, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.load.native.lib=true, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.sst_dumptool.buffer.size=8KB, ozone.om.snapshot.sst_dumptool.pool.size=1, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.volume.listall.allowed=true, ozone.path.deleting.limit.per.task=6000, ozone.recon.address=recon:9891, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/recon.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/recon@EXAMPLE.COM, ozone.recon.http.auth.type=kerberos, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.kerberos.keytab.file=/etc/security/keytabs/recon.keytab, ozone.recon.kerberos.principal=recon/recon@EXAMPLE.COM, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=1m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.scmclient.failover.max.retry=3, ozone.recon.scmclient.max.retry.timeout=6s, ozone.recon.scmclient.rpc.timeout=1m, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3.administrators=testuser,s3g, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/s3g@EXAMPLE.COM, ozone.s3g.http.auth.type=kerberos, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/s3g@EXAMPLE.COM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.metrics.percentiles.intervals.seconds=60, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=true, ozone.s3g.volume.name=s3v, ozone.scm.address.scmservice.scm1=scm1.org, ozone.scm.address.scmservice.scm2=scm2.org, ozone.scm.address.scmservice.scm3=scm3.org, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.handler.count.key=100, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.handler.count.key=100, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=150s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.handler.count.key=100, ozone.scm.datanode.id.dir=/data, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=1GB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.nodes.scmservice=scm1,scm2,scm3, ozone.scm.pipeline.allocated.timeout=2m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=30s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=1m, ozone.scm.primordial.node.id=scm1, ozone.scm.ratis.enable=true, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.service.ids=scmservice, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=true, ozone.security.http.kerberos.enabled=true, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.directory.service.interval=24h, ozone.snapshot.directory.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.trace.enabled=false, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2024-01-15 07:56:28,168 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-15 07:56:28,216 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-01-15 07:56:28,552 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2024-01-15 07:56:28,558 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2024-01-15 07:56:28,583 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
2024-01-15 07:56:28,588 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
2024-01-15 07:56:28,793 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
2024-01-15 07:56:28,793 [main] INFO server.StorageContainerManager: SCM login successful.
2024-01-15 07:56:29,408 [main] INFO client.SCMCertificateClient: Certificate serial ID set to 503304745880
2024-01-15 07:56:29,507 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 503304745880
             IssuerDN: CN=scm@scm1.org,OU=4e866cc2-839f-4d23-a8df-7474513825dc,O=CID-683d5636-fdaa-48e7-9616-a9985e8d8993
           Start Date: Mon Jan 15 00:00:00 UTC 2024
           Final Date: Thu Feb 22 00:00:00 UTC 2029
            SubjectDN: CN=scm-sub@scm3.org,OU=38ca2b18-7c52-4d7d-9687-c935ff383fee,O=CID-683d5636-fdaa-48e7-9616-a9985e8d8993
           Public Key: RSA Public Key [f6:4f:5c:ba:b7:01:90:fa:d0:c6:ca:1b:25:14:33:ca:54:ac:b9:a2],[56:66:d1:a4]
        modulus: b7aa00da5b95cb8d9d8c0f9174093d4def5ff88dab22fbd40613a568cff49a87c7f36e03080f03680efbeee1acf9f9341ff385634b4745917baa3c604f1569ba088aa6fcdd5a25374089bcd492a2c17185c704cf351ac0cf8d1497df02dad98015f188fb1715ecbe69fec0cdf61632d3eefc5f3f560e83c3b80b91f08f288114e76f0b7c33ced36016d8f6e763d2e52e5ad619e4c717fe191263438a4e015217568053bd2de49a7c45d8ca160076ed4fb07b0560bc6c4918111b3eb1ec2ed87c8dd4498dbb462232d49b2dfd5b982baae75b6457ba1533190721b75278ce9b61dfd8e1174a870caaa461e721cafc3092f7148cccb89d50fed2f88015cb21f9db
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 1307fe3907289fe69bb851028f0bdfb79ecc7fed
                       dbcef46011d2ffbf1e04ffb199d9728e41eb32b5
                       7c3a9ecdce71af5a1a1da2c3ecdf611b3f992d19
                       a3409ce6d64d66b4490b403aea17388540e2f2bc
                       b8ceb8ff19294b19e7d93347bd1a5bbe6b57f53b
                       27c8911e0edb2ec62517f797f1750409c16441be
                       33a304a1c8c77ede9e6bf6c3f970a50360cbacf9
                       672f512708f2ecba6b42201684104cb7da411ab4
                       0329fd471551c195e23721fb72845cf4db37a770
                       a0b0857a4cfbd32f069b307efd4ef5475ab9c273
                       783ed04cd855c069fc19abc646a1c0e98c0a0e2a
                       5f9e23b19b6d00fc6b49b0de979e0ee71a4bc92e
                       31f1c6060920354871222a1604db4b12
       Extensions: 
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0xbe
 from file: /data/metadata/scm/sub-ca/certs/503304745880.crt.
2024-01-15 07:56:29,511 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm@scm1.org,OU=4e866cc2-839f-4d23-a8df-7474513825dc,O=CID-683d5636-fdaa-48e7-9616-a9985e8d8993
           Start Date: Mon Jan 15 00:00:00 UTC 2024
           Final Date: Thu Feb 22 23:59:59 UTC 2029
            SubjectDN: CN=scm@scm1.org,OU=4e866cc2-839f-4d23-a8df-7474513825dc,O=CID-683d5636-fdaa-48e7-9616-a9985e8d8993
           Public Key: RSA Public Key [b6:de:f5:8e:72:d2:97:92:9c:3a:15:75:3e:75:7b:70:2d:a6:c7:3d],[56:66:d1:a4]
        modulus: a681591e4465f9d9683ded5e8f66013d905bf8a1dc7a2802c24e4e026f7be29ca2d08dd24c3720053cc8f3679c1c27fb8ff1ba086bf6979c1e68cf3b2f3a6d937f1602fcf1f6501e12798fd0ecdbfa7fc7ff41ccd7155857171c166e6c181cd58026c3cdd072fd8374a522025290515a420ef309565dd1766c11c7bda1f2025af916f8ad60dbc67523d97182d320d35b6d682c3c0ad69b50abc15b8dc22de645051a249533caa6a63ead563847172c98ade7f737f8de987f711550482b03a016b995c3c7c07f33e94e82208067e8e32d32e4f77217731dd92582186993adbc5b022dc2167fafc87292fe4fe504e50afe5d10b84ef700f10c375aad65175a91c9
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 2ae22a8da2895c040a2500bf876b36dc19784fb4
                       04963d3d73675cf47f79516ee501c7d54491ed07
                       5bdf8b36333f6126386d95cc6251798ab33c57e7
                       7a4afd28641d4ac4db1c3ee1a5dca16f08a2635d
                       69611bc9328ce2293c96ce6f5638fe4a643ed777
                       2f2867816d116d0625f9f5523a8e8541854c0837
                       59ab2dec467935250654080966693df94bdc11ff
                       9bca39217968061569ab7a92c164dd1d56d34864
                       8c3c84658f7f7814dc56ac86e9ad61804de72c03
                       e09df96299b292842803e1b69b30889141361fd3
                       de12bfe1f7d781ef1f8b23976d5b7baee71a7035
                       a5e0b3773f1cb41995787c383c161465552b00cb
                       249c7ed77b6edea9f284d8f497192ae9
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

 from file: /data/metadata/scm/sub-ca/certs/CA-1.crt.
2024-01-15 07:56:29,514 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 503304745880
             IssuerDN: CN=scm@scm1.org,OU=4e866cc2-839f-4d23-a8df-7474513825dc,O=CID-683d5636-fdaa-48e7-9616-a9985e8d8993
           Start Date: Mon Jan 15 00:00:00 UTC 2024
           Final Date: Thu Feb 22 00:00:00 UTC 2029
            SubjectDN: CN=scm-sub@scm3.org,OU=38ca2b18-7c52-4d7d-9687-c935ff383fee,O=CID-683d5636-fdaa-48e7-9616-a9985e8d8993
           Public Key: RSA Public Key [f6:4f:5c:ba:b7:01:90:fa:d0:c6:ca:1b:25:14:33:ca:54:ac:b9:a2],[56:66:d1:a4]
        modulus: b7aa00da5b95cb8d9d8c0f9174093d4def5ff88dab22fbd40613a568cff49a87c7f36e03080f03680efbeee1acf9f9341ff385634b4745917baa3c604f1569ba088aa6fcdd5a25374089bcd492a2c17185c704cf351ac0cf8d1497df02dad98015f188fb1715ecbe69fec0cdf61632d3eefc5f3f560e83c3b80b91f08f288114e76f0b7c33ced36016d8f6e763d2e52e5ad619e4c717fe191263438a4e015217568053bd2de49a7c45d8ca160076ed4fb07b0560bc6c4918111b3eb1ec2ed87c8dd4498dbb462232d49b2dfd5b982baae75b6457ba1533190721b75278ce9b61dfd8e1174a870caaa461e721cafc3092f7148cccb89d50fed2f88015cb21f9db
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 1307fe3907289fe69bb851028f0bdfb79ecc7fed
                       dbcef46011d2ffbf1e04ffb199d9728e41eb32b5
                       7c3a9ecdce71af5a1a1da2c3ecdf611b3f992d19
                       a3409ce6d64d66b4490b403aea17388540e2f2bc
                       b8ceb8ff19294b19e7d93347bd1a5bbe6b57f53b
                       27c8911e0edb2ec62517f797f1750409c16441be
                       33a304a1c8c77ede9e6bf6c3f970a50360cbacf9
                       672f512708f2ecba6b42201684104cb7da411ab4
                       0329fd471551c195e23721fb72845cf4db37a770
                       a0b0857a4cfbd32f069b307efd4ef5475ab9c273
                       783ed04cd855c069fc19abc646a1c0e98c0a0e2a
                       5f9e23b19b6d00fc6b49b0de979e0ee71a4bc92e
                       31f1c6060920354871222a1604db4b12
       Extensions: 
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0xbe
 from file: /data/metadata/scm/sub-ca/certs/certificate.crt.
2024-01-15 07:56:29,515 [main] INFO client.SCMCertificateClient: CertificateRenewerService and root ca rotation polling is disabled for scm/sub-ca
2024-01-15 07:56:29,584 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-01-15 07:56:29,694 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-01-15 07:56:29,701 [main] INFO utils.LeakDetector: Starting leak detector thread ManagedRocksObject0.
2024-01-15 07:56:29,791 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.5.0-SNAPSHOT.jar!/network-topology-default.xml]
2024-01-15 07:56:29,792 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
2024-01-15 07:56:29,835 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.dropwizard3.Dm3MetricRegistriesImpl
2024-01-15 07:56:29,942 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:38ca2b18-7c52-4d7d-9687-c935ff383fee
2024-01-15 07:56:29,957 [main] INFO ssl.ReloadingX509KeyManager: Key manager is loaded with certificate chain
2024-01-15 07:56:29,973 [main] INFO ssl.ReloadingX509KeyManager:   [0]         Version: 3
         SerialNumber: 503304745880
             IssuerDN: CN=scm@scm1.org,OU=4e866cc2-839f-4d23-a8df-7474513825dc,O=CID-683d5636-fdaa-48e7-9616-a9985e8d8993
           Start Date: Mon Jan 15 00:00:00 UTC 2024
           Final Date: Thu Feb 22 00:00:00 UTC 2029
            SubjectDN: CN=scm-sub@scm3.org,OU=38ca2b18-7c52-4d7d-9687-c935ff383fee,O=CID-683d5636-fdaa-48e7-9616-a9985e8d8993
           Public Key: RSA Public Key [f6:4f:5c:ba:b7:01:90:fa:d0:c6:ca:1b:25:14:33:ca:54:ac:b9:a2],[56:66:d1:a4]
        modulus: b7aa00da5b95cb8d9d8c0f9174093d4def5ff88dab22fbd40613a568cff49a87c7f36e03080f03680efbeee1acf9f9341ff385634b4745917baa3c604f1569ba088aa6fcdd5a25374089bcd492a2c17185c704cf351ac0cf8d1497df02dad98015f188fb1715ecbe69fec0cdf61632d3eefc5f3f560e83c3b80b91f08f288114e76f0b7c33ced36016d8f6e763d2e52e5ad619e4c717fe191263438a4e015217568053bd2de49a7c45d8ca160076ed4fb07b0560bc6c4918111b3eb1ec2ed87c8dd4498dbb462232d49b2dfd5b982baae75b6457ba1533190721b75278ce9b61dfd8e1174a870caaa461e721cafc3092f7148cccb89d50fed2f88015cb21f9db
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 1307fe3907289fe69bb851028f0bdfb79ecc7fed
                       dbcef46011d2ffbf1e04ffb199d9728e41eb32b5
                       7c3a9ecdce71af5a1a1da2c3ecdf611b3f992d19
                       a3409ce6d64d66b4490b403aea17388540e2f2bc
                       b8ceb8ff19294b19e7d93347bd1a5bbe6b57f53b
                       27c8911e0edb2ec62517f797f1750409c16441be
                       33a304a1c8c77ede9e6bf6c3f970a50360cbacf9
                       672f512708f2ecba6b42201684104cb7da411ab4
                       0329fd471551c195e23721fb72845cf4db37a770
                       a0b0857a4cfbd32f069b307efd4ef5475ab9c273
                       783ed04cd855c069fc19abc646a1c0e98c0a0e2a
                       5f9e23b19b6d00fc6b49b0de979e0ee71a4bc92e
                       31f1c6060920354871222a1604db4b12
       Extensions: 
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0xbe

2024-01-15 07:56:29,976 [main] INFO ssl.ReloadingX509KeyManager:   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm@scm1.org,OU=4e866cc2-839f-4d23-a8df-7474513825dc,O=CID-683d5636-fdaa-48e7-9616-a9985e8d8993
           Start Date: Mon Jan 15 00:00:00 UTC 2024
           Final Date: Thu Feb 22 23:59:59 UTC 2029
            SubjectDN: CN=scm@scm1.org,OU=4e866cc2-839f-4d23-a8df-7474513825dc,O=CID-683d5636-fdaa-48e7-9616-a9985e8d8993
           Public Key: RSA Public Key [b6:de:f5:8e:72:d2:97:92:9c:3a:15:75:3e:75:7b:70:2d:a6:c7:3d],[56:66:d1:a4]
        modulus: a681591e4465f9d9683ded5e8f66013d905bf8a1dc7a2802c24e4e026f7be29ca2d08dd24c3720053cc8f3679c1c27fb8ff1ba086bf6979c1e68cf3b2f3a6d937f1602fcf1f6501e12798fd0ecdbfa7fc7ff41ccd7155857171c166e6c181cd58026c3cdd072fd8374a522025290515a420ef309565dd1766c11c7bda1f2025af916f8ad60dbc67523d97182d320d35b6d682c3c0ad69b50abc15b8dc22de645051a249533caa6a63ead563847172c98ade7f737f8de987f711550482b03a016b995c3c7c07f33e94e82208067e8e32d32e4f77217731dd92582186993adbc5b022dc2167fafc87292fe4fe504e50afe5d10b84ef700f10c375aad65175a91c9
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 2ae22a8da2895c040a2500bf876b36dc19784fb4
                       04963d3d73675cf47f79516ee501c7d54491ed07
                       5bdf8b36333f6126386d95cc6251798ab33c57e7
                       7a4afd28641d4ac4db1c3ee1a5dca16f08a2635d
                       69611bc9328ce2293c96ce6f5638fe4a643ed777
                       2f2867816d116d0625f9f5523a8e8541854c0837
                       59ab2dec467935250654080966693df94bdc11ff
                       9bca39217968061569ab7a92c164dd1d56d34864
                       8c3c84658f7f7814dc56ac86e9ad61804de72c03
                       e09df96299b292842803e1b69b30889141361fd3
                       de12bfe1f7d781ef1f8b23976d5b7baee71a7035
                       a5e0b3773f1cb41995787c383c161465552b00cb
                       249c7ed77b6edea9f284d8f497192ae9
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 


2024-01-15 07:56:29,979 [main] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2024-01-15 07:56:29,979 [main] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2024-01-15 07:56:29,980 [main] INFO ssl.ReloadingX509TrustManager: Trust manager is loaded with certificates
2024-01-15 07:56:29,983 [main] INFO ssl.ReloadingX509TrustManager:   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm@scm1.org,OU=4e866cc2-839f-4d23-a8df-7474513825dc,O=CID-683d5636-fdaa-48e7-9616-a9985e8d8993
           Start Date: Mon Jan 15 00:00:00 UTC 2024
           Final Date: Thu Feb 22 23:59:59 UTC 2029
            SubjectDN: CN=scm@scm1.org,OU=4e866cc2-839f-4d23-a8df-7474513825dc,O=CID-683d5636-fdaa-48e7-9616-a9985e8d8993
           Public Key: RSA Public Key [b6:de:f5:8e:72:d2:97:92:9c:3a:15:75:3e:75:7b:70:2d:a6:c7:3d],[56:66:d1:a4]
        modulus: a681591e4465f9d9683ded5e8f66013d905bf8a1dc7a2802c24e4e026f7be29ca2d08dd24c3720053cc8f3679c1c27fb8ff1ba086bf6979c1e68cf3b2f3a6d937f1602fcf1f6501e12798fd0ecdbfa7fc7ff41ccd7155857171c166e6c181cd58026c3cdd072fd8374a522025290515a420ef309565dd1766c11c7bda1f2025af916f8ad60dbc67523d97182d320d35b6d682c3c0ad69b50abc15b8dc22de645051a249533caa6a63ead563847172c98ade7f737f8de987f711550482b03a016b995c3c7c07f33e94e82208067e8e32d32e4f77217731dd92582186993adbc5b022dc2167fafc87292fe4fe504e50afe5d10b84ef700f10c375aad65175a91c9
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 2ae22a8da2895c040a2500bf876b36dc19784fb4
                       04963d3d73675cf47f79516ee501c7d54491ed07
                       5bdf8b36333f6126386d95cc6251798ab33c57e7
                       7a4afd28641d4ac4db1c3ee1a5dca16f08a2635d
                       69611bc9328ce2293c96ce6f5638fe4a643ed777
                       2f2867816d116d0625f9f5523a8e8541854c0837
                       59ab2dec467935250654080966693df94bdc11ff
                       9bca39217968061569ab7a92c164dd1d56d34864
                       8c3c84658f7f7814dc56ac86e9ad61804de72c03
                       e09df96299b292842803e1b69b30889141361fd3
                       de12bfe1f7d781ef1f8b23976d5b7baee71a7035
                       a5e0b3773f1cb41995787c383c161465552b00cb
                       249c7ed77b6edea9f284d8f497192ae9
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 


2024-01-15 07:56:29,992 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2024-01-15 07:56:29,994 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2024-01-15 07:56:30,042 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2024-01-15 07:56:30,049 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-01-15 07:56:30,049 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2024-01-15 07:56:30,050 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-01-15 07:56:30,050 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2024-01-15 07:56:30,050 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2024-01-15 07:56:30,050 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2024-01-15 07:56:30,051 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
2024-01-15 07:56:30,052 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-01-15 07:56:30,053 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2024-01-15 07:56:30,053 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2024-01-15 07:56:30,062 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2024-01-15 07:56:30,065 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-01-15 07:56:30,065 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-01-15 07:56:30,401 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2024-01-15 07:56:30,403 [main] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2024-01-15 07:56:30,403 [main] INFO server.RaftServerConfigKeys: raft.server.close.threshold = 60s (default)
2024-01-15 07:56:30,404 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-01-15 07:56:30,407 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2024-01-15 07:56:30,409 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2024-01-15 07:56:30,409 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2024-01-15 07:56:30,421 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServer: 38ca2b18-7c52-4d7d-9687-c935ff383fee: found a subdirectory /data/metadata/scm-ha/683d5636-fdaa-48e7-9616-a9985e8d8993
2024-01-15 07:56:30,430 [main] INFO server.RaftServer: 38ca2b18-7c52-4d7d-9687-c935ff383fee: addNew group-A9985E8D8993:[] returns group-A9985E8D8993:java.util.concurrent.CompletableFuture@1859ffda[Not completed]
2024-01-15 07:56:30,448 [38ca2b18-7c52-4d7d-9687-c935ff383fee-groupManagement] INFO ha.SCMStateMachine: Updated lastAppliedTermIndex 6#104 with transactionInfo term andIndex
2024-01-15 07:56:30,449 [38ca2b18-7c52-4d7d-9687-c935ff383fee-groupManagement] INFO server.RaftServer$Division: 38ca2b18-7c52-4d7d-9687-c935ff383fee: new RaftServerImpl for group-A9985E8D8993:[] with SCMStateMachine:uninitialized
2024-01-15 07:56:30,456 [38ca2b18-7c52-4d7d-9687-c935ff383fee-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2024-01-15 07:56:30,456 [38ca2b18-7c52-4d7d-9687-c935ff383fee-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2024-01-15 07:56:30,457 [38ca2b18-7c52-4d7d-9687-c935ff383fee-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2024-01-15 07:56:30,457 [38ca2b18-7c52-4d7d-9687-c935ff383fee-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2024-01-15 07:56:30,457 [38ca2b18-7c52-4d7d-9687-c935ff383fee-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-01-15 07:56:30,458 [38ca2b18-7c52-4d7d-9687-c935ff383fee-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.member.majority-add = false (default)
2024-01-15 07:56:30,458 [38ca2b18-7c52-4d7d-9687-c935ff383fee-groupManagement] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2024-01-15 07:56:30,465 [38ca2b18-7c52-4d7d-9687-c935ff383fee-groupManagement] INFO server.RaftServer$Division: 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-01-15 07:56:30,470 [38ca2b18-7c52-4d7d-9687-c935ff383fee-groupManagement] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2024-01-15 07:56:30,473 [38ca2b18-7c52-4d7d-9687-c935ff383fee-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.timeout = 10s (default)
2024-01-15 07:56:30,475 [38ca2b18-7c52-4d7d-9687-c935ff383fee-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2024-01-15 07:56:30,475 [38ca2b18-7c52-4d7d-9687-c935ff383fee-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-01-15 07:56:30,479 [38ca2b18-7c52-4d7d-9687-c935ff383fee-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.option = DEFAULT (default)
2024-01-15 07:56:30,479 [38ca2b18-7c52-4d7d-9687-c935ff383fee-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-01-15 07:56:30,563 [38ca2b18-7c52-4d7d-9687-c935ff383fee-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2024-01-15 07:56:30,565 [38ca2b18-7c52-4d7d-9687-c935ff383fee-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-01-15 07:56:30,565 [38ca2b18-7c52-4d7d-9687-c935ff383fee-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2024-01-15 07:56:30,565 [38ca2b18-7c52-4d7d-9687-c935ff383fee-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2024-01-15 07:56:30,566 [38ca2b18-7c52-4d7d-9687-c935ff383fee-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2024-01-15 07:56:30,566 [38ca2b18-7c52-4d7d-9687-c935ff383fee-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2024-01-15 07:56:30,568 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
2024-01-15 07:56:30,568 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2024-01-15 07:56:30,568 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
2024-01-15 07:56:30,586 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-01-15 07:56:30,614 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
2024-01-15 07:56:30,649 [main] INFO node.SCMNodeManager: Entering startup safe mode.
2024-01-15 07:56:30,657 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2024-01-15 07:56:30,658 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2024-01-15 07:56:30,687 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2024-01-15 07:56:30,687 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2024-01-15 07:56:30,690 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
2024-01-15 07:56:30,690 [main] INFO pipeline.BackgroundPipelineCreator: Starting scm3-RatisPipelineUtilsThread.
2024-01-15 07:56:30,692 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
2024-01-15 07:56:30,692 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
2024-01-15 07:56:30,695 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
2024-01-15 07:56:30,695 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
2024-01-15 07:56:30,710 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2024-01-15 07:56:30,710 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2024-01-15 07:56:30,728 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
2024-01-15 07:56:30,765 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
2024-01-15 07:56:30,765 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
2024-01-15 07:56:30,765 [scm3-ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 5000ms after safemode exit
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.hadoop.hdds.utils.MetricsUtil (file:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.5.0-SNAPSHOT.jar) to method java.lang.Class.annotationData()
WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.hdds.utils.MetricsUtil
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
2024-01-15 07:56:30,771 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
2024-01-15 07:56:30,773 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 2, healthy pipeline threshold count is 1
2024-01-15 07:56:30,774 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 2, pipeline's with at least one datanode reported threshold count is 2
2024-01-15 07:56:30,903 [main] INFO security.SecretKeyManagerService: Scheduling rotation checker with interval PT1M
2024-01-15 07:56:30,903 [main] INFO ha.SCMServiceManager: Registering service SecretKeyManagerService.
2024-01-15 07:56:30,916 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
2024-01-15 07:56:30,928 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-01-15 07:56:30,955 [main] INFO ipc.Server: Listener at 0.0.0.0:9961
2024-01-15 07:56:30,956 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
2024-01-15 07:56:30,974 [main] INFO server.StorageContainerManager: SCM start with adminUsers: [testuser, recon, om, scm]
2024-01-15 07:56:31,312 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2024-01-15 07:56:31,316 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-01-15 07:56:31,316 [main] INFO ipc.Server: Listener at 0.0.0.0:9861
2024-01-15 07:56:31,319 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
2024-01-15 07:56:31,346 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2024-01-15 07:56:31,352 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-01-15 07:56:31,352 [main] INFO ipc.Server: Listener at 0.0.0.0:9863
2024-01-15 07:56:31,352 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
2024-01-15 07:56:31,381 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2024-01-15 07:56:31,388 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-01-15 07:56:31,388 [main] INFO ipc.Server: Listener at 0.0.0.0:9860
2024-01-15 07:56:31,388 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
2024-01-15 07:56:31,437 [main] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
2024-01-15 07:56:31,438 [main] INFO server.StorageContainerManager: 
Container Balancer status:
Key                            Value
Running                        false
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB
Number of Iterations                               10
Time Limit for Single Container's Movement         65min
Time Limit for Single Container's Replication      50min
Interval between each Iteration                    70min
Whether to Enable Network Topology                 false
Whether to Trigger Refresh Datanode Usage Info     false
Container IDs to Exclude from Balancing            None
Datanodes Specified to be Balanced                 None
Datanodes Excluded from Balancing                  None

2024-01-15 07:56:31,438 [main] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2024-01-15 07:56:31,441 [main] INFO upgrade.UpgradeFinalizer: Running pre-finalized state validations for unfinalized layout features.
2024-01-15 07:56:31,443 [main] INFO upgrade.UpgradeFinalizer: Running first upgrade commands for unfinalized layout features.
2024-01-15 07:56:31,443 [main] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
2024-01-15 07:56:31,446 [main] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
2024-01-15 07:56:31,449 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2024-01-15 07:56:31,451 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2024-01-15 07:56:31,451 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2024-01-15 07:56:31,473 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/683d5636-fdaa-48e7-9616-a9985e8d8993/in_use.lock acquired by nodename 7@scm3.org
2024-01-15 07:56:31,498 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=6, votedFor=4e866cc2-839f-4d23-a8df-7474513825dc} from /data/metadata/scm-ha/683d5636-fdaa-48e7-9616-a9985e8d8993/current/raft-meta
2024-01-15 07:56:31,573 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServer$Division: 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993: set configuration 93: peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894, 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894, 38ca2b18-7c52-4d7d-9687-c935ff383fee|scm3.org:9894]|listeners:[], old=null
2024-01-15 07:56:31,576 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2024-01-15 07:56:31,586 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2024-01-15 07:56:31,586 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-01-15 07:56:31,588 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-01-15 07:56:31,589 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2024-01-15 07:56:31,597 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2024-01-15 07:56:31,603 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2024-01-15 07:56:31,603 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-01-15 07:56:31,603 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-01-15 07:56:31,605 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO util.AwaitToRun: Thread[38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-cacheEviction-AwaitToRun,5,main] started
2024-01-15 07:56:31,610 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/683d5636-fdaa-48e7-9616-a9985e8d8993
2024-01-15 07:56:31,610 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2024-01-15 07:56:31,610 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2024-01-15 07:56:31,612 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2024-01-15 07:56:31,612 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2024-01-15 07:56:31,613 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2024-01-15 07:56:31,614 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2024-01-15 07:56:31,614 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-01-15 07:56:31,614 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2024-01-15 07:56:31,616 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554440 (custom)
2024-01-15 07:56:31,623 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-01-15 07:56:31,624 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2024-01-15 07:56:31,627 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2024-01-15 07:56:31,628 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2024-01-15 07:56:31,657 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServer$Division: 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993: set configuration 0: peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894]|listeners:[], old=null
2024-01-15 07:56:31,658 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/683d5636-fdaa-48e7-9616-a9985e8d8993/current/log_0-0
2024-01-15 07:56:31,659 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServer$Division: 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993: set configuration 1: peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894]|listeners:[], old=null
2024-01-15 07:56:31,669 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServer$Division: 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993: set configuration 23: peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894, 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894]|listeners:[], old=peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894]|listeners:[]
2024-01-15 07:56:31,671 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServer$Division: 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993: set configuration 25: peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894, 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894]|listeners:[], old=null
2024-01-15 07:56:31,676 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServer$Division: 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993: set configuration 41: peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894, 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894, 38ca2b18-7c52-4d7d-9687-c935ff383fee|scm3.org:9894]|listeners:[], old=peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894, 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894]|listeners:[]
2024-01-15 07:56:31,677 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServer$Division: 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993: set configuration 43: peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894, 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894, 38ca2b18-7c52-4d7d-9687-c935ff383fee|scm3.org:9894]|listeners:[], old=null
2024-01-15 07:56:31,682 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO segmented.LogSegment: Successfully read 70 entries from segment file /data/metadata/scm-ha/683d5636-fdaa-48e7-9616-a9985e8d8993/current/log_1-70
2024-01-15 07:56:31,683 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServer$Division: 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993: set configuration 71: peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894, 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894, 38ca2b18-7c52-4d7d-9687-c935ff383fee|scm3.org:9894]|listeners:[], old=null
2024-01-15 07:56:31,687 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO segmented.LogSegment: Successfully read 22 entries from segment file /data/metadata/scm-ha/683d5636-fdaa-48e7-9616-a9985e8d8993/current/log_71-92
2024-01-15 07:56:31,687 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServer$Division: 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993: set configuration 93: peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894, 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894, 38ca2b18-7c52-4d7d-9687-c935ff383fee|scm3.org:9894]|listeners:[], old=null
2024-01-15 07:56:31,751 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO segmented.LogSegment: Successfully read 12 entries from segment file /data/metadata/scm-ha/683d5636-fdaa-48e7-9616-a9985e8d8993/current/log_inprogress_93
2024-01-15 07:56:31,760 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 104
2024-01-15 07:56:31,760 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 92
2024-01-15 07:56:31,778 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO segmented.BufferedWriteChannel: open log_inprogress_93 (append) at position 1064
2024-01-15 07:56:31,788 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServer$Division: 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993: start as a follower, conf=93: peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894, 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894, 38ca2b18-7c52-4d7d-9687-c935ff383fee|scm3.org:9894]|listeners:[], old=null
2024-01-15 07:56:31,789 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServer$Division: 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993: changes role from      null to FOLLOWER at term 6 for startAsFollower
2024-01-15 07:56:31,790 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO impl.RoleInfo: 38ca2b18-7c52-4d7d-9687-c935ff383fee: start 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-FollowerState
2024-01-15 07:56:31,791 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2024-01-15 07:56:31,791 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-01-15 07:56:31,793 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A9985E8D8993,id=38ca2b18-7c52-4d7d-9687-c935ff383fee
2024-01-15 07:56:31,795 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-01-15 07:56:31,796 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-01-15 07:56:31,796 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2024-01-15 07:56:31,797 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2024-01-15 07:56:31,797 [38ca2b18-7c52-4d7d-9687-c935ff383fee-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2024-01-15 07:56:31,810 [main] INFO server.RaftServer: 38ca2b18-7c52-4d7d-9687-c935ff383fee: start RPC server
2024-01-15 07:56:31,922 [main] INFO server.GrpcService: 38ca2b18-7c52-4d7d-9687-c935ff383fee: GrpcService started, listening on 9894
2024-01-15 07:56:31,927 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-38ca2b18-7c52-4d7d-9687-c935ff383fee: Started
2024-01-15 07:56:31,942 [main] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894, 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894, 38ca2b18-7c52-4d7d-9687-c935ff383fee|scm3.org:9894]
2024-01-15 07:56:31,943 [main] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
2024-01-15 07:56:31,944 [main] INFO SCMHATransactionMonitor: Starting SCMHATransactionMonitor Service.
2024-01-15 07:56:31,945 [main] INFO ha.SCMServiceManager: Registering service SCMHATransactionMonitor.
2024-01-15 07:56:31,945 [main] INFO SCMHATransactionMonitor: SCMHATransactionMonitor Service is already running, skip start.
2024-01-15 07:56:32,037 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2024-01-15 07:56:32,098 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-01-15 07:56:32,102 [main] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
2024-01-15 07:56:33,237 [main] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
2024-01-15 07:56:33,257 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-01-15 07:56:33,261 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
2024-01-15 07:56:34,327 [main] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
2024-01-15 07:56:34,328 [main] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
2024-01-15 07:56:34,331 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-01-15 07:56:34,331 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
2024-01-15 07:56:34,563 [main] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
2024-01-15 07:56:34,593 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-01-15 07:56:34,594 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
2024-01-15 07:56:34,640 [main] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
2024-01-15 07:56:36,936 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-FollowerState] INFO impl.FollowerState: 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5146010434ns, electionTimeout:5115ms
2024-01-15 07:56:36,936 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-FollowerState] INFO impl.RoleInfo: 38ca2b18-7c52-4d7d-9687-c935ff383fee: shutdown 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-FollowerState
2024-01-15 07:56:37,013 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-FollowerState] INFO server.RaftServer$Division: 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993: changes role from  FOLLOWER to CANDIDATE at term 6 for changeToCandidate
2024-01-15 07:56:37,049 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
2024-01-15 07:56:37,049 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-FollowerState] INFO impl.RoleInfo: 38ca2b18-7c52-4d7d-9687-c935ff383fee: start 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-LeaderElection1
2024-01-15 07:56:37,239 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-LeaderElection1] INFO impl.LeaderElection: 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 6 for 93: peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894, 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894, 38ca2b18-7c52-4d7d-9687-c935ff383fee|scm3.org:9894]|listeners:[], old=null
2024-01-15 07:56:37,369 [main] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
2024-01-15 07:56:37,371 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
2024-01-15 07:56:37,414 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
2024-01-15 07:56:37,465 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2024-01-15 07:56:37,465 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-01-15 07:56:37,473 [38ca2b18-7c52-4d7d-9687-c935ff383fee-server-thread1] INFO server.RaftServer$Division: 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993: changes role from CANDIDATE to FOLLOWER at term 7 for appendEntries
2024-01-15 07:56:37,474 [38ca2b18-7c52-4d7d-9687-c935ff383fee-server-thread1] INFO impl.RoleInfo: 38ca2b18-7c52-4d7d-9687-c935ff383fee: shutdown 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-LeaderElection1
2024-01-15 07:56:37,492 [38ca2b18-7c52-4d7d-9687-c935ff383fee-server-thread1] INFO impl.RoleInfo: 38ca2b18-7c52-4d7d-9687-c935ff383fee: start 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-FollowerState
2024-01-15 07:56:37,543 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-LeaderElection1] INFO impl.LeaderElection: 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-LeaderElection1: PRE_VOTE REJECTED received 0 response(s) and 0 exception(s):
2024-01-15 07:56:37,543 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-LeaderElection1] INFO impl.LeaderElection: 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-LeaderElection1 PRE_VOTE round 0: result REJECTED
2024-01-15 07:56:37,544 [38ca2b18-7c52-4d7d-9687-c935ff383fee-server-thread1] INFO server.RaftServer$Division: 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993: set firstElectionSinceStartup to false for appendEntries
2024-01-15 07:56:37,550 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-LeaderElection1-2] INFO server.GrpcServerProtocolClient: Build channel for 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894
2024-01-15 07:56:37,555 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-LeaderElection1-1] INFO server.GrpcServerProtocolClient: Build channel for 4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894
2024-01-15 07:56:37,639 [38ca2b18-7c52-4d7d-9687-c935ff383fee-server-thread1] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
2024-01-15 07:56:37,653 [38ca2b18-7c52-4d7d-9687-c935ff383fee-server-thread1] INFO server.RaftServer$Division: 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993: change Leader from null to 4e866cc2-839f-4d23-a8df-7474513825dc at term 7 for appendEntries, leader elected after 7168ms
2024-01-15 07:56:37,802 [38ca2b18-7c52-4d7d-9687-c935ff383fee-server-thread1] INFO server.RaftServer$Division: 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993: Failed appendEntries as previous log entry ((t:7, i:108)) is not found
2024-01-15 07:56:37,929 [38ca2b18-7c52-4d7d-9687-c935ff383fee-server-thread1] INFO server.RaftServer$Division: 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993: inconsistency entries. Reply:4e866cc2-839f-4d23-a8df-7474513825dc<-38ca2b18-7c52-4d7d-9687-c935ff383fee#457:FAIL-t6,INCONSISTENCY,nextIndex=105,followerCommit=104,matchIndex=-1
2024-01-15 07:56:38,090 [38ca2b18-7c52-4d7d-9687-c935ff383fee-server-thread1] INFO server.RaftServer$Division: 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993: set configuration 105: peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894, 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894, 38ca2b18-7c52-4d7d-9687-c935ff383fee|scm3.org:9894]|listeners:[], old=null
2024-01-15 07:56:38,135 [38ca2b18-7c52-4d7d-9687-c935ff383fee-server-thread1] INFO segmented.SegmentedRaftLogWorker: 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-SegmentedRaftLogWorker: Rolling segment log-93_104 to index:104
2024-01-15 07:56:38,184 [main] INFO util.log: Logging initialized @10975ms to org.eclipse.jetty.util.log.Slf4jLog
2024-01-15 07:56:38,189 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/683d5636-fdaa-48e7-9616-a9985e8d8993/current/log_inprogress_93 to /data/metadata/scm-ha/683d5636-fdaa-48e7-9616-a9985e8d8993/current/log_93-104
2024-01-15 07:56:38,253 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-SegmentedRaftLogWorker] INFO segmented.BufferedWriteChannel: open log_inprogress_105 at position 0
2024-01-15 07:56:38,537 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/683d5636-fdaa-48e7-9616-a9985e8d8993/current/log_inprogress_105
2024-01-15 07:56:38,607 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 2, healthy pipeline threshold count is 1
2024-01-15 07:56:38,613 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
2024-01-15 07:56:38,622 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 2, pipeline's with at least one datanode reported threshold count is 2
2024-01-15 07:56:38,624 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
2024-01-15 07:56:38,680 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
2024-01-15 07:56:38,758 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-01-15 07:56:39,884 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Updating keys with [SecretKey(id = 17343b73-6203-4ee1-839d-499f80eed361, creation at: 2024-01-15T07:49:06.544Z, expire at: 2024-01-15T08:49:06.544Z)]
2024-01-15 07:56:39,903 [main] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
2024-01-15 07:56:39,909 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Current key updated SecretKey(id = 17343b73-6203-4ee1-839d-499f80eed361, creation at: 2024-01-15T07:49:06.544Z, expire at: 2024-01-15T08:49:06.544Z)
2024-01-15 07:56:40,023 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-01-15 07:56:40,076 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
2024-01-15 07:56:40,114 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2024-01-15 07:56:40,125 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2024-01-15 07:56:40,127 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
2024-01-15 07:56:40,806 [main] INFO http.BaseHttpServer: HTTP server of scm uses base directory /data/metadata/webserver
2024-01-15 07:56:40,810 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-StateMachineUpdater] INFO symmetric.LocalSecretKeyStore: Saved [SecretKey(id = 17343b73-6203-4ee1-839d-499f80eed361, creation at: 2024-01-15T07:49:06.544Z, expire at: 2024-01-15T08:49:06.544Z)] to file /data/metadata/scm/keys/secret_keys.json
2024-01-15 07:56:40,826 [main] INFO http.HttpServer2: Jetty bound to port 9876
2024-01-15 07:56:40,829 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 2, healthy pipeline threshold count is 1
2024-01-15 07:56:40,845 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
2024-01-15 07:56:40,846 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 2, pipeline's with at least one datanode reported threshold count is 2
2024-01-15 07:56:40,880 [main] INFO server.Server: jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 11.0.19+7-LTS
2024-01-15 07:56:41,082 [main] INFO server.session: DefaultSessionIdManager workerName=node0
2024-01-15 07:56:41,085 [main] INFO server.session: No SessionScavenger set, using defaults
2024-01-15 07:56:41,089 [main] INFO server.session: node0 Scavenging every 600000ms
2024-01-15 07:56:41,238 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
2024-01-15 07:56:41,256 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3dd66ff5{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
2024-01-15 07:56:41,257 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@36ecf9f6{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2024-01-15 07:56:41,861 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
2024-01-15 07:56:41,912 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1b7a4930{scm,/,file:///data/metadata/webserver/jetty-0_0_0_0-9876-hdds-server-scm-1_5_0-SNAPSHOT_jar-_-any-6086351577598104694/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.5.0-SNAPSHOT.jar!/webapps/scm}
2024-01-15 07:56:41,961 [main] INFO server.AbstractConnector: Started ServerConnector@6ad3fbe4{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
2024-01-15 07:56:41,962 [main] INFO server.Server: Started @14752ms
2024-01-15 07:56:41,973 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
2024-01-15 07:56:41,974 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
2024-01-15 07:56:41,980 [main] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
2024-01-15 07:56:42,024 [38ca2b18-7c52-4d7d-9687-c935ff383fee-scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2024-01-15 07:56:42,026 [38ca2b18-7c52-4d7d-9687-c935ff383fee-scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2024-01-15 07:56:42,067 [38ca2b18-7c52-4d7d-9687-c935ff383fee-scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: CA certificates are not changed.
2024-01-15 07:56:48,584 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:52312 / 10.9.0.18:52312
2024-01-15 07:56:48,643 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:56:49,766 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:47052 / 10.9.0.17:47052
2024-01-15 07:56:49,788 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:56:50,255 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:41868 / 10.9.0.20:41868
2024-01-15 07:56:50,322 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:41746 / 10.9.0.21:41746
2024-01-15 07:56:50,379 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:56:50,403 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:56:51,241 [IPC Server handler 73 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/5953220d-7af2-4159-933f-22262aae1e87
2024-01-15 07:56:51,246 [IPC Server handler 73 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 5953220d-7af2-4159-933f-22262aae1e87{ip: 10.9.0.18, host: ha_dn2_1.ha_net, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 484395141220, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2024-01-15 07:56:51,265 [scm3-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
2024-01-15 07:56:51,278 [scm3-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Pipelines with at least one datanode reported count is 0, required at least one datanode reported per pipeline count is 2
2024-01-15 07:56:51,278 [scm3-EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
2024-01-15 07:56:51,282 [scm3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-01-15 07:56:51,616 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:39300 / 10.9.0.19:39300
2024-01-15 07:56:51,693 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:56:52,224 [IPC Server handler 72 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/d8ef6392-c8b7-40ba-a1b4-c245afaf6945
2024-01-15 07:56:52,226 [IPC Server handler 72 on default port 9861] INFO node.SCMNodeManager: Registered datanode: d8ef6392-c8b7-40ba-a1b4-c245afaf6945{ip: 10.9.0.17, host: ha_dn1_1.ha_net, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 481078400134, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2024-01-15 07:56:52,228 [scm3-EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
2024-01-15 07:56:52,235 [scm3-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
2024-01-15 07:56:52,236 [scm3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-01-15 07:56:52,236 [scm3-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Pipelines with at least one datanode reported count is 2, required at least one datanode reported per pipeline count is 2
2024-01-15 07:56:52,236 [scm3-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2024-01-15 07:56:52,749 [IPC Server handler 30 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/577b93ae-aa5e-4de8-a35f-0c336284cb6e
2024-01-15 07:56:52,749 [IPC Server handler 30 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 577b93ae-aa5e-4de8-a35f-0c336284cb6e{ip: 10.9.0.20, host: ha_dn4_1.ha_net, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 480984214326, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2024-01-15 07:56:52,749 [scm3-EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
2024-01-15 07:56:52,753 [scm3-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
2024-01-15 07:56:52,754 [scm3-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
2024-01-15 07:56:52,754 [scm3-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
2024-01-15 07:56:52,753 [scm3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-01-15 07:56:52,772 [IPC Server handler 43 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/1ad0897d-1843-4d24-b971-4a92bbe2a364
2024-01-15 07:56:52,754 [scm3-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2024-01-15 07:56:52,779 [scm3-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
2024-01-15 07:56:52,779 [IPC Server handler 43 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 1ad0897d-1843-4d24-b971-4a92bbe2a364{ip: 10.9.0.21, host: ha_dn5_1.ha_net, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 483469243666, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2024-01-15 07:56:52,779 [scm3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-01-15 07:56:52,780 [scm3-EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
2024-01-15 07:56:53,224 [scm3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-01-15 07:56:53,870 [IPC Server handler 49 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/6df82867-8830-4371-a735-44f603d10388
2024-01-15 07:56:53,871 [IPC Server handler 49 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 6df82867-8830-4371-a735-44f603d10388{ip: 10.9.0.19, host: ha_dn3_1.ha_net, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 481034662901, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2024-01-15 07:56:53,871 [scm3-EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
2024-01-15 07:56:53,872 [scm3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2024-01-15 07:56:53,872 [scm3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
2024-01-15 07:56:53,872 [scm3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
2024-01-15 07:56:53,872 [scm3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
2024-01-15 07:56:53,872 [scm3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2024-01-15 07:57:10,158 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Stopping scm3-RatisPipelineUtilsThread.
2024-01-15 07:57:10,170 [scm3-RatisPipelineUtilsThread-0] WARN pipeline.BackgroundPipelineCreator: scm3-RatisPipelineUtilsThread is interrupted.
2024-01-15 07:57:10,344 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-StateMachineUpdater] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: RATIS_DATASTREAM_PORT_IN_DATANODEDETAILS.
2024-01-15 07:57:10,346 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-StateMachineUpdater] INFO upgrade.AbstractLayoutVersionManager: Layout feature RATIS_DATASTREAM_PORT_IN_DATANODEDETAILS has been finalized.
2024-01-15 07:57:10,364 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-StateMachineUpdater] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: WEBUI_PORTS_IN_DATANODEDETAILS.
2024-01-15 07:57:10,365 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-StateMachineUpdater] INFO upgrade.AbstractLayoutVersionManager: Layout feature WEBUI_PORTS_IN_DATANODEDETAILS has been finalized.
2024-01-15 07:57:10,382 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-StateMachineUpdater] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: HADOOP_PRC_PORTS_IN_DATANODEDETAILS.
2024-01-15 07:57:10,383 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-StateMachineUpdater] INFO upgrade.AbstractLayoutVersionManager: Layout feature HADOOP_PRC_PORTS_IN_DATANODEDETAILS has been finalized.
2024-01-15 07:57:10,383 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-StateMachineUpdater] INFO upgrade.AbstractLayoutVersionManager: Finalization is complete.
2024-01-15 07:57:10,386 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Starting scm3-RatisPipelineUtilsThread.
2024-01-15 07:57:10,386 [scm3-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Datanode 6df82867-8830-4371-a735-44f603d10388(ha_dn3_1.ha_net/10.9.0.19) moved to HEALTHY READONLY state.
2024-01-15 07:57:10,386 [scm3-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=05aed6cd-b189-4551-97b5-76e89ecb956c in state CLOSED which uses HEALTHY_READONLY datanode 6df82867-8830-4371-a735-44f603d10388. This will send close commands for its containers.
2024-01-15 07:57:10,387 [scm3-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=9a16f334-35fa-429b-9443-c54a2f17258f in state CLOSED which uses HEALTHY_READONLY datanode 6df82867-8830-4371-a735-44f603d10388. This will send close commands for its containers.
2024-01-15 07:57:10,387 [scm3-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=8d2d4132-d1ad-4792-b8b3-58645b77e67c in state CLOSED which uses HEALTHY_READONLY datanode 6df82867-8830-4371-a735-44f603d10388. This will send close commands for its containers.
2024-01-15 07:57:10,387 [scm3-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Datanode 5953220d-7af2-4159-933f-22262aae1e87(ha_dn2_1.ha_net/10.9.0.18) moved to HEALTHY READONLY state.
2024-01-15 07:57:10,387 [scm3-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=05f3cc29-ea59-41ee-adf1-15524c6ede5a in state CLOSED which uses HEALTHY_READONLY datanode 5953220d-7af2-4159-933f-22262aae1e87. This will send close commands for its containers.
2024-01-15 07:57:10,388 [scm3-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Datanode 577b93ae-aa5e-4de8-a35f-0c336284cb6e(ha_dn4_1.ha_net/10.9.0.20) moved to HEALTHY READONLY state.
2024-01-15 07:57:10,388 [scm3-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=05aed6cd-b189-4551-97b5-76e89ecb956c in state CLOSED which uses HEALTHY_READONLY datanode 577b93ae-aa5e-4de8-a35f-0c336284cb6e. This will send close commands for its containers.
2024-01-15 07:57:10,388 [scm3-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=8d2d4132-d1ad-4792-b8b3-58645b77e67c in state CLOSED which uses HEALTHY_READONLY datanode 577b93ae-aa5e-4de8-a35f-0c336284cb6e. This will send close commands for its containers.
2024-01-15 07:57:10,388 [scm3-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=f504e273-0ce2-4715-845a-959982386376 in state CLOSED which uses HEALTHY_READONLY datanode 577b93ae-aa5e-4de8-a35f-0c336284cb6e. This will send close commands for its containers.
2024-01-15 07:57:10,388 [scm3-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17) moved to HEALTHY READONLY state.
2024-01-15 07:57:10,389 [scm3-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=05aed6cd-b189-4551-97b5-76e89ecb956c in state CLOSED which uses HEALTHY_READONLY datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945. This will send close commands for its containers.
2024-01-15 07:57:10,389 [scm3-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=8d2d4132-d1ad-4792-b8b3-58645b77e67c in state CLOSED which uses HEALTHY_READONLY datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945. This will send close commands for its containers.
2024-01-15 07:57:10,389 [scm3-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=48b053ac-c1bd-4404-acc0-1be0d203e4b8 in state CLOSED which uses HEALTHY_READONLY datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945. This will send close commands for its containers.
2024-01-15 07:57:10,389 [scm3-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Datanode 1ad0897d-1843-4d24-b971-4a92bbe2a364(ha_dn5_1.ha_net/10.9.0.21) moved to HEALTHY READONLY state.
2024-01-15 07:57:10,389 [scm3-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=4aeba50b-28be-40f1-9953-3ea879790287 in state CLOSED which uses HEALTHY_READONLY datanode 1ad0897d-1843-4d24-b971-4a92bbe2a364. This will send close commands for its containers.
2024-01-15 07:57:16,183 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Updating keys with [SecretKey(id = 17343b73-6203-4ee1-839d-499f80eed361, creation at: 2024-01-15T07:49:06.544Z, expire at: 2024-01-15T08:49:06.544Z), SecretKey(id = 9bddd15d-aa6f-4d02-8759-c55324acb0bf, creation at: 2024-01-15T07:57:16.172Z, expire at: 2024-01-15T08:57:16.172Z)]
2024-01-15 07:57:16,183 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Current key updated SecretKey(id = 9bddd15d-aa6f-4d02-8759-c55324acb0bf, creation at: 2024-01-15T07:57:16.172Z, expire at: 2024-01-15T08:57:16.172Z)
2024-01-15 07:57:16,184 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-StateMachineUpdater] INFO symmetric.LocalSecretKeyStore: Saved [SecretKey(id = 9bddd15d-aa6f-4d02-8759-c55324acb0bf, creation at: 2024-01-15T07:57:16.172Z, expire at: 2024-01-15T08:57:16.172Z), SecretKey(id = 17343b73-6203-4ee1-839d-499f80eed361, creation at: 2024-01-15T07:49:06.544Z, expire at: 2024-01-15T08:49:06.544Z)] to file /data/metadata/scm/keys/secret_keys.json
2024-01-15 07:57:25,199 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:34912 / 10.9.0.18:34912
2024-01-15 07:57:25,209 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:57:25,210 [IPC Server handler 75 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:57:25,912 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:56610 / 10.9.0.17:56610
2024-01-15 07:57:25,950 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:57:25,951 [IPC Server handler 3 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:57:26,255 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:37576 / 10.9.0.21:37576
2024-01-15 07:57:26,266 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:57:26,267 [IPC Server handler 71 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:57:26,959 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:49050 / 10.9.0.20:49050
2024-01-15 07:57:26,985 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:57:26,985 [IPC Server handler 52 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:57:27,582 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:48040 / 10.9.0.19:48040
2024-01-15 07:57:27,606 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:57:27,607 [IPC Server handler 1 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:57:48,765 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for delTxnId, expected lastId is 0, actual lastId is 2000.
2024-01-15 07:57:55,195 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:45022 / 10.9.0.18:45022
2024-01-15 07:57:55,199 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:57:55,200 [IPC Server handler 72 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:57:55,885 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:48010 / 10.9.0.17:48010
2024-01-15 07:57:55,897 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:57:55,897 [IPC Server handler 51 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:57:56,250 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:33154 / 10.9.0.21:33154
2024-01-15 07:57:56,259 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:57:56,259 [IPC Server handler 71 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:57:56,952 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:35288 / 10.9.0.20:35288
2024-01-15 07:57:56,960 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:57:56,961 [IPC Server handler 52 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:57:57,580 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:33694 / 10.9.0.19:33694
2024-01-15 07:57:57,596 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:57:57,596 [IPC Server handler 1 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:58:25,198 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:45010 / 10.9.0.18:45010
2024-01-15 07:58:25,218 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:58:25,887 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:58650 / 10.9.0.17:58650
2024-01-15 07:58:25,928 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:58:25,928 [IPC Server handler 3 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:58:26,244 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:39990 / 10.9.0.21:39990
2024-01-15 07:58:26,260 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:58:26,948 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:53096 / 10.9.0.20:53096
2024-01-15 07:58:26,977 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:58:26,981 [IPC Server handler 53 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:58:27,621 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:38828 / 10.9.0.19:38828
2024-01-15 07:58:27,636 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:58:27,637 [IPC Server handler 0 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:58:27,717 [scm3-EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO node.ReadOnlyHealthyToHealthyNodeHandler: Datanode 5953220d-7af2-4159-933f-22262aae1e87(ha_dn2_1.ha_net/10.9.0.18) moved to HEALTHY state.
2024-01-15 07:58:27,717 [scm3-EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
2024-01-15 07:58:27,717 [scm3-EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO node.ReadOnlyHealthyToHealthyNodeHandler: Datanode 1ad0897d-1843-4d24-b971-4a92bbe2a364(ha_dn5_1.ha_net/10.9.0.21) moved to HEALTHY state.
2024-01-15 07:58:27,717 [scm3-EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
2024-01-15 07:58:55,186 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:35378 / 10.9.0.18:35378
2024-01-15 07:58:55,204 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:58:55,892 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:44754 / 10.9.0.17:44754
2024-01-15 07:58:55,909 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:58:55,910 [IPC Server handler 3 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:58:56,256 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:55668 / 10.9.0.21:55668
2024-01-15 07:58:56,279 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:58:56,958 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:44024 / 10.9.0.20:44024
2024-01-15 07:58:56,989 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:58:56,990 [IPC Server handler 63 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:58:57,298 [scm3-EventQueue-PipelineReportForPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
  id: "344d6bd2-8230-408d-b722-5cb7a85c3652"
  uuid128 {
    mostSigBits: 3768787015050477709
    leastSigBits: -5250532271687190958
  }
}
isLeader: false
bytesWritten: 0
 from dn=1ad0897d-1843-4d24-b971-4a92bbe2a364(ha_dn5_1.ha_net/10.9.0.21).
org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993 is not the leader 4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.translateException(SCMHAInvocationHandler.java:165)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:115)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:74)
	at com.sun.proxy.$Proxy20.updatePipelineState(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.openPipeline(PipelineManagerImpl.java:430)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.processPipelineReport(PipelineReportHandler.java:135)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:52)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:86)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993 is not the leader 4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894
	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:807)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:772)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:758)
	at org.apache.ratis.server.impl.RaftServerImpl.writeAsync(RaftServerImpl.java:938)
	at org.apache.ratis.server.impl.RaftServerImpl.replyFuture(RaftServerImpl.java:931)
	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:908)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$13(RaftServerImpl.java:897)
	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:118)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$14(RaftServerImpl.java:897)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
	... 3 more
2024-01-15 07:58:57,578 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:55158 / 10.9.0.19:55158
2024-01-15 07:58:57,619 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:58:57,620 [IPC Server handler 0 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:25,894 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:44882 / 10.9.0.17:44882
2024-01-15 07:59:25,903 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:59:25,904 [IPC Server handler 51 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:26,943 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:56052 / 10.9.0.20:56052
2024-01-15 07:59:26,947 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:59:26,949 [IPC Server handler 52 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:27,130 [IPC Server handler 60 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:27,138 [IPC Server handler 55 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:27,140 [scm3-FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Moving container #1 to QUASI_CLOSED state, datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17) reported QUASI_CLOSED replica.
2024-01-15 07:59:27,141 [scm3-FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Failed to process QUASI_CLOSED container #1: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993 is not the leader 4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894
2024-01-15 07:59:27,166 [IPC Server handler 67 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:27,178 [IPC Server handler 69 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:27,179 [scm3-FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Moving container #1001 to QUASI_CLOSED state, datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17) reported QUASI_CLOSED replica.
2024-01-15 07:59:27,180 [scm3-FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Failed to process QUASI_CLOSED container #1001: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993 is not the leader 4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894
2024-01-15 07:59:27,577 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:37510 / 10.9.0.19:37510
2024-01-15 07:59:27,585 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:59:27,585 [IPC Server handler 1 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:27,707 [IPC Server handler 4 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:27,724 [IPC Server handler 5 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:27,725 [scm3-FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Moving container #2 to QUASI_CLOSED state, datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17) reported QUASI_CLOSED replica.
2024-01-15 07:59:27,726 [scm3-FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Failed to process QUASI_CLOSED container #2: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993 is not the leader 4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894
2024-01-15 07:59:27,734 [IPC Server handler 6 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:27,745 [IPC Server handler 9 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:27,748 [scm3-FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Moving container #1002 to QUASI_CLOSED state, datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17) reported QUASI_CLOSED replica.
2024-01-15 07:59:27,750 [scm3-FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Failed to process QUASI_CLOSED container #1002: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993 is not the leader 4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894
2024-01-15 07:59:28,123 [IPC Server handler 60 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:28,141 [IPC Server handler 58 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:28,157 [IPC Server handler 54 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:28,167 [IPC Server handler 66 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:28,713 [IPC Server handler 5 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:28,721 [IPC Server handler 6 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:28,726 [IPC Server handler 7 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:28,731 [IPC Server handler 10 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:29,197 [IPC Server handler 72 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:29,204 [IPC Server handler 75 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:29,211 [IPC Server handler 74 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:29,217 [IPC Server handler 71 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:29,703 [IPC Server handler 4 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:29,713 [IPC Server handler 5 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:29,720 [IPC Server handler 6 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:29,727 [IPC Server handler 7 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:31,304 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:54422 / 10.9.0.18:54422
2024-01-15 07:59:31,339 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:59:32,408 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:40452 / 10.9.0.21:40452
2024-01-15 07:59:32,431 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:59:57,778 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:50326 / 10.9.0.17:50326
2024-01-15 07:59:57,797 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:59:58,754 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:37270 / 10.9.0.20:37270
2024-01-15 07:59:58,770 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:59:59,753 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:37452 / 10.9.0.19:37452
2024-01-15 07:59:59,773 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:00:00,722 [scm3-EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO node.ReadOnlyHealthyToHealthyNodeHandler: Datanode 6df82867-8830-4371-a735-44f603d10388(ha_dn3_1.ha_net/10.9.0.19) moved to HEALTHY state.
2024-01-15 08:00:00,722 [scm3-EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
2024-01-15 08:00:00,722 [scm3-EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO node.ReadOnlyHealthyToHealthyNodeHandler: Datanode 577b93ae-aa5e-4de8-a35f-0c336284cb6e(ha_dn4_1.ha_net/10.9.0.20) moved to HEALTHY state.
2024-01-15 08:00:00,722 [scm3-EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
2024-01-15 08:00:00,722 [scm3-EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO node.ReadOnlyHealthyToHealthyNodeHandler: Datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17) moved to HEALTHY state.
2024-01-15 08:00:00,722 [scm3-EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
2024-01-15 08:00:01,317 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:59376 / 10.9.0.18:59376
2024-01-15 08:00:01,332 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:00:02,457 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:37118 / 10.9.0.21:37118
2024-01-15 08:00:02,486 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:00:07,872 [scm3-EventQueue-PipelineReportForPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
  id: "b9bdfe39-f2aa-46ec-8637-d4e42024cba9"
  uuid128 {
    mostSigBits: -5062610881256732948
    leastSigBits: -8775311272651207767
  }
}
isLeader: true
bytesWritten: 0
 from dn=6df82867-8830-4371-a735-44f603d10388(ha_dn3_1.ha_net/10.9.0.19).
org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993 is not the leader 4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.translateException(SCMHAInvocationHandler.java:165)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:115)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:74)
	at com.sun.proxy.$Proxy20.updatePipelineState(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.openPipeline(PipelineManagerImpl.java:430)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.processPipelineReport(PipelineReportHandler.java:135)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:52)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:86)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993 is not the leader 4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894
	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:807)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:772)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:758)
	at org.apache.ratis.server.impl.RaftServerImpl.writeAsync(RaftServerImpl.java:938)
	at org.apache.ratis.server.impl.RaftServerImpl.replyFuture(RaftServerImpl.java:931)
	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:908)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$13(RaftServerImpl.java:897)
	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:118)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$14(RaftServerImpl.java:897)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
	... 3 more
2024-01-15 08:00:09,253 [scm3-EventQueue-PipelineReportForPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
  id: "9dad8ba8-a15e-48be-84a4-45ae75dd8fcc"
  uuid128 {
    mostSigBits: -7084853082405844802
    leastSigBits: -8888903148918435892
  }
}
isLeader: true
bytesWritten: 0
 from dn=d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17).
org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993 is not the leader 4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.translateException(SCMHAInvocationHandler.java:165)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:115)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:74)
	at com.sun.proxy.$Proxy20.updatePipelineState(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.openPipeline(PipelineManagerImpl.java:430)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.processPipelineReport(PipelineReportHandler.java:135)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:52)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:86)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993 is not the leader 4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894
	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:807)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:772)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:758)
	at org.apache.ratis.server.impl.RaftServerImpl.writeAsync(RaftServerImpl.java:938)
	at org.apache.ratis.server.impl.RaftServerImpl.replyFuture(RaftServerImpl.java:931)
	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:908)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$13(RaftServerImpl.java:897)
	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:118)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$14(RaftServerImpl.java:897)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
	... 3 more
2024-01-15 08:00:28,832 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:36890 / 10.9.0.17:36890
2024-01-15 08:00:28,862 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:00:28,864 [scm3-EventQueue-PipelineReportForPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
  id: "b8376600-aa0d-4667-948d-af548f80b617"
  uuid128 {
    mostSigBits: -5172553493972695449
    leastSigBits: -7742339406660323817
  }
}
isLeader: false
bytesWritten: 0
 from dn=d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17).
org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993 is not the leader 4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.translateException(SCMHAInvocationHandler.java:165)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:115)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:74)
	at com.sun.proxy.$Proxy20.updatePipelineState(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.openPipeline(PipelineManagerImpl.java:430)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.processPipelineReport(PipelineReportHandler.java:135)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:52)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:86)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993 is not the leader 4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894
	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:807)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:772)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:758)
	at org.apache.ratis.server.impl.RaftServerImpl.writeAsync(RaftServerImpl.java:938)
	at org.apache.ratis.server.impl.RaftServerImpl.replyFuture(RaftServerImpl.java:931)
	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:908)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$13(RaftServerImpl.java:897)
	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:118)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$14(RaftServerImpl.java:897)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
	... 3 more
2024-01-15 08:00:29,798 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:51352 / 10.9.0.20:51352
2024-01-15 08:00:29,816 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:00:29,818 [scm3-EventQueue-PipelineReportForPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
  id: "2c08dffb-8e6a-44c0-87e0-7e8cf5449e0e"
  uuid128 {
    mostSigBits: 3173032209001628864
    leastSigBits: -8655779339930657266
  }
}
isLeader: false
bytesWritten: 0
 from dn=577b93ae-aa5e-4de8-a35f-0c336284cb6e(ha_dn4_1.ha_net/10.9.0.20).
org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993 is not the leader 4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.translateException(SCMHAInvocationHandler.java:165)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:115)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:74)
	at com.sun.proxy.$Proxy20.updatePipelineState(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.openPipeline(PipelineManagerImpl.java:430)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.processPipelineReport(PipelineReportHandler.java:135)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:52)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:86)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993 is not the leader 4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894
	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:807)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:772)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:758)
	at org.apache.ratis.server.impl.RaftServerImpl.writeAsync(RaftServerImpl.java:938)
	at org.apache.ratis.server.impl.RaftServerImpl.replyFuture(RaftServerImpl.java:931)
	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:908)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$13(RaftServerImpl.java:897)
	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:118)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$14(RaftServerImpl.java:897)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
	... 3 more
2024-01-15 08:00:30,805 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:41430 / 10.9.0.19:41430
2024-01-15 08:00:30,831 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:00:30,834 [scm3-EventQueue-PipelineReportForPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
  id: "c926dcb5-cbc9-427d-9689-f0e2819cfaeb"
  uuid128 {
    mostSigBits: -3952228949604875651
    leastSigBits: -7599278040583177493
  }
}
isLeader: false
bytesWritten: 0
 from dn=6df82867-8830-4371-a735-44f603d10388(ha_dn3_1.ha_net/10.9.0.19).
org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993 is not the leader 4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.translateException(SCMHAInvocationHandler.java:165)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:115)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:74)
	at com.sun.proxy.$Proxy20.updatePipelineState(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.openPipeline(PipelineManagerImpl.java:430)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.processPipelineReport(PipelineReportHandler.java:135)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:52)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:86)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993 is not the leader 4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894
	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:807)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:772)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:758)
	at org.apache.ratis.server.impl.RaftServerImpl.writeAsync(RaftServerImpl.java:938)
	at org.apache.ratis.server.impl.RaftServerImpl.replyFuture(RaftServerImpl.java:931)
	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:908)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$13(RaftServerImpl.java:897)
	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:118)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$14(RaftServerImpl.java:897)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
	... 3 more
2024-01-15 08:00:32,306 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:51444 / 10.9.0.18:51444
2024-01-15 08:00:32,345 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:00:33,931 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:49134 / 10.9.0.21:49134
2024-01-15 08:00:33,959 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:01:02,320 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:57214 / 10.9.0.18:57214
2024-01-15 08:01:02,331 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:01:03,928 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:35980 / 10.9.0.17:35980
2024-01-15 08:01:03,929 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:56118 / 10.9.0.21:56118
2024-01-15 08:01:03,936 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:01:03,957 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:01:03,984 [scm3-EventQueue-DeleteBlockStatusForDeletedBlockLogImpl] INFO block.DeletedBlockLogImpl: Skip commit transactions since current SCM is not leader.
2024-01-15 08:01:04,869 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:38652 / 10.9.0.20:38652
2024-01-15 08:01:04,876 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:01:04,876 [scm3-EventQueue-DeleteBlockStatusForDeletedBlockLogImpl] INFO block.DeletedBlockLogImpl: Skip commit transactions since current SCM is not leader.
2024-01-15 08:01:06,035 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:46458 / 10.9.0.19:46458
2024-01-15 08:01:06,089 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:01:06,093 [scm3-EventQueue-DeleteBlockStatusForDeletedBlockLogImpl] INFO block.DeletedBlockLogImpl: Skip commit transactions since current SCM is not leader.
2024-01-15 08:01:30,766 [scm3-ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 5000ms after safemode exit
2024-01-15 08:01:32,339 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:35950 / 10.9.0.18:35950
2024-01-15 08:01:32,371 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:01:33,902 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:38100 / 10.9.0.17:38100
2024-01-15 08:01:33,940 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:01:33,943 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:51506 / 10.9.0.21:51506
2024-01-15 08:01:33,962 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:01:34,871 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:60280 / 10.9.0.20:60280
2024-01-15 08:01:34,890 [scm3-FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Moving container #1001 to CLOSED state, datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17) reported CLOSED replica.
2024-01-15 08:01:34,893 [scm3-FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Failed to process CLOSED container #1001: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993 is not the leader 4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894
2024-01-15 08:01:34,896 [scm3-FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Moving container #1 to CLOSED state, datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17) reported CLOSED replica.
2024-01-15 08:01:34,897 [scm3-FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Failed to process CLOSED container #1: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993 is not the leader 4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894
2024-01-15 08:01:34,898 [scm3-FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Moving container #2 to CLOSED state, datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17) reported CLOSED replica.
2024-01-15 08:01:34,900 [scm3-FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Failed to process CLOSED container #2: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993 is not the leader 4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894
2024-01-15 08:01:34,920 [scm3-FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Moving container #1002 to CLOSED state, datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17) reported CLOSED replica.
2024-01-15 08:01:34,921 [scm3-FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Failed to process CLOSED container #1002: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993 is not the leader 4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894
2024-01-15 08:01:34,941 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:01:36,039 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:55074 / 10.9.0.19:55074
2024-01-15 08:01:36,048 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:01:58,369 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for containerId, expected lastId is 0, actual lastId is 2000.
2024-01-15 08:01:58,390 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 113750153625603000.
2024-01-15 08:01:59,736 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:35972 / 10.9.0.17:35972
2024-01-15 08:01:59,756 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:52120 / 10.9.0.20:52120
2024-01-15 08:01:59,783 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:01:59,816 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:01:59,887 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:51762 / 10.9.0.21:51762
2024-01-15 08:01:59,967 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:02:02,307 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:33854 / 10.9.0.18:33854
2024-01-15 08:02:02,328 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:02:07,057 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:51290 / 10.9.0.19:51290
2024-01-15 08:02:07,071 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:02:16,182 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Updating keys with [SecretKey(id = 9bddd15d-aa6f-4d02-8759-c55324acb0bf, creation at: 2024-01-15T07:57:16.172Z, expire at: 2024-01-15T08:57:16.172Z), SecretKey(id = 17343b73-6203-4ee1-839d-499f80eed361, creation at: 2024-01-15T07:49:06.544Z, expire at: 2024-01-15T08:49:06.544Z), SecretKey(id = c1f6048b-6d4b-45eb-9ff8-10fd96802102, creation at: 2024-01-15T08:02:16.172Z, expire at: 2024-01-15T09:02:16.172Z)]
2024-01-15 08:02:16,183 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Current key updated SecretKey(id = c1f6048b-6d4b-45eb-9ff8-10fd96802102, creation at: 2024-01-15T08:02:16.172Z, expire at: 2024-01-15T09:02:16.172Z)
2024-01-15 08:02:16,184 [38ca2b18-7c52-4d7d-9687-c935ff383fee@group-A9985E8D8993-StateMachineUpdater] INFO symmetric.LocalSecretKeyStore: Saved [SecretKey(id = c1f6048b-6d4b-45eb-9ff8-10fd96802102, creation at: 2024-01-15T08:02:16.172Z, expire at: 2024-01-15T09:02:16.172Z), SecretKey(id = 9bddd15d-aa6f-4d02-8759-c55324acb0bf, creation at: 2024-01-15T07:57:16.172Z, expire at: 2024-01-15T08:57:16.172Z), SecretKey(id = 17343b73-6203-4ee1-839d-499f80eed361, creation at: 2024-01-15T07:49:06.544Z, expire at: 2024-01-15T08:49:06.544Z)] to file /data/metadata/scm/keys/secret_keys.json
2024-01-15 08:02:18,400 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:45746 / 10.9.0.17:45746
2024-01-15 08:02:18,407 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:46862 / 10.9.0.19:46862
2024-01-15 08:02:18,428 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:36762 / 10.9.0.21:36762
2024-01-15 08:02:18,453 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:02:18,456 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:02:18,483 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:02:37,481 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:39252 / 10.9.0.20:39252
2024-01-15 08:02:37,509 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:02:37,588 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:39582 / 10.9.0.18:39582
2024-01-15 08:02:37,599 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:02:48,401 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:33566 / 10.9.0.17:33566
2024-01-15 08:02:48,442 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:02:48,448 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:34070 / 10.9.0.21:34070
2024-01-15 08:02:48,456 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:42360 / 10.9.0.19:42360
2024-01-15 08:02:48,482 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:02:48,501 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:03:07,495 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:46494 / 10.9.0.20:46494
2024-01-15 08:03:07,510 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:03:07,584 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:41356 / 10.9.0.18:41356
2024-01-15 08:03:07,594 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:03:18,401 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:53432 / 10.9.0.19:53432
2024-01-15 08:03:18,402 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:35834 / 10.9.0.21:35834
2024-01-15 08:03:18,419 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:46856 / 10.9.0.17:46856
2024-01-15 08:03:18,426 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:03:18,435 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:03:18,450 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:03:37,489 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:56744 / 10.9.0.20:56744
2024-01-15 08:03:37,534 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:03:37,603 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:40642 / 10.9.0.18:40642
2024-01-15 08:03:37,614 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:03:48,380 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:33920 / 10.9.0.17:33920
2024-01-15 08:03:48,385 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:36492 / 10.9.0.19:36492
2024-01-15 08:03:48,405 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:03:48,418 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:39554 / 10.9.0.21:39554
2024-01-15 08:03:48,438 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:03:48,487 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
