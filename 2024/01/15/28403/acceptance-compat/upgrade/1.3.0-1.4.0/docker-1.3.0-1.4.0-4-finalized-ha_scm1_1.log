Waiting for the service kdc:88
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2024-01-15 07:55:56,836 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = scm1.org/10.9.0.14
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.5.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jgraphx-2.0.0.1.jar:/opt/hadoop/share/ozone/lib/commons-net-3.10.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/okhttp-4.12.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.9.22.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.3.2.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.25.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-2.0.10.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.6.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.2.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.16.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-text-1.10.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.6.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.0.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.16.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/okio-3.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-2.0.10.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.9.22.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.5.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.9.22.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.12.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/jgraph-5.13.0.0.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/antlr4-runtime-4.5.3.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.5.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.25.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.9.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-1.2.2.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.9.22.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.16.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.14.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.58.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.9.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.0.1.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.5.0-SNAPSHOT.jar
STARTUP_MSG:   build = https://github.com/apache/ozone/26be5d9ce6d871bdab56b32fdc8bb85511f51f24 ; compiled by 'runner' on 2024-01-15T07:23Z
STARTUP_MSG:   java = 11.0.19
STARTUP_MSG:   conf = {dfs.container.chunk.write.sync=false, dfs.container.ipc=9859, dfs.container.ipc.random.port=false, dfs.container.ratis.admin.port=9857, dfs.container.ratis.datastream.enabled=false, dfs.container.ratis.datastream.port=9855, dfs.container.ratis.datastream.random.port=false, dfs.container.ratis.enabled=false, dfs.container.ratis.ipc=9858, dfs.container.ratis.ipc.random.port=false, dfs.container.ratis.leader.pending.bytes.limit=1GB, dfs.container.ratis.log.appender.queue.byte-limit=32MB, dfs.container.ratis.log.appender.queue.num-elements=1, dfs.container.ratis.log.purge.gap=1000000, dfs.container.ratis.log.queue.byte-limit=4GB, dfs.container.ratis.log.queue.num-elements=1024, dfs.container.ratis.num.container.op.executors=10, dfs.container.ratis.num.write.chunk.threads.per.volume=10, dfs.container.ratis.replication.level=MAJORITY, dfs.container.ratis.rpc.type=GRPC, dfs.container.ratis.segment.preallocated.size=4MB, dfs.container.ratis.segment.size=64MB, dfs.container.ratis.server.port=9856, dfs.container.ratis.statemachine.max.pending.apply-transactions=10000, dfs.container.ratis.statemachinedata.sync.timeout=10s, dfs.ratis.leader.election.minimum.timeout.duration=5s, dfs.ratis.server.retry-cache.timeout.duration=600000ms, dfs.ratis.snapshot.threshold=10000, hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=true, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.close.threshold=0.9f, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=false, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=true, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/db@EXAMPLE.COM, hdds.datanode.http.auth.type=kerberos, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=true, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/scm@EXAMPLE.COM, hdds.scm.http.auth.type=kerberos, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/scm.keytab, hdds.scm.kerberos.principal=scm/scm@EXAMPLE.COM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=3, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5s, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=10m, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=1h, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=1m, hdds.secret.key.rotate.duration=5m, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneNativeAuthorizer, ozone.acl.enabled=true, ozone.administrators=testuser,recon,om, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=6, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.directory.deleting.service.interval=1m, ozone.ec.grpc.zerocopy.enabled=true, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.http.filter.initializers=org.apache.hadoop.security.AuthenticationFilterInitializer, ozone.http.policy=HTTP_ONLY, ozone.httpfs.http.auth.kerberos.keytab=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.http.auth.kerberos.principal=HTTP/httpfs@EXAMPLE.COM, ozone.httpfs.http.auth.type=kerberos, ozone.httpfs.kerberos.keytab.file=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.kerberos.principal=httpfs/httpfs@EXAMPLE.COM, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=0.0.0.0:9862, ozone.om.address.omservice.om1=om1, ozone.om.address.omservice.om2=om2, ozone.om.address.omservice.om3=om3, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=0.0.0.0:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/om@EXAMPLE.COM, ozone.om.http.auth.type=kerberos, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.kerberos.keytab.file=/etc/security/keytabs/om.keytab, ozone.om.kerberos.principal=om/om@EXAMPLE.COM, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.nodes.omservice=om1,om2,om3, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.service.ids=omservice, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.load.native.lib=true, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.sst_dumptool.buffer.size=8KB, ozone.om.snapshot.sst_dumptool.pool.size=1, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.volume.listall.allowed=true, ozone.path.deleting.limit.per.task=6000, ozone.recon.address=recon:9891, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/recon.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/recon@EXAMPLE.COM, ozone.recon.http.auth.type=kerberos, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.kerberos.keytab.file=/etc/security/keytabs/recon.keytab, ozone.recon.kerberos.principal=recon/recon@EXAMPLE.COM, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=1m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.scmclient.failover.max.retry=3, ozone.recon.scmclient.max.retry.timeout=6s, ozone.recon.scmclient.rpc.timeout=1m, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3.administrators=testuser,s3g, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/s3g@EXAMPLE.COM, ozone.s3g.http.auth.type=kerberos, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/s3g@EXAMPLE.COM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.metrics.percentiles.intervals.seconds=60, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=true, ozone.s3g.volume.name=s3v, ozone.scm.address.scmservice.scm1=scm1.org, ozone.scm.address.scmservice.scm2=scm2.org, ozone.scm.address.scmservice.scm3=scm3.org, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.handler.count.key=100, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.handler.count.key=100, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=150s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.handler.count.key=100, ozone.scm.datanode.id.dir=/data, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=1GB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.nodes.scmservice=scm1,scm2,scm3, ozone.scm.pipeline.allocated.timeout=2m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=30s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=1m, ozone.scm.primordial.node.id=scm1, ozone.scm.ratis.enable=true, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.service.ids=scmservice, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=true, ozone.security.http.kerberos.enabled=true, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.directory.service.interval=24h, ozone.snapshot.directory.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.trace.enabled=false, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2024-01-15 07:55:56,847 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2024-01-15 07:55:57,034 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-01-15 07:55:59,075 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2024-01-15 07:55:59,113 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2024-01-15 07:55:59,218 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
2024-01-15 07:55:59,222 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
2024-01-15 07:56:01,029 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
2024-01-15 07:56:01,030 [main] INFO server.StorageContainerManager: SCM login successful.
2024-01-15 07:56:06,124 [main] INFO client.SCMCertificateClient: Certificate serial ID set to 460033252902
2024-01-15 07:56:07,184 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 460033252902
             IssuerDN: CN=scm@scm1.org,OU=4e866cc2-839f-4d23-a8df-7474513825dc,O=CID-683d5636-fdaa-48e7-9616-a9985e8d8993
           Start Date: Mon Jan 15 00:00:00 UTC 2024
           Final Date: Thu Feb 22 00:00:00 UTC 2029
            SubjectDN: CN=scm-sub@scm1.org,OU=4e866cc2-839f-4d23-a8df-7474513825dc,O=CID-683d5636-fdaa-48e7-9616-a9985e8d8993
           Public Key: RSA Public Key [84:41:0f:07:79:7a:a5:b1:0f:2e:5f:f2:a9:b9:1d:d8:c5:5e:8d:10],[56:66:d1:a4]
        modulus: ca72844dc398048a414b86eb8795aa8b5f487989c4ffb32ad671696942468db8f19f324bb827269f5d729d0b10acdda0025013fa26beba4c764d52a2930c09b2b1f45b7159bfbaaba5182d609c1c9dd48b49b40a5f2c26530f78a14a709dc293d85576a242d3fbd605b6b9b463175518cff2c797633d1e4935cf511d5370ec3a622b545ef6f68f7c2194f160e833c6c06ffb1f7545e57146e843f8a203ac46169612c18eeca8b05c769f81b2ea67364e6a67e882358501f0350fee00fe65ed955788cb61588567968b120fa1872c9fc0e253ec93d97281bcc0e68d313635e468a7b35b042e8264f4fcba752947183523533f3d94d64ed89bee90cbc7f1ed1ad7
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 73fe11fa40ccd1a8b41462431bcbfe660e58d699
                       33380ce947193477ae0d390a944ef25b68f9d7f6
                       4c9be47825c8922e268f0186197c755da5fc6de3
                       7ca388a3d56d369023ff63384f9b78bd841c27a5
                       b3e841f56891dd05b530324c12ed8cc47c26a1fe
                       653ed78c88f709a848e0ce2b69d653430e309e5a
                       9d3a60c6307eb2ae00a62963a482a1a6cb16ddaa
                       435984e39094514c012c392e41f1a3ba3f472cdf
                       0a91da1fe4b4035733f7f03fa0cd811ff520a948
                       4717807778bb462ab730b7d0d4dbf7e113387a25
                       527a5ea4cfa7262258255582b1a4df568d70a225
                       e0110f5317e314725a764742f31eb036abeee482
                       d722047a3ff388e5f2735f32ed2f597b
       Extensions: 
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0xbe
 from file: /data/metadata/scm/sub-ca/certs/460033252902.crt.
2024-01-15 07:56:07,249 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm@scm1.org,OU=4e866cc2-839f-4d23-a8df-7474513825dc,O=CID-683d5636-fdaa-48e7-9616-a9985e8d8993
           Start Date: Mon Jan 15 00:00:00 UTC 2024
           Final Date: Thu Feb 22 23:59:59 UTC 2029
            SubjectDN: CN=scm@scm1.org,OU=4e866cc2-839f-4d23-a8df-7474513825dc,O=CID-683d5636-fdaa-48e7-9616-a9985e8d8993
           Public Key: RSA Public Key [b6:de:f5:8e:72:d2:97:92:9c:3a:15:75:3e:75:7b:70:2d:a6:c7:3d],[56:66:d1:a4]
        modulus: a681591e4465f9d9683ded5e8f66013d905bf8a1dc7a2802c24e4e026f7be29ca2d08dd24c3720053cc8f3679c1c27fb8ff1ba086bf6979c1e68cf3b2f3a6d937f1602fcf1f6501e12798fd0ecdbfa7fc7ff41ccd7155857171c166e6c181cd58026c3cdd072fd8374a522025290515a420ef309565dd1766c11c7bda1f2025af916f8ad60dbc67523d97182d320d35b6d682c3c0ad69b50abc15b8dc22de645051a249533caa6a63ead563847172c98ade7f737f8de987f711550482b03a016b995c3c7c07f33e94e82208067e8e32d32e4f77217731dd92582186993adbc5b022dc2167fafc87292fe4fe504e50afe5d10b84ef700f10c375aad65175a91c9
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 2ae22a8da2895c040a2500bf876b36dc19784fb4
                       04963d3d73675cf47f79516ee501c7d54491ed07
                       5bdf8b36333f6126386d95cc6251798ab33c57e7
                       7a4afd28641d4ac4db1c3ee1a5dca16f08a2635d
                       69611bc9328ce2293c96ce6f5638fe4a643ed777
                       2f2867816d116d0625f9f5523a8e8541854c0837
                       59ab2dec467935250654080966693df94bdc11ff
                       9bca39217968061569ab7a92c164dd1d56d34864
                       8c3c84658f7f7814dc56ac86e9ad61804de72c03
                       e09df96299b292842803e1b69b30889141361fd3
                       de12bfe1f7d781ef1f8b23976d5b7baee71a7035
                       a5e0b3773f1cb41995787c383c161465552b00cb
                       249c7ed77b6edea9f284d8f497192ae9
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

 from file: /data/metadata/scm/sub-ca/certs/CA-1.crt.
2024-01-15 07:56:07,301 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 460033252902
             IssuerDN: CN=scm@scm1.org,OU=4e866cc2-839f-4d23-a8df-7474513825dc,O=CID-683d5636-fdaa-48e7-9616-a9985e8d8993
           Start Date: Mon Jan 15 00:00:00 UTC 2024
           Final Date: Thu Feb 22 00:00:00 UTC 2029
            SubjectDN: CN=scm-sub@scm1.org,OU=4e866cc2-839f-4d23-a8df-7474513825dc,O=CID-683d5636-fdaa-48e7-9616-a9985e8d8993
           Public Key: RSA Public Key [84:41:0f:07:79:7a:a5:b1:0f:2e:5f:f2:a9:b9:1d:d8:c5:5e:8d:10],[56:66:d1:a4]
        modulus: ca72844dc398048a414b86eb8795aa8b5f487989c4ffb32ad671696942468db8f19f324bb827269f5d729d0b10acdda0025013fa26beba4c764d52a2930c09b2b1f45b7159bfbaaba5182d609c1c9dd48b49b40a5f2c26530f78a14a709dc293d85576a242d3fbd605b6b9b463175518cff2c797633d1e4935cf511d5370ec3a622b545ef6f68f7c2194f160e833c6c06ffb1f7545e57146e843f8a203ac46169612c18eeca8b05c769f81b2ea67364e6a67e882358501f0350fee00fe65ed955788cb61588567968b120fa1872c9fc0e253ec93d97281bcc0e68d313635e468a7b35b042e8264f4fcba752947183523533f3d94d64ed89bee90cbc7f1ed1ad7
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 73fe11fa40ccd1a8b41462431bcbfe660e58d699
                       33380ce947193477ae0d390a944ef25b68f9d7f6
                       4c9be47825c8922e268f0186197c755da5fc6de3
                       7ca388a3d56d369023ff63384f9b78bd841c27a5
                       b3e841f56891dd05b530324c12ed8cc47c26a1fe
                       653ed78c88f709a848e0ce2b69d653430e309e5a
                       9d3a60c6307eb2ae00a62963a482a1a6cb16ddaa
                       435984e39094514c012c392e41f1a3ba3f472cdf
                       0a91da1fe4b4035733f7f03fa0cd811ff520a948
                       4717807778bb462ab730b7d0d4dbf7e113387a25
                       527a5ea4cfa7262258255582b1a4df568d70a225
                       e0110f5317e314725a764742f31eb036abeee482
                       d722047a3ff388e5f2735f32ed2f597b
       Extensions: 
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0xbe
 from file: /data/metadata/scm/sub-ca/certs/certificate.crt.
2024-01-15 07:56:07,322 [main] INFO client.SCMCertificateClient: CertificateRenewerService and root ca rotation polling is disabled for scm/sub-ca
2024-01-15 07:56:07,643 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-01-15 07:56:08,649 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-01-15 07:56:08,707 [main] INFO utils.LeakDetector: Starting leak detector thread ManagedRocksObject0.
2024-01-15 07:56:09,221 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.5.0-SNAPSHOT.jar!/network-topology-default.xml]
2024-01-15 07:56:09,236 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
2024-01-15 07:56:09,507 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.dropwizard3.Dm3MetricRegistriesImpl
2024-01-15 07:56:10,033 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:4e866cc2-839f-4d23-a8df-7474513825dc
2024-01-15 07:56:10,542 [main] INFO ssl.ReloadingX509KeyManager: Key manager is loaded with certificate chain
2024-01-15 07:56:10,614 [main] INFO ssl.ReloadingX509KeyManager:   [0]         Version: 3
         SerialNumber: 460033252902
             IssuerDN: CN=scm@scm1.org,OU=4e866cc2-839f-4d23-a8df-7474513825dc,O=CID-683d5636-fdaa-48e7-9616-a9985e8d8993
           Start Date: Mon Jan 15 00:00:00 UTC 2024
           Final Date: Thu Feb 22 00:00:00 UTC 2029
            SubjectDN: CN=scm-sub@scm1.org,OU=4e866cc2-839f-4d23-a8df-7474513825dc,O=CID-683d5636-fdaa-48e7-9616-a9985e8d8993
           Public Key: RSA Public Key [84:41:0f:07:79:7a:a5:b1:0f:2e:5f:f2:a9:b9:1d:d8:c5:5e:8d:10],[56:66:d1:a4]
        modulus: ca72844dc398048a414b86eb8795aa8b5f487989c4ffb32ad671696942468db8f19f324bb827269f5d729d0b10acdda0025013fa26beba4c764d52a2930c09b2b1f45b7159bfbaaba5182d609c1c9dd48b49b40a5f2c26530f78a14a709dc293d85576a242d3fbd605b6b9b463175518cff2c797633d1e4935cf511d5370ec3a622b545ef6f68f7c2194f160e833c6c06ffb1f7545e57146e843f8a203ac46169612c18eeca8b05c769f81b2ea67364e6a67e882358501f0350fee00fe65ed955788cb61588567968b120fa1872c9fc0e253ec93d97281bcc0e68d313635e468a7b35b042e8264f4fcba752947183523533f3d94d64ed89bee90cbc7f1ed1ad7
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 73fe11fa40ccd1a8b41462431bcbfe660e58d699
                       33380ce947193477ae0d390a944ef25b68f9d7f6
                       4c9be47825c8922e268f0186197c755da5fc6de3
                       7ca388a3d56d369023ff63384f9b78bd841c27a5
                       b3e841f56891dd05b530324c12ed8cc47c26a1fe
                       653ed78c88f709a848e0ce2b69d653430e309e5a
                       9d3a60c6307eb2ae00a62963a482a1a6cb16ddaa
                       435984e39094514c012c392e41f1a3ba3f472cdf
                       0a91da1fe4b4035733f7f03fa0cd811ff520a948
                       4717807778bb462ab730b7d0d4dbf7e113387a25
                       527a5ea4cfa7262258255582b1a4df568d70a225
                       e0110f5317e314725a764742f31eb036abeee482
                       d722047a3ff388e5f2735f32ed2f597b
       Extensions: 
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0xbe

2024-01-15 07:56:10,615 [main] INFO ssl.ReloadingX509KeyManager:   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm@scm1.org,OU=4e866cc2-839f-4d23-a8df-7474513825dc,O=CID-683d5636-fdaa-48e7-9616-a9985e8d8993
           Start Date: Mon Jan 15 00:00:00 UTC 2024
           Final Date: Thu Feb 22 23:59:59 UTC 2029
            SubjectDN: CN=scm@scm1.org,OU=4e866cc2-839f-4d23-a8df-7474513825dc,O=CID-683d5636-fdaa-48e7-9616-a9985e8d8993
           Public Key: RSA Public Key [b6:de:f5:8e:72:d2:97:92:9c:3a:15:75:3e:75:7b:70:2d:a6:c7:3d],[56:66:d1:a4]
        modulus: a681591e4465f9d9683ded5e8f66013d905bf8a1dc7a2802c24e4e026f7be29ca2d08dd24c3720053cc8f3679c1c27fb8ff1ba086bf6979c1e68cf3b2f3a6d937f1602fcf1f6501e12798fd0ecdbfa7fc7ff41ccd7155857171c166e6c181cd58026c3cdd072fd8374a522025290515a420ef309565dd1766c11c7bda1f2025af916f8ad60dbc67523d97182d320d35b6d682c3c0ad69b50abc15b8dc22de645051a249533caa6a63ead563847172c98ade7f737f8de987f711550482b03a016b995c3c7c07f33e94e82208067e8e32d32e4f77217731dd92582186993adbc5b022dc2167fafc87292fe4fe504e50afe5d10b84ef700f10c375aad65175a91c9
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 2ae22a8da2895c040a2500bf876b36dc19784fb4
                       04963d3d73675cf47f79516ee501c7d54491ed07
                       5bdf8b36333f6126386d95cc6251798ab33c57e7
                       7a4afd28641d4ac4db1c3ee1a5dca16f08a2635d
                       69611bc9328ce2293c96ce6f5638fe4a643ed777
                       2f2867816d116d0625f9f5523a8e8541854c0837
                       59ab2dec467935250654080966693df94bdc11ff
                       9bca39217968061569ab7a92c164dd1d56d34864
                       8c3c84658f7f7814dc56ac86e9ad61804de72c03
                       e09df96299b292842803e1b69b30889141361fd3
                       de12bfe1f7d781ef1f8b23976d5b7baee71a7035
                       a5e0b3773f1cb41995787c383c161465552b00cb
                       249c7ed77b6edea9f284d8f497192ae9
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 


2024-01-15 07:56:10,618 [main] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2024-01-15 07:56:10,618 [main] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2024-01-15 07:56:10,618 [main] INFO ssl.ReloadingX509TrustManager: Trust manager is loaded with certificates
2024-01-15 07:56:10,746 [main] INFO ssl.ReloadingX509TrustManager:   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm@scm1.org,OU=4e866cc2-839f-4d23-a8df-7474513825dc,O=CID-683d5636-fdaa-48e7-9616-a9985e8d8993
           Start Date: Mon Jan 15 00:00:00 UTC 2024
           Final Date: Thu Feb 22 23:59:59 UTC 2029
            SubjectDN: CN=scm@scm1.org,OU=4e866cc2-839f-4d23-a8df-7474513825dc,O=CID-683d5636-fdaa-48e7-9616-a9985e8d8993
           Public Key: RSA Public Key [b6:de:f5:8e:72:d2:97:92:9c:3a:15:75:3e:75:7b:70:2d:a6:c7:3d],[56:66:d1:a4]
        modulus: a681591e4465f9d9683ded5e8f66013d905bf8a1dc7a2802c24e4e026f7be29ca2d08dd24c3720053cc8f3679c1c27fb8ff1ba086bf6979c1e68cf3b2f3a6d937f1602fcf1f6501e12798fd0ecdbfa7fc7ff41ccd7155857171c166e6c181cd58026c3cdd072fd8374a522025290515a420ef309565dd1766c11c7bda1f2025af916f8ad60dbc67523d97182d320d35b6d682c3c0ad69b50abc15b8dc22de645051a249533caa6a63ead563847172c98ade7f737f8de987f711550482b03a016b995c3c7c07f33e94e82208067e8e32d32e4f77217731dd92582186993adbc5b022dc2167fafc87292fe4fe504e50afe5d10b84ef700f10c375aad65175a91c9
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 2ae22a8da2895c040a2500bf876b36dc19784fb4
                       04963d3d73675cf47f79516ee501c7d54491ed07
                       5bdf8b36333f6126386d95cc6251798ab33c57e7
                       7a4afd28641d4ac4db1c3ee1a5dca16f08a2635d
                       69611bc9328ce2293c96ce6f5638fe4a643ed777
                       2f2867816d116d0625f9f5523a8e8541854c0837
                       59ab2dec467935250654080966693df94bdc11ff
                       9bca39217968061569ab7a92c164dd1d56d34864
                       8c3c84658f7f7814dc56ac86e9ad61804de72c03
                       e09df96299b292842803e1b69b30889141361fd3
                       de12bfe1f7d781ef1f8b23976d5b7baee71a7035
                       a5e0b3773f1cb41995787c383c161465552b00cb
                       249c7ed77b6edea9f284d8f497192ae9
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 


2024-01-15 07:56:10,883 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2024-01-15 07:56:10,946 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2024-01-15 07:56:11,910 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2024-01-15 07:56:11,979 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-01-15 07:56:11,983 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2024-01-15 07:56:11,987 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-01-15 07:56:11,988 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2024-01-15 07:56:11,991 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2024-01-15 07:56:11,996 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2024-01-15 07:56:11,996 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
2024-01-15 07:56:12,032 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-01-15 07:56:12,033 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2024-01-15 07:56:12,033 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2024-01-15 07:56:12,118 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2024-01-15 07:56:12,139 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-01-15 07:56:12,158 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-01-15 07:56:14,652 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2024-01-15 07:56:14,654 [main] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2024-01-15 07:56:14,654 [main] INFO server.RaftServerConfigKeys: raft.server.close.threshold = 60s (default)
2024-01-15 07:56:14,654 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-01-15 07:56:14,663 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2024-01-15 07:56:14,665 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2024-01-15 07:56:14,665 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2024-01-15 07:56:14,688 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServer: 4e866cc2-839f-4d23-a8df-7474513825dc: found a subdirectory /data/metadata/scm-ha/683d5636-fdaa-48e7-9616-a9985e8d8993
2024-01-15 07:56:14,704 [main] INFO server.RaftServer: 4e866cc2-839f-4d23-a8df-7474513825dc: addNew group-A9985E8D8993:[] returns group-A9985E8D8993:java.util.concurrent.CompletableFuture@5ae15[Not completed]
2024-01-15 07:56:14,802 [4e866cc2-839f-4d23-a8df-7474513825dc-groupManagement] INFO ha.SCMStateMachine: Updated lastAppliedTermIndex 6#104 with transactionInfo term andIndex
2024-01-15 07:56:14,804 [4e866cc2-839f-4d23-a8df-7474513825dc-groupManagement] INFO server.RaftServer$Division: 4e866cc2-839f-4d23-a8df-7474513825dc: new RaftServerImpl for group-A9985E8D8993:[] with SCMStateMachine:uninitialized
2024-01-15 07:56:14,805 [4e866cc2-839f-4d23-a8df-7474513825dc-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2024-01-15 07:56:14,806 [4e866cc2-839f-4d23-a8df-7474513825dc-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2024-01-15 07:56:14,806 [4e866cc2-839f-4d23-a8df-7474513825dc-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2024-01-15 07:56:14,806 [4e866cc2-839f-4d23-a8df-7474513825dc-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2024-01-15 07:56:14,806 [4e866cc2-839f-4d23-a8df-7474513825dc-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-01-15 07:56:14,807 [4e866cc2-839f-4d23-a8df-7474513825dc-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.member.majority-add = false (default)
2024-01-15 07:56:14,807 [4e866cc2-839f-4d23-a8df-7474513825dc-groupManagement] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2024-01-15 07:56:14,835 [4e866cc2-839f-4d23-a8df-7474513825dc-groupManagement] INFO server.RaftServer$Division: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-01-15 07:56:14,858 [4e866cc2-839f-4d23-a8df-7474513825dc-groupManagement] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2024-01-15 07:56:14,887 [4e866cc2-839f-4d23-a8df-7474513825dc-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.timeout = 10s (default)
2024-01-15 07:56:14,921 [4e866cc2-839f-4d23-a8df-7474513825dc-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2024-01-15 07:56:14,922 [4e866cc2-839f-4d23-a8df-7474513825dc-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-01-15 07:56:14,925 [4e866cc2-839f-4d23-a8df-7474513825dc-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.option = DEFAULT (default)
2024-01-15 07:56:14,926 [4e866cc2-839f-4d23-a8df-7474513825dc-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-01-15 07:56:15,237 [4e866cc2-839f-4d23-a8df-7474513825dc-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2024-01-15 07:56:15,240 [4e866cc2-839f-4d23-a8df-7474513825dc-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-01-15 07:56:15,240 [4e866cc2-839f-4d23-a8df-7474513825dc-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2024-01-15 07:56:15,240 [4e866cc2-839f-4d23-a8df-7474513825dc-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2024-01-15 07:56:15,241 [4e866cc2-839f-4d23-a8df-7474513825dc-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2024-01-15 07:56:15,241 [4e866cc2-839f-4d23-a8df-7474513825dc-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2024-01-15 07:56:15,248 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
2024-01-15 07:56:15,248 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2024-01-15 07:56:15,248 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
2024-01-15 07:56:15,296 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-01-15 07:56:15,452 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
2024-01-15 07:56:15,559 [main] INFO node.SCMNodeManager: Entering startup safe mode.
2024-01-15 07:56:15,567 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2024-01-15 07:56:15,569 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2024-01-15 07:56:15,656 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2024-01-15 07:56:15,656 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2024-01-15 07:56:15,660 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
2024-01-15 07:56:15,663 [main] INFO pipeline.BackgroundPipelineCreator: Starting scm1-RatisPipelineUtilsThread.
2024-01-15 07:56:15,671 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
2024-01-15 07:56:15,671 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
2024-01-15 07:56:15,682 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
2024-01-15 07:56:15,687 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
2024-01-15 07:56:15,719 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2024-01-15 07:56:15,719 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2024-01-15 07:56:15,755 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
2024-01-15 07:56:15,848 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
2024-01-15 07:56:15,849 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.hadoop.hdds.utils.MetricsUtil (file:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.5.0-SNAPSHOT.jar) to method java.lang.Class.annotationData()
WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.hdds.utils.MetricsUtil
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
2024-01-15 07:56:15,859 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
2024-01-15 07:56:15,859 [scm1-ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 5000ms after safemode exit
2024-01-15 07:56:15,866 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 2, healthy pipeline threshold count is 1
2024-01-15 07:56:15,867 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 2, pipeline's with at least one datanode reported threshold count is 2
2024-01-15 07:56:16,172 [main] INFO security.SecretKeyManagerService: Scheduling rotation checker with interval PT1M
2024-01-15 07:56:16,180 [main] INFO ha.SCMServiceManager: Registering service SecretKeyManagerService.
2024-01-15 07:56:16,211 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
2024-01-15 07:56:16,224 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
2024-01-15 07:56:16,294 [main] INFO ha.SequenceIdGenerator: upgrade CertificateId to 503304745880
2024-01-15 07:56:16,310 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-01-15 07:56:16,411 [main] INFO ipc.Server: Listener at 0.0.0.0:9961
2024-01-15 07:56:16,419 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
2024-01-15 07:56:16,510 [main] INFO server.StorageContainerManager: SCM start with adminUsers: [testuser, recon, om, scm]
2024-01-15 07:56:17,310 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2024-01-15 07:56:17,314 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-01-15 07:56:17,315 [main] INFO ipc.Server: Listener at 0.0.0.0:9861
2024-01-15 07:56:17,315 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
2024-01-15 07:56:17,337 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2024-01-15 07:56:17,340 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-01-15 07:56:17,341 [main] INFO ipc.Server: Listener at 0.0.0.0:9863
2024-01-15 07:56:17,341 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
2024-01-15 07:56:17,359 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2024-01-15 07:56:17,364 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-01-15 07:56:17,365 [main] INFO ipc.Server: Listener at 0.0.0.0:9860
2024-01-15 07:56:17,365 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
2024-01-15 07:56:17,407 [main] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
2024-01-15 07:56:17,408 [main] INFO server.StorageContainerManager: 
Container Balancer status:
Key                            Value
Running                        false
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB
Number of Iterations                               10
Time Limit for Single Container's Movement         65min
Time Limit for Single Container's Replication      50min
Interval between each Iteration                    70min
Whether to Enable Network Topology                 false
Whether to Trigger Refresh Datanode Usage Info     false
Container IDs to Exclude from Balancing            None
Datanodes Specified to be Balanced                 None
Datanodes Excluded from Balancing                  None

2024-01-15 07:56:17,408 [main] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2024-01-15 07:56:17,419 [main] INFO upgrade.UpgradeFinalizer: Running pre-finalized state validations for unfinalized layout features.
2024-01-15 07:56:17,422 [main] INFO upgrade.UpgradeFinalizer: Running first upgrade commands for unfinalized layout features.
2024-01-15 07:56:17,422 [main] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
2024-01-15 07:56:17,430 [main] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
2024-01-15 07:56:17,433 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2024-01-15 07:56:17,434 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2024-01-15 07:56:17,434 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2024-01-15 07:56:17,460 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/683d5636-fdaa-48e7-9616-a9985e8d8993/in_use.lock acquired by nodename 6@scm1.org
2024-01-15 07:56:17,471 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=6, votedFor=4e866cc2-839f-4d23-a8df-7474513825dc} from /data/metadata/scm-ha/683d5636-fdaa-48e7-9616-a9985e8d8993/current/raft-meta
2024-01-15 07:56:17,511 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServer$Division: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993: set configuration 93: peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894, 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894, 38ca2b18-7c52-4d7d-9687-c935ff383fee|scm3.org:9894]|listeners:[], old=null
2024-01-15 07:56:17,513 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2024-01-15 07:56:17,521 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2024-01-15 07:56:17,521 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-01-15 07:56:17,522 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-01-15 07:56:17,523 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2024-01-15 07:56:17,526 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2024-01-15 07:56:17,531 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2024-01-15 07:56:17,531 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-01-15 07:56:17,531 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-01-15 07:56:17,533 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO util.AwaitToRun: Thread[4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-cacheEviction-AwaitToRun,5,main] started
2024-01-15 07:56:17,537 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/683d5636-fdaa-48e7-9616-a9985e8d8993
2024-01-15 07:56:17,537 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2024-01-15 07:56:17,538 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2024-01-15 07:56:17,539 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2024-01-15 07:56:17,539 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2024-01-15 07:56:17,540 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2024-01-15 07:56:17,540 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2024-01-15 07:56:17,541 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-01-15 07:56:17,541 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2024-01-15 07:56:17,542 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554440 (custom)
2024-01-15 07:56:17,549 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-01-15 07:56:17,550 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2024-01-15 07:56:17,550 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2024-01-15 07:56:17,550 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2024-01-15 07:56:17,596 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServer$Division: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993: set configuration 0: peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894]|listeners:[], old=null
2024-01-15 07:56:17,597 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/683d5636-fdaa-48e7-9616-a9985e8d8993/current/log_0-0
2024-01-15 07:56:17,601 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServer$Division: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993: set configuration 1: peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894]|listeners:[], old=null
2024-01-15 07:56:17,609 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServer$Division: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993: set configuration 23: peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894, 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894]|listeners:[], old=peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894]|listeners:[]
2024-01-15 07:56:17,611 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServer$Division: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993: set configuration 25: peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894, 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894]|listeners:[], old=null
2024-01-15 07:56:17,614 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServer$Division: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993: set configuration 41: peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894, 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894, 38ca2b18-7c52-4d7d-9687-c935ff383fee|scm3.org:9894]|listeners:[], old=peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894, 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894]|listeners:[]
2024-01-15 07:56:17,622 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServer$Division: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993: set configuration 43: peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894, 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894, 38ca2b18-7c52-4d7d-9687-c935ff383fee|scm3.org:9894]|listeners:[], old=null
2024-01-15 07:56:17,624 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO segmented.LogSegment: Successfully read 70 entries from segment file /data/metadata/scm-ha/683d5636-fdaa-48e7-9616-a9985e8d8993/current/log_1-70
2024-01-15 07:56:17,625 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServer$Division: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993: set configuration 71: peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894, 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894, 38ca2b18-7c52-4d7d-9687-c935ff383fee|scm3.org:9894]|listeners:[], old=null
2024-01-15 07:56:17,627 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO segmented.LogSegment: Successfully read 22 entries from segment file /data/metadata/scm-ha/683d5636-fdaa-48e7-9616-a9985e8d8993/current/log_71-92
2024-01-15 07:56:17,632 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServer$Division: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993: set configuration 93: peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894, 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894, 38ca2b18-7c52-4d7d-9687-c935ff383fee|scm3.org:9894]|listeners:[], old=null
2024-01-15 07:56:17,683 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO segmented.LogSegment: Successfully read 12 entries from segment file /data/metadata/scm-ha/683d5636-fdaa-48e7-9616-a9985e8d8993/current/log_inprogress_93
2024-01-15 07:56:17,689 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 104
2024-01-15 07:56:17,689 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> 92
2024-01-15 07:56:17,712 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO segmented.BufferedWriteChannel: open log_inprogress_93 (append) at position 1064
2024-01-15 07:56:17,713 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServer$Division: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993: start as a follower, conf=93: peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894, 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894, 38ca2b18-7c52-4d7d-9687-c935ff383fee|scm3.org:9894]|listeners:[], old=null
2024-01-15 07:56:17,714 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServer$Division: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993: changes role from      null to FOLLOWER at term 6 for startAsFollower
2024-01-15 07:56:17,715 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO impl.RoleInfo: 4e866cc2-839f-4d23-a8df-7474513825dc: start 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-FollowerState
2024-01-15 07:56:17,716 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2024-01-15 07:56:17,717 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A9985E8D8993,id=4e866cc2-839f-4d23-a8df-7474513825dc
2024-01-15 07:56:17,717 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-01-15 07:56:17,722 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-01-15 07:56:17,731 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-01-15 07:56:17,731 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2024-01-15 07:56:17,732 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2024-01-15 07:56:17,732 [4e866cc2-839f-4d23-a8df-7474513825dc-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2024-01-15 07:56:17,737 [main] INFO server.RaftServer: 4e866cc2-839f-4d23-a8df-7474513825dc: start RPC server
2024-01-15 07:56:17,860 [main] INFO server.GrpcService: 4e866cc2-839f-4d23-a8df-7474513825dc: GrpcService started, listening on 9894
2024-01-15 07:56:17,888 [main] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894, 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894, 38ca2b18-7c52-4d7d-9687-c935ff383fee|scm3.org:9894]
2024-01-15 07:56:17,888 [main] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
2024-01-15 07:56:17,892 [main] INFO SCMHATransactionMonitor: Starting SCMHATransactionMonitor Service.
2024-01-15 07:56:17,894 [main] INFO ha.SCMServiceManager: Registering service SCMHATransactionMonitor.
2024-01-15 07:56:17,894 [main] INFO SCMHATransactionMonitor: SCMHATransactionMonitor Service is already running, skip start.
2024-01-15 07:56:17,898 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-4e866cc2-839f-4d23-a8df-7474513825dc: Started
2024-01-15 07:56:18,067 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2024-01-15 07:56:18,125 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-01-15 07:56:18,125 [main] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
2024-01-15 07:56:18,354 [main] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
2024-01-15 07:56:18,362 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-01-15 07:56:18,372 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
2024-01-15 07:56:18,516 [main] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
2024-01-15 07:56:18,517 [main] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
2024-01-15 07:56:18,518 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-01-15 07:56:18,518 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
2024-01-15 07:56:18,586 [main] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
2024-01-15 07:56:18,719 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-01-15 07:56:18,723 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
2024-01-15 07:56:18,724 [main] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
2024-01-15 07:56:18,894 [main] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
2024-01-15 07:56:18,895 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
2024-01-15 07:56:18,900 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
2024-01-15 07:56:18,989 [main] INFO util.log: Logging initialized @29656ms to org.eclipse.jetty.util.log.Slf4jLog
2024-01-15 07:56:19,509 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om1_1.ha_net:33712 / 10.9.0.11:33712
2024-01-15 07:56:19,533 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2024-01-15 07:56:19,534 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:35324 / 10.9.0.20:35324
2024-01-15 07:56:19,556 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:46540 / 10.9.0.18:46540
2024-01-15 07:56:19,573 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:34564 / 10.9.0.17:34564
2024-01-15 07:56:19,577 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2024-01-15 07:56:19,589 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2024-01-15 07:56:19,644 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2024-01-15 07:56:19,711 [main] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
2024-01-15 07:56:19,734 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-01-15 07:56:19,736 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
2024-01-15 07:56:19,736 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2024-01-15 07:56:19,737 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2024-01-15 07:56:19,742 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
2024-01-15 07:56:19,844 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#3 org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode.submitRequest from ha_dn4_1.ha_net:35324 / 10.9.0.20:35324
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:4e866cc2-839f-4d23-a8df-7474513825dc is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SecretKeyProtocolServerSideTranslatorPB.submitRequest(SecretKeyProtocolServerSideTranslatorPB.java:76)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecretKeyProtocolProtos$SCMSecretKeyProtocolService$2.callBlockingMethod(SCMSecretKeyProtocolProtos.java:7548)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2024-01-15 07:56:19,845 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#3 org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode.submitRequest from ha_dn2_1.ha_net:46540 / 10.9.0.18:46540
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:4e866cc2-839f-4d23-a8df-7474513825dc is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SecretKeyProtocolServerSideTranslatorPB.submitRequest(SecretKeyProtocolServerSideTranslatorPB.java:76)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecretKeyProtocolProtos$SCMSecretKeyProtocolService$2.callBlockingMethod(SCMSecretKeyProtocolProtos.java:7548)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2024-01-15 07:56:19,904 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#3 org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode.submitRequest from ha_dn1_1.ha_net:34564 / 10.9.0.17:34564
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:4e866cc2-839f-4d23-a8df-7474513825dc is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SecretKeyProtocolServerSideTranslatorPB.submitRequest(SecretKeyProtocolServerSideTranslatorPB.java:76)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecretKeyProtocolProtos$SCMSecretKeyProtocolService$2.callBlockingMethod(SCMSecretKeyProtocolProtos.java:7548)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2024-01-15 07:56:19,978 [main] INFO http.BaseHttpServer: HTTP server of scm uses base directory /data/metadata/webserver
2024-01-15 07:56:19,979 [main] INFO http.HttpServer2: Jetty bound to port 9876
2024-01-15 07:56:19,982 [main] INFO server.Server: jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 11.0.19+7-LTS
2024-01-15 07:56:20,133 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om2_1.ha_net:44482 / 10.9.0.12:44482
2024-01-15 07:56:20,229 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2024-01-15 07:56:20,275 [main] INFO server.session: DefaultSessionIdManager workerName=node0
2024-01-15 07:56:20,281 [main] INFO server.session: No SessionScavenger set, using defaults
2024-01-15 07:56:20,282 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:59584 / 10.9.0.21:59584
2024-01-15 07:56:20,343 [main] INFO server.session: node0 Scavenging every 600000ms
2024-01-15 07:56:20,355 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2024-01-15 07:56:20,356 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#3 org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode.submitRequest from ha_dn5_1.ha_net:59584 / 10.9.0.21:59584
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:4e866cc2-839f-4d23-a8df-7474513825dc is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SecretKeyProtocolServerSideTranslatorPB.submitRequest(SecretKeyProtocolServerSideTranslatorPB.java:76)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecretKeyProtocolProtos$SCMSecretKeyProtocolService$2.callBlockingMethod(SCMSecretKeyProtocolProtos.java:7548)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2024-01-15 07:56:20,447 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:34146 / 10.9.0.19:34146
2024-01-15 07:56:20,449 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
2024-01-15 07:56:20,461 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7e1762e6{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
2024-01-15 07:56:20,472 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@49d979c4{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2024-01-15 07:56:20,472 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2024-01-15 07:56:20,474 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#3 org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode.submitRequest from ha_dn3_1.ha_net:34146 / 10.9.0.19:34146
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:4e866cc2-839f-4d23-a8df-7474513825dc is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SecretKeyProtocolServerSideTranslatorPB.submitRequest(SecretKeyProtocolServerSideTranslatorPB.java:76)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecretKeyProtocolProtos$SCMSecretKeyProtocolService$2.callBlockingMethod(SCMSecretKeyProtocolProtos.java:7548)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2024-01-15 07:56:20,736 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
2024-01-15 07:56:20,773 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@642c5bb3{scm,/,file:///data/metadata/webserver/jetty-0_0_0_0-9876-hdds-server-scm-1_5_0-SNAPSHOT_jar-_-any-10464835546082235620/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.5.0-SNAPSHOT.jar!/webapps/scm}
2024-01-15 07:56:20,803 [main] INFO server.AbstractConnector: Started ServerConnector@2cff03cf{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
2024-01-15 07:56:20,806 [main] INFO server.Server: Started @31473ms
2024-01-15 07:56:20,817 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
2024-01-15 07:56:20,817 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
2024-01-15 07:56:20,820 [main] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
2024-01-15 07:56:21,032 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from scm1.org:54362 / 10.9.0.14:54362
2024-01-15 07:56:21,070 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2024-01-15 07:56:21,086 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#0 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from scm1.org:54362 / 10.9.0.14:54362
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:4e866cc2-839f-4d23-a8df-7474513825dc is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:90)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18732)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2024-01-15 07:56:21,128 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om3_1.ha_net:60936 / 10.9.0.13:60936
2024-01-15 07:56:21,146 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2024-01-15 07:56:22,724 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-FollowerState] INFO impl.FollowerState: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5009636252ns, electionTimeout:5004ms
2024-01-15 07:56:22,724 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-FollowerState] INFO impl.RoleInfo: 4e866cc2-839f-4d23-a8df-7474513825dc: shutdown 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-FollowerState
2024-01-15 07:56:22,725 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-FollowerState] INFO server.RaftServer$Division: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993: changes role from  FOLLOWER to CANDIDATE at term 6 for changeToCandidate
2024-01-15 07:56:22,727 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
2024-01-15 07:56:22,736 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-FollowerState] INFO impl.RoleInfo: 4e866cc2-839f-4d23-a8df-7474513825dc: start 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection1
2024-01-15 07:56:22,771 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection1] INFO impl.LeaderElection: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 6 for 93: peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894, 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894, 38ca2b18-7c52-4d7d-9687-c935ff383fee|scm3.org:9894]|listeners:[], old=null
2024-01-15 07:56:22,848 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection1-1] INFO server.GrpcServerProtocolClient: Build channel for 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894
2024-01-15 07:56:22,850 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2024-01-15 07:56:22,851 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-01-15 07:56:22,855 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection1-2] INFO server.GrpcServerProtocolClient: Build channel for 38ca2b18-7c52-4d7d-9687-c935ff383fee|scm3.org:9894
2024-01-15 07:56:23,244 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection1] INFO impl.LeaderElection: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection1 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-01-15 07:56:23,248 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection1] INFO impl.LeaderElection: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection1 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-01-15 07:56:23,249 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection1] INFO impl.LeaderElection: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection1: PRE_VOTE REJECTED received 0 response(s) and 2 exception(s):
2024-01-15 07:56:23,249 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection1] INFO impl.LeaderElection:   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-01-15 07:56:23,249 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection1] INFO impl.LeaderElection:   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-01-15 07:56:23,249 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection1] INFO impl.LeaderElection: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection1 PRE_VOTE round 0: result REJECTED
2024-01-15 07:56:23,252 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection1] INFO server.RaftServer$Division: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993: changes role from CANDIDATE to FOLLOWER at term 6 for REJECTED
2024-01-15 07:56:23,252 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection1] INFO impl.RoleInfo: 4e866cc2-839f-4d23-a8df-7474513825dc: shutdown 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection1
2024-01-15 07:56:23,253 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection1] INFO impl.RoleInfo: 4e866cc2-839f-4d23-a8df-7474513825dc: start 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-FollowerState
2024-01-15 07:56:23,258 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection1] INFO server.RaftServer$Division: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993: set firstElectionSinceStartup to false for REJECTED
2024-01-15 07:56:23,366 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from ha_recon_1.ha_net:37765 / 10.9.0.22:37765
2024-01-15 07:56:23,402 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2024-01-15 07:56:25,692 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from scm1.org:40510 / 10.9.0.14:40510
2024-01-15 07:56:25,715 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2024-01-15 07:56:25,926 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#6 org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode.submitRequest from ha_dn2_1.ha_net:46540 / 10.9.0.18:46540
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:4e866cc2-839f-4d23-a8df-7474513825dc is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SecretKeyProtocolServerSideTranslatorPB.submitRequest(SecretKeyProtocolServerSideTranslatorPB.java:76)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecretKeyProtocolProtos$SCMSecretKeyProtocolService$2.callBlockingMethod(SCMSecretKeyProtocolProtos.java:7548)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2024-01-15 07:56:25,938 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#6 org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode.submitRequest from ha_dn1_1.ha_net:34564 / 10.9.0.17:34564
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:4e866cc2-839f-4d23-a8df-7474513825dc is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SecretKeyProtocolServerSideTranslatorPB.submitRequest(SecretKeyProtocolServerSideTranslatorPB.java:76)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecretKeyProtocolProtos$SCMSecretKeyProtocolService$2.callBlockingMethod(SCMSecretKeyProtocolProtos.java:7548)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2024-01-15 07:56:25,978 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#6 org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode.submitRequest from ha_dn4_1.ha_net:35324 / 10.9.0.20:35324
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:4e866cc2-839f-4d23-a8df-7474513825dc is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SecretKeyProtocolServerSideTranslatorPB.submitRequest(SecretKeyProtocolServerSideTranslatorPB.java:76)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecretKeyProtocolProtos$SCMSecretKeyProtocolService$2.callBlockingMethod(SCMSecretKeyProtocolProtos.java:7548)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2024-01-15 07:56:26,430 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#6 org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode.submitRequest from ha_dn5_1.ha_net:59584 / 10.9.0.21:59584
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:4e866cc2-839f-4d23-a8df-7474513825dc is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SecretKeyProtocolServerSideTranslatorPB.submitRequest(SecretKeyProtocolServerSideTranslatorPB.java:76)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecretKeyProtocolProtos$SCMSecretKeyProtocolService$2.callBlockingMethod(SCMSecretKeyProtocolProtos.java:7548)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2024-01-15 07:56:26,540 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#6 org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode.submitRequest from ha_dn3_1.ha_net:34146 / 10.9.0.19:34146
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:4e866cc2-839f-4d23-a8df-7474513825dc is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SecretKeyProtocolServerSideTranslatorPB.submitRequest(SecretKeyProtocolServerSideTranslatorPB.java:76)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecretKeyProtocolProtos$SCMSecretKeyProtocolService$2.callBlockingMethod(SCMSecretKeyProtocolProtos.java:7548)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2024-01-15 07:56:26,626 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from ha_scm2_1.ha_net:39964 / 10.9.0.15:39964
2024-01-15 07:56:26,639 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2024-01-15 07:56:26,639 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#0 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from ha_scm2_1.ha_net:39964 / 10.9.0.15:39964
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:4e866cc2-839f-4d23-a8df-7474513825dc is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:90)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18732)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2024-01-15 07:56:27,110 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#3 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from scm1.org:54362 / 10.9.0.14:54362
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:4e866cc2-839f-4d23-a8df-7474513825dc is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:90)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18732)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2024-01-15 07:56:27,114 [4e866cc2-839f-4d23-a8df-7474513825dc-scm/sub-ca-refreshCACertificates] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:4e866cc2-839f-4d23-a8df-7474513825dc is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:90)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18732)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
, while invoking $Proxy14.submitRequest over nodeId=scm1,nodeAddress=scm1.org/10.9.0.14:9961 after 3 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 3.
2024-01-15 07:56:28,301 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-FollowerState] INFO impl.FollowerState: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5048724558ns, electionTimeout:5035ms
2024-01-15 07:56:28,302 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-FollowerState] INFO impl.RoleInfo: 4e866cc2-839f-4d23-a8df-7474513825dc: shutdown 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-FollowerState
2024-01-15 07:56:28,302 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-FollowerState] INFO server.RaftServer$Division: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993: changes role from  FOLLOWER to CANDIDATE at term 6 for changeToCandidate
2024-01-15 07:56:28,302 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
2024-01-15 07:56:28,302 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-FollowerState] INFO impl.RoleInfo: 4e866cc2-839f-4d23-a8df-7474513825dc: start 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2
2024-01-15 07:56:28,303 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO impl.LeaderElection: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2 PRE_VOTE round 0: submit vote requests at term 6 for 93: peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894, 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894, 38ca2b18-7c52-4d7d-9687-c935ff383fee|scm3.org:9894]|listeners:[], old=null
2024-01-15 07:56:28,317 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO impl.LeaderElection: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-01-15 07:56:28,516 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO impl.LeaderElection: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2: PRE_VOTE PASSED received 1 response(s) and 1 exception(s):
2024-01-15 07:56:28,517 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO impl.LeaderElection:   Response 0: 4e866cc2-839f-4d23-a8df-7474513825dc<-52da82f3-81bd-406e-862e-9fbf871b6f1e#0:OK-t6
2024-01-15 07:56:28,517 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO impl.LeaderElection:   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-01-15 07:56:28,517 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO impl.LeaderElection: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2 PRE_VOTE round 0: result PASSED
2024-01-15 07:56:28,524 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO impl.LeaderElection: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2 ELECTION round 0: submit vote requests at term 7 for 93: peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894, 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894, 38ca2b18-7c52-4d7d-9687-c935ff383fee|scm3.org:9894]|listeners:[], old=null
2024-01-15 07:56:28,529 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO impl.LeaderElection: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-01-15 07:56:28,548 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO impl.LeaderElection: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2: ELECTION PASSED received 1 response(s) and 1 exception(s):
2024-01-15 07:56:28,548 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO impl.LeaderElection:   Response 0: 4e866cc2-839f-4d23-a8df-7474513825dc<-52da82f3-81bd-406e-862e-9fbf871b6f1e#0:OK-t7
2024-01-15 07:56:28,548 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO impl.LeaderElection:   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-01-15 07:56:28,548 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO impl.LeaderElection: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2 ELECTION round 0: result PASSED
2024-01-15 07:56:28,549 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO impl.RoleInfo: 4e866cc2-839f-4d23-a8df-7474513825dc: shutdown 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2
2024-01-15 07:56:28,549 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO server.RaftServer$Division: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993: changes role from CANDIDATE to LEADER at term 7 for changeToLeader
2024-01-15 07:56:28,555 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
2024-01-15 07:56:28,569 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2024-01-15 07:56:28,569 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
2024-01-15 07:56:28,573 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
2024-01-15 07:56:28,574 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
2024-01-15 07:56:28,574 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
2024-01-15 07:56:28,584 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.enabled = false (default)
2024-01-15 07:56:28,586 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-01-15 07:56:28,587 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2024-01-15 07:56:28,587 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2024-01-15 07:56:28,587 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-01-15 07:56:28,603 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-01-15 07:56:28,604 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-01-15 07:56:28,604 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
2024-01-15 07:56:28,606 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.wait-time.min = 0ms (custom)
2024-01-15 07:56:28,607 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-01-15 07:56:28,607 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2024-01-15 07:56:28,608 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-01-15 07:56:28,608 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-01-15 07:56:28,608 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.log-message.batch.duration = 5s (default)
2024-01-15 07:56:28,608 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-01-15 07:56:28,609 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2024-01-15 07:56:28,616 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-01-15 07:56:28,617 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-01-15 07:56:28,617 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
2024-01-15 07:56:28,617 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.wait-time.min = 0ms (custom)
2024-01-15 07:56:28,617 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-01-15 07:56:28,617 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2024-01-15 07:56:28,618 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-01-15 07:56:28,618 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-01-15 07:56:28,619 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.log-message.batch.duration = 5s (default)
2024-01-15 07:56:28,619 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-01-15 07:56:28,619 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2024-01-15 07:56:28,621 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO impl.RoleInfo: 4e866cc2-839f-4d23-a8df-7474513825dc: start 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderStateImpl
2024-01-15 07:56:28,621 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO ha.SCMStateMachine: current SCM becomes leader of term 7.
2024-01-15 07:56:28,622 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,7>
2024-01-15 07:56:28,627 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO server.RaftServer$Division: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993: change Leader from null to 4e866cc2-839f-4d23-a8df-7474513825dc at term 7 for becomeLeader, leader elected after 13764ms
2024-01-15 07:56:28,634 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-SegmentedRaftLogWorker: Rolling segment log-93_104 to index:104
2024-01-15 07:56:28,637 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LeaderElection2] INFO server.RaftServer$Division: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993: set configuration 105: peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894, 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894, 38ca2b18-7c52-4d7d-9687-c935ff383fee|scm3.org:9894]|listeners:[], old=null
2024-01-15 07:56:28,637 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/683d5636-fdaa-48e7-9616-a9985e8d8993/current/log_inprogress_93 to /data/metadata/scm-ha/683d5636-fdaa-48e7-9616-a9985e8d8993/current/log_93-104
2024-01-15 07:56:28,641 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-SegmentedRaftLogWorker] INFO segmented.BufferedWriteChannel: open log_inprogress_105 at position 0
2024-01-15 07:56:28,664 [grpc-default-executor-0] WARN server.GrpcLogAppender: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993->38ca2b18-7c52-4d7d-9687-c935ff383fee-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-01-15 07:56:28,665 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/683d5636-fdaa-48e7-9616-a9985e8d8993/current/log_inprogress_105
2024-01-15 07:56:28,685 [grpc-default-executor-0] WARN server.GrpcLogAppender: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993->38ca2b18-7c52-4d7d-9687-c935ff383fee-GrpcLogAppender: Follower failed (request=null, errorCount=1); keep nextIndex (105) unchanged and retry.
2024-01-15 07:56:28,725 [grpc-default-executor-2] WARN server.GrpcLogAppender: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993->38ca2b18-7c52-4d7d-9687-c935ff383fee-GrpcLogAppender: Follower failed (request=null, errorCount=5); keep nextIndex (106) unchanged and retry.
2024-01-15 07:56:28,812 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] INFO server.RaftServer$Division: leader is ready since appliedIndex == 105 >= startIndex == 105
2024-01-15 07:56:28,813 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
2024-01-15 07:56:28,814 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
2024-01-15 07:56:28,815 [scm1-SecretKeyManagerService] INFO symmetric.SecretKeyManager: Initializing SecretKeys.
2024-01-15 07:56:28,818 [grpc-default-executor-2] WARN server.GrpcLogAppender: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993->38ca2b18-7c52-4d7d-9687-c935ff383fee-GrpcLogAppender: Follower failed (request=null, errorCount=7); keep nextIndex (107) unchanged and retry.
2024-01-15 07:56:28,827 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 2, healthy pipeline threshold count is 1
2024-01-15 07:56:28,838 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
2024-01-15 07:56:28,838 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 2, pipeline's with at least one datanode reported threshold count is 2
2024-01-15 07:56:28,839 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
2024-01-15 07:56:28,842 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-01-15 07:56:28,855 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
2024-01-15 07:56:28,992 [scm1-SecretKeyManagerService] INFO symmetric.LocalSecretKeyStore: Loaded [SecretKey(id = 17343b73-6203-4ee1-839d-499f80eed361, creation at: 2024-01-15T07:49:06.544Z, expire at: 2024-01-15T08:49:06.544Z)] from /data/metadata/scm/keys/secret_keys.json
2024-01-15 07:56:28,993 [scm1-SecretKeyManagerService] INFO symmetric.SecretKeyManager: Keys reloaded: [SecretKey(id = 17343b73-6203-4ee1-839d-499f80eed361, creation at: 2024-01-15T07:49:06.544Z, expire at: 2024-01-15T08:49:06.544Z)]
2024-01-15 07:56:29,062 [grpc-default-executor-4] WARN server.GrpcLogAppender: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993->38ca2b18-7c52-4d7d-9687-c935ff383fee-GrpcLogAppender: Follower failed (request=null, errorCount=9); keep nextIndex (108) unchanged and retry.
2024-01-15 07:56:29,076 [grpc-default-executor-2] WARN server.GrpcLogAppender: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993->38ca2b18-7c52-4d7d-9687-c935ff383fee-GrpcLogAppender: Follower failed (request=null, errorCount=11); keep nextIndex (109) unchanged and retry.
2024-01-15 07:56:29,087 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Updating keys with [SecretKey(id = 17343b73-6203-4ee1-839d-499f80eed361, creation at: 2024-01-15T07:49:06.544Z, expire at: 2024-01-15T08:49:06.544Z)]
2024-01-15 07:56:29,088 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Current key updated SecretKey(id = 17343b73-6203-4ee1-839d-499f80eed361, creation at: 2024-01-15T07:49:06.544Z, expire at: 2024-01-15T08:49:06.544Z)
2024-01-15 07:56:29,120 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] INFO symmetric.LocalSecretKeyStore: Saved [SecretKey(id = 17343b73-6203-4ee1-839d-499f80eed361, creation at: 2024-01-15T07:49:06.544Z, expire at: 2024-01-15T08:49:06.544Z)] to file /data/metadata/scm/keys/secret_keys.json
2024-01-15 07:56:29,121 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 2, healthy pipeline threshold count is 1
2024-01-15 07:56:29,121 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
2024-01-15 07:56:29,121 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 2, pipeline's with at least one datanode reported threshold count is 2
2024-01-15 07:56:29,203 [4e866cc2-839f-4d23-a8df-7474513825dc-scm/sub-ca-refreshCACertificates] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:52da82f3-81bd-406e-862e-9fbf871b6f1e is not the leader. Suggested leader is Server:scm1.org:9961.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:107)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:90)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18732)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
, while invoking $Proxy14.submitRequest over nodeId=scm2,nodeAddress=scm2.org/10.9.0.15:9961 after 4 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 4.
2024-01-15 07:56:31,228 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2024-01-15 07:56:31,228 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2024-01-15 07:56:31,237 [4e866cc2-839f-4d23-a8df-7474513825dc-scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2024-01-15 07:56:31,238 [4e866cc2-839f-4d23-a8df-7474513825dc-scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2024-01-15 07:56:31,240 [4e866cc2-839f-4d23-a8df-7474513825dc-scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: CA certificates are not changed.
2024-01-15 07:56:33,681 [timer1] WARN server.GrpcLogAppender: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993->38ca2b18-7c52-4d7d-9687-c935ff383fee-AppendLogResponseHandler: Failed appendEntries (Repeated 18 times in the last 5.016s): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-01-15 07:56:33,685 [timer2] WARN server.GrpcLogAppender: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993->38ca2b18-7c52-4d7d-9687-c935ff383fee-GrpcLogAppender: Follower failed (request=null, errorCount=4); keep nextIndex (105) unchanged and retry. (Repeated 4 times in the last 5.001s)
2024-01-15 07:56:33,728 [timer4] WARN server.GrpcLogAppender: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993->38ca2b18-7c52-4d7d-9687-c935ff383fee-GrpcLogAppender: Follower failed (request=null, errorCount=6); keep nextIndex (106) unchanged and retry. (Repeated 2 times in the last 5.003s)
2024-01-15 07:56:33,818 [timer1] WARN server.GrpcLogAppender: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993->38ca2b18-7c52-4d7d-9687-c935ff383fee-GrpcLogAppender: Follower failed (request=null, errorCount=8); keep nextIndex (107) unchanged and retry. (Repeated 2 times in the last 5.000s)
2024-01-15 07:56:34,062 [timer4] WARN server.GrpcLogAppender: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993->38ca2b18-7c52-4d7d-9687-c935ff383fee-GrpcLogAppender: Follower failed (request=null, errorCount=10); keep nextIndex (108) unchanged and retry. (Repeated 2 times in the last 5.000s)
2024-01-15 07:56:34,077 [timer6] WARN server.GrpcLogAppender: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993->38ca2b18-7c52-4d7d-9687-c935ff383fee-GrpcLogAppender: Follower failed (request=null, errorCount=18); keep nextIndex (109) unchanged and retry. (Repeated 8 times in the last 5.001s)
2024-01-15 07:56:34,090 [grpc-default-executor-4] WARN server.GrpcLogAppender: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993->38ca2b18-7c52-4d7d-9687-c935ff383fee-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-01-15 07:56:34,091 [grpc-default-executor-0] WARN server.GrpcLogAppender: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993->38ca2b18-7c52-4d7d-9687-c935ff383fee-GrpcLogAppender: Follower failed (request=null, errorCount=19); keep nextIndex (109) unchanged and retry.
2024-01-15 07:56:36,262 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2024-01-15 07:56:36,262 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2024-01-15 07:56:36,281 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from ha_scm3_1.ha_net:55178 / 10.9.0.16:55178
2024-01-15 07:56:36,373 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2024-01-15 07:56:38,071 [grpc-default-executor-4] WARN server.GrpcLogAppender: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993->38ca2b18-7c52-4d7d-9687-c935ff383fee-AppendLogResponseHandler: received INCONSISTENCY reply with nextIndex 105, errorCount=21, request=AppendEntriesRequest:cid=457,entriesCount=0
2024-01-15 07:56:38,072 [grpc-default-executor-4] INFO leader.FollowerInfo: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993->38ca2b18-7c52-4d7d-9687-c935ff383fee: setNextIndex nextIndex: updateUnconditionally 109 -> 105
2024-01-15 07:56:39,091 [timer1] WARN server.GrpcLogAppender: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993->38ca2b18-7c52-4d7d-9687-c935ff383fee-AppendLogResponseHandler: Failed appendEntries (Repeated 2 times in the last 5.001s): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-01-15 07:56:39,091 [timer7] WARN server.GrpcLogAppender: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993->38ca2b18-7c52-4d7d-9687-c935ff383fee-GrpcLogAppender: Follower failed (request=null, errorCount=20); keep nextIndex (109) unchanged and retry. (Repeated 2 times in the last 5.000s)
2024-01-15 07:56:40,078 [grpc-default-executor-4] INFO server.RaftServer$Division: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993: receive requestVote(PRE_VOTE, 38ca2b18-7c52-4d7d-9687-c935ff383fee, group-A9985E8D8993, 6, (t:6, i:104))
2024-01-15 07:56:40,081 [grpc-default-executor-4] INFO impl.VoteContext: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-LEADER: reject PRE_VOTE from 38ca2b18-7c52-4d7d-9687-c935ff383fee: this server is the leader and still has leadership
2024-01-15 07:56:40,093 [grpc-default-executor-4] INFO server.RaftServer$Division: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993 replies to PRE_VOTE vote request: 38ca2b18-7c52-4d7d-9687-c935ff383fee<-4e866cc2-839f-4d23-a8df-7474513825dc#0:FAIL-t7. Peer's state: 4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993:t7, leader=4e866cc2-839f-4d23-a8df-7474513825dc, voted=4e866cc2-839f-4d23-a8df-7474513825dc, raftlog=Memoized:4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-SegmentedRaftLog:OPENED:c108, conf=105: peers:[4e866cc2-839f-4d23-a8df-7474513825dc|scm1.org:9894, 52da82f3-81bd-406e-862e-9fbf871b6f1e|scm2.org:9894, 38ca2b18-7c52-4d7d-9687-c935ff383fee|scm3.org:9894]|listeners:[], old=null
2024-01-15 07:56:42,019 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2024-01-15 07:56:42,019 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2024-01-15 07:56:42,686 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:42614 / 10.9.0.18:42614
2024-01-15 07:56:42,755 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2024-01-15 07:56:43,350 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:38400 / 10.9.0.21:38400
2024-01-15 07:56:43,437 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:55038 / 10.9.0.20:55038
2024-01-15 07:56:43,473 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2024-01-15 07:56:43,521 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2024-01-15 07:56:43,801 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:44960 / 10.9.0.17:44960
2024-01-15 07:56:43,821 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2024-01-15 07:56:44,932 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:37928 / 10.9.0.19:37928
2024-01-15 07:56:44,983 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2024-01-15 07:56:48,493 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om3_1.ha_net:48848 / 10.9.0.13:48848
2024-01-15 07:56:48,509 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolOm
2024-01-15 07:56:48,569 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:43362 / 10.9.0.18:43362
2024-01-15 07:56:48,621 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:56:49,327 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om1_1.ha_net:46854 / 10.9.0.11:46854
2024-01-15 07:56:49,336 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolOm
2024-01-15 07:56:49,746 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:36850 / 10.9.0.17:36850
2024-01-15 07:56:49,781 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:56:50,236 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:39596 / 10.9.0.20:39596
2024-01-15 07:56:50,332 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:39438 / 10.9.0.21:39438
2024-01-15 07:56:50,338 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:56:50,427 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:56:50,726 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om2_1.ha_net:36580 / 10.9.0.12:36580
2024-01-15 07:56:50,728 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolOm
2024-01-15 07:56:51,229 [IPC Server handler 0 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/5953220d-7af2-4159-933f-22262aae1e87
2024-01-15 07:56:51,237 [IPC Server handler 0 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 5953220d-7af2-4159-933f-22262aae1e87{ip: 10.9.0.18, host: ha_dn2_1.ha_net, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 484395141220, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2024-01-15 07:56:51,267 [scm1-EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on scm1-RatisPipelineUtilsThread.
2024-01-15 07:56:51,261 [scm1-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
2024-01-15 07:56:51,272 [scm1-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Pipelines with at least one datanode reported count is 0, required at least one datanode reported per pipeline count is 2
2024-01-15 07:56:51,272 [scm1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-01-15 07:56:51,639 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:46452 / 10.9.0.19:46452
2024-01-15 07:56:51,692 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:56:52,205 [IPC Server handler 0 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/d8ef6392-c8b7-40ba-a1b4-c245afaf6945
2024-01-15 07:56:52,205 [IPC Server handler 0 on default port 9861] INFO node.SCMNodeManager: Registered datanode: d8ef6392-c8b7-40ba-a1b4-c245afaf6945{ip: 10.9.0.17, host: ha_dn1_1.ha_net, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 481078400134, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2024-01-15 07:56:52,206 [scm1-EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on scm1-RatisPipelineUtilsThread.
2024-01-15 07:56:52,207 [scm1-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Pipelines with at least one datanode reported count is 2, required at least one datanode reported per pipeline count is 2
2024-01-15 07:56:52,207 [scm1-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2024-01-15 07:56:52,207 [scm1-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
2024-01-15 07:56:52,207 [scm1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-01-15 07:56:52,740 [IPC Server handler 4 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/577b93ae-aa5e-4de8-a35f-0c336284cb6e
2024-01-15 07:56:52,742 [IPC Server handler 4 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 577b93ae-aa5e-4de8-a35f-0c336284cb6e{ip: 10.9.0.20, host: ha_dn4_1.ha_net, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 480984214326, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2024-01-15 07:56:52,742 [scm1-EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on scm1-RatisPipelineUtilsThread.
2024-01-15 07:56:52,743 [scm1-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
2024-01-15 07:56:52,743 [scm1-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
2024-01-15 07:56:52,744 [scm1-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
2024-01-15 07:56:52,744 [scm1-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2024-01-15 07:56:52,744 [scm1-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on scm1-RatisPipelineUtilsThread.
2024-01-15 07:56:52,744 [scm1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-01-15 07:56:52,761 [IPC Server handler 5 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/1ad0897d-1843-4d24-b971-4a92bbe2a364
2024-01-15 07:56:52,762 [IPC Server handler 5 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 1ad0897d-1843-4d24-b971-4a92bbe2a364{ip: 10.9.0.21, host: ha_dn5_1.ha_net, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 483469243666, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2024-01-15 07:56:52,764 [scm1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-01-15 07:56:52,764 [scm1-EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on scm1-RatisPipelineUtilsThread.
2024-01-15 07:56:53,224 [scm1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-01-15 07:56:53,876 [IPC Server handler 26 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/6df82867-8830-4371-a735-44f603d10388
2024-01-15 07:56:53,876 [IPC Server handler 26 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 6df82867-8830-4371-a735-44f603d10388{ip: 10.9.0.19, host: ha_dn3_1.ha_net, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 481034662901, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2024-01-15 07:56:53,876 [scm1-EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on scm1-RatisPipelineUtilsThread.
2024-01-15 07:56:53,877 [scm1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2024-01-15 07:56:53,877 [scm1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
2024-01-15 07:56:53,877 [scm1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
2024-01-15 07:56:53,877 [scm1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
2024-01-15 07:56:53,877 [scm1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2024-01-15 07:56:53,877 [scm1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO BackgroundPipelineScrubber: Service BackgroundPipelineScrubber transitions to RUNNING.
2024-01-15 07:56:53,877 [scm1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ExpiredContainerReplicaOpScrubber: Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2024-01-15 07:56:53,878 [scm1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO block.SCMBlockDeletingService: notifyStatusChanged:RUNNING
2024-01-15 07:56:53,878 [scm1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO replication.ReplicationManager: Service ReplicationManager transitions to RUNNING.
2024-01-15 07:56:53,881 [scm1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2024-01-15 07:56:53,881 [scm1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO SCMHATransactionMonitor: Service SCMHATransactionMonitor transitions to RUNNING.
2024-01-15 07:56:59,818 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from ha_recon_1.ha_net:46211 / 10.9.0.22:46211
2024-01-15 07:56:59,824 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2024-01-15 07:57:10,100 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from scm1.org:51674 / 10.9.0.14:51674
2024-01-15 07:57:10,133 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2024-01-15 07:57:10,134 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Finalization started.
2024-01-15 07:57:10,154 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Stopping scm1-RatisPipelineUtilsThread.
2024-01-15 07:57:10,155 [scm1-RatisPipelineUtilsThread-0] WARN pipeline.BackgroundPipelineCreator: scm1-RatisPipelineUtilsThread is interrupted.
2024-01-15 07:57:10,155 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: SCM Finalization has crossed checkpoint FINALIZATION_STARTED
2024-01-15 07:57:10,185 [IPC Server handler 42 on default port 9860] INFO pipeline.PipelineManagerImpl: Container #1 closed for pipeline=PipelineID=05aed6cd-b189-4551-97b5-76e89ecb956c
2024-01-15 07:57:10,185 [scm1-EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #1, current state: CLOSING
2024-01-15 07:57:10,202 [IPC Server handler 42 on default port 9860] INFO pipeline.PipelineManagerImpl: Container #1001 closed for pipeline=PipelineID=05aed6cd-b189-4551-97b5-76e89ecb956c
2024-01-15 07:57:10,225 [IPC Server handler 42 on default port 9860] INFO pipeline.PipelineManagerImpl: Pipeline PipelineID=05aed6cd-b189-4551-97b5-76e89ecb956c moved to CLOSED state
2024-01-15 07:57:10,235 [IPC Server handler 42 on default port 9860] INFO pipeline.PipelineManagerImpl: Pipeline PipelineID=9a16f334-35fa-429b-9443-c54a2f17258f moved to CLOSED state
2024-01-15 07:57:10,243 [scm1-EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #1001, current state: CLOSING
2024-01-15 07:57:10,248 [IPC Server handler 42 on default port 9860] INFO pipeline.PipelineManagerImpl: Pipeline PipelineID=05f3cc29-ea59-41ee-adf1-15524c6ede5a moved to CLOSED state
2024-01-15 07:57:10,262 [IPC Server handler 42 on default port 9860] INFO pipeline.PipelineManagerImpl: Pipeline PipelineID=4aeba50b-28be-40f1-9953-3ea879790287 moved to CLOSED state
2024-01-15 07:57:10,281 [IPC Server handler 42 on default port 9860] INFO pipeline.PipelineManagerImpl: Container #2 closed for pipeline=PipelineID=8d2d4132-d1ad-4792-b8b3-58645b77e67c
2024-01-15 07:57:10,289 [scm1-EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #2, current state: CLOSING
2024-01-15 07:57:10,293 [IPC Server handler 42 on default port 9860] INFO pipeline.PipelineManagerImpl: Container #1002 closed for pipeline=PipelineID=8d2d4132-d1ad-4792-b8b3-58645b77e67c
2024-01-15 07:57:10,294 [scm1-EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #1002, current state: CLOSING
2024-01-15 07:57:10,307 [IPC Server handler 42 on default port 9860] INFO pipeline.PipelineManagerImpl: Pipeline PipelineID=8d2d4132-d1ad-4792-b8b3-58645b77e67c moved to CLOSED state
2024-01-15 07:57:10,317 [IPC Server handler 42 on default port 9860] INFO pipeline.PipelineManagerImpl: Pipeline PipelineID=f504e273-0ce2-4715-845a-959982386376 moved to CLOSED state
2024-01-15 07:57:10,329 [IPC Server handler 42 on default port 9860] INFO pipeline.PipelineManagerImpl: Pipeline PipelineID=48b053ac-c1bd-4404-acc0-1be0d203e4b8 moved to CLOSED state
2024-01-15 07:57:10,329 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer:   Existing pipelines and containers will be closed during Upgrade.
  New pipelines creation will remain frozen until Upgrade is finalized.
2024-01-15 07:57:10,340 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: RATIS_DATASTREAM_PORT_IN_DATANODEDETAILS.
2024-01-15 07:57:10,354 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] INFO upgrade.AbstractLayoutVersionManager: Layout feature RATIS_DATASTREAM_PORT_IN_DATANODEDETAILS has been finalized.
2024-01-15 07:57:10,360 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: WEBUI_PORTS_IN_DATANODEDETAILS.
2024-01-15 07:57:10,363 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] INFO upgrade.AbstractLayoutVersionManager: Layout feature WEBUI_PORTS_IN_DATANODEDETAILS has been finalized.
2024-01-15 07:57:10,379 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] INFO upgrade.UpgradeFinalizer: No onFinalize work defined for feature: HADOOP_PRC_PORTS_IN_DATANODEDETAILS.
2024-01-15 07:57:10,381 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] INFO upgrade.AbstractLayoutVersionManager: Layout feature HADOOP_PRC_PORTS_IN_DATANODEDETAILS has been finalized.
2024-01-15 07:57:10,381 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] INFO upgrade.AbstractLayoutVersionManager: Finalization is complete.
2024-01-15 07:57:10,386 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Starting scm1-RatisPipelineUtilsThread.
2024-01-15 07:57:10,387 [scm1-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Datanode 6df82867-8830-4371-a735-44f603d10388(ha_dn3_1.ha_net/10.9.0.19) moved to HEALTHY READONLY state.
2024-01-15 07:57:10,388 [scm1-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=05aed6cd-b189-4551-97b5-76e89ecb956c in state CLOSED which uses HEALTHY_READONLY datanode 6df82867-8830-4371-a735-44f603d10388. This will send close commands for its containers.
2024-01-15 07:57:10,388 [scm1-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=9a16f334-35fa-429b-9443-c54a2f17258f in state CLOSED which uses HEALTHY_READONLY datanode 6df82867-8830-4371-a735-44f603d10388. This will send close commands for its containers.
2024-01-15 07:57:10,389 [scm1-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=8d2d4132-d1ad-4792-b8b3-58645b77e67c in state CLOSED which uses HEALTHY_READONLY datanode 6df82867-8830-4371-a735-44f603d10388. This will send close commands for its containers.
2024-01-15 07:57:10,389 [scm1-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Datanode 5953220d-7af2-4159-933f-22262aae1e87(ha_dn2_1.ha_net/10.9.0.18) moved to HEALTHY READONLY state.
2024-01-15 07:57:10,390 [scm1-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=05f3cc29-ea59-41ee-adf1-15524c6ede5a in state CLOSED which uses HEALTHY_READONLY datanode 5953220d-7af2-4159-933f-22262aae1e87. This will send close commands for its containers.
2024-01-15 07:57:10,390 [scm1-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Datanode 577b93ae-aa5e-4de8-a35f-0c336284cb6e(ha_dn4_1.ha_net/10.9.0.20) moved to HEALTHY READONLY state.
2024-01-15 07:57:10,390 [scm1-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=05aed6cd-b189-4551-97b5-76e89ecb956c in state CLOSED which uses HEALTHY_READONLY datanode 577b93ae-aa5e-4de8-a35f-0c336284cb6e. This will send close commands for its containers.
2024-01-15 07:57:10,391 [scm1-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=8d2d4132-d1ad-4792-b8b3-58645b77e67c in state CLOSED which uses HEALTHY_READONLY datanode 577b93ae-aa5e-4de8-a35f-0c336284cb6e. This will send close commands for its containers.
2024-01-15 07:57:10,392 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: SCM Finalization has crossed checkpoint MLV_EQUALS_SLV
2024-01-15 07:57:10,392 [scm1-RatisPipelineUtilsThread-0] ERROR pipeline.PipelinePlacementPolicy: No healthy node found to allocate container.
2024-01-15 07:57:10,393 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:57:10,393 [scm1-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=f504e273-0ce2-4715-845a-959982386376 in state CLOSED which uses HEALTHY_READONLY datanode 577b93ae-aa5e-4de8-a35f-0c336284cb6e. This will send close commands for its containers.
2024-01-15 07:57:10,393 [scm1-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17) moved to HEALTHY READONLY state.
2024-01-15 07:57:10,393 [scm1-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=05aed6cd-b189-4551-97b5-76e89ecb956c in state CLOSED which uses HEALTHY_READONLY datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945. This will send close commands for its containers.
2024-01-15 07:57:10,393 [scm1-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=8d2d4132-d1ad-4792-b8b3-58645b77e67c in state CLOSED which uses HEALTHY_READONLY datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945. This will send close commands for its containers.
2024-01-15 07:57:10,394 [scm1-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=48b053ac-c1bd-4404-acc0-1be0d203e4b8 in state CLOSED which uses HEALTHY_READONLY datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945. This will send close commands for its containers.
2024-01-15 07:57:10,394 [scm1-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Datanode 1ad0897d-1843-4d24-b971-4a92bbe2a364(ha_dn5_1.ha_net/10.9.0.21) moved to HEALTHY READONLY state.
2024-01-15 07:57:10,394 [scm1-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO node.HealthyReadOnlyNodeHandler: Sending close command for pipeline PipelineID=4aeba50b-28be-40f1-9953-3ea879790287 in state CLOSED which uses HEALTHY_READONLY datanode 1ad0897d-1843-4d24-b971-4a92bbe2a364. This will send close commands for its containers.
2024-01-15 07:57:15,393 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:57:16,173 [scm1-SecretKeyManagerService] INFO symmetric.SecretKeyManager: SecretKey rotation is happening, new key generated SecretKey(id = 9bddd15d-aa6f-4d02-8759-c55324acb0bf, creation at: 2024-01-15T07:57:16.172993Z, expire at: 2024-01-15T08:57:16.172993Z)
2024-01-15 07:57:16,181 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Updating keys with [SecretKey(id = 17343b73-6203-4ee1-839d-499f80eed361, creation at: 2024-01-15T07:49:06.544Z, expire at: 2024-01-15T08:49:06.544Z), SecretKey(id = 9bddd15d-aa6f-4d02-8759-c55324acb0bf, creation at: 2024-01-15T07:57:16.172Z, expire at: 2024-01-15T08:57:16.172Z)]
2024-01-15 07:57:16,183 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Current key updated SecretKey(id = 9bddd15d-aa6f-4d02-8759-c55324acb0bf, creation at: 2024-01-15T07:57:16.172Z, expire at: 2024-01-15T08:57:16.172Z)
2024-01-15 07:57:16,184 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] INFO symmetric.LocalSecretKeyStore: Saved [SecretKey(id = 9bddd15d-aa6f-4d02-8759-c55324acb0bf, creation at: 2024-01-15T07:57:16.172Z, expire at: 2024-01-15T08:57:16.172Z), SecretKey(id = 17343b73-6203-4ee1-839d-499f80eed361, creation at: 2024-01-15T07:49:06.544Z, expire at: 2024-01-15T08:49:06.544Z)] to file /data/metadata/scm/keys/secret_keys.json
2024-01-15 07:57:20,395 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:57:25,187 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:41440 / 10.9.0.18:41440
2024-01-15 07:57:25,207 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:57:25,208 [IPC Server handler 1 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:57:25,395 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:57:25,905 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:59420 / 10.9.0.17:59420
2024-01-15 07:57:25,945 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:57:25,946 [IPC Server handler 96 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:57:26,246 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:40120 / 10.9.0.21:40120
2024-01-15 07:57:26,255 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:57:26,256 [IPC Server handler 2 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:57:26,983 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:46142 / 10.9.0.20:46142
2024-01-15 07:57:26,998 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:57:26,999 [IPC Server handler 1 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:57:27,579 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:45812 / 10.9.0.19:45812
2024-01-15 07:57:27,605 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:57:27,605 [IPC Server handler 5 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:57:29,732 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from ha_recon_1.ha_net:44609 / 10.9.0.22:44609
2024-01-15 07:57:29,752 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2024-01-15 07:57:30,395 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:57:32,140 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:48254 / 10.9.0.17:48254
2024-01-15 07:57:32,152 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:55706 / 10.9.0.20:55706
2024-01-15 07:57:32,159 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2024-01-15 07:57:32,161 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2024-01-15 07:57:32,177 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:48910 / 10.9.0.18:48910
2024-01-15 07:57:32,185 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2024-01-15 07:57:32,515 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:46354 / 10.9.0.21:46354
2024-01-15 07:57:32,520 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2024-01-15 07:57:32,637 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:53294 / 10.9.0.19:53294
2024-01-15 07:57:32,641 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2024-01-15 07:57:35,396 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:57:40,393 [scm1-RatisPipelineUtilsThread-0] ERROR pipeline.PipelinePlacementPolicy: No healthy node found to allocate container.
2024-01-15 07:57:40,396 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:57:45,396 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:57:48,597 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om3_1.ha_net:57524 / 10.9.0.13:57524
2024-01-15 07:57:48,599 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolOm
2024-01-15 07:57:48,734 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om3_1.ha_net:38526 / 10.9.0.13:38526
2024-01-15 07:57:48,742 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2024-01-15 07:57:48,757 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for delTxnId, expected lastId is 0, actual lastId is 2000.
2024-01-15 07:57:48,769 [IPC Server handler 99 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for delTxnId, change lastId from 2000 to 3000.
2024-01-15 07:57:49,371 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om1_1.ha_net:36668 / 10.9.0.11:36668
2024-01-15 07:57:49,373 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolOm
2024-01-15 07:57:50,397 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:57:50,773 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om2_1.ha_net:45426 / 10.9.0.12:45426
2024-01-15 07:57:50,774 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolOm
2024-01-15 07:57:55,195 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:48590 / 10.9.0.18:48590
2024-01-15 07:57:55,199 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:57:55,200 [IPC Server handler 2 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn2_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:57:55,397 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:57:55,892 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:42252 / 10.9.0.17:42252
2024-01-15 07:57:55,897 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:57:55,899 [IPC Server handler 52 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:57:56,244 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:58150 / 10.9.0.21:58150
2024-01-15 07:57:56,260 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:57:56,262 [IPC Server handler 4 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn5_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:57:56,950 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:42096 / 10.9.0.20:42096
2024-01-15 07:57:56,957 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:57:56,958 [IPC Server handler 1 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:57:57,571 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:58994 / 10.9.0.19:58994
2024-01-15 07:57:57,590 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:57:57,591 [IPC Server handler 5 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:58:00,397 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:58:05,397 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:58:10,394 [scm1-RatisPipelineUtilsThread-0] ERROR pipeline.PipelinePlacementPolicy: No healthy node found to allocate container.
2024-01-15 07:58:10,397 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:58:15,397 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:58:20,398 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:58:25,197 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:34638 / 10.9.0.18:34638
2024-01-15 07:58:25,216 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:58:25,398 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:58:25,889 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:59882 / 10.9.0.17:59882
2024-01-15 07:58:25,928 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:58:25,929 [IPC Server handler 71 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:58:26,244 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:48972 / 10.9.0.21:48972
2024-01-15 07:58:26,261 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:58:26,946 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:36870 / 10.9.0.20:36870
2024-01-15 07:58:26,975 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:58:26,976 [IPC Server handler 2 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:58:27,575 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:38958 / 10.9.0.19:38958
2024-01-15 07:58:27,581 [scm1-EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO node.ReadOnlyHealthyToHealthyNodeHandler: Datanode 5953220d-7af2-4159-933f-22262aae1e87(ha_dn2_1.ha_net/10.9.0.18) moved to HEALTHY state.
2024-01-15 07:58:27,581 [scm1-EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on scm1-RatisPipelineUtilsThread.
2024-01-15 07:58:27,582 [scm1-EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO node.ReadOnlyHealthyToHealthyNodeHandler: Datanode 1ad0897d-1843-4d24-b971-4a92bbe2a364(ha_dn5_1.ha_net/10.9.0.21) moved to HEALTHY state.
2024-01-15 07:58:27,582 [scm1-EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on scm1-RatisPipelineUtilsThread.
2024-01-15 07:58:27,584 [scm1-RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a4acbb6a-f8af-42d8-afd6-357e80aa8803 to datanode:5953220d-7af2-4159-933f-22262aae1e87
2024-01-15 07:58:27,597 [scm1-RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: a4acbb6a-f8af-42d8-afd6-357e80aa8803, Nodes: 5953220d-7af2-4159-933f-22262aae1e87(ha_dn2_1.ha_net/10.9.0.18), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-01-15T07:58:27.584247Z[UTC]]
2024-01-15 07:58:27,598 [scm1-RatisPipelineUtilsThread-0] WARN scm.SCMCommonPlacementPolicy: Unable to find enough nodes that meet the space requirement of 1073741824 bytes for metadata and 1073741824 bytes for data in healthy node set. Required 3. Found 2.
2024-01-15 07:58:27,599 [scm1-RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=344d6bd2-8230-408d-b722-5cb7a85c3652 to datanode:1ad0897d-1843-4d24-b971-4a92bbe2a364
2024-01-15 07:58:27,608 [scm1-RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 344d6bd2-8230-408d-b722-5cb7a85c3652, Nodes: 1ad0897d-1843-4d24-b971-4a92bbe2a364(ha_dn5_1.ha_net/10.9.0.21), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-01-15T07:58:27.599429Z[UTC]]
2024-01-15 07:58:27,610 [scm1-RatisPipelineUtilsThread-0] WARN scm.SCMCommonPlacementPolicy: Unable to find enough nodes that meet the space requirement of 1073741824 bytes for metadata and 1073741824 bytes for data in healthy node set. Required 3. Found 2.
2024-01-15 07:58:27,621 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:58:27,621 [IPC Server handler 3 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:58:30,398 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:58:35,398 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:58:40,398 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:58:45,399 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:58:50,399 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:58:55,181 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:60680 / 10.9.0.18:60680
2024-01-15 07:58:55,205 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:58:55,399 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:58:55,892 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:54334 / 10.9.0.17:54334
2024-01-15 07:58:55,907 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:58:55,907 [IPC Server handler 55 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:58:56,201 [scm1-EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=a4acbb6a-f8af-42d8-afd6-357e80aa8803
2024-01-15 07:58:56,221 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from ha_recon_1.ha_net:43767 / 10.9.0.22:43767
2024-01-15 07:58:56,235 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2024-01-15 07:58:56,270 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:58932 / 10.9.0.21:58932
2024-01-15 07:58:56,282 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:58:56,951 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:38482 / 10.9.0.20:38482
2024-01-15 07:58:56,989 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:58:56,990 [IPC Server handler 4 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:58:57,273 [scm1-EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=344d6bd2-8230-408d-b722-5cb7a85c3652
2024-01-15 07:58:57,576 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:45774 / 10.9.0.19:45774
2024-01-15 07:58:57,611 [scm1-RatisPipelineUtilsThread-0] WARN scm.SCMCommonPlacementPolicy: Unable to find enough nodes that meet the space requirement of 1073741824 bytes for metadata and 1073741824 bytes for data in healthy node set. Required 3. Found 2.
2024-01-15 07:58:57,621 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:58:57,622 [IPC Server handler 3 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:00,399 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:59:05,399 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:59:10,400 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:59:15,400 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:59:15,683 [scm1-BackgroundPipelineScrubber] INFO pipeline.PipelineManagerImpl: Scrubbing pipeline: id: PipelineID=05aed6cd-b189-4551-97b5-76e89ecb956c since it stays at CLOSED stage.
2024-01-15 07:59:15,685 [scm1-BackgroundPipelineScrubber] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=05aed6cd-b189-4551-97b5-76e89ecb956c close command to datanode 577b93ae-aa5e-4de8-a35f-0c336284cb6e
2024-01-15 07:59:15,685 [scm1-BackgroundPipelineScrubber] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=05aed6cd-b189-4551-97b5-76e89ecb956c close command to datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945
2024-01-15 07:59:15,686 [scm1-BackgroundPipelineScrubber] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=05aed6cd-b189-4551-97b5-76e89ecb956c close command to datanode 6df82867-8830-4371-a735-44f603d10388
2024-01-15 07:59:15,692 [scm1-BackgroundPipelineScrubber] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 05aed6cd-b189-4551-97b5-76e89ecb956c, Nodes: 577b93ae-aa5e-4de8-a35f-0c336284cb6e(ha_dn4_1.ha_net/10.9.0.20)d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17)6df82867-8830-4371-a735-44f603d10388(ha_dn3_1.ha_net/10.9.0.19), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:577b93ae-aa5e-4de8-a35f-0c336284cb6e, CreationTimestamp2024-01-15T07:56:15.629421Z[UTC]] removed.
2024-01-15 07:59:15,693 [scm1-BackgroundPipelineScrubber] INFO pipeline.PipelineManagerImpl: Scrubbing pipeline: id: PipelineID=9a16f334-35fa-429b-9443-c54a2f17258f since it stays at CLOSED stage.
2024-01-15 07:59:15,693 [scm1-BackgroundPipelineScrubber] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=9a16f334-35fa-429b-9443-c54a2f17258f close command to datanode 6df82867-8830-4371-a735-44f603d10388
2024-01-15 07:59:15,702 [scm1-BackgroundPipelineScrubber] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 9a16f334-35fa-429b-9443-c54a2f17258f, Nodes: 6df82867-8830-4371-a735-44f603d10388(ha_dn3_1.ha_net/10.9.0.19), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:6df82867-8830-4371-a735-44f603d10388, CreationTimestamp2024-01-15T07:56:15.633459Z[UTC]] removed.
2024-01-15 07:59:15,702 [scm1-BackgroundPipelineScrubber] INFO pipeline.PipelineManagerImpl: Scrubbing pipeline: id: PipelineID=05f3cc29-ea59-41ee-adf1-15524c6ede5a since it stays at CLOSED stage.
2024-01-15 07:59:15,702 [scm1-BackgroundPipelineScrubber] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=05f3cc29-ea59-41ee-adf1-15524c6ede5a close command to datanode 5953220d-7af2-4159-933f-22262aae1e87
2024-01-15 07:59:15,707 [scm1-BackgroundPipelineScrubber] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 05f3cc29-ea59-41ee-adf1-15524c6ede5a, Nodes: 5953220d-7af2-4159-933f-22262aae1e87(ha_dn2_1.ha_net/10.9.0.18), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:5953220d-7af2-4159-933f-22262aae1e87, CreationTimestamp2024-01-15T07:56:15.631746Z[UTC]] removed.
2024-01-15 07:59:15,707 [scm1-BackgroundPipelineScrubber] INFO pipeline.PipelineManagerImpl: Scrubbing pipeline: id: PipelineID=4aeba50b-28be-40f1-9953-3ea879790287 since it stays at CLOSED stage.
2024-01-15 07:59:15,707 [scm1-BackgroundPipelineScrubber] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=4aeba50b-28be-40f1-9953-3ea879790287 close command to datanode 1ad0897d-1843-4d24-b971-4a92bbe2a364
2024-01-15 07:59:15,715 [scm1-BackgroundPipelineScrubber] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 4aeba50b-28be-40f1-9953-3ea879790287, Nodes: 1ad0897d-1843-4d24-b971-4a92bbe2a364(ha_dn5_1.ha_net/10.9.0.21), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:1ad0897d-1843-4d24-b971-4a92bbe2a364, CreationTimestamp2024-01-15T07:56:15.632285Z[UTC]] removed.
2024-01-15 07:59:15,715 [scm1-BackgroundPipelineScrubber] INFO pipeline.PipelineManagerImpl: Scrubbing pipeline: id: PipelineID=8d2d4132-d1ad-4792-b8b3-58645b77e67c since it stays at CLOSED stage.
2024-01-15 07:59:15,716 [scm1-BackgroundPipelineScrubber] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=8d2d4132-d1ad-4792-b8b3-58645b77e67c close command to datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945
2024-01-15 07:59:15,716 [scm1-BackgroundPipelineScrubber] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=8d2d4132-d1ad-4792-b8b3-58645b77e67c close command to datanode 577b93ae-aa5e-4de8-a35f-0c336284cb6e
2024-01-15 07:59:15,716 [scm1-BackgroundPipelineScrubber] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=8d2d4132-d1ad-4792-b8b3-58645b77e67c close command to datanode 6df82867-8830-4371-a735-44f603d10388
2024-01-15 07:59:15,720 [scm1-BackgroundPipelineScrubber] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 8d2d4132-d1ad-4792-b8b3-58645b77e67c, Nodes: d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17)577b93ae-aa5e-4de8-a35f-0c336284cb6e(ha_dn4_1.ha_net/10.9.0.20)6df82867-8830-4371-a735-44f603d10388(ha_dn3_1.ha_net/10.9.0.19), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:6df82867-8830-4371-a735-44f603d10388, CreationTimestamp2024-01-15T07:56:15.633211Z[UTC]] removed.
2024-01-15 07:59:15,720 [scm1-BackgroundPipelineScrubber] INFO pipeline.PipelineManagerImpl: Scrubbing pipeline: id: PipelineID=f504e273-0ce2-4715-845a-959982386376 since it stays at CLOSED stage.
2024-01-15 07:59:15,720 [scm1-BackgroundPipelineScrubber] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=f504e273-0ce2-4715-845a-959982386376 close command to datanode 577b93ae-aa5e-4de8-a35f-0c336284cb6e
2024-01-15 07:59:15,725 [scm1-BackgroundPipelineScrubber] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: f504e273-0ce2-4715-845a-959982386376, Nodes: 577b93ae-aa5e-4de8-a35f-0c336284cb6e(ha_dn4_1.ha_net/10.9.0.20), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:577b93ae-aa5e-4de8-a35f-0c336284cb6e, CreationTimestamp2024-01-15T07:56:15.636846Z[UTC]] removed.
2024-01-15 07:59:15,725 [scm1-BackgroundPipelineScrubber] INFO pipeline.PipelineManagerImpl: Scrubbing pipeline: id: PipelineID=48b053ac-c1bd-4404-acc0-1be0d203e4b8 since it stays at CLOSED stage.
2024-01-15 07:59:15,725 [scm1-BackgroundPipelineScrubber] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=48b053ac-c1bd-4404-acc0-1be0d203e4b8 close command to datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945
2024-01-15 07:59:15,731 [scm1-BackgroundPipelineScrubber] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 48b053ac-c1bd-4404-acc0-1be0d203e4b8, Nodes: d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:d8ef6392-c8b7-40ba-a1b4-c245afaf6945, CreationTimestamp2024-01-15T07:56:15.632003Z[UTC]] removed.
2024-01-15 07:59:20,400 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:59:25,400 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:59:25,892 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:34692 / 10.9.0.17:34692
2024-01-15 07:59:25,906 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:59:25,906 [IPC Server handler 52 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:26,959 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:57876 / 10.9.0.20:57876
2024-01-15 07:59:26,969 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:59:26,970 [IPC Server handler 2 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:27,133 [IPC Server handler 5 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:27,137 [IPC Server handler 3 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:27,137 [scm1-FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Moving container #1 to QUASI_CLOSED state, datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17) reported QUASI_CLOSED replica.
2024-01-15 07:59:27,170 [IPC Server handler 8 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:27,178 [IPC Server handler 9 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:27,179 [scm1-FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Moving container #1001 to QUASI_CLOSED state, datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17) reported QUASI_CLOSED replica.
2024-01-15 07:59:27,573 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:38194 / 10.9.0.19:38194
2024-01-15 07:59:27,584 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:59:27,585 [IPC Server handler 11 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:27,586 [scm1-EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Reported pipeline PipelineID=05aed6cd-b189-4551-97b5-76e89ecb956c is not found
2024-01-15 07:59:27,586 [scm1-EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Reported pipeline PipelineID=9a16f334-35fa-429b-9443-c54a2f17258f is not found
2024-01-15 07:59:27,586 [scm1-EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Reported pipeline PipelineID=8d2d4132-d1ad-4792-b8b3-58645b77e67c is not found
2024-01-15 07:59:27,612 [scm1-RatisPipelineUtilsThread-0] WARN scm.SCMCommonPlacementPolicy: Unable to find enough nodes that meet the space requirement of 1073741824 bytes for metadata and 1073741824 bytes for data in healthy node set. Required 3. Found 2.
2024-01-15 07:59:27,709 [IPC Server handler 18 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:27,723 [IPC Server handler 7 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:27,724 [scm1-FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Moving container #2 to QUASI_CLOSED state, datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17) reported QUASI_CLOSED replica.
2024-01-15 07:59:27,734 [IPC Server handler 10 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:27,748 [IPC Server handler 13 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn1_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:27,750 [scm1-FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Moving container #1002 to QUASI_CLOSED state, datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17) reported QUASI_CLOSED replica.
2024-01-15 07:59:28,127 [IPC Server handler 5 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:28,147 [IPC Server handler 8 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:28,158 [IPC Server handler 9 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:28,166 [IPC Server handler 11 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:28,713 [IPC Server handler 7 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:28,722 [IPC Server handler 10 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:28,724 [IPC Server handler 13 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:28,730 [IPC Server handler 6 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn4_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:29,195 [IPC Server handler 18 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:29,205 [IPC Server handler 7 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:29,212 [IPC Server handler 10 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:29,216 [IPC Server handler 13 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:29,709 [IPC Server handler 6 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:29,714 [IPC Server handler 14 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:29,721 [IPC Server handler 17 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:29,726 [IPC Server handler 15 on default port 9861] WARN node.SCMNodeManager: Data node ha_dn3_1.ha_net can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 7
2024-01-15 07:59:30,400 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:59:31,306 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:54410 / 10.9.0.18:54410
2024-01-15 07:59:31,337 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:59:31,341 [scm1-EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Reported pipeline PipelineID=05f3cc29-ea59-41ee-adf1-15524c6ede5a is not found
2024-01-15 07:59:32,397 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:42060 / 10.9.0.21:42060
2024-01-15 07:59:32,424 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:59:32,425 [scm1-EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Reported pipeline PipelineID=4aeba50b-28be-40f1-9953-3ea879790287 is not found
2024-01-15 07:59:35,400 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:59:40,401 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:59:45,401 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:59:50,401 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:59:55,401 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 07:59:57,612 [scm1-RatisPipelineUtilsThread-0] WARN scm.SCMCommonPlacementPolicy: Unable to find enough nodes that meet the space requirement of 1073741824 bytes for metadata and 1073741824 bytes for data in healthy node set. Required 3. Found 2.
2024-01-15 07:59:57,776 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:43900 / 10.9.0.17:43900
2024-01-15 07:59:57,791 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:59:58,755 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:54418 / 10.9.0.20:54418
2024-01-15 07:59:58,766 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 07:59:59,763 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:51728 / 10.9.0.19:51728
2024-01-15 07:59:59,776 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:00:00,401 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 08:00:00,586 [scm1-EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO node.ReadOnlyHealthyToHealthyNodeHandler: Datanode 6df82867-8830-4371-a735-44f603d10388(ha_dn3_1.ha_net/10.9.0.19) moved to HEALTHY state.
2024-01-15 08:00:00,586 [scm1-EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on scm1-RatisPipelineUtilsThread.
2024-01-15 08:00:00,586 [scm1-EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO node.ReadOnlyHealthyToHealthyNodeHandler: Datanode 577b93ae-aa5e-4de8-a35f-0c336284cb6e(ha_dn4_1.ha_net/10.9.0.20) moved to HEALTHY state.
2024-01-15 08:00:00,586 [scm1-EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on scm1-RatisPipelineUtilsThread.
2024-01-15 08:00:00,586 [scm1-EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO node.ReadOnlyHealthyToHealthyNodeHandler: Datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17) moved to HEALTHY state.
2024-01-15 08:00:00,586 [scm1-EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on scm1-RatisPipelineUtilsThread.
2024-01-15 08:00:00,587 [scm1-RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=c926dcb5-cbc9-427d-9689-f0e2819cfaeb to datanode:6df82867-8830-4371-a735-44f603d10388
2024-01-15 08:00:00,595 [scm1-RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: c926dcb5-cbc9-427d-9689-f0e2819cfaeb, Nodes: 6df82867-8830-4371-a735-44f603d10388(ha_dn3_1.ha_net/10.9.0.19), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-01-15T08:00:00.587282Z[UTC]]
2024-01-15 08:00:00,599 [scm1-RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=90680b44-58ed-40db-8293-1db662497aaa to datanode:d8ef6392-c8b7-40ba-a1b4-c245afaf6945
2024-01-15 08:00:00,599 [scm1-RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=90680b44-58ed-40db-8293-1db662497aaa to datanode:1ad0897d-1843-4d24-b971-4a92bbe2a364
2024-01-15 08:00:00,599 [scm1-RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=90680b44-58ed-40db-8293-1db662497aaa to datanode:577b93ae-aa5e-4de8-a35f-0c336284cb6e
2024-01-15 08:00:00,605 [scm1-RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 90680b44-58ed-40db-8293-1db662497aaa, Nodes: d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17)1ad0897d-1843-4d24-b971-4a92bbe2a364(ha_dn5_1.ha_net/10.9.0.21)577b93ae-aa5e-4de8-a35f-0c336284cb6e(ha_dn4_1.ha_net/10.9.0.20), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-01-15T08:00:00.599754Z[UTC]]
2024-01-15 08:00:00,606 [scm1-RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=2c08dffb-8e6a-44c0-87e0-7e8cf5449e0e to datanode:577b93ae-aa5e-4de8-a35f-0c336284cb6e
2024-01-15 08:00:00,615 [scm1-RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 2c08dffb-8e6a-44c0-87e0-7e8cf5449e0e, Nodes: 577b93ae-aa5e-4de8-a35f-0c336284cb6e(ha_dn4_1.ha_net/10.9.0.20), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-01-15T08:00:00.606196Z[UTC]]
2024-01-15 08:00:00,617 [scm1-RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=9dad8ba8-a15e-48be-84a4-45ae75dd8fcc to datanode:6df82867-8830-4371-a735-44f603d10388
2024-01-15 08:00:00,618 [scm1-RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=9dad8ba8-a15e-48be-84a4-45ae75dd8fcc to datanode:1ad0897d-1843-4d24-b971-4a92bbe2a364
2024-01-15 08:00:00,618 [scm1-RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=9dad8ba8-a15e-48be-84a4-45ae75dd8fcc to datanode:d8ef6392-c8b7-40ba-a1b4-c245afaf6945
2024-01-15 08:00:00,623 [scm1-RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 9dad8ba8-a15e-48be-84a4-45ae75dd8fcc, Nodes: 6df82867-8830-4371-a735-44f603d10388(ha_dn3_1.ha_net/10.9.0.19)1ad0897d-1843-4d24-b971-4a92bbe2a364(ha_dn5_1.ha_net/10.9.0.21)d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-01-15T08:00:00.617916Z[UTC]]
2024-01-15 08:00:00,624 [scm1-RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=b8376600-aa0d-4667-948d-af548f80b617 to datanode:d8ef6392-c8b7-40ba-a1b4-c245afaf6945
2024-01-15 08:00:00,631 [scm1-RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: b8376600-aa0d-4667-948d-af548f80b617, Nodes: d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-01-15T08:00:00.624332Z[UTC]]
2024-01-15 08:00:00,632 [scm1-RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=b9bdfe39-f2aa-46ec-8637-d4e42024cba9 to datanode:6df82867-8830-4371-a735-44f603d10388
2024-01-15 08:00:00,632 [scm1-RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=b9bdfe39-f2aa-46ec-8637-d4e42024cba9 to datanode:5953220d-7af2-4159-933f-22262aae1e87
2024-01-15 08:00:00,632 [scm1-RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=b9bdfe39-f2aa-46ec-8637-d4e42024cba9 to datanode:577b93ae-aa5e-4de8-a35f-0c336284cb6e
2024-01-15 08:00:00,637 [scm1-RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: b9bdfe39-f2aa-46ec-8637-d4e42024cba9, Nodes: 6df82867-8830-4371-a735-44f603d10388(ha_dn3_1.ha_net/10.9.0.19)5953220d-7af2-4159-933f-22262aae1e87(ha_dn2_1.ha_net/10.9.0.18)577b93ae-aa5e-4de8-a35f-0c336284cb6e(ha_dn4_1.ha_net/10.9.0.20), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-01-15T08:00:00.632426Z[UTC]]
2024-01-15 08:00:01,317 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:55416 / 10.9.0.18:55416
2024-01-15 08:00:01,331 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:00:02,303 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from ha_recon_1.ha_net:40229 / 10.9.0.22:40229
2024-01-15 08:00:02,305 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2024-01-15 08:00:02,422 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:57040 / 10.9.0.21:57040
2024-01-15 08:00:02,472 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:00:05,401 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2024-01-15 08:00:07,884 [scm1-EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=b9bdfe39-f2aa-46ec-8637-d4e42024cba9
2024-01-15 08:00:09,093 [scm1-EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=90680b44-58ed-40db-8293-1db662497aaa
2024-01-15 08:00:09,257 [scm1-EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=9dad8ba8-a15e-48be-84a4-45ae75dd8fcc
2024-01-15 08:00:10,402 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Open pipeline found after SCM finalization
2024-01-15 08:00:10,408 [IPC Server handler 42 on default port 9860] INFO upgrade.UpgradeFinalizer: Finalization is done.
2024-01-15 08:00:18,875 [scm1-SCMBlockDeletingService#0] INFO block.SCMBlockDeletingService: Totally added 18 blocks to be deleted for 3 datanodes, task elapsed time: 8ms
2024-01-15 08:00:23,006 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from scm1.org:50952 / 10.9.0.14:50952
2024-01-15 08:00:23,024 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2024-01-15 08:00:28,831 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:42882 / 10.9.0.17:42882
2024-01-15 08:00:28,863 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:00:28,872 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from ha_recon_1.ha_net:41023 / 10.9.0.22:41023
2024-01-15 08:00:28,891 [scm1-EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=b8376600-aa0d-4667-948d-af548f80b617
2024-01-15 08:00:28,891 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2024-01-15 08:00:29,449 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om3_1.ha_net:48580 / 10.9.0.13:48580
2024-01-15 08:00:29,456 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2024-01-15 08:00:29,529 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om3_1.ha_net:41306 / 10.9.0.13:41306
2024-01-15 08:00:29,532 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2024-01-15 08:00:29,533 [IPC Server handler 9 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.9.0.14
2024-01-15 08:00:29,799 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:43168 / 10.9.0.20:43168
2024-01-15 08:00:29,812 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:00:29,826 [scm1-EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=2c08dffb-8e6a-44c0-87e0-7e8cf5449e0e
2024-01-15 08:00:30,659 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:32934 / 10.9.0.19:32934
2024-01-15 08:00:30,660 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2024-01-15 08:00:30,805 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:37238 / 10.9.0.19:37238
2024-01-15 08:00:30,836 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:00:30,844 [scm1-EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=c926dcb5-cbc9-427d-9689-f0e2819cfaeb
2024-01-15 08:00:32,330 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:53166 / 10.9.0.18:53166
2024-01-15 08:00:32,351 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:00:33,953 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:50784 / 10.9.0.21:50784
2024-01-15 08:00:33,961 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:00:41,596 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om3_1.ha_net:34050 / 10.9.0.13:34050
2024-01-15 08:00:41,598 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2024-01-15 08:00:41,608 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om3_1.ha_net:59296 / 10.9.0.13:59296
2024-01-15 08:00:41,616 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2024-01-15 08:00:41,617 [IPC Server handler 78 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.9.0.23
2024-01-15 08:00:42,406 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:44888 / 10.9.0.17:44888
2024-01-15 08:00:42,407 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2024-01-15 08:00:52,230 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om3_1.ha_net:51924 / 10.9.0.13:51924
2024-01-15 08:00:52,232 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2024-01-15 08:00:52,233 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.9.0.23
2024-01-15 08:00:52,306 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:44648 / 10.9.0.20:44648
2024-01-15 08:00:52,310 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2024-01-15 08:00:58,607 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om3_1.ha_net:56582 / 10.9.0.13:56582
2024-01-15 08:00:58,616 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2024-01-15 08:00:58,621 [IPC Server handler 92 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.9.0.14
2024-01-15 08:01:02,319 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:54794 / 10.9.0.18:54794
2024-01-15 08:01:02,330 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:01:03,931 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:35848 / 10.9.0.17:35848
2024-01-15 08:01:03,954 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:52104 / 10.9.0.21:52104
2024-01-15 08:01:03,956 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:01:03,997 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:01:04,872 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:43568 / 10.9.0.20:43568
2024-01-15 08:01:04,894 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:01:06,055 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:54098 / 10.9.0.19:54098
2024-01-15 08:01:06,094 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:01:09,544 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om3_1.ha_net:57500 / 10.9.0.13:57500
2024-01-15 08:01:09,545 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2024-01-15 08:01:09,552 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om3_1.ha_net:55928 / 10.9.0.13:55928
2024-01-15 08:01:09,553 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2024-01-15 08:01:09,554 [IPC Server handler 24 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.9.0.23
2024-01-15 08:01:15,869 [scm1-ReplicationMonitor] INFO health.QuasiClosedContainerHandler: Force closing container #1 with BCSID 33, which is in QUASI_CLOSED state.
2024-01-15 08:01:15,871 [scm1-ReplicationMonitor] INFO replication.ReplicationManager: Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=05aed6cd-b189-4551-97b5-76e89ecb956c, force: true] for container ContainerInfo{id=#1, state=QUASI_CLOSED, stateEnterTime=2024-01-15T07:59:27.144649Z, pipelineID=PipelineID=05aed6cd-b189-4551-97b5-76e89ecb956c, owner=om1} to d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17) with datanode deadline 1705306245870 and scm deadline 1705306275870
2024-01-15 08:01:15,871 [scm1-ReplicationMonitor] INFO replication.ReplicationManager: Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=05aed6cd-b189-4551-97b5-76e89ecb956c, force: true] for container ContainerInfo{id=#1, state=QUASI_CLOSED, stateEnterTime=2024-01-15T07:59:27.144649Z, pipelineID=PipelineID=05aed6cd-b189-4551-97b5-76e89ecb956c, owner=om1} to 577b93ae-aa5e-4de8-a35f-0c336284cb6e(ha_dn4_1.ha_net/10.9.0.20) with datanode deadline 1705306245871 and scm deadline 1705306275871
2024-01-15 08:01:15,871 [scm1-ReplicationMonitor] INFO replication.ReplicationManager: Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=05aed6cd-b189-4551-97b5-76e89ecb956c, force: true] for container ContainerInfo{id=#1, state=QUASI_CLOSED, stateEnterTime=2024-01-15T07:59:27.144649Z, pipelineID=PipelineID=05aed6cd-b189-4551-97b5-76e89ecb956c, owner=om1} to 6df82867-8830-4371-a735-44f603d10388(ha_dn3_1.ha_net/10.9.0.19) with datanode deadline 1705306245871 and scm deadline 1705306275871
2024-01-15 08:01:15,872 [scm1-ReplicationMonitor] INFO health.QuasiClosedContainerHandler: Force closing container #2 with BCSID 29, which is in QUASI_CLOSED state.
2024-01-15 08:01:15,872 [scm1-ReplicationMonitor] INFO replication.ReplicationManager: Sending command [closeContainerCommand: containerID: 2, pipelineID: PipelineID=8d2d4132-d1ad-4792-b8b3-58645b77e67c, force: true] for container ContainerInfo{id=#2, state=QUASI_CLOSED, stateEnterTime=2024-01-15T07:59:27.729948Z, pipelineID=PipelineID=8d2d4132-d1ad-4792-b8b3-58645b77e67c, owner=om1} to 577b93ae-aa5e-4de8-a35f-0c336284cb6e(ha_dn4_1.ha_net/10.9.0.20) with datanode deadline 1705306245872 and scm deadline 1705306275872
2024-01-15 08:01:15,873 [scm1-ReplicationMonitor] INFO replication.ReplicationManager: Sending command [closeContainerCommand: containerID: 2, pipelineID: PipelineID=8d2d4132-d1ad-4792-b8b3-58645b77e67c, force: true] for container ContainerInfo{id=#2, state=QUASI_CLOSED, stateEnterTime=2024-01-15T07:59:27.729948Z, pipelineID=PipelineID=8d2d4132-d1ad-4792-b8b3-58645b77e67c, owner=om1} to 6df82867-8830-4371-a735-44f603d10388(ha_dn3_1.ha_net/10.9.0.19) with datanode deadline 1705306245873 and scm deadline 1705306275873
2024-01-15 08:01:15,873 [scm1-ReplicationMonitor] INFO replication.ReplicationManager: Sending command [closeContainerCommand: containerID: 2, pipelineID: PipelineID=8d2d4132-d1ad-4792-b8b3-58645b77e67c, force: true] for container ContainerInfo{id=#2, state=QUASI_CLOSED, stateEnterTime=2024-01-15T07:59:27.729948Z, pipelineID=PipelineID=8d2d4132-d1ad-4792-b8b3-58645b77e67c, owner=om1} to d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17) with datanode deadline 1705306245873 and scm deadline 1705306275873
2024-01-15 08:01:15,873 [scm1-ReplicationMonitor] INFO health.QuasiClosedContainerHandler: Force closing container #1001 with BCSID 25, which is in QUASI_CLOSED state.
2024-01-15 08:01:15,873 [scm1-ReplicationMonitor] INFO replication.ReplicationManager: Sending command [closeContainerCommand: containerID: 1001, pipelineID: PipelineID=05aed6cd-b189-4551-97b5-76e89ecb956c, force: true] for container ContainerInfo{id=#1001, state=QUASI_CLOSED, stateEnterTime=2024-01-15T07:59:27.189236Z, pipelineID=PipelineID=05aed6cd-b189-4551-97b5-76e89ecb956c, owner=omservice} to 6df82867-8830-4371-a735-44f603d10388(ha_dn3_1.ha_net/10.9.0.19) with datanode deadline 1705306245873 and scm deadline 1705306275873
2024-01-15 08:01:15,874 [scm1-ReplicationMonitor] INFO replication.ReplicationManager: Sending command [closeContainerCommand: containerID: 1001, pipelineID: PipelineID=05aed6cd-b189-4551-97b5-76e89ecb956c, force: true] for container ContainerInfo{id=#1001, state=QUASI_CLOSED, stateEnterTime=2024-01-15T07:59:27.189236Z, pipelineID=PipelineID=05aed6cd-b189-4551-97b5-76e89ecb956c, owner=omservice} to 577b93ae-aa5e-4de8-a35f-0c336284cb6e(ha_dn4_1.ha_net/10.9.0.20) with datanode deadline 1705306245874 and scm deadline 1705306275874
2024-01-15 08:01:15,874 [scm1-ReplicationMonitor] INFO replication.ReplicationManager: Sending command [closeContainerCommand: containerID: 1001, pipelineID: PipelineID=05aed6cd-b189-4551-97b5-76e89ecb956c, force: true] for container ContainerInfo{id=#1001, state=QUASI_CLOSED, stateEnterTime=2024-01-15T07:59:27.189236Z, pipelineID=PipelineID=05aed6cd-b189-4551-97b5-76e89ecb956c, owner=omservice} to d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17) with datanode deadline 1705306245874 and scm deadline 1705306275874
2024-01-15 08:01:15,874 [scm1-ReplicationMonitor] INFO health.QuasiClosedContainerHandler: Force closing container #1002 with BCSID 11, which is in QUASI_CLOSED state.
2024-01-15 08:01:15,874 [scm1-ReplicationMonitor] INFO replication.ReplicationManager: Sending command [closeContainerCommand: containerID: 1002, pipelineID: PipelineID=8d2d4132-d1ad-4792-b8b3-58645b77e67c, force: true] for container ContainerInfo{id=#1002, state=QUASI_CLOSED, stateEnterTime=2024-01-15T07:59:27.755001Z, pipelineID=PipelineID=8d2d4132-d1ad-4792-b8b3-58645b77e67c, owner=omservice} to 577b93ae-aa5e-4de8-a35f-0c336284cb6e(ha_dn4_1.ha_net/10.9.0.20) with datanode deadline 1705306245874 and scm deadline 1705306275874
2024-01-15 08:01:15,875 [scm1-ReplicationMonitor] INFO replication.ReplicationManager: Sending command [closeContainerCommand: containerID: 1002, pipelineID: PipelineID=8d2d4132-d1ad-4792-b8b3-58645b77e67c, force: true] for container ContainerInfo{id=#1002, state=QUASI_CLOSED, stateEnterTime=2024-01-15T07:59:27.755001Z, pipelineID=PipelineID=8d2d4132-d1ad-4792-b8b3-58645b77e67c, owner=omservice} to d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17) with datanode deadline 1705306245875 and scm deadline 1705306275875
2024-01-15 08:01:15,875 [scm1-ReplicationMonitor] INFO replication.ReplicationManager: Sending command [closeContainerCommand: containerID: 1002, pipelineID: PipelineID=8d2d4132-d1ad-4792-b8b3-58645b77e67c, force: true] for container ContainerInfo{id=#1002, state=QUASI_CLOSED, stateEnterTime=2024-01-15T07:59:27.755001Z, pipelineID=PipelineID=8d2d4132-d1ad-4792-b8b3-58645b77e67c, owner=omservice} to 6df82867-8830-4371-a735-44f603d10388(ha_dn3_1.ha_net/10.9.0.19) with datanode deadline 1705306245875 and scm deadline 1705306275875
2024-01-15 08:01:15,875 [scm1-ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 9 milliseconds for processing 4 containers.
2024-01-15 08:01:18,916 [IPC Server handler 35 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.9.0.23
2024-01-15 08:01:25,362 [IPC Server handler 9 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.9.0.14
2024-01-15 08:01:32,347 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:46622 / 10.9.0.18:46622
2024-01-15 08:01:32,370 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:01:33,932 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:34108 / 10.9.0.17:34108
2024-01-15 08:01:33,945 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:45424 / 10.9.0.21:45424
2024-01-15 08:01:33,951 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:01:33,961 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:01:34,882 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:43610 / 10.9.0.20:43610
2024-01-15 08:01:34,899 [scm1-FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Moving container #1001 to CLOSED state, datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17) reported CLOSED replica.
2024-01-15 08:01:34,909 [scm1-FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Moving container #1 to CLOSED state, datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17) reported CLOSED replica.
2024-01-15 08:01:34,931 [scm1-FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Moving container #2 to CLOSED state, datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17) reported CLOSED replica.
2024-01-15 08:01:34,939 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:01:34,947 [scm1-FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Moving container #1002 to CLOSED state, datanode d8ef6392-c8b7-40ba-a1b4-c245afaf6945(ha_dn1_1.ha_net/10.9.0.17) reported CLOSED replica.
2024-01-15 08:01:36,039 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:55854 / 10.9.0.19:55854
2024-01-15 08:01:36,057 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:01:36,199 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om3_1.ha_net:54048 / 10.9.0.13:54048
2024-01-15 08:01:36,204 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2024-01-15 08:01:36,205 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.9.0.23
2024-01-15 08:01:45,893 [IPC Server handler 35 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.9.0.23
2024-01-15 08:01:58,353 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om3_1.ha_net:57722 / 10.9.0.13:57722
2024-01-15 08:01:58,357 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2024-01-15 08:01:58,367 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for containerId, expected lastId is 0, actual lastId is 2000.
2024-01-15 08:01:58,374 [IPC Server handler 9 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 2000 to 3000.
2024-01-15 08:01:58,388 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 113750153625603000.
2024-01-15 08:01:58,399 [IPC Server handler 9 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 113750153625603000 to 113750153625604000.
2024-01-15 08:01:59,732 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:53954 / 10.9.0.17:53954
2024-01-15 08:01:59,769 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:56764 / 10.9.0.20:56764
2024-01-15 08:01:59,798 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:01:59,804 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:01:59,860 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:49124 / 10.9.0.21:49124
2024-01-15 08:01:59,908 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:01:59,932 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from ha_recon_1.ha_net:46421 / 10.9.0.22:46421
2024-01-15 08:01:59,940 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2024-01-15 08:02:02,332 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:51010 / 10.9.0.18:51010
2024-01-15 08:02:02,345 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:02:07,063 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:36590 / 10.9.0.19:36590
2024-01-15 08:02:07,073 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:02:16,173 [scm1-SecretKeyManagerService] INFO symmetric.SecretKeyManager: SecretKey rotation is happening, new key generated SecretKey(id = c1f6048b-6d4b-45eb-9ff8-10fd96802102, creation at: 2024-01-15T08:02:16.172981Z, expire at: 2024-01-15T09:02:16.172981Z)
2024-01-15 08:02:16,180 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Updating keys with [SecretKey(id = 9bddd15d-aa6f-4d02-8759-c55324acb0bf, creation at: 2024-01-15T07:57:16.172Z, expire at: 2024-01-15T08:57:16.172Z), SecretKey(id = 17343b73-6203-4ee1-839d-499f80eed361, creation at: 2024-01-15T07:49:06.544Z, expire at: 2024-01-15T08:49:06.544Z), SecretKey(id = c1f6048b-6d4b-45eb-9ff8-10fd96802102, creation at: 2024-01-15T08:02:16.172Z, expire at: 2024-01-15T09:02:16.172Z)]
2024-01-15 08:02:16,185 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Current key updated SecretKey(id = c1f6048b-6d4b-45eb-9ff8-10fd96802102, creation at: 2024-01-15T08:02:16.172Z, expire at: 2024-01-15T09:02:16.172Z)
2024-01-15 08:02:16,189 [4e866cc2-839f-4d23-a8df-7474513825dc@group-A9985E8D8993-StateMachineUpdater] INFO symmetric.LocalSecretKeyStore: Saved [SecretKey(id = c1f6048b-6d4b-45eb-9ff8-10fd96802102, creation at: 2024-01-15T08:02:16.172Z, expire at: 2024-01-15T09:02:16.172Z), SecretKey(id = 9bddd15d-aa6f-4d02-8759-c55324acb0bf, creation at: 2024-01-15T07:57:16.172Z, expire at: 2024-01-15T08:57:16.172Z), SecretKey(id = 17343b73-6203-4ee1-839d-499f80eed361, creation at: 2024-01-15T07:49:06.544Z, expire at: 2024-01-15T08:49:06.544Z)] to file /data/metadata/scm/keys/secret_keys.json
2024-01-15 08:02:18,082 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om3_1.ha_net:36384 / 10.9.0.13:36384
2024-01-15 08:02:18,084 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2024-01-15 08:02:18,385 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:50778 / 10.9.0.21:50778
2024-01-15 08:02:18,389 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:55416 / 10.9.0.19:55416
2024-01-15 08:02:18,398 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:59060 / 10.9.0.17:59060
2024-01-15 08:02:18,403 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:02:18,447 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:02:18,477 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:02:18,499 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from ha_recon_1.ha_net:39053 / 10.9.0.22:39053
2024-01-15 08:02:18,505 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2024-01-15 08:02:24,658 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om3_1.ha_net:41656 / 10.9.0.13:41656
2024-01-15 08:02:24,662 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2024-01-15 08:02:24,665 [IPC Server handler 99 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.9.0.14
2024-01-15 08:02:32,183 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:34726 / 10.9.0.17:34726
2024-01-15 08:02:32,191 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:40078 / 10.9.0.20:40078
2024-01-15 08:02:32,193 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2024-01-15 08:02:32,201 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:39226 / 10.9.0.18:39226
2024-01-15 08:02:32,202 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2024-01-15 08:02:32,203 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2024-01-15 08:02:32,524 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:44972 / 10.9.0.21:44972
2024-01-15 08:02:32,532 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2024-01-15 08:02:32,649 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:48218 / 10.9.0.19:48218
2024-01-15 08:02:32,651 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2024-01-15 08:02:35,694 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om3_1.ha_net:60350 / 10.9.0.13:60350
2024-01-15 08:02:35,697 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2024-01-15 08:02:35,704 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om3_1.ha_net:40338 / 10.9.0.13:40338
2024-01-15 08:02:35,706 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2024-01-15 08:02:35,707 [IPC Server handler 35 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.9.0.23
2024-01-15 08:02:37,487 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:47734 / 10.9.0.20:47734
2024-01-15 08:02:37,519 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:02:37,570 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:43094 / 10.9.0.18:43094
2024-01-15 08:02:37,597 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:02:45,231 [IPC Server handler 2 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.9.0.23
2024-01-15 08:02:48,423 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:42444 / 10.9.0.17:42444
2024-01-15 08:02:48,447 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:47856 / 10.9.0.21:47856
2024-01-15 08:02:48,475 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:02:48,480 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:39494 / 10.9.0.19:39494
2024-01-15 08:02:48,485 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:02:48,515 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:02:48,582 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om3_1.ha_net:60138 / 10.9.0.13:60138
2024-01-15 08:02:48,591 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolOm
2024-01-15 08:02:49,375 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om1_1.ha_net:39318 / 10.9.0.11:39318
2024-01-15 08:02:49,377 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolOm
2024-01-15 08:02:50,779 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om2_1.ha_net:35504 / 10.9.0.12:35504
2024-01-15 08:02:50,782 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolOm
2024-01-15 08:02:53,824 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from scm1.org:41404 / 10.9.0.14:41404
2024-01-15 08:02:53,847 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2024-01-15 08:03:05,977 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om3_1.ha_net:47686 / 10.9.0.13:47686
2024-01-15 08:03:05,979 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2024-01-15 08:03:07,055 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:44756 / 10.9.0.19:44756
2024-01-15 08:03:07,064 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2024-01-15 08:03:07,481 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:47674 / 10.9.0.20:47674
2024-01-15 08:03:07,497 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:03:07,590 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:35466 / 10.9.0.18:35466
2024-01-15 08:03:07,596 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:03:16,334 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om3_1.ha_net:33744 / 10.9.0.13:33744
2024-01-15 08:03:16,336 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2024-01-15 08:03:18,387 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:43688 / 10.9.0.17:43688
2024-01-15 08:03:18,415 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:57318 / 10.9.0.19:57318
2024-01-15 08:03:18,427 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:43026 / 10.9.0.21:43026
2024-01-15 08:03:18,433 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:03:18,436 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:03:18,441 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:03:22,125 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:36492 / 10.9.0.20:36492
2024-01-15 08:03:22,130 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2024-01-15 08:03:37,349 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om3_1.ha_net:48204 / 10.9.0.13:48204
2024-01-15 08:03:37,350 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2024-01-15 08:03:37,351 [IPC Server handler 9 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.9.0.14
2024-01-15 08:03:37,495 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:49646 / 10.9.0.20:49646
2024-01-15 08:03:37,533 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:03:37,601 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:43898 / 10.9.0.18:43898
2024-01-15 08:03:37,615 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:03:41,929 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.9.0.14
2024-01-15 08:03:42,922 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:42098 / 10.9.0.18:42098
2024-01-15 08:03:42,929 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2024-01-15 08:03:46,124 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.9.0.14
2024-01-15 08:03:48,410 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:60152 / 10.9.0.17:60152
2024-01-15 08:03:48,442 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:03:48,446 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:59984 / 10.9.0.21:59984
2024-01-15 08:03:48,453 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:36552 / 10.9.0.19:36552
2024-01-15 08:03:48,460 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2024-01-15 08:03:48,511 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
